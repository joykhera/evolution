{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9457085892952308, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.856468547588934, "policy_loss": -0.005447705589215118, "vf_loss": 6.860763990059101, "vf_explained_var": -0.003484946741628899, "kl": 0.0057613128661171895, "entropy": 1.6038001957393828, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 945.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8773023879559583, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.626899068317716, "policy_loss": -0.004042532703982144, "vf_loss": 8.628756809486914, "vf_explained_var": 0.0007846050161533255, "kl": 0.010923980972583671, "entropy": 1.5985765355604666, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 945.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 4000, "num_env_steps_trained": 4000, "num_agent_steps_sampled": 16000, "num_agent_steps_trained": 16000}, "env_runners": {"episode_reward_max": 188.29999999999987, "episode_reward_min": -274.1, "episode_reward_mean": -43.38333333333349, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 3600, "policy_reward_min": {"prey_policy": -355.8999999999998, "predator_policy": 2.0}, "policy_reward_max": {"prey_policy": 173.89999999999998, "predator_policy": 183.0}, "policy_reward_mean": {"prey_policy": -95.49722222222239, "predator_policy": 73.80555555555556}, "custom_metrics": {}, "hist_stats": {"episode_reward": [131.9999999999992, 54.90000000000012, 9.400000000000261, -13.799999999999756, -197.80000000000064, -58.800000000001084, 12.50000000000024, 14.500000000000089, 22.400000000000162, -52.50000000000034, -139.90000000000018, 188.29999999999987, 19.10000000000017, -25.499999999999964, -212.00000000000037, -221.10000000000088, -274.1, -38.49999999999979], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-5.200000000000047, 117.19999999999976, 23.600000000000065, -33.69999999999999, 57.800000000000125, -162.40000000000038, 62.30000000000003, -254.1000000000004, -246.70000000000036, -174.1000000000003, 3.200000000000168, -169.00000000000057, -120.69999999999993, 36.20000000000012, -106.0000000000008, 42.50000000000011, -19.600000000000026, -103.0000000000006, -45.99999999999987, -122.5000000000006, -222.40000000000003, -128.5000000000002, 173.89999999999998, -61.60000000000025, -105.70000000000039, 42.800000000000104, 16.4, -355.8999999999998, -326.79999999999995, -128.19999999999985, -198.40000000000055, -207.70000000000033, -220.9000000000004, -320.2000000000002, -208.90000000000052, 34.40000000000022], "policy_predator_policy_reward": [18.0, 2.0, 50.0, 15.0, 88.0, 26.0, 77.0, 101.0, 100.0, 123.0, 90.0, 17.0, 67.0, 30.0, 18.0, 60.0, 53.0, 92.0, 43.0, 73.0, 82.0, 129.0, 17.0, 59.0, 17.0, 65.0, 183.0, 131.0, 169.0, 74.0, 130.0, 55.0, 147.0, 120.0, 56.0, 80.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8788837746679082, "mean_inference_ms": 2.518492030820316, "mean_action_processing_ms": 0.37576345684291784, "mean_env_wait_ms": 0.2824616047912951, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.012038151423136393, "StateBufferConnector_ms": 0.0038007895151774087, "ViewRequirementAgentConnector_ms": 0.10568896929423015}, "num_episodes": 18, "episode_return_max": 188.29999999999987, "episode_return_min": -274.1, "episode_return_mean": -43.38333333333349, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 16000, "num_agent_steps_trained": 16000, "num_env_steps_sampled": 4000, "num_env_steps_trained": 4000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 319.6668084701068, "num_env_steps_trained_throughput_per_sec": 319.6668084701068, "timesteps_total": 4000, "num_env_steps_sampled_lifetime": 4000, "num_agent_steps_sampled_lifetime": 16000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 16000, "timers": {"training_iteration_time_ms": 12513.037, "restore_workers_time_ms": 0.02, "training_step_time_ms": 12512.99, "sample_time_ms": 1984.764, "learn_time_ms": 10512.127, "learn_throughput": 380.513, "synch_weights_time_ms": 14.158}, "counters": {"num_env_steps_sampled": 4000, "num_env_steps_trained": 4000, "num_agent_steps_sampled": 16000, "num_agent_steps_trained": 16000}, "done": false, "training_iteration": 1, "trial_id": "3dae5_00000", "date": "2024-08-14_08-39-48", "timestamp": 1723639188, "time_this_iter_s": 12.5693199634552, "time_total_s": 12.5693199634552, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0f81670>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 12.5693199634552, "iterations_since_restore": 1, "perf": {"cpu_util_percent": 35.88947368421053, "ram_util_percent": 83.82631578947368}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.04353983484248, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.990349617458525, "policy_loss": -0.005640227551985946, "vf_loss": 5.994850225297231, "vf_explained_var": 0.01121786293529329, "kl": 0.005698000965832177, "entropy": 1.604044624295815, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 2835.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.366723298837268, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.840791658875803, "policy_loss": -0.004930502324852915, "vf_loss": 7.843265491818625, "vf_explained_var": 0.007238145101638067, "kl": 0.012283415120283333, "entropy": 1.588126122446918, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 2835.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 8000, "num_env_steps_trained": 8000, "num_agent_steps_sampled": 32000, "num_agent_steps_trained": 32000}, "env_runners": {"episode_reward_max": 188.29999999999987, "episode_reward_min": -274.1, "episode_reward_mean": -31.602777777777874, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 7200, "policy_reward_min": {"prey_policy": -355.8999999999998, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 173.89999999999998, "predator_policy": 183.0}, "policy_reward_mean": {"prey_policy": -85.74583333333347, "predator_policy": 69.94444444444444}, "custom_metrics": {}, "hist_stats": {"episode_reward": [131.9999999999992, 54.90000000000012, 9.400000000000261, -13.799999999999756, -197.80000000000064, -58.800000000001084, 12.50000000000024, 14.500000000000089, 22.400000000000162, -52.50000000000034, -139.90000000000018, 188.29999999999987, 19.10000000000017, -25.499999999999964, -212.00000000000037, -221.10000000000088, -274.1, -38.49999999999979, -43.900000000000276, 50.500000000000064, -3.69999999999982, -23.199999999999783, -70.09999999999967, -56.79999999999985, -88.8999999999998, 75.29999999999973, -37.50000000000018, -41.60000000000033, -46.599999999999994, 14.100000000000184, -36.499999999999716, -76.09999999999988, 70.79999999999997, 110.59999999999985, -49.89999999999994, -103.30000000000103], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-5.200000000000047, 117.19999999999976, 23.600000000000065, -33.69999999999999, 57.800000000000125, -162.40000000000038, 62.30000000000003, -254.1000000000004, -246.70000000000036, -174.1000000000003, 3.200000000000168, -169.00000000000057, -120.69999999999993, 36.20000000000012, -106.0000000000008, 42.50000000000011, -19.600000000000026, -103.0000000000006, -45.99999999999987, -122.5000000000006, -222.40000000000003, -128.5000000000002, 173.89999999999998, -61.60000000000025, -105.70000000000039, 42.800000000000104, 16.4, -355.8999999999998, -326.79999999999995, -128.19999999999985, -198.40000000000055, -207.70000000000033, -220.9000000000004, -320.2000000000002, -208.90000000000052, 34.40000000000022, -70.00000000000013, -91.9000000000008, 119.8999999999997, -201.39999999999998, 72.19999999999956, -190.90000000000032, -4.599999999999978, -139.6, -113.60000000000005, -80.50000000000003, -311.7999999999998, 56.00000000000023, -5.200000000000014, -225.70000000000047, -25.59999999999976, 65.89999999999988, -148.9000000000004, -31.599999999999937, -66.10000000000048, -113.50000000000014, -36.7, -187.9000000000003, -234.10000000000028, 96.19999999999953, -233.50000000000037, 20.000000000000014, -190.60000000000008, -53.499999999999766, 32.90000000000002, -6.0999999999999375, 147.79999999999998, -89.1999999999999, 75.80000000000018, -330.70000000000016, -259.29999999999905, 20.000000000000014], "policy_predator_policy_reward": [18.0, 2.0, 50.0, 15.0, 88.0, 26.0, 77.0, 101.0, 100.0, 123.0, 90.0, 17.0, 67.0, 30.0, 18.0, 60.0, 53.0, 92.0, 43.0, 73.0, 82.0, 129.0, 17.0, 59.0, 17.0, 65.0, 183.0, 131.0, 169.0, 74.0, 130.0, 55.0, 147.0, 120.0, 56.0, 80.0, 63.0, 55.0, 52.0, 80.0, 100.0, 15.0, 25.0, 96.0, 50.0, 74.0, 142.0, 57.0, 86.0, 56.0, 0.0, 35.0, 47.0, 96.0, 41.0, 97.0, 112.0, 66.0, 95.0, 57.0, 107.0, 70.0, 115.0, 53.0, 7.0, 37.0, 52.0, 0.0, 41.0, 164.0, 133.0, 3.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8226483302748063, "mean_inference_ms": 2.4077026587571075, "mean_action_processing_ms": 0.34865633378813643, "mean_env_wait_ms": 0.269656625283944, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.009392367468939887, "StateBufferConnector_ms": 0.0034713082843356663, "ViewRequirementAgentConnector_ms": 0.10212229357825385}, "num_episodes": 18, "episode_return_max": 188.29999999999987, "episode_return_min": -274.1, "episode_return_mean": -31.602777777777874, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 32000, "num_agent_steps_trained": 32000, "num_env_steps_sampled": 8000, "num_env_steps_trained": 8000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 345.36964430740085, "num_env_steps_trained_throughput_per_sec": 345.36964430740085, "timesteps_total": 8000, "num_env_steps_sampled_lifetime": 8000, "num_agent_steps_sampled_lifetime": 32000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 32000, "timers": {"training_iteration_time_ms": 12047.426, "restore_workers_time_ms": 0.029, "training_step_time_ms": 12047.359, "sample_time_ms": 1743.324, "learn_time_ms": 10287.085, "learn_throughput": 388.837, "synch_weights_time_ms": 15.079}, "counters": {"num_env_steps_sampled": 8000, "num_env_steps_trained": 8000, "num_agent_steps_sampled": 32000, "num_agent_steps_trained": 32000}, "done": false, "training_iteration": 2, "trial_id": "3dae5_00000", "date": "2024-08-14_08-40-02", "timestamp": 1723639202, "time_this_iter_s": 11.621181011199951, "time_total_s": 24.19050097465515, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b1111ee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 24.19050097465515, "iterations_since_restore": 2, "perf": {"cpu_util_percent": 29.915, "ram_util_percent": 83.655}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0934282180335786, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.883614576052105, "policy_loss": -0.007021631432756309, "vf_loss": 4.888845131132338, "vf_explained_var": 0.028426376631650974, "kl": 0.008955396675342243, "entropy": 1.5954190159600878, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 4725.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.1148309919096175, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.115162485364884, "policy_loss": -0.002369585460564368, "vf_loss": 7.116263631790403, "vf_explained_var": 0.004718189075510338, "kl": 0.0063421430082334414, "entropy": 1.5727213069244668, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 4725.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 12000, "num_env_steps_trained": 12000, "num_agent_steps_sampled": 48000, "num_agent_steps_trained": 48000}, "env_runners": {"episode_reward_max": 188.29999999999987, "episode_reward_min": -430.2999999999992, "episode_reward_mean": -50.56296296296313, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 10800, "policy_reward_min": {"prey_policy": -355.8999999999998, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 173.89999999999998, "predator_policy": 186.0}, "policy_reward_mean": {"prey_policy": -95.36481481481496, "predator_policy": 70.08333333333333}, "custom_metrics": {}, "hist_stats": {"episode_reward": [131.9999999999992, 54.90000000000012, 9.400000000000261, -13.799999999999756, -197.80000000000064, -58.800000000001084, 12.50000000000024, 14.500000000000089, 22.400000000000162, -52.50000000000034, -139.90000000000018, 188.29999999999987, 19.10000000000017, -25.499999999999964, -212.00000000000037, -221.10000000000088, -274.1, -38.49999999999979, -43.900000000000276, 50.500000000000064, -3.69999999999982, -23.199999999999783, -70.09999999999967, -56.79999999999985, -88.8999999999998, 75.29999999999973, -37.50000000000018, -41.60000000000033, -46.599999999999994, 14.100000000000184, -36.499999999999716, -76.09999999999988, 70.79999999999997, 110.59999999999985, -49.89999999999994, -103.30000000000103, -31.499999999999773, -164.30000000000038, 137.89999999999952, 86.89999999999975, -105.80000000000047, -83.39999999999986, 9.3, -129.90000000000126, -25.69999999999971, -430.2999999999992, 78.49999999999925, 3.2000000000001663, -112.40000000000114, -261.5000000000004, -30.699999999999882, -184.00000000000063, -126.90000000000066, -222.1000000000007], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-5.200000000000047, 117.19999999999976, 23.600000000000065, -33.69999999999999, 57.800000000000125, -162.40000000000038, 62.30000000000003, -254.1000000000004, -246.70000000000036, -174.1000000000003, 3.200000000000168, -169.00000000000057, -120.69999999999993, 36.20000000000012, -106.0000000000008, 42.50000000000011, -19.600000000000026, -103.0000000000006, -45.99999999999987, -122.5000000000006, -222.40000000000003, -128.5000000000002, 173.89999999999998, -61.60000000000025, -105.70000000000039, 42.800000000000104, 16.4, -355.8999999999998, -326.79999999999995, -128.19999999999985, -198.40000000000055, -207.70000000000033, -220.9000000000004, -320.2000000000002, -208.90000000000052, 34.40000000000022, -70.00000000000013, -91.9000000000008, 119.8999999999997, -201.39999999999998, 72.19999999999956, -190.90000000000032, -4.599999999999978, -139.6, -113.60000000000005, -80.50000000000003, -311.7999999999998, 56.00000000000023, -5.200000000000014, -225.70000000000047, -25.59999999999976, 65.89999999999988, -148.9000000000004, -31.599999999999937, -66.10000000000048, -113.50000000000014, -36.7, -187.9000000000003, -234.10000000000028, 96.19999999999953, -233.50000000000037, 20.000000000000014, -190.60000000000008, -53.499999999999766, 32.90000000000002, -6.0999999999999375, 147.79999999999998, -89.1999999999999, 75.80000000000018, -330.70000000000016, -259.29999999999905, 20.000000000000014, -78.70000000000063, -44.79999999999988, -139.60000000000016, -147.70000000000024, 77.89999999999995, 20.000000000000014, -10.599999999999978, 9.500000000000108, -82.90000000000012, -187.9000000000005, -83.20000000000071, -122.20000000000056, -5.200000000000015, -32.49999999999975, -130.30000000000067, -160.6000000000006, 20.000000000000014, -147.70000000000036, -347.4999999999999, -290.8000000000002, -103.9000000000006, 118.39999999999958, -1.000000000000024, -47.79999999999979, -49.299999999999905, -213.10000000000034, -244.0, -263.50000000000034, 28.100000000000147, -245.79999999999995, -172.00000000000045, -240.0000000000002, -139.89999999999992, -196.0000000000003, -242.50000000000034, -228.60000000000036], "policy_predator_policy_reward": [18.0, 2.0, 50.0, 15.0, 88.0, 26.0, 77.0, 101.0, 100.0, 123.0, 90.0, 17.0, 67.0, 30.0, 18.0, 60.0, 53.0, 92.0, 43.0, 73.0, 82.0, 129.0, 17.0, 59.0, 17.0, 65.0, 183.0, 131.0, 169.0, 74.0, 130.0, 55.0, 147.0, 120.0, 56.0, 80.0, 63.0, 55.0, 52.0, 80.0, 100.0, 15.0, 25.0, 96.0, 50.0, 74.0, 142.0, 57.0, 86.0, 56.0, 0.0, 35.0, 47.0, 96.0, 41.0, 97.0, 112.0, 66.0, 95.0, 57.0, 107.0, 70.0, 115.0, 53.0, 7.0, 37.0, 52.0, 0.0, 41.0, 164.0, 133.0, 3.0, 0.0, 92.0, 17.0, 106.0, 29.0, 11.0, 80.0, 8.0, 31.0, 134.0, 25.0, 97.0, 12.0, 35.0, 86.0, 75.0, 19.0, 83.0, 22.0, 186.0, 5.0, 59.0, 16.0, 36.0, 33.0, 117.0, 68.0, 178.0, 38.0, 149.0, 82.0, 146.0, 95.0, 114.0, 124.0, 125.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7876686203471314, "mean_inference_ms": 2.334131622144414, "mean_action_processing_ms": 0.3326322341701298, "mean_env_wait_ms": 0.26113556885087924, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.014052788416544596, "StateBufferConnector_ms": 0.0034820150446008753, "ViewRequirementAgentConnector_ms": 0.10182393921746148}, "num_episodes": 18, "episode_return_max": 188.29999999999987, "episode_return_min": -430.2999999999992, "episode_return_mean": -50.56296296296313, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 48000, "num_agent_steps_trained": 48000, "num_env_steps_sampled": 12000, "num_env_steps_trained": 12000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 339.75062985294477, "num_env_steps_trained_throughput_per_sec": 339.75062985294477, "timesteps_total": 12000, "num_env_steps_sampled_lifetime": 12000, "num_agent_steps_sampled_lifetime": 48000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 48000, "timers": {"training_iteration_time_ms": 11956.067, "restore_workers_time_ms": 0.024, "training_step_time_ms": 11956.009, "sample_time_ms": 1649.436, "learn_time_ms": 10287.816, "learn_throughput": 388.809, "synch_weights_time_ms": 16.374}, "counters": {"num_env_steps_sampled": 12000, "num_env_steps_trained": 12000, "num_agent_steps_sampled": 48000, "num_agent_steps_trained": 48000}, "done": false, "training_iteration": 3, "trial_id": "3dae5_00000", "date": "2024-08-14_08-40-14", "timestamp": 1723639214, "time_this_iter_s": 11.79473876953125, "time_total_s": 35.9852397441864, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b1111f70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 35.9852397441864, "iterations_since_restore": 3, "perf": {"cpu_util_percent": 35.28125, "ram_util_percent": 83.5875}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0870191044277615, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.255790333268504, "policy_loss": -0.01274782673064028, "vf_loss": 6.265408913799064, "vf_explained_var": 0.012519230319078638, "kl": 0.01564632190487089, "entropy": 1.5666566848754884, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 6615.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.023883142373549, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.916494834486139, "policy_loss": -0.0033908933489805175, "vf_loss": 6.918198903906283, "vf_explained_var": 0.005139475997793612, "kl": 0.00843425742194093, "entropy": 1.580267789124181, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 6615.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 16000, "num_env_steps_trained": 16000, "num_agent_steps_sampled": 64000, "num_agent_steps_trained": 64000}, "env_runners": {"episode_reward_max": 188.29999999999987, "episode_reward_min": -430.2999999999992, "episode_reward_mean": -44.290277777777916, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 14400, "policy_reward_min": {"prey_policy": -416.3, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 173.89999999999998, "predator_policy": 251.0}, "policy_reward_mean": {"prey_policy": -89.04097222222234, "predator_policy": 66.89583333333333}, "custom_metrics": {}, "hist_stats": {"episode_reward": [131.9999999999992, 54.90000000000012, 9.400000000000261, -13.799999999999756, -197.80000000000064, -58.800000000001084, 12.50000000000024, 14.500000000000089, 22.400000000000162, -52.50000000000034, -139.90000000000018, 188.29999999999987, 19.10000000000017, -25.499999999999964, -212.00000000000037, -221.10000000000088, -274.1, -38.49999999999979, -43.900000000000276, 50.500000000000064, -3.69999999999982, -23.199999999999783, -70.09999999999967, -56.79999999999985, -88.8999999999998, 75.29999999999973, -37.50000000000018, -41.60000000000033, -46.599999999999994, 14.100000000000184, -36.499999999999716, -76.09999999999988, 70.79999999999997, 110.59999999999985, -49.89999999999994, -103.30000000000103, -31.499999999999773, -164.30000000000038, 137.89999999999952, 86.89999999999975, -105.80000000000047, -83.39999999999986, 9.3, -129.90000000000126, -25.69999999999971, -430.2999999999992, 78.49999999999925, 3.2000000000001663, -112.40000000000114, -261.5000000000004, -30.699999999999882, -184.00000000000063, -126.90000000000066, -222.1000000000007, 152.0999999999994, -49.50000000000082, -49.69999999999968, -123.30000000000106, -9.299999999999788, -98.60000000000004, 61.600000000000215, -106.10000000000002, 61.000000000000355, -33.89999999999998, -100.30000000000024, -138.39999999999998, 67.90000000000006, -99.09999999999982, -34.400000000000034, 37.400000000000276, -10.200000000000081, 14.300000000000125], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-5.200000000000047, 117.19999999999976, 23.600000000000065, -33.69999999999999, 57.800000000000125, -162.40000000000038, 62.30000000000003, -254.1000000000004, -246.70000000000036, -174.1000000000003, 3.200000000000168, -169.00000000000057, -120.69999999999993, 36.20000000000012, -106.0000000000008, 42.50000000000011, -19.600000000000026, -103.0000000000006, -45.99999999999987, -122.5000000000006, -222.40000000000003, -128.5000000000002, 173.89999999999998, -61.60000000000025, -105.70000000000039, 42.800000000000104, 16.4, -355.8999999999998, -326.79999999999995, -128.19999999999985, -198.40000000000055, -207.70000000000033, -220.9000000000004, -320.2000000000002, -208.90000000000052, 34.40000000000022, -70.00000000000013, -91.9000000000008, 119.8999999999997, -201.39999999999998, 72.19999999999956, -190.90000000000032, -4.599999999999978, -139.6, -113.60000000000005, -80.50000000000003, -311.7999999999998, 56.00000000000023, -5.200000000000014, -225.70000000000047, -25.59999999999976, 65.89999999999988, -148.9000000000004, -31.599999999999937, -66.10000000000048, -113.50000000000014, -36.7, -187.9000000000003, -234.10000000000028, 96.19999999999953, -233.50000000000037, 20.000000000000014, -190.60000000000008, -53.499999999999766, 32.90000000000002, -6.0999999999999375, 147.79999999999998, -89.1999999999999, 75.80000000000018, -330.70000000000016, -259.29999999999905, 20.000000000000014, -78.70000000000063, -44.79999999999988, -139.60000000000016, -147.70000000000024, 77.89999999999995, 20.000000000000014, -10.599999999999978, 9.500000000000108, -82.90000000000012, -187.9000000000005, -83.20000000000071, -122.20000000000056, -5.200000000000015, -32.49999999999975, -130.30000000000067, -160.6000000000006, 20.000000000000014, -147.70000000000036, -347.4999999999999, -290.8000000000002, -103.9000000000006, 118.39999999999958, -1.000000000000024, -47.79999999999979, -49.299999999999905, -213.10000000000034, -244.0, -263.50000000000034, 28.100000000000147, -245.79999999999995, -172.00000000000045, -240.0000000000002, -139.89999999999992, -196.0000000000003, -242.50000000000034, -228.60000000000036, 12.499999999999943, 113.5999999999999, -55.600000000000136, -61.90000000000068, -126.40000000000043, -25.29999999999975, -27.9999999999998, -376.299999999999, -240.4000000000004, 97.10000000000002, -93.40000000000003, -131.19999999999982, 17.900000000000006, -28.29999999999994, 7.399999999999965, -308.5, 20.000000000000014, 29.000000000000185, -148.00000000000063, 1.1000000000001364, -40.89999999999991, -210.4000000000002, -109.89999999999992, -179.50000000000009, -6.100000000000014, 20.000000000000014, -41.79999999999983, -416.3, -62.19999999999987, -47.19999999999979, -7.599999999999904, 20.000000000000014, -68.2000000000001, 4.99999999999997, -85.0000000000004, 32.300000000000246], "policy_predator_policy_reward": [18.0, 2.0, 50.0, 15.0, 88.0, 26.0, 77.0, 101.0, 100.0, 123.0, 90.0, 17.0, 67.0, 30.0, 18.0, 60.0, 53.0, 92.0, 43.0, 73.0, 82.0, 129.0, 17.0, 59.0, 17.0, 65.0, 183.0, 131.0, 169.0, 74.0, 130.0, 55.0, 147.0, 120.0, 56.0, 80.0, 63.0, 55.0, 52.0, 80.0, 100.0, 15.0, 25.0, 96.0, 50.0, 74.0, 142.0, 57.0, 86.0, 56.0, 0.0, 35.0, 47.0, 96.0, 41.0, 97.0, 112.0, 66.0, 95.0, 57.0, 107.0, 70.0, 115.0, 53.0, 7.0, 37.0, 52.0, 0.0, 41.0, 164.0, 133.0, 3.0, 0.0, 92.0, 17.0, 106.0, 29.0, 11.0, 80.0, 8.0, 31.0, 134.0, 25.0, 97.0, 12.0, 35.0, 86.0, 75.0, 19.0, 83.0, 22.0, 186.0, 5.0, 59.0, 16.0, 36.0, 33.0, 117.0, 68.0, 178.0, 38.0, 149.0, 82.0, 146.0, 95.0, 114.0, 124.0, 125.0, 25.0, 1.0, 26.0, 42.0, 22.0, 80.0, 251.0, 30.0, 10.0, 124.0, 59.0, 67.0, 56.0, 16.0, 42.0, 153.0, 9.0, 3.0, 52.0, 61.0, 88.0, 63.0, 1.0, 150.0, 32.0, 22.0, 116.0, 243.0, 29.0, 46.0, 8.0, 17.0, 7.0, 46.0, 34.0, 33.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7620866566285117, "mean_inference_ms": 2.2857277123681823, "mean_action_processing_ms": 0.32214062471034843, "mean_env_wait_ms": 0.2552790354288736, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.012262993388705783, "StateBufferConnector_ms": 0.004306601153479682, "ViewRequirementAgentConnector_ms": 0.10461542341444227}, "num_episodes": 18, "episode_return_max": 188.29999999999987, "episode_return_min": -430.2999999999992, "episode_return_mean": -44.290277777777916, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 64000, "num_agent_steps_trained": 64000, "num_env_steps_sampled": 16000, "num_env_steps_trained": 16000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 339.8771830907393, "num_env_steps_trained_throughput_per_sec": 339.8771830907393, "timesteps_total": 16000, "num_env_steps_sampled_lifetime": 16000, "num_agent_steps_sampled_lifetime": 64000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 64000, "timers": {"training_iteration_time_ms": 11909.291, "restore_workers_time_ms": 0.021, "training_step_time_ms": 11909.239, "sample_time_ms": 1606.993, "learn_time_ms": 10284.519, "learn_throughput": 388.934, "synch_weights_time_ms": 15.768}, "counters": {"num_env_steps_sampled": 16000, "num_env_steps_trained": 16000, "num_agent_steps_sampled": 64000, "num_agent_steps_trained": 64000}, "done": false, "training_iteration": 4, "trial_id": "3dae5_00000", "date": "2024-08-14_08-40-26", "timestamp": 1723639226, "time_this_iter_s": 11.775454998016357, "time_total_s": 47.76069474220276, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b117c1f0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 47.76069474220276, "iterations_since_restore": 4, "perf": {"cpu_util_percent": 33.970588235294116, "ram_util_percent": 82.67058823529412}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1156198044460286, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.831069202271719, "policy_loss": -0.0034454126539270554, "vf_loss": 4.833743496798965, "vf_explained_var": 0.001664075081941312, "kl": 0.003855575177672323, "entropy": 1.562439358738995, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 8505.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6691883545230937, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.211839345270994, "policy_loss": -0.005831910375254376, "vf_loss": 5.21545761615511, "vf_explained_var": 0.015177368234705042, "kl": 0.01106824292259542, "entropy": 1.5969553361494075, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 8505.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 20000, "num_env_steps_trained": 20000, "num_agent_steps_sampled": 80000, "num_agent_steps_trained": 80000}, "env_runners": {"episode_reward_max": 239.59999999999906, "episode_reward_min": -430.2999999999992, "episode_reward_mean": -37.15959595959608, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 19800, "policy_reward_min": {"prey_policy": -573.5, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 192.79999999999995, "predator_policy": 449.0}, "policy_reward_mean": {"prey_policy": -92.7111111111112, "predator_policy": 74.13131313131314}, "custom_metrics": {}, "hist_stats": {"episode_reward": [131.9999999999992, 54.90000000000012, 9.400000000000261, -13.799999999999756, -197.80000000000064, -58.800000000001084, 12.50000000000024, 14.500000000000089, 22.400000000000162, -52.50000000000034, -139.90000000000018, 188.29999999999987, 19.10000000000017, -25.499999999999964, -212.00000000000037, -221.10000000000088, -274.1, -38.49999999999979, -43.900000000000276, 50.500000000000064, -3.69999999999982, -23.199999999999783, -70.09999999999967, -56.79999999999985, -88.8999999999998, 75.29999999999973, -37.50000000000018, -41.60000000000033, -46.599999999999994, 14.100000000000184, -36.499999999999716, -76.09999999999988, 70.79999999999997, 110.59999999999985, -49.89999999999994, -103.30000000000103, -31.499999999999773, -164.30000000000038, 137.89999999999952, 86.89999999999975, -105.80000000000047, -83.39999999999986, 9.3, -129.90000000000126, -25.69999999999971, -430.2999999999992, 78.49999999999925, 3.2000000000001663, -112.40000000000114, -261.5000000000004, -30.699999999999882, -184.00000000000063, -126.90000000000066, -222.1000000000007, 152.0999999999994, -49.50000000000082, -49.69999999999968, -123.30000000000106, -9.299999999999788, -98.60000000000004, 61.600000000000215, -106.10000000000002, 61.000000000000355, -33.89999999999998, -100.30000000000024, -138.39999999999998, 67.90000000000006, -99.09999999999982, -34.400000000000034, 37.400000000000276, -10.200000000000081, 14.300000000000125, 7.300000000000168, 16.900000000000176, 136.99999999999955, 10.400000000000254, 52.90000000000033, 13.59999999999997, -244.5000000000003, -307.1999999999998, 239.59999999999906, -203.50000000000074, 20.500000000000004, -10.599999999999623, 0.4000000000001268, -51.69999999999966, -108.40000000000083, 115.39999999999971, -45.69999999999958, -38.69999999999974, -164.39999999999966, 140.89999999999927, 83.69999999999911, 21.600000000000016, -53.69999999999974, 11.399999999999956, -38.399999999999714, -151.90000000000092, 57.200000000000244], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-5.200000000000047, 117.19999999999976, 23.600000000000065, -33.69999999999999, 57.800000000000125, -162.40000000000038, 62.30000000000003, -254.1000000000004, -246.70000000000036, -174.1000000000003, 3.200000000000168, -169.00000000000057, -120.69999999999993, 36.20000000000012, -106.0000000000008, 42.50000000000011, -19.600000000000026, -103.0000000000006, -45.99999999999987, -122.5000000000006, -222.40000000000003, -128.5000000000002, 173.89999999999998, -61.60000000000025, -105.70000000000039, 42.800000000000104, 16.4, -355.8999999999998, -326.79999999999995, -128.19999999999985, -198.40000000000055, -207.70000000000033, -220.9000000000004, -320.2000000000002, -208.90000000000052, 34.40000000000022, -70.00000000000013, -91.9000000000008, 119.8999999999997, -201.39999999999998, 72.19999999999956, -190.90000000000032, -4.599999999999978, -139.6, -113.60000000000005, -80.50000000000003, -311.7999999999998, 56.00000000000023, -5.200000000000014, -225.70000000000047, -25.59999999999976, 65.89999999999988, -148.9000000000004, -31.599999999999937, -66.10000000000048, -113.50000000000014, -36.7, -187.9000000000003, -234.10000000000028, 96.19999999999953, -233.50000000000037, 20.000000000000014, -190.60000000000008, -53.499999999999766, 32.90000000000002, -6.0999999999999375, 147.79999999999998, -89.1999999999999, 75.80000000000018, -330.70000000000016, -259.29999999999905, 20.000000000000014, -78.70000000000063, -44.79999999999988, -139.60000000000016, -147.70000000000024, 77.89999999999995, 20.000000000000014, -10.599999999999978, 9.500000000000108, -82.90000000000012, -187.9000000000005, -83.20000000000071, -122.20000000000056, -5.200000000000015, -32.49999999999975, -130.30000000000067, -160.6000000000006, 20.000000000000014, -147.70000000000036, -347.4999999999999, -290.8000000000002, -103.9000000000006, 118.39999999999958, -1.000000000000024, -47.79999999999979, -49.299999999999905, -213.10000000000034, -244.0, -263.50000000000034, 28.100000000000147, -245.79999999999995, -172.00000000000045, -240.0000000000002, -139.89999999999992, -196.0000000000003, -242.50000000000034, -228.60000000000036, 12.499999999999943, 113.5999999999999, -55.600000000000136, -61.90000000000068, -126.40000000000043, -25.29999999999975, -27.9999999999998, -376.299999999999, -240.4000000000004, 97.10000000000002, -93.40000000000003, -131.19999999999982, 17.900000000000006, -28.29999999999994, 7.399999999999965, -308.5, 20.000000000000014, 29.000000000000185, -148.00000000000063, 1.1000000000001364, -40.89999999999991, -210.4000000000002, -109.89999999999992, -179.50000000000009, -6.100000000000014, 20.000000000000014, -41.79999999999983, -416.3, -62.19999999999987, -47.19999999999979, -7.599999999999904, 20.000000000000014, -68.2000000000001, 4.99999999999997, -85.0000000000004, 32.300000000000246, 21.80000000000004, -477.4999999999999, -446.09999999999917, 20.000000000000014, 23.00000000000009, 86.0, -51.69999999999977, -10.899999999999986, 44.30000000000015, -30.39999999999975, -9.399999999999876, -1.0000000000000275, -210.40000000000018, -366.1000000000002, -222.7999999999999, -338.40000000000026, 45.80000000000023, 192.79999999999995, -142.49999999999997, -570.9999999999999, 16.09999999999995, -34.59999999999975, -76.60000000000088, 20.000000000000014, 15.499999999999982, -138.1000000000001, -222.70000000000047, 20.000000000000014, -72.40000000000086, -324.99999999999994, -573.5, 137.89999999999972, 13.699999999999964, -141.4000000000006, -535.1999999999998, -11.499999999999819, -103.5, -214.90000000000055, -1.2999999999999847, 123.19999999999976, 99.19999999999956, -95.50000000000082, -76.60000000000073, 36.20000000000026, 15.799999999999963, -242.50000000000034, 20.000000000000014, -46.599999999999795, 5.299999999999976, -273.69999999999936, -39.99999999999983, -329.8999999999991, 36.20000000000006, -94.00000000000026], "policy_predator_policy_reward": [18.0, 2.0, 50.0, 15.0, 88.0, 26.0, 77.0, 101.0, 100.0, 123.0, 90.0, 17.0, 67.0, 30.0, 18.0, 60.0, 53.0, 92.0, 43.0, 73.0, 82.0, 129.0, 17.0, 59.0, 17.0, 65.0, 183.0, 131.0, 169.0, 74.0, 130.0, 55.0, 147.0, 120.0, 56.0, 80.0, 63.0, 55.0, 52.0, 80.0, 100.0, 15.0, 25.0, 96.0, 50.0, 74.0, 142.0, 57.0, 86.0, 56.0, 0.0, 35.0, 47.0, 96.0, 41.0, 97.0, 112.0, 66.0, 95.0, 57.0, 107.0, 70.0, 115.0, 53.0, 7.0, 37.0, 52.0, 0.0, 41.0, 164.0, 133.0, 3.0, 0.0, 92.0, 17.0, 106.0, 29.0, 11.0, 80.0, 8.0, 31.0, 134.0, 25.0, 97.0, 12.0, 35.0, 86.0, 75.0, 19.0, 83.0, 22.0, 186.0, 5.0, 59.0, 16.0, 36.0, 33.0, 117.0, 68.0, 178.0, 38.0, 149.0, 82.0, 146.0, 95.0, 114.0, 124.0, 125.0, 25.0, 1.0, 26.0, 42.0, 22.0, 80.0, 251.0, 30.0, 10.0, 124.0, 59.0, 67.0, 56.0, 16.0, 42.0, 153.0, 9.0, 3.0, 52.0, 61.0, 88.0, 63.0, 1.0, 150.0, 32.0, 22.0, 116.0, 243.0, 29.0, 46.0, 8.0, 17.0, 7.0, 46.0, 34.0, 33.0, 264.0, 199.0, 171.0, 272.0, 26.0, 2.0, 28.0, 45.0, 24.0, 15.0, 14.0, 10.0, 82.0, 250.0, 20.0, 234.0, 0.0, 1.0, 449.0, 61.0, 2.0, 37.0, 46.0, 0.0, 54.0, 69.0, 104.0, 47.0, 87.0, 202.0, 317.0, 234.0, 3.0, 79.0, 234.0, 274.0, 113.0, 41.0, 9.0, 10.0, 52.0, 28.0, 27.0, 35.0, 68.0, 105.0, 10.0, 28.0, 154.0, 76.0, 176.0, 42.0, 40.0, 75.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7377497170265429, "mean_inference_ms": 2.234365952116224, "mean_action_processing_ms": 0.311349214746712, "mean_env_wait_ms": 0.24849052423819049, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.011210248927877408, "StateBufferConnector_ms": 0.0040916481403389365, "ViewRequirementAgentConnector_ms": 0.10792667215520685}, "num_episodes": 27, "episode_return_max": 239.59999999999906, "episode_return_min": -430.2999999999992, "episode_return_mean": -37.15959595959608, "episodes_this_iter": 27}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 80000, "num_agent_steps_trained": 80000, "num_env_steps_sampled": 20000, "num_env_steps_trained": 20000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 338.9178883253169, "num_env_steps_trained_throughput_per_sec": 338.9178883253169, "timesteps_total": 20000, "num_env_steps_sampled_lifetime": 20000, "num_agent_steps_sampled_lifetime": 80000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 80000, "timers": {"training_iteration_time_ms": 11887.89, "restore_workers_time_ms": 0.02, "training_step_time_ms": 11887.835, "sample_time_ms": 1567.755, "learn_time_ms": 10302.31, "learn_throughput": 388.262, "synch_weights_time_ms": 15.955}, "counters": {"num_env_steps_sampled": 20000, "num_env_steps_trained": 20000, "num_agent_steps_sampled": 80000, "num_agent_steps_trained": 80000}, "done": false, "training_iteration": 5, "trial_id": "3dae5_00000", "date": "2024-08-14_08-40-38", "timestamp": 1723639238, "time_this_iter_s": 11.808718204498291, "time_total_s": 59.56941294670105, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b116a9d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 59.56941294670105, "iterations_since_restore": 5, "perf": {"cpu_util_percent": 31.53529411764706, "ram_util_percent": 82.88235294117646}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.205315490879079, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.2484285146471055, "policy_loss": -0.009859513062934476, "vf_loss": 3.2570102147324373, "vf_explained_var": 0.00726278821627299, "kl": 0.012778168587872705, "entropy": 1.563770355244793, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 10395.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9237973102186092, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.685783834936758, "policy_loss": -0.00285723234943198, "vf_loss": 4.687123119768011, "vf_explained_var": 0.003716390505038872, "kl": 0.007589714033335522, "entropy": 1.5882519282361187, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 10395.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 24000, "num_env_steps_trained": 24000, "num_agent_steps_sampled": 96000, "num_agent_steps_trained": 96000}, "env_runners": {"episode_reward_max": 239.59999999999906, "episode_reward_min": -430.2999999999992, "episode_reward_mean": -28.83900000000015, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -573.5, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 192.79999999999995, "predator_policy": 449.0}, "policy_reward_mean": {"prey_policy": -83.15450000000008, "predator_policy": 68.735}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-38.49999999999979, -43.900000000000276, 50.500000000000064, -3.69999999999982, -23.199999999999783, -70.09999999999967, -56.79999999999985, -88.8999999999998, 75.29999999999973, -37.50000000000018, -41.60000000000033, -46.599999999999994, 14.100000000000184, -36.499999999999716, -76.09999999999988, 70.79999999999997, 110.59999999999985, -49.89999999999994, -103.30000000000103, -31.499999999999773, -164.30000000000038, 137.89999999999952, 86.89999999999975, -105.80000000000047, -83.39999999999986, 9.3, -129.90000000000126, -25.69999999999971, -430.2999999999992, 78.49999999999925, 3.2000000000001663, -112.40000000000114, -261.5000000000004, -30.699999999999882, -184.00000000000063, -126.90000000000066, -222.1000000000007, 152.0999999999994, -49.50000000000082, -49.69999999999968, -123.30000000000106, -9.299999999999788, -98.60000000000004, 61.600000000000215, -106.10000000000002, 61.000000000000355, -33.89999999999998, -100.30000000000024, -138.39999999999998, 67.90000000000006, -99.09999999999982, -34.400000000000034, 37.400000000000276, -10.200000000000081, 14.300000000000125, 7.300000000000168, 16.900000000000176, 136.99999999999955, 10.400000000000254, 52.90000000000033, 13.59999999999997, -244.5000000000003, -307.1999999999998, 239.59999999999906, -203.50000000000074, 20.500000000000004, -10.599999999999623, 0.4000000000001268, -51.69999999999966, -108.40000000000083, 115.39999999999971, -45.69999999999958, -38.69999999999974, -164.39999999999966, 140.89999999999927, 83.69999999999911, 21.600000000000016, -53.69999999999974, 11.399999999999956, -38.399999999999714, -151.90000000000092, 57.200000000000244, -50.79999999999967, 90.59999999999988, 25.70000000000007, 20.80000000000007, 90.99999999999937, 33.2000000000002, -19.900000000000013, 86.60000000000007, -74.40000000000146, -77.20000000000127, -91.90000000000069, -91.50000000000155, 27.40000000000022, 20.100000000000023, -109.60000000000011, 13.500000000000039, 77.69999999999929, 81.19999999999925], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-208.90000000000052, 34.40000000000022, -70.00000000000013, -91.9000000000008, 119.8999999999997, -201.39999999999998, 72.19999999999956, -190.90000000000032, -4.599999999999978, -139.6, -113.60000000000005, -80.50000000000003, -311.7999999999998, 56.00000000000023, -5.200000000000014, -225.70000000000047, -25.59999999999976, 65.89999999999988, -148.9000000000004, -31.599999999999937, -66.10000000000048, -113.50000000000014, -36.7, -187.9000000000003, -234.10000000000028, 96.19999999999953, -233.50000000000037, 20.000000000000014, -190.60000000000008, -53.499999999999766, 32.90000000000002, -6.0999999999999375, 147.79999999999998, -89.1999999999999, 75.80000000000018, -330.70000000000016, -259.29999999999905, 20.000000000000014, -78.70000000000063, -44.79999999999988, -139.60000000000016, -147.70000000000024, 77.89999999999995, 20.000000000000014, -10.599999999999978, 9.500000000000108, -82.90000000000012, -187.9000000000005, -83.20000000000071, -122.20000000000056, -5.200000000000015, -32.49999999999975, -130.30000000000067, -160.6000000000006, 20.000000000000014, -147.70000000000036, -347.4999999999999, -290.8000000000002, -103.9000000000006, 118.39999999999958, -1.000000000000024, -47.79999999999979, -49.299999999999905, -213.10000000000034, -244.0, -263.50000000000034, 28.100000000000147, -245.79999999999995, -172.00000000000045, -240.0000000000002, -139.89999999999992, -196.0000000000003, -242.50000000000034, -228.60000000000036, 12.499999999999943, 113.5999999999999, -55.600000000000136, -61.90000000000068, -126.40000000000043, -25.29999999999975, -27.9999999999998, -376.299999999999, -240.4000000000004, 97.10000000000002, -93.40000000000003, -131.19999999999982, 17.900000000000006, -28.29999999999994, 7.399999999999965, -308.5, 20.000000000000014, 29.000000000000185, -148.00000000000063, 1.1000000000001364, -40.89999999999991, -210.4000000000002, -109.89999999999992, -179.50000000000009, -6.100000000000014, 20.000000000000014, -41.79999999999983, -416.3, -62.19999999999987, -47.19999999999979, -7.599999999999904, 20.000000000000014, -68.2000000000001, 4.99999999999997, -85.0000000000004, 32.300000000000246, 21.80000000000004, -477.4999999999999, -446.09999999999917, 20.000000000000014, 23.00000000000009, 86.0, -51.69999999999977, -10.899999999999986, 44.30000000000015, -30.39999999999975, -9.399999999999876, -1.0000000000000275, -210.40000000000018, -366.1000000000002, -222.7999999999999, -338.40000000000026, 45.80000000000023, 192.79999999999995, -142.49999999999997, -570.9999999999999, 16.09999999999995, -34.59999999999975, -76.60000000000088, 20.000000000000014, 15.499999999999982, -138.1000000000001, -222.70000000000047, 20.000000000000014, -72.40000000000086, -324.99999999999994, -573.5, 137.89999999999972, 13.699999999999964, -141.4000000000006, -535.1999999999998, -11.499999999999819, -103.5, -214.90000000000055, -1.2999999999999847, 123.19999999999976, 99.19999999999956, -95.50000000000082, -76.60000000000073, 36.20000000000026, 15.799999999999963, -242.50000000000034, 20.000000000000014, -46.599999999999795, 5.299999999999976, -273.69999999999936, -39.99999999999983, -329.8999999999991, 36.20000000000006, -94.00000000000026, -246.70000000000041, 2.899999999999972, 26.600000000000122, 20.000000000000014, -7.299999999999898, 20.000000000000014, -26.499999999999808, 5.299999999999965, 17.299999999999976, 13.699999999999964, -17.79999999999974, 20.000000000000014, 95.89999999999999, -248.8000000000004, 19.700000000000042, 35.90000000000015, -51.399999999999814, -211.0000000000005, -13.599999999999758, -223.60000000000048, -126.7000000000003, -74.20000000000019, -127.00000000000071, -74.50000000000064, -55.600000000000136, -7.000000000000009, 57.80000000000016, -120.70000000000076, -196.2999999999999, -49.29999999999986, -129.40000000000063, 17.89999999999981, -34.59999999999976, 71.29999999999961, 20.000000000000014, 60.200000000000216], "policy_predator_policy_reward": [56.0, 80.0, 63.0, 55.0, 52.0, 80.0, 100.0, 15.0, 25.0, 96.0, 50.0, 74.0, 142.0, 57.0, 86.0, 56.0, 0.0, 35.0, 47.0, 96.0, 41.0, 97.0, 112.0, 66.0, 95.0, 57.0, 107.0, 70.0, 115.0, 53.0, 7.0, 37.0, 52.0, 0.0, 41.0, 164.0, 133.0, 3.0, 0.0, 92.0, 17.0, 106.0, 29.0, 11.0, 80.0, 8.0, 31.0, 134.0, 25.0, 97.0, 12.0, 35.0, 86.0, 75.0, 19.0, 83.0, 22.0, 186.0, 5.0, 59.0, 16.0, 36.0, 33.0, 117.0, 68.0, 178.0, 38.0, 149.0, 82.0, 146.0, 95.0, 114.0, 124.0, 125.0, 25.0, 1.0, 26.0, 42.0, 22.0, 80.0, 251.0, 30.0, 10.0, 124.0, 59.0, 67.0, 56.0, 16.0, 42.0, 153.0, 9.0, 3.0, 52.0, 61.0, 88.0, 63.0, 1.0, 150.0, 32.0, 22.0, 116.0, 243.0, 29.0, 46.0, 8.0, 17.0, 7.0, 46.0, 34.0, 33.0, 264.0, 199.0, 171.0, 272.0, 26.0, 2.0, 28.0, 45.0, 24.0, 15.0, 14.0, 10.0, 82.0, 250.0, 20.0, 234.0, 0.0, 1.0, 449.0, 61.0, 2.0, 37.0, 46.0, 0.0, 54.0, 69.0, 104.0, 47.0, 87.0, 202.0, 317.0, 234.0, 3.0, 79.0, 234.0, 274.0, 113.0, 41.0, 9.0, 10.0, 52.0, 28.0, 27.0, 35.0, 68.0, 105.0, 10.0, 28.0, 154.0, 76.0, 176.0, 42.0, 40.0, 75.0, 123.0, 70.0, 14.0, 30.0, 6.0, 7.0, 35.0, 7.0, 15.0, 45.0, 13.0, 18.0, 128.0, 5.0, 30.0, 1.0, 83.0, 105.0, 78.0, 82.0, 107.0, 2.0, 79.0, 31.0, 31.0, 59.0, 16.0, 67.0, 107.0, 29.0, 81.0, 44.0, 17.0, 24.0, 1.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7046230351794844, "mean_inference_ms": 2.172931479887166, "mean_action_processing_ms": 0.29678499256965263, "mean_env_wait_ms": 0.2398548325688796, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.010105252265930176, "StateBufferConnector_ms": 0.004196643829345703, "ViewRequirementAgentConnector_ms": 0.1104501485824585}, "num_episodes": 18, "episode_return_max": 239.59999999999906, "episode_return_min": -430.2999999999992, "episode_return_mean": -28.83900000000015, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 96000, "num_agent_steps_trained": 96000, "num_env_steps_sampled": 24000, "num_env_steps_trained": 24000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 289.03206102462053, "num_env_steps_trained_throughput_per_sec": 289.03206102462053, "timesteps_total": 24000, "num_env_steps_sampled_lifetime": 24000, "num_agent_steps_sampled_lifetime": 96000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 96000, "timers": {"training_iteration_time_ms": 12213.126, "restore_workers_time_ms": 0.019, "training_step_time_ms": 12213.066, "sample_time_ms": 1603.112, "learn_time_ms": 10592.202, "learn_throughput": 377.636, "synch_weights_time_ms": 15.576}, "counters": {"num_env_steps_sampled": 24000, "num_env_steps_trained": 24000, "num_agent_steps_sampled": 96000, "num_agent_steps_trained": 96000}, "done": false, "training_iteration": 6, "trial_id": "3dae5_00000", "date": "2024-08-14_08-40-52", "timestamp": 1723639252, "time_this_iter_s": 13.884989261627197, "time_total_s": 73.45440220832825, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b116ac10>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 73.45440220832825, "iterations_since_restore": 6, "perf": {"cpu_util_percent": 45.93000000000001, "ram_util_percent": 83.86500000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.457981636126836, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.094719479702137, "policy_loss": -0.008256279951375392, "vf_loss": 3.101847918954476, "vf_explained_var": 0.026599301547600478, "kl": 0.01127839388905629, "entropy": 1.5410134716008705, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 12285.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7638938345921733, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.264076075225911, "policy_loss": -0.004744024352027625, "vf_loss": 5.266745076356111, "vf_explained_var": 0.02131722159486599, "kl": 0.010375104249634066, "entropy": 1.5896397390693584, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 12285.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 28000, "num_env_steps_trained": 28000, "num_agent_steps_sampled": 112000, "num_agent_steps_trained": 112000}, "env_runners": {"episode_reward_max": 239.59999999999906, "episode_reward_min": -430.2999999999992, "episode_reward_mean": -22.146000000000196, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -573.5, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 192.79999999999995, "predator_policy": 449.0}, "policy_reward_mean": {"prey_policy": -73.87800000000007, "predator_policy": 62.805}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-103.30000000000103, -31.499999999999773, -164.30000000000038, 137.89999999999952, 86.89999999999975, -105.80000000000047, -83.39999999999986, 9.3, -129.90000000000126, -25.69999999999971, -430.2999999999992, 78.49999999999925, 3.2000000000001663, -112.40000000000114, -261.5000000000004, -30.699999999999882, -184.00000000000063, -126.90000000000066, -222.1000000000007, 152.0999999999994, -49.50000000000082, -49.69999999999968, -123.30000000000106, -9.299999999999788, -98.60000000000004, 61.600000000000215, -106.10000000000002, 61.000000000000355, -33.89999999999998, -100.30000000000024, -138.39999999999998, 67.90000000000006, -99.09999999999982, -34.400000000000034, 37.400000000000276, -10.200000000000081, 14.300000000000125, 7.300000000000168, 16.900000000000176, 136.99999999999955, 10.400000000000254, 52.90000000000033, 13.59999999999997, -244.5000000000003, -307.1999999999998, 239.59999999999906, -203.50000000000074, 20.500000000000004, -10.599999999999623, 0.4000000000001268, -51.69999999999966, -108.40000000000083, 115.39999999999971, -45.69999999999958, -38.69999999999974, -164.39999999999966, 140.89999999999927, 83.69999999999911, 21.600000000000016, -53.69999999999974, 11.399999999999956, -38.399999999999714, -151.90000000000092, 57.200000000000244, -50.79999999999967, 90.59999999999988, 25.70000000000007, 20.80000000000007, 90.99999999999937, 33.2000000000002, -19.900000000000013, 86.60000000000007, -74.40000000000146, -77.20000000000127, -91.90000000000069, -91.50000000000155, 27.40000000000022, 20.100000000000023, -109.60000000000011, 13.500000000000039, 77.69999999999929, 81.19999999999925, -25.999999999999524, 52.30000000000032, 88.7999999999999, 38.90000000000028, 111.39999999999912, -87.80000000000082, 102.59999999999995, 198.0999999999993, 32.80000000000013, -126.50000000000051, 60.800000000000175, 34.0000000000002, -65.10000000000144, 3.4999999999999263, -114.60000000000063, 15.200000000000095, 87.09999999999933, -28.199999999999612], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-259.29999999999905, 20.000000000000014, -78.70000000000063, -44.79999999999988, -139.60000000000016, -147.70000000000024, 77.89999999999995, 20.000000000000014, -10.599999999999978, 9.500000000000108, -82.90000000000012, -187.9000000000005, -83.20000000000071, -122.20000000000056, -5.200000000000015, -32.49999999999975, -130.30000000000067, -160.6000000000006, 20.000000000000014, -147.70000000000036, -347.4999999999999, -290.8000000000002, -103.9000000000006, 118.39999999999958, -1.000000000000024, -47.79999999999979, -49.299999999999905, -213.10000000000034, -244.0, -263.50000000000034, 28.100000000000147, -245.79999999999995, -172.00000000000045, -240.0000000000002, -139.89999999999992, -196.0000000000003, -242.50000000000034, -228.60000000000036, 12.499999999999943, 113.5999999999999, -55.600000000000136, -61.90000000000068, -126.40000000000043, -25.29999999999975, -27.9999999999998, -376.299999999999, -240.4000000000004, 97.10000000000002, -93.40000000000003, -131.19999999999982, 17.900000000000006, -28.29999999999994, 7.399999999999965, -308.5, 20.000000000000014, 29.000000000000185, -148.00000000000063, 1.1000000000001364, -40.89999999999991, -210.4000000000002, -109.89999999999992, -179.50000000000009, -6.100000000000014, 20.000000000000014, -41.79999999999983, -416.3, -62.19999999999987, -47.19999999999979, -7.599999999999904, 20.000000000000014, -68.2000000000001, 4.99999999999997, -85.0000000000004, 32.300000000000246, 21.80000000000004, -477.4999999999999, -446.09999999999917, 20.000000000000014, 23.00000000000009, 86.0, -51.69999999999977, -10.899999999999986, 44.30000000000015, -30.39999999999975, -9.399999999999876, -1.0000000000000275, -210.40000000000018, -366.1000000000002, -222.7999999999999, -338.40000000000026, 45.80000000000023, 192.79999999999995, -142.49999999999997, -570.9999999999999, 16.09999999999995, -34.59999999999975, -76.60000000000088, 20.000000000000014, 15.499999999999982, -138.1000000000001, -222.70000000000047, 20.000000000000014, -72.40000000000086, -324.99999999999994, -573.5, 137.89999999999972, 13.699999999999964, -141.4000000000006, -535.1999999999998, -11.499999999999819, -103.5, -214.90000000000055, -1.2999999999999847, 123.19999999999976, 99.19999999999956, -95.50000000000082, -76.60000000000073, 36.20000000000026, 15.799999999999963, -242.50000000000034, 20.000000000000014, -46.599999999999795, 5.299999999999976, -273.69999999999936, -39.99999999999983, -329.8999999999991, 36.20000000000006, -94.00000000000026, -246.70000000000041, 2.899999999999972, 26.600000000000122, 20.000000000000014, -7.299999999999898, 20.000000000000014, -26.499999999999808, 5.299999999999965, 17.299999999999976, 13.699999999999964, -17.79999999999974, 20.000000000000014, 95.89999999999999, -248.8000000000004, 19.700000000000042, 35.90000000000015, -51.399999999999814, -211.0000000000005, -13.599999999999758, -223.60000000000048, -126.7000000000003, -74.20000000000019, -127.00000000000071, -74.50000000000064, -55.600000000000136, -7.000000000000009, 57.80000000000016, -120.70000000000076, -196.2999999999999, -49.29999999999986, -129.40000000000063, 17.89999999999981, -34.59999999999976, 71.29999999999961, 20.000000000000014, 60.200000000000216, -34.59999999999976, -51.40000000000005, 20.000000000000014, -3.6999999999999993, 62.3000000000001, 9.499999999999964, 17.899999999999988, 20.000000000000014, 107.29999999999963, -19.899999999999743, -59.80000000000004, -85.00000000000041, -53.199999999999925, 99.79999999999998, 74.00000000000009, 112.09999999999972, -34.90000000000036, 13.699999999999964, -51.39999999999994, -186.10000000000014, -25.89999999999987, 25.700000000000074, -21.9999999999998, 29.00000000000017, -18.099999999999746, -145.00000000000068, -87.10000000000048, 32.60000000000023, -342.5000000000002, -66.10000000000049, -26.799999999999756, 10.999999999999947, 5.600000000000014, 12.499999999999993, -10.899999999999826, -144.29999999999984], "policy_predator_policy_reward": [133.0, 3.0, 0.0, 92.0, 17.0, 106.0, 29.0, 11.0, 80.0, 8.0, 31.0, 134.0, 25.0, 97.0, 12.0, 35.0, 86.0, 75.0, 19.0, 83.0, 22.0, 186.0, 5.0, 59.0, 16.0, 36.0, 33.0, 117.0, 68.0, 178.0, 38.0, 149.0, 82.0, 146.0, 95.0, 114.0, 124.0, 125.0, 25.0, 1.0, 26.0, 42.0, 22.0, 80.0, 251.0, 30.0, 10.0, 124.0, 59.0, 67.0, 56.0, 16.0, 42.0, 153.0, 9.0, 3.0, 52.0, 61.0, 88.0, 63.0, 1.0, 150.0, 32.0, 22.0, 116.0, 243.0, 29.0, 46.0, 8.0, 17.0, 7.0, 46.0, 34.0, 33.0, 264.0, 199.0, 171.0, 272.0, 26.0, 2.0, 28.0, 45.0, 24.0, 15.0, 14.0, 10.0, 82.0, 250.0, 20.0, 234.0, 0.0, 1.0, 449.0, 61.0, 2.0, 37.0, 46.0, 0.0, 54.0, 69.0, 104.0, 47.0, 87.0, 202.0, 317.0, 234.0, 3.0, 79.0, 234.0, 274.0, 113.0, 41.0, 9.0, 10.0, 52.0, 28.0, 27.0, 35.0, 68.0, 105.0, 10.0, 28.0, 154.0, 76.0, 176.0, 42.0, 40.0, 75.0, 123.0, 70.0, 14.0, 30.0, 6.0, 7.0, 35.0, 7.0, 15.0, 45.0, 13.0, 18.0, 128.0, 5.0, 30.0, 1.0, 83.0, 105.0, 78.0, 82.0, 107.0, 2.0, 79.0, 31.0, 31.0, 59.0, 16.0, 67.0, 107.0, 29.0, 81.0, 44.0, 17.0, 24.0, 1.0, 0.0, 34.0, 26.0, 8.0, 28.0, 5.0, 12.0, 0.0, 1.0, 19.0, 5.0, 0.0, 57.0, 46.0, 10.0, 8.0, 4.0, 15.0, 39.0, 103.0, 8.0, 3.0, 58.0, 7.0, 20.0, 79.0, 19.0, 6.0, 52.0, 154.0, 140.0, 25.0, 6.0, 8.0, 61.0, 99.0, 28.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6946753205293306, "mean_inference_ms": 2.1720650555051746, "mean_action_processing_ms": 0.2922902648673286, "mean_env_wait_ms": 0.2384631137848219, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.009568333625793457, "StateBufferConnector_ms": 0.004355072975158691, "ViewRequirementAgentConnector_ms": 0.12427639961242676}, "num_episodes": 18, "episode_return_max": 239.59999999999906, "episode_return_min": -430.2999999999992, "episode_return_mean": -22.146000000000196, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 112000, "num_agent_steps_trained": 112000, "num_env_steps_sampled": 28000, "num_env_steps_trained": 28000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 291.8679658999199, "num_env_steps_trained_throughput_per_sec": 291.8679658999199, "timesteps_total": 28000, "num_env_steps_sampled_lifetime": 28000, "num_agent_steps_sampled_lifetime": 112000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 112000, "timers": {"training_iteration_time_ms": 12426.227, "restore_workers_time_ms": 0.018, "training_step_time_ms": 12426.17, "sample_time_ms": 1688.3, "learn_time_ms": 10720.218, "learn_throughput": 373.127, "synch_weights_time_ms": 15.254}, "counters": {"num_env_steps_sampled": 28000, "num_env_steps_trained": 28000, "num_agent_steps_sampled": 112000, "num_agent_steps_trained": 112000}, "done": false, "training_iteration": 7, "trial_id": "3dae5_00000", "date": "2024-08-14_08-41-06", "timestamp": 1723639266, "time_this_iter_s": 13.755272150039673, "time_total_s": 87.20967435836792, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b1111ee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 87.20967435836792, "iterations_since_restore": 7, "perf": {"cpu_util_percent": 43.08421052631578, "ram_util_percent": 83.35789473684208}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.16741186724138, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.643594849298871, "policy_loss": -0.008550936140110174, "vf_loss": 4.650745247533082, "vf_explained_var": 0.012903075495724956, "kl": 0.014005315907480073, "entropy": 1.5341879745009084, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 14175.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.922223594800505, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.968224576415208, "policy_loss": -0.0027284244759126553, "vf_loss": 6.969628491477361, "vf_explained_var": 0.02426380786315474, "kl": 0.00662258317491233, "entropy": 1.5893802632099736, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 14175.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 32000, "num_env_steps_trained": 32000, "num_agent_steps_sampled": 128000, "num_agent_steps_trained": 128000}, "env_runners": {"episode_reward_max": 239.59999999999906, "episode_reward_min": -307.1999999999998, "episode_reward_mean": -7.030000000000199, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -573.5, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 192.79999999999995, "predator_policy": 449.0}, "policy_reward_mean": {"prey_policy": -63.44000000000006, "predator_policy": 59.925}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-222.1000000000007, 152.0999999999994, -49.50000000000082, -49.69999999999968, -123.30000000000106, -9.299999999999788, -98.60000000000004, 61.600000000000215, -106.10000000000002, 61.000000000000355, -33.89999999999998, -100.30000000000024, -138.39999999999998, 67.90000000000006, -99.09999999999982, -34.400000000000034, 37.400000000000276, -10.200000000000081, 14.300000000000125, 7.300000000000168, 16.900000000000176, 136.99999999999955, 10.400000000000254, 52.90000000000033, 13.59999999999997, -244.5000000000003, -307.1999999999998, 239.59999999999906, -203.50000000000074, 20.500000000000004, -10.599999999999623, 0.4000000000001268, -51.69999999999966, -108.40000000000083, 115.39999999999971, -45.69999999999958, -38.69999999999974, -164.39999999999966, 140.89999999999927, 83.69999999999911, 21.600000000000016, -53.69999999999974, 11.399999999999956, -38.399999999999714, -151.90000000000092, 57.200000000000244, -50.79999999999967, 90.59999999999988, 25.70000000000007, 20.80000000000007, 90.99999999999937, 33.2000000000002, -19.900000000000013, 86.60000000000007, -74.40000000000146, -77.20000000000127, -91.90000000000069, -91.50000000000155, 27.40000000000022, 20.100000000000023, -109.60000000000011, 13.500000000000039, 77.69999999999929, 81.19999999999925, -25.999999999999524, 52.30000000000032, 88.7999999999999, 38.90000000000028, 111.39999999999912, -87.80000000000082, 102.59999999999995, 198.0999999999993, 32.80000000000013, -126.50000000000051, 60.800000000000175, 34.0000000000002, -65.10000000000144, 3.4999999999999263, -114.60000000000063, 15.200000000000095, 87.09999999999933, -28.199999999999612, -49.800000000000466, 33.20000000000006, 18.800000000000246, 142.89999999999927, 112.09999999999886, 63.000000000000234, -4.299999999999951, 77.19999999999939, -74.80000000000138, -131.50000000000077, -33.39999999999959, 25.300000000000257, 80.89999999999915, 68.7999999999998, -76.30000000000014, -80.30000000000004, -66.2999999999998, -67.80000000000054], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-242.50000000000034, -228.60000000000036, 12.499999999999943, 113.5999999999999, -55.600000000000136, -61.90000000000068, -126.40000000000043, -25.29999999999975, -27.9999999999998, -376.299999999999, -240.4000000000004, 97.10000000000002, -93.40000000000003, -131.19999999999982, 17.900000000000006, -28.29999999999994, 7.399999999999965, -308.5, 20.000000000000014, 29.000000000000185, -148.00000000000063, 1.1000000000001364, -40.89999999999991, -210.4000000000002, -109.89999999999992, -179.50000000000009, -6.100000000000014, 20.000000000000014, -41.79999999999983, -416.3, -62.19999999999987, -47.19999999999979, -7.599999999999904, 20.000000000000014, -68.2000000000001, 4.99999999999997, -85.0000000000004, 32.300000000000246, 21.80000000000004, -477.4999999999999, -446.09999999999917, 20.000000000000014, 23.00000000000009, 86.0, -51.69999999999977, -10.899999999999986, 44.30000000000015, -30.39999999999975, -9.399999999999876, -1.0000000000000275, -210.40000000000018, -366.1000000000002, -222.7999999999999, -338.40000000000026, 45.80000000000023, 192.79999999999995, -142.49999999999997, -570.9999999999999, 16.09999999999995, -34.59999999999975, -76.60000000000088, 20.000000000000014, 15.499999999999982, -138.1000000000001, -222.70000000000047, 20.000000000000014, -72.40000000000086, -324.99999999999994, -573.5, 137.89999999999972, 13.699999999999964, -141.4000000000006, -535.1999999999998, -11.499999999999819, -103.5, -214.90000000000055, -1.2999999999999847, 123.19999999999976, 99.19999999999956, -95.50000000000082, -76.60000000000073, 36.20000000000026, 15.799999999999963, -242.50000000000034, 20.000000000000014, -46.599999999999795, 5.299999999999976, -273.69999999999936, -39.99999999999983, -329.8999999999991, 36.20000000000006, -94.00000000000026, -246.70000000000041, 2.899999999999972, 26.600000000000122, 20.000000000000014, -7.299999999999898, 20.000000000000014, -26.499999999999808, 5.299999999999965, 17.299999999999976, 13.699999999999964, -17.79999999999974, 20.000000000000014, 95.89999999999999, -248.8000000000004, 19.700000000000042, 35.90000000000015, -51.399999999999814, -211.0000000000005, -13.599999999999758, -223.60000000000048, -126.7000000000003, -74.20000000000019, -127.00000000000071, -74.50000000000064, -55.600000000000136, -7.000000000000009, 57.80000000000016, -120.70000000000076, -196.2999999999999, -49.29999999999986, -129.40000000000063, 17.89999999999981, -34.59999999999976, 71.29999999999961, 20.000000000000014, 60.200000000000216, -34.59999999999976, -51.40000000000005, 20.000000000000014, -3.6999999999999993, 62.3000000000001, 9.499999999999964, 17.899999999999988, 20.000000000000014, 107.29999999999963, -19.899999999999743, -59.80000000000004, -85.00000000000041, -53.199999999999925, 99.79999999999998, 74.00000000000009, 112.09999999999972, -34.90000000000036, 13.699999999999964, -51.39999999999994, -186.10000000000014, -25.89999999999987, 25.700000000000074, -21.9999999999998, 29.00000000000017, -18.099999999999746, -145.00000000000068, -87.10000000000048, 32.60000000000023, -342.5000000000002, -66.10000000000049, -26.799999999999756, 10.999999999999947, 5.600000000000014, 12.499999999999993, -10.899999999999826, -144.29999999999984, -217.3000000000005, -14.500000000000071, -17.199999999999747, 25.399999999999984, -49.29999999999976, -34.899999999999956, 36.50000000000012, 70.40000000000012, 20.000000000000014, 73.0999999999995, 0.20000000000022738, -11.199999999999955, -87.10000000000072, 15.800000000000054, -10.900000000000047, 37.1000000000002, -106.00000000000071, -74.8000000000003, -227.40000000000043, -72.10000000000042, -91.00000000000038, -21.399999999999764, 49.099999999999966, -101.80000000000047, -11.499999999999819, 70.39999999999968, -351.7, 177.49999999999986, -248.00000000000003, 13.699999999999964, -127.89999999999992, -111.40000000000055, -215.20000000000036, 35.90000000000025, -292.9000000000002, 64.10000000000005], "policy_predator_policy_reward": [124.0, 125.0, 25.0, 1.0, 26.0, 42.0, 22.0, 80.0, 251.0, 30.0, 10.0, 124.0, 59.0, 67.0, 56.0, 16.0, 42.0, 153.0, 9.0, 3.0, 52.0, 61.0, 88.0, 63.0, 1.0, 150.0, 32.0, 22.0, 116.0, 243.0, 29.0, 46.0, 8.0, 17.0, 7.0, 46.0, 34.0, 33.0, 264.0, 199.0, 171.0, 272.0, 26.0, 2.0, 28.0, 45.0, 24.0, 15.0, 14.0, 10.0, 82.0, 250.0, 20.0, 234.0, 0.0, 1.0, 449.0, 61.0, 2.0, 37.0, 46.0, 0.0, 54.0, 69.0, 104.0, 47.0, 87.0, 202.0, 317.0, 234.0, 3.0, 79.0, 234.0, 274.0, 113.0, 41.0, 9.0, 10.0, 52.0, 28.0, 27.0, 35.0, 68.0, 105.0, 10.0, 28.0, 154.0, 76.0, 176.0, 42.0, 40.0, 75.0, 123.0, 70.0, 14.0, 30.0, 6.0, 7.0, 35.0, 7.0, 15.0, 45.0, 13.0, 18.0, 128.0, 5.0, 30.0, 1.0, 83.0, 105.0, 78.0, 82.0, 107.0, 2.0, 79.0, 31.0, 31.0, 59.0, 16.0, 67.0, 107.0, 29.0, 81.0, 44.0, 17.0, 24.0, 1.0, 0.0, 34.0, 26.0, 8.0, 28.0, 5.0, 12.0, 0.0, 1.0, 19.0, 5.0, 0.0, 57.0, 46.0, 10.0, 8.0, 4.0, 15.0, 39.0, 103.0, 8.0, 3.0, 58.0, 7.0, 20.0, 79.0, 19.0, 6.0, 52.0, 154.0, 140.0, 25.0, 6.0, 8.0, 61.0, 99.0, 28.0, 77.0, 105.0, 6.0, 19.0, 99.0, 4.0, 26.0, 10.0, 12.0, 7.0, 4.0, 70.0, 49.0, 18.0, 17.0, 34.0, 46.0, 60.0, 89.0, 79.0, 45.0, 34.0, 39.0, 39.0, 7.0, 15.0, 91.0, 152.0, 120.0, 38.0, 119.0, 40.0, 112.0, 1.0, 12.0, 149.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6899495723211992, "mean_inference_ms": 2.177632973927598, "mean_action_processing_ms": 0.2900882322858266, "mean_env_wait_ms": 0.23782685455741062, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.008680224418640137, "StateBufferConnector_ms": 0.004276752471923828, "ViewRequirementAgentConnector_ms": 0.12431776523590088}, "num_episodes": 18, "episode_return_max": 239.59999999999906, "episode_return_min": -307.1999999999998, "episode_return_mean": -7.030000000000199, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 128000, "num_agent_steps_trained": 128000, "num_env_steps_sampled": 32000, "num_env_steps_trained": 32000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 22.27897460202239, "num_env_steps_trained_throughput_per_sec": 22.27897460202239, "timesteps_total": 32000, "num_env_steps_sampled_lifetime": 32000, "num_agent_steps_sampled_lifetime": 128000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 128000, "timers": {"training_iteration_time_ms": 33315.634, "restore_workers_time_ms": 0.018, "training_step_time_ms": 33315.579, "sample_time_ms": 1634.121, "learn_time_ms": 31663.873, "learn_throughput": 126.327, "synch_weights_time_ms": 15.151}, "counters": {"num_env_steps_sampled": 32000, "num_env_steps_trained": 32000, "num_agent_steps_sampled": 128000, "num_agent_steps_trained": 128000}, "done": false, "training_iteration": 8, "trial_id": "3dae5_00000", "date": "2024-08-14_08-44-05", "timestamp": 1723639445, "time_this_iter_s": 179.5945041179657, "time_total_s": 266.8041784763336, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0f81e50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 266.8041784763336, "iterations_since_restore": 8, "perf": {"cpu_util_percent": 36.15882352941177, "ram_util_percent": 83.35882352941178}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4650935270168164, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.030965073903402, "policy_loss": -0.006193382922983753, "vf_loss": 4.0357700550997695, "vf_explained_var": 0.004549633352844804, "kl": 0.01388402832795558, "entropy": 1.4913411527714402, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 16065.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9991480400007238, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.695040534034608, "policy_loss": -0.004588845707032652, "vf_loss": 6.69820031489014, "vf_explained_var": 0.05222345398216651, "kl": 0.00714539539688343, "entropy": 1.5826358605944921, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 16065.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 36000, "num_env_steps_trained": 36000, "num_agent_steps_sampled": 144000, "num_agent_steps_trained": 144000}, "env_runners": {"episode_reward_max": 329.10000000000093, "episode_reward_min": -307.1999999999998, "episode_reward_mean": 0.0489999999997729, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -573.5, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 194.59999999999997, "predator_policy": 449.0}, "policy_reward_mean": {"prey_policy": -55.79550000000008, "predator_policy": 55.82}, "custom_metrics": {}, "hist_stats": {"episode_reward": [10.400000000000254, 52.90000000000033, 13.59999999999997, -244.5000000000003, -307.1999999999998, 239.59999999999906, -203.50000000000074, 20.500000000000004, -10.599999999999623, 0.4000000000001268, -51.69999999999966, -108.40000000000083, 115.39999999999971, -45.69999999999958, -38.69999999999974, -164.39999999999966, 140.89999999999927, 83.69999999999911, 21.600000000000016, -53.69999999999974, 11.399999999999956, -38.399999999999714, -151.90000000000092, 57.200000000000244, -50.79999999999967, 90.59999999999988, 25.70000000000007, 20.80000000000007, 90.99999999999937, 33.2000000000002, -19.900000000000013, 86.60000000000007, -74.40000000000146, -77.20000000000127, -91.90000000000069, -91.50000000000155, 27.40000000000022, 20.100000000000023, -109.60000000000011, 13.500000000000039, 77.69999999999929, 81.19999999999925, -25.999999999999524, 52.30000000000032, 88.7999999999999, 38.90000000000028, 111.39999999999912, -87.80000000000082, 102.59999999999995, 198.0999999999993, 32.80000000000013, -126.50000000000051, 60.800000000000175, 34.0000000000002, -65.10000000000144, 3.4999999999999263, -114.60000000000063, 15.200000000000095, 87.09999999999933, -28.199999999999612, -49.800000000000466, 33.20000000000006, 18.800000000000246, 142.89999999999927, 112.09999999999886, 63.000000000000234, -4.299999999999951, 77.19999999999939, -74.80000000000138, -131.50000000000077, -33.39999999999959, 25.300000000000257, 80.89999999999915, 68.7999999999998, -76.30000000000014, -80.30000000000004, -66.2999999999998, -67.80000000000054, 28.999999999999957, 97.29999999999993, 49.80000000000041, -51.09999999999967, 179.39999999999992, 54.30000000000033, -146.70000000000078, 174.39999999999975, 17.200000000000067, -99.80000000000052, -87.6000000000003, 329.10000000000093, 33.70000000000009, 148.5999999999993, -0.6999999999998696, -73.00000000000011, 168.7999999999992, -197.8000000000004, -142.80000000000095, -153.10000000000144, -94.80000000000058, -45.69999999999988], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-51.69999999999977, -10.899999999999986, 44.30000000000015, -30.39999999999975, -9.399999999999876, -1.0000000000000275, -210.40000000000018, -366.1000000000002, -222.7999999999999, -338.40000000000026, 45.80000000000023, 192.79999999999995, -142.49999999999997, -570.9999999999999, 16.09999999999995, -34.59999999999975, -76.60000000000088, 20.000000000000014, 15.499999999999982, -138.1000000000001, -222.70000000000047, 20.000000000000014, -72.40000000000086, -324.99999999999994, -573.5, 137.89999999999972, 13.699999999999964, -141.4000000000006, -535.1999999999998, -11.499999999999819, -103.5, -214.90000000000055, -1.2999999999999847, 123.19999999999976, 99.19999999999956, -95.50000000000082, -76.60000000000073, 36.20000000000026, 15.799999999999963, -242.50000000000034, 20.000000000000014, -46.599999999999795, 5.299999999999976, -273.69999999999936, -39.99999999999983, -329.8999999999991, 36.20000000000006, -94.00000000000026, -246.70000000000041, 2.899999999999972, 26.600000000000122, 20.000000000000014, -7.299999999999898, 20.000000000000014, -26.499999999999808, 5.299999999999965, 17.299999999999976, 13.699999999999964, -17.79999999999974, 20.000000000000014, 95.89999999999999, -248.8000000000004, 19.700000000000042, 35.90000000000015, -51.399999999999814, -211.0000000000005, -13.599999999999758, -223.60000000000048, -126.7000000000003, -74.20000000000019, -127.00000000000071, -74.50000000000064, -55.600000000000136, -7.000000000000009, 57.80000000000016, -120.70000000000076, -196.2999999999999, -49.29999999999986, -129.40000000000063, 17.89999999999981, -34.59999999999976, 71.29999999999961, 20.000000000000014, 60.200000000000216, -34.59999999999976, -51.40000000000005, 20.000000000000014, -3.6999999999999993, 62.3000000000001, 9.499999999999964, 17.899999999999988, 20.000000000000014, 107.29999999999963, -19.899999999999743, -59.80000000000004, -85.00000000000041, -53.199999999999925, 99.79999999999998, 74.00000000000009, 112.09999999999972, -34.90000000000036, 13.699999999999964, -51.39999999999994, -186.10000000000014, -25.89999999999987, 25.700000000000074, -21.9999999999998, 29.00000000000017, -18.099999999999746, -145.00000000000068, -87.10000000000048, 32.60000000000023, -342.5000000000002, -66.10000000000049, -26.799999999999756, 10.999999999999947, 5.600000000000014, 12.499999999999993, -10.899999999999826, -144.29999999999984, -217.3000000000005, -14.500000000000071, -17.199999999999747, 25.399999999999984, -49.29999999999976, -34.899999999999956, 36.50000000000012, 70.40000000000012, 20.000000000000014, 73.0999999999995, 0.20000000000022738, -11.199999999999955, -87.10000000000072, 15.800000000000054, -10.900000000000047, 37.1000000000002, -106.00000000000071, -74.8000000000003, -227.40000000000043, -72.10000000000042, -91.00000000000038, -21.399999999999764, 49.099999999999966, -101.80000000000047, -11.499999999999819, 70.39999999999968, -351.7, 177.49999999999986, -248.00000000000003, 13.699999999999964, -127.89999999999992, -111.40000000000055, -215.20000000000036, 35.90000000000025, -292.9000000000002, 64.10000000000005, 20.000000000000014, -15.99999999999991, 20.000000000000014, 56.300000000000054, 51.50000000000019, -78.7000000000008, -176.8000000000003, 7.69999999999999, 55.70000000000003, 64.69999999999996, -26.499999999999794, 30.799999999999955, -68.20000000000049, -292.5000000000001, 101.89999999999988, 42.50000000000009, 3.1999999999999122, -82.00000000000031, -181.80000000000015, -115.00000000000074, -46.59999999999984, -207.99999999999994, 194.59999999999997, 108.49999999999973, 66.80000000000008, -87.10000000000049, 40.10000000000003, 30.500000000000092, -32.49999999999979, -5.199999999999944, -178.9000000000002, -0.10000000000000636, 95.29999999999961, 60.500000000000064, -370.2999999999997, -216.50000000000037, -95.19999999999987, -223.60000000000042, -108.10000000000076, -127.00000000000068, 24.500000000000092, -322.2999999999994, 48.80000000000023, -302.4999999999998], "policy_predator_policy_reward": [28.0, 45.0, 24.0, 15.0, 14.0, 10.0, 82.0, 250.0, 20.0, 234.0, 0.0, 1.0, 449.0, 61.0, 2.0, 37.0, 46.0, 0.0, 54.0, 69.0, 104.0, 47.0, 87.0, 202.0, 317.0, 234.0, 3.0, 79.0, 234.0, 274.0, 113.0, 41.0, 9.0, 10.0, 52.0, 28.0, 27.0, 35.0, 68.0, 105.0, 10.0, 28.0, 154.0, 76.0, 176.0, 42.0, 40.0, 75.0, 123.0, 70.0, 14.0, 30.0, 6.0, 7.0, 35.0, 7.0, 15.0, 45.0, 13.0, 18.0, 128.0, 5.0, 30.0, 1.0, 83.0, 105.0, 78.0, 82.0, 107.0, 2.0, 79.0, 31.0, 31.0, 59.0, 16.0, 67.0, 107.0, 29.0, 81.0, 44.0, 17.0, 24.0, 1.0, 0.0, 34.0, 26.0, 8.0, 28.0, 5.0, 12.0, 0.0, 1.0, 19.0, 5.0, 0.0, 57.0, 46.0, 10.0, 8.0, 4.0, 15.0, 39.0, 103.0, 8.0, 3.0, 58.0, 7.0, 20.0, 79.0, 19.0, 6.0, 52.0, 154.0, 140.0, 25.0, 6.0, 8.0, 61.0, 99.0, 28.0, 77.0, 105.0, 6.0, 19.0, 99.0, 4.0, 26.0, 10.0, 12.0, 7.0, 4.0, 70.0, 49.0, 18.0, 17.0, 34.0, 46.0, 60.0, 89.0, 79.0, 45.0, 34.0, 39.0, 39.0, 7.0, 15.0, 91.0, 152.0, 120.0, 38.0, 119.0, 40.0, 112.0, 1.0, 12.0, 149.0, 3.0, 22.0, 19.0, 2.0, 47.0, 30.0, 23.0, 95.0, 27.0, 32.0, 8.0, 42.0, 154.0, 60.0, 19.0, 11.0, 86.0, 10.0, 89.0, 108.0, 48.0, 119.0, 14.0, 12.0, 3.0, 51.0, 33.0, 45.0, 16.0, 21.0, 10.0, 96.0, 8.0, 5.0, 207.0, 182.0, 60.0, 116.0, 82.0, 0.0, 155.0, 48.0, 106.0, 102.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6878729575460824, "mean_inference_ms": 2.1830527822017554, "mean_action_processing_ms": 0.2885064638502176, "mean_env_wait_ms": 0.23808622612746663, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005263566970825195, "StateBufferConnector_ms": 0.018662333488464355, "ViewRequirementAgentConnector_ms": 0.1212012767791748}, "num_episodes": 22, "episode_return_max": 329.10000000000093, "episode_return_min": -307.1999999999998, "episode_return_mean": 0.0489999999997729, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 144000, "num_agent_steps_trained": 144000, "num_env_steps_sampled": 36000, "num_env_steps_trained": 36000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 364.1850327891467, "num_env_steps_trained_throughput_per_sec": 364.1850327891467, "timesteps_total": 36000, "num_env_steps_sampled_lifetime": 36000, "num_agent_steps_sampled_lifetime": 144000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 144000, "timers": {"training_iteration_time_ms": 30834.279, "restore_workers_time_ms": 0.017, "training_step_time_ms": 30834.226, "sample_time_ms": 1598.811, "learn_time_ms": 29218.377, "learn_throughput": 136.9, "synch_weights_time_ms": 14.787}, "counters": {"num_env_steps_sampled": 36000, "num_env_steps_trained": 36000, "num_agent_steps_sampled": 144000, "num_agent_steps_trained": 144000}, "done": false, "training_iteration": 9, "trial_id": "3dae5_00000", "date": "2024-08-14_08-44-16", "timestamp": 1723639456, "time_this_iter_s": 10.987730026245117, "time_total_s": 277.79190850257874, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0f81ee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 277.79190850257874, "iterations_since_restore": 9, "perf": {"cpu_util_percent": 28.43333333333333, "ram_util_percent": 82.07333333333332}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7056028665688934, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.4575636888937975, "policy_loss": -0.0050352709264391, "vf_loss": 5.461733828902875, "vf_explained_var": -0.003507605336961292, "kl": 0.008651377748158646, "entropy": 1.5085872493723713, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 17955.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.1264019333496296, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.211669042123058, "policy_loss": -0.006257839003705946, "vf_loss": 8.215764271266877, "vf_explained_var": 0.08143451327369326, "kl": 0.010812973284268461, "entropy": 1.5761806592108711, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 17955.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 40000, "num_env_steps_trained": 40000, "num_agent_steps_sampled": 160000, "num_agent_steps_trained": 160000}, "env_runners": {"episode_reward_max": 329.10000000000093, "episode_reward_min": -197.8000000000004, "episode_reward_mean": 21.132999999999747, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -370.2999999999997, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 194.59999999999997, "predator_policy": 207.0}, "policy_reward_mean": {"prey_policy": -35.36850000000007, "predator_policy": 45.935}, "custom_metrics": {}, "hist_stats": {"episode_reward": [57.200000000000244, -50.79999999999967, 90.59999999999988, 25.70000000000007, 20.80000000000007, 90.99999999999937, 33.2000000000002, -19.900000000000013, 86.60000000000007, -74.40000000000146, -77.20000000000127, -91.90000000000069, -91.50000000000155, 27.40000000000022, 20.100000000000023, -109.60000000000011, 13.500000000000039, 77.69999999999929, 81.19999999999925, -25.999999999999524, 52.30000000000032, 88.7999999999999, 38.90000000000028, 111.39999999999912, -87.80000000000082, 102.59999999999995, 198.0999999999993, 32.80000000000013, -126.50000000000051, 60.800000000000175, 34.0000000000002, -65.10000000000144, 3.4999999999999263, -114.60000000000063, 15.200000000000095, 87.09999999999933, -28.199999999999612, -49.800000000000466, 33.20000000000006, 18.800000000000246, 142.89999999999927, 112.09999999999886, 63.000000000000234, -4.299999999999951, 77.19999999999939, -74.80000000000138, -131.50000000000077, -33.39999999999959, 25.300000000000257, 80.89999999999915, 68.7999999999998, -76.30000000000014, -80.30000000000004, -66.2999999999998, -67.80000000000054, 28.999999999999957, 97.29999999999993, 49.80000000000041, -51.09999999999967, 179.39999999999992, 54.30000000000033, -146.70000000000078, 174.39999999999975, 17.200000000000067, -99.80000000000052, -87.6000000000003, 329.10000000000093, 33.70000000000009, 148.5999999999993, -0.6999999999998696, -73.00000000000011, 168.7999999999992, -197.8000000000004, -142.80000000000095, -153.10000000000144, -94.80000000000058, -45.69999999999988, 48.400000000000176, 74.69999999999952, 179.39999999999995, -38.19999999999993, 0.8000000000000043, 108.60000000000001, 139.89999999999887, 102.39999999999952, 87.79999999999978, 183.4999999999993, 84.29999999999998, 20.000000000000004, 77.09999999999945, 3.4999999999999503, -87.69999999999999, 204.29999999999976, -181.8000000000009, 212.79999999999956, 199.99999999999991, 6.299999999999947, 39.400000000000254, 35.600000000000165, -101.00000000000048], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [36.20000000000006, -94.00000000000026, -246.70000000000041, 2.899999999999972, 26.600000000000122, 20.000000000000014, -7.299999999999898, 20.000000000000014, -26.499999999999808, 5.299999999999965, 17.299999999999976, 13.699999999999964, -17.79999999999974, 20.000000000000014, 95.89999999999999, -248.8000000000004, 19.700000000000042, 35.90000000000015, -51.399999999999814, -211.0000000000005, -13.599999999999758, -223.60000000000048, -126.7000000000003, -74.20000000000019, -127.00000000000071, -74.50000000000064, -55.600000000000136, -7.000000000000009, 57.80000000000016, -120.70000000000076, -196.2999999999999, -49.29999999999986, -129.40000000000063, 17.89999999999981, -34.59999999999976, 71.29999999999961, 20.000000000000014, 60.200000000000216, -34.59999999999976, -51.40000000000005, 20.000000000000014, -3.6999999999999993, 62.3000000000001, 9.499999999999964, 17.899999999999988, 20.000000000000014, 107.29999999999963, -19.899999999999743, -59.80000000000004, -85.00000000000041, -53.199999999999925, 99.79999999999998, 74.00000000000009, 112.09999999999972, -34.90000000000036, 13.699999999999964, -51.39999999999994, -186.10000000000014, -25.89999999999987, 25.700000000000074, -21.9999999999998, 29.00000000000017, -18.099999999999746, -145.00000000000068, -87.10000000000048, 32.60000000000023, -342.5000000000002, -66.10000000000049, -26.799999999999756, 10.999999999999947, 5.600000000000014, 12.499999999999993, -10.899999999999826, -144.29999999999984, -217.3000000000005, -14.500000000000071, -17.199999999999747, 25.399999999999984, -49.29999999999976, -34.899999999999956, 36.50000000000012, 70.40000000000012, 20.000000000000014, 73.0999999999995, 0.20000000000022738, -11.199999999999955, -87.10000000000072, 15.800000000000054, -10.900000000000047, 37.1000000000002, -106.00000000000071, -74.8000000000003, -227.40000000000043, -72.10000000000042, -91.00000000000038, -21.399999999999764, 49.099999999999966, -101.80000000000047, -11.499999999999819, 70.39999999999968, -351.7, 177.49999999999986, -248.00000000000003, 13.699999999999964, -127.89999999999992, -111.40000000000055, -215.20000000000036, 35.90000000000025, -292.9000000000002, 64.10000000000005, 20.000000000000014, -15.99999999999991, 20.000000000000014, 56.300000000000054, 51.50000000000019, -78.7000000000008, -176.8000000000003, 7.69999999999999, 55.70000000000003, 64.69999999999996, -26.499999999999794, 30.799999999999955, -68.20000000000049, -292.5000000000001, 101.89999999999988, 42.50000000000009, 3.1999999999999122, -82.00000000000031, -181.80000000000015, -115.00000000000074, -46.59999999999984, -207.99999999999994, 194.59999999999997, 108.49999999999973, 66.80000000000008, -87.10000000000049, 40.10000000000003, 30.500000000000092, -32.49999999999979, -5.199999999999944, -178.9000000000002, -0.10000000000000636, 95.29999999999961, 60.500000000000064, -370.2999999999997, -216.50000000000037, -95.19999999999987, -223.60000000000042, -108.10000000000076, -127.00000000000068, 24.500000000000092, -322.2999999999994, 48.80000000000023, -302.4999999999998, -166.90000000000057, 122.29999999999993, 29.000000000000043, -28.29999999999975, -3.999999999999993, 106.39999999999998, -152.20000000000016, -54.999999999999964, -86.80000000000004, -0.4000000000000128, -103.90000000000003, 117.49999999999999, 48.200000000000195, 73.69999999999966, -91.30000000000024, 124.69999999999996, -53.49999999999978, 83.2999999999999, 183.49999999999991, -21.999999999999744, 2.5999999999999965, 49.70000000000014, -4.299999999999926, 5.299999999999965, 115.39999999999972, -165.30000000000024, -30.3999999999999, -105.10000000000011, 45.800000000000196, -284.5000000000002, 91.70000000000002, 32.6, -108.69999999999985, -231.10000000000025, 91.1, 67.69999999999985, 173.89999999999998, -49.90000000000019, 38.600000000000016, -175.3, -32.499999999999865, 20.9000000000001, -19.899999999999743, 24.500000000000007, -265.5999999999995, -30.40000000000012], "policy_predator_policy_reward": [40.0, 75.0, 123.0, 70.0, 14.0, 30.0, 6.0, 7.0, 35.0, 7.0, 15.0, 45.0, 13.0, 18.0, 128.0, 5.0, 30.0, 1.0, 83.0, 105.0, 78.0, 82.0, 107.0, 2.0, 79.0, 31.0, 31.0, 59.0, 16.0, 67.0, 107.0, 29.0, 81.0, 44.0, 17.0, 24.0, 1.0, 0.0, 34.0, 26.0, 8.0, 28.0, 5.0, 12.0, 0.0, 1.0, 19.0, 5.0, 0.0, 57.0, 46.0, 10.0, 8.0, 4.0, 15.0, 39.0, 103.0, 8.0, 3.0, 58.0, 7.0, 20.0, 79.0, 19.0, 6.0, 52.0, 154.0, 140.0, 25.0, 6.0, 8.0, 61.0, 99.0, 28.0, 77.0, 105.0, 6.0, 19.0, 99.0, 4.0, 26.0, 10.0, 12.0, 7.0, 4.0, 70.0, 49.0, 18.0, 17.0, 34.0, 46.0, 60.0, 89.0, 79.0, 45.0, 34.0, 39.0, 39.0, 7.0, 15.0, 91.0, 152.0, 120.0, 38.0, 119.0, 40.0, 112.0, 1.0, 12.0, 149.0, 3.0, 22.0, 19.0, 2.0, 47.0, 30.0, 23.0, 95.0, 27.0, 32.0, 8.0, 42.0, 154.0, 60.0, 19.0, 11.0, 86.0, 10.0, 89.0, 108.0, 48.0, 119.0, 14.0, 12.0, 3.0, 51.0, 33.0, 45.0, 16.0, 21.0, 10.0, 96.0, 8.0, 5.0, 207.0, 182.0, 60.0, 116.0, 82.0, 0.0, 155.0, 48.0, 106.0, 102.0, 1.0, 92.0, 42.0, 32.0, 14.0, 63.0, 100.0, 69.0, 62.0, 26.0, 47.0, 48.0, 8.0, 10.0, 62.0, 7.0, 23.0, 35.0, 17.0, 5.0, 11.0, 21.0, 12.0, 7.0, 12.0, 115.0, 39.0, 100.0, 40.0, 111.0, 27.0, 53.0, 108.0, 50.0, 36.0, 18.0, 68.0, 8.0, 26.0, 117.0, 43.0, 8.0, 13.0, 18.0, 76.0, 119.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6869591904024468, "mean_inference_ms": 2.1861994852734, "mean_action_processing_ms": 0.28621302268912363, "mean_env_wait_ms": 0.2365047267080114, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003945350646972656, "StateBufferConnector_ms": 0.01852405071258545, "ViewRequirementAgentConnector_ms": 0.1137230396270752}, "num_episodes": 23, "episode_return_max": 329.10000000000093, "episode_return_min": -197.8000000000004, "episode_return_mean": 21.132999999999747, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 160000, "num_agent_steps_trained": 160000, "num_env_steps_sampled": 40000, "num_env_steps_trained": 40000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 374.1588698205941, "num_env_steps_trained_throughput_per_sec": 374.1588698205941, "timesteps_total": 40000, "num_env_steps_sampled_lifetime": 40000, "num_agent_steps_sampled_lifetime": 160000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 160000, "timers": {"training_iteration_time_ms": 28819.916, "restore_workers_time_ms": 0.017, "training_step_time_ms": 28819.866, "sample_time_ms": 1560.998, "learn_time_ms": 27242.18, "learn_throughput": 146.831, "synch_weights_time_ms": 14.581}, "counters": {"num_env_steps_sampled": 40000, "num_env_steps_trained": 40000, "num_agent_steps_sampled": 160000, "num_agent_steps_trained": 160000}, "done": false, "training_iteration": 10, "trial_id": "3dae5_00000", "date": "2024-08-14_08-44-27", "timestamp": 1723639467, "time_this_iter_s": 10.696053981781006, "time_total_s": 288.48796248435974, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b362cee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 288.48796248435974, "iterations_since_restore": 10, "perf": {"cpu_util_percent": 26.539999999999996, "ram_util_percent": 80.95333333333335}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4832466398124342, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.2070778033090015, "policy_loss": -0.006238351601900326, "vf_loss": 4.2124369671735815, "vf_explained_var": 0.039929033902587084, "kl": 0.008791847752295707, "entropy": 1.5117057865889614, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 19845.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.0925850451307952, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.120755272315293, "policy_loss": -0.0023829709505662324, "vf_loss": 8.122070835002516, "vf_explained_var": 0.07899700103613434, "kl": 0.005337109667164347, "entropy": 1.5773157221930367, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 19845.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 44000, "num_env_steps_trained": 44000, "num_agent_steps_sampled": 176000, "num_agent_steps_trained": 176000}, "env_runners": {"episode_reward_max": 340.0, "episode_reward_min": -197.8000000000004, "episode_reward_mean": 44.18999999999979, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -370.2999999999997, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 194.59999999999997, "predator_policy": 207.0}, "policy_reward_mean": {"prey_policy": -23.305000000000053, "predator_policy": 45.4}, "custom_metrics": {}, "hist_stats": {"episode_reward": [81.19999999999925, -25.999999999999524, 52.30000000000032, 88.7999999999999, 38.90000000000028, 111.39999999999912, -87.80000000000082, 102.59999999999995, 198.0999999999993, 32.80000000000013, -126.50000000000051, 60.800000000000175, 34.0000000000002, -65.10000000000144, 3.4999999999999263, -114.60000000000063, 15.200000000000095, 87.09999999999933, -28.199999999999612, -49.800000000000466, 33.20000000000006, 18.800000000000246, 142.89999999999927, 112.09999999999886, 63.000000000000234, -4.299999999999951, 77.19999999999939, -74.80000000000138, -131.50000000000077, -33.39999999999959, 25.300000000000257, 80.89999999999915, 68.7999999999998, -76.30000000000014, -80.30000000000004, -66.2999999999998, -67.80000000000054, 28.999999999999957, 97.29999999999993, 49.80000000000041, -51.09999999999967, 179.39999999999992, 54.30000000000033, -146.70000000000078, 174.39999999999975, 17.200000000000067, -99.80000000000052, -87.6000000000003, 329.10000000000093, 33.70000000000009, 148.5999999999993, -0.6999999999998696, -73.00000000000011, 168.7999999999992, -197.8000000000004, -142.80000000000095, -153.10000000000144, -94.80000000000058, -45.69999999999988, 48.400000000000176, 74.69999999999952, 179.39999999999995, -38.19999999999993, 0.8000000000000043, 108.60000000000001, 139.89999999999887, 102.39999999999952, 87.79999999999978, 183.4999999999993, 84.29999999999998, 20.000000000000004, 77.09999999999945, 3.4999999999999503, -87.69999999999999, 204.29999999999976, -181.8000000000009, 212.79999999999956, 199.99999999999991, 6.299999999999947, 39.400000000000254, 35.600000000000165, -101.00000000000048, -3.699999999999873, -71.40000000000063, 198.09999999999988, 124.69999999999975, 172.59999999999948, 123.20000000000007, 285.39999999999986, 340.0, 320.69999999999993, 177.89999999999958, -29.099999999999987, 289.19999999999993, 33.19999999999998, 193.39999999999992, 19.400000000000148, 41.10000000000006, 92.7999999999999, 26.700000000000262], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 60.200000000000216, -34.59999999999976, -51.40000000000005, 20.000000000000014, -3.6999999999999993, 62.3000000000001, 9.499999999999964, 17.899999999999988, 20.000000000000014, 107.29999999999963, -19.899999999999743, -59.80000000000004, -85.00000000000041, -53.199999999999925, 99.79999999999998, 74.00000000000009, 112.09999999999972, -34.90000000000036, 13.699999999999964, -51.39999999999994, -186.10000000000014, -25.89999999999987, 25.700000000000074, -21.9999999999998, 29.00000000000017, -18.099999999999746, -145.00000000000068, -87.10000000000048, 32.60000000000023, -342.5000000000002, -66.10000000000049, -26.799999999999756, 10.999999999999947, 5.600000000000014, 12.499999999999993, -10.899999999999826, -144.29999999999984, -217.3000000000005, -14.500000000000071, -17.199999999999747, 25.399999999999984, -49.29999999999976, -34.899999999999956, 36.50000000000012, 70.40000000000012, 20.000000000000014, 73.0999999999995, 0.20000000000022738, -11.199999999999955, -87.10000000000072, 15.800000000000054, -10.900000000000047, 37.1000000000002, -106.00000000000071, -74.8000000000003, -227.40000000000043, -72.10000000000042, -91.00000000000038, -21.399999999999764, 49.099999999999966, -101.80000000000047, -11.499999999999819, 70.39999999999968, -351.7, 177.49999999999986, -248.00000000000003, 13.699999999999964, -127.89999999999992, -111.40000000000055, -215.20000000000036, 35.90000000000025, -292.9000000000002, 64.10000000000005, 20.000000000000014, -15.99999999999991, 20.000000000000014, 56.300000000000054, 51.50000000000019, -78.7000000000008, -176.8000000000003, 7.69999999999999, 55.70000000000003, 64.69999999999996, -26.499999999999794, 30.799999999999955, -68.20000000000049, -292.5000000000001, 101.89999999999988, 42.50000000000009, 3.1999999999999122, -82.00000000000031, -181.80000000000015, -115.00000000000074, -46.59999999999984, -207.99999999999994, 194.59999999999997, 108.49999999999973, 66.80000000000008, -87.10000000000049, 40.10000000000003, 30.500000000000092, -32.49999999999979, -5.199999999999944, -178.9000000000002, -0.10000000000000636, 95.29999999999961, 60.500000000000064, -370.2999999999997, -216.50000000000037, -95.19999999999987, -223.60000000000042, -108.10000000000076, -127.00000000000068, 24.500000000000092, -322.2999999999994, 48.80000000000023, -302.4999999999998, -166.90000000000057, 122.29999999999993, 29.000000000000043, -28.29999999999975, -3.999999999999993, 106.39999999999998, -152.20000000000016, -54.999999999999964, -86.80000000000004, -0.4000000000000128, -103.90000000000003, 117.49999999999999, 48.200000000000195, 73.69999999999966, -91.30000000000024, 124.69999999999996, -53.49999999999978, 83.2999999999999, 183.49999999999991, -21.999999999999744, 2.5999999999999965, 49.70000000000014, -4.299999999999926, 5.299999999999965, 115.39999999999972, -165.30000000000024, -30.3999999999999, -105.10000000000011, 45.800000000000196, -284.5000000000002, 91.70000000000002, 32.6, -108.69999999999985, -231.10000000000025, 91.1, 67.69999999999985, 173.89999999999998, -49.90000000000019, 38.600000000000016, -175.3, -32.499999999999865, 20.9000000000001, -19.899999999999743, 24.500000000000007, -265.5999999999995, -30.40000000000012, 8.299999999999965, -177.99999999999994, -133.6000000000004, -35.799999999999756, -87.40000000000012, 132.49999999999994, 41.0, 13.699999999999964, -7.000000000000121, 140.5999999999999, 125.0, -175.8000000000004, 167.59999999999985, 54.79999999999997, 139.70000000000005, 182.3, 107.30000000000005, 178.4, 49.70000000000009, 102.20000000000006, 10.099999999999993, -209.2, 139.7, 102.5, 17.600000000000193, -93.40000000000077, 44.60000000000004, 90.80000000000004, -99.4, 3.8000000000000873, -58.00000000000023, 19.099999999999966, 50.30000000000013, -53.5000000000002, 1.0999999999999865, -54.399999999999935], "policy_predator_policy_reward": [1.0, 0.0, 34.0, 26.0, 8.0, 28.0, 5.0, 12.0, 0.0, 1.0, 19.0, 5.0, 0.0, 57.0, 46.0, 10.0, 8.0, 4.0, 15.0, 39.0, 103.0, 8.0, 3.0, 58.0, 7.0, 20.0, 79.0, 19.0, 6.0, 52.0, 154.0, 140.0, 25.0, 6.0, 8.0, 61.0, 99.0, 28.0, 77.0, 105.0, 6.0, 19.0, 99.0, 4.0, 26.0, 10.0, 12.0, 7.0, 4.0, 70.0, 49.0, 18.0, 17.0, 34.0, 46.0, 60.0, 89.0, 79.0, 45.0, 34.0, 39.0, 39.0, 7.0, 15.0, 91.0, 152.0, 120.0, 38.0, 119.0, 40.0, 112.0, 1.0, 12.0, 149.0, 3.0, 22.0, 19.0, 2.0, 47.0, 30.0, 23.0, 95.0, 27.0, 32.0, 8.0, 42.0, 154.0, 60.0, 19.0, 11.0, 86.0, 10.0, 89.0, 108.0, 48.0, 119.0, 14.0, 12.0, 3.0, 51.0, 33.0, 45.0, 16.0, 21.0, 10.0, 96.0, 8.0, 5.0, 207.0, 182.0, 60.0, 116.0, 82.0, 0.0, 155.0, 48.0, 106.0, 102.0, 1.0, 92.0, 42.0, 32.0, 14.0, 63.0, 100.0, 69.0, 62.0, 26.0, 47.0, 48.0, 8.0, 10.0, 62.0, 7.0, 23.0, 35.0, 17.0, 5.0, 11.0, 21.0, 12.0, 7.0, 12.0, 115.0, 39.0, 100.0, 40.0, 111.0, 27.0, 53.0, 108.0, 50.0, 36.0, 18.0, 68.0, 8.0, 26.0, 117.0, 43.0, 8.0, 13.0, 18.0, 76.0, 119.0, 60.0, 106.0, 28.0, 70.0, 83.0, 70.0, 39.0, 31.0, 39.0, 0.0, 67.0, 107.0, 38.0, 25.0, 11.0, 7.0, 17.0, 18.0, 12.0, 14.0, 129.0, 41.0, 18.0, 29.0, 60.0, 49.0, 24.0, 34.0, 16.0, 99.0, 31.0, 49.0, 22.0, 74.0, 11.0, 69.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.680658201540818, "mean_inference_ms": 2.170534696387339, "mean_action_processing_ms": 0.2824173127517404, "mean_env_wait_ms": 0.23452351731615365, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003561735153198242, "StateBufferConnector_ms": 0.018839120864868164, "ViewRequirementAgentConnector_ms": 0.11056911945343018}, "num_episodes": 18, "episode_return_max": 340.0, "episode_return_min": -197.8000000000004, "episode_return_mean": 44.18999999999979, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 176000, "num_agent_steps_trained": 176000, "num_env_steps_sampled": 44000, "num_env_steps_trained": 44000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 363.4066496863917, "num_env_steps_trained_throughput_per_sec": 363.4066496863917, "timesteps_total": 44000, "num_env_steps_sampled_lifetime": 44000, "num_agent_steps_sampled_lifetime": 176000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 176000, "timers": {"training_iteration_time_ms": 28669.308, "restore_workers_time_ms": 0.016, "training_step_time_ms": 28669.259, "sample_time_ms": 1490.474, "learn_time_ms": 27162.093, "learn_throughput": 147.264, "synch_weights_time_ms": 14.598}, "counters": {"num_env_steps_sampled": 44000, "num_env_steps_trained": 44000, "num_agent_steps_sampled": 176000, "num_agent_steps_trained": 176000}, "done": false, "training_iteration": 11, "trial_id": "3dae5_00000", "date": "2024-08-14_08-44-38", "timestamp": 1723639478, "time_this_iter_s": 11.059324026107788, "time_total_s": 299.54728651046753, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0f81e50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 299.54728651046753, "iterations_since_restore": 11, "perf": {"cpu_util_percent": 28.0125, "ram_util_percent": 81.42500000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7015481816082405, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.827593844151371, "policy_loss": -0.008116660724522141, "vf_loss": 3.8343542131797346, "vf_explained_var": 0.025135522103183483, "kl": 0.013562953326197252, "entropy": 1.4990984009056496, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 21735.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.0494546694414955, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.333042958173802, "policy_loss": -0.00400935603446135, "vf_loss": 7.335294562546665, "vf_explained_var": 0.030807653589854166, "kl": 0.008788702310557724, "entropy": 1.5711730043093364, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 21735.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 48000, "num_env_steps_trained": 48000, "num_agent_steps_sampled": 192000, "num_agent_steps_trained": 192000}, "env_runners": {"episode_reward_max": 340.0, "episode_reward_min": -197.8000000000004, "episode_reward_mean": 59.94899999999981, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -370.2999999999997, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 194.59999999999997, "predator_policy": 207.0}, "policy_reward_mean": {"prey_policy": -19.05050000000006, "predator_policy": 49.025}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-28.199999999999612, -49.800000000000466, 33.20000000000006, 18.800000000000246, 142.89999999999927, 112.09999999999886, 63.000000000000234, -4.299999999999951, 77.19999999999939, -74.80000000000138, -131.50000000000077, -33.39999999999959, 25.300000000000257, 80.89999999999915, 68.7999999999998, -76.30000000000014, -80.30000000000004, -66.2999999999998, -67.80000000000054, 28.999999999999957, 97.29999999999993, 49.80000000000041, -51.09999999999967, 179.39999999999992, 54.30000000000033, -146.70000000000078, 174.39999999999975, 17.200000000000067, -99.80000000000052, -87.6000000000003, 329.10000000000093, 33.70000000000009, 148.5999999999993, -0.6999999999998696, -73.00000000000011, 168.7999999999992, -197.8000000000004, -142.80000000000095, -153.10000000000144, -94.80000000000058, -45.69999999999988, 48.400000000000176, 74.69999999999952, 179.39999999999995, -38.19999999999993, 0.8000000000000043, 108.60000000000001, 139.89999999999887, 102.39999999999952, 87.79999999999978, 183.4999999999993, 84.29999999999998, 20.000000000000004, 77.09999999999945, 3.4999999999999503, -87.69999999999999, 204.29999999999976, -181.8000000000009, 212.79999999999956, 199.99999999999991, 6.299999999999947, 39.400000000000254, 35.600000000000165, -101.00000000000048, -3.699999999999873, -71.40000000000063, 198.09999999999988, 124.69999999999975, 172.59999999999948, 123.20000000000007, 285.39999999999986, 340.0, 320.69999999999993, 177.89999999999958, -29.099999999999987, 289.19999999999993, 33.19999999999998, 193.39999999999992, 19.400000000000148, 41.10000000000006, 92.7999999999999, 26.700000000000262, 273.8, 11.20000000000005, 92.59999999999985, 19.800000000000033, 75.00000000000016, 190.39999999999966, -36.399999999999565, 147.19999999999976, 93.99999999999991, 171.7999999999994, -48.49999999999999, 194.79999999999933, 150.49999999999943, 108.59999999999994, 239.69999999999956, 9.399999999999999, 223.1, 145.59999999999997], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-10.899999999999826, -144.29999999999984, -217.3000000000005, -14.500000000000071, -17.199999999999747, 25.399999999999984, -49.29999999999976, -34.899999999999956, 36.50000000000012, 70.40000000000012, 20.000000000000014, 73.0999999999995, 0.20000000000022738, -11.199999999999955, -87.10000000000072, 15.800000000000054, -10.900000000000047, 37.1000000000002, -106.00000000000071, -74.8000000000003, -227.40000000000043, -72.10000000000042, -91.00000000000038, -21.399999999999764, 49.099999999999966, -101.80000000000047, -11.499999999999819, 70.39999999999968, -351.7, 177.49999999999986, -248.00000000000003, 13.699999999999964, -127.89999999999992, -111.40000000000055, -215.20000000000036, 35.90000000000025, -292.9000000000002, 64.10000000000005, 20.000000000000014, -15.99999999999991, 20.000000000000014, 56.300000000000054, 51.50000000000019, -78.7000000000008, -176.8000000000003, 7.69999999999999, 55.70000000000003, 64.69999999999996, -26.499999999999794, 30.799999999999955, -68.20000000000049, -292.5000000000001, 101.89999999999988, 42.50000000000009, 3.1999999999999122, -82.00000000000031, -181.80000000000015, -115.00000000000074, -46.59999999999984, -207.99999999999994, 194.59999999999997, 108.49999999999973, 66.80000000000008, -87.10000000000049, 40.10000000000003, 30.500000000000092, -32.49999999999979, -5.199999999999944, -178.9000000000002, -0.10000000000000636, 95.29999999999961, 60.500000000000064, -370.2999999999997, -216.50000000000037, -95.19999999999987, -223.60000000000042, -108.10000000000076, -127.00000000000068, 24.500000000000092, -322.2999999999994, 48.80000000000023, -302.4999999999998, -166.90000000000057, 122.29999999999993, 29.000000000000043, -28.29999999999975, -3.999999999999993, 106.39999999999998, -152.20000000000016, -54.999999999999964, -86.80000000000004, -0.4000000000000128, -103.90000000000003, 117.49999999999999, 48.200000000000195, 73.69999999999966, -91.30000000000024, 124.69999999999996, -53.49999999999978, 83.2999999999999, 183.49999999999991, -21.999999999999744, 2.5999999999999965, 49.70000000000014, -4.299999999999926, 5.299999999999965, 115.39999999999972, -165.30000000000024, -30.3999999999999, -105.10000000000011, 45.800000000000196, -284.5000000000002, 91.70000000000002, 32.6, -108.69999999999985, -231.10000000000025, 91.1, 67.69999999999985, 173.89999999999998, -49.90000000000019, 38.600000000000016, -175.3, -32.499999999999865, 20.9000000000001, -19.899999999999743, 24.500000000000007, -265.5999999999995, -30.40000000000012, 8.299999999999965, -177.99999999999994, -133.6000000000004, -35.799999999999756, -87.40000000000012, 132.49999999999994, 41.0, 13.699999999999964, -7.000000000000121, 140.5999999999999, 125.0, -175.8000000000004, 167.59999999999985, 54.79999999999997, 139.70000000000005, 182.3, 107.30000000000005, 178.4, 49.70000000000009, 102.20000000000006, 10.099999999999993, -209.2, 139.7, 102.5, 17.600000000000193, -93.40000000000077, 44.60000000000004, 90.80000000000004, -99.4, 3.8000000000000873, -58.00000000000023, 19.099999999999966, 50.30000000000013, -53.5000000000002, 1.0999999999999865, -54.399999999999935, 164.0, 69.8, -211.6000000000002, 48.80000000000024, 23.60000000000011, -0.9999999999999858, -64.00000000000023, -2.1999999999999336, -9.699999999999843, -22.29999999999999, 88.39999999999975, 23.000000000000036, -30.39999999999975, -106.00000000000068, 77.0, -53.80000000000025, 140.89999999999992, -145.9000000000004, -12.09999999999998, 119.89999999999975, -234.1, -9.400000000000013, 25.70000000000012, 160.09999999999997, 149.29999999999987, -44.799999999999834, 56.90000000000001, -46.3, 112.99999999999984, 91.69999999999979, -149.8, 3.200000000000001, -34.60000000000008, 121.69999999999999, -74.80000000000007, 46.40000000000002], "policy_predator_policy_reward": [99.0, 28.0, 77.0, 105.0, 6.0, 19.0, 99.0, 4.0, 26.0, 10.0, 12.0, 7.0, 4.0, 70.0, 49.0, 18.0, 17.0, 34.0, 46.0, 60.0, 89.0, 79.0, 45.0, 34.0, 39.0, 39.0, 7.0, 15.0, 91.0, 152.0, 120.0, 38.0, 119.0, 40.0, 112.0, 1.0, 12.0, 149.0, 3.0, 22.0, 19.0, 2.0, 47.0, 30.0, 23.0, 95.0, 27.0, 32.0, 8.0, 42.0, 154.0, 60.0, 19.0, 11.0, 86.0, 10.0, 89.0, 108.0, 48.0, 119.0, 14.0, 12.0, 3.0, 51.0, 33.0, 45.0, 16.0, 21.0, 10.0, 96.0, 8.0, 5.0, 207.0, 182.0, 60.0, 116.0, 82.0, 0.0, 155.0, 48.0, 106.0, 102.0, 1.0, 92.0, 42.0, 32.0, 14.0, 63.0, 100.0, 69.0, 62.0, 26.0, 47.0, 48.0, 8.0, 10.0, 62.0, 7.0, 23.0, 35.0, 17.0, 5.0, 11.0, 21.0, 12.0, 7.0, 12.0, 115.0, 39.0, 100.0, 40.0, 111.0, 27.0, 53.0, 108.0, 50.0, 36.0, 18.0, 68.0, 8.0, 26.0, 117.0, 43.0, 8.0, 13.0, 18.0, 76.0, 119.0, 60.0, 106.0, 28.0, 70.0, 83.0, 70.0, 39.0, 31.0, 39.0, 0.0, 67.0, 107.0, 38.0, 25.0, 11.0, 7.0, 17.0, 18.0, 12.0, 14.0, 129.0, 41.0, 18.0, 29.0, 60.0, 49.0, 24.0, 34.0, 16.0, 99.0, 31.0, 49.0, 22.0, 74.0, 11.0, 69.0, 8.0, 32.0, 91.0, 83.0, 25.0, 45.0, 5.0, 81.0, 69.0, 38.0, 59.0, 20.0, 50.0, 50.0, 93.0, 31.0, 29.0, 70.0, 26.0, 38.0, 149.0, 46.0, 7.0, 2.0, 45.0, 1.0, 10.0, 88.0, 3.0, 32.0, 131.0, 25.0, 70.0, 66.0, 98.0, 76.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.668319358030372, "mean_inference_ms": 2.124511266687914, "mean_action_processing_ms": 0.276134691810045, "mean_env_wait_ms": 0.22897847566655594, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003456711769104004, "StateBufferConnector_ms": 0.018632888793945312, "ViewRequirementAgentConnector_ms": 0.09531068801879883}, "num_episodes": 18, "episode_return_max": 340.0, "episode_return_min": -197.8000000000004, "episode_return_mean": 59.94899999999981, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 192000, "num_agent_steps_trained": 192000, "num_env_steps_sampled": 48000, "num_env_steps_trained": 48000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 6.718265869534495, "num_env_steps_trained_throughput_per_sec": 6.718265869534495, "timesteps_total": 48000, "num_env_steps_sampled_lifetime": 48000, "num_agent_steps_sampled_lifetime": 192000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 192000, "timers": {"training_iteration_time_ms": 87050.301, "restore_workers_time_ms": 0.013, "training_step_time_ms": 87050.256, "sample_time_ms": 1473.57, "learn_time_ms": 85559.656, "learn_throughput": 46.751, "synch_weights_time_ms": 14.756}, "counters": {"num_env_steps_sampled": 48000, "num_env_steps_trained": 48000, "num_agent_steps_sampled": 192000, "num_agent_steps_trained": 192000}, "done": false, "training_iteration": 12, "trial_id": "3dae5_00000", "date": "2024-08-14_08-54-34", "timestamp": 1723640074, "time_this_iter_s": 595.4587090015411, "time_total_s": 895.0059955120087, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3629c10>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 895.0059955120087, "iterations_since_restore": 12, "perf": {"cpu_util_percent": 55.11500000000001, "ram_util_percent": 81.56}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.672164381717248, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.789957344721234, "policy_loss": -0.006987957071473517, "vf_loss": 3.7958118808332575, "vf_explained_var": 0.00890181991789076, "kl": 0.011334278039023394, "entropy": 1.4938796444544717, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 23625.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.0762738876241857, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.902522357809481, "policy_loss": -0.005900223245942798, "vf_loss": 5.906628792878812, "vf_explained_var": -0.06251170288318049, "kl": 0.008968927326416399, "entropy": 1.5661343390979463, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 23625.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 52000, "num_env_steps_trained": 52000, "num_agent_steps_sampled": 208000, "num_agent_steps_trained": 208000}, "env_runners": {"episode_reward_max": 340.0, "episode_reward_min": -197.8000000000004, "episode_reward_mean": 64.92599999999985, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -370.2999999999997, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 194.59999999999997, "predator_policy": 207.0}, "policy_reward_mean": {"prey_policy": -16.357000000000042, "predator_policy": 48.82}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-67.80000000000054, 28.999999999999957, 97.29999999999993, 49.80000000000041, -51.09999999999967, 179.39999999999992, 54.30000000000033, -146.70000000000078, 174.39999999999975, 17.200000000000067, -99.80000000000052, -87.6000000000003, 329.10000000000093, 33.70000000000009, 148.5999999999993, -0.6999999999998696, -73.00000000000011, 168.7999999999992, -197.8000000000004, -142.80000000000095, -153.10000000000144, -94.80000000000058, -45.69999999999988, 48.400000000000176, 74.69999999999952, 179.39999999999995, -38.19999999999993, 0.8000000000000043, 108.60000000000001, 139.89999999999887, 102.39999999999952, 87.79999999999978, 183.4999999999993, 84.29999999999998, 20.000000000000004, 77.09999999999945, 3.4999999999999503, -87.69999999999999, 204.29999999999976, -181.8000000000009, 212.79999999999956, 199.99999999999991, 6.299999999999947, 39.400000000000254, 35.600000000000165, -101.00000000000048, -3.699999999999873, -71.40000000000063, 198.09999999999988, 124.69999999999975, 172.59999999999948, 123.20000000000007, 285.39999999999986, 340.0, 320.69999999999993, 177.89999999999958, -29.099999999999987, 289.19999999999993, 33.19999999999998, 193.39999999999992, 19.400000000000148, 41.10000000000006, 92.7999999999999, 26.700000000000262, 273.8, 11.20000000000005, 92.59999999999985, 19.800000000000033, 75.00000000000016, 190.39999999999966, -36.399999999999565, 147.19999999999976, 93.99999999999991, 171.7999999999994, -48.49999999999999, 194.79999999999933, 150.49999999999943, 108.59999999999994, 239.69999999999956, 9.399999999999999, 223.1, 145.59999999999997, 326.0000000000009, 24.400000000000045, 139.29999999999936, 18.800000000000182, -12.499999999999567, -100.10000000000062, 105.89999999999955, -105.40000000000045, 80.30000000000001, 143.5999999999996, -5.199999999999752, 4.799999999999947, 23.900000000000247, 40.90000000000013, -71.90000000000006, 16.700000000000085, -115.1000000000002, 60.600000000000044], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-292.9000000000002, 64.10000000000005, 20.000000000000014, -15.99999999999991, 20.000000000000014, 56.300000000000054, 51.50000000000019, -78.7000000000008, -176.8000000000003, 7.69999999999999, 55.70000000000003, 64.69999999999996, -26.499999999999794, 30.799999999999955, -68.20000000000049, -292.5000000000001, 101.89999999999988, 42.50000000000009, 3.1999999999999122, -82.00000000000031, -181.80000000000015, -115.00000000000074, -46.59999999999984, -207.99999999999994, 194.59999999999997, 108.49999999999973, 66.80000000000008, -87.10000000000049, 40.10000000000003, 30.500000000000092, -32.49999999999979, -5.199999999999944, -178.9000000000002, -0.10000000000000636, 95.29999999999961, 60.500000000000064, -370.2999999999997, -216.50000000000037, -95.19999999999987, -223.60000000000042, -108.10000000000076, -127.00000000000068, 24.500000000000092, -322.2999999999994, 48.80000000000023, -302.4999999999998, -166.90000000000057, 122.29999999999993, 29.000000000000043, -28.29999999999975, -3.999999999999993, 106.39999999999998, -152.20000000000016, -54.999999999999964, -86.80000000000004, -0.4000000000000128, -103.90000000000003, 117.49999999999999, 48.200000000000195, 73.69999999999966, -91.30000000000024, 124.69999999999996, -53.49999999999978, 83.2999999999999, 183.49999999999991, -21.999999999999744, 2.5999999999999965, 49.70000000000014, -4.299999999999926, 5.299999999999965, 115.39999999999972, -165.30000000000024, -30.3999999999999, -105.10000000000011, 45.800000000000196, -284.5000000000002, 91.70000000000002, 32.6, -108.69999999999985, -231.10000000000025, 91.1, 67.69999999999985, 173.89999999999998, -49.90000000000019, 38.600000000000016, -175.3, -32.499999999999865, 20.9000000000001, -19.899999999999743, 24.500000000000007, -265.5999999999995, -30.40000000000012, 8.299999999999965, -177.99999999999994, -133.6000000000004, -35.799999999999756, -87.40000000000012, 132.49999999999994, 41.0, 13.699999999999964, -7.000000000000121, 140.5999999999999, 125.0, -175.8000000000004, 167.59999999999985, 54.79999999999997, 139.70000000000005, 182.3, 107.30000000000005, 178.4, 49.70000000000009, 102.20000000000006, 10.099999999999993, -209.2, 139.7, 102.5, 17.600000000000193, -93.40000000000077, 44.60000000000004, 90.80000000000004, -99.4, 3.8000000000000873, -58.00000000000023, 19.099999999999966, 50.30000000000013, -53.5000000000002, 1.0999999999999865, -54.399999999999935, 164.0, 69.8, -211.6000000000002, 48.80000000000024, 23.60000000000011, -0.9999999999999858, -64.00000000000023, -2.1999999999999336, -9.699999999999843, -22.29999999999999, 88.39999999999975, 23.000000000000036, -30.39999999999975, -106.00000000000068, 77.0, -53.80000000000025, 140.89999999999992, -145.9000000000004, -12.09999999999998, 119.89999999999975, -234.1, -9.400000000000013, 25.70000000000012, 160.09999999999997, 149.29999999999987, -44.799999999999834, 56.90000000000001, -46.3, 112.99999999999984, 91.69999999999979, -149.8, 3.200000000000001, -34.60000000000008, 121.69999999999999, -74.80000000000007, 46.40000000000002, 179.29999999999987, 121.6999999999999, 14.599999999999966, -5.1999999999999265, 77.29999999999984, 20.000000000000014, -200.80000000000018, 47.600000000000136, -10.59999999999984, -40.89999999999976, -279.1, 20.000000000000014, 90.49999999999997, -34.59999999999989, -282.70000000000005, -99.70000000000044, -66.40000000000026, 46.700000000000024, 52.700000000000095, 41.90000000000001, -12.099999999999817, -72.10000000000043, -28.299999999999763, -70.90000000000052, -3.0999999999999117, -39.99999999999977, 6.500000000000014, -82.60000000000026, -230.50000000000003, -102.40000000000003, -11.499999999999826, 0.20000000000005438, -271.00000000000017, -3.099999999999958, 20.000000000000014, 14.600000000000168], "policy_predator_policy_reward": [12.0, 149.0, 3.0, 22.0, 19.0, 2.0, 47.0, 30.0, 23.0, 95.0, 27.0, 32.0, 8.0, 42.0, 154.0, 60.0, 19.0, 11.0, 86.0, 10.0, 89.0, 108.0, 48.0, 119.0, 14.0, 12.0, 3.0, 51.0, 33.0, 45.0, 16.0, 21.0, 10.0, 96.0, 8.0, 5.0, 207.0, 182.0, 60.0, 116.0, 82.0, 0.0, 155.0, 48.0, 106.0, 102.0, 1.0, 92.0, 42.0, 32.0, 14.0, 63.0, 100.0, 69.0, 62.0, 26.0, 47.0, 48.0, 8.0, 10.0, 62.0, 7.0, 23.0, 35.0, 17.0, 5.0, 11.0, 21.0, 12.0, 7.0, 12.0, 115.0, 39.0, 100.0, 40.0, 111.0, 27.0, 53.0, 108.0, 50.0, 36.0, 18.0, 68.0, 8.0, 26.0, 117.0, 43.0, 8.0, 13.0, 18.0, 76.0, 119.0, 60.0, 106.0, 28.0, 70.0, 83.0, 70.0, 39.0, 31.0, 39.0, 0.0, 67.0, 107.0, 38.0, 25.0, 11.0, 7.0, 17.0, 18.0, 12.0, 14.0, 129.0, 41.0, 18.0, 29.0, 60.0, 49.0, 24.0, 34.0, 16.0, 99.0, 31.0, 49.0, 22.0, 74.0, 11.0, 69.0, 8.0, 32.0, 91.0, 83.0, 25.0, 45.0, 5.0, 81.0, 69.0, 38.0, 59.0, 20.0, 50.0, 50.0, 93.0, 31.0, 29.0, 70.0, 26.0, 38.0, 149.0, 46.0, 7.0, 2.0, 45.0, 1.0, 10.0, 88.0, 3.0, 32.0, 131.0, 25.0, 70.0, 66.0, 98.0, 76.0, 15.0, 10.0, 12.0, 3.0, 31.0, 11.0, 53.0, 119.0, 29.0, 10.0, 27.0, 132.0, 4.0, 46.0, 109.0, 168.0, 16.0, 84.0, 29.0, 20.0, 14.0, 65.0, 47.0, 57.0, 39.0, 28.0, 42.0, 75.0, 92.0, 169.0, 16.0, 12.0, 138.0, 21.0, 12.0, 14.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6628307472206201, "mean_inference_ms": 2.1004794009971763, "mean_action_processing_ms": 0.2727986358795269, "mean_env_wait_ms": 0.22673688997231392, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004110455513000488, "StateBufferConnector_ms": 0.01869058609008789, "ViewRequirementAgentConnector_ms": 0.11067521572113037}, "num_episodes": 18, "episode_return_max": 340.0, "episode_return_min": -197.8000000000004, "episode_return_mean": 64.92599999999985, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 208000, "num_agent_steps_trained": 208000, "num_env_steps_sampled": 52000, "num_env_steps_trained": 52000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 310.3720424341217, "num_env_steps_trained_throughput_per_sec": 310.3720424341217, "timesteps_total": 52000, "num_env_steps_sampled_lifetime": 52000, "num_agent_steps_sampled_lifetime": 208000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 208000, "timers": {"training_iteration_time_ms": 87161.743, "restore_workers_time_ms": 0.013, "training_step_time_ms": 87161.696, "sample_time_ms": 1526.768, "learn_time_ms": 85617.837, "learn_throughput": 46.719, "synch_weights_time_ms": 14.733}, "counters": {"num_env_steps_sampled": 52000, "num_env_steps_trained": 52000, "num_agent_steps_sampled": 208000, "num_agent_steps_trained": 208000}, "done": false, "training_iteration": 13, "trial_id": "3dae5_00000", "date": "2024-08-14_08-54-47", "timestamp": 1723640087, "time_this_iter_s": 12.951539039611816, "time_total_s": 907.9575345516205, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b362cdc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 907.9575345516205, "iterations_since_restore": 13, "perf": {"cpu_util_percent": 57.18333333333333, "ram_util_percent": 81.67222222222223}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.743482770837804, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.354738551851303, "policy_loss": -0.008214316993370337, "vf_loss": 4.361564231297327, "vf_explained_var": 0.01740051788627786, "kl": 0.013886426315833462, "entropy": 1.4453067462911051, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 25515.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.153472294977733, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.727695646235552, "policy_loss": -0.011387827979257853, "vf_loss": 4.73689839562411, "vf_explained_var": -0.046452152003686895, "kl": 0.010925395149856451, "entropy": 1.5513939173133284, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 25515.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 56000, "num_env_steps_trained": 56000, "num_agent_steps_sampled": 224000, "num_agent_steps_trained": 224000}, "env_runners": {"episode_reward_max": 340.0, "episode_reward_min": -181.8000000000009, "episode_reward_mean": 73.58299999999987, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -370.9, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 183.49999999999991, "predator_policy": 169.0}, "policy_reward_mean": {"prey_policy": -7.648500000000041, "predator_policy": 44.44}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.8000000000000043, 108.60000000000001, 139.89999999999887, 102.39999999999952, 87.79999999999978, 183.4999999999993, 84.29999999999998, 20.000000000000004, 77.09999999999945, 3.4999999999999503, -87.69999999999999, 204.29999999999976, -181.8000000000009, 212.79999999999956, 199.99999999999991, 6.299999999999947, 39.400000000000254, 35.600000000000165, -101.00000000000048, -3.699999999999873, -71.40000000000063, 198.09999999999988, 124.69999999999975, 172.59999999999948, 123.20000000000007, 285.39999999999986, 340.0, 320.69999999999993, 177.89999999999958, -29.099999999999987, 289.19999999999993, 33.19999999999998, 193.39999999999992, 19.400000000000148, 41.10000000000006, 92.7999999999999, 26.700000000000262, 273.8, 11.20000000000005, 92.59999999999985, 19.800000000000033, 75.00000000000016, 190.39999999999966, -36.399999999999565, 147.19999999999976, 93.99999999999991, 171.7999999999994, -48.49999999999999, 194.79999999999933, 150.49999999999943, 108.59999999999994, 239.69999999999956, 9.399999999999999, 223.1, 145.59999999999997, 326.0000000000009, 24.400000000000045, 139.29999999999936, 18.800000000000182, -12.499999999999567, -100.10000000000062, 105.89999999999955, -105.40000000000045, 80.30000000000001, 143.5999999999996, -5.199999999999752, 4.799999999999947, 23.900000000000247, 40.90000000000013, -71.90000000000006, 16.700000000000085, -115.1000000000002, 60.600000000000044, 40.50000000000031, 54.90000000000031, 140.59999999999923, 55.70000000000008, 41.40000000000033, -43.49999999999965, 9.700000000000156, 81.09999999999994, 74.89999999999976, 238.59999999999948, 66.59999999999957, 42.90000000000016, 11.80000000000014, -17.599999999999568, -102.90000000000029, 36.3000000000002, 44.500000000000135, -22.899999999999686, 254.99999999999966, -7.000000000000078, -87.50000000000125, 122.29999999999967, 22.200000000000017, 2.3000000000001726, -49.70000000000054, 99.39999999999915, 141.09999999999948], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-86.80000000000004, -0.4000000000000128, -103.90000000000003, 117.49999999999999, 48.200000000000195, 73.69999999999966, -91.30000000000024, 124.69999999999996, -53.49999999999978, 83.2999999999999, 183.49999999999991, -21.999999999999744, 2.5999999999999965, 49.70000000000014, -4.299999999999926, 5.299999999999965, 115.39999999999972, -165.30000000000024, -30.3999999999999, -105.10000000000011, 45.800000000000196, -284.5000000000002, 91.70000000000002, 32.6, -108.69999999999985, -231.10000000000025, 91.1, 67.69999999999985, 173.89999999999998, -49.90000000000019, 38.600000000000016, -175.3, -32.499999999999865, 20.9000000000001, -19.899999999999743, 24.500000000000007, -265.5999999999995, -30.40000000000012, 8.299999999999965, -177.99999999999994, -133.6000000000004, -35.799999999999756, -87.40000000000012, 132.49999999999994, 41.0, 13.699999999999964, -7.000000000000121, 140.5999999999999, 125.0, -175.8000000000004, 167.59999999999985, 54.79999999999997, 139.70000000000005, 182.3, 107.30000000000005, 178.4, 49.70000000000009, 102.20000000000006, 10.099999999999993, -209.2, 139.7, 102.5, 17.600000000000193, -93.40000000000077, 44.60000000000004, 90.80000000000004, -99.4, 3.8000000000000873, -58.00000000000023, 19.099999999999966, 50.30000000000013, -53.5000000000002, 1.0999999999999865, -54.399999999999935, 164.0, 69.8, -211.6000000000002, 48.80000000000024, 23.60000000000011, -0.9999999999999858, -64.00000000000023, -2.1999999999999336, -9.699999999999843, -22.29999999999999, 88.39999999999975, 23.000000000000036, -30.39999999999975, -106.00000000000068, 77.0, -53.80000000000025, 140.89999999999992, -145.9000000000004, -12.09999999999998, 119.89999999999975, -234.1, -9.400000000000013, 25.70000000000012, 160.09999999999997, 149.29999999999987, -44.799999999999834, 56.90000000000001, -46.3, 112.99999999999984, 91.69999999999979, -149.8, 3.200000000000001, -34.60000000000008, 121.69999999999999, -74.80000000000007, 46.40000000000002, 179.29999999999987, 121.6999999999999, 14.599999999999966, -5.1999999999999265, 77.29999999999984, 20.000000000000014, -200.80000000000018, 47.600000000000136, -10.59999999999984, -40.89999999999976, -279.1, 20.000000000000014, 90.49999999999997, -34.59999999999989, -282.70000000000005, -99.70000000000044, -66.40000000000026, 46.700000000000024, 52.700000000000095, 41.90000000000001, -12.099999999999817, -72.10000000000043, -28.299999999999763, -70.90000000000052, -3.0999999999999117, -39.99999999999977, 6.500000000000014, -82.60000000000026, -230.50000000000003, -102.40000000000003, -11.499999999999826, 0.20000000000005438, -271.00000000000017, -3.099999999999958, 20.000000000000014, 14.600000000000168, 2.5999999999999717, 17.899999999999988, -85.60000000000038, 60.50000000000018, 20.300000000000022, 77.30000000000001, -91.30000000000081, 89.00000000000003, 20.000000000000014, 10.399999999999968, -97.00000000000051, -53.50000000000002, -115.90000000000006, 23.60000000000007, 142.39999999999984, -208.30000000000032, 20.000000000000014, -21.099999999999902, 115.6999999999999, 74.89999999999982, -0.9999999999999846, 32.60000000000004, 13.699999999999964, -32.79999999999996, 23.000000000000096, -152.20000000000002, 14.299999999999967, -103.9000000000008, -370.9, 20.000000000000014, -22.599999999999845, 17.899999999999988, 7.100000000000118, -13.59999999999979, -91.30000000000081, -46.5999999999999, 47.90000000000004, 148.1, -5.1999999999999265, -182.80000000000027, -204.70000000000053, 3.1999999999999615, 103.09999999999997, 3.2000000000000064, 15.799999999999946, -13.599999999999868, 20.000000000000014, -57.70000000000042, 20.000000000000014, -213.7, 65.30000000000003, -4.8999999999998956, 67.10000000000004, 20.000000000000014], "policy_predator_policy_reward": [62.0, 26.0, 47.0, 48.0, 8.0, 10.0, 62.0, 7.0, 23.0, 35.0, 17.0, 5.0, 11.0, 21.0, 12.0, 7.0, 12.0, 115.0, 39.0, 100.0, 40.0, 111.0, 27.0, 53.0, 108.0, 50.0, 36.0, 18.0, 68.0, 8.0, 26.0, 117.0, 43.0, 8.0, 13.0, 18.0, 76.0, 119.0, 60.0, 106.0, 28.0, 70.0, 83.0, 70.0, 39.0, 31.0, 39.0, 0.0, 67.0, 107.0, 38.0, 25.0, 11.0, 7.0, 17.0, 18.0, 12.0, 14.0, 129.0, 41.0, 18.0, 29.0, 60.0, 49.0, 24.0, 34.0, 16.0, 99.0, 31.0, 49.0, 22.0, 74.0, 11.0, 69.0, 8.0, 32.0, 91.0, 83.0, 25.0, 45.0, 5.0, 81.0, 69.0, 38.0, 59.0, 20.0, 50.0, 50.0, 93.0, 31.0, 29.0, 70.0, 26.0, 38.0, 149.0, 46.0, 7.0, 2.0, 45.0, 1.0, 10.0, 88.0, 3.0, 32.0, 131.0, 25.0, 70.0, 66.0, 98.0, 76.0, 15.0, 10.0, 12.0, 3.0, 31.0, 11.0, 53.0, 119.0, 29.0, 10.0, 27.0, 132.0, 4.0, 46.0, 109.0, 168.0, 16.0, 84.0, 29.0, 20.0, 14.0, 65.0, 47.0, 57.0, 39.0, 28.0, 42.0, 75.0, 92.0, 169.0, 16.0, 12.0, 138.0, 21.0, 12.0, 14.0, 12.0, 8.0, 53.0, 27.0, 23.0, 20.0, 6.0, 52.0, 8.0, 3.0, 52.0, 55.0, 0.0, 102.0, 85.0, 62.0, 28.0, 48.0, 28.0, 20.0, 7.0, 28.0, 56.0, 6.0, 133.0, 8.0, 59.0, 13.0, 82.0, 166.0, 7.0, 34.0, 20.0, 31.0, 60.0, 55.0, 26.0, 33.0, 104.0, 77.0, 8.0, 106.0, 5.0, 11.0, 2.0, 18.0, 0.0, 40.0, 12.0, 132.0, 18.0, 21.0, 22.0, 32.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6625912147560618, "mean_inference_ms": 2.0871295551566114, "mean_action_processing_ms": 0.27112562869574974, "mean_env_wait_ms": 0.22593405518241375, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004331827163696289, "StateBufferConnector_ms": 0.0036939382553100586, "ViewRequirementAgentConnector_ms": 0.11163246631622314}, "num_episodes": 27, "episode_return_max": 340.0, "episode_return_min": -181.8000000000009, "episode_return_mean": 73.58299999999987, "episodes_this_iter": 27}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 224000, "num_agent_steps_trained": 224000, "num_env_steps_sampled": 56000, "num_env_steps_trained": 56000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 332.35905068288434, "num_env_steps_trained_throughput_per_sec": 332.35905068288434, "timesteps_total": 56000, "num_env_steps_sampled_lifetime": 56000, "num_agent_steps_sampled_lifetime": 224000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 224000, "timers": {"training_iteration_time_ms": 87188.365, "restore_workers_time_ms": 0.013, "training_step_time_ms": 87188.318, "sample_time_ms": 1564.295, "learn_time_ms": 85607.182, "learn_throughput": 46.725, "synch_weights_time_ms": 14.441}, "counters": {"num_env_steps_sampled": 56000, "num_env_steps_trained": 56000, "num_agent_steps_sampled": 224000, "num_agent_steps_trained": 224000}, "done": false, "training_iteration": 14, "trial_id": "3dae5_00000", "date": "2024-08-14_08-54-59", "timestamp": 1723640099, "time_this_iter_s": 12.093456268310547, "time_total_s": 920.050990819931, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b362c3a0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 920.050990819931, "iterations_since_restore": 14, "perf": {"cpu_util_percent": 38.505882352941185, "ram_util_percent": 83.76470588235294}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5391894616777935, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.8814439156068063, "policy_loss": -0.009960448249149574, "vf_loss": 2.8901494236219496, "vf_explained_var": 0.01901710872296934, "kl": 0.012549425027538646, "entropy": 1.4259674860056115, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 27405.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.2197158553928293, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.029678764671245, "policy_loss": -0.009269931377281273, "vf_loss": 5.037163692681247, "vf_explained_var": -0.028215896389471792, "kl": 0.008924991224211067, "entropy": 1.5537434696520447, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 27405.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 60000, "num_env_steps_trained": 60000, "num_agent_steps_sampled": 240000, "num_agent_steps_trained": 240000}, "env_runners": {"episode_reward_max": 340.0, "episode_reward_min": -139.40000000000083, "episode_reward_mean": 66.7879999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -370.9, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 182.3, "predator_policy": 169.0}, "policy_reward_mean": {"prey_policy": -9.741000000000062, "predator_policy": 43.135}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-101.00000000000048, -3.699999999999873, -71.40000000000063, 198.09999999999988, 124.69999999999975, 172.59999999999948, 123.20000000000007, 285.39999999999986, 340.0, 320.69999999999993, 177.89999999999958, -29.099999999999987, 289.19999999999993, 33.19999999999998, 193.39999999999992, 19.400000000000148, 41.10000000000006, 92.7999999999999, 26.700000000000262, 273.8, 11.20000000000005, 92.59999999999985, 19.800000000000033, 75.00000000000016, 190.39999999999966, -36.399999999999565, 147.19999999999976, 93.99999999999991, 171.7999999999994, -48.49999999999999, 194.79999999999933, 150.49999999999943, 108.59999999999994, 239.69999999999956, 9.399999999999999, 223.1, 145.59999999999997, 326.0000000000009, 24.400000000000045, 139.29999999999936, 18.800000000000182, -12.499999999999567, -100.10000000000062, 105.89999999999955, -105.40000000000045, 80.30000000000001, 143.5999999999996, -5.199999999999752, 4.799999999999947, 23.900000000000247, 40.90000000000013, -71.90000000000006, 16.700000000000085, -115.1000000000002, 60.600000000000044, 40.50000000000031, 54.90000000000031, 140.59999999999923, 55.70000000000008, 41.40000000000033, -43.49999999999965, 9.700000000000156, 81.09999999999994, 74.89999999999976, 238.59999999999948, 66.59999999999957, 42.90000000000016, 11.80000000000014, -17.599999999999568, -102.90000000000029, 36.3000000000002, 44.500000000000135, -22.899999999999686, 254.99999999999966, -7.000000000000078, -87.50000000000125, 122.29999999999967, 22.200000000000017, 2.3000000000001726, -49.70000000000054, 99.39999999999915, 141.09999999999948, 46.60000000000028, -10.599999999999602, 71.00000000000031, 42.90000000000024, 104.7999999999993, 79.2999999999993, 29.500000000000234, 35.50000000000008, 88.79999999999937, 56.400000000000105, 46.30000000000012, 91.79999999999984, -72.10000000000082, 53.30000000000018, 36.80000000000025, -139.40000000000083, -1.0999999999999028, -2.49999999999962], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-265.5999999999995, -30.40000000000012, 8.299999999999965, -177.99999999999994, -133.6000000000004, -35.799999999999756, -87.40000000000012, 132.49999999999994, 41.0, 13.699999999999964, -7.000000000000121, 140.5999999999999, 125.0, -175.8000000000004, 167.59999999999985, 54.79999999999997, 139.70000000000005, 182.3, 107.30000000000005, 178.4, 49.70000000000009, 102.20000000000006, 10.099999999999993, -209.2, 139.7, 102.5, 17.600000000000193, -93.40000000000077, 44.60000000000004, 90.80000000000004, -99.4, 3.8000000000000873, -58.00000000000023, 19.099999999999966, 50.30000000000013, -53.5000000000002, 1.0999999999999865, -54.399999999999935, 164.0, 69.8, -211.6000000000002, 48.80000000000024, 23.60000000000011, -0.9999999999999858, -64.00000000000023, -2.1999999999999336, -9.699999999999843, -22.29999999999999, 88.39999999999975, 23.000000000000036, -30.39999999999975, -106.00000000000068, 77.0, -53.80000000000025, 140.89999999999992, -145.9000000000004, -12.09999999999998, 119.89999999999975, -234.1, -9.400000000000013, 25.70000000000012, 160.09999999999997, 149.29999999999987, -44.799999999999834, 56.90000000000001, -46.3, 112.99999999999984, 91.69999999999979, -149.8, 3.200000000000001, -34.60000000000008, 121.69999999999999, -74.80000000000007, 46.40000000000002, 179.29999999999987, 121.6999999999999, 14.599999999999966, -5.1999999999999265, 77.29999999999984, 20.000000000000014, -200.80000000000018, 47.600000000000136, -10.59999999999984, -40.89999999999976, -279.1, 20.000000000000014, 90.49999999999997, -34.59999999999989, -282.70000000000005, -99.70000000000044, -66.40000000000026, 46.700000000000024, 52.700000000000095, 41.90000000000001, -12.099999999999817, -72.10000000000043, -28.299999999999763, -70.90000000000052, -3.0999999999999117, -39.99999999999977, 6.500000000000014, -82.60000000000026, -230.50000000000003, -102.40000000000003, -11.499999999999826, 0.20000000000005438, -271.00000000000017, -3.099999999999958, 20.000000000000014, 14.600000000000168, 2.5999999999999717, 17.899999999999988, -85.60000000000038, 60.50000000000018, 20.300000000000022, 77.30000000000001, -91.30000000000081, 89.00000000000003, 20.000000000000014, 10.399999999999968, -97.00000000000051, -53.50000000000002, -115.90000000000006, 23.60000000000007, 142.39999999999984, -208.30000000000032, 20.000000000000014, -21.099999999999902, 115.6999999999999, 74.89999999999982, -0.9999999999999846, 32.60000000000004, 13.699999999999964, -32.79999999999996, 23.000000000000096, -152.20000000000002, 14.299999999999967, -103.9000000000008, -370.9, 20.000000000000014, -22.599999999999845, 17.899999999999988, 7.100000000000118, -13.59999999999979, -91.30000000000081, -46.5999999999999, 47.90000000000004, 148.1, -5.1999999999999265, -182.80000000000027, -204.70000000000053, 3.1999999999999615, 103.09999999999997, 3.2000000000000064, 15.799999999999946, -13.599999999999868, 20.000000000000014, -57.70000000000042, 20.000000000000014, -213.7, 65.30000000000003, -4.8999999999998956, 67.10000000000004, 20.000000000000014, 20.000000000000014, -3.400000000000012, 5.299999999999965, -61.90000000000071, 54.20000000000023, -8.199999999999813, 8.89999999999997, 20.000000000000014, 69.49999999999977, 26.300000000000125, 29.300000000000175, 41.00000000000017, 11.000000000000016, -83.50000000000082, -9.999999999999824, 9.499999999999964, -32.20000000000003, 20.000000000000014, 3.1999999999999615, -32.800000000000125, -93.40000000000047, 52.70000000000004, 33.50000000000006, 11.299999999999962, -98.80000000000024, -70.30000000000062, -220.30000000000052, 80.59999999999982, 23.900000000000077, -3.099999999999958, -82.50000000000026, -187.9000000000004, -75.10000000000048, -0.9999999999999846, 13.399999999999958, -61.900000000000766], "policy_predator_policy_reward": [76.0, 119.0, 60.0, 106.0, 28.0, 70.0, 83.0, 70.0, 39.0, 31.0, 39.0, 0.0, 67.0, 107.0, 38.0, 25.0, 11.0, 7.0, 17.0, 18.0, 12.0, 14.0, 129.0, 41.0, 18.0, 29.0, 60.0, 49.0, 24.0, 34.0, 16.0, 99.0, 31.0, 49.0, 22.0, 74.0, 11.0, 69.0, 8.0, 32.0, 91.0, 83.0, 25.0, 45.0, 5.0, 81.0, 69.0, 38.0, 59.0, 20.0, 50.0, 50.0, 93.0, 31.0, 29.0, 70.0, 26.0, 38.0, 149.0, 46.0, 7.0, 2.0, 45.0, 1.0, 10.0, 88.0, 3.0, 32.0, 131.0, 25.0, 70.0, 66.0, 98.0, 76.0, 15.0, 10.0, 12.0, 3.0, 31.0, 11.0, 53.0, 119.0, 29.0, 10.0, 27.0, 132.0, 4.0, 46.0, 109.0, 168.0, 16.0, 84.0, 29.0, 20.0, 14.0, 65.0, 47.0, 57.0, 39.0, 28.0, 42.0, 75.0, 92.0, 169.0, 16.0, 12.0, 138.0, 21.0, 12.0, 14.0, 12.0, 8.0, 53.0, 27.0, 23.0, 20.0, 6.0, 52.0, 8.0, 3.0, 52.0, 55.0, 0.0, 102.0, 85.0, 62.0, 28.0, 48.0, 28.0, 20.0, 7.0, 28.0, 56.0, 6.0, 133.0, 8.0, 59.0, 13.0, 82.0, 166.0, 7.0, 34.0, 20.0, 31.0, 60.0, 55.0, 26.0, 33.0, 104.0, 77.0, 8.0, 106.0, 5.0, 11.0, 2.0, 18.0, 0.0, 40.0, 12.0, 132.0, 18.0, 21.0, 22.0, 32.0, 10.0, 20.0, 39.0, 7.0, 25.0, 0.0, 8.0, 6.0, 4.0, 5.0, 1.0, 8.0, 47.0, 55.0, 12.0, 24.0, 50.0, 51.0, 29.0, 57.0, 65.0, 22.0, 39.0, 8.0, 6.0, 91.0, 130.0, 63.0, 5.0, 11.0, 105.0, 26.0, 65.0, 10.0, 39.0, 7.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6648281710474806, "mean_inference_ms": 2.0822200557306445, "mean_action_processing_ms": 0.27077280824563543, "mean_env_wait_ms": 0.2261885123002171, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004366278648376465, "StateBufferConnector_ms": 0.003665924072265625, "ViewRequirementAgentConnector_ms": 0.11273908615112305}, "num_episodes": 18, "episode_return_max": 340.0, "episode_return_min": -139.40000000000083, "episode_return_mean": 66.7879999999999, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 240000, "num_agent_steps_trained": 240000, "num_env_steps_sampled": 60000, "num_env_steps_trained": 60000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 357.8510816894585, "num_env_steps_trained_throughput_per_sec": 357.8510816894585, "timesteps_total": 60000, "num_env_steps_sampled_lifetime": 60000, "num_agent_steps_sampled_lifetime": 240000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 240000, "timers": {"training_iteration_time_ms": 87125.92, "restore_workers_time_ms": 0.013, "training_step_time_ms": 87125.876, "sample_time_ms": 1549.732, "learn_time_ms": 85559.409, "learn_throughput": 46.751, "synch_weights_time_ms": 14.389}, "counters": {"num_env_steps_sampled": 60000, "num_env_steps_trained": 60000, "num_agent_steps_sampled": 240000, "num_agent_steps_trained": 240000}, "done": false, "training_iteration": 15, "trial_id": "3dae5_00000", "date": "2024-08-14_08-55-10", "timestamp": 1723640110, "time_this_iter_s": 11.18230390548706, "time_total_s": 931.2332947254181, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0f81670>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 931.2332947254181, "iterations_since_restore": 15, "perf": {"cpu_util_percent": 26.875, "ram_util_percent": 83.48124999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7740367497085894, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.800383348565884, "policy_loss": -0.01053024840284947, "vf_loss": 4.809291530790783, "vf_explained_var": 0.002498359591872604, "kl": 0.01622055602369199, "entropy": 1.407009494052362, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 29295.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.5096190945812005, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.864324614862916, "policy_loss": -0.0058704409092940665, "vf_loss": 6.868164979086982, "vf_explained_var": 0.029562810741404377, "kl": 0.01015043783572668, "entropy": 1.5596844954465432, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 29295.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 64000, "num_env_steps_trained": 64000, "num_agent_steps_sampled": 256000, "num_agent_steps_trained": 256000}, "env_runners": {"episode_reward_max": 326.0000000000009, "episode_reward_min": -139.40000000000083, "episode_reward_mean": 56.16799999999992, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -370.9, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 179.29999999999987, "predator_policy": 169.0}, "policy_reward_mean": {"prey_policy": -14.716000000000065, "predator_policy": 42.8}, "custom_metrics": {}, "hist_stats": {"episode_reward": [26.700000000000262, 273.8, 11.20000000000005, 92.59999999999985, 19.800000000000033, 75.00000000000016, 190.39999999999966, -36.399999999999565, 147.19999999999976, 93.99999999999991, 171.7999999999994, -48.49999999999999, 194.79999999999933, 150.49999999999943, 108.59999999999994, 239.69999999999956, 9.399999999999999, 223.1, 145.59999999999997, 326.0000000000009, 24.400000000000045, 139.29999999999936, 18.800000000000182, -12.499999999999567, -100.10000000000062, 105.89999999999955, -105.40000000000045, 80.30000000000001, 143.5999999999996, -5.199999999999752, 4.799999999999947, 23.900000000000247, 40.90000000000013, -71.90000000000006, 16.700000000000085, -115.1000000000002, 60.600000000000044, 40.50000000000031, 54.90000000000031, 140.59999999999923, 55.70000000000008, 41.40000000000033, -43.49999999999965, 9.700000000000156, 81.09999999999994, 74.89999999999976, 238.59999999999948, 66.59999999999957, 42.90000000000016, 11.80000000000014, -17.599999999999568, -102.90000000000029, 36.3000000000002, 44.500000000000135, -22.899999999999686, 254.99999999999966, -7.000000000000078, -87.50000000000125, 122.29999999999967, 22.200000000000017, 2.3000000000001726, -49.70000000000054, 99.39999999999915, 141.09999999999948, 46.60000000000028, -10.599999999999602, 71.00000000000031, 42.90000000000024, 104.7999999999993, 79.2999999999993, 29.500000000000234, 35.50000000000008, 88.79999999999937, 56.400000000000105, 46.30000000000012, 91.79999999999984, -72.10000000000082, 53.30000000000018, 36.80000000000025, -139.40000000000083, -1.0999999999999028, -2.49999999999962, 82.50000000000006, 70.10000000000021, 85.10000000000005, 72.19999999999972, 3.40000000000007, 158.69999999999956, 69.50000000000031, 67.49999999999986, 8.199999999999985, -99.7000000000005, 59.90000000000031, 78.1999999999999, 60.10000000000008, 83.90000000000018, 38.700000000000124, 75.59999999999947, 124.39999999999921, 106.19999999999962], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [1.0999999999999865, -54.399999999999935, 164.0, 69.8, -211.6000000000002, 48.80000000000024, 23.60000000000011, -0.9999999999999858, -64.00000000000023, -2.1999999999999336, -9.699999999999843, -22.29999999999999, 88.39999999999975, 23.000000000000036, -30.39999999999975, -106.00000000000068, 77.0, -53.80000000000025, 140.89999999999992, -145.9000000000004, -12.09999999999998, 119.89999999999975, -234.1, -9.400000000000013, 25.70000000000012, 160.09999999999997, 149.29999999999987, -44.799999999999834, 56.90000000000001, -46.3, 112.99999999999984, 91.69999999999979, -149.8, 3.200000000000001, -34.60000000000008, 121.69999999999999, -74.80000000000007, 46.40000000000002, 179.29999999999987, 121.6999999999999, 14.599999999999966, -5.1999999999999265, 77.29999999999984, 20.000000000000014, -200.80000000000018, 47.600000000000136, -10.59999999999984, -40.89999999999976, -279.1, 20.000000000000014, 90.49999999999997, -34.59999999999989, -282.70000000000005, -99.70000000000044, -66.40000000000026, 46.700000000000024, 52.700000000000095, 41.90000000000001, -12.099999999999817, -72.10000000000043, -28.299999999999763, -70.90000000000052, -3.0999999999999117, -39.99999999999977, 6.500000000000014, -82.60000000000026, -230.50000000000003, -102.40000000000003, -11.499999999999826, 0.20000000000005438, -271.00000000000017, -3.099999999999958, 20.000000000000014, 14.600000000000168, 2.5999999999999717, 17.899999999999988, -85.60000000000038, 60.50000000000018, 20.300000000000022, 77.30000000000001, -91.30000000000081, 89.00000000000003, 20.000000000000014, 10.399999999999968, -97.00000000000051, -53.50000000000002, -115.90000000000006, 23.60000000000007, 142.39999999999984, -208.30000000000032, 20.000000000000014, -21.099999999999902, 115.6999999999999, 74.89999999999982, -0.9999999999999846, 32.60000000000004, 13.699999999999964, -32.79999999999996, 23.000000000000096, -152.20000000000002, 14.299999999999967, -103.9000000000008, -370.9, 20.000000000000014, -22.599999999999845, 17.899999999999988, 7.100000000000118, -13.59999999999979, -91.30000000000081, -46.5999999999999, 47.90000000000004, 148.1, -5.1999999999999265, -182.80000000000027, -204.70000000000053, 3.1999999999999615, 103.09999999999997, 3.2000000000000064, 15.799999999999946, -13.599999999999868, 20.000000000000014, -57.70000000000042, 20.000000000000014, -213.7, 65.30000000000003, -4.8999999999998956, 67.10000000000004, 20.000000000000014, 20.000000000000014, -3.400000000000012, 5.299999999999965, -61.90000000000071, 54.20000000000023, -8.199999999999813, 8.89999999999997, 20.000000000000014, 69.49999999999977, 26.300000000000125, 29.300000000000175, 41.00000000000017, 11.000000000000016, -83.50000000000082, -9.999999999999824, 9.499999999999964, -32.20000000000003, 20.000000000000014, 3.1999999999999615, -32.800000000000125, -93.40000000000047, 52.70000000000004, 33.50000000000006, 11.299999999999962, -98.80000000000024, -70.30000000000062, -220.30000000000052, 80.59999999999982, 23.900000000000077, -3.099999999999958, -82.50000000000026, -187.9000000000004, -75.10000000000048, -0.9999999999999846, 13.399999999999958, -61.900000000000766, -29.79999999999994, 29.300000000000004, 6.500000000000057, -9.39999999999985, -0.9999999999999881, 28.100000000000023, -22.29999999999979, 48.50000000000011, 20.000000000000014, -76.59999999999985, 14.300000000000026, 52.40000000000003, 0.4999999999999777, 34.99999999999996, -35.19999999999985, 37.70000000000002, -147.40000000000026, -54.39999999999989, -105.10000000000034, -175.60000000000028, -59.20000000000067, 28.100000000000158, -66.10000000000039, 35.30000000000017, 66.19999999999999, -144.10000000000022, 90.1999999999999, -212.30000000000055, -0.09999999999980247, -17.199999999999775, 64.99999999999999, -54.40000000000009, -24.69999999999999, 103.0999999999996, 94.09999999999985, -19.899999999999743], "policy_predator_policy_reward": [11.0, 69.0, 8.0, 32.0, 91.0, 83.0, 25.0, 45.0, 5.0, 81.0, 69.0, 38.0, 59.0, 20.0, 50.0, 50.0, 93.0, 31.0, 29.0, 70.0, 26.0, 38.0, 149.0, 46.0, 7.0, 2.0, 45.0, 1.0, 10.0, 88.0, 3.0, 32.0, 131.0, 25.0, 70.0, 66.0, 98.0, 76.0, 15.0, 10.0, 12.0, 3.0, 31.0, 11.0, 53.0, 119.0, 29.0, 10.0, 27.0, 132.0, 4.0, 46.0, 109.0, 168.0, 16.0, 84.0, 29.0, 20.0, 14.0, 65.0, 47.0, 57.0, 39.0, 28.0, 42.0, 75.0, 92.0, 169.0, 16.0, 12.0, 138.0, 21.0, 12.0, 14.0, 12.0, 8.0, 53.0, 27.0, 23.0, 20.0, 6.0, 52.0, 8.0, 3.0, 52.0, 55.0, 0.0, 102.0, 85.0, 62.0, 28.0, 48.0, 28.0, 20.0, 7.0, 28.0, 56.0, 6.0, 133.0, 8.0, 59.0, 13.0, 82.0, 166.0, 7.0, 34.0, 20.0, 31.0, 60.0, 55.0, 26.0, 33.0, 104.0, 77.0, 8.0, 106.0, 5.0, 11.0, 2.0, 18.0, 0.0, 40.0, 12.0, 132.0, 18.0, 21.0, 22.0, 32.0, 10.0, 20.0, 39.0, 7.0, 25.0, 0.0, 8.0, 6.0, 4.0, 5.0, 1.0, 8.0, 47.0, 55.0, 12.0, 24.0, 50.0, 51.0, 29.0, 57.0, 65.0, 22.0, 39.0, 8.0, 6.0, 91.0, 130.0, 63.0, 5.0, 11.0, 105.0, 26.0, 65.0, 10.0, 39.0, 7.0, 39.0, 44.0, 36.0, 37.0, 10.0, 48.0, 20.0, 26.0, 30.0, 30.0, 51.0, 41.0, 16.0, 18.0, 37.0, 28.0, 85.0, 125.0, 93.0, 88.0, 54.0, 37.0, 55.0, 54.0, 106.0, 32.0, 95.0, 111.0, 38.0, 18.0, 49.0, 16.0, 41.0, 5.0, 19.0, 13.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6680664275990861, "mean_inference_ms": 2.084986660996494, "mean_action_processing_ms": 0.27104170565167196, "mean_env_wait_ms": 0.2270087310752376, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004390120506286621, "StateBufferConnector_ms": 0.003535151481628418, "ViewRequirementAgentConnector_ms": 0.11363482475280762}, "num_episodes": 18, "episode_return_max": 326.0000000000009, "episode_return_min": -139.40000000000083, "episode_return_mean": 56.16799999999992, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 256000, "num_agent_steps_trained": 256000, "num_env_steps_sampled": 64000, "num_env_steps_trained": 64000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 4.572701795444687, "num_env_steps_trained_throughput_per_sec": 4.572701795444687, "timesteps_total": 64000, "num_env_steps_sampled_lifetime": 64000, "num_agent_steps_sampled_lifetime": 256000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 256000, "timers": {"training_iteration_time_ms": 173217.628, "restore_workers_time_ms": 0.013, "training_step_time_ms": 173217.588, "sample_time_ms": 1532.436, "learn_time_ms": 171667.307, "learn_throughput": 23.301, "synch_weights_time_ms": 15.385}, "counters": {"num_env_steps_sampled": 64000, "num_env_steps_trained": 64000, "num_agent_steps_sampled": 256000, "num_agent_steps_trained": 256000}, "done": false, "training_iteration": 16, "trial_id": "3dae5_00000", "date": "2024-08-14_09-09-45", "timestamp": 1723640985, "time_this_iter_s": 874.794704914093, "time_total_s": 1806.027999639511, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0f398b0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1806.027999639511, "iterations_since_restore": 16, "perf": {"cpu_util_percent": 73.58518518518518, "ram_util_percent": 80.77037037037036}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8951510884459057, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.618055493995626, "policy_loss": -0.015692898576152782, "vf_loss": 5.6318399716937355, "vf_explained_var": 0.002832124252167959, "kl": 0.0190842702648002, "entropy": 1.389068217946108, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 31185.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.559872416970591, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.283381998223602, "policy_loss": -0.008100595490184055, "vf_loss": 8.288908308271377, "vf_explained_var": 0.00956715739593304, "kl": 0.01287145845711119, "entropy": 1.5161197045492747, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 31185.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 68000, "num_env_steps_trained": 68000, "num_agent_steps_sampled": 272000, "num_agent_steps_trained": 272000}, "env_runners": {"episode_reward_max": 326.0000000000009, "episode_reward_min": -139.40000000000083, "episode_reward_mean": 44.39299999999992, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -412.70000000000005, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 179.29999999999987, "predator_policy": 212.0}, "policy_reward_mean": {"prey_policy": -23.728500000000057, "predator_policy": 45.925}, "custom_metrics": {}, "hist_stats": {"episode_reward": [145.59999999999997, 326.0000000000009, 24.400000000000045, 139.29999999999936, 18.800000000000182, -12.499999999999567, -100.10000000000062, 105.89999999999955, -105.40000000000045, 80.30000000000001, 143.5999999999996, -5.199999999999752, 4.799999999999947, 23.900000000000247, 40.90000000000013, -71.90000000000006, 16.700000000000085, -115.1000000000002, 60.600000000000044, 40.50000000000031, 54.90000000000031, 140.59999999999923, 55.70000000000008, 41.40000000000033, -43.49999999999965, 9.700000000000156, 81.09999999999994, 74.89999999999976, 238.59999999999948, 66.59999999999957, 42.90000000000016, 11.80000000000014, -17.599999999999568, -102.90000000000029, 36.3000000000002, 44.500000000000135, -22.899999999999686, 254.99999999999966, -7.000000000000078, -87.50000000000125, 122.29999999999967, 22.200000000000017, 2.3000000000001726, -49.70000000000054, 99.39999999999915, 141.09999999999948, 46.60000000000028, -10.599999999999602, 71.00000000000031, 42.90000000000024, 104.7999999999993, 79.2999999999993, 29.500000000000234, 35.50000000000008, 88.79999999999937, 56.400000000000105, 46.30000000000012, 91.79999999999984, -72.10000000000082, 53.30000000000018, 36.80000000000025, -139.40000000000083, -1.0999999999999028, -2.49999999999962, 82.50000000000006, 70.10000000000021, 85.10000000000005, 72.19999999999972, 3.40000000000007, 158.69999999999956, 69.50000000000031, 67.49999999999986, 8.199999999999985, -99.7000000000005, 59.90000000000031, 78.1999999999999, 60.10000000000008, 83.90000000000018, 38.700000000000124, 75.59999999999947, 124.39999999999921, 106.19999999999962, 52.500000000000185, -69.40000000000046, 64.50000000000023, 95.99999999999989, 103.19999999999945, -63.099999999999994, 68.8000000000001, 12.399999999999974, 88.80000000000007, 223.99999999999955, -90.70000000000024, 85.40000000000015, 11.600000000000078, 97.2999999999993, 68.70000000000012, -3.999999999999801, -25.499999999999964, 45.700000000000045], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-74.80000000000007, 46.40000000000002, 179.29999999999987, 121.6999999999999, 14.599999999999966, -5.1999999999999265, 77.29999999999984, 20.000000000000014, -200.80000000000018, 47.600000000000136, -10.59999999999984, -40.89999999999976, -279.1, 20.000000000000014, 90.49999999999997, -34.59999999999989, -282.70000000000005, -99.70000000000044, -66.40000000000026, 46.700000000000024, 52.700000000000095, 41.90000000000001, -12.099999999999817, -72.10000000000043, -28.299999999999763, -70.90000000000052, -3.0999999999999117, -39.99999999999977, 6.500000000000014, -82.60000000000026, -230.50000000000003, -102.40000000000003, -11.499999999999826, 0.20000000000005438, -271.00000000000017, -3.099999999999958, 20.000000000000014, 14.600000000000168, 2.5999999999999717, 17.899999999999988, -85.60000000000038, 60.50000000000018, 20.300000000000022, 77.30000000000001, -91.30000000000081, 89.00000000000003, 20.000000000000014, 10.399999999999968, -97.00000000000051, -53.50000000000002, -115.90000000000006, 23.60000000000007, 142.39999999999984, -208.30000000000032, 20.000000000000014, -21.099999999999902, 115.6999999999999, 74.89999999999982, -0.9999999999999846, 32.60000000000004, 13.699999999999964, -32.79999999999996, 23.000000000000096, -152.20000000000002, 14.299999999999967, -103.9000000000008, -370.9, 20.000000000000014, -22.599999999999845, 17.899999999999988, 7.100000000000118, -13.59999999999979, -91.30000000000081, -46.5999999999999, 47.90000000000004, 148.1, -5.1999999999999265, -182.80000000000027, -204.70000000000053, 3.1999999999999615, 103.09999999999997, 3.2000000000000064, 15.799999999999946, -13.599999999999868, 20.000000000000014, -57.70000000000042, 20.000000000000014, -213.7, 65.30000000000003, -4.8999999999998956, 67.10000000000004, 20.000000000000014, 20.000000000000014, -3.400000000000012, 5.299999999999965, -61.90000000000071, 54.20000000000023, -8.199999999999813, 8.89999999999997, 20.000000000000014, 69.49999999999977, 26.300000000000125, 29.300000000000175, 41.00000000000017, 11.000000000000016, -83.50000000000082, -9.999999999999824, 9.499999999999964, -32.20000000000003, 20.000000000000014, 3.1999999999999615, -32.800000000000125, -93.40000000000047, 52.70000000000004, 33.50000000000006, 11.299999999999962, -98.80000000000024, -70.30000000000062, -220.30000000000052, 80.59999999999982, 23.900000000000077, -3.099999999999958, -82.50000000000026, -187.9000000000004, -75.10000000000048, -0.9999999999999846, 13.399999999999958, -61.900000000000766, -29.79999999999994, 29.300000000000004, 6.500000000000057, -9.39999999999985, -0.9999999999999881, 28.100000000000023, -22.29999999999979, 48.50000000000011, 20.000000000000014, -76.59999999999985, 14.300000000000026, 52.40000000000003, 0.4999999999999777, 34.99999999999996, -35.19999999999985, 37.70000000000002, -147.40000000000026, -54.39999999999989, -105.10000000000034, -175.60000000000028, -59.20000000000067, 28.100000000000158, -66.10000000000039, 35.30000000000017, 66.19999999999999, -144.10000000000022, 90.1999999999999, -212.30000000000055, -0.09999999999980247, -17.199999999999775, 64.99999999999999, -54.40000000000009, -24.69999999999999, 103.0999999999996, 94.09999999999985, -19.899999999999743, 20.000000000000014, -26.49999999999983, -127.60000000000034, -62.80000000000005, -234.20000000000047, 94.69999999999972, 27.800000000000026, -11.799999999999894, 30.20000000000006, 20.000000000000014, -97.30000000000011, -149.80000000000015, 29.60000000000006, -47.79999999999987, 73.10000000000008, -412.70000000000005, -203.00000000000014, 102.80000000000007, 93.79999999999978, 126.19999999999982, -315.1999999999999, 24.499999999999993, 25.70000000000009, 19.69999999999999, -4.599999999999966, -164.8000000000004, 43.099999999999945, -56.799999999999926, 77.90000000000003, -131.20000000000016, -21.999999999999915, -69.99999999999983, -80.50000000000001, -57.999999999999936, -121.00000000000037, 31.699999999999996], "policy_predator_policy_reward": [98.0, 76.0, 15.0, 10.0, 12.0, 3.0, 31.0, 11.0, 53.0, 119.0, 29.0, 10.0, 27.0, 132.0, 4.0, 46.0, 109.0, 168.0, 16.0, 84.0, 29.0, 20.0, 14.0, 65.0, 47.0, 57.0, 39.0, 28.0, 42.0, 75.0, 92.0, 169.0, 16.0, 12.0, 138.0, 21.0, 12.0, 14.0, 12.0, 8.0, 53.0, 27.0, 23.0, 20.0, 6.0, 52.0, 8.0, 3.0, 52.0, 55.0, 0.0, 102.0, 85.0, 62.0, 28.0, 48.0, 28.0, 20.0, 7.0, 28.0, 56.0, 6.0, 133.0, 8.0, 59.0, 13.0, 82.0, 166.0, 7.0, 34.0, 20.0, 31.0, 60.0, 55.0, 26.0, 33.0, 104.0, 77.0, 8.0, 106.0, 5.0, 11.0, 2.0, 18.0, 0.0, 40.0, 12.0, 132.0, 18.0, 21.0, 22.0, 32.0, 10.0, 20.0, 39.0, 7.0, 25.0, 0.0, 8.0, 6.0, 4.0, 5.0, 1.0, 8.0, 47.0, 55.0, 12.0, 24.0, 50.0, 51.0, 29.0, 57.0, 65.0, 22.0, 39.0, 8.0, 6.0, 91.0, 130.0, 63.0, 5.0, 11.0, 105.0, 26.0, 65.0, 10.0, 39.0, 7.0, 39.0, 44.0, 36.0, 37.0, 10.0, 48.0, 20.0, 26.0, 30.0, 30.0, 51.0, 41.0, 16.0, 18.0, 37.0, 28.0, 85.0, 125.0, 93.0, 88.0, 54.0, 37.0, 55.0, 54.0, 106.0, 32.0, 95.0, 111.0, 38.0, 18.0, 49.0, 16.0, 41.0, 5.0, 19.0, 13.0, 36.0, 23.0, 96.0, 25.0, 133.0, 71.0, 29.0, 51.0, 25.0, 28.0, 108.0, 76.0, 26.0, 61.0, 212.0, 140.0, 80.0, 109.0, 3.0, 1.0, 170.0, 30.0, 19.0, 21.0, 109.0, 72.0, 31.0, 80.0, 20.0, 102.0, 35.0, 53.0, 60.0, 53.0, 71.0, 64.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6747137086075452, "mean_inference_ms": 2.0964947268230425, "mean_action_processing_ms": 0.2726055897714209, "mean_env_wait_ms": 0.2290111457434844, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004503011703491211, "StateBufferConnector_ms": 0.003314971923828125, "ViewRequirementAgentConnector_ms": 0.13552379608154297}, "num_episodes": 18, "episode_return_max": 326.0000000000009, "episode_return_min": -139.40000000000083, "episode_return_mean": 44.39299999999992, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 272000, "num_agent_steps_trained": 272000, "num_env_steps_sampled": 68000, "num_env_steps_trained": 68000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 310.0579130160976, "num_env_steps_trained_throughput_per_sec": 310.0579130160976, "timesteps_total": 68000, "num_env_steps_sampled_lifetime": 68000, "num_agent_steps_sampled_lifetime": 272000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 272000, "timers": {"training_iteration_time_ms": 173137.227, "restore_workers_time_ms": 0.013, "training_step_time_ms": 173137.182, "sample_time_ms": 1490.951, "learn_time_ms": 171628.311, "learn_throughput": 23.306, "synch_weights_time_ms": 15.425}, "counters": {"num_env_steps_sampled": 68000, "num_env_steps_trained": 68000, "num_agent_steps_sampled": 272000, "num_agent_steps_trained": 272000}, "done": false, "training_iteration": 17, "trial_id": "3dae5_00000", "date": "2024-08-14_09-09-58", "timestamp": 1723640998, "time_this_iter_s": 12.949623107910156, "time_total_s": 1818.9776227474213, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0fd7700>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1818.9776227474213, "iterations_since_restore": 17, "perf": {"cpu_util_percent": 48.49999999999999, "ram_util_percent": 83.25}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4715000431689005, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.19309214296795, "policy_loss": -0.01218185852473927, "vf_loss": 5.2031032755261375, "vf_explained_var": 0.04658317424002148, "kl": 0.02170732711409593, "entropy": 1.3429311647616997, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 33075.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7442403094163017, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.39264609775846, "policy_loss": -0.007560665674492835, "vf_loss": 6.398044653796645, "vf_explained_var": -0.09529982660182569, "kl": 0.010810596415372227, "entropy": 1.5295689737986005, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 33075.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 72000, "num_env_steps_trained": 72000, "num_agent_steps_sampled": 288000, "num_agent_steps_trained": 288000}, "env_runners": {"episode_reward_max": 280.69999999999965, "episode_reward_min": -204.10000000000045, "episode_reward_mean": 44.01699999999991, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -412.70000000000005, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 162.2, "predator_policy": 212.0}, "policy_reward_mean": {"prey_policy": -24.721500000000077, "predator_policy": 46.73}, "custom_metrics": {}, "hist_stats": {"episode_reward": [55.70000000000008, 41.40000000000033, -43.49999999999965, 9.700000000000156, 81.09999999999994, 74.89999999999976, 238.59999999999948, 66.59999999999957, 42.90000000000016, 11.80000000000014, -17.599999999999568, -102.90000000000029, 36.3000000000002, 44.500000000000135, -22.899999999999686, 254.99999999999966, -7.000000000000078, -87.50000000000125, 122.29999999999967, 22.200000000000017, 2.3000000000001726, -49.70000000000054, 99.39999999999915, 141.09999999999948, 46.60000000000028, -10.599999999999602, 71.00000000000031, 42.90000000000024, 104.7999999999993, 79.2999999999993, 29.500000000000234, 35.50000000000008, 88.79999999999937, 56.400000000000105, 46.30000000000012, 91.79999999999984, -72.10000000000082, 53.30000000000018, 36.80000000000025, -139.40000000000083, -1.0999999999999028, -2.49999999999962, 82.50000000000006, 70.10000000000021, 85.10000000000005, 72.19999999999972, 3.40000000000007, 158.69999999999956, 69.50000000000031, 67.49999999999986, 8.199999999999985, -99.7000000000005, 59.90000000000031, 78.1999999999999, 60.10000000000008, 83.90000000000018, 38.700000000000124, 75.59999999999947, 124.39999999999921, 106.19999999999962, 52.500000000000185, -69.40000000000046, 64.50000000000023, 95.99999999999989, 103.19999999999945, -63.099999999999994, 68.8000000000001, 12.399999999999974, 88.80000000000007, 223.99999999999955, -90.70000000000024, 85.40000000000015, 11.600000000000078, 97.2999999999993, 68.70000000000012, -3.999999999999801, -25.499999999999964, 45.700000000000045, 62.299999999999955, 195.39999999999958, -143.40000000000018, 15.200000000000088, -204.10000000000045, 132.99999999999935, 66.89999999999937, 244.19999999999976, -67.00000000000034, 256.09999999999945, -5.500000000000018, -26.499999999999822, -17.299999999999976, 280.69999999999965, 13.200000000000243, 38.90000000000028, 34.90000000000021, -27.299999999999933, 25.19999999999997, 36.70000000000025, 43.100000000000094, -35.69999999999968], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-91.30000000000081, 89.00000000000003, 20.000000000000014, 10.399999999999968, -97.00000000000051, -53.50000000000002, -115.90000000000006, 23.60000000000007, 142.39999999999984, -208.30000000000032, 20.000000000000014, -21.099999999999902, 115.6999999999999, 74.89999999999982, -0.9999999999999846, 32.60000000000004, 13.699999999999964, -32.79999999999996, 23.000000000000096, -152.20000000000002, 14.299999999999967, -103.9000000000008, -370.9, 20.000000000000014, -22.599999999999845, 17.899999999999988, 7.100000000000118, -13.59999999999979, -91.30000000000081, -46.5999999999999, 47.90000000000004, 148.1, -5.1999999999999265, -182.80000000000027, -204.70000000000053, 3.1999999999999615, 103.09999999999997, 3.2000000000000064, 15.799999999999946, -13.599999999999868, 20.000000000000014, -57.70000000000042, 20.000000000000014, -213.7, 65.30000000000003, -4.8999999999998956, 67.10000000000004, 20.000000000000014, 20.000000000000014, -3.400000000000012, 5.299999999999965, -61.90000000000071, 54.20000000000023, -8.199999999999813, 8.89999999999997, 20.000000000000014, 69.49999999999977, 26.300000000000125, 29.300000000000175, 41.00000000000017, 11.000000000000016, -83.50000000000082, -9.999999999999824, 9.499999999999964, -32.20000000000003, 20.000000000000014, 3.1999999999999615, -32.800000000000125, -93.40000000000047, 52.70000000000004, 33.50000000000006, 11.299999999999962, -98.80000000000024, -70.30000000000062, -220.30000000000052, 80.59999999999982, 23.900000000000077, -3.099999999999958, -82.50000000000026, -187.9000000000004, -75.10000000000048, -0.9999999999999846, 13.399999999999958, -61.900000000000766, -29.79999999999994, 29.300000000000004, 6.500000000000057, -9.39999999999985, -0.9999999999999881, 28.100000000000023, -22.29999999999979, 48.50000000000011, 20.000000000000014, -76.59999999999985, 14.300000000000026, 52.40000000000003, 0.4999999999999777, 34.99999999999996, -35.19999999999985, 37.70000000000002, -147.40000000000026, -54.39999999999989, -105.10000000000034, -175.60000000000028, -59.20000000000067, 28.100000000000158, -66.10000000000039, 35.30000000000017, 66.19999999999999, -144.10000000000022, 90.1999999999999, -212.30000000000055, -0.09999999999980247, -17.199999999999775, 64.99999999999999, -54.40000000000009, -24.69999999999999, 103.0999999999996, 94.09999999999985, -19.899999999999743, 20.000000000000014, -26.49999999999983, -127.60000000000034, -62.80000000000005, -234.20000000000047, 94.69999999999972, 27.800000000000026, -11.799999999999894, 30.20000000000006, 20.000000000000014, -97.30000000000011, -149.80000000000015, 29.60000000000006, -47.79999999999987, 73.10000000000008, -412.70000000000005, -203.00000000000014, 102.80000000000007, 93.79999999999978, 126.19999999999982, -315.1999999999999, 24.499999999999993, 25.70000000000009, 19.69999999999999, -4.599999999999966, -164.8000000000004, 43.099999999999945, -56.799999999999926, 77.90000000000003, -131.20000000000016, -21.999999999999915, -69.99999999999983, -80.50000000000001, -57.999999999999936, -121.00000000000037, 31.699999999999996, -90.10000000000005, 7.400000000000048, -34.90000000000069, 161.29999999999987, -295.0, -105.39999999999995, -61.899999999999885, -73.9, -228.70000000000022, -219.40000000000023, 109.99999999999991, 20.000000000000014, -16.299999999999905, -5.799999999999981, 92.9, 131.3, -77.50000000000011, -179.50000000000028, 143.29999999999976, 81.79999999999995, 20.000000000000014, -104.50000000000023, 20.000000000000014, -179.50000000000006, -100.9, -51.39999999999997, 111.49999999999972, 162.2, -0.9999999999999846, -47.800000000000296, 17.899999999999988, 20.000000000000014, 20.000000000000014, -51.09999999999988, -143.80000000000004, -74.50000000000088, -41.80000000000004, -31.000000000000014, 13.699999999999964, 20.000000000000014, -12.40000000000001, -50.49999999999994, 5.299999999999967, -208.00000000000023], "policy_predator_policy_reward": [6.0, 52.0, 8.0, 3.0, 52.0, 55.0, 0.0, 102.0, 85.0, 62.0, 28.0, 48.0, 28.0, 20.0, 7.0, 28.0, 56.0, 6.0, 133.0, 8.0, 59.0, 13.0, 82.0, 166.0, 7.0, 34.0, 20.0, 31.0, 60.0, 55.0, 26.0, 33.0, 104.0, 77.0, 8.0, 106.0, 5.0, 11.0, 2.0, 18.0, 0.0, 40.0, 12.0, 132.0, 18.0, 21.0, 22.0, 32.0, 10.0, 20.0, 39.0, 7.0, 25.0, 0.0, 8.0, 6.0, 4.0, 5.0, 1.0, 8.0, 47.0, 55.0, 12.0, 24.0, 50.0, 51.0, 29.0, 57.0, 65.0, 22.0, 39.0, 8.0, 6.0, 91.0, 130.0, 63.0, 5.0, 11.0, 105.0, 26.0, 65.0, 10.0, 39.0, 7.0, 39.0, 44.0, 36.0, 37.0, 10.0, 48.0, 20.0, 26.0, 30.0, 30.0, 51.0, 41.0, 16.0, 18.0, 37.0, 28.0, 85.0, 125.0, 93.0, 88.0, 54.0, 37.0, 55.0, 54.0, 106.0, 32.0, 95.0, 111.0, 38.0, 18.0, 49.0, 16.0, 41.0, 5.0, 19.0, 13.0, 36.0, 23.0, 96.0, 25.0, 133.0, 71.0, 29.0, 51.0, 25.0, 28.0, 108.0, 76.0, 26.0, 61.0, 212.0, 140.0, 80.0, 109.0, 3.0, 1.0, 170.0, 30.0, 19.0, 21.0, 109.0, 72.0, 31.0, 80.0, 20.0, 102.0, 35.0, 53.0, 60.0, 53.0, 71.0, 64.0, 69.0, 76.0, 30.0, 39.0, 149.0, 108.0, 74.0, 77.0, 102.0, 142.0, 0.0, 3.0, 56.0, 33.0, 1.0, 19.0, 85.0, 105.0, 7.0, 24.0, 0.0, 79.0, 12.0, 121.0, 74.0, 61.0, 0.0, 7.0, 10.0, 52.0, 1.0, 0.0, 60.0, 6.0, 100.0, 91.0, 77.0, 21.0, 3.0, 0.0, 44.0, 62.0, 97.0, 70.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6776095676672462, "mean_inference_ms": 2.1014354425632296, "mean_action_processing_ms": 0.27305809123094565, "mean_env_wait_ms": 0.2294108521675762, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0038979053497314453, "StateBufferConnector_ms": 0.00331723690032959, "ViewRequirementAgentConnector_ms": 0.11948692798614502}, "num_episodes": 22, "episode_return_max": 280.69999999999965, "episode_return_min": -204.10000000000045, "episode_return_mean": 44.01699999999991, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 288000, "num_agent_steps_trained": 288000, "num_env_steps_sampled": 72000, "num_env_steps_trained": 72000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 336.0113152461554, "num_env_steps_trained_throughput_per_sec": 336.0113152461554, "timesteps_total": 72000, "num_env_steps_sampled_lifetime": 72000, "num_agent_steps_sampled_lifetime": 288000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 288000, "timers": {"training_iteration_time_ms": 156373.515, "restore_workers_time_ms": 0.012, "training_step_time_ms": 156373.471, "sample_time_ms": 1521.787, "learn_time_ms": 154832.952, "learn_throughput": 25.834, "synch_weights_time_ms": 16.107}, "counters": {"num_env_steps_sampled": 72000, "num_env_steps_trained": 72000, "num_agent_steps_sampled": 288000, "num_agent_steps_trained": 288000}, "done": false, "training_iteration": 18, "trial_id": "3dae5_00000", "date": "2024-08-14_09-10-10", "timestamp": 1723641010, "time_this_iter_s": 11.935606956481934, "time_total_s": 1830.9132297039032, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0f81670>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1830.9132297039032, "iterations_since_restore": 18, "perf": {"cpu_util_percent": 34.64705882352941, "ram_util_percent": 83.71764705882354}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9963156564525826, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.8026751059073, "policy_loss": -0.010515623263738774, "vf_loss": 8.810674810914135, "vf_explained_var": 0.004604104744694221, "kl": 0.016772684827062394, "entropy": 1.3077337232216326, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 34965.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7527929863917133, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.488691034266557, "policy_loss": -0.007118168757568119, "vf_loss": 8.491900881509933, "vf_explained_var": -0.04416448227942936, "kl": 0.019541665539150644, "entropy": 1.5460698057734776, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 34965.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 76000, "num_env_steps_trained": 76000, "num_agent_steps_sampled": 304000, "num_agent_steps_trained": 304000}, "env_runners": {"episode_reward_max": 280.69999999999965, "episode_reward_min": -255.20000000000016, "episode_reward_mean": 14.419999999999895, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -412.70000000000005, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 162.2, "predator_policy": 212.0}, "policy_reward_mean": {"prey_policy": -51.40500000000008, "predator_policy": 58.615}, "custom_metrics": {}, "hist_stats": {"episode_reward": [141.09999999999948, 46.60000000000028, -10.599999999999602, 71.00000000000031, 42.90000000000024, 104.7999999999993, 79.2999999999993, 29.500000000000234, 35.50000000000008, 88.79999999999937, 56.400000000000105, 46.30000000000012, 91.79999999999984, -72.10000000000082, 53.30000000000018, 36.80000000000025, -139.40000000000083, -1.0999999999999028, -2.49999999999962, 82.50000000000006, 70.10000000000021, 85.10000000000005, 72.19999999999972, 3.40000000000007, 158.69999999999956, 69.50000000000031, 67.49999999999986, 8.199999999999985, -99.7000000000005, 59.90000000000031, 78.1999999999999, 60.10000000000008, 83.90000000000018, 38.700000000000124, 75.59999999999947, 124.39999999999921, 106.19999999999962, 52.500000000000185, -69.40000000000046, 64.50000000000023, 95.99999999999989, 103.19999999999945, -63.099999999999994, 68.8000000000001, 12.399999999999974, 88.80000000000007, 223.99999999999955, -90.70000000000024, 85.40000000000015, 11.600000000000078, 97.2999999999993, 68.70000000000012, -3.999999999999801, -25.499999999999964, 45.700000000000045, 62.299999999999955, 195.39999999999958, -143.40000000000018, 15.200000000000088, -204.10000000000045, 132.99999999999935, 66.89999999999937, 244.19999999999976, -67.00000000000034, 256.09999999999945, -5.500000000000018, -26.499999999999822, -17.299999999999976, 280.69999999999965, 13.200000000000243, 38.90000000000028, 34.90000000000021, -27.299999999999933, 25.19999999999997, 36.70000000000025, 43.100000000000094, -35.69999999999968, -255.20000000000016, -123.30000000000058, -58.199999999999754, -111.00000000000077, -52.49999999999985, -189.20000000000053, -93.6, -138.90000000000032, -91.00000000000037, -153.5000000000007, -81.7000000000005, 29.800000000000143, -125.40000000000033, -131.10000000000025, -49.79999999999972, -57.79999999999968, 22.40000000000004, 26.000000000000078, -48.99999999999971, -78.79999999999988, -137.50000000000034, -193.90000000000038, 7.1000000000000405], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [67.10000000000004, 20.000000000000014, 20.000000000000014, -3.400000000000012, 5.299999999999965, -61.90000000000071, 54.20000000000023, -8.199999999999813, 8.89999999999997, 20.000000000000014, 69.49999999999977, 26.300000000000125, 29.300000000000175, 41.00000000000017, 11.000000000000016, -83.50000000000082, -9.999999999999824, 9.499999999999964, -32.20000000000003, 20.000000000000014, 3.1999999999999615, -32.800000000000125, -93.40000000000047, 52.70000000000004, 33.50000000000006, 11.299999999999962, -98.80000000000024, -70.30000000000062, -220.30000000000052, 80.59999999999982, 23.900000000000077, -3.099999999999958, -82.50000000000026, -187.9000000000004, -75.10000000000048, -0.9999999999999846, 13.399999999999958, -61.900000000000766, -29.79999999999994, 29.300000000000004, 6.500000000000057, -9.39999999999985, -0.9999999999999881, 28.100000000000023, -22.29999999999979, 48.50000000000011, 20.000000000000014, -76.59999999999985, 14.300000000000026, 52.40000000000003, 0.4999999999999777, 34.99999999999996, -35.19999999999985, 37.70000000000002, -147.40000000000026, -54.39999999999989, -105.10000000000034, -175.60000000000028, -59.20000000000067, 28.100000000000158, -66.10000000000039, 35.30000000000017, 66.19999999999999, -144.10000000000022, 90.1999999999999, -212.30000000000055, -0.09999999999980247, -17.199999999999775, 64.99999999999999, -54.40000000000009, -24.69999999999999, 103.0999999999996, 94.09999999999985, -19.899999999999743, 20.000000000000014, -26.49999999999983, -127.60000000000034, -62.80000000000005, -234.20000000000047, 94.69999999999972, 27.800000000000026, -11.799999999999894, 30.20000000000006, 20.000000000000014, -97.30000000000011, -149.80000000000015, 29.60000000000006, -47.79999999999987, 73.10000000000008, -412.70000000000005, -203.00000000000014, 102.80000000000007, 93.79999999999978, 126.19999999999982, -315.1999999999999, 24.499999999999993, 25.70000000000009, 19.69999999999999, -4.599999999999966, -164.8000000000004, 43.099999999999945, -56.799999999999926, 77.90000000000003, -131.20000000000016, -21.999999999999915, -69.99999999999983, -80.50000000000001, -57.999999999999936, -121.00000000000037, 31.699999999999996, -90.10000000000005, 7.400000000000048, -34.90000000000069, 161.29999999999987, -295.0, -105.39999999999995, -61.899999999999885, -73.9, -228.70000000000022, -219.40000000000023, 109.99999999999991, 20.000000000000014, -16.299999999999905, -5.799999999999981, 92.9, 131.3, -77.50000000000011, -179.50000000000028, 143.29999999999976, 81.79999999999995, 20.000000000000014, -104.50000000000023, 20.000000000000014, -179.50000000000006, -100.9, -51.39999999999997, 111.49999999999972, 162.2, -0.9999999999999846, -47.800000000000296, 17.899999999999988, 20.000000000000014, 20.000000000000014, -51.09999999999988, -143.80000000000004, -74.50000000000088, -41.80000000000004, -31.000000000000014, 13.699999999999964, 20.000000000000014, -12.40000000000001, -50.49999999999994, 5.299999999999967, -208.00000000000023, -279.7, -242.50000000000017, -110.50000000000017, -209.80000000000047, -40.29999999999987, -214.9000000000002, -262.00000000000034, -16.000000000000032, -164.20000000000022, -85.30000000000007, -218.50000000000037, -156.70000000000013, -132.70000000000002, -181.90000000000035, -121.90000000000012, -264.9999999999999, 20.000000000000014, -322.0, -242.50000000000026, -154.00000000000045, -59.80000000000004, -244.90000000000015, 20.000000000000014, -5.1999999999999265, -250.30000000000032, -114.10000000000021, -156.70000000000024, -222.40000000000018, 20.000000000000014, -290.80000000000007, -148.30000000000044, -11.499999999999819, -55.599999999999895, 20.000000000000014, -49.89999999999997, -42.1000000000001, -196.00000000000037, -0.9999999999999846, -66.70000000000002, -195.10000000000014, -153.40000000000015, -189.10000000000036, -266.20000000000016, -159.7, -176.80000000000013, 5.900000000000013], "policy_predator_policy_reward": [22.0, 32.0, 10.0, 20.0, 39.0, 7.0, 25.0, 0.0, 8.0, 6.0, 4.0, 5.0, 1.0, 8.0, 47.0, 55.0, 12.0, 24.0, 50.0, 51.0, 29.0, 57.0, 65.0, 22.0, 39.0, 8.0, 6.0, 91.0, 130.0, 63.0, 5.0, 11.0, 105.0, 26.0, 65.0, 10.0, 39.0, 7.0, 39.0, 44.0, 36.0, 37.0, 10.0, 48.0, 20.0, 26.0, 30.0, 30.0, 51.0, 41.0, 16.0, 18.0, 37.0, 28.0, 85.0, 125.0, 93.0, 88.0, 54.0, 37.0, 55.0, 54.0, 106.0, 32.0, 95.0, 111.0, 38.0, 18.0, 49.0, 16.0, 41.0, 5.0, 19.0, 13.0, 36.0, 23.0, 96.0, 25.0, 133.0, 71.0, 29.0, 51.0, 25.0, 28.0, 108.0, 76.0, 26.0, 61.0, 212.0, 140.0, 80.0, 109.0, 3.0, 1.0, 170.0, 30.0, 19.0, 21.0, 109.0, 72.0, 31.0, 80.0, 20.0, 102.0, 35.0, 53.0, 60.0, 53.0, 71.0, 64.0, 69.0, 76.0, 30.0, 39.0, 149.0, 108.0, 74.0, 77.0, 102.0, 142.0, 0.0, 3.0, 56.0, 33.0, 1.0, 19.0, 85.0, 105.0, 7.0, 24.0, 0.0, 79.0, 12.0, 121.0, 74.0, 61.0, 0.0, 7.0, 10.0, 52.0, 1.0, 0.0, 60.0, 6.0, 100.0, 91.0, 77.0, 21.0, 3.0, 0.0, 44.0, 62.0, 97.0, 70.0, 136.0, 131.0, 99.0, 98.0, 107.0, 90.0, 97.0, 70.0, 104.0, 93.0, 59.0, 127.0, 103.0, 118.0, 115.0, 133.0, 51.0, 160.0, 151.0, 92.0, 121.0, 102.0, 12.0, 3.0, 124.0, 115.0, 123.0, 125.0, 114.0, 107.0, 15.0, 87.0, 24.0, 34.0, 17.0, 101.0, 103.0, 45.0, 98.0, 85.0, 85.0, 120.0, 105.0, 127.0, 83.0, 95.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6788126943818698, "mean_inference_ms": 2.100387034628854, "mean_action_processing_ms": 0.27240715091808754, "mean_env_wait_ms": 0.22871667261363393, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004386186599731445, "StateBufferConnector_ms": 0.003703474998474121, "ViewRequirementAgentConnector_ms": 0.14621925354003906}, "num_episodes": 23, "episode_return_max": 280.69999999999965, "episode_return_min": -255.20000000000016, "episode_return_mean": 14.419999999999895, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 304000, "num_agent_steps_trained": 304000, "num_env_steps_sampled": 76000, "num_env_steps_trained": 76000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 350.8094273911201, "num_env_steps_trained_throughput_per_sec": 350.8094273911201, "timesteps_total": 76000, "num_env_steps_sampled_lifetime": 76000, "num_agent_steps_sampled_lifetime": 304000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 304000, "timers": {"training_iteration_time_ms": 156415.393, "restore_workers_time_ms": 0.012, "training_step_time_ms": 156415.341, "sample_time_ms": 1536.022, "learn_time_ms": 154859.667, "learn_throughput": 25.83, "synch_weights_time_ms": 16.848}, "counters": {"num_env_steps_sampled": 76000, "num_env_steps_trained": 76000, "num_agent_steps_sampled": 304000, "num_agent_steps_trained": 304000}, "done": false, "training_iteration": 19, "trial_id": "3dae5_00000", "date": "2024-08-14_09-10-21", "timestamp": 1723641021, "time_this_iter_s": 11.43998908996582, "time_total_s": 1842.353218793869, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0fd7e50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1842.353218793869, "iterations_since_restore": 19, "perf": {"cpu_util_percent": 32.64375, "ram_util_percent": 83.44375}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.5444578982850232, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.005651007758247, "policy_loss": -0.006411744051529144, "vf_loss": 7.010461787824277, "vf_explained_var": -0.01095581710653961, "kl": 0.010673170057632813, "entropy": 1.2460427143586377, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 36855.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9150507723055188, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.0516936218927775, "policy_loss": -0.015464297023222402, "vf_loss": 5.063204920607269, "vf_explained_var": -0.00982098620404642, "kl": 0.019765006324599887, "entropy": 1.5409241699667835, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 36855.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 80000, "num_env_steps_trained": 80000, "num_agent_steps_sampled": 320000, "num_agent_steps_trained": 320000}, "env_runners": {"episode_reward_max": 280.69999999999965, "episode_reward_min": -255.20000000000016, "episode_reward_mean": 4.131999999999931, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -412.70000000000005, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 162.2, "predator_policy": 212.0}, "policy_reward_mean": {"prey_policy": -60.929000000000094, "predator_policy": 62.995}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-2.49999999999962, 82.50000000000006, 70.10000000000021, 85.10000000000005, 72.19999999999972, 3.40000000000007, 158.69999999999956, 69.50000000000031, 67.49999999999986, 8.199999999999985, -99.7000000000005, 59.90000000000031, 78.1999999999999, 60.10000000000008, 83.90000000000018, 38.700000000000124, 75.59999999999947, 124.39999999999921, 106.19999999999962, 52.500000000000185, -69.40000000000046, 64.50000000000023, 95.99999999999989, 103.19999999999945, -63.099999999999994, 68.8000000000001, 12.399999999999974, 88.80000000000007, 223.99999999999955, -90.70000000000024, 85.40000000000015, 11.600000000000078, 97.2999999999993, 68.70000000000012, -3.999999999999801, -25.499999999999964, 45.700000000000045, 62.299999999999955, 195.39999999999958, -143.40000000000018, 15.200000000000088, -204.10000000000045, 132.99999999999935, 66.89999999999937, 244.19999999999976, -67.00000000000034, 256.09999999999945, -5.500000000000018, -26.499999999999822, -17.299999999999976, 280.69999999999965, 13.200000000000243, 38.90000000000028, 34.90000000000021, -27.299999999999933, 25.19999999999997, 36.70000000000025, 43.100000000000094, -35.69999999999968, -255.20000000000016, -123.30000000000058, -58.199999999999754, -111.00000000000077, -52.49999999999985, -189.20000000000053, -93.6, -138.90000000000032, -91.00000000000037, -153.5000000000007, -81.7000000000005, 29.800000000000143, -125.40000000000033, -131.10000000000025, -49.79999999999972, -57.79999999999968, 22.40000000000004, 26.000000000000078, -48.99999999999971, -78.79999999999988, -137.50000000000034, -193.90000000000038, 7.1000000000000405, -34.099999999999596, -48.19999999999956, -48.39999999999967, 10.100000000000167, -52.4000000000006, 29.800000000000082, -21.59999999999971, 42.50000000000028, 5.400000000000091, -63.000000000000874, 10.699999999999978, -57.00000000000013, -57.19999999999982, -38.89999999999956, -20.699999999999932, 24.600000000000055, -17.89999999999958, 8.399999999999944], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [13.399999999999958, -61.900000000000766, -29.79999999999994, 29.300000000000004, 6.500000000000057, -9.39999999999985, -0.9999999999999881, 28.100000000000023, -22.29999999999979, 48.50000000000011, 20.000000000000014, -76.59999999999985, 14.300000000000026, 52.40000000000003, 0.4999999999999777, 34.99999999999996, -35.19999999999985, 37.70000000000002, -147.40000000000026, -54.39999999999989, -105.10000000000034, -175.60000000000028, -59.20000000000067, 28.100000000000158, -66.10000000000039, 35.30000000000017, 66.19999999999999, -144.10000000000022, 90.1999999999999, -212.30000000000055, -0.09999999999980247, -17.199999999999775, 64.99999999999999, -54.40000000000009, -24.69999999999999, 103.0999999999996, 94.09999999999985, -19.899999999999743, 20.000000000000014, -26.49999999999983, -127.60000000000034, -62.80000000000005, -234.20000000000047, 94.69999999999972, 27.800000000000026, -11.799999999999894, 30.20000000000006, 20.000000000000014, -97.30000000000011, -149.80000000000015, 29.60000000000006, -47.79999999999987, 73.10000000000008, -412.70000000000005, -203.00000000000014, 102.80000000000007, 93.79999999999978, 126.19999999999982, -315.1999999999999, 24.499999999999993, 25.70000000000009, 19.69999999999999, -4.599999999999966, -164.8000000000004, 43.099999999999945, -56.799999999999926, 77.90000000000003, -131.20000000000016, -21.999999999999915, -69.99999999999983, -80.50000000000001, -57.999999999999936, -121.00000000000037, 31.699999999999996, -90.10000000000005, 7.400000000000048, -34.90000000000069, 161.29999999999987, -295.0, -105.39999999999995, -61.899999999999885, -73.9, -228.70000000000022, -219.40000000000023, 109.99999999999991, 20.000000000000014, -16.299999999999905, -5.799999999999981, 92.9, 131.3, -77.50000000000011, -179.50000000000028, 143.29999999999976, 81.79999999999995, 20.000000000000014, -104.50000000000023, 20.000000000000014, -179.50000000000006, -100.9, -51.39999999999997, 111.49999999999972, 162.2, -0.9999999999999846, -47.800000000000296, 17.899999999999988, 20.000000000000014, 20.000000000000014, -51.09999999999988, -143.80000000000004, -74.50000000000088, -41.80000000000004, -31.000000000000014, 13.699999999999964, 20.000000000000014, -12.40000000000001, -50.49999999999994, 5.299999999999967, -208.00000000000023, -279.7, -242.50000000000017, -110.50000000000017, -209.80000000000047, -40.29999999999987, -214.9000000000002, -262.00000000000034, -16.000000000000032, -164.20000000000022, -85.30000000000007, -218.50000000000037, -156.70000000000013, -132.70000000000002, -181.90000000000035, -121.90000000000012, -264.9999999999999, 20.000000000000014, -322.0, -242.50000000000026, -154.00000000000045, -59.80000000000004, -244.90000000000015, 20.000000000000014, -5.1999999999999265, -250.30000000000032, -114.10000000000021, -156.70000000000024, -222.40000000000018, 20.000000000000014, -290.80000000000007, -148.30000000000044, -11.499999999999819, -55.599999999999895, 20.000000000000014, -49.89999999999997, -42.1000000000001, -196.00000000000037, -0.9999999999999846, -66.70000000000002, -195.10000000000014, -153.40000000000015, -189.10000000000036, -266.20000000000016, -159.7, -176.80000000000013, 5.900000000000013, 10.999999999999961, -171.10000000000056, -42.99999999999976, -107.2000000000003, -172.00000000000014, -30.399999999999757, 8.0000000000001, -190.90000000000032, -136.60000000000068, -62.80000000000072, -97.00000000000009, -11.19999999999992, -6.09999999999993, -125.50000000000011, 20.000000000000014, 21.500000000000043, 20.000000000000014, -70.60000000000088, -115.0000000000003, -85.00000000000082, -217.30000000000035, 53.00000000000021, -105.40000000000074, -43.59999999999977, -144.4000000000006, -59.79999999999982, -130.3000000000004, -13.599999999999783, -189.70000000000047, 20.000000000000014, -13.59999999999979, 15.200000000000063, -53.799999999999926, -39.09999999999979, -28.0, -67.60000000000082], "policy_predator_policy_reward": [39.0, 7.0, 39.0, 44.0, 36.0, 37.0, 10.0, 48.0, 20.0, 26.0, 30.0, 30.0, 51.0, 41.0, 16.0, 18.0, 37.0, 28.0, 85.0, 125.0, 93.0, 88.0, 54.0, 37.0, 55.0, 54.0, 106.0, 32.0, 95.0, 111.0, 38.0, 18.0, 49.0, 16.0, 41.0, 5.0, 19.0, 13.0, 36.0, 23.0, 96.0, 25.0, 133.0, 71.0, 29.0, 51.0, 25.0, 28.0, 108.0, 76.0, 26.0, 61.0, 212.0, 140.0, 80.0, 109.0, 3.0, 1.0, 170.0, 30.0, 19.0, 21.0, 109.0, 72.0, 31.0, 80.0, 20.0, 102.0, 35.0, 53.0, 60.0, 53.0, 71.0, 64.0, 69.0, 76.0, 30.0, 39.0, 149.0, 108.0, 74.0, 77.0, 102.0, 142.0, 0.0, 3.0, 56.0, 33.0, 1.0, 19.0, 85.0, 105.0, 7.0, 24.0, 0.0, 79.0, 12.0, 121.0, 74.0, 61.0, 0.0, 7.0, 10.0, 52.0, 1.0, 0.0, 60.0, 6.0, 100.0, 91.0, 77.0, 21.0, 3.0, 0.0, 44.0, 62.0, 97.0, 70.0, 136.0, 131.0, 99.0, 98.0, 107.0, 90.0, 97.0, 70.0, 104.0, 93.0, 59.0, 127.0, 103.0, 118.0, 115.0, 133.0, 51.0, 160.0, 151.0, 92.0, 121.0, 102.0, 12.0, 3.0, 124.0, 115.0, 123.0, 125.0, 114.0, 107.0, 15.0, 87.0, 24.0, 34.0, 17.0, 101.0, 103.0, 45.0, 98.0, 85.0, 85.0, 120.0, 105.0, 127.0, 83.0, 95.0, 50.0, 76.0, 52.0, 50.0, 82.0, 72.0, 96.0, 97.0, 67.0, 80.0, 72.0, 66.0, 55.0, 55.0, 1.0, 0.0, 25.0, 31.0, 65.0, 72.0, 80.0, 95.0, 63.0, 29.0, 89.0, 58.0, 67.0, 38.0, 93.0, 56.0, 3.0, 20.0, 48.0, 27.0, 43.0, 61.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.680241807948157, "mean_inference_ms": 2.1035625057772664, "mean_action_processing_ms": 0.27245378993180736, "mean_env_wait_ms": 0.22893747036567944, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005086541175842285, "StateBufferConnector_ms": 0.003808736801147461, "ViewRequirementAgentConnector_ms": 0.15102875232696533}, "num_episodes": 18, "episode_return_max": 280.69999999999965, "episode_return_min": -255.20000000000016, "episode_return_mean": 4.131999999999931, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 320000, "num_agent_steps_trained": 320000, "num_env_steps_sampled": 80000, "num_env_steps_trained": 80000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 327.675065674304, "num_env_steps_trained_throughput_per_sec": 327.675065674304, "timesteps_total": 80000, "num_env_steps_sampled_lifetime": 80000, "num_agent_steps_sampled_lifetime": 320000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 320000, "timers": {"training_iteration_time_ms": 156567.05, "restore_workers_time_ms": 0.013, "training_step_time_ms": 156566.987, "sample_time_ms": 1562.056, "learn_time_ms": 154984.625, "learn_throughput": 25.809, "synch_weights_time_ms": 17.309}, "counters": {"num_env_steps_sampled": 80000, "num_env_steps_trained": 80000, "num_agent_steps_sampled": 320000, "num_agent_steps_trained": 320000}, "done": false, "training_iteration": 20, "trial_id": "3dae5_00000", "date": "2024-08-14_09-10-33", "timestamp": 1723641033, "time_this_iter_s": 12.250006914138794, "time_total_s": 1854.6032257080078, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0f81670>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1854.6032257080078, "iterations_since_restore": 20, "perf": {"cpu_util_percent": 35.977777777777774, "ram_util_percent": 83.70555555555556}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.217244042858245, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.7025549024501174, "policy_loss": -0.005704028663230399, "vf_loss": 3.7073022612818964, "vf_explained_var": -0.023337279772632336, "kl": 0.00637783186406293, "entropy": 1.2179225967043923, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 38745.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.791187734121368, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.8520431100376067, "policy_loss": -0.004265007588559042, "vf_loss": 2.855318840975484, "vf_explained_var": -0.05068171093703578, "kl": 0.0049463645652977695, "entropy": 1.5373577992121379, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 38745.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 84000, "num_env_steps_trained": 84000, "num_agent_steps_sampled": 336000, "num_agent_steps_trained": 336000}, "env_runners": {"episode_reward_max": 280.69999999999965, "episode_reward_min": -255.20000000000016, "episode_reward_mean": -5.203000000000031, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -412.70000000000005, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 162.2, "predator_policy": 212.0}, "policy_reward_mean": {"prey_policy": -64.2465000000001, "predator_policy": 61.645}, "custom_metrics": {}, "hist_stats": {"episode_reward": [106.19999999999962, 52.500000000000185, -69.40000000000046, 64.50000000000023, 95.99999999999989, 103.19999999999945, -63.099999999999994, 68.8000000000001, 12.399999999999974, 88.80000000000007, 223.99999999999955, -90.70000000000024, 85.40000000000015, 11.600000000000078, 97.2999999999993, 68.70000000000012, -3.999999999999801, -25.499999999999964, 45.700000000000045, 62.299999999999955, 195.39999999999958, -143.40000000000018, 15.200000000000088, -204.10000000000045, 132.99999999999935, 66.89999999999937, 244.19999999999976, -67.00000000000034, 256.09999999999945, -5.500000000000018, -26.499999999999822, -17.299999999999976, 280.69999999999965, 13.200000000000243, 38.90000000000028, 34.90000000000021, -27.299999999999933, 25.19999999999997, 36.70000000000025, 43.100000000000094, -35.69999999999968, -255.20000000000016, -123.30000000000058, -58.199999999999754, -111.00000000000077, -52.49999999999985, -189.20000000000053, -93.6, -138.90000000000032, -91.00000000000037, -153.5000000000007, -81.7000000000005, 29.800000000000143, -125.40000000000033, -131.10000000000025, -49.79999999999972, -57.79999999999968, 22.40000000000004, 26.000000000000078, -48.99999999999971, -78.79999999999988, -137.50000000000034, -193.90000000000038, 7.1000000000000405, -34.099999999999596, -48.19999999999956, -48.39999999999967, 10.100000000000167, -52.4000000000006, 29.800000000000082, -21.59999999999971, 42.50000000000028, 5.400000000000091, -63.000000000000874, 10.699999999999978, -57.00000000000013, -57.19999999999982, -38.89999999999956, -20.699999999999932, 24.600000000000055, -17.89999999999958, 8.399999999999944, 16.59999999999993, 5.500000000000009, 47.50000000000007, 27.0000000000003, 23.300000000000146, 9.70000000000005, -198.69999999999936, 18.499999999999975, -4.599999999999815, -39.39999999999996, 32.30000000000013, 27.10000000000018, -8.999999999999686, 19.000000000000007, -3.099999999999766, 52.900000000000446, 40.69999999999998, 37.000000000000256], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [94.09999999999985, -19.899999999999743, 20.000000000000014, -26.49999999999983, -127.60000000000034, -62.80000000000005, -234.20000000000047, 94.69999999999972, 27.800000000000026, -11.799999999999894, 30.20000000000006, 20.000000000000014, -97.30000000000011, -149.80000000000015, 29.60000000000006, -47.79999999999987, 73.10000000000008, -412.70000000000005, -203.00000000000014, 102.80000000000007, 93.79999999999978, 126.19999999999982, -315.1999999999999, 24.499999999999993, 25.70000000000009, 19.69999999999999, -4.599999999999966, -164.8000000000004, 43.099999999999945, -56.799999999999926, 77.90000000000003, -131.20000000000016, -21.999999999999915, -69.99999999999983, -80.50000000000001, -57.999999999999936, -121.00000000000037, 31.699999999999996, -90.10000000000005, 7.400000000000048, -34.90000000000069, 161.29999999999987, -295.0, -105.39999999999995, -61.899999999999885, -73.9, -228.70000000000022, -219.40000000000023, 109.99999999999991, 20.000000000000014, -16.299999999999905, -5.799999999999981, 92.9, 131.3, -77.50000000000011, -179.50000000000028, 143.29999999999976, 81.79999999999995, 20.000000000000014, -104.50000000000023, 20.000000000000014, -179.50000000000006, -100.9, -51.39999999999997, 111.49999999999972, 162.2, -0.9999999999999846, -47.800000000000296, 17.899999999999988, 20.000000000000014, 20.000000000000014, -51.09999999999988, -143.80000000000004, -74.50000000000088, -41.80000000000004, -31.000000000000014, 13.699999999999964, 20.000000000000014, -12.40000000000001, -50.49999999999994, 5.299999999999967, -208.00000000000023, -279.7, -242.50000000000017, -110.50000000000017, -209.80000000000047, -40.29999999999987, -214.9000000000002, -262.00000000000034, -16.000000000000032, -164.20000000000022, -85.30000000000007, -218.50000000000037, -156.70000000000013, -132.70000000000002, -181.90000000000035, -121.90000000000012, -264.9999999999999, 20.000000000000014, -322.0, -242.50000000000026, -154.00000000000045, -59.80000000000004, -244.90000000000015, 20.000000000000014, -5.1999999999999265, -250.30000000000032, -114.10000000000021, -156.70000000000024, -222.40000000000018, 20.000000000000014, -290.80000000000007, -148.30000000000044, -11.499999999999819, -55.599999999999895, 20.000000000000014, -49.89999999999997, -42.1000000000001, -196.00000000000037, -0.9999999999999846, -66.70000000000002, -195.10000000000014, -153.40000000000015, -189.10000000000036, -266.20000000000016, -159.7, -176.80000000000013, 5.900000000000013, 10.999999999999961, -171.10000000000056, -42.99999999999976, -107.2000000000003, -172.00000000000014, -30.399999999999757, 8.0000000000001, -190.90000000000032, -136.60000000000068, -62.80000000000072, -97.00000000000009, -11.19999999999992, -6.09999999999993, -125.50000000000011, 20.000000000000014, 21.500000000000043, 20.000000000000014, -70.60000000000088, -115.0000000000003, -85.00000000000082, -217.30000000000035, 53.00000000000021, -105.40000000000074, -43.59999999999977, -144.4000000000006, -59.79999999999982, -130.3000000000004, -13.599999999999783, -189.70000000000047, 20.000000000000014, -13.59999999999979, 15.200000000000063, -53.799999999999926, -39.09999999999979, -28.0, -67.60000000000082, -75.7000000000005, 5.299999999999965, -51.0999999999998, -9.399999999999855, 41.00000000000001, -11.499999999999826, 32.600000000000186, -115.59999999999997, -101.2000000000007, 42.5000000000001, -30.39999999999975, -16.89999999999977, -184.30000000000035, -174.40000000000018, -48.999999999999815, -11.499999999999822, -47.199999999999804, -54.40000000000009, -45.09999999999976, -70.30000000000084, -92.80000000000007, 28.10000000000016, 11.899999999999997, -38.799999999999756, -137.5000000000007, -8.499999999999872, -18.999999999999876, -9.999999999999902, -114.40000000000077, 5.299999999999965, 13.699999999999958, 3.199999999999983, -57.70000000000014, 37.39999999999996, 20.000000000000014, -0.9999999999999846], "policy_predator_policy_reward": [19.0, 13.0, 36.0, 23.0, 96.0, 25.0, 133.0, 71.0, 29.0, 51.0, 25.0, 28.0, 108.0, 76.0, 26.0, 61.0, 212.0, 140.0, 80.0, 109.0, 3.0, 1.0, 170.0, 30.0, 19.0, 21.0, 109.0, 72.0, 31.0, 80.0, 20.0, 102.0, 35.0, 53.0, 60.0, 53.0, 71.0, 64.0, 69.0, 76.0, 30.0, 39.0, 149.0, 108.0, 74.0, 77.0, 102.0, 142.0, 0.0, 3.0, 56.0, 33.0, 1.0, 19.0, 85.0, 105.0, 7.0, 24.0, 0.0, 79.0, 12.0, 121.0, 74.0, 61.0, 0.0, 7.0, 10.0, 52.0, 1.0, 0.0, 60.0, 6.0, 100.0, 91.0, 77.0, 21.0, 3.0, 0.0, 44.0, 62.0, 97.0, 70.0, 136.0, 131.0, 99.0, 98.0, 107.0, 90.0, 97.0, 70.0, 104.0, 93.0, 59.0, 127.0, 103.0, 118.0, 115.0, 133.0, 51.0, 160.0, 151.0, 92.0, 121.0, 102.0, 12.0, 3.0, 124.0, 115.0, 123.0, 125.0, 114.0, 107.0, 15.0, 87.0, 24.0, 34.0, 17.0, 101.0, 103.0, 45.0, 98.0, 85.0, 85.0, 120.0, 105.0, 127.0, 83.0, 95.0, 50.0, 76.0, 52.0, 50.0, 82.0, 72.0, 96.0, 97.0, 67.0, 80.0, 72.0, 66.0, 55.0, 55.0, 1.0, 0.0, 25.0, 31.0, 65.0, 72.0, 80.0, 95.0, 63.0, 29.0, 89.0, 58.0, 67.0, 38.0, 93.0, 56.0, 3.0, 20.0, 48.0, 27.0, 43.0, 61.0, 37.0, 50.0, 35.0, 31.0, 14.0, 4.0, 61.0, 49.0, 22.0, 60.0, 22.0, 35.0, 160.0, 0.0, 38.0, 41.0, 50.0, 47.0, 33.0, 43.0, 39.0, 58.0, 15.0, 39.0, 66.0, 71.0, 28.0, 20.0, 62.0, 44.0, 18.0, 18.0, 11.0, 50.0, 8.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6816386370424664, "mean_inference_ms": 2.105423237910724, "mean_action_processing_ms": 0.2727627118831435, "mean_env_wait_ms": 0.2292168990645041, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006415843963623047, "StateBufferConnector_ms": 0.0046149492263793945, "ViewRequirementAgentConnector_ms": 0.15242326259613037}, "num_episodes": 18, "episode_return_max": 280.69999999999965, "episode_return_min": -255.20000000000016, "episode_return_mean": -5.203000000000031, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 336000, "num_agent_steps_trained": 336000, "num_env_steps_sampled": 84000, "num_env_steps_trained": 84000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 368.0401206608509, "num_env_steps_trained_throughput_per_sec": 368.0401206608509, "timesteps_total": 84000, "num_env_steps_sampled_lifetime": 84000, "num_agent_steps_sampled_lifetime": 336000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 336000, "timers": {"training_iteration_time_ms": 156553.193, "restore_workers_time_ms": 0.013, "training_step_time_ms": 156553.13, "sample_time_ms": 1586.549, "learn_time_ms": 154946.547, "learn_throughput": 25.815, "synch_weights_time_ms": 17.138}, "counters": {"num_env_steps_sampled": 84000, "num_env_steps_trained": 84000, "num_agent_steps_sampled": 336000, "num_agent_steps_trained": 336000}, "done": false, "training_iteration": 21, "trial_id": "3dae5_00000", "date": "2024-08-14_09-10-44", "timestamp": 1723641044, "time_this_iter_s": 10.874830961227417, "time_total_s": 1865.4780566692352, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b116f8b0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1865.4780566692352, "iterations_since_restore": 21, "perf": {"cpu_util_percent": 30.7, "ram_util_percent": 83.38000000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.846278959828079, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.5485610035992172, "policy_loss": -0.008426546523096188, "vf_loss": 2.5556146481049753, "vf_explained_var": -0.010855669823903886, "kl": 0.009152633476750209, "entropy": 1.1815168056538496, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 40635.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7432260264164556, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.254420648081593, "policy_loss": -0.007782843830704531, "vf_loss": 2.2604886625809644, "vf_explained_var": 0.013254226641680198, "kl": 0.01714826630861076, "entropy": 1.485565112002943, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 40635.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 88000, "num_env_steps_trained": 88000, "num_agent_steps_sampled": 352000, "num_agent_steps_trained": 352000}, "env_runners": {"episode_reward_max": 280.69999999999965, "episode_reward_min": -255.20000000000016, "episode_reward_mean": -10.97499999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -322.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 162.2, "predator_policy": 160.0}, "policy_reward_mean": {"prey_policy": -61.2025000000001, "predator_policy": 55.715}, "custom_metrics": {}, "hist_stats": {"episode_reward": [45.700000000000045, 62.299999999999955, 195.39999999999958, -143.40000000000018, 15.200000000000088, -204.10000000000045, 132.99999999999935, 66.89999999999937, 244.19999999999976, -67.00000000000034, 256.09999999999945, -5.500000000000018, -26.499999999999822, -17.299999999999976, 280.69999999999965, 13.200000000000243, 38.90000000000028, 34.90000000000021, -27.299999999999933, 25.19999999999997, 36.70000000000025, 43.100000000000094, -35.69999999999968, -255.20000000000016, -123.30000000000058, -58.199999999999754, -111.00000000000077, -52.49999999999985, -189.20000000000053, -93.6, -138.90000000000032, -91.00000000000037, -153.5000000000007, -81.7000000000005, 29.800000000000143, -125.40000000000033, -131.10000000000025, -49.79999999999972, -57.79999999999968, 22.40000000000004, 26.000000000000078, -48.99999999999971, -78.79999999999988, -137.50000000000034, -193.90000000000038, 7.1000000000000405, -34.099999999999596, -48.19999999999956, -48.39999999999967, 10.100000000000167, -52.4000000000006, 29.800000000000082, -21.59999999999971, 42.50000000000028, 5.400000000000091, -63.000000000000874, 10.699999999999978, -57.00000000000013, -57.19999999999982, -38.89999999999956, -20.699999999999932, 24.600000000000055, -17.89999999999958, 8.399999999999944, 16.59999999999993, 5.500000000000009, 47.50000000000007, 27.0000000000003, 23.300000000000146, 9.70000000000005, -198.69999999999936, 18.499999999999975, -4.599999999999815, -39.39999999999996, 32.30000000000013, 27.10000000000018, -8.999999999999686, 19.000000000000007, -3.099999999999766, 52.900000000000446, 40.69999999999998, 37.000000000000256, -15.49999999999958, 29.40000000000014, 31.200000000000166, -0.8999999999997572, -7.29999999999967, 25.00000000000005, 35.70000000000023, 6.900000000000022, -31.299999999999663, -10.699999999999623, 1.5000000000002147, 10.799999999999933, 16.299999999999937, 45.500000000000384, -27.499999999999588, 35.200000000000216, 74.39999999999966, 30.800000000000225], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-121.00000000000037, 31.699999999999996, -90.10000000000005, 7.400000000000048, -34.90000000000069, 161.29999999999987, -295.0, -105.39999999999995, -61.899999999999885, -73.9, -228.70000000000022, -219.40000000000023, 109.99999999999991, 20.000000000000014, -16.299999999999905, -5.799999999999981, 92.9, 131.3, -77.50000000000011, -179.50000000000028, 143.29999999999976, 81.79999999999995, 20.000000000000014, -104.50000000000023, 20.000000000000014, -179.50000000000006, -100.9, -51.39999999999997, 111.49999999999972, 162.2, -0.9999999999999846, -47.800000000000296, 17.899999999999988, 20.000000000000014, 20.000000000000014, -51.09999999999988, -143.80000000000004, -74.50000000000088, -41.80000000000004, -31.000000000000014, 13.699999999999964, 20.000000000000014, -12.40000000000001, -50.49999999999994, 5.299999999999967, -208.00000000000023, -279.7, -242.50000000000017, -110.50000000000017, -209.80000000000047, -40.29999999999987, -214.9000000000002, -262.00000000000034, -16.000000000000032, -164.20000000000022, -85.30000000000007, -218.50000000000037, -156.70000000000013, -132.70000000000002, -181.90000000000035, -121.90000000000012, -264.9999999999999, 20.000000000000014, -322.0, -242.50000000000026, -154.00000000000045, -59.80000000000004, -244.90000000000015, 20.000000000000014, -5.1999999999999265, -250.30000000000032, -114.10000000000021, -156.70000000000024, -222.40000000000018, 20.000000000000014, -290.80000000000007, -148.30000000000044, -11.499999999999819, -55.599999999999895, 20.000000000000014, -49.89999999999997, -42.1000000000001, -196.00000000000037, -0.9999999999999846, -66.70000000000002, -195.10000000000014, -153.40000000000015, -189.10000000000036, -266.20000000000016, -159.7, -176.80000000000013, 5.900000000000013, 10.999999999999961, -171.10000000000056, -42.99999999999976, -107.2000000000003, -172.00000000000014, -30.399999999999757, 8.0000000000001, -190.90000000000032, -136.60000000000068, -62.80000000000072, -97.00000000000009, -11.19999999999992, -6.09999999999993, -125.50000000000011, 20.000000000000014, 21.500000000000043, 20.000000000000014, -70.60000000000088, -115.0000000000003, -85.00000000000082, -217.30000000000035, 53.00000000000021, -105.40000000000074, -43.59999999999977, -144.4000000000006, -59.79999999999982, -130.3000000000004, -13.599999999999783, -189.70000000000047, 20.000000000000014, -13.59999999999979, 15.200000000000063, -53.799999999999926, -39.09999999999979, -28.0, -67.60000000000082, -75.7000000000005, 5.299999999999965, -51.0999999999998, -9.399999999999855, 41.00000000000001, -11.499999999999826, 32.600000000000186, -115.59999999999997, -101.2000000000007, 42.5000000000001, -30.39999999999975, -16.89999999999977, -184.30000000000035, -174.40000000000018, -48.999999999999815, -11.499999999999822, -47.199999999999804, -54.40000000000009, -45.09999999999976, -70.30000000000084, -92.80000000000007, 28.10000000000016, 11.899999999999997, -38.799999999999756, -137.5000000000007, -8.499999999999872, -18.999999999999876, -9.999999999999902, -114.40000000000077, 5.299999999999965, 13.699999999999958, 3.199999999999983, -57.70000000000014, 37.39999999999996, 20.000000000000014, -0.9999999999999846, -48.69999999999977, -38.799999999999756, 26.300000000000114, -19.899999999999743, 3.1999999999999615, 20.000000000000014, -11.499999999999819, -51.39999999999996, -65.20000000000087, -3.0999999999999615, 2.599999999999975, -7.60000000000003, 21.80000000000003, -3.099999999999958, -34.59999999999975, -32.49999999999985, -187.30000000000055, 47.000000000000156, -99.70000000000081, -0.9999999999999846, 11.599999999999964, -45.09999999999976, -125.20000000000067, 20.000000000000014, 15.799999999999963, -74.50000000000088, 29.60000000000018, -24.099999999999746, -84.10000000000053, -63.400000000000844, -38.19999999999976, 16.39999999999995, 54.80000000000019, 11.599999999999964, -3.3999999999999866, -2.8000000000000096], "policy_predator_policy_reward": [71.0, 64.0, 69.0, 76.0, 30.0, 39.0, 149.0, 108.0, 74.0, 77.0, 102.0, 142.0, 0.0, 3.0, 56.0, 33.0, 1.0, 19.0, 85.0, 105.0, 7.0, 24.0, 0.0, 79.0, 12.0, 121.0, 74.0, 61.0, 0.0, 7.0, 10.0, 52.0, 1.0, 0.0, 60.0, 6.0, 100.0, 91.0, 77.0, 21.0, 3.0, 0.0, 44.0, 62.0, 97.0, 70.0, 136.0, 131.0, 99.0, 98.0, 107.0, 90.0, 97.0, 70.0, 104.0, 93.0, 59.0, 127.0, 103.0, 118.0, 115.0, 133.0, 51.0, 160.0, 151.0, 92.0, 121.0, 102.0, 12.0, 3.0, 124.0, 115.0, 123.0, 125.0, 114.0, 107.0, 15.0, 87.0, 24.0, 34.0, 17.0, 101.0, 103.0, 45.0, 98.0, 85.0, 85.0, 120.0, 105.0, 127.0, 83.0, 95.0, 50.0, 76.0, 52.0, 50.0, 82.0, 72.0, 96.0, 97.0, 67.0, 80.0, 72.0, 66.0, 55.0, 55.0, 1.0, 0.0, 25.0, 31.0, 65.0, 72.0, 80.0, 95.0, 63.0, 29.0, 89.0, 58.0, 67.0, 38.0, 93.0, 56.0, 3.0, 20.0, 48.0, 27.0, 43.0, 61.0, 37.0, 50.0, 35.0, 31.0, 14.0, 4.0, 61.0, 49.0, 22.0, 60.0, 22.0, 35.0, 160.0, 0.0, 38.0, 41.0, 50.0, 47.0, 33.0, 43.0, 39.0, 58.0, 15.0, 39.0, 66.0, 71.0, 28.0, 20.0, 62.0, 44.0, 18.0, 18.0, 11.0, 50.0, 8.0, 10.0, 27.0, 45.0, 19.0, 4.0, 0.0, 8.0, 31.0, 31.0, 29.0, 32.0, 16.0, 14.0, 11.0, 6.0, 32.0, 42.0, 9.0, 100.0, 38.0, 52.0, 4.0, 31.0, 65.0, 51.0, 45.0, 30.0, 21.0, 19.0, 80.0, 40.0, 26.0, 31.0, 3.0, 5.0, 24.0, 13.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.680798730313579, "mean_inference_ms": 2.1029896898588656, "mean_action_processing_ms": 0.2724792014720794, "mean_env_wait_ms": 0.2289133188202542, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006412386894226074, "StateBufferConnector_ms": 0.004560112953186035, "ViewRequirementAgentConnector_ms": 0.13270771503448486}, "num_episodes": 18, "episode_return_max": 280.69999999999965, "episode_return_min": -255.20000000000016, "episode_return_mean": -10.97499999999998, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 352000, "num_agent_steps_trained": 352000, "num_env_steps_sampled": 88000, "num_env_steps_trained": 88000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 365.88723896085173, "num_env_steps_trained_throughput_per_sec": 365.88723896085173, "timesteps_total": 88000, "num_env_steps_sampled_lifetime": 88000, "num_agent_steps_sampled_lifetime": 352000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 352000, "timers": {"training_iteration_time_ms": 98107.252, "restore_workers_time_ms": 0.013, "training_step_time_ms": 98107.19, "sample_time_ms": 1598.809, "learn_time_ms": 96489.053, "learn_throughput": 41.455, "synch_weights_time_ms": 16.659}, "counters": {"num_env_steps_sampled": 88000, "num_env_steps_trained": 88000, "num_agent_steps_sampled": 352000, "num_agent_steps_trained": 352000}, "done": false, "training_iteration": 22, "trial_id": "3dae5_00000", "date": "2024-08-14_09-10-55", "timestamp": 1723641055, "time_this_iter_s": 10.936383962631226, "time_total_s": 1876.4144406318665, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b362c550>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1876.4144406318665, "iterations_since_restore": 22, "perf": {"cpu_util_percent": 29.75625, "ram_util_percent": 83.475}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6924010870633301, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.7936907413775327, "policy_loss": -0.0076076109920721995, "vf_loss": 1.8000510055867454, "vf_explained_var": 0.017802169146361173, "kl": 0.008315608678844903, "entropy": 1.174753337688547, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 42525.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.0954491119536143, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.318062824988491, "policy_loss": -0.004161567728419508, "vf_loss": 2.3213379308029456, "vf_explained_var": 0.015268017785259025, "kl": 0.008864581972990997, "entropy": 1.4845485909906013, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 42525.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 92000, "num_env_steps_trained": 92000, "num_agent_steps_sampled": 368000, "num_agent_steps_trained": 368000}, "env_runners": {"episode_reward_max": 105.19999999999877, "episode_reward_min": -198.69999999999936, "episode_reward_mean": -6.093999999999924, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -322.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 78.79999999999943, "predator_policy": 160.0}, "policy_reward_mean": {"prey_policy": -47.43700000000008, "predator_policy": 44.39}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-52.49999999999985, -189.20000000000053, -93.6, -138.90000000000032, -91.00000000000037, -153.5000000000007, -81.7000000000005, 29.800000000000143, -125.40000000000033, -131.10000000000025, -49.79999999999972, -57.79999999999968, 22.40000000000004, 26.000000000000078, -48.99999999999971, -78.79999999999988, -137.50000000000034, -193.90000000000038, 7.1000000000000405, -34.099999999999596, -48.19999999999956, -48.39999999999967, 10.100000000000167, -52.4000000000006, 29.800000000000082, -21.59999999999971, 42.50000000000028, 5.400000000000091, -63.000000000000874, 10.699999999999978, -57.00000000000013, -57.19999999999982, -38.89999999999956, -20.699999999999932, 24.600000000000055, -17.89999999999958, 8.399999999999944, 16.59999999999993, 5.500000000000009, 47.50000000000007, 27.0000000000003, 23.300000000000146, 9.70000000000005, -198.69999999999936, 18.499999999999975, -4.599999999999815, -39.39999999999996, 32.30000000000013, 27.10000000000018, -8.999999999999686, 19.000000000000007, -3.099999999999766, 52.900000000000446, 40.69999999999998, 37.000000000000256, -15.49999999999958, 29.40000000000014, 31.200000000000166, -0.8999999999997572, -7.29999999999967, 25.00000000000005, 35.70000000000023, 6.900000000000022, -31.299999999999663, -10.699999999999623, 1.5000000000002147, 10.799999999999933, 16.299999999999937, 45.500000000000384, -27.499999999999588, 35.200000000000216, 74.39999999999966, 30.800000000000225, 16.29999999999998, 26.800000000000086, 46.900000000000375, 21.299999999999994, 41.000000000000135, 27.300000000000104, 39.500000000000185, 20.2, 61.20000000000042, 62.20000000000041, 35.30000000000001, 24.800000000000264, 70.49999999999993, 105.19999999999877, 21.10000000000002, -26.999999999999517, 12.500000000000002, 30.100000000000147, -22.399999999999544, 32.30000000000018, 5.10000000000017, 69.39999999999984, 63.10000000000019, 68.30000000000004, -48.30000000000036, 37.80000000000022, 64.6000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-164.20000000000022, -85.30000000000007, -218.50000000000037, -156.70000000000013, -132.70000000000002, -181.90000000000035, -121.90000000000012, -264.9999999999999, 20.000000000000014, -322.0, -242.50000000000026, -154.00000000000045, -59.80000000000004, -244.90000000000015, 20.000000000000014, -5.1999999999999265, -250.30000000000032, -114.10000000000021, -156.70000000000024, -222.40000000000018, 20.000000000000014, -290.80000000000007, -148.30000000000044, -11.499999999999819, -55.599999999999895, 20.000000000000014, -49.89999999999997, -42.1000000000001, -196.00000000000037, -0.9999999999999846, -66.70000000000002, -195.10000000000014, -153.40000000000015, -189.10000000000036, -266.20000000000016, -159.7, -176.80000000000013, 5.900000000000013, 10.999999999999961, -171.10000000000056, -42.99999999999976, -107.2000000000003, -172.00000000000014, -30.399999999999757, 8.0000000000001, -190.90000000000032, -136.60000000000068, -62.80000000000072, -97.00000000000009, -11.19999999999992, -6.09999999999993, -125.50000000000011, 20.000000000000014, 21.500000000000043, 20.000000000000014, -70.60000000000088, -115.0000000000003, -85.00000000000082, -217.30000000000035, 53.00000000000021, -105.40000000000074, -43.59999999999977, -144.4000000000006, -59.79999999999982, -130.3000000000004, -13.599999999999783, -189.70000000000047, 20.000000000000014, -13.59999999999979, 15.200000000000063, -53.799999999999926, -39.09999999999979, -28.0, -67.60000000000082, -75.7000000000005, 5.299999999999965, -51.0999999999998, -9.399999999999855, 41.00000000000001, -11.499999999999826, 32.600000000000186, -115.59999999999997, -101.2000000000007, 42.5000000000001, -30.39999999999975, -16.89999999999977, -184.30000000000035, -174.40000000000018, -48.999999999999815, -11.499999999999822, -47.199999999999804, -54.40000000000009, -45.09999999999976, -70.30000000000084, -92.80000000000007, 28.10000000000016, 11.899999999999997, -38.799999999999756, -137.5000000000007, -8.499999999999872, -18.999999999999876, -9.999999999999902, -114.40000000000077, 5.299999999999965, 13.699999999999958, 3.199999999999983, -57.70000000000014, 37.39999999999996, 20.000000000000014, -0.9999999999999846, -48.69999999999977, -38.799999999999756, 26.300000000000114, -19.899999999999743, 3.1999999999999615, 20.000000000000014, -11.499999999999819, -51.39999999999996, -65.20000000000087, -3.0999999999999615, 2.599999999999975, -7.60000000000003, 21.80000000000003, -3.099999999999958, -34.59999999999975, -32.49999999999985, -187.30000000000055, 47.000000000000156, -99.70000000000081, -0.9999999999999846, 11.599999999999964, -45.09999999999976, -125.20000000000067, 20.000000000000014, 15.799999999999963, -74.50000000000088, 29.60000000000018, -24.099999999999746, -84.10000000000053, -63.400000000000844, -38.19999999999976, 16.39999999999995, 54.80000000000019, 11.599999999999964, -3.3999999999999866, -2.8000000000000096, 1.0999999999999865, -32.799999999999756, 3.1999999999999615, 11.599999999999964, 29.30000000000017, 11.599999999999964, 20.000000000000014, -15.699999999999747, 21.20000000000005, 6.800000000000036, 20.000000000000014, -15.699999999999747, 17.899999999999988, 2.599999999999985, 5.299999999999965, -3.099999999999958, -22.599999999999795, 30.80000000000001, 20.000000000000014, -11.799999999999917, 1.3999999999999673, -24.09999999999986, -13.599999999999783, 10.400000000000052, 56.00000000000023, -65.50000000000063, 7.399999999999965, 78.79999999999943, -3.0999999999999934, -38.79999999999977, -36.699999999999754, -46.29999999999976, -9.399999999999883, -3.099999999999958, 20.000000000000014, 1.0999999999999865, -98.20000000000077, 15.799999999999963, 15.799999999999963, 9.499999999999964, -11.499999999999819, -18.39999999999975, 49.700000000000095, 13.699999999999964, 20.000000000000014, 37.100000000000065, 4.6999999999999975, -9.399999999999855, -112.30000000000078, -42.99999999999978, 17.299999999999965, 9.499999999999964, 20.000000000000014, 5.6], "policy_predator_policy_reward": [104.0, 93.0, 59.0, 127.0, 103.0, 118.0, 115.0, 133.0, 51.0, 160.0, 151.0, 92.0, 121.0, 102.0, 12.0, 3.0, 124.0, 115.0, 123.0, 125.0, 114.0, 107.0, 15.0, 87.0, 24.0, 34.0, 17.0, 101.0, 103.0, 45.0, 98.0, 85.0, 85.0, 120.0, 105.0, 127.0, 83.0, 95.0, 50.0, 76.0, 52.0, 50.0, 82.0, 72.0, 96.0, 97.0, 67.0, 80.0, 72.0, 66.0, 55.0, 55.0, 1.0, 0.0, 25.0, 31.0, 65.0, 72.0, 80.0, 95.0, 63.0, 29.0, 89.0, 58.0, 67.0, 38.0, 93.0, 56.0, 3.0, 20.0, 48.0, 27.0, 43.0, 61.0, 37.0, 50.0, 35.0, 31.0, 14.0, 4.0, 61.0, 49.0, 22.0, 60.0, 22.0, 35.0, 160.0, 0.0, 38.0, 41.0, 50.0, 47.0, 33.0, 43.0, 39.0, 58.0, 15.0, 39.0, 66.0, 71.0, 28.0, 20.0, 62.0, 44.0, 18.0, 18.0, 11.0, 50.0, 8.0, 10.0, 27.0, 45.0, 19.0, 4.0, 0.0, 8.0, 31.0, 31.0, 29.0, 32.0, 16.0, 14.0, 11.0, 6.0, 32.0, 42.0, 9.0, 100.0, 38.0, 52.0, 4.0, 31.0, 65.0, 51.0, 45.0, 30.0, 21.0, 19.0, 80.0, 40.0, 26.0, 31.0, 3.0, 5.0, 24.0, 13.0, 23.0, 25.0, 8.0, 4.0, 2.0, 4.0, 16.0, 1.0, 2.0, 11.0, 6.0, 17.0, 15.0, 4.0, 11.0, 7.0, 28.0, 25.0, 27.0, 27.0, 29.0, 29.0, 16.0, 12.0, 35.0, 45.0, 12.0, 7.0, 33.0, 30.0, 16.0, 40.0, 25.0, 0.0, 0.0, 9.0, 21.0, 39.0, 2.0, 5.0, 18.0, 17.0, 3.0, 3.0, 6.0, 0.0, 45.0, 28.0, 67.0, 40.0, 5.0, 6.0, 13.0, 26.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6782172729243895, "mean_inference_ms": 2.0952155318517454, "mean_action_processing_ms": 0.27153387679999297, "mean_env_wait_ms": 0.2284203310651039, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006749510765075684, "StateBufferConnector_ms": 0.004638552665710449, "ViewRequirementAgentConnector_ms": 0.13557088375091553}, "num_episodes": 27, "episode_return_max": 105.19999999999877, "episode_return_min": -198.69999999999936, "episode_return_mean": -6.093999999999924, "episodes_this_iter": 27}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 368000, "num_agent_steps_trained": 368000, "num_env_steps_sampled": 92000, "num_env_steps_trained": 92000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 349.59332195125864, "num_env_steps_trained_throughput_per_sec": 349.59332195125864, "timesteps_total": 92000, "num_env_steps_sampled_lifetime": 92000, "num_agent_steps_sampled_lifetime": 368000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 368000, "timers": {"training_iteration_time_ms": 97962.662, "restore_workers_time_ms": 0.013, "training_step_time_ms": 97962.602, "sample_time_ms": 1540.71, "learn_time_ms": 96402.946, "learn_throughput": 41.493, "synch_weights_time_ms": 16.42}, "counters": {"num_env_steps_sampled": 92000, "num_env_steps_trained": 92000, "num_agent_steps_sampled": 368000, "num_agent_steps_trained": 368000}, "done": false, "training_iteration": 23, "trial_id": "3dae5_00000", "date": "2024-08-14_09-11-07", "timestamp": 1723641067, "time_this_iter_s": 11.48449182510376, "time_total_s": 1887.8989324569702, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0fbdca0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1887.8989324569702, "iterations_since_restore": 23, "perf": {"cpu_util_percent": 31.193749999999998, "ram_util_percent": 83.75625}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8437369027781108, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.7316782011556877, "policy_loss": -0.009143827618321493, "vf_loss": 2.739494146619524, "vf_explained_var": 0.04214793386913481, "kl": 0.008852535670790734, "entropy": 1.2228937082820468, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 44415.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8268760713950667, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.7832234211699673, "policy_loss": -0.005196561335053827, "vf_loss": 2.787079544735964, "vf_explained_var": -0.024623011438934892, "kl": 0.01340441514022703, "entropy": 1.45929518433475, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 44415.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 96000, "num_env_steps_trained": 96000, "num_agent_steps_sampled": 384000, "num_agent_steps_trained": 384000}, "env_runners": {"episode_reward_max": 105.19999999999877, "episode_reward_min": -198.69999999999936, "episode_reward_mean": 15.736000000000113, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -217.30000000000035, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 78.79999999999943, "predator_policy": 160.0}, "policy_reward_mean": {"prey_policy": -23.887000000000054, "predator_policy": 31.755}, "custom_metrics": {}, "hist_stats": {"episode_reward": [7.1000000000000405, -34.099999999999596, -48.19999999999956, -48.39999999999967, 10.100000000000167, -52.4000000000006, 29.800000000000082, -21.59999999999971, 42.50000000000028, 5.400000000000091, -63.000000000000874, 10.699999999999978, -57.00000000000013, -57.19999999999982, -38.89999999999956, -20.699999999999932, 24.600000000000055, -17.89999999999958, 8.399999999999944, 16.59999999999993, 5.500000000000009, 47.50000000000007, 27.0000000000003, 23.300000000000146, 9.70000000000005, -198.69999999999936, 18.499999999999975, -4.599999999999815, -39.39999999999996, 32.30000000000013, 27.10000000000018, -8.999999999999686, 19.000000000000007, -3.099999999999766, 52.900000000000446, 40.69999999999998, 37.000000000000256, -15.49999999999958, 29.40000000000014, 31.200000000000166, -0.8999999999997572, -7.29999999999967, 25.00000000000005, 35.70000000000023, 6.900000000000022, -31.299999999999663, -10.699999999999623, 1.5000000000002147, 10.799999999999933, 16.299999999999937, 45.500000000000384, -27.499999999999588, 35.200000000000216, 74.39999999999966, 30.800000000000225, 16.29999999999998, 26.800000000000086, 46.900000000000375, 21.299999999999994, 41.000000000000135, 27.300000000000104, 39.500000000000185, 20.2, 61.20000000000042, 62.20000000000041, 35.30000000000001, 24.800000000000264, 70.49999999999993, 105.19999999999877, 21.10000000000002, -26.999999999999517, 12.500000000000002, 30.100000000000147, -22.399999999999544, 32.30000000000018, 5.10000000000017, 69.39999999999984, 63.10000000000019, 68.30000000000004, -48.30000000000036, 37.80000000000022, 64.6000000000003, -19.499999999999687, 61.500000000000334, -4.599999999999715, 79.49999999999916, 48.50000000000038, 27.500000000000107, 34.50000000000022, 101.59999999999934, 17.899999999999945, 11.800000000000068, 34.50000000000022, 13.79999999999992, 30.800000000000193, 57.90000000000027, 64.10000000000014, 70.39999999999993, -1.7999999999997294, 9.100000000000007], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-176.80000000000013, 5.900000000000013, 10.999999999999961, -171.10000000000056, -42.99999999999976, -107.2000000000003, -172.00000000000014, -30.399999999999757, 8.0000000000001, -190.90000000000032, -136.60000000000068, -62.80000000000072, -97.00000000000009, -11.19999999999992, -6.09999999999993, -125.50000000000011, 20.000000000000014, 21.500000000000043, 20.000000000000014, -70.60000000000088, -115.0000000000003, -85.00000000000082, -217.30000000000035, 53.00000000000021, -105.40000000000074, -43.59999999999977, -144.4000000000006, -59.79999999999982, -130.3000000000004, -13.599999999999783, -189.70000000000047, 20.000000000000014, -13.59999999999979, 15.200000000000063, -53.799999999999926, -39.09999999999979, -28.0, -67.60000000000082, -75.7000000000005, 5.299999999999965, -51.0999999999998, -9.399999999999855, 41.00000000000001, -11.499999999999826, 32.600000000000186, -115.59999999999997, -101.2000000000007, 42.5000000000001, -30.39999999999975, -16.89999999999977, -184.30000000000035, -174.40000000000018, -48.999999999999815, -11.499999999999822, -47.199999999999804, -54.40000000000009, -45.09999999999976, -70.30000000000084, -92.80000000000007, 28.10000000000016, 11.899999999999997, -38.799999999999756, -137.5000000000007, -8.499999999999872, -18.999999999999876, -9.999999999999902, -114.40000000000077, 5.299999999999965, 13.699999999999958, 3.199999999999983, -57.70000000000014, 37.39999999999996, 20.000000000000014, -0.9999999999999846, -48.69999999999977, -38.799999999999756, 26.300000000000114, -19.899999999999743, 3.1999999999999615, 20.000000000000014, -11.499999999999819, -51.39999999999996, -65.20000000000087, -3.0999999999999615, 2.599999999999975, -7.60000000000003, 21.80000000000003, -3.099999999999958, -34.59999999999975, -32.49999999999985, -187.30000000000055, 47.000000000000156, -99.70000000000081, -0.9999999999999846, 11.599999999999964, -45.09999999999976, -125.20000000000067, 20.000000000000014, 15.799999999999963, -74.50000000000088, 29.60000000000018, -24.099999999999746, -84.10000000000053, -63.400000000000844, -38.19999999999976, 16.39999999999995, 54.80000000000019, 11.599999999999964, -3.3999999999999866, -2.8000000000000096, 1.0999999999999865, -32.799999999999756, 3.1999999999999615, 11.599999999999964, 29.30000000000017, 11.599999999999964, 20.000000000000014, -15.699999999999747, 21.20000000000005, 6.800000000000036, 20.000000000000014, -15.699999999999747, 17.899999999999988, 2.599999999999985, 5.299999999999965, -3.099999999999958, -22.599999999999795, 30.80000000000001, 20.000000000000014, -11.799999999999917, 1.3999999999999673, -24.09999999999986, -13.599999999999783, 10.400000000000052, 56.00000000000023, -65.50000000000063, 7.399999999999965, 78.79999999999943, -3.0999999999999934, -38.79999999999977, -36.699999999999754, -46.29999999999976, -9.399999999999883, -3.099999999999958, 20.000000000000014, 1.0999999999999865, -98.20000000000077, 15.799999999999963, 15.799999999999963, 9.499999999999964, -11.499999999999819, -18.39999999999975, 49.700000000000095, 13.699999999999964, 20.000000000000014, 37.100000000000065, 4.6999999999999975, -9.399999999999855, -112.30000000000078, -42.99999999999978, 17.299999999999965, 9.499999999999964, 20.000000000000014, 5.6, -26.1999999999999, -85.30000000000084, -38.19999999999976, 58.700000000000145, -55.00000000000027, 7.399999999999965, 38.30000000000019, -29.799999999999855, -49.599999999999824, 40.1000000000002, 3.1999999999999615, 8.29999999999997, 9.499999999999964, 20.000000000000014, 60.800000000000054, 6.799999999999981, 20.000000000000014, -51.09999999999999, -11.499999999999819, 5.299999999999967, 13.699999999999964, 15.799999999999963, -68.20000000000078, 20.000000000000014, -107.20000000000044, 20.000000000000014, -1.000000000000031, 17.9, 11.599999999999964, 33.50000000000019, 29.6000000000001, 21.80000000000004, -30.39999999999975, -9.399999999999919, -36.39999999999978, 3.499999999999969], "policy_predator_policy_reward": [83.0, 95.0, 50.0, 76.0, 52.0, 50.0, 82.0, 72.0, 96.0, 97.0, 67.0, 80.0, 72.0, 66.0, 55.0, 55.0, 1.0, 0.0, 25.0, 31.0, 65.0, 72.0, 80.0, 95.0, 63.0, 29.0, 89.0, 58.0, 67.0, 38.0, 93.0, 56.0, 3.0, 20.0, 48.0, 27.0, 43.0, 61.0, 37.0, 50.0, 35.0, 31.0, 14.0, 4.0, 61.0, 49.0, 22.0, 60.0, 22.0, 35.0, 160.0, 0.0, 38.0, 41.0, 50.0, 47.0, 33.0, 43.0, 39.0, 58.0, 15.0, 39.0, 66.0, 71.0, 28.0, 20.0, 62.0, 44.0, 18.0, 18.0, 11.0, 50.0, 8.0, 10.0, 27.0, 45.0, 19.0, 4.0, 0.0, 8.0, 31.0, 31.0, 29.0, 32.0, 16.0, 14.0, 11.0, 6.0, 32.0, 42.0, 9.0, 100.0, 38.0, 52.0, 4.0, 31.0, 65.0, 51.0, 45.0, 30.0, 21.0, 19.0, 80.0, 40.0, 26.0, 31.0, 3.0, 5.0, 24.0, 13.0, 23.0, 25.0, 8.0, 4.0, 2.0, 4.0, 16.0, 1.0, 2.0, 11.0, 6.0, 17.0, 15.0, 4.0, 11.0, 7.0, 28.0, 25.0, 27.0, 27.0, 29.0, 29.0, 16.0, 12.0, 35.0, 45.0, 12.0, 7.0, 33.0, 30.0, 16.0, 40.0, 25.0, 0.0, 0.0, 9.0, 21.0, 39.0, 2.0, 5.0, 18.0, 17.0, 3.0, 3.0, 6.0, 0.0, 45.0, 28.0, 67.0, 40.0, 5.0, 6.0, 13.0, 26.0, 33.0, 59.0, 35.0, 6.0, 33.0, 10.0, 35.0, 36.0, 9.0, 49.0, 10.0, 6.0, 1.0, 4.0, 15.0, 19.0, 29.0, 20.0, 15.0, 3.0, 3.0, 2.0, 44.0, 18.0, 65.0, 53.0, 23.0, 18.0, 15.0, 4.0, 6.0, 13.0, 24.0, 14.0, 32.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6769636464555893, "mean_inference_ms": 2.0911637581173927, "mean_action_processing_ms": 0.2712570399589342, "mean_env_wait_ms": 0.22784657878156786, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006734251976013184, "StateBufferConnector_ms": 0.004329323768615723, "ViewRequirementAgentConnector_ms": 0.11160814762115479}, "num_episodes": 18, "episode_return_max": 105.19999999999877, "episode_return_min": -198.69999999999936, "episode_return_mean": 15.736000000000113, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 384000, "num_agent_steps_trained": 384000, "num_env_steps_sampled": 96000, "num_env_steps_trained": 96000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 352.240113936463, "num_env_steps_trained_throughput_per_sec": 352.240113936463, "timesteps_total": 96000, "num_env_steps_sampled_lifetime": 96000, "num_agent_steps_sampled_lifetime": 384000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 384000, "timers": {"training_iteration_time_ms": 97894.734, "restore_workers_time_ms": 0.014, "training_step_time_ms": 97894.672, "sample_time_ms": 1501.49, "learn_time_ms": 96374.116, "learn_throughput": 41.505, "synch_weights_time_ms": 16.573}, "counters": {"num_env_steps_sampled": 96000, "num_env_steps_trained": 96000, "num_agent_steps_sampled": 384000, "num_agent_steps_trained": 384000}, "done": false, "training_iteration": 24, "trial_id": "3dae5_00000", "date": "2024-08-14_09-11-18", "timestamp": 1723641078, "time_this_iter_s": 11.362671136856079, "time_total_s": 1899.2616035938263, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0fbdd30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1899.2616035938263, "iterations_since_restore": 24, "perf": {"cpu_util_percent": 30.9125, "ram_util_percent": 83.50625}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6803318524486803, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.4165984399104246, "policy_loss": -0.00809167260550475, "vf_loss": 1.422722085096218, "vf_explained_var": 0.03058628859343352, "kl": 0.013120179801934341, "entropy": 1.2162005787804013, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 46305.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.111664909660501, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.102603945877186, "policy_loss": -0.004197056240416945, "vf_loss": 2.106120341858536, "vf_explained_var": -0.07038650295091053, "kl": 0.006806613385945894, "entropy": 1.4376225537723966, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 46305.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 100000, "num_env_steps_trained": 100000, "num_agent_steps_sampled": 400000, "num_agent_steps_trained": 400000}, "env_runners": {"episode_reward_max": 105.19999999999877, "episode_reward_min": -198.69999999999936, "episode_reward_mean": 26.9190000000001, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -187.30000000000055, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 78.79999999999943, "predator_policy": 160.0}, "policy_reward_mean": {"prey_policy": -11.180500000000016, "predator_policy": 24.64}, "custom_metrics": {}, "hist_stats": {"episode_reward": [8.399999999999944, 16.59999999999993, 5.500000000000009, 47.50000000000007, 27.0000000000003, 23.300000000000146, 9.70000000000005, -198.69999999999936, 18.499999999999975, -4.599999999999815, -39.39999999999996, 32.30000000000013, 27.10000000000018, -8.999999999999686, 19.000000000000007, -3.099999999999766, 52.900000000000446, 40.69999999999998, 37.000000000000256, -15.49999999999958, 29.40000000000014, 31.200000000000166, -0.8999999999997572, -7.29999999999967, 25.00000000000005, 35.70000000000023, 6.900000000000022, -31.299999999999663, -10.699999999999623, 1.5000000000002147, 10.799999999999933, 16.299999999999937, 45.500000000000384, -27.499999999999588, 35.200000000000216, 74.39999999999966, 30.800000000000225, 16.29999999999998, 26.800000000000086, 46.900000000000375, 21.299999999999994, 41.000000000000135, 27.300000000000104, 39.500000000000185, 20.2, 61.20000000000042, 62.20000000000041, 35.30000000000001, 24.800000000000264, 70.49999999999993, 105.19999999999877, 21.10000000000002, -26.999999999999517, 12.500000000000002, 30.100000000000147, -22.399999999999544, 32.30000000000018, 5.10000000000017, 69.39999999999984, 63.10000000000019, 68.30000000000004, -48.30000000000036, 37.80000000000022, 64.6000000000003, -19.499999999999687, 61.500000000000334, -4.599999999999715, 79.49999999999916, 48.50000000000038, 27.500000000000107, 34.50000000000022, 101.59999999999934, 17.899999999999945, 11.800000000000068, 34.50000000000022, 13.79999999999992, 30.800000000000193, 57.90000000000027, 64.10000000000014, 70.39999999999993, -1.7999999999997294, 9.100000000000007, 53.10000000000041, 60.40000000000048, 52.60000000000034, 16.799999999999986, 51.50000000000047, 2.1000000000002292, 78.89999999999928, 26.400000000000052, 47.30000000000008, 38.80000000000028, 46.30000000000017, 75.09999999999934, 92.99999999999841, 61.60000000000036, -13.299999999999606, 42.20000000000035, 1.8999999999997723, 54.400000000000475], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-28.0, -67.60000000000082, -75.7000000000005, 5.299999999999965, -51.0999999999998, -9.399999999999855, 41.00000000000001, -11.499999999999826, 32.600000000000186, -115.59999999999997, -101.2000000000007, 42.5000000000001, -30.39999999999975, -16.89999999999977, -184.30000000000035, -174.40000000000018, -48.999999999999815, -11.499999999999822, -47.199999999999804, -54.40000000000009, -45.09999999999976, -70.30000000000084, -92.80000000000007, 28.10000000000016, 11.899999999999997, -38.799999999999756, -137.5000000000007, -8.499999999999872, -18.999999999999876, -9.999999999999902, -114.40000000000077, 5.299999999999965, 13.699999999999958, 3.199999999999983, -57.70000000000014, 37.39999999999996, 20.000000000000014, -0.9999999999999846, -48.69999999999977, -38.799999999999756, 26.300000000000114, -19.899999999999743, 3.1999999999999615, 20.000000000000014, -11.499999999999819, -51.39999999999996, -65.20000000000087, -3.0999999999999615, 2.599999999999975, -7.60000000000003, 21.80000000000003, -3.099999999999958, -34.59999999999975, -32.49999999999985, -187.30000000000055, 47.000000000000156, -99.70000000000081, -0.9999999999999846, 11.599999999999964, -45.09999999999976, -125.20000000000067, 20.000000000000014, 15.799999999999963, -74.50000000000088, 29.60000000000018, -24.099999999999746, -84.10000000000053, -63.400000000000844, -38.19999999999976, 16.39999999999995, 54.80000000000019, 11.599999999999964, -3.3999999999999866, -2.8000000000000096, 1.0999999999999865, -32.799999999999756, 3.1999999999999615, 11.599999999999964, 29.30000000000017, 11.599999999999964, 20.000000000000014, -15.699999999999747, 21.20000000000005, 6.800000000000036, 20.000000000000014, -15.699999999999747, 17.899999999999988, 2.599999999999985, 5.299999999999965, -3.099999999999958, -22.599999999999795, 30.80000000000001, 20.000000000000014, -11.799999999999917, 1.3999999999999673, -24.09999999999986, -13.599999999999783, 10.400000000000052, 56.00000000000023, -65.50000000000063, 7.399999999999965, 78.79999999999943, -3.0999999999999934, -38.79999999999977, -36.699999999999754, -46.29999999999976, -9.399999999999883, -3.099999999999958, 20.000000000000014, 1.0999999999999865, -98.20000000000077, 15.799999999999963, 15.799999999999963, 9.499999999999964, -11.499999999999819, -18.39999999999975, 49.700000000000095, 13.699999999999964, 20.000000000000014, 37.100000000000065, 4.6999999999999975, -9.399999999999855, -112.30000000000078, -42.99999999999978, 17.299999999999965, 9.499999999999964, 20.000000000000014, 5.6, -26.1999999999999, -85.30000000000084, -38.19999999999976, 58.700000000000145, -55.00000000000027, 7.399999999999965, 38.30000000000019, -29.799999999999855, -49.599999999999824, 40.1000000000002, 3.1999999999999615, 8.29999999999997, 9.499999999999964, 20.000000000000014, 60.800000000000054, 6.799999999999981, 20.000000000000014, -51.09999999999999, -11.499999999999819, 5.299999999999967, 13.699999999999964, 15.799999999999963, -68.20000000000078, 20.000000000000014, -107.20000000000044, 20.000000000000014, -1.000000000000031, 17.9, 11.599999999999964, 33.50000000000019, 29.6000000000001, 21.80000000000004, -30.39999999999975, -9.399999999999919, -36.39999999999978, 3.499999999999969, -3.099999999999958, -5.80000000000001, -32.49999999999975, 47.90000000000023, -11.499999999999819, 46.10000000000023, 4.400000000000001, -13.599999999999783, -15.999999999999789, 9.499999999999964, -13.599999999999783, -7.299999999999891, 51.50000000000019, -28.599999999999838, 15.799999999999963, -3.3999999999999297, 13.699999999999964, 20.600000000000076, 15.799999999999963, 20.000000000000014, 35.60000000000017, -85.30000000000061, -6.999999999999934, 31.100000000000108, 35.900000000000205, 28.10000000000017, 19.400000000000006, 27.200000000000145, 8.900000000000015, -74.20000000000053, 29.900000000000187, 5.299999999999965, -25.299999999999834, -80.80000000000032, 29.6000000000002, 15.799999999999963], "policy_predator_policy_reward": [43.0, 61.0, 37.0, 50.0, 35.0, 31.0, 14.0, 4.0, 61.0, 49.0, 22.0, 60.0, 22.0, 35.0, 160.0, 0.0, 38.0, 41.0, 50.0, 47.0, 33.0, 43.0, 39.0, 58.0, 15.0, 39.0, 66.0, 71.0, 28.0, 20.0, 62.0, 44.0, 18.0, 18.0, 11.0, 50.0, 8.0, 10.0, 27.0, 45.0, 19.0, 4.0, 0.0, 8.0, 31.0, 31.0, 29.0, 32.0, 16.0, 14.0, 11.0, 6.0, 32.0, 42.0, 9.0, 100.0, 38.0, 52.0, 4.0, 31.0, 65.0, 51.0, 45.0, 30.0, 21.0, 19.0, 80.0, 40.0, 26.0, 31.0, 3.0, 5.0, 24.0, 13.0, 23.0, 25.0, 8.0, 4.0, 2.0, 4.0, 16.0, 1.0, 2.0, 11.0, 6.0, 17.0, 15.0, 4.0, 11.0, 7.0, 28.0, 25.0, 27.0, 27.0, 29.0, 29.0, 16.0, 12.0, 35.0, 45.0, 12.0, 7.0, 33.0, 30.0, 16.0, 40.0, 25.0, 0.0, 0.0, 9.0, 21.0, 39.0, 2.0, 5.0, 18.0, 17.0, 3.0, 3.0, 6.0, 0.0, 45.0, 28.0, 67.0, 40.0, 5.0, 6.0, 13.0, 26.0, 33.0, 59.0, 35.0, 6.0, 33.0, 10.0, 35.0, 36.0, 9.0, 49.0, 10.0, 6.0, 1.0, 4.0, 15.0, 19.0, 29.0, 20.0, 15.0, 3.0, 3.0, 2.0, 44.0, 18.0, 65.0, 53.0, 23.0, 18.0, 15.0, 4.0, 6.0, 13.0, 24.0, 14.0, 32.0, 10.0, 36.0, 26.0, 25.0, 20.0, 16.0, 2.0, 17.0, 9.0, 31.0, 27.0, 16.0, 7.0, 42.0, 14.0, 12.0, 2.0, 3.0, 10.0, 2.0, 1.0, 36.0, 60.0, 27.0, 24.0, 18.0, 11.0, 8.0, 7.0, 51.0, 1.0, 7.0, 0.0, 68.0, 40.0, 4.0, 5.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.675185281597671, "mean_inference_ms": 2.087524372138824, "mean_action_processing_ms": 0.27088178901808185, "mean_env_wait_ms": 0.22742670198274567, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006646156311035156, "StateBufferConnector_ms": 0.004281878471374512, "ViewRequirementAgentConnector_ms": 0.11112284660339355}, "num_episodes": 18, "episode_return_max": 105.19999999999877, "episode_return_min": -198.69999999999936, "episode_return_mean": 26.9190000000001, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 400000, "num_agent_steps_trained": 400000, "num_env_steps_sampled": 100000, "num_env_steps_trained": 100000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 360.761878335639, "num_env_steps_trained_throughput_per_sec": 360.761878335639, "timesteps_total": 100000, "num_env_steps_sampled_lifetime": 100000, "num_agent_steps_sampled_lifetime": 400000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 400000, "timers": {"training_iteration_time_ms": 97885.715, "restore_workers_time_ms": 0.014, "training_step_time_ms": 97885.652, "sample_time_ms": 1521.886, "learn_time_ms": 96344.915, "learn_throughput": 41.517, "synch_weights_time_ms": 16.333}, "counters": {"num_env_steps_sampled": 100000, "num_env_steps_trained": 100000, "num_agent_steps_sampled": 400000, "num_agent_steps_trained": 400000}, "done": false, "training_iteration": 25, "trial_id": "3dae5_00000", "date": "2024-08-14_09-11-29", "timestamp": 1723641089, "time_this_iter_s": 11.100091934204102, "time_total_s": 1910.3616955280304, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b36291f0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1910.3616955280304, "iterations_since_restore": 25, "perf": {"cpu_util_percent": 29.956249999999997, "ram_util_percent": 83.54374999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4994462318521329, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.071538641465404, "policy_loss": -0.008788500512117353, "vf_loss": 1.0787472395985216, "vf_explained_var": 0.023977123555682954, "kl": 0.01053268477158025, "entropy": 1.2352332130311028, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 48195.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.749951459096853, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.7995465756408753, "policy_loss": -0.006622720135883404, "vf_loss": 1.8056179697551424, "vf_explained_var": 0.05815064525478101, "kl": 0.005513224232709795, "entropy": 1.4321962653013764, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 48195.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 104000, "num_env_steps_trained": 104000, "num_agent_steps_sampled": 416000, "num_agent_steps_trained": 416000}, "env_runners": {"episode_reward_max": 132.2999999999988, "episode_reward_min": -48.30000000000036, "episode_reward_mean": 32.87200000000009, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -187.30000000000055, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 78.79999999999943, "predator_policy": 100.0}, "policy_reward_mean": {"prey_policy": -3.123999999999991, "predator_policy": 19.56}, "custom_metrics": {}, "hist_stats": {"episode_reward": [37.000000000000256, -15.49999999999958, 29.40000000000014, 31.200000000000166, -0.8999999999997572, -7.29999999999967, 25.00000000000005, 35.70000000000023, 6.900000000000022, -31.299999999999663, -10.699999999999623, 1.5000000000002147, 10.799999999999933, 16.299999999999937, 45.500000000000384, -27.499999999999588, 35.200000000000216, 74.39999999999966, 30.800000000000225, 16.29999999999998, 26.800000000000086, 46.900000000000375, 21.299999999999994, 41.000000000000135, 27.300000000000104, 39.500000000000185, 20.2, 61.20000000000042, 62.20000000000041, 35.30000000000001, 24.800000000000264, 70.49999999999993, 105.19999999999877, 21.10000000000002, -26.999999999999517, 12.500000000000002, 30.100000000000147, -22.399999999999544, 32.30000000000018, 5.10000000000017, 69.39999999999984, 63.10000000000019, 68.30000000000004, -48.30000000000036, 37.80000000000022, 64.6000000000003, -19.499999999999687, 61.500000000000334, -4.599999999999715, 79.49999999999916, 48.50000000000038, 27.500000000000107, 34.50000000000022, 101.59999999999934, 17.899999999999945, 11.800000000000068, 34.50000000000022, 13.79999999999992, 30.800000000000193, 57.90000000000027, 64.10000000000014, 70.39999999999993, -1.7999999999997294, 9.100000000000007, 53.10000000000041, 60.40000000000048, 52.60000000000034, 16.799999999999986, 51.50000000000047, 2.1000000000002292, 78.89999999999928, 26.400000000000052, 47.30000000000008, 38.80000000000028, 46.30000000000017, 75.09999999999934, 92.99999999999841, 61.60000000000036, -13.299999999999606, 42.20000000000035, 1.8999999999997723, 54.400000000000475, 37.00000000000017, 6.000000000000153, 18.60000000000002, 72.19999999999978, 28.4000000000002, 44.600000000000286, 52.50000000000041, 20.200000000000006, 75.19999999999959, 79.89999999999935, -16.899999999999608, 36.90000000000031, 4.700000000000186, 132.2999999999988, 30.100000000000147, 58.400000000000446, 17.999999999999996, -29.09999999999959], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, -0.9999999999999846, -48.69999999999977, -38.799999999999756, 26.300000000000114, -19.899999999999743, 3.1999999999999615, 20.000000000000014, -11.499999999999819, -51.39999999999996, -65.20000000000087, -3.0999999999999615, 2.599999999999975, -7.60000000000003, 21.80000000000003, -3.099999999999958, -34.59999999999975, -32.49999999999985, -187.30000000000055, 47.000000000000156, -99.70000000000081, -0.9999999999999846, 11.599999999999964, -45.09999999999976, -125.20000000000067, 20.000000000000014, 15.799999999999963, -74.50000000000088, 29.60000000000018, -24.099999999999746, -84.10000000000053, -63.400000000000844, -38.19999999999976, 16.39999999999995, 54.80000000000019, 11.599999999999964, -3.3999999999999866, -2.8000000000000096, 1.0999999999999865, -32.799999999999756, 3.1999999999999615, 11.599999999999964, 29.30000000000017, 11.599999999999964, 20.000000000000014, -15.699999999999747, 21.20000000000005, 6.800000000000036, 20.000000000000014, -15.699999999999747, 17.899999999999988, 2.599999999999985, 5.299999999999965, -3.099999999999958, -22.599999999999795, 30.80000000000001, 20.000000000000014, -11.799999999999917, 1.3999999999999673, -24.09999999999986, -13.599999999999783, 10.400000000000052, 56.00000000000023, -65.50000000000063, 7.399999999999965, 78.79999999999943, -3.0999999999999934, -38.79999999999977, -36.699999999999754, -46.29999999999976, -9.399999999999883, -3.099999999999958, 20.000000000000014, 1.0999999999999865, -98.20000000000077, 15.799999999999963, 15.799999999999963, 9.499999999999964, -11.499999999999819, -18.39999999999975, 49.700000000000095, 13.699999999999964, 20.000000000000014, 37.100000000000065, 4.6999999999999975, -9.399999999999855, -112.30000000000078, -42.99999999999978, 17.299999999999965, 9.499999999999964, 20.000000000000014, 5.6, -26.1999999999999, -85.30000000000084, -38.19999999999976, 58.700000000000145, -55.00000000000027, 7.399999999999965, 38.30000000000019, -29.799999999999855, -49.599999999999824, 40.1000000000002, 3.1999999999999615, 8.29999999999997, 9.499999999999964, 20.000000000000014, 60.800000000000054, 6.799999999999981, 20.000000000000014, -51.09999999999999, -11.499999999999819, 5.299999999999967, 13.699999999999964, 15.799999999999963, -68.20000000000078, 20.000000000000014, -107.20000000000044, 20.000000000000014, -1.000000000000031, 17.9, 11.599999999999964, 33.50000000000019, 29.6000000000001, 21.80000000000004, -30.39999999999975, -9.399999999999919, -36.39999999999978, 3.499999999999969, -3.099999999999958, -5.80000000000001, -32.49999999999975, 47.90000000000023, -11.499999999999819, 46.10000000000023, 4.400000000000001, -13.599999999999783, -15.999999999999789, 9.499999999999964, -13.599999999999783, -7.299999999999891, 51.50000000000019, -28.599999999999838, 15.799999999999963, -3.3999999999999297, 13.699999999999964, 20.600000000000076, 15.799999999999963, 20.000000000000014, 35.60000000000017, -85.30000000000061, -6.999999999999934, 31.100000000000108, 35.900000000000205, 28.10000000000017, 19.400000000000006, 27.200000000000145, 8.900000000000015, -74.20000000000053, 29.900000000000187, 5.299999999999965, -25.299999999999834, -80.80000000000032, 29.6000000000002, 15.799999999999963, 6.1999999999999655, 6.799999999999983, -5.1999999999999265, -32.799999999999756, -7.299999999999905, -18.09999999999979, -12.6999999999998, 56.900000000000155, -5.199999999999871, 11.599999999999964, 20.000000000000014, 2.6000000000000734, 20.000000000000014, 18.500000000000007, 1.0999999999999865, 1.0999999999999865, 48.20000000000017, 16.999999999999975, 39.50000000000025, 31.400000000000176, -18.999999999999787, -70.90000000000047, 0.4999999999999635, 16.399999999999967, -4.299999999999944, -18.99999999999975, 63.20000000000018, 67.09999999999994, 17.899999999999977, 3.1999999999999615, 11.599999999999964, 39.80000000000022, 7.399999999999965, -9.399999999999855, -36.6999999999998, -57.400000000000304], "policy_predator_policy_reward": [8.0, 10.0, 27.0, 45.0, 19.0, 4.0, 0.0, 8.0, 31.0, 31.0, 29.0, 32.0, 16.0, 14.0, 11.0, 6.0, 32.0, 42.0, 9.0, 100.0, 38.0, 52.0, 4.0, 31.0, 65.0, 51.0, 45.0, 30.0, 21.0, 19.0, 80.0, 40.0, 26.0, 31.0, 3.0, 5.0, 24.0, 13.0, 23.0, 25.0, 8.0, 4.0, 2.0, 4.0, 16.0, 1.0, 2.0, 11.0, 6.0, 17.0, 15.0, 4.0, 11.0, 7.0, 28.0, 25.0, 27.0, 27.0, 29.0, 29.0, 16.0, 12.0, 35.0, 45.0, 12.0, 7.0, 33.0, 30.0, 16.0, 40.0, 25.0, 0.0, 0.0, 9.0, 21.0, 39.0, 2.0, 5.0, 18.0, 17.0, 3.0, 3.0, 6.0, 0.0, 45.0, 28.0, 67.0, 40.0, 5.0, 6.0, 13.0, 26.0, 33.0, 59.0, 35.0, 6.0, 33.0, 10.0, 35.0, 36.0, 9.0, 49.0, 10.0, 6.0, 1.0, 4.0, 15.0, 19.0, 29.0, 20.0, 15.0, 3.0, 3.0, 2.0, 44.0, 18.0, 65.0, 53.0, 23.0, 18.0, 15.0, 4.0, 6.0, 13.0, 24.0, 14.0, 32.0, 10.0, 36.0, 26.0, 25.0, 20.0, 16.0, 2.0, 17.0, 9.0, 31.0, 27.0, 16.0, 7.0, 42.0, 14.0, 12.0, 2.0, 3.0, 10.0, 2.0, 1.0, 36.0, 60.0, 27.0, 24.0, 18.0, 11.0, 8.0, 7.0, 51.0, 1.0, 7.0, 0.0, 68.0, 40.0, 4.0, 5.0, 16.0, 8.0, 25.0, 19.0, 13.0, 31.0, 16.0, 12.0, 4.0, 18.0, 7.0, 15.0, 3.0, 11.0, 9.0, 9.0, 5.0, 5.0, 3.0, 6.0, 44.0, 29.0, 17.0, 3.0, 21.0, 7.0, 1.0, 1.0, 9.0, 0.0, 4.0, 3.0, 14.0, 6.0, 23.0, 42.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6730886867852807, "mean_inference_ms": 2.083135710009728, "mean_action_processing_ms": 0.27042181467214677, "mean_env_wait_ms": 0.2268731746570267, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005991935729980469, "StateBufferConnector_ms": 0.0040187835693359375, "ViewRequirementAgentConnector_ms": 0.11260902881622314}, "num_episodes": 18, "episode_return_max": 132.2999999999988, "episode_return_min": -48.30000000000036, "episode_return_mean": 32.87200000000009, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 416000, "num_agent_steps_trained": 416000, "num_env_steps_sampled": 104000, "num_env_steps_trained": 104000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 357.2700397334025, "num_env_steps_trained_throughput_per_sec": 357.2700397334025, "timesteps_total": 104000, "num_env_steps_sampled_lifetime": 104000, "num_agent_steps_sampled_lifetime": 416000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 416000, "timers": {"training_iteration_time_ms": 11529.68, "restore_workers_time_ms": 0.015, "training_step_time_ms": 11529.617, "sample_time_ms": 1505.286, "learn_time_ms": 10007.062, "learn_throughput": 399.718, "synch_weights_time_ms": 15.107}, "counters": {"num_env_steps_sampled": 104000, "num_env_steps_trained": 104000, "num_agent_steps_sampled": 416000, "num_agent_steps_trained": 416000}, "done": false, "training_iteration": 26, "trial_id": "3dae5_00000", "date": "2024-08-14_09-11-41", "timestamp": 1723641101, "time_this_iter_s": 11.250401020050049, "time_total_s": 1921.6120965480804, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3629ca0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1921.6120965480804, "iterations_since_restore": 26, "perf": {"cpu_util_percent": 31.325, "ram_util_percent": 83.57499999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6333848760556922, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.1821334751825483, "policy_loss": -0.005731545857809208, "vf_loss": 2.186539215259451, "vf_explained_var": 0.015598805051632029, "kl": 0.008838673034094288, "entropy": 1.235062385993029, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 50085.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8208535348927533, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.211867410701419, "policy_loss": -0.013847240405009379, "vf_loss": 2.224554613689897, "vf_explained_var": 0.04755194294389593, "kl": 0.011600374586430994, "entropy": 1.401400007772698, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 50085.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 108000, "num_env_steps_trained": 108000, "num_agent_steps_sampled": 432000, "num_agent_steps_trained": 432000}, "env_runners": {"episode_reward_max": 132.2999999999988, "episode_reward_min": -48.30000000000036, "episode_reward_mean": 38.15100000000006, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -112.30000000000078, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 78.79999999999943, "predator_policy": 68.0}, "policy_reward_mean": {"prey_policy": 1.7705000000000346, "predator_policy": 17.305}, "custom_metrics": {}, "hist_stats": {"episode_reward": [21.299999999999994, 41.000000000000135, 27.300000000000104, 39.500000000000185, 20.2, 61.20000000000042, 62.20000000000041, 35.30000000000001, 24.800000000000264, 70.49999999999993, 105.19999999999877, 21.10000000000002, -26.999999999999517, 12.500000000000002, 30.100000000000147, -22.399999999999544, 32.30000000000018, 5.10000000000017, 69.39999999999984, 63.10000000000019, 68.30000000000004, -48.30000000000036, 37.80000000000022, 64.6000000000003, -19.499999999999687, 61.500000000000334, -4.599999999999715, 79.49999999999916, 48.50000000000038, 27.500000000000107, 34.50000000000022, 101.59999999999934, 17.899999999999945, 11.800000000000068, 34.50000000000022, 13.79999999999992, 30.800000000000193, 57.90000000000027, 64.10000000000014, 70.39999999999993, -1.7999999999997294, 9.100000000000007, 53.10000000000041, 60.40000000000048, 52.60000000000034, 16.799999999999986, 51.50000000000047, 2.1000000000002292, 78.89999999999928, 26.400000000000052, 47.30000000000008, 38.80000000000028, 46.30000000000017, 75.09999999999934, 92.99999999999841, 61.60000000000036, -13.299999999999606, 42.20000000000035, 1.8999999999997723, 54.400000000000475, 37.00000000000017, 6.000000000000153, 18.60000000000002, 72.19999999999978, 28.4000000000002, 44.600000000000286, 52.50000000000041, 20.200000000000006, 75.19999999999959, 79.89999999999935, -16.899999999999608, 36.90000000000031, 4.700000000000186, 132.2999999999988, 30.100000000000147, 58.400000000000446, 17.999999999999996, -29.09999999999959, 34.50000000000022, 24.400000000000045, 62.50000000000042, 35.400000000000226, 8.499999999999945, 38.10000000000027, 49.60000000000041, 90.49999999999957, 29.30000000000016, 46.100000000000335, 79.4999999999993, 3.0000000000002016, 26.700000000000088, 47.3000000000004, 17.39999999999993, 21.499999999999996, 120.99999999999898, 26.800000000000086, 51.000000000000284, 19.10000000000005, 39.600000000000236, 32.60000000000019], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, -15.699999999999747, 21.20000000000005, 6.800000000000036, 20.000000000000014, -15.699999999999747, 17.899999999999988, 2.599999999999985, 5.299999999999965, -3.099999999999958, -22.599999999999795, 30.80000000000001, 20.000000000000014, -11.799999999999917, 1.3999999999999673, -24.09999999999986, -13.599999999999783, 10.400000000000052, 56.00000000000023, -65.50000000000063, 7.399999999999965, 78.79999999999943, -3.0999999999999934, -38.79999999999977, -36.699999999999754, -46.29999999999976, -9.399999999999883, -3.099999999999958, 20.000000000000014, 1.0999999999999865, -98.20000000000077, 15.799999999999963, 15.799999999999963, 9.499999999999964, -11.499999999999819, -18.39999999999975, 49.700000000000095, 13.699999999999964, 20.000000000000014, 37.100000000000065, 4.6999999999999975, -9.399999999999855, -112.30000000000078, -42.99999999999978, 17.299999999999965, 9.499999999999964, 20.000000000000014, 5.6, -26.1999999999999, -85.30000000000084, -38.19999999999976, 58.700000000000145, -55.00000000000027, 7.399999999999965, 38.30000000000019, -29.799999999999855, -49.599999999999824, 40.1000000000002, 3.1999999999999615, 8.29999999999997, 9.499999999999964, 20.000000000000014, 60.800000000000054, 6.799999999999981, 20.000000000000014, -51.09999999999999, -11.499999999999819, 5.299999999999967, 13.699999999999964, 15.799999999999963, -68.20000000000078, 20.000000000000014, -107.20000000000044, 20.000000000000014, -1.000000000000031, 17.9, 11.599999999999964, 33.50000000000019, 29.6000000000001, 21.80000000000004, -30.39999999999975, -9.399999999999919, -36.39999999999978, 3.499999999999969, -3.099999999999958, -5.80000000000001, -32.49999999999975, 47.90000000000023, -11.499999999999819, 46.10000000000023, 4.400000000000001, -13.599999999999783, -15.999999999999789, 9.499999999999964, -13.599999999999783, -7.299999999999891, 51.50000000000019, -28.599999999999838, 15.799999999999963, -3.3999999999999297, 13.699999999999964, 20.600000000000076, 15.799999999999963, 20.000000000000014, 35.60000000000017, -85.30000000000061, -6.999999999999934, 31.100000000000108, 35.900000000000205, 28.10000000000017, 19.400000000000006, 27.200000000000145, 8.900000000000015, -74.20000000000053, 29.900000000000187, 5.299999999999965, -25.299999999999834, -80.80000000000032, 29.6000000000002, 15.799999999999963, 6.1999999999999655, 6.799999999999983, -5.1999999999999265, -32.799999999999756, -7.299999999999905, -18.09999999999979, -12.6999999999998, 56.900000000000155, -5.199999999999871, 11.599999999999964, 20.000000000000014, 2.6000000000000734, 20.000000000000014, 18.500000000000007, 1.0999999999999865, 1.0999999999999865, 48.20000000000017, 16.999999999999975, 39.50000000000025, 31.400000000000176, -18.999999999999787, -70.90000000000047, 0.4999999999999635, 16.399999999999967, -4.299999999999944, -18.99999999999975, 63.20000000000018, 67.09999999999994, 17.899999999999977, 3.1999999999999615, 11.599999999999964, 39.80000000000022, 7.399999999999965, -9.399999999999855, -36.6999999999998, -57.400000000000304, 17.899999999999988, 11.599999999999964, 7.399999999999965, 1.9999999999999696, -0.9999999999999846, 33.50000000000016, 20.000000000000014, -10.59999999999985, -16.29999999999985, -29.19999999999976, 1.0999999999999865, 20.000000000000014, -21.999999999999744, 41.60000000000021, 17.899999999999988, 68.5999999999998, -28.299999999999834, -24.399999999999924, -5.19999999999993, 11.299999999999963, 42.50000000000016, 20.000000000000014, -13.599999999999783, -30.39999999999975, 20.000000000000014, -7.299999999999891, 20.000000000000014, 8.299999999999988, -42.99999999999976, 7.399999999999965, -8.49999999999988, -0.9999999999999846, 34.40000000000022, 32.600000000000094, 3.1999999999999615, 11.599999999999964, 20.000000000000014, 23.000000000000036, -28.89999999999977, 20.000000000000014, -33.39999999999978, 20.000000000000014, 9.499999999999964, -4.89999999999997], "policy_predator_policy_reward": [16.0, 1.0, 2.0, 11.0, 6.0, 17.0, 15.0, 4.0, 11.0, 7.0, 28.0, 25.0, 27.0, 27.0, 29.0, 29.0, 16.0, 12.0, 35.0, 45.0, 12.0, 7.0, 33.0, 30.0, 16.0, 40.0, 25.0, 0.0, 0.0, 9.0, 21.0, 39.0, 2.0, 5.0, 18.0, 17.0, 3.0, 3.0, 6.0, 0.0, 45.0, 28.0, 67.0, 40.0, 5.0, 6.0, 13.0, 26.0, 33.0, 59.0, 35.0, 6.0, 33.0, 10.0, 35.0, 36.0, 9.0, 49.0, 10.0, 6.0, 1.0, 4.0, 15.0, 19.0, 29.0, 20.0, 15.0, 3.0, 3.0, 2.0, 44.0, 18.0, 65.0, 53.0, 23.0, 18.0, 15.0, 4.0, 6.0, 13.0, 24.0, 14.0, 32.0, 10.0, 36.0, 26.0, 25.0, 20.0, 16.0, 2.0, 17.0, 9.0, 31.0, 27.0, 16.0, 7.0, 42.0, 14.0, 12.0, 2.0, 3.0, 10.0, 2.0, 1.0, 36.0, 60.0, 27.0, 24.0, 18.0, 11.0, 8.0, 7.0, 51.0, 1.0, 7.0, 0.0, 68.0, 40.0, 4.0, 5.0, 16.0, 8.0, 25.0, 19.0, 13.0, 31.0, 16.0, 12.0, 4.0, 18.0, 7.0, 15.0, 3.0, 11.0, 9.0, 9.0, 5.0, 5.0, 3.0, 6.0, 44.0, 29.0, 17.0, 3.0, 21.0, 7.0, 1.0, 1.0, 9.0, 0.0, 4.0, 3.0, 14.0, 6.0, 23.0, 42.0, 4.0, 1.0, 9.0, 6.0, 21.0, 9.0, 15.0, 11.0, 43.0, 11.0, 9.0, 8.0, 10.0, 20.0, 3.0, 1.0, 26.0, 56.0, 14.0, 26.0, 2.0, 15.0, 24.0, 23.0, 1.0, 13.0, 1.0, 18.0, 25.0, 28.0, 14.0, 17.0, 24.0, 30.0, 8.0, 4.0, 3.0, 5.0, 0.0, 28.0, 26.0, 27.0, 5.0, 23.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6702677776303636, "mean_inference_ms": 2.0789373881267954, "mean_action_processing_ms": 0.2700680724900408, "mean_env_wait_ms": 0.2265803594076219, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006801724433898926, "StateBufferConnector_ms": 0.0041501522064208984, "ViewRequirementAgentConnector_ms": 0.1092599630355835}, "num_episodes": 22, "episode_return_max": 132.2999999999988, "episode_return_min": -48.30000000000036, "episode_return_mean": 38.15100000000006, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 432000, "num_agent_steps_trained": 432000, "num_env_steps_sampled": 108000, "num_env_steps_trained": 108000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 361.76642381599515, "num_env_steps_trained_throughput_per_sec": 361.76642381599515, "timesteps_total": 108000, "num_env_steps_sampled_lifetime": 108000, "num_agent_steps_sampled_lifetime": 432000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 432000, "timers": {"training_iteration_time_ms": 11345.284, "restore_workers_time_ms": 0.015, "training_step_time_ms": 11345.225, "sample_time_ms": 1473.561, "learn_time_ms": 9854.727, "learn_throughput": 405.897, "synch_weights_time_ms": 15.112}, "counters": {"num_env_steps_sampled": 108000, "num_env_steps_trained": 108000, "num_agent_steps_sampled": 432000, "num_agent_steps_trained": 432000}, "done": false, "training_iteration": 27, "trial_id": "3dae5_00000", "date": "2024-08-14_09-11-52", "timestamp": 1723641112, "time_this_iter_s": 11.062445163726807, "time_total_s": 1932.6745417118073, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b362cd30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1932.6745417118073, "iterations_since_restore": 27, "perf": {"cpu_util_percent": 29.550000000000004, "ram_util_percent": 83.46249999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7770988715704157, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.051732353180173, "policy_loss": -0.012375429721928581, "vf_loss": 6.061970225843803, "vf_explained_var": 0.012613074268613543, "kl": 0.01425040208667948, "entropy": 1.2258199129155074, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 51975.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.243082601746554, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.349751367392363, "policy_loss": -0.01049044811864083, "vf_loss": 5.359046204001816, "vf_explained_var": -0.005277794946438421, "kl": 0.011956051858211409, "entropy": 1.4285197642114427, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 51975.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 112000, "num_env_steps_trained": 112000, "num_agent_steps_sampled": 448000, "num_agent_steps_trained": 448000}, "env_runners": {"episode_reward_max": 178.69999999999965, "episode_reward_min": -118.40000000000106, "episode_reward_mean": 38.71900000000001, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -227.50000000000026, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 73.09999999999997, "predator_policy": 110.0}, "policy_reward_mean": {"prey_policy": -2.7954999999999743, "predator_policy": 22.155}, "custom_metrics": {}, "hist_stats": {"episode_reward": [64.6000000000003, -19.499999999999687, 61.500000000000334, -4.599999999999715, 79.49999999999916, 48.50000000000038, 27.500000000000107, 34.50000000000022, 101.59999999999934, 17.899999999999945, 11.800000000000068, 34.50000000000022, 13.79999999999992, 30.800000000000193, 57.90000000000027, 64.10000000000014, 70.39999999999993, -1.7999999999997294, 9.100000000000007, 53.10000000000041, 60.40000000000048, 52.60000000000034, 16.799999999999986, 51.50000000000047, 2.1000000000002292, 78.89999999999928, 26.400000000000052, 47.30000000000008, 38.80000000000028, 46.30000000000017, 75.09999999999934, 92.99999999999841, 61.60000000000036, -13.299999999999606, 42.20000000000035, 1.8999999999997723, 54.400000000000475, 37.00000000000017, 6.000000000000153, 18.60000000000002, 72.19999999999978, 28.4000000000002, 44.600000000000286, 52.50000000000041, 20.200000000000006, 75.19999999999959, 79.89999999999935, -16.899999999999608, 36.90000000000031, 4.700000000000186, 132.2999999999988, 30.100000000000147, 58.400000000000446, 17.999999999999996, -29.09999999999959, 34.50000000000022, 24.400000000000045, 62.50000000000042, 35.400000000000226, 8.499999999999945, 38.10000000000027, 49.60000000000041, 90.49999999999957, 29.30000000000016, 46.100000000000335, 79.4999999999993, 3.0000000000002016, 26.700000000000088, 47.3000000000004, 17.39999999999993, 21.499999999999996, 120.99999999999898, 26.800000000000086, 51.000000000000284, 19.10000000000005, 39.600000000000236, 32.60000000000019, 72.09999999999951, 10.800000000000072, -118.40000000000106, 44.100000000000136, 93.09999999999964, 71.49999999999957, 59.50000000000029, 178.69999999999965, 24.60000000000008, -22.900000000000176, 23.700000000000223, 51.699999999999775, 25.500000000000068, 48.00000000000018, 89.89999999999918, -27.19999999999998, 9.500000000000034, 31.80000000000018, 24.100000000000122, -59.89999999999973, 30.200000000000244, 97.6999999999994, 49.199999999999534], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 5.6, -26.1999999999999, -85.30000000000084, -38.19999999999976, 58.700000000000145, -55.00000000000027, 7.399999999999965, 38.30000000000019, -29.799999999999855, -49.599999999999824, 40.1000000000002, 3.1999999999999615, 8.29999999999997, 9.499999999999964, 20.000000000000014, 60.800000000000054, 6.799999999999981, 20.000000000000014, -51.09999999999999, -11.499999999999819, 5.299999999999967, 13.699999999999964, 15.799999999999963, -68.20000000000078, 20.000000000000014, -107.20000000000044, 20.000000000000014, -1.000000000000031, 17.9, 11.599999999999964, 33.50000000000019, 29.6000000000001, 21.80000000000004, -30.39999999999975, -9.399999999999919, -36.39999999999978, 3.499999999999969, -3.099999999999958, -5.80000000000001, -32.49999999999975, 47.90000000000023, -11.499999999999819, 46.10000000000023, 4.400000000000001, -13.599999999999783, -15.999999999999789, 9.499999999999964, -13.599999999999783, -7.299999999999891, 51.50000000000019, -28.599999999999838, 15.799999999999963, -3.3999999999999297, 13.699999999999964, 20.600000000000076, 15.799999999999963, 20.000000000000014, 35.60000000000017, -85.30000000000061, -6.999999999999934, 31.100000000000108, 35.900000000000205, 28.10000000000017, 19.400000000000006, 27.200000000000145, 8.900000000000015, -74.20000000000053, 29.900000000000187, 5.299999999999965, -25.299999999999834, -80.80000000000032, 29.6000000000002, 15.799999999999963, 6.1999999999999655, 6.799999999999983, -5.1999999999999265, -32.799999999999756, -7.299999999999905, -18.09999999999979, -12.6999999999998, 56.900000000000155, -5.199999999999871, 11.599999999999964, 20.000000000000014, 2.6000000000000734, 20.000000000000014, 18.500000000000007, 1.0999999999999865, 1.0999999999999865, 48.20000000000017, 16.999999999999975, 39.50000000000025, 31.400000000000176, -18.999999999999787, -70.90000000000047, 0.4999999999999635, 16.399999999999967, -4.299999999999944, -18.99999999999975, 63.20000000000018, 67.09999999999994, 17.899999999999977, 3.1999999999999615, 11.599999999999964, 39.80000000000022, 7.399999999999965, -9.399999999999855, -36.6999999999998, -57.400000000000304, 17.899999999999988, 11.599999999999964, 7.399999999999965, 1.9999999999999696, -0.9999999999999846, 33.50000000000016, 20.000000000000014, -10.59999999999985, -16.29999999999985, -29.19999999999976, 1.0999999999999865, 20.000000000000014, -21.999999999999744, 41.60000000000021, 17.899999999999988, 68.5999999999998, -28.299999999999834, -24.399999999999924, -5.19999999999993, 11.299999999999963, 42.50000000000016, 20.000000000000014, -13.599999999999783, -30.39999999999975, 20.000000000000014, -7.299999999999891, 20.000000000000014, 8.299999999999988, -42.99999999999976, 7.399999999999965, -8.49999999999988, -0.9999999999999846, 34.40000000000022, 32.600000000000094, 3.1999999999999615, 11.599999999999964, 20.000000000000014, 23.000000000000036, -28.89999999999977, 20.000000000000014, -33.39999999999978, 20.000000000000014, 9.499999999999964, -4.89999999999997, 17.899999999999988, -8.799999999999963, -13.599999999999783, -13.59999999999979, -227.50000000000026, -61.90000000000065, -172.60000000000008, 40.70000000000023, 20.000000000000014, 73.09999999999997, 11.599999999999964, -15.100000000000001, 18.200000000000138, 8.299999999999965, 57.50000000000004, 33.200000000000074, -12.999999999999828, -9.399999999999869, -98.80000000000028, -30.099999999999888, -36.39999999999992, -28.900000000000013, -37.300000000000004, 20.00000000000011, 3.1999999999999615, -3.6999999999999584, 20.000000000000014, -72.99999999999993, 3.1999999999999615, 61.70000000000013, -76.30000000000021, -85.90000000000043, 20.000000000000014, -71.50000000000088, -5.1999999999999265, 20.000000000000014, -106.30000000000013, -4.5999999999999925, -130.5999999999999, -118.30000000000067, 7.399999999999965, -17.199999999999953, 50.600000000000065, -16.89999999999985, 9.499999999999964, -22.299999999999912], "policy_predator_policy_reward": [13.0, 26.0, 33.0, 59.0, 35.0, 6.0, 33.0, 10.0, 35.0, 36.0, 9.0, 49.0, 10.0, 6.0, 1.0, 4.0, 15.0, 19.0, 29.0, 20.0, 15.0, 3.0, 3.0, 2.0, 44.0, 18.0, 65.0, 53.0, 23.0, 18.0, 15.0, 4.0, 6.0, 13.0, 24.0, 14.0, 32.0, 10.0, 36.0, 26.0, 25.0, 20.0, 16.0, 2.0, 17.0, 9.0, 31.0, 27.0, 16.0, 7.0, 42.0, 14.0, 12.0, 2.0, 3.0, 10.0, 2.0, 1.0, 36.0, 60.0, 27.0, 24.0, 18.0, 11.0, 8.0, 7.0, 51.0, 1.0, 7.0, 0.0, 68.0, 40.0, 4.0, 5.0, 16.0, 8.0, 25.0, 19.0, 13.0, 31.0, 16.0, 12.0, 4.0, 18.0, 7.0, 15.0, 3.0, 11.0, 9.0, 9.0, 5.0, 5.0, 3.0, 6.0, 44.0, 29.0, 17.0, 3.0, 21.0, 7.0, 1.0, 1.0, 9.0, 0.0, 4.0, 3.0, 14.0, 6.0, 23.0, 42.0, 4.0, 1.0, 9.0, 6.0, 21.0, 9.0, 15.0, 11.0, 43.0, 11.0, 9.0, 8.0, 10.0, 20.0, 3.0, 1.0, 26.0, 56.0, 14.0, 26.0, 2.0, 15.0, 24.0, 23.0, 1.0, 13.0, 1.0, 18.0, 25.0, 28.0, 14.0, 17.0, 24.0, 30.0, 8.0, 4.0, 3.0, 5.0, 0.0, 28.0, 26.0, 27.0, 5.0, 23.0, 35.0, 28.0, 17.0, 21.0, 104.0, 67.0, 95.0, 81.0, 0.0, 0.0, 52.0, 23.0, 27.0, 6.0, 44.0, 44.0, 23.0, 24.0, 17.0, 89.0, 33.0, 56.0, 43.0, 26.0, 16.0, 10.0, 58.0, 43.0, 12.0, 13.0, 51.0, 84.0, 18.0, 43.0, 6.0, 11.0, 55.0, 80.0, 110.0, 79.0, 33.0, 7.0, 13.0, 51.0, 52.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6684654069946029, "mean_inference_ms": 2.076721478826013, "mean_action_processing_ms": 0.2798986716937776, "mean_env_wait_ms": 0.22605309360973322, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00688779354095459, "StateBufferConnector_ms": 0.004199624061584473, "ViewRequirementAgentConnector_ms": 0.10986721515655518}, "num_episodes": 23, "episode_return_max": 178.69999999999965, "episode_return_min": -118.40000000000106, "episode_return_mean": 38.71900000000001, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 448000, "num_agent_steps_trained": 448000, "num_env_steps_sampled": 112000, "num_env_steps_trained": 112000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 325.4564207106261, "num_env_steps_trained_throughput_per_sec": 325.4564207106261, "timesteps_total": 112000, "num_env_steps_sampled_lifetime": 112000, "num_agent_steps_sampled_lifetime": 448000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 448000, "timers": {"training_iteration_time_ms": 11383.891, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11383.833, "sample_time_ms": 1526.5, "learn_time_ms": 9841.206, "learn_throughput": 406.454, "synch_weights_time_ms": 14.592}, "counters": {"num_env_steps_sampled": 112000, "num_env_steps_trained": 112000, "num_agent_steps_sampled": 448000, "num_agent_steps_trained": 448000}, "done": false, "training_iteration": 28, "trial_id": "3dae5_00000", "date": "2024-08-14_09-12-04", "timestamp": 1723641124, "time_this_iter_s": 12.308881998062134, "time_total_s": 1944.9834237098694, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0f398b0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1944.9834237098694, "iterations_since_restore": 28, "perf": {"cpu_util_percent": 33.00588235294117, "ram_util_percent": 83.78235294117647}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5745868129074259, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.2962665743298, "policy_loss": -0.006079185390401454, "vf_loss": 3.300899842176488, "vf_explained_var": 0.005851160943823517, "kl": 0.009639429118610552, "entropy": 1.254817097149198, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 53865.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.0751621503047843, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.950074222226622, "policy_loss": -0.005102736684469082, "vf_loss": 4.9544290731823635, "vf_explained_var": 0.04920371546947136, "kl": 0.007478973603019214, "entropy": 1.4135777284228612, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 53865.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 116000, "num_env_steps_trained": 116000, "num_agent_steps_sampled": 464000, "num_agent_steps_trained": 464000}, "env_runners": {"episode_reward_max": 268.0, "episode_reward_min": -118.40000000000106, "episode_reward_mean": 49.05899999999995, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -256.9, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 141.19999999999993, "predator_policy": 153.0}, "policy_reward_mean": {"prey_policy": 1.134500000000031, "predator_policy": 23.395}, "custom_metrics": {}, "hist_stats": {"episode_reward": [9.100000000000007, 53.10000000000041, 60.40000000000048, 52.60000000000034, 16.799999999999986, 51.50000000000047, 2.1000000000002292, 78.89999999999928, 26.400000000000052, 47.30000000000008, 38.80000000000028, 46.30000000000017, 75.09999999999934, 92.99999999999841, 61.60000000000036, -13.299999999999606, 42.20000000000035, 1.8999999999997723, 54.400000000000475, 37.00000000000017, 6.000000000000153, 18.60000000000002, 72.19999999999978, 28.4000000000002, 44.600000000000286, 52.50000000000041, 20.200000000000006, 75.19999999999959, 79.89999999999935, -16.899999999999608, 36.90000000000031, 4.700000000000186, 132.2999999999988, 30.100000000000147, 58.400000000000446, 17.999999999999996, -29.09999999999959, 34.50000000000022, 24.400000000000045, 62.50000000000042, 35.400000000000226, 8.499999999999945, 38.10000000000027, 49.60000000000041, 90.49999999999957, 29.30000000000016, 46.100000000000335, 79.4999999999993, 3.0000000000002016, 26.700000000000088, 47.3000000000004, 17.39999999999993, 21.499999999999996, 120.99999999999898, 26.800000000000086, 51.000000000000284, 19.10000000000005, 39.600000000000236, 32.60000000000019, 72.09999999999951, 10.800000000000072, -118.40000000000106, 44.100000000000136, 93.09999999999964, 71.49999999999957, 59.50000000000029, 178.69999999999965, 24.60000000000008, -22.900000000000176, 23.700000000000223, 51.699999999999775, 25.500000000000068, 48.00000000000018, 89.89999999999918, -27.19999999999998, 9.500000000000034, 31.80000000000018, 24.100000000000122, -59.89999999999973, 30.200000000000244, 97.6999999999994, 49.199999999999534, 23.50000000000003, 97.59999999999938, 139.69999999999962, 144.29999999999927, 225.49999999999966, 268.0, 11.000000000000078, 77.90000000000019, 68.50000000000006, 124.79999999999933, -21.400000000000027, 110.99999999999962, 76.49999999999987, 34.200000000000216, 146.19999999999925, 83.69999999999933, 29.800000000000104, 86.20000000000002], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-36.39999999999978, 3.499999999999969, -3.099999999999958, -5.80000000000001, -32.49999999999975, 47.90000000000023, -11.499999999999819, 46.10000000000023, 4.400000000000001, -13.599999999999783, -15.999999999999789, 9.499999999999964, -13.599999999999783, -7.299999999999891, 51.50000000000019, -28.599999999999838, 15.799999999999963, -3.3999999999999297, 13.699999999999964, 20.600000000000076, 15.799999999999963, 20.000000000000014, 35.60000000000017, -85.30000000000061, -6.999999999999934, 31.100000000000108, 35.900000000000205, 28.10000000000017, 19.400000000000006, 27.200000000000145, 8.900000000000015, -74.20000000000053, 29.900000000000187, 5.299999999999965, -25.299999999999834, -80.80000000000032, 29.6000000000002, 15.799999999999963, 6.1999999999999655, 6.799999999999983, -5.1999999999999265, -32.799999999999756, -7.299999999999905, -18.09999999999979, -12.6999999999998, 56.900000000000155, -5.199999999999871, 11.599999999999964, 20.000000000000014, 2.6000000000000734, 20.000000000000014, 18.500000000000007, 1.0999999999999865, 1.0999999999999865, 48.20000000000017, 16.999999999999975, 39.50000000000025, 31.400000000000176, -18.999999999999787, -70.90000000000047, 0.4999999999999635, 16.399999999999967, -4.299999999999944, -18.99999999999975, 63.20000000000018, 67.09999999999994, 17.899999999999977, 3.1999999999999615, 11.599999999999964, 39.80000000000022, 7.399999999999965, -9.399999999999855, -36.6999999999998, -57.400000000000304, 17.899999999999988, 11.599999999999964, 7.399999999999965, 1.9999999999999696, -0.9999999999999846, 33.50000000000016, 20.000000000000014, -10.59999999999985, -16.29999999999985, -29.19999999999976, 1.0999999999999865, 20.000000000000014, -21.999999999999744, 41.60000000000021, 17.899999999999988, 68.5999999999998, -28.299999999999834, -24.399999999999924, -5.19999999999993, 11.299999999999963, 42.50000000000016, 20.000000000000014, -13.599999999999783, -30.39999999999975, 20.000000000000014, -7.299999999999891, 20.000000000000014, 8.299999999999988, -42.99999999999976, 7.399999999999965, -8.49999999999988, -0.9999999999999846, 34.40000000000022, 32.600000000000094, 3.1999999999999615, 11.599999999999964, 20.000000000000014, 23.000000000000036, -28.89999999999977, 20.000000000000014, -33.39999999999978, 20.000000000000014, 9.499999999999964, -4.89999999999997, 17.899999999999988, -8.799999999999963, -13.599999999999783, -13.59999999999979, -227.50000000000026, -61.90000000000065, -172.60000000000008, 40.70000000000023, 20.000000000000014, 73.09999999999997, 11.599999999999964, -15.100000000000001, 18.200000000000138, 8.299999999999965, 57.50000000000004, 33.200000000000074, -12.999999999999828, -9.399999999999869, -98.80000000000028, -30.099999999999888, -36.39999999999992, -28.900000000000013, -37.300000000000004, 20.00000000000011, 3.1999999999999615, -3.6999999999999584, 20.000000000000014, -72.99999999999993, 3.1999999999999615, 61.70000000000013, -76.30000000000021, -85.90000000000043, 20.000000000000014, -71.50000000000088, -5.1999999999999265, 20.000000000000014, -106.30000000000013, -4.5999999999999925, -130.5999999999999, -118.30000000000067, 7.399999999999965, -17.199999999999953, 50.600000000000065, -16.89999999999985, 9.499999999999964, -22.299999999999912, 1.0999999999999865, 7.399999999999965, 86.59999999999991, -21.99999999999975, 107.00000000000003, 13.699999999999964, 113.89999999999993, 7.399999999999965, 90.19999999999993, 107.29999999999984, 108.79999999999998, 141.19999999999993, -17.79999999999974, -5.1999999999999265, -25.299999999999976, 27.20000000000004, -2.1999999999999673, 13.699999999999964, 78.7999999999999, 10.999999999999966, -256.9, -11.499999999999822, 64.40000000000003, 23.600000000000065, 11.599999999999966, 53.90000000000009, -42.99999999999976, 27.20000000000013, 3.1999999999999615, 124.99999999999979, -54.3999999999999, 28.100000000000147, 31.9999999999998, -179.19999999999993, 8.90000000000012, 35.30000000000003], "policy_predator_policy_reward": [32.0, 10.0, 36.0, 26.0, 25.0, 20.0, 16.0, 2.0, 17.0, 9.0, 31.0, 27.0, 16.0, 7.0, 42.0, 14.0, 12.0, 2.0, 3.0, 10.0, 2.0, 1.0, 36.0, 60.0, 27.0, 24.0, 18.0, 11.0, 8.0, 7.0, 51.0, 1.0, 7.0, 0.0, 68.0, 40.0, 4.0, 5.0, 16.0, 8.0, 25.0, 19.0, 13.0, 31.0, 16.0, 12.0, 4.0, 18.0, 7.0, 15.0, 3.0, 11.0, 9.0, 9.0, 5.0, 5.0, 3.0, 6.0, 44.0, 29.0, 17.0, 3.0, 21.0, 7.0, 1.0, 1.0, 9.0, 0.0, 4.0, 3.0, 14.0, 6.0, 23.0, 42.0, 4.0, 1.0, 9.0, 6.0, 21.0, 9.0, 15.0, 11.0, 43.0, 11.0, 9.0, 8.0, 10.0, 20.0, 3.0, 1.0, 26.0, 56.0, 14.0, 26.0, 2.0, 15.0, 24.0, 23.0, 1.0, 13.0, 1.0, 18.0, 25.0, 28.0, 14.0, 17.0, 24.0, 30.0, 8.0, 4.0, 3.0, 5.0, 0.0, 28.0, 26.0, 27.0, 5.0, 23.0, 35.0, 28.0, 17.0, 21.0, 104.0, 67.0, 95.0, 81.0, 0.0, 0.0, 52.0, 23.0, 27.0, 6.0, 44.0, 44.0, 23.0, 24.0, 17.0, 89.0, 33.0, 56.0, 43.0, 26.0, 16.0, 10.0, 58.0, 43.0, 12.0, 13.0, 51.0, 84.0, 18.0, 43.0, 6.0, 11.0, 55.0, 80.0, 110.0, 79.0, 33.0, 7.0, 13.0, 51.0, 52.0, 10.0, 6.0, 9.0, 13.0, 20.0, 6.0, 13.0, 6.0, 17.0, 19.0, 9.0, 15.0, 3.0, 19.0, 15.0, 30.0, 46.0, 22.0, 35.0, 15.0, 20.0, 153.0, 94.0, 3.0, 20.0, 4.0, 7.0, 21.0, 29.0, 6.0, 12.0, 56.0, 54.0, 97.0, 80.0, 10.0, 32.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6667748350866541, "mean_inference_ms": 2.0762749881219453, "mean_action_processing_ms": 0.2867001565378588, "mean_env_wait_ms": 0.22572077797555928, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006387829780578613, "StateBufferConnector_ms": 0.004181623458862305, "ViewRequirementAgentConnector_ms": 0.10817945003509521}, "num_episodes": 18, "episode_return_max": 268.0, "episode_return_min": -118.40000000000106, "episode_return_mean": 49.05899999999995, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 464000, "num_agent_steps_trained": 464000, "num_env_steps_sampled": 116000, "num_env_steps_trained": 116000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 365.4556119825813, "num_env_steps_trained_throughput_per_sec": 365.4556119825813, "timesteps_total": 116000, "num_env_steps_sampled_lifetime": 116000, "num_agent_steps_sampled_lifetime": 464000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 464000, "timers": {"training_iteration_time_ms": 11338.195, "restore_workers_time_ms": 0.015, "training_step_time_ms": 11338.144, "sample_time_ms": 1529.772, "learn_time_ms": 9792.901, "learn_throughput": 408.459, "synch_weights_time_ms": 14.107}, "counters": {"num_env_steps_sampled": 116000, "num_env_steps_trained": 116000, "num_agent_steps_sampled": 464000, "num_agent_steps_trained": 464000}, "done": false, "training_iteration": 29, "trial_id": "3dae5_00000", "date": "2024-08-14_09-12-15", "timestamp": 1723641135, "time_this_iter_s": 10.9509859085083, "time_total_s": 1955.9344096183777, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0fea040>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1955.9344096183777, "iterations_since_restore": 29, "perf": {"cpu_util_percent": 29.418750000000003, "ram_util_percent": 83.5375}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6230368632803518, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.0512761139995837, "policy_loss": -0.007901628322101065, "vf_loss": 1.058022385851416, "vf_explained_var": 0.03532985158698269, "kl": 0.007702370750785706, "entropy": 1.2493132545203758, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 55755.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.116165757841534, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.811955805178042, "policy_loss": -0.006946151013727541, "vf_loss": 4.817448802978274, "vf_explained_var": 0.33791347827230184, "kl": 0.014531488086973944, "entropy": 1.384715334069792, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 55755.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 120000, "num_env_steps_trained": 120000, "num_agent_steps_sampled": 480000, "num_agent_steps_trained": 480000}, "env_runners": {"episode_reward_max": 268.0, "episode_reward_min": -118.40000000000106, "episode_reward_mean": 59.46299999999992, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -256.9, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 177.49999999999994, "predator_policy": 153.0}, "policy_reward_mean": {"prey_policy": 7.596500000000017, "predator_policy": 22.135}, "custom_metrics": {}, "hist_stats": {"episode_reward": [54.400000000000475, 37.00000000000017, 6.000000000000153, 18.60000000000002, 72.19999999999978, 28.4000000000002, 44.600000000000286, 52.50000000000041, 20.200000000000006, 75.19999999999959, 79.89999999999935, -16.899999999999608, 36.90000000000031, 4.700000000000186, 132.2999999999988, 30.100000000000147, 58.400000000000446, 17.999999999999996, -29.09999999999959, 34.50000000000022, 24.400000000000045, 62.50000000000042, 35.400000000000226, 8.499999999999945, 38.10000000000027, 49.60000000000041, 90.49999999999957, 29.30000000000016, 46.100000000000335, 79.4999999999993, 3.0000000000002016, 26.700000000000088, 47.3000000000004, 17.39999999999993, 21.499999999999996, 120.99999999999898, 26.800000000000086, 51.000000000000284, 19.10000000000005, 39.600000000000236, 32.60000000000019, 72.09999999999951, 10.800000000000072, -118.40000000000106, 44.100000000000136, 93.09999999999964, 71.49999999999957, 59.50000000000029, 178.69999999999965, 24.60000000000008, -22.900000000000176, 23.700000000000223, 51.699999999999775, 25.500000000000068, 48.00000000000018, 89.89999999999918, -27.19999999999998, 9.500000000000034, 31.80000000000018, 24.100000000000122, -59.89999999999973, 30.200000000000244, 97.6999999999994, 49.199999999999534, 23.50000000000003, 97.59999999999938, 139.69999999999962, 144.29999999999927, 225.49999999999966, 268.0, 11.000000000000078, 77.90000000000019, 68.50000000000006, 124.79999999999933, -21.400000000000027, 110.99999999999962, 76.49999999999987, 34.200000000000216, 146.19999999999925, 83.69999999999933, 29.800000000000104, 86.20000000000002, 52.700000000000244, 57.700000000000166, 177.19999999999908, 169.19999999999942, 37.80000000000027, 199.3999999999992, 36.40000000000025, 0.9000000000001858, 20.300000000000004, 177.8999999999992, 81.40000000000002, 157.39999999999966, 37.40000000000026, 23.400000000000027, 163.99999999999946, 161.49999999999918, 218.49999999999972, 11.100000000000092], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [29.6000000000002, 15.799999999999963, 6.1999999999999655, 6.799999999999983, -5.1999999999999265, -32.799999999999756, -7.299999999999905, -18.09999999999979, -12.6999999999998, 56.900000000000155, -5.199999999999871, 11.599999999999964, 20.000000000000014, 2.6000000000000734, 20.000000000000014, 18.500000000000007, 1.0999999999999865, 1.0999999999999865, 48.20000000000017, 16.999999999999975, 39.50000000000025, 31.400000000000176, -18.999999999999787, -70.90000000000047, 0.4999999999999635, 16.399999999999967, -4.299999999999944, -18.99999999999975, 63.20000000000018, 67.09999999999994, 17.899999999999977, 3.1999999999999615, 11.599999999999964, 39.80000000000022, 7.399999999999965, -9.399999999999855, -36.6999999999998, -57.400000000000304, 17.899999999999988, 11.599999999999964, 7.399999999999965, 1.9999999999999696, -0.9999999999999846, 33.50000000000016, 20.000000000000014, -10.59999999999985, -16.29999999999985, -29.19999999999976, 1.0999999999999865, 20.000000000000014, -21.999999999999744, 41.60000000000021, 17.899999999999988, 68.5999999999998, -28.299999999999834, -24.399999999999924, -5.19999999999993, 11.299999999999963, 42.50000000000016, 20.000000000000014, -13.599999999999783, -30.39999999999975, 20.000000000000014, -7.299999999999891, 20.000000000000014, 8.299999999999988, -42.99999999999976, 7.399999999999965, -8.49999999999988, -0.9999999999999846, 34.40000000000022, 32.600000000000094, 3.1999999999999615, 11.599999999999964, 20.000000000000014, 23.000000000000036, -28.89999999999977, 20.000000000000014, -33.39999999999978, 20.000000000000014, 9.499999999999964, -4.89999999999997, 17.899999999999988, -8.799999999999963, -13.599999999999783, -13.59999999999979, -227.50000000000026, -61.90000000000065, -172.60000000000008, 40.70000000000023, 20.000000000000014, 73.09999999999997, 11.599999999999964, -15.100000000000001, 18.200000000000138, 8.299999999999965, 57.50000000000004, 33.200000000000074, -12.999999999999828, -9.399999999999869, -98.80000000000028, -30.099999999999888, -36.39999999999992, -28.900000000000013, -37.300000000000004, 20.00000000000011, 3.1999999999999615, -3.6999999999999584, 20.000000000000014, -72.99999999999993, 3.1999999999999615, 61.70000000000013, -76.30000000000021, -85.90000000000043, 20.000000000000014, -71.50000000000088, -5.1999999999999265, 20.000000000000014, -106.30000000000013, -4.5999999999999925, -130.5999999999999, -118.30000000000067, 7.399999999999965, -17.199999999999953, 50.600000000000065, -16.89999999999985, 9.499999999999964, -22.299999999999912, 1.0999999999999865, 7.399999999999965, 86.59999999999991, -21.99999999999975, 107.00000000000003, 13.699999999999964, 113.89999999999993, 7.399999999999965, 90.19999999999993, 107.29999999999984, 108.79999999999998, 141.19999999999993, -17.79999999999974, -5.1999999999999265, -25.299999999999976, 27.20000000000004, -2.1999999999999673, 13.699999999999964, 78.7999999999999, 10.999999999999966, -256.9, -11.499999999999822, 64.40000000000003, 23.600000000000065, 11.599999999999966, 53.90000000000009, -42.99999999999976, 27.20000000000013, 3.1999999999999615, 124.99999999999979, -54.3999999999999, 28.100000000000147, 31.9999999999998, -179.19999999999993, 8.90000000000012, 35.30000000000003, -33.399999999999764, 55.10000000000012, -3.399999999999951, 16.100000000000072, 3.1999999999999615, 163.99999999999977, 20.000000000000014, 108.2, 15.799999999999963, 20.000000000000014, 17.899999999999988, 177.49999999999994, 20.000000000000014, 7.399999999999965, 11.599999999999964, -78.70000000000086, 1.0999999999999865, 3.1999999999999615, 97.39999999999972, 57.50000000000009, -3.0999999999999615, 60.500000000000014, 52.400000000000084, 62.00000000000004, 7.399999999999965, 20.000000000000014, 7.399999999999965, -0.9999999999999917, 20.000000000000014, 128.00000000000003, 11.599999999999964, 134.89999999999978, 62.000000000000014, 75.5, 3.1999999999999615, -3.099999999999958], "policy_predator_policy_reward": [4.0, 5.0, 16.0, 8.0, 25.0, 19.0, 13.0, 31.0, 16.0, 12.0, 4.0, 18.0, 7.0, 15.0, 3.0, 11.0, 9.0, 9.0, 5.0, 5.0, 3.0, 6.0, 44.0, 29.0, 17.0, 3.0, 21.0, 7.0, 1.0, 1.0, 9.0, 0.0, 4.0, 3.0, 14.0, 6.0, 23.0, 42.0, 4.0, 1.0, 9.0, 6.0, 21.0, 9.0, 15.0, 11.0, 43.0, 11.0, 9.0, 8.0, 10.0, 20.0, 3.0, 1.0, 26.0, 56.0, 14.0, 26.0, 2.0, 15.0, 24.0, 23.0, 1.0, 13.0, 1.0, 18.0, 25.0, 28.0, 14.0, 17.0, 24.0, 30.0, 8.0, 4.0, 3.0, 5.0, 0.0, 28.0, 26.0, 27.0, 5.0, 23.0, 35.0, 28.0, 17.0, 21.0, 104.0, 67.0, 95.0, 81.0, 0.0, 0.0, 52.0, 23.0, 27.0, 6.0, 44.0, 44.0, 23.0, 24.0, 17.0, 89.0, 33.0, 56.0, 43.0, 26.0, 16.0, 10.0, 58.0, 43.0, 12.0, 13.0, 51.0, 84.0, 18.0, 43.0, 6.0, 11.0, 55.0, 80.0, 110.0, 79.0, 33.0, 7.0, 13.0, 51.0, 52.0, 10.0, 6.0, 9.0, 13.0, 20.0, 6.0, 13.0, 6.0, 17.0, 19.0, 9.0, 15.0, 3.0, 19.0, 15.0, 30.0, 46.0, 22.0, 35.0, 15.0, 20.0, 153.0, 94.0, 3.0, 20.0, 4.0, 7.0, 21.0, 29.0, 6.0, 12.0, 56.0, 54.0, 97.0, 80.0, 10.0, 32.0, 26.0, 5.0, 44.0, 1.0, 5.0, 5.0, 14.0, 27.0, 0.0, 2.0, 1.0, 3.0, 6.0, 3.0, 28.0, 40.0, 6.0, 10.0, 10.0, 13.0, 10.0, 14.0, 7.0, 36.0, 5.0, 5.0, 7.0, 10.0, 12.0, 4.0, 7.0, 8.0, 37.0, 44.0, 11.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6650868052175847, "mean_inference_ms": 2.076086770258621, "mean_action_processing_ms": 0.29327036409023605, "mean_env_wait_ms": 0.2253701290328985, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005869269371032715, "StateBufferConnector_ms": 0.004212617874145508, "ViewRequirementAgentConnector_ms": 0.10482585430145264}, "num_episodes": 18, "episode_return_max": 268.0, "episode_return_min": -118.40000000000106, "episode_return_mean": 59.46299999999992, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 480000, "num_agent_steps_trained": 480000, "num_env_steps_sampled": 120000, "num_env_steps_trained": 120000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 356.5553115643784, "num_env_steps_trained_throughput_per_sec": 356.5553115643784, "timesteps_total": 120000, "num_env_steps_sampled_lifetime": 120000, "num_agent_steps_sampled_lifetime": 480000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 480000, "timers": {"training_iteration_time_ms": 11239.319, "restore_workers_time_ms": 0.015, "training_step_time_ms": 11239.278, "sample_time_ms": 1529.003, "learn_time_ms": 9695.598, "learn_throughput": 412.558, "synch_weights_time_ms": 13.507}, "counters": {"num_env_steps_sampled": 120000, "num_env_steps_trained": 120000, "num_agent_steps_sampled": 480000, "num_agent_steps_trained": 480000}, "done": false, "training_iteration": 30, "trial_id": "3dae5_00000", "date": "2024-08-14_09-12-26", "timestamp": 1723641146, "time_this_iter_s": 11.225565910339355, "time_total_s": 1967.159975528717, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0feadc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1967.159975528717, "iterations_since_restore": 30, "perf": {"cpu_util_percent": 29.61875, "ram_util_percent": 83.60625}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2734746205585974, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.8462314171292794, "policy_loss": -0.00942113903393013, "vf_loss": 0.8547077881852313, "vf_explained_var": 0.024071915029848696, "kl": 0.006298440642154397, "entropy": 1.2451422431481578, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 57645.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.696348034420972, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.754808376831983, "policy_loss": -0.003259325757987364, "vf_loss": 4.757414518966876, "vf_explained_var": 0.4530659332161858, "kl": 0.006531827133995556, "entropy": 1.3914204992945232, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 57645.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 124000, "num_env_steps_trained": 124000, "num_agent_steps_sampled": 496000, "num_agent_steps_trained": 496000}, "env_runners": {"episode_reward_max": 323.70000000000005, "episode_reward_min": -118.40000000000106, "episode_reward_mean": 79.51199999999986, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -256.9, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 177.49999999999994, "predator_policy": 153.0}, "policy_reward_mean": {"prey_policy": 17.396000000000004, "predator_policy": 22.36}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-29.09999999999959, 34.50000000000022, 24.400000000000045, 62.50000000000042, 35.400000000000226, 8.499999999999945, 38.10000000000027, 49.60000000000041, 90.49999999999957, 29.30000000000016, 46.100000000000335, 79.4999999999993, 3.0000000000002016, 26.700000000000088, 47.3000000000004, 17.39999999999993, 21.499999999999996, 120.99999999999898, 26.800000000000086, 51.000000000000284, 19.10000000000005, 39.600000000000236, 32.60000000000019, 72.09999999999951, 10.800000000000072, -118.40000000000106, 44.100000000000136, 93.09999999999964, 71.49999999999957, 59.50000000000029, 178.69999999999965, 24.60000000000008, -22.900000000000176, 23.700000000000223, 51.699999999999775, 25.500000000000068, 48.00000000000018, 89.89999999999918, -27.19999999999998, 9.500000000000034, 31.80000000000018, 24.100000000000122, -59.89999999999973, 30.200000000000244, 97.6999999999994, 49.199999999999534, 23.50000000000003, 97.59999999999938, 139.69999999999962, 144.29999999999927, 225.49999999999966, 268.0, 11.000000000000078, 77.90000000000019, 68.50000000000006, 124.79999999999933, -21.400000000000027, 110.99999999999962, 76.49999999999987, 34.200000000000216, 146.19999999999925, 83.69999999999933, 29.800000000000104, 86.20000000000002, 52.700000000000244, 57.700000000000166, 177.19999999999908, 169.19999999999942, 37.80000000000027, 199.3999999999992, 36.40000000000025, 0.9000000000001858, 20.300000000000004, 177.8999999999992, 81.40000000000002, 157.39999999999966, 37.40000000000026, 23.400000000000027, 163.99999999999946, 161.49999999999918, 218.49999999999972, 11.100000000000092, 159.99999999999935, 51.1000000000002, 275.89999999999986, 182.69999999999922, 32.00000000000018, 205.09999999999926, 128.09999999999968, 154.99999999999932, 323.70000000000005, 153.89999999999932, 102.20000000000005, 138.19999999999953, 181.6999999999995, 21.90000000000001, 160.69999999999993, 162.1999999999995, 152.0999999999993, 170.89999999999924], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-36.6999999999998, -57.400000000000304, 17.899999999999988, 11.599999999999964, 7.399999999999965, 1.9999999999999696, -0.9999999999999846, 33.50000000000016, 20.000000000000014, -10.59999999999985, -16.29999999999985, -29.19999999999976, 1.0999999999999865, 20.000000000000014, -21.999999999999744, 41.60000000000021, 17.899999999999988, 68.5999999999998, -28.299999999999834, -24.399999999999924, -5.19999999999993, 11.299999999999963, 42.50000000000016, 20.000000000000014, -13.599999999999783, -30.39999999999975, 20.000000000000014, -7.299999999999891, 20.000000000000014, 8.299999999999988, -42.99999999999976, 7.399999999999965, -8.49999999999988, -0.9999999999999846, 34.40000000000022, 32.600000000000094, 3.1999999999999615, 11.599999999999964, 20.000000000000014, 23.000000000000036, -28.89999999999977, 20.000000000000014, -33.39999999999978, 20.000000000000014, 9.499999999999964, -4.89999999999997, 17.899999999999988, -8.799999999999963, -13.599999999999783, -13.59999999999979, -227.50000000000026, -61.90000000000065, -172.60000000000008, 40.70000000000023, 20.000000000000014, 73.09999999999997, 11.599999999999964, -15.100000000000001, 18.200000000000138, 8.299999999999965, 57.50000000000004, 33.200000000000074, -12.999999999999828, -9.399999999999869, -98.80000000000028, -30.099999999999888, -36.39999999999992, -28.900000000000013, -37.300000000000004, 20.00000000000011, 3.1999999999999615, -3.6999999999999584, 20.000000000000014, -72.99999999999993, 3.1999999999999615, 61.70000000000013, -76.30000000000021, -85.90000000000043, 20.000000000000014, -71.50000000000088, -5.1999999999999265, 20.000000000000014, -106.30000000000013, -4.5999999999999925, -130.5999999999999, -118.30000000000067, 7.399999999999965, -17.199999999999953, 50.600000000000065, -16.89999999999985, 9.499999999999964, -22.299999999999912, 1.0999999999999865, 7.399999999999965, 86.59999999999991, -21.99999999999975, 107.00000000000003, 13.699999999999964, 113.89999999999993, 7.399999999999965, 90.19999999999993, 107.29999999999984, 108.79999999999998, 141.19999999999993, -17.79999999999974, -5.1999999999999265, -25.299999999999976, 27.20000000000004, -2.1999999999999673, 13.699999999999964, 78.7999999999999, 10.999999999999966, -256.9, -11.499999999999822, 64.40000000000003, 23.600000000000065, 11.599999999999966, 53.90000000000009, -42.99999999999976, 27.20000000000013, 3.1999999999999615, 124.99999999999979, -54.3999999999999, 28.100000000000147, 31.9999999999998, -179.19999999999993, 8.90000000000012, 35.30000000000003, -33.399999999999764, 55.10000000000012, -3.399999999999951, 16.100000000000072, 3.1999999999999615, 163.99999999999977, 20.000000000000014, 108.2, 15.799999999999963, 20.000000000000014, 17.899999999999988, 177.49999999999994, 20.000000000000014, 7.399999999999965, 11.599999999999964, -78.70000000000086, 1.0999999999999865, 3.1999999999999615, 97.39999999999972, 57.50000000000009, -3.0999999999999615, 60.500000000000014, 52.400000000000084, 62.00000000000004, 7.399999999999965, 20.000000000000014, 7.399999999999965, -0.9999999999999917, 20.000000000000014, 128.00000000000003, 11.599999999999964, 134.89999999999978, 62.000000000000014, 75.5, 3.1999999999999615, -3.099999999999958, 140.59999999999994, 7.399999999999965, -25.599999999999987, -7.299999999999891, 146.3, 113.5999999999999, 168.4999999999999, 3.1999999999999615, 20.90000000000003, 1.0999999999999865, 20.000000000000014, 175.09999999999997, 20.000000000000014, 94.10000000000005, 145.9999999999999, -0.9999999999999846, 172.99999999999983, 133.69999999999993, 126.49999999999986, 7.399999999999965, 50.300000000000026, -3.099999999999958, 11.599999999999964, 122.59999999999997, 59.60000000000009, 88.10000000000001, -1.2999999999999847, 3.1999999999999615, 56.300000000000004, 37.399999999999956, 131.59999999999997, 11.599999999999966, -10.899999999999835, 133.99999999999986, 3.1999999999999615, 151.6999999999999], "policy_predator_policy_reward": [23.0, 42.0, 4.0, 1.0, 9.0, 6.0, 21.0, 9.0, 15.0, 11.0, 43.0, 11.0, 9.0, 8.0, 10.0, 20.0, 3.0, 1.0, 26.0, 56.0, 14.0, 26.0, 2.0, 15.0, 24.0, 23.0, 1.0, 13.0, 1.0, 18.0, 25.0, 28.0, 14.0, 17.0, 24.0, 30.0, 8.0, 4.0, 3.0, 5.0, 0.0, 28.0, 26.0, 27.0, 5.0, 23.0, 35.0, 28.0, 17.0, 21.0, 104.0, 67.0, 95.0, 81.0, 0.0, 0.0, 52.0, 23.0, 27.0, 6.0, 44.0, 44.0, 23.0, 24.0, 17.0, 89.0, 33.0, 56.0, 43.0, 26.0, 16.0, 10.0, 58.0, 43.0, 12.0, 13.0, 51.0, 84.0, 18.0, 43.0, 6.0, 11.0, 55.0, 80.0, 110.0, 79.0, 33.0, 7.0, 13.0, 51.0, 52.0, 10.0, 6.0, 9.0, 13.0, 20.0, 6.0, 13.0, 6.0, 17.0, 19.0, 9.0, 15.0, 3.0, 19.0, 15.0, 30.0, 46.0, 22.0, 35.0, 15.0, 20.0, 153.0, 94.0, 3.0, 20.0, 4.0, 7.0, 21.0, 29.0, 6.0, 12.0, 56.0, 54.0, 97.0, 80.0, 10.0, 32.0, 26.0, 5.0, 44.0, 1.0, 5.0, 5.0, 14.0, 27.0, 0.0, 2.0, 1.0, 3.0, 6.0, 3.0, 28.0, 40.0, 6.0, 10.0, 10.0, 13.0, 10.0, 14.0, 7.0, 36.0, 5.0, 5.0, 7.0, 10.0, 12.0, 4.0, 7.0, 8.0, 37.0, 44.0, 11.0, 0.0, 6.0, 6.0, 13.0, 71.0, 10.0, 6.0, 2.0, 9.0, 9.0, 1.0, 5.0, 5.0, 14.0, 0.0, 0.0, 10.0, 3.0, 14.0, 10.0, 10.0, 29.0, 26.0, 4.0, 0.0, 19.0, 15.0, 9.0, 11.0, 54.0, 13.0, 4.0, 15.0, 17.0, 12.0, 9.0, 7.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6635530094996954, "mean_inference_ms": 2.0758686538644935, "mean_action_processing_ms": 0.29963466494301705, "mean_env_wait_ms": 0.22514667884965495, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005280971527099609, "StateBufferConnector_ms": 0.0036107301712036133, "ViewRequirementAgentConnector_ms": 0.10181033611297607}, "num_episodes": 18, "episode_return_max": 323.70000000000005, "episode_return_min": -118.40000000000106, "episode_return_mean": 79.51199999999986, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 496000, "num_agent_steps_trained": 496000, "num_env_steps_sampled": 124000, "num_env_steps_trained": 124000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 364.3426241135075, "num_env_steps_trained_throughput_per_sec": 364.3426241135075, "timesteps_total": 124000, "num_env_steps_sampled_lifetime": 124000, "num_agent_steps_sampled_lifetime": 496000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 496000, "timers": {"training_iteration_time_ms": 11250.349, "restore_workers_time_ms": 0.015, "training_step_time_ms": 11250.308, "sample_time_ms": 1522.329, "learn_time_ms": 9713.298, "learn_throughput": 411.807, "synch_weights_time_ms": 13.492}, "counters": {"num_env_steps_sampled": 124000, "num_env_steps_trained": 124000, "num_agent_steps_sampled": 496000, "num_agent_steps_trained": 496000}, "done": false, "training_iteration": 31, "trial_id": "3dae5_00000", "date": "2024-08-14_09-12-37", "timestamp": 1723641157, "time_this_iter_s": 10.985536098480225, "time_total_s": 1978.1455116271973, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0fd7f70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1978.1455116271973, "iterations_since_restore": 31, "perf": {"cpu_util_percent": 32.7, "ram_util_percent": 83.72}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9044303788079155, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.9520214235341107, "policy_loss": -0.010618775745572906, "vf_loss": 1.9617639115878514, "vf_explained_var": 0.09601973487586571, "kl": 0.005841942921913246, "entropy": 1.241775916745423, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 59535.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9316223776529706, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.259400871569517, "policy_loss": -0.0023189913345964025, "vf_loss": 5.260744092199538, "vf_explained_var": 0.5251950031865842, "kl": 0.009757922364692917, "entropy": 1.3643126931770768, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 59535.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 128000, "num_env_steps_trained": 128000, "num_agent_steps_sampled": 512000, "num_agent_steps_trained": 512000}, "env_runners": {"episode_reward_max": 351.60000000000014, "episode_reward_min": -59.89999999999973, "episode_reward_mean": 109.8229999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -256.9, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 191.89999999999998, "predator_policy": 153.0}, "policy_reward_mean": {"prey_policy": 33.486499999999985, "predator_policy": 21.425}, "custom_metrics": {}, "hist_stats": {"episode_reward": [93.09999999999964, 71.49999999999957, 59.50000000000029, 178.69999999999965, 24.60000000000008, -22.900000000000176, 23.700000000000223, 51.699999999999775, 25.500000000000068, 48.00000000000018, 89.89999999999918, -27.19999999999998, 9.500000000000034, 31.80000000000018, 24.100000000000122, -59.89999999999973, 30.200000000000244, 97.6999999999994, 49.199999999999534, 23.50000000000003, 97.59999999999938, 139.69999999999962, 144.29999999999927, 225.49999999999966, 268.0, 11.000000000000078, 77.90000000000019, 68.50000000000006, 124.79999999999933, -21.400000000000027, 110.99999999999962, 76.49999999999987, 34.200000000000216, 146.19999999999925, 83.69999999999933, 29.800000000000104, 86.20000000000002, 52.700000000000244, 57.700000000000166, 177.19999999999908, 169.19999999999942, 37.80000000000027, 199.3999999999992, 36.40000000000025, 0.9000000000001858, 20.300000000000004, 177.8999999999992, 81.40000000000002, 157.39999999999966, 37.40000000000026, 23.400000000000027, 163.99999999999946, 161.49999999999918, 218.49999999999972, 11.100000000000092, 159.99999999999935, 51.1000000000002, 275.89999999999986, 182.69999999999922, 32.00000000000018, 205.09999999999926, 128.09999999999968, 154.99999999999932, 323.70000000000005, 153.89999999999932, 102.20000000000005, 138.19999999999953, 181.6999999999995, 21.90000000000001, 160.69999999999993, 162.1999999999995, 152.0999999999993, 170.89999999999924, 10.600000000000094, 198.7999999999993, 236.69999999999996, 184.29999999999936, 22.300000000000015, 137.99999999999963, -16.099999999999532, 116.59999999999985, 307.6, 19.899999999999988, 37.600000000000264, 38.300000000000274, 125.6999999999998, 156.9999999999995, 127.69999999999985, 216.9999999999997, 180.79999999999998, 351.60000000000014, 197.79999999999922, 191.89999999999932, 3.600000000000202, 207.29999999999993, 140.19999999999916, 169.09999999999948, 119.99999999999977, 170.29999999999927, 260.4], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 73.09999999999997, 11.599999999999964, -15.100000000000001, 18.200000000000138, 8.299999999999965, 57.50000000000004, 33.200000000000074, -12.999999999999828, -9.399999999999869, -98.80000000000028, -30.099999999999888, -36.39999999999992, -28.900000000000013, -37.300000000000004, 20.00000000000011, 3.1999999999999615, -3.6999999999999584, 20.000000000000014, -72.99999999999993, 3.1999999999999615, 61.70000000000013, -76.30000000000021, -85.90000000000043, 20.000000000000014, -71.50000000000088, -5.1999999999999265, 20.000000000000014, -106.30000000000013, -4.5999999999999925, -130.5999999999999, -118.30000000000067, 7.399999999999965, -17.199999999999953, 50.600000000000065, -16.89999999999985, 9.499999999999964, -22.299999999999912, 1.0999999999999865, 7.399999999999965, 86.59999999999991, -21.99999999999975, 107.00000000000003, 13.699999999999964, 113.89999999999993, 7.399999999999965, 90.19999999999993, 107.29999999999984, 108.79999999999998, 141.19999999999993, -17.79999999999974, -5.1999999999999265, -25.299999999999976, 27.20000000000004, -2.1999999999999673, 13.699999999999964, 78.7999999999999, 10.999999999999966, -256.9, -11.499999999999822, 64.40000000000003, 23.600000000000065, 11.599999999999966, 53.90000000000009, -42.99999999999976, 27.20000000000013, 3.1999999999999615, 124.99999999999979, -54.3999999999999, 28.100000000000147, 31.9999999999998, -179.19999999999993, 8.90000000000012, 35.30000000000003, -33.399999999999764, 55.10000000000012, -3.399999999999951, 16.100000000000072, 3.1999999999999615, 163.99999999999977, 20.000000000000014, 108.2, 15.799999999999963, 20.000000000000014, 17.899999999999988, 177.49999999999994, 20.000000000000014, 7.399999999999965, 11.599999999999964, -78.70000000000086, 1.0999999999999865, 3.1999999999999615, 97.39999999999972, 57.50000000000009, -3.0999999999999615, 60.500000000000014, 52.400000000000084, 62.00000000000004, 7.399999999999965, 20.000000000000014, 7.399999999999965, -0.9999999999999917, 20.000000000000014, 128.00000000000003, 11.599999999999964, 134.89999999999978, 62.000000000000014, 75.5, 3.1999999999999615, -3.099999999999958, 140.59999999999994, 7.399999999999965, -25.599999999999987, -7.299999999999891, 146.3, 113.5999999999999, 168.4999999999999, 3.1999999999999615, 20.90000000000003, 1.0999999999999865, 20.000000000000014, 175.09999999999997, 20.000000000000014, 94.10000000000005, 145.9999999999999, -0.9999999999999846, 172.99999999999983, 133.69999999999993, 126.49999999999986, 7.399999999999965, 50.300000000000026, -3.099999999999958, 11.599999999999964, 122.59999999999997, 59.60000000000009, 88.10000000000001, -1.2999999999999847, 3.1999999999999615, 56.300000000000004, 37.399999999999956, 131.59999999999997, 11.599999999999966, -10.899999999999835, 133.99999999999986, 3.1999999999999615, 151.6999999999999, -0.9999999999999846, -9.399999999999855, 13.699999999999964, 178.1, 127.1, 68.60000000000002, 158.6, 13.699999999999964, 9.499999999999966, -5.1999999999999265, 15.799999999999963, 75.19999999999997, 20.000000000000014, -87.10000000000085, -0.9999999999999846, 68.60000000000002, 139.1, 138.5, 9.499999999999964, -13.599999999999783, 11.599999999999964, 20.000000000000014, 1.0999999999999865, 27.20000000000013, 59.900000000000006, -5.1999999999999265, 106.39999999999995, 11.599999999999966, -19.89999999999975, 113.60000000000007, 124.69999999999992, 47.30000000000005, -62.50000000000003, 119.29999999999998, 191.89999999999998, 133.69999999999996, 177.49999999999994, 5.299999999999965, 5.299999999999965, 176.59999999999997, -24.099999999999746, -7.299999999999891, 50.60000000000001, 73.69999999999996, 127.99999999999973, 3.1999999999999615, 7.399999999999965, 136.69999999999996, -28.29999999999975, 98.30000000000001, 9.499999999999964, 150.79999999999995, 67.09999999999997, 92.29999999999998], "policy_predator_policy_reward": [0.0, 0.0, 52.0, 23.0, 27.0, 6.0, 44.0, 44.0, 23.0, 24.0, 17.0, 89.0, 33.0, 56.0, 43.0, 26.0, 16.0, 10.0, 58.0, 43.0, 12.0, 13.0, 51.0, 84.0, 18.0, 43.0, 6.0, 11.0, 55.0, 80.0, 110.0, 79.0, 33.0, 7.0, 13.0, 51.0, 52.0, 10.0, 6.0, 9.0, 13.0, 20.0, 6.0, 13.0, 6.0, 17.0, 19.0, 9.0, 15.0, 3.0, 19.0, 15.0, 30.0, 46.0, 22.0, 35.0, 15.0, 20.0, 153.0, 94.0, 3.0, 20.0, 4.0, 7.0, 21.0, 29.0, 6.0, 12.0, 56.0, 54.0, 97.0, 80.0, 10.0, 32.0, 26.0, 5.0, 44.0, 1.0, 5.0, 5.0, 14.0, 27.0, 0.0, 2.0, 1.0, 3.0, 6.0, 3.0, 28.0, 40.0, 6.0, 10.0, 10.0, 13.0, 10.0, 14.0, 7.0, 36.0, 5.0, 5.0, 7.0, 10.0, 12.0, 4.0, 7.0, 8.0, 37.0, 44.0, 11.0, 0.0, 6.0, 6.0, 13.0, 71.0, 10.0, 6.0, 2.0, 9.0, 9.0, 1.0, 5.0, 5.0, 14.0, 0.0, 0.0, 10.0, 3.0, 14.0, 10.0, 10.0, 29.0, 26.0, 4.0, 0.0, 19.0, 15.0, 9.0, 11.0, 54.0, 13.0, 4.0, 15.0, 17.0, 12.0, 9.0, 7.0, 7.0, 14.0, 6.0, 1.0, 19.0, 22.0, 3.0, 9.0, 12.0, 6.0, 14.0, 33.0, 0.0, 51.0, 10.0, 39.0, 24.0, 6.0, 16.0, 8.0, 4.0, 2.0, 1.0, 9.0, 44.0, 27.0, 14.0, 25.0, 15.0, 19.0, 4.0, 41.0, 76.0, 48.0, 15.0, 11.0, 8.0, 7.0, 7.0, 3.0, 19.0, 16.0, 39.0, 44.0, 8.0, 1.0, 10.0, 15.0, 24.0, 26.0, 3.0, 7.0, 48.0, 53.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6613529359463243, "mean_inference_ms": 2.0740237232614156, "mean_action_processing_ms": 0.3075343207214197, "mean_env_wait_ms": 0.2248627478456337, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004377126693725586, "StateBufferConnector_ms": 0.0035518407821655273, "ViewRequirementAgentConnector_ms": 0.10601699352264404}, "num_episodes": 27, "episode_return_max": 351.60000000000014, "episode_return_min": -59.89999999999973, "episode_return_mean": 109.8229999999998, "episodes_this_iter": 27}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 512000, "num_agent_steps_trained": 512000, "num_env_steps_sampled": 128000, "num_env_steps_trained": 128000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 351.55523523377536, "num_env_steps_trained_throughput_per_sec": 351.55523523377536, "timesteps_total": 128000, "num_env_steps_sampled_lifetime": 128000, "num_agent_steps_sampled_lifetime": 512000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 512000, "timers": {"training_iteration_time_ms": 11294.917, "restore_workers_time_ms": 0.015, "training_step_time_ms": 11294.876, "sample_time_ms": 1518.849, "learn_time_ms": 9761.203, "learn_throughput": 409.786, "synch_weights_time_ms": 13.635}, "counters": {"num_env_steps_sampled": 128000, "num_env_steps_trained": 128000, "num_agent_steps_sampled": 512000, "num_agent_steps_trained": 512000}, "done": false, "training_iteration": 32, "trial_id": "3dae5_00000", "date": "2024-08-14_09-12-49", "timestamp": 1723641169, "time_this_iter_s": 11.383270978927612, "time_total_s": 1989.5287826061249, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0fd7700>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1989.5287826061249, "iterations_since_restore": 32, "perf": {"cpu_util_percent": 29.5, "ram_util_percent": 83.3125}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8418526268194593, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.8789413090736147, "policy_loss": -0.007998542348662065, "vf_loss": 1.8859849784740064, "vf_explained_var": 0.04318948924226105, "kl": 0.00636580582942248, "entropy": 1.2565620679073233, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 61425.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9213851415291034, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.783549344855011, "policy_loss": -0.006548626234301577, "vf_loss": 5.7889050594713325, "vf_explained_var": 0.5302840524564976, "kl": 0.011929142276786046, "entropy": 1.3377301795772774, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 61425.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 132000, "num_env_steps_trained": 132000, "num_agent_steps_sampled": 528000, "num_agent_steps_trained": 528000}, "env_runners": {"episode_reward_max": 352.79999999999995, "episode_reward_min": -21.400000000000027, "episode_reward_mean": 133.08299999999977, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -256.9, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 191.89999999999998, "predator_policy": 153.0}, "policy_reward_mean": {"prey_policy": 48.0815, "predator_policy": 18.46}, "custom_metrics": {}, "hist_stats": {"episode_reward": [49.199999999999534, 23.50000000000003, 97.59999999999938, 139.69999999999962, 144.29999999999927, 225.49999999999966, 268.0, 11.000000000000078, 77.90000000000019, 68.50000000000006, 124.79999999999933, -21.400000000000027, 110.99999999999962, 76.49999999999987, 34.200000000000216, 146.19999999999925, 83.69999999999933, 29.800000000000104, 86.20000000000002, 52.700000000000244, 57.700000000000166, 177.19999999999908, 169.19999999999942, 37.80000000000027, 199.3999999999992, 36.40000000000025, 0.9000000000001858, 20.300000000000004, 177.8999999999992, 81.40000000000002, 157.39999999999966, 37.40000000000026, 23.400000000000027, 163.99999999999946, 161.49999999999918, 218.49999999999972, 11.100000000000092, 159.99999999999935, 51.1000000000002, 275.89999999999986, 182.69999999999922, 32.00000000000018, 205.09999999999926, 128.09999999999968, 154.99999999999932, 323.70000000000005, 153.89999999999932, 102.20000000000005, 138.19999999999953, 181.6999999999995, 21.90000000000001, 160.69999999999993, 162.1999999999995, 152.0999999999993, 170.89999999999924, 10.600000000000094, 198.7999999999993, 236.69999999999996, 184.29999999999936, 22.300000000000015, 137.99999999999963, -16.099999999999532, 116.59999999999985, 307.6, 19.899999999999988, 37.600000000000264, 38.300000000000274, 125.6999999999998, 156.9999999999995, 127.69999999999985, 216.9999999999997, 180.79999999999998, 351.60000000000014, 197.79999999999922, 191.89999999999932, 3.600000000000202, 207.29999999999993, 140.19999999999916, 169.09999999999948, 119.99999999999977, 170.29999999999927, 260.4, 33.4000000000002, 352.79999999999995, 194.59999999999994, 183.79999999999933, 139.69999999999948, 351.9, 152.49999999999952, 175.79999999999941, 153.89999999999944, 73.90000000000013, 102.19999999999996, 204.2999999999999, 126.69999999999982, 341.6, 172.7999999999995, 152.49999999999966, 159.5999999999995, 3.5000000000001807], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [9.499999999999964, -22.299999999999912, 1.0999999999999865, 7.399999999999965, 86.59999999999991, -21.99999999999975, 107.00000000000003, 13.699999999999964, 113.89999999999993, 7.399999999999965, 90.19999999999993, 107.29999999999984, 108.79999999999998, 141.19999999999993, -17.79999999999974, -5.1999999999999265, -25.299999999999976, 27.20000000000004, -2.1999999999999673, 13.699999999999964, 78.7999999999999, 10.999999999999966, -256.9, -11.499999999999822, 64.40000000000003, 23.600000000000065, 11.599999999999966, 53.90000000000009, -42.99999999999976, 27.20000000000013, 3.1999999999999615, 124.99999999999979, -54.3999999999999, 28.100000000000147, 31.9999999999998, -179.19999999999993, 8.90000000000012, 35.30000000000003, -33.399999999999764, 55.10000000000012, -3.399999999999951, 16.100000000000072, 3.1999999999999615, 163.99999999999977, 20.000000000000014, 108.2, 15.799999999999963, 20.000000000000014, 17.899999999999988, 177.49999999999994, 20.000000000000014, 7.399999999999965, 11.599999999999964, -78.70000000000086, 1.0999999999999865, 3.1999999999999615, 97.39999999999972, 57.50000000000009, -3.0999999999999615, 60.500000000000014, 52.400000000000084, 62.00000000000004, 7.399999999999965, 20.000000000000014, 7.399999999999965, -0.9999999999999917, 20.000000000000014, 128.00000000000003, 11.599999999999964, 134.89999999999978, 62.000000000000014, 75.5, 3.1999999999999615, -3.099999999999958, 140.59999999999994, 7.399999999999965, -25.599999999999987, -7.299999999999891, 146.3, 113.5999999999999, 168.4999999999999, 3.1999999999999615, 20.90000000000003, 1.0999999999999865, 20.000000000000014, 175.09999999999997, 20.000000000000014, 94.10000000000005, 145.9999999999999, -0.9999999999999846, 172.99999999999983, 133.69999999999993, 126.49999999999986, 7.399999999999965, 50.300000000000026, -3.099999999999958, 11.599999999999964, 122.59999999999997, 59.60000000000009, 88.10000000000001, -1.2999999999999847, 3.1999999999999615, 56.300000000000004, 37.399999999999956, 131.59999999999997, 11.599999999999966, -10.899999999999835, 133.99999999999986, 3.1999999999999615, 151.6999999999999, -0.9999999999999846, -9.399999999999855, 13.699999999999964, 178.1, 127.1, 68.60000000000002, 158.6, 13.699999999999964, 9.499999999999966, -5.1999999999999265, 15.799999999999963, 75.19999999999997, 20.000000000000014, -87.10000000000085, -0.9999999999999846, 68.60000000000002, 139.1, 138.5, 9.499999999999964, -13.599999999999783, 11.599999999999964, 20.000000000000014, 1.0999999999999865, 27.20000000000013, 59.900000000000006, -5.1999999999999265, 106.39999999999995, 11.599999999999966, -19.89999999999975, 113.60000000000007, 124.69999999999992, 47.30000000000005, -62.50000000000003, 119.29999999999998, 191.89999999999998, 133.69999999999996, 177.49999999999994, 5.299999999999965, 5.299999999999965, 176.59999999999997, -24.099999999999746, -7.299999999999891, 50.60000000000001, 73.69999999999996, 127.99999999999973, 3.1999999999999615, 7.399999999999965, 136.69999999999996, -28.29999999999975, 98.30000000000001, 9.499999999999964, 150.79999999999995, 67.09999999999997, 92.29999999999998, 9.499999999999964, 17.899999999999988, 169.70000000000002, 175.1, 58.40000000000002, 60.2, 169.69999999999996, -19.899999999999743, 3.1999999999999615, 102.49999999999987, 174.79999999999995, 166.1, 120.79999999999995, 13.699999999999964, -7.299999999999898, 160.09999999999997, 120.20000000000002, 13.699999999999964, -89.80000000000001, 13.699999999999964, 32.3, -3.099999999999958, 100.4, 56.900000000000055, 86.0, -7.299999999999891, 168.19999999999993, 151.39999999999998, 11.599999999999964, 141.2, 1.0999999999999865, 133.40000000000003, -23.799999999999756, 127.4, -21.69999999999976, -17.79999999999975], "policy_predator_policy_reward": [52.0, 10.0, 6.0, 9.0, 13.0, 20.0, 6.0, 13.0, 6.0, 17.0, 19.0, 9.0, 15.0, 3.0, 19.0, 15.0, 30.0, 46.0, 22.0, 35.0, 15.0, 20.0, 153.0, 94.0, 3.0, 20.0, 4.0, 7.0, 21.0, 29.0, 6.0, 12.0, 56.0, 54.0, 97.0, 80.0, 10.0, 32.0, 26.0, 5.0, 44.0, 1.0, 5.0, 5.0, 14.0, 27.0, 0.0, 2.0, 1.0, 3.0, 6.0, 3.0, 28.0, 40.0, 6.0, 10.0, 10.0, 13.0, 10.0, 14.0, 7.0, 36.0, 5.0, 5.0, 7.0, 10.0, 12.0, 4.0, 7.0, 8.0, 37.0, 44.0, 11.0, 0.0, 6.0, 6.0, 13.0, 71.0, 10.0, 6.0, 2.0, 9.0, 9.0, 1.0, 5.0, 5.0, 14.0, 0.0, 0.0, 10.0, 3.0, 14.0, 10.0, 10.0, 29.0, 26.0, 4.0, 0.0, 19.0, 15.0, 9.0, 11.0, 54.0, 13.0, 4.0, 15.0, 17.0, 12.0, 9.0, 7.0, 7.0, 14.0, 6.0, 1.0, 19.0, 22.0, 3.0, 9.0, 12.0, 6.0, 14.0, 33.0, 0.0, 51.0, 10.0, 39.0, 24.0, 6.0, 16.0, 8.0, 4.0, 2.0, 1.0, 9.0, 44.0, 27.0, 14.0, 25.0, 15.0, 19.0, 4.0, 41.0, 76.0, 48.0, 15.0, 11.0, 8.0, 7.0, 7.0, 3.0, 19.0, 16.0, 39.0, 44.0, 8.0, 1.0, 10.0, 15.0, 24.0, 26.0, 3.0, 7.0, 48.0, 53.0, 3.0, 3.0, 0.0, 8.0, 47.0, 29.0, 16.0, 18.0, 13.0, 21.0, 0.0, 11.0, 15.0, 3.0, 11.0, 12.0, 3.0, 17.0, 90.0, 60.0, 49.0, 24.0, 14.0, 33.0, 14.0, 34.0, 13.0, 9.0, 16.0, 4.0, 9.0, 9.0, 28.0, 28.0, 20.0, 23.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6605360340209243, "mean_inference_ms": 2.0729070299594268, "mean_action_processing_ms": 0.30501616322716374, "mean_env_wait_ms": 0.22432046601144223, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004246950149536133, "StateBufferConnector_ms": 0.0034755468368530273, "ViewRequirementAgentConnector_ms": 0.10432684421539307}, "num_episodes": 18, "episode_return_max": 352.79999999999995, "episode_return_min": -21.400000000000027, "episode_return_mean": 133.08299999999977, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 528000, "num_agent_steps_trained": 528000, "num_env_steps_sampled": 132000, "num_env_steps_trained": 132000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 370.7554139880502, "num_env_steps_trained_throughput_per_sec": 370.7554139880502, "timesteps_total": 132000, "num_env_steps_sampled_lifetime": 132000, "num_agent_steps_sampled_lifetime": 528000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 528000, "timers": {"training_iteration_time_ms": 11229.609, "restore_workers_time_ms": 0.015, "training_step_time_ms": 11229.567, "sample_time_ms": 1520.777, "learn_time_ms": 9694.164, "learn_throughput": 412.619, "synch_weights_time_ms": 13.549}, "counters": {"num_env_steps_sampled": 132000, "num_env_steps_trained": 132000, "num_agent_steps_sampled": 528000, "num_agent_steps_trained": 528000}, "done": false, "training_iteration": 33, "trial_id": "3dae5_00000", "date": "2024-08-14_09-12-59", "timestamp": 1723641179, "time_this_iter_s": 10.7933349609375, "time_total_s": 2000.3221175670624, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b116f040>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2000.3221175670624, "iterations_since_restore": 33, "perf": {"cpu_util_percent": 29.118750000000002, "ram_util_percent": 83.52499999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.452185379055442, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.3487448904249404, "policy_loss": -0.010668383416024938, "vf_loss": 1.3582893478807319, "vf_explained_var": 0.10842159459830591, "kl": 0.007492839795392043, "entropy": 1.2581046147952004, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 63315.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6861579442781116, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.14394255378259, "policy_loss": -0.0025313273440583277, "vf_loss": 5.144903938480155, "vf_explained_var": 0.718179434443277, "kl": 0.015699364741405753, "entropy": 1.2884349438248488, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 63315.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 136000, "num_env_steps_trained": 136000, "num_agent_steps_sampled": 544000, "num_agent_steps_trained": 544000}, "env_runners": {"episode_reward_max": 352.79999999999995, "episode_reward_min": -16.099999999999532, "episode_reward_mean": 149.34399999999974, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -89.80000000000001, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 191.89999999999998, "predator_policy": 90.0}, "policy_reward_mean": {"prey_policy": 58.38199999999999, "predator_policy": 16.29}, "custom_metrics": {}, "hist_stats": {"episode_reward": [86.20000000000002, 52.700000000000244, 57.700000000000166, 177.19999999999908, 169.19999999999942, 37.80000000000027, 199.3999999999992, 36.40000000000025, 0.9000000000001858, 20.300000000000004, 177.8999999999992, 81.40000000000002, 157.39999999999966, 37.40000000000026, 23.400000000000027, 163.99999999999946, 161.49999999999918, 218.49999999999972, 11.100000000000092, 159.99999999999935, 51.1000000000002, 275.89999999999986, 182.69999999999922, 32.00000000000018, 205.09999999999926, 128.09999999999968, 154.99999999999932, 323.70000000000005, 153.89999999999932, 102.20000000000005, 138.19999999999953, 181.6999999999995, 21.90000000000001, 160.69999999999993, 162.1999999999995, 152.0999999999993, 170.89999999999924, 10.600000000000094, 198.7999999999993, 236.69999999999996, 184.29999999999936, 22.300000000000015, 137.99999999999963, -16.099999999999532, 116.59999999999985, 307.6, 19.899999999999988, 37.600000000000264, 38.300000000000274, 125.6999999999998, 156.9999999999995, 127.69999999999985, 216.9999999999997, 180.79999999999998, 351.60000000000014, 197.79999999999922, 191.89999999999932, 3.600000000000202, 207.29999999999993, 140.19999999999916, 169.09999999999948, 119.99999999999977, 170.29999999999927, 260.4, 33.4000000000002, 352.79999999999995, 194.59999999999994, 183.79999999999933, 139.69999999999948, 351.9, 152.49999999999952, 175.79999999999941, 153.89999999999944, 73.90000000000013, 102.19999999999996, 204.2999999999999, 126.69999999999982, 341.6, 172.7999999999995, 152.49999999999966, 159.5999999999995, 3.5000000000001807, 22.40000000000001, 155.69999999999953, 287.8999999999999, 320.4000000000001, 186.89999999999932, 188.79999999999936, 208.39999999999927, 135.6999999999997, 338.50000000000006, 146.49999999999955, 285.1999999999998, 14.700000000000022, 183.9999999999994, 198.59999999999926, 162.5999999999995, 13.299999999999908, 266.9, 199.59999999999937], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [8.90000000000012, 35.30000000000003, -33.399999999999764, 55.10000000000012, -3.399999999999951, 16.100000000000072, 3.1999999999999615, 163.99999999999977, 20.000000000000014, 108.2, 15.799999999999963, 20.000000000000014, 17.899999999999988, 177.49999999999994, 20.000000000000014, 7.399999999999965, 11.599999999999964, -78.70000000000086, 1.0999999999999865, 3.1999999999999615, 97.39999999999972, 57.50000000000009, -3.0999999999999615, 60.500000000000014, 52.400000000000084, 62.00000000000004, 7.399999999999965, 20.000000000000014, 7.399999999999965, -0.9999999999999917, 20.000000000000014, 128.00000000000003, 11.599999999999964, 134.89999999999978, 62.000000000000014, 75.5, 3.1999999999999615, -3.099999999999958, 140.59999999999994, 7.399999999999965, -25.599999999999987, -7.299999999999891, 146.3, 113.5999999999999, 168.4999999999999, 3.1999999999999615, 20.90000000000003, 1.0999999999999865, 20.000000000000014, 175.09999999999997, 20.000000000000014, 94.10000000000005, 145.9999999999999, -0.9999999999999846, 172.99999999999983, 133.69999999999993, 126.49999999999986, 7.399999999999965, 50.300000000000026, -3.099999999999958, 11.599999999999964, 122.59999999999997, 59.60000000000009, 88.10000000000001, -1.2999999999999847, 3.1999999999999615, 56.300000000000004, 37.399999999999956, 131.59999999999997, 11.599999999999966, -10.899999999999835, 133.99999999999986, 3.1999999999999615, 151.6999999999999, -0.9999999999999846, -9.399999999999855, 13.699999999999964, 178.1, 127.1, 68.60000000000002, 158.6, 13.699999999999964, 9.499999999999966, -5.1999999999999265, 15.799999999999963, 75.19999999999997, 20.000000000000014, -87.10000000000085, -0.9999999999999846, 68.60000000000002, 139.1, 138.5, 9.499999999999964, -13.599999999999783, 11.599999999999964, 20.000000000000014, 1.0999999999999865, 27.20000000000013, 59.900000000000006, -5.1999999999999265, 106.39999999999995, 11.599999999999966, -19.89999999999975, 113.60000000000007, 124.69999999999992, 47.30000000000005, -62.50000000000003, 119.29999999999998, 191.89999999999998, 133.69999999999996, 177.49999999999994, 5.299999999999965, 5.299999999999965, 176.59999999999997, -24.099999999999746, -7.299999999999891, 50.60000000000001, 73.69999999999996, 127.99999999999973, 3.1999999999999615, 7.399999999999965, 136.69999999999996, -28.29999999999975, 98.30000000000001, 9.499999999999964, 150.79999999999995, 67.09999999999997, 92.29999999999998, 9.499999999999964, 17.899999999999988, 169.70000000000002, 175.1, 58.40000000000002, 60.2, 169.69999999999996, -19.899999999999743, 3.1999999999999615, 102.49999999999987, 174.79999999999995, 166.1, 120.79999999999995, 13.699999999999964, -7.299999999999898, 160.09999999999997, 120.20000000000002, 13.699999999999964, -89.80000000000001, 13.699999999999964, 32.3, -3.099999999999958, 100.4, 56.900000000000055, 86.0, -7.299999999999891, 168.19999999999993, 151.39999999999998, 11.599999999999964, 141.2, 1.0999999999999865, 133.40000000000003, -23.799999999999756, 127.4, -21.69999999999976, -17.79999999999975, 9.499999999999964, -3.099999999999972, 122.00000000000001, 13.699999999999964, 25.70000000000001, 168.19999999999996, 99.19999999999996, 168.2, 1.0999999999999865, 174.79999999999995, 20.000000000000014, 141.8, 184.39999999999998, 20.000000000000014, 83.00000000000003, 13.699999999999964, 134.6, 182.89999999999995, 78.50000000000001, 20.000000000000014, 115.09999999999995, 133.09999999999994, -5.1999999999999265, -3.099999999999958, 5.299999999999965, 166.7, 11.599999999999964, 178.99999999999994, 20.000000000000014, 122.60000000000002, -0.9999999999999846, -51.69999999999994, 19.699999999999996, 153.20000000000002, 20.000000000000014, 170.60000000000002], "policy_predator_policy_reward": [10.0, 32.0, 26.0, 5.0, 44.0, 1.0, 5.0, 5.0, 14.0, 27.0, 0.0, 2.0, 1.0, 3.0, 6.0, 3.0, 28.0, 40.0, 6.0, 10.0, 10.0, 13.0, 10.0, 14.0, 7.0, 36.0, 5.0, 5.0, 7.0, 10.0, 12.0, 4.0, 7.0, 8.0, 37.0, 44.0, 11.0, 0.0, 6.0, 6.0, 13.0, 71.0, 10.0, 6.0, 2.0, 9.0, 9.0, 1.0, 5.0, 5.0, 14.0, 0.0, 0.0, 10.0, 3.0, 14.0, 10.0, 10.0, 29.0, 26.0, 4.0, 0.0, 19.0, 15.0, 9.0, 11.0, 54.0, 13.0, 4.0, 15.0, 17.0, 12.0, 9.0, 7.0, 7.0, 14.0, 6.0, 1.0, 19.0, 22.0, 3.0, 9.0, 12.0, 6.0, 14.0, 33.0, 0.0, 51.0, 10.0, 39.0, 24.0, 6.0, 16.0, 8.0, 4.0, 2.0, 1.0, 9.0, 44.0, 27.0, 14.0, 25.0, 15.0, 19.0, 4.0, 41.0, 76.0, 48.0, 15.0, 11.0, 8.0, 7.0, 7.0, 3.0, 19.0, 16.0, 39.0, 44.0, 8.0, 1.0, 10.0, 15.0, 24.0, 26.0, 3.0, 7.0, 48.0, 53.0, 3.0, 3.0, 0.0, 8.0, 47.0, 29.0, 16.0, 18.0, 13.0, 21.0, 0.0, 11.0, 15.0, 3.0, 11.0, 12.0, 3.0, 17.0, 90.0, 60.0, 49.0, 24.0, 14.0, 33.0, 14.0, 34.0, 13.0, 9.0, 16.0, 4.0, 9.0, 9.0, 28.0, 28.0, 20.0, 23.0, 5.0, 11.0, 3.0, 17.0, 44.0, 50.0, 30.0, 23.0, 2.0, 9.0, 16.0, 11.0, 2.0, 2.0, 7.0, 32.0, 17.0, 4.0, 12.0, 36.0, 22.0, 15.0, 12.0, 11.0, 5.0, 7.0, 5.0, 3.0, 15.0, 5.0, 26.0, 40.0, 42.0, 52.0, 7.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6592844322115781, "mean_inference_ms": 2.0694538279048, "mean_action_processing_ms": 0.30366647858042173, "mean_env_wait_ms": 0.2239397166466145, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004213571548461914, "StateBufferConnector_ms": 0.003714442253112793, "ViewRequirementAgentConnector_ms": 0.10339176654815674}, "num_episodes": 18, "episode_return_max": 352.79999999999995, "episode_return_min": -16.099999999999532, "episode_return_mean": 149.34399999999974, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 544000, "num_agent_steps_trained": 544000, "num_env_steps_sampled": 136000, "num_env_steps_trained": 136000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 354.3522383179796, "num_env_steps_trained_throughput_per_sec": 354.3522383179796, "timesteps_total": 136000, "num_env_steps_sampled_lifetime": 136000, "num_agent_steps_sampled_lifetime": 544000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 544000, "timers": {"training_iteration_time_ms": 11222.841, "restore_workers_time_ms": 0.013, "training_step_time_ms": 11222.8, "sample_time_ms": 1511.026, "learn_time_ms": 9696.403, "learn_throughput": 412.524, "synch_weights_time_ms": 13.784}, "counters": {"num_env_steps_sampled": 136000, "num_env_steps_trained": 136000, "num_agent_steps_sampled": 544000, "num_agent_steps_trained": 544000}, "done": false, "training_iteration": 34, "trial_id": "3dae5_00000", "date": "2024-08-14_09-13-11", "timestamp": 1723641191, "time_this_iter_s": 11.304786205291748, "time_total_s": 2011.6269037723541, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b362cd30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2011.6269037723541, "iterations_since_restore": 34, "perf": {"cpu_util_percent": 29.2625, "ram_util_percent": 83.54375}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.335931133593201, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.8592011587645011, "policy_loss": -0.013896299095173913, "vf_loss": 0.8721013573269365, "vf_explained_var": 0.20734385882735884, "kl": 0.0066406734880581336, "entropy": 1.239716429622085, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 65205.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9840432249837452, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.105462675498276, "policy_loss": -0.0043782259874716005, "vf_loss": 5.108748025995083, "vf_explained_var": 0.7734781866666501, "kl": 0.010928737510511469, "entropy": 1.253159713555896, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 65205.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 140000, "num_env_steps_trained": 140000, "num_agent_steps_sampled": 560000, "num_agent_steps_trained": 560000}, "env_runners": {"episode_reward_max": 352.79999999999995, "episode_reward_min": -16.099999999999532, "episode_reward_mean": 159.10499999999973, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -110.20000000000076, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 191.89999999999998, "predator_policy": 90.0}, "policy_reward_mean": {"prey_policy": 62.9525, "predator_policy": 16.6}, "custom_metrics": {}, "hist_stats": {"episode_reward": [11.100000000000092, 159.99999999999935, 51.1000000000002, 275.89999999999986, 182.69999999999922, 32.00000000000018, 205.09999999999926, 128.09999999999968, 154.99999999999932, 323.70000000000005, 153.89999999999932, 102.20000000000005, 138.19999999999953, 181.6999999999995, 21.90000000000001, 160.69999999999993, 162.1999999999995, 152.0999999999993, 170.89999999999924, 10.600000000000094, 198.7999999999993, 236.69999999999996, 184.29999999999936, 22.300000000000015, 137.99999999999963, -16.099999999999532, 116.59999999999985, 307.6, 19.899999999999988, 37.600000000000264, 38.300000000000274, 125.6999999999998, 156.9999999999995, 127.69999999999985, 216.9999999999997, 180.79999999999998, 351.60000000000014, 197.79999999999922, 191.89999999999932, 3.600000000000202, 207.29999999999993, 140.19999999999916, 169.09999999999948, 119.99999999999977, 170.29999999999927, 260.4, 33.4000000000002, 352.79999999999995, 194.59999999999994, 183.79999999999933, 139.69999999999948, 351.9, 152.49999999999952, 175.79999999999941, 153.89999999999944, 73.90000000000013, 102.19999999999996, 204.2999999999999, 126.69999999999982, 341.6, 172.7999999999995, 152.49999999999966, 159.5999999999995, 3.5000000000001807, 22.40000000000001, 155.69999999999953, 287.8999999999999, 320.4000000000001, 186.89999999999932, 188.79999999999936, 208.39999999999927, 135.6999999999997, 338.50000000000006, 146.49999999999955, 285.1999999999998, 14.700000000000022, 183.9999999999994, 198.59999999999926, 162.5999999999995, 13.299999999999908, 266.9, 199.59999999999937, 140.9999999999997, 198.5999999999992, 34.50000000000022, 196.39999999999986, 180.8999999999994, 229.69999999999987, 182.99999999999926, 308.5000000000001, 277.29999999999984, 137.3999999999997, 140.09999999999962, 134.19999999999953, 1.4999999999999851, 203.7999999999993, 201.3999999999992, -7.499999999999634, 122.0999999999992, 152.4999999999994], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [3.1999999999999615, -3.099999999999958, 140.59999999999994, 7.399999999999965, -25.599999999999987, -7.299999999999891, 146.3, 113.5999999999999, 168.4999999999999, 3.1999999999999615, 20.90000000000003, 1.0999999999999865, 20.000000000000014, 175.09999999999997, 20.000000000000014, 94.10000000000005, 145.9999999999999, -0.9999999999999846, 172.99999999999983, 133.69999999999993, 126.49999999999986, 7.399999999999965, 50.300000000000026, -3.099999999999958, 11.599999999999964, 122.59999999999997, 59.60000000000009, 88.10000000000001, -1.2999999999999847, 3.1999999999999615, 56.300000000000004, 37.399999999999956, 131.59999999999997, 11.599999999999966, -10.899999999999835, 133.99999999999986, 3.1999999999999615, 151.6999999999999, -0.9999999999999846, -9.399999999999855, 13.699999999999964, 178.1, 127.1, 68.60000000000002, 158.6, 13.699999999999964, 9.499999999999966, -5.1999999999999265, 15.799999999999963, 75.19999999999997, 20.000000000000014, -87.10000000000085, -0.9999999999999846, 68.60000000000002, 139.1, 138.5, 9.499999999999964, -13.599999999999783, 11.599999999999964, 20.000000000000014, 1.0999999999999865, 27.20000000000013, 59.900000000000006, -5.1999999999999265, 106.39999999999995, 11.599999999999966, -19.89999999999975, 113.60000000000007, 124.69999999999992, 47.30000000000005, -62.50000000000003, 119.29999999999998, 191.89999999999998, 133.69999999999996, 177.49999999999994, 5.299999999999965, 5.299999999999965, 176.59999999999997, -24.099999999999746, -7.299999999999891, 50.60000000000001, 73.69999999999996, 127.99999999999973, 3.1999999999999615, 7.399999999999965, 136.69999999999996, -28.29999999999975, 98.30000000000001, 9.499999999999964, 150.79999999999995, 67.09999999999997, 92.29999999999998, 9.499999999999964, 17.899999999999988, 169.70000000000002, 175.1, 58.40000000000002, 60.2, 169.69999999999996, -19.899999999999743, 3.1999999999999615, 102.49999999999987, 174.79999999999995, 166.1, 120.79999999999995, 13.699999999999964, -7.299999999999898, 160.09999999999997, 120.20000000000002, 13.699999999999964, -89.80000000000001, 13.699999999999964, 32.3, -3.099999999999958, 100.4, 56.900000000000055, 86.0, -7.299999999999891, 168.19999999999993, 151.39999999999998, 11.599999999999964, 141.2, 1.0999999999999865, 133.40000000000003, -23.799999999999756, 127.4, -21.69999999999976, -17.79999999999975, 9.499999999999964, -3.099999999999972, 122.00000000000001, 13.699999999999964, 25.70000000000001, 168.19999999999996, 99.19999999999996, 168.2, 1.0999999999999865, 174.79999999999995, 20.000000000000014, 141.8, 184.39999999999998, 20.000000000000014, 83.00000000000003, 13.699999999999964, 134.6, 182.89999999999995, 78.50000000000001, 20.000000000000014, 115.09999999999995, 133.09999999999994, -5.1999999999999265, -3.099999999999958, 5.299999999999965, 166.7, 11.599999999999964, 178.99999999999994, 20.000000000000014, 122.60000000000002, -0.9999999999999846, -51.69999999999994, 19.699999999999996, 153.20000000000002, 20.000000000000014, 170.60000000000002, 131.0, -42.99999999999976, -0.9999999999999846, 185.5999999999999, 20.000000000000014, 9.499999999999964, 89.60000000000002, 57.80000000000005, 17.899999999999988, 151.99999999999997, 70.1, 92.6, 163.09999999999997, 17.899999999999988, 126.19999999999996, 161.2999999999999, 42.50000000000003, 183.79999999999995, 1.0999999999999865, 101.30000000000001, 80.30000000000003, 21.80000000000004, 112.69999999999992, -11.499999999999833, -110.20000000000076, 22.700000000000053, 19.100000000000005, 175.7, 13.699999999999964, 184.69999999999993, -17.79999999999974, -15.699999999999747, 15.799999999999963, 71.30000000000001, 122.89999999999989, 11.599999999999964], "policy_predator_policy_reward": [11.0, 0.0, 6.0, 6.0, 13.0, 71.0, 10.0, 6.0, 2.0, 9.0, 9.0, 1.0, 5.0, 5.0, 14.0, 0.0, 0.0, 10.0, 3.0, 14.0, 10.0, 10.0, 29.0, 26.0, 4.0, 0.0, 19.0, 15.0, 9.0, 11.0, 54.0, 13.0, 4.0, 15.0, 17.0, 12.0, 9.0, 7.0, 7.0, 14.0, 6.0, 1.0, 19.0, 22.0, 3.0, 9.0, 12.0, 6.0, 14.0, 33.0, 0.0, 51.0, 10.0, 39.0, 24.0, 6.0, 16.0, 8.0, 4.0, 2.0, 1.0, 9.0, 44.0, 27.0, 14.0, 25.0, 15.0, 19.0, 4.0, 41.0, 76.0, 48.0, 15.0, 11.0, 8.0, 7.0, 7.0, 3.0, 19.0, 16.0, 39.0, 44.0, 8.0, 1.0, 10.0, 15.0, 24.0, 26.0, 3.0, 7.0, 48.0, 53.0, 3.0, 3.0, 0.0, 8.0, 47.0, 29.0, 16.0, 18.0, 13.0, 21.0, 0.0, 11.0, 15.0, 3.0, 11.0, 12.0, 3.0, 17.0, 90.0, 60.0, 49.0, 24.0, 14.0, 33.0, 14.0, 34.0, 13.0, 9.0, 16.0, 4.0, 9.0, 9.0, 28.0, 28.0, 20.0, 23.0, 5.0, 11.0, 3.0, 17.0, 44.0, 50.0, 30.0, 23.0, 2.0, 9.0, 16.0, 11.0, 2.0, 2.0, 7.0, 32.0, 17.0, 4.0, 12.0, 36.0, 22.0, 15.0, 12.0, 11.0, 5.0, 7.0, 5.0, 3.0, 15.0, 5.0, 26.0, 40.0, 42.0, 52.0, 7.0, 2.0, 30.0, 23.0, 4.0, 10.0, 0.0, 5.0, 1.0, 48.0, 2.0, 9.0, 44.0, 23.0, 1.0, 1.0, 21.0, 0.0, 23.0, 28.0, 9.0, 26.0, 16.0, 22.0, 18.0, 15.0, 47.0, 42.0, 3.0, 6.0, 0.0, 3.0, 18.0, 8.0, 11.0, 24.0, 14.0, 4.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6582621135253691, "mean_inference_ms": 2.0655095639633116, "mean_action_processing_ms": 0.3023552611498357, "mean_env_wait_ms": 0.22364475816107368, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004264950752258301, "StateBufferConnector_ms": 0.0036791563034057617, "ViewRequirementAgentConnector_ms": 0.1044994592666626}, "num_episodes": 18, "episode_return_max": 352.79999999999995, "episode_return_min": -16.099999999999532, "episode_return_mean": 159.10499999999973, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 560000, "num_agent_steps_trained": 560000, "num_env_steps_sampled": 140000, "num_env_steps_trained": 140000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 364.3877295287896, "num_env_steps_trained_throughput_per_sec": 364.3877295287896, "timesteps_total": 140000, "num_env_steps_sampled_lifetime": 140000, "num_agent_steps_sampled_lifetime": 560000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 560000, "timers": {"training_iteration_time_ms": 11211.816, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11211.764, "sample_time_ms": 1508.574, "learn_time_ms": 9687.863, "learn_throughput": 412.888, "synch_weights_time_ms": 13.769}, "counters": {"num_env_steps_sampled": 140000, "num_env_steps_trained": 140000, "num_agent_steps_sampled": 560000, "num_agent_steps_trained": 560000}, "done": false, "training_iteration": 35, "trial_id": "3dae5_00000", "date": "2024-08-14_09-13-22", "timestamp": 1723641202, "time_this_iter_s": 10.98275899887085, "time_total_s": 2022.609662771225, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3629d30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2022.609662771225, "iterations_since_restore": 35, "perf": {"cpu_util_percent": 29.91875, "ram_util_percent": 83.36875}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.641129002290428, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.8551643066305332, "policy_loss": -0.008880779939511465, "vf_loss": 1.8628763810352043, "vf_explained_var": 0.0340261266029701, "kl": 0.007791353141712979, "entropy": 1.2199808602610593, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 67095.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8444355535601813, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.91210518791562, "policy_loss": -0.005635799209232487, "vf_loss": 5.916397208763809, "vf_explained_var": 0.5970891022808338, "kl": 0.013437764353801155, "entropy": 1.1795104822153768, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 67095.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 144000, "num_env_steps_trained": 144000, "num_agent_steps_sampled": 576000, "num_agent_steps_trained": 576000}, "env_runners": {"episode_reward_max": 367.0, "episode_reward_min": -205.80000000000098, "episode_reward_mean": 157.66099999999975, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -278.19999999999965, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 191.89999999999998, "predator_policy": 128.0}, "policy_reward_mean": {"prey_policy": 60.40549999999999, "predator_policy": 18.425}, "custom_metrics": {}, "hist_stats": {"episode_reward": [184.29999999999936, 22.300000000000015, 137.99999999999963, -16.099999999999532, 116.59999999999985, 307.6, 19.899999999999988, 37.600000000000264, 38.300000000000274, 125.6999999999998, 156.9999999999995, 127.69999999999985, 216.9999999999997, 180.79999999999998, 351.60000000000014, 197.79999999999922, 191.89999999999932, 3.600000000000202, 207.29999999999993, 140.19999999999916, 169.09999999999948, 119.99999999999977, 170.29999999999927, 260.4, 33.4000000000002, 352.79999999999995, 194.59999999999994, 183.79999999999933, 139.69999999999948, 351.9, 152.49999999999952, 175.79999999999941, 153.89999999999944, 73.90000000000013, 102.19999999999996, 204.2999999999999, 126.69999999999982, 341.6, 172.7999999999995, 152.49999999999966, 159.5999999999995, 3.5000000000001807, 22.40000000000001, 155.69999999999953, 287.8999999999999, 320.4000000000001, 186.89999999999932, 188.79999999999936, 208.39999999999927, 135.6999999999997, 338.50000000000006, 146.49999999999955, 285.1999999999998, 14.700000000000022, 183.9999999999994, 198.59999999999926, 162.5999999999995, 13.299999999999908, 266.9, 199.59999999999937, 140.9999999999997, 198.5999999999992, 34.50000000000022, 196.39999999999986, 180.8999999999994, 229.69999999999987, 182.99999999999926, 308.5000000000001, 277.29999999999984, 137.3999999999997, 140.09999999999962, 134.19999999999953, 1.4999999999999851, 203.7999999999993, 201.3999999999992, -7.499999999999634, 122.0999999999992, 152.4999999999994, 178.49999999999937, 357.20000000000005, 164.4999999999995, 6.4000000000001585, 23.800000000000118, 210.09999999999926, 113.29999999999987, 32.20000000000019, 304.70000000000005, 24.000000000000043, 277.69999999999993, 162.89999999999958, 200.29999999999933, 29.100000000000126, 169.0999999999995, 24.600000000000048, 125.19999999999985, -205.80000000000098, 315.4999999999999, 167.39999999999932, 22.500000000000014, 367.0], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [158.6, 13.699999999999964, 9.499999999999966, -5.1999999999999265, 15.799999999999963, 75.19999999999997, 20.000000000000014, -87.10000000000085, -0.9999999999999846, 68.60000000000002, 139.1, 138.5, 9.499999999999964, -13.599999999999783, 11.599999999999964, 20.000000000000014, 1.0999999999999865, 27.20000000000013, 59.900000000000006, -5.1999999999999265, 106.39999999999995, 11.599999999999966, -19.89999999999975, 113.60000000000007, 124.69999999999992, 47.30000000000005, -62.50000000000003, 119.29999999999998, 191.89999999999998, 133.69999999999996, 177.49999999999994, 5.299999999999965, 5.299999999999965, 176.59999999999997, -24.099999999999746, -7.299999999999891, 50.60000000000001, 73.69999999999996, 127.99999999999973, 3.1999999999999615, 7.399999999999965, 136.69999999999996, -28.29999999999975, 98.30000000000001, 9.499999999999964, 150.79999999999995, 67.09999999999997, 92.29999999999998, 9.499999999999964, 17.899999999999988, 169.70000000000002, 175.1, 58.40000000000002, 60.2, 169.69999999999996, -19.899999999999743, 3.1999999999999615, 102.49999999999987, 174.79999999999995, 166.1, 120.79999999999995, 13.699999999999964, -7.299999999999898, 160.09999999999997, 120.20000000000002, 13.699999999999964, -89.80000000000001, 13.699999999999964, 32.3, -3.099999999999958, 100.4, 56.900000000000055, 86.0, -7.299999999999891, 168.19999999999993, 151.39999999999998, 11.599999999999964, 141.2, 1.0999999999999865, 133.40000000000003, -23.799999999999756, 127.4, -21.69999999999976, -17.79999999999975, 9.499999999999964, -3.099999999999972, 122.00000000000001, 13.699999999999964, 25.70000000000001, 168.19999999999996, 99.19999999999996, 168.2, 1.0999999999999865, 174.79999999999995, 20.000000000000014, 141.8, 184.39999999999998, 20.000000000000014, 83.00000000000003, 13.699999999999964, 134.6, 182.89999999999995, 78.50000000000001, 20.000000000000014, 115.09999999999995, 133.09999999999994, -5.1999999999999265, -3.099999999999958, 5.299999999999965, 166.7, 11.599999999999964, 178.99999999999994, 20.000000000000014, 122.60000000000002, -0.9999999999999846, -51.69999999999994, 19.699999999999996, 153.20000000000002, 20.000000000000014, 170.60000000000002, 131.0, -42.99999999999976, -0.9999999999999846, 185.5999999999999, 20.000000000000014, 9.499999999999964, 89.60000000000002, 57.80000000000005, 17.899999999999988, 151.99999999999997, 70.1, 92.6, 163.09999999999997, 17.899999999999988, 126.19999999999996, 161.2999999999999, 42.50000000000003, 183.79999999999995, 1.0999999999999865, 101.30000000000001, 80.30000000000003, 21.80000000000004, 112.69999999999992, -11.499999999999833, -110.20000000000076, 22.700000000000053, 19.100000000000005, 175.7, 13.699999999999964, 184.69999999999993, -17.79999999999974, -15.699999999999747, 15.799999999999963, 71.30000000000001, 122.89999999999989, 11.599999999999964, 135.49999999999994, 20.000000000000014, 172.1, 175.1, -13.599999999999783, 148.09999999999997, -0.9999999999999917, -13.599999999999783, 83.00000000000003, -194.20000000000041, 13.699999999999964, 190.39999999999998, -70.30000000000086, 131.6, -9.399999999999855, 23.600000000000065, 132.5, 144.2, -21.999999999999744, 20.000000000000014, 112.7, 125.0, 11.599999999999964, 122.30000000000001, 155.3, 20.000000000000014, 7.399999999999965, 13.699999999999964, 158.60000000000002, -23.49999999999975, 3.1999999999999615, 7.399999999999965, 44.59999999999997, 5.599999999999916, -278.19999999999965, -160.60000000000065, 180.8, 112.70000000000005, 123.80000000000001, 20.600000000000026, 1.0999999999999865, 7.399999999999965, 185.59999999999997, 154.4], "policy_predator_policy_reward": [3.0, 9.0, 12.0, 6.0, 14.0, 33.0, 0.0, 51.0, 10.0, 39.0, 24.0, 6.0, 16.0, 8.0, 4.0, 2.0, 1.0, 9.0, 44.0, 27.0, 14.0, 25.0, 15.0, 19.0, 4.0, 41.0, 76.0, 48.0, 15.0, 11.0, 8.0, 7.0, 7.0, 3.0, 19.0, 16.0, 39.0, 44.0, 8.0, 1.0, 10.0, 15.0, 24.0, 26.0, 3.0, 7.0, 48.0, 53.0, 3.0, 3.0, 0.0, 8.0, 47.0, 29.0, 16.0, 18.0, 13.0, 21.0, 0.0, 11.0, 15.0, 3.0, 11.0, 12.0, 3.0, 17.0, 90.0, 60.0, 49.0, 24.0, 14.0, 33.0, 14.0, 34.0, 13.0, 9.0, 16.0, 4.0, 9.0, 9.0, 28.0, 28.0, 20.0, 23.0, 5.0, 11.0, 3.0, 17.0, 44.0, 50.0, 30.0, 23.0, 2.0, 9.0, 16.0, 11.0, 2.0, 2.0, 7.0, 32.0, 17.0, 4.0, 12.0, 36.0, 22.0, 15.0, 12.0, 11.0, 5.0, 7.0, 5.0, 3.0, 15.0, 5.0, 26.0, 40.0, 42.0, 52.0, 7.0, 2.0, 30.0, 23.0, 4.0, 10.0, 0.0, 5.0, 1.0, 48.0, 2.0, 9.0, 44.0, 23.0, 1.0, 1.0, 21.0, 0.0, 23.0, 28.0, 9.0, 26.0, 16.0, 22.0, 18.0, 15.0, 47.0, 42.0, 3.0, 6.0, 0.0, 3.0, 18.0, 8.0, 11.0, 24.0, 14.0, 4.0, 13.0, 10.0, 3.0, 7.0, 16.0, 14.0, 16.0, 5.0, 102.0, 33.0, 3.0, 3.0, 43.0, 9.0, 14.0, 4.0, 12.0, 16.0, 6.0, 20.0, 35.0, 5.0, 25.0, 4.0, 11.0, 14.0, 2.0, 6.0, 12.0, 22.0, 6.0, 8.0, 39.0, 36.0, 105.0, 128.0, 1.0, 21.0, 3.0, 20.0, 9.0, 5.0, 13.0, 14.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6563136632277629, "mean_inference_ms": 2.0601406625721053, "mean_action_processing_ms": 0.2992842520725929, "mean_env_wait_ms": 0.22325781495885771, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004131197929382324, "StateBufferConnector_ms": 0.0036363601684570312, "ViewRequirementAgentConnector_ms": 0.10059058666229248}, "num_episodes": 22, "episode_return_max": 367.0, "episode_return_min": -205.80000000000098, "episode_return_mean": 157.66099999999975, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 576000, "num_agent_steps_trained": 576000, "num_env_steps_sampled": 144000, "num_env_steps_trained": 144000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 372.1887185698749, "num_env_steps_trained_throughput_per_sec": 372.1887185698749, "timesteps_total": 144000, "num_env_steps_sampled_lifetime": 144000, "num_agent_steps_sampled_lifetime": 576000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 576000, "timers": {"training_iteration_time_ms": 11166.938, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11166.887, "sample_time_ms": 1485.911, "learn_time_ms": 9665.494, "learn_throughput": 413.843, "synch_weights_time_ms": 13.982}, "counters": {"num_env_steps_sampled": 144000, "num_env_steps_trained": 144000, "num_agent_steps_sampled": 576000, "num_agent_steps_trained": 576000}, "done": false, "training_iteration": 36, "trial_id": "3dae5_00000", "date": "2024-08-14_09-13-33", "timestamp": 1723641213, "time_this_iter_s": 10.791198015213013, "time_total_s": 2033.400860786438, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0fef700>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2033.400860786438, "iterations_since_restore": 36, "perf": {"cpu_util_percent": 31.080000000000002, "ram_util_percent": 83.67333333333333}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5449377269341202, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.2245241219089145, "policy_loss": -0.01441424065441997, "vf_loss": 1.2376693798593743, "vf_explained_var": 0.2949793046429044, "kl": 0.008459881390937698, "entropy": 1.1996184420964076, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 68985.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.028690222709898, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.630805133385633, "policy_loss": 0.005986559630258295, "vf_loss": 5.621783554743207, "vf_explained_var": 0.7460090068597642, "kl": 0.030350435163853582, "entropy": 1.2410413636101616, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 68985.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 148000, "num_env_steps_trained": 148000, "num_agent_steps_sampled": 592000, "num_agent_steps_trained": 592000}, "env_runners": {"episode_reward_max": 367.0, "episode_reward_min": -205.80000000000098, "episode_reward_mean": 165.7929999999997, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -278.19999999999965, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 190.39999999999998, "predator_policy": 128.0}, "policy_reward_mean": {"prey_policy": 64.19149999999999, "predator_policy": 18.705}, "custom_metrics": {}, "hist_stats": {"episode_reward": [260.4, 33.4000000000002, 352.79999999999995, 194.59999999999994, 183.79999999999933, 139.69999999999948, 351.9, 152.49999999999952, 175.79999999999941, 153.89999999999944, 73.90000000000013, 102.19999999999996, 204.2999999999999, 126.69999999999982, 341.6, 172.7999999999995, 152.49999999999966, 159.5999999999995, 3.5000000000001807, 22.40000000000001, 155.69999999999953, 287.8999999999999, 320.4000000000001, 186.89999999999932, 188.79999999999936, 208.39999999999927, 135.6999999999997, 338.50000000000006, 146.49999999999955, 285.1999999999998, 14.700000000000022, 183.9999999999994, 198.59999999999926, 162.5999999999995, 13.299999999999908, 266.9, 199.59999999999937, 140.9999999999997, 198.5999999999992, 34.50000000000022, 196.39999999999986, 180.8999999999994, 229.69999999999987, 182.99999999999926, 308.5000000000001, 277.29999999999984, 137.3999999999997, 140.09999999999962, 134.19999999999953, 1.4999999999999851, 203.7999999999993, 201.3999999999992, -7.499999999999634, 122.0999999999992, 152.4999999999994, 178.49999999999937, 357.20000000000005, 164.4999999999995, 6.4000000000001585, 23.800000000000118, 210.09999999999926, 113.29999999999987, 32.20000000000019, 304.70000000000005, 24.000000000000043, 277.69999999999993, 162.89999999999958, 200.29999999999933, 29.100000000000126, 169.0999999999995, 24.600000000000048, 125.19999999999985, -205.80000000000098, 315.4999999999999, 167.39999999999932, 22.500000000000014, 367.0, 189.29999999999941, 261.59999999999985, 149.6999999999995, 160.79999999999959, 92.0, 220.39999999999992, 155.89999999999955, 175.19999999999933, 295.5, 102.19999999999993, 178.99999999999937, 336.20000000000016, 144.6999999999997, 129.09999999999965, -13.89999999999954, 142.79999999999967, 326.3999999999998, 135.19999999999968, 143.8999999999997, 208.19999999999933, 168.29999999999947, 157.09999999999923, 162.09999999999957], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [67.09999999999997, 92.29999999999998, 9.499999999999964, 17.899999999999988, 169.70000000000002, 175.1, 58.40000000000002, 60.2, 169.69999999999996, -19.899999999999743, 3.1999999999999615, 102.49999999999987, 174.79999999999995, 166.1, 120.79999999999995, 13.699999999999964, -7.299999999999898, 160.09999999999997, 120.20000000000002, 13.699999999999964, -89.80000000000001, 13.699999999999964, 32.3, -3.099999999999958, 100.4, 56.900000000000055, 86.0, -7.299999999999891, 168.19999999999993, 151.39999999999998, 11.599999999999964, 141.2, 1.0999999999999865, 133.40000000000003, -23.799999999999756, 127.4, -21.69999999999976, -17.79999999999975, 9.499999999999964, -3.099999999999972, 122.00000000000001, 13.699999999999964, 25.70000000000001, 168.19999999999996, 99.19999999999996, 168.2, 1.0999999999999865, 174.79999999999995, 20.000000000000014, 141.8, 184.39999999999998, 20.000000000000014, 83.00000000000003, 13.699999999999964, 134.6, 182.89999999999995, 78.50000000000001, 20.000000000000014, 115.09999999999995, 133.09999999999994, -5.1999999999999265, -3.099999999999958, 5.299999999999965, 166.7, 11.599999999999964, 178.99999999999994, 20.000000000000014, 122.60000000000002, -0.9999999999999846, -51.69999999999994, 19.699999999999996, 153.20000000000002, 20.000000000000014, 170.60000000000002, 131.0, -42.99999999999976, -0.9999999999999846, 185.5999999999999, 20.000000000000014, 9.499999999999964, 89.60000000000002, 57.80000000000005, 17.899999999999988, 151.99999999999997, 70.1, 92.6, 163.09999999999997, 17.899999999999988, 126.19999999999996, 161.2999999999999, 42.50000000000003, 183.79999999999995, 1.0999999999999865, 101.30000000000001, 80.30000000000003, 21.80000000000004, 112.69999999999992, -11.499999999999833, -110.20000000000076, 22.700000000000053, 19.100000000000005, 175.7, 13.699999999999964, 184.69999999999993, -17.79999999999974, -15.699999999999747, 15.799999999999963, 71.30000000000001, 122.89999999999989, 11.599999999999964, 135.49999999999994, 20.000000000000014, 172.1, 175.1, -13.599999999999783, 148.09999999999997, -0.9999999999999917, -13.599999999999783, 83.00000000000003, -194.20000000000041, 13.699999999999964, 190.39999999999998, -70.30000000000086, 131.6, -9.399999999999855, 23.600000000000065, 132.5, 144.2, -21.999999999999744, 20.000000000000014, 112.7, 125.0, 11.599999999999964, 122.30000000000001, 155.3, 20.000000000000014, 7.399999999999965, 13.699999999999964, 158.60000000000002, -23.49999999999975, 3.1999999999999615, 7.399999999999965, 44.59999999999997, 5.599999999999916, -278.19999999999965, -160.60000000000065, 180.8, 112.70000000000005, 123.80000000000001, 20.600000000000026, 1.0999999999999865, 7.399999999999965, 185.59999999999997, 154.4, 17.899999999999988, 166.4, 84.80000000000004, 117.8, -2.199999999999975, 119.89999999999998, 131.0, -5.1999999999999265, 132.79999999999998, -122.80000000000075, 85.40000000000002, 74.0, -17.799999999999756, 145.7, 17.899999999999988, 137.2999999999999, 112.1, 151.4, 15.200000000000038, 20.000000000000014, 17.899999999999988, 154.1, 178.4, 111.79999999999995, 92.0, 13.699999999999964, -3.099999999999958, 87.19999999999993, -68.2000000000009, 5.299999999999965, -49.299999999999905, 139.1, 163.6999999999999, 127.69999999999999, 123.8, -34.5999999999999, 77.9, 20.000000000000014, 189.20000000000002, -0.9999999999999846, 119.9, 19.39999999999999, 155.89999999999972, -17.79999999999974, 20.000000000000014, 118.1], "policy_predator_policy_reward": [48.0, 53.0, 3.0, 3.0, 0.0, 8.0, 47.0, 29.0, 16.0, 18.0, 13.0, 21.0, 0.0, 11.0, 15.0, 3.0, 11.0, 12.0, 3.0, 17.0, 90.0, 60.0, 49.0, 24.0, 14.0, 33.0, 14.0, 34.0, 13.0, 9.0, 16.0, 4.0, 9.0, 9.0, 28.0, 28.0, 20.0, 23.0, 5.0, 11.0, 3.0, 17.0, 44.0, 50.0, 30.0, 23.0, 2.0, 9.0, 16.0, 11.0, 2.0, 2.0, 7.0, 32.0, 17.0, 4.0, 12.0, 36.0, 22.0, 15.0, 12.0, 11.0, 5.0, 7.0, 5.0, 3.0, 15.0, 5.0, 26.0, 40.0, 42.0, 52.0, 7.0, 2.0, 30.0, 23.0, 4.0, 10.0, 0.0, 5.0, 1.0, 48.0, 2.0, 9.0, 44.0, 23.0, 1.0, 1.0, 21.0, 0.0, 23.0, 28.0, 9.0, 26.0, 16.0, 22.0, 18.0, 15.0, 47.0, 42.0, 3.0, 6.0, 0.0, 3.0, 18.0, 8.0, 11.0, 24.0, 14.0, 4.0, 13.0, 10.0, 3.0, 7.0, 16.0, 14.0, 16.0, 5.0, 102.0, 33.0, 3.0, 3.0, 43.0, 9.0, 14.0, 4.0, 12.0, 16.0, 6.0, 20.0, 35.0, 5.0, 25.0, 4.0, 11.0, 14.0, 2.0, 6.0, 12.0, 22.0, 6.0, 8.0, 39.0, 36.0, 105.0, 128.0, 1.0, 21.0, 3.0, 20.0, 9.0, 5.0, 13.0, 14.0, 4.0, 1.0, 33.0, 26.0, 21.0, 11.0, 12.0, 23.0, 68.0, 14.0, 52.0, 9.0, 6.0, 22.0, 9.0, 11.0, 20.0, 12.0, 40.0, 27.0, 6.0, 1.0, 18.0, 28.0, 3.0, 36.0, 11.0, 34.0, 42.0, 7.0, 33.0, 20.0, 18.0, 17.0, 5.0, 41.0, 11.0, 35.0, 10.0, 10.0, 8.0, 21.0, 18.0, 1.0, 13.0, 11.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6543911298697218, "mean_inference_ms": 2.051130816578887, "mean_action_processing_ms": 0.29865658241750015, "mean_env_wait_ms": 0.2224404821016228, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00393366813659668, "StateBufferConnector_ms": 0.0035657882690429688, "ViewRequirementAgentConnector_ms": 0.09644877910614014}, "num_episodes": 23, "episode_return_max": 367.0, "episode_return_min": -205.80000000000098, "episode_return_mean": 165.7929999999997, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 592000, "num_agent_steps_trained": 592000, "num_env_steps_sampled": 148000, "num_env_steps_trained": 148000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 371.4270476481612, "num_env_steps_trained_throughput_per_sec": 371.4270476481612, "timesteps_total": 148000, "num_env_steps_sampled_lifetime": 148000, "num_agent_steps_sampled_lifetime": 592000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 592000, "timers": {"training_iteration_time_ms": 11138.18, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11138.129, "sample_time_ms": 1466.537, "learn_time_ms": 9656.066, "learn_throughput": 414.247, "synch_weights_time_ms": 14.027}, "counters": {"num_env_steps_sampled": 148000, "num_env_steps_trained": 148000, "num_agent_steps_sampled": 592000, "num_agent_steps_trained": 592000}, "done": false, "training_iteration": 37, "trial_id": "3dae5_00000", "date": "2024-08-14_09-13-43", "timestamp": 1723641223, "time_this_iter_s": 10.774351835250854, "time_total_s": 2044.1752126216888, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0fefd30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2044.1752126216888, "iterations_since_restore": 37, "perf": {"cpu_util_percent": 29.740000000000006, "ram_util_percent": 83.66000000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8260208106230176, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.5723441516280805, "policy_loss": -0.01220793005241643, "vf_loss": 3.582731600160952, "vf_explained_var": 0.16713287527599033, "kl": 0.012136533640768771, "entropy": 1.1621904596449837, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 70875.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.425074476823605, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.5907833450055, "policy_loss": -0.002993197567889063, "vf_loss": 6.591817381268456, "vf_explained_var": 0.37018728653589883, "kl": 0.013061041035823017, "entropy": 1.252001654471039, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 70875.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 152000, "num_env_steps_trained": 152000, "num_agent_steps_sampled": 608000, "num_agent_steps_trained": 608000}, "env_runners": {"episode_reward_max": 367.0, "episode_reward_min": -205.80000000000098, "episode_reward_mean": 154.69099999999972, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -278.19999999999965, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 196.39999999999998, "predator_policy": 128.0}, "policy_reward_mean": {"prey_policy": 55.635499999999986, "predator_policy": 21.71}, "custom_metrics": {}, "hist_stats": {"episode_reward": [3.5000000000001807, 22.40000000000001, 155.69999999999953, 287.8999999999999, 320.4000000000001, 186.89999999999932, 188.79999999999936, 208.39999999999927, 135.6999999999997, 338.50000000000006, 146.49999999999955, 285.1999999999998, 14.700000000000022, 183.9999999999994, 198.59999999999926, 162.5999999999995, 13.299999999999908, 266.9, 199.59999999999937, 140.9999999999997, 198.5999999999992, 34.50000000000022, 196.39999999999986, 180.8999999999994, 229.69999999999987, 182.99999999999926, 308.5000000000001, 277.29999999999984, 137.3999999999997, 140.09999999999962, 134.19999999999953, 1.4999999999999851, 203.7999999999993, 201.3999999999992, -7.499999999999634, 122.0999999999992, 152.4999999999994, 178.49999999999937, 357.20000000000005, 164.4999999999995, 6.4000000000001585, 23.800000000000118, 210.09999999999926, 113.29999999999987, 32.20000000000019, 304.70000000000005, 24.000000000000043, 277.69999999999993, 162.89999999999958, 200.29999999999933, 29.100000000000126, 169.0999999999995, 24.600000000000048, 125.19999999999985, -205.80000000000098, 315.4999999999999, 167.39999999999932, 22.500000000000014, 367.0, 189.29999999999941, 261.59999999999985, 149.6999999999995, 160.79999999999959, 92.0, 220.39999999999992, 155.89999999999955, 175.19999999999933, 295.5, 102.19999999999993, 178.99999999999937, 336.20000000000016, 144.6999999999997, 129.09999999999965, -13.89999999999954, 142.79999999999967, 326.3999999999998, 135.19999999999968, 143.8999999999997, 208.19999999999933, 168.29999999999947, 157.09999999999923, 162.09999999999957, 89.39999999999996, 142.3999999999996, 188.19999999999936, -13.10000000000017, 72.9000000000001, 224.39999999999978, 139.9, -60.0000000000001, 157.89999999999964, 8.90000000000012, 159.0999999999996, 95.99999999999984, 212.79999999999924, 147.29999999999933, 308.1999999999998, 108.79999999999983, 283.1000000000001, -44.000000000000085], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-21.69999999999976, -17.79999999999975, 9.499999999999964, -3.099999999999972, 122.00000000000001, 13.699999999999964, 25.70000000000001, 168.19999999999996, 99.19999999999996, 168.2, 1.0999999999999865, 174.79999999999995, 20.000000000000014, 141.8, 184.39999999999998, 20.000000000000014, 83.00000000000003, 13.699999999999964, 134.6, 182.89999999999995, 78.50000000000001, 20.000000000000014, 115.09999999999995, 133.09999999999994, -5.1999999999999265, -3.099999999999958, 5.299999999999965, 166.7, 11.599999999999964, 178.99999999999994, 20.000000000000014, 122.60000000000002, -0.9999999999999846, -51.69999999999994, 19.699999999999996, 153.20000000000002, 20.000000000000014, 170.60000000000002, 131.0, -42.99999999999976, -0.9999999999999846, 185.5999999999999, 20.000000000000014, 9.499999999999964, 89.60000000000002, 57.80000000000005, 17.899999999999988, 151.99999999999997, 70.1, 92.6, 163.09999999999997, 17.899999999999988, 126.19999999999996, 161.2999999999999, 42.50000000000003, 183.79999999999995, 1.0999999999999865, 101.30000000000001, 80.30000000000003, 21.80000000000004, 112.69999999999992, -11.499999999999833, -110.20000000000076, 22.700000000000053, 19.100000000000005, 175.7, 13.699999999999964, 184.69999999999993, -17.79999999999974, -15.699999999999747, 15.799999999999963, 71.30000000000001, 122.89999999999989, 11.599999999999964, 135.49999999999994, 20.000000000000014, 172.1, 175.1, -13.599999999999783, 148.09999999999997, -0.9999999999999917, -13.599999999999783, 83.00000000000003, -194.20000000000041, 13.699999999999964, 190.39999999999998, -70.30000000000086, 131.6, -9.399999999999855, 23.600000000000065, 132.5, 144.2, -21.999999999999744, 20.000000000000014, 112.7, 125.0, 11.599999999999964, 122.30000000000001, 155.3, 20.000000000000014, 7.399999999999965, 13.699999999999964, 158.60000000000002, -23.49999999999975, 3.1999999999999615, 7.399999999999965, 44.59999999999997, 5.599999999999916, -278.19999999999965, -160.60000000000065, 180.8, 112.70000000000005, 123.80000000000001, 20.600000000000026, 1.0999999999999865, 7.399999999999965, 185.59999999999997, 154.4, 17.899999999999988, 166.4, 84.80000000000004, 117.8, -2.199999999999975, 119.89999999999998, 131.0, -5.1999999999999265, 132.79999999999998, -122.80000000000075, 85.40000000000002, 74.0, -17.799999999999756, 145.7, 17.899999999999988, 137.2999999999999, 112.1, 151.4, 15.200000000000038, 20.000000000000014, 17.899999999999988, 154.1, 178.4, 111.79999999999995, 92.0, 13.699999999999964, -3.099999999999958, 87.19999999999993, -68.2000000000009, 5.299999999999965, -49.299999999999905, 139.1, 163.6999999999999, 127.69999999999999, 123.8, -34.5999999999999, 77.9, 20.000000000000014, 189.20000000000002, -0.9999999999999846, 119.9, 19.39999999999999, 155.89999999999972, -17.79999999999974, 20.000000000000014, 118.1, 20.000000000000014, -1.5999999999999943, 37.400000000000006, 20.000000000000014, -7.299999999999891, 177.49999999999997, -39.10000000000011, -64.00000000000014, 127.69999999999997, -143.80000000000067, 71.89999999999998, 66.5, 41.29999999999997, 35.6, -136.60000000000005, -63.40000000000005, 141.50000000000003, 7.399999999999965, 20.000000000000014, -111.1000000000002, -5.1999999999999265, 143.3, 20.000000000000014, -40.0, 7.399999999999965, 196.39999999999998, -110.20000000000078, 168.49999999999983, 133.10000000000002, 157.09999999999994, 175.6999999999999, -271.8999999999994, 125.3, 105.79999999999993, -120.70000000000076, -28.29999999999975], "policy_predator_policy_reward": [20.0, 23.0, 5.0, 11.0, 3.0, 17.0, 44.0, 50.0, 30.0, 23.0, 2.0, 9.0, 16.0, 11.0, 2.0, 2.0, 7.0, 32.0, 17.0, 4.0, 12.0, 36.0, 22.0, 15.0, 12.0, 11.0, 5.0, 7.0, 5.0, 3.0, 15.0, 5.0, 26.0, 40.0, 42.0, 52.0, 7.0, 2.0, 30.0, 23.0, 4.0, 10.0, 0.0, 5.0, 1.0, 48.0, 2.0, 9.0, 44.0, 23.0, 1.0, 1.0, 21.0, 0.0, 23.0, 28.0, 9.0, 26.0, 16.0, 22.0, 18.0, 15.0, 47.0, 42.0, 3.0, 6.0, 0.0, 3.0, 18.0, 8.0, 11.0, 24.0, 14.0, 4.0, 13.0, 10.0, 3.0, 7.0, 16.0, 14.0, 16.0, 5.0, 102.0, 33.0, 3.0, 3.0, 43.0, 9.0, 14.0, 4.0, 12.0, 16.0, 6.0, 20.0, 35.0, 5.0, 25.0, 4.0, 11.0, 14.0, 2.0, 6.0, 12.0, 22.0, 6.0, 8.0, 39.0, 36.0, 105.0, 128.0, 1.0, 21.0, 3.0, 20.0, 9.0, 5.0, 13.0, 14.0, 4.0, 1.0, 33.0, 26.0, 21.0, 11.0, 12.0, 23.0, 68.0, 14.0, 52.0, 9.0, 6.0, 22.0, 9.0, 11.0, 20.0, 12.0, 40.0, 27.0, 6.0, 1.0, 18.0, 28.0, 3.0, 36.0, 11.0, 34.0, 42.0, 7.0, 33.0, 20.0, 18.0, 17.0, 5.0, 41.0, 11.0, 35.0, 10.0, 10.0, 8.0, 21.0, 18.0, 1.0, 13.0, 11.0, 10.0, 61.0, 37.0, 48.0, 5.0, 13.0, 16.0, 74.0, 77.0, 12.0, 46.0, 40.0, 9.0, 54.0, 95.0, 45.0, 6.0, 3.0, 39.0, 61.0, 12.0, 9.0, 69.0, 47.0, 6.0, 3.0, 58.0, 31.0, 5.0, 13.0, 120.0, 85.0, 21.0, 31.0, 55.0, 50.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.652250927841843, "mean_inference_ms": 2.0439198407437438, "mean_action_processing_ms": 0.29705697869002345, "mean_env_wait_ms": 0.221800237223524, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0037473440170288086, "StateBufferConnector_ms": 0.0034564733505249023, "ViewRequirementAgentConnector_ms": 0.09312617778778076}, "num_episodes": 18, "episode_return_max": 367.0, "episode_return_min": -205.80000000000098, "episode_return_mean": 154.69099999999972, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 608000, "num_agent_steps_trained": 608000, "num_env_steps_sampled": 152000, "num_env_steps_trained": 152000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 377.73087554084367, "num_env_steps_trained_throughput_per_sec": 377.73087554084367, "timesteps_total": 152000, "num_env_steps_sampled_lifetime": 152000, "num_agent_steps_sampled_lifetime": 608000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 608000, "timers": {"training_iteration_time_ms": 10968.092, "restore_workers_time_ms": 0.014, "training_step_time_ms": 10968.039, "sample_time_ms": 1381.533, "learn_time_ms": 9571.5, "learn_throughput": 417.907, "synch_weights_time_ms": 13.524}, "counters": {"num_env_steps_sampled": 152000, "num_env_steps_trained": 152000, "num_agent_steps_sampled": 608000, "num_agent_steps_trained": 608000}, "done": false, "training_iteration": 38, "trial_id": "3dae5_00000", "date": "2024-08-14_09-13-54", "timestamp": 1723641234, "time_this_iter_s": 10.596276998519897, "time_total_s": 2054.7714896202087, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0fbdca0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2054.7714896202087, "iterations_since_restore": 38, "perf": {"cpu_util_percent": 28.220000000000002, "ram_util_percent": 83.61999999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.085372538352139, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.9005069384499205, "policy_loss": -0.010672920051390531, "vf_loss": 4.909548249698821, "vf_explained_var": 0.24828468826082017, "kl": 0.010877444368878136, "entropy": 1.1779353156922356, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 72765.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.2171295251795855, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.8798782441981885, "policy_loss": -0.00033431260417851193, "vf_loss": 7.878245227803629, "vf_explained_var": 0.034124589407885514, "kl": 0.013115507170965747, "entropy": 1.2037918976375035, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 72765.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 156000, "num_env_steps_trained": 156000, "num_agent_steps_sampled": 624000, "num_agent_steps_trained": 624000}, "env_runners": {"episode_reward_max": 368.5000000000003, "episode_reward_min": -441.9999999999997, "episode_reward_mean": 126.18999999999973, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -333.9999999999999, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 196.39999999999998, "predator_policy": 184.0}, "policy_reward_mean": {"prey_policy": 34.084999999999965, "predator_policy": 29.01}, "custom_metrics": {}, "hist_stats": {"episode_reward": [199.59999999999937, 140.9999999999997, 198.5999999999992, 34.50000000000022, 196.39999999999986, 180.8999999999994, 229.69999999999987, 182.99999999999926, 308.5000000000001, 277.29999999999984, 137.3999999999997, 140.09999999999962, 134.19999999999953, 1.4999999999999851, 203.7999999999993, 201.3999999999992, -7.499999999999634, 122.0999999999992, 152.4999999999994, 178.49999999999937, 357.20000000000005, 164.4999999999995, 6.4000000000001585, 23.800000000000118, 210.09999999999926, 113.29999999999987, 32.20000000000019, 304.70000000000005, 24.000000000000043, 277.69999999999993, 162.89999999999958, 200.29999999999933, 29.100000000000126, 169.0999999999995, 24.600000000000048, 125.19999999999985, -205.80000000000098, 315.4999999999999, 167.39999999999932, 22.500000000000014, 367.0, 189.29999999999941, 261.59999999999985, 149.6999999999995, 160.79999999999959, 92.0, 220.39999999999992, 155.89999999999955, 175.19999999999933, 295.5, 102.19999999999993, 178.99999999999937, 336.20000000000016, 144.6999999999997, 129.09999999999965, -13.89999999999954, 142.79999999999967, 326.3999999999998, 135.19999999999968, 143.8999999999997, 208.19999999999933, 168.29999999999947, 157.09999999999923, 162.09999999999957, 89.39999999999996, 142.3999999999996, 188.19999999999936, -13.10000000000017, 72.9000000000001, 224.39999999999978, 139.9, -60.0000000000001, 157.89999999999964, 8.90000000000012, 159.0999999999996, 95.99999999999984, 212.79999999999924, 147.29999999999933, 308.1999999999998, 108.79999999999983, 283.1000000000001, -44.000000000000085, -12.800000000000312, 169.0, 194.2999999999993, -77.70000000000086, 122.79999999999993, -441.9999999999997, 179.49999999999932, 34.79999999999986, 368.5000000000003, 127.89999999999989, 168.9, -393.29999999999995, -77.90000000000006, 133.29999999999956, 239.29999999999993, 177.99999999999943, -320.0, -322.7], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 170.60000000000002, 131.0, -42.99999999999976, -0.9999999999999846, 185.5999999999999, 20.000000000000014, 9.499999999999964, 89.60000000000002, 57.80000000000005, 17.899999999999988, 151.99999999999997, 70.1, 92.6, 163.09999999999997, 17.899999999999988, 126.19999999999996, 161.2999999999999, 42.50000000000003, 183.79999999999995, 1.0999999999999865, 101.30000000000001, 80.30000000000003, 21.80000000000004, 112.69999999999992, -11.499999999999833, -110.20000000000076, 22.700000000000053, 19.100000000000005, 175.7, 13.699999999999964, 184.69999999999993, -17.79999999999974, -15.699999999999747, 15.799999999999963, 71.30000000000001, 122.89999999999989, 11.599999999999964, 135.49999999999994, 20.000000000000014, 172.1, 175.1, -13.599999999999783, 148.09999999999997, -0.9999999999999917, -13.599999999999783, 83.00000000000003, -194.20000000000041, 13.699999999999964, 190.39999999999998, -70.30000000000086, 131.6, -9.399999999999855, 23.600000000000065, 132.5, 144.2, -21.999999999999744, 20.000000000000014, 112.7, 125.0, 11.599999999999964, 122.30000000000001, 155.3, 20.000000000000014, 7.399999999999965, 13.699999999999964, 158.60000000000002, -23.49999999999975, 3.1999999999999615, 7.399999999999965, 44.59999999999997, 5.599999999999916, -278.19999999999965, -160.60000000000065, 180.8, 112.70000000000005, 123.80000000000001, 20.600000000000026, 1.0999999999999865, 7.399999999999965, 185.59999999999997, 154.4, 17.899999999999988, 166.4, 84.80000000000004, 117.8, -2.199999999999975, 119.89999999999998, 131.0, -5.1999999999999265, 132.79999999999998, -122.80000000000075, 85.40000000000002, 74.0, -17.799999999999756, 145.7, 17.899999999999988, 137.2999999999999, 112.1, 151.4, 15.200000000000038, 20.000000000000014, 17.899999999999988, 154.1, 178.4, 111.79999999999995, 92.0, 13.699999999999964, -3.099999999999958, 87.19999999999993, -68.2000000000009, 5.299999999999965, -49.299999999999905, 139.1, 163.6999999999999, 127.69999999999999, 123.8, -34.5999999999999, 77.9, 20.000000000000014, 189.20000000000002, -0.9999999999999846, 119.9, 19.39999999999999, 155.89999999999972, -17.79999999999974, 20.000000000000014, 118.1, 20.000000000000014, -1.5999999999999943, 37.400000000000006, 20.000000000000014, -7.299999999999891, 177.49999999999997, -39.10000000000011, -64.00000000000014, 127.69999999999997, -143.80000000000067, 71.89999999999998, 66.5, 41.29999999999997, 35.6, -136.60000000000005, -63.40000000000005, 141.50000000000003, 7.399999999999965, 20.000000000000014, -111.1000000000002, -5.1999999999999265, 143.3, 20.000000000000014, -40.0, 7.399999999999965, 196.39999999999998, -110.20000000000078, 168.49999999999983, 133.10000000000002, 157.09999999999994, 175.6999999999999, -271.8999999999994, 125.3, 105.79999999999993, -120.70000000000076, -28.29999999999975, -148.00000000000068, -11.80000000000001, 77.0, 5.0, 187.39999999999995, -24.099999999999746, -112.30000000000044, -72.40000000000089, 3.200000000000024, 20.599999999999916, -316.00000000000006, -333.9999999999999, 161.89999999999995, -9.399999999999855, -32.20000000000016, -21.999999999999744, 187.99999999999997, 153.49999999999997, 16.699999999999903, 39.20000000000003, 48.800000000000026, 37.10000000000004, -318.7, -325.5999999999999, -168.10000000000005, -83.80000000000001, 44.3, 20.000000000000014, 49.40000000000002, 137.89999999999992, -200.50000000000054, 195.49999999999997, -208.9, -288.1, -231.7, -304.0], "policy_predator_policy_reward": [7.0, 2.0, 30.0, 23.0, 4.0, 10.0, 0.0, 5.0, 1.0, 48.0, 2.0, 9.0, 44.0, 23.0, 1.0, 1.0, 21.0, 0.0, 23.0, 28.0, 9.0, 26.0, 16.0, 22.0, 18.0, 15.0, 47.0, 42.0, 3.0, 6.0, 0.0, 3.0, 18.0, 8.0, 11.0, 24.0, 14.0, 4.0, 13.0, 10.0, 3.0, 7.0, 16.0, 14.0, 16.0, 5.0, 102.0, 33.0, 3.0, 3.0, 43.0, 9.0, 14.0, 4.0, 12.0, 16.0, 6.0, 20.0, 35.0, 5.0, 25.0, 4.0, 11.0, 14.0, 2.0, 6.0, 12.0, 22.0, 6.0, 8.0, 39.0, 36.0, 105.0, 128.0, 1.0, 21.0, 3.0, 20.0, 9.0, 5.0, 13.0, 14.0, 4.0, 1.0, 33.0, 26.0, 21.0, 11.0, 12.0, 23.0, 68.0, 14.0, 52.0, 9.0, 6.0, 22.0, 9.0, 11.0, 20.0, 12.0, 40.0, 27.0, 6.0, 1.0, 18.0, 28.0, 3.0, 36.0, 11.0, 34.0, 42.0, 7.0, 33.0, 20.0, 18.0, 17.0, 5.0, 41.0, 11.0, 35.0, 10.0, 10.0, 8.0, 21.0, 18.0, 1.0, 13.0, 11.0, 10.0, 61.0, 37.0, 48.0, 5.0, 13.0, 16.0, 74.0, 77.0, 12.0, 46.0, 40.0, 9.0, 54.0, 95.0, 45.0, 6.0, 3.0, 39.0, 61.0, 12.0, 9.0, 69.0, 47.0, 6.0, 3.0, 58.0, 31.0, 5.0, 13.0, 120.0, 85.0, 21.0, 31.0, 55.0, 50.0, 80.0, 67.0, 73.0, 14.0, 11.0, 20.0, 7.0, 100.0, 52.0, 47.0, 184.0, 24.0, 14.0, 13.0, 20.0, 69.0, 14.0, 13.0, 14.0, 58.0, 61.0, 22.0, 180.0, 71.0, 109.0, 65.0, 44.0, 25.0, 33.0, 19.0, 104.0, 79.0, 170.0, 7.0, 98.0, 115.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6500380892904718, "mean_inference_ms": 2.036027104825118, "mean_action_processing_ms": 0.29538857073886055, "mean_env_wait_ms": 0.22108956951107386, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0036897659301757812, "StateBufferConnector_ms": 0.0031436681747436523, "ViewRequirementAgentConnector_ms": 0.09182071685791016}, "num_episodes": 18, "episode_return_max": 368.5000000000003, "episode_return_min": -441.9999999999997, "episode_return_mean": 126.18999999999973, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 624000, "num_agent_steps_trained": 624000, "num_env_steps_sampled": 156000, "num_env_steps_trained": 156000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 372.29149331879955, "num_env_steps_trained_throughput_per_sec": 372.29149331879955, "timesteps_total": 156000, "num_env_steps_sampled_lifetime": 156000, "num_agent_steps_sampled_lifetime": 624000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 624000, "timers": {"training_iteration_time_ms": 10947.994, "restore_workers_time_ms": 0.014, "training_step_time_ms": 10947.942, "sample_time_ms": 1363.787, "learn_time_ms": 9569.227, "learn_throughput": 418.007, "synch_weights_time_ms": 13.47}, "counters": {"num_env_steps_sampled": 156000, "num_env_steps_trained": 156000, "num_agent_steps_sampled": 624000, "num_agent_steps_trained": 624000}, "done": false, "training_iteration": 39, "trial_id": "3dae5_00000", "date": "2024-08-14_09-14-05", "timestamp": 1723641245, "time_this_iter_s": 10.74908995628357, "time_total_s": 2065.5205795764923, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0fd7310>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2065.5205795764923, "iterations_since_restore": 39, "perf": {"cpu_util_percent": 28.38, "ram_util_percent": 83.49333333333333}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9325667512479914, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.116642892171466, "policy_loss": -0.013834856603560703, "vf_loss": 7.127393358725088, "vf_explained_var": 0.30256644317082, "kl": 0.020562673763569097, "entropy": 1.1919159713245573, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 74655.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5662064422059943, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.280716012016175, "policy_loss": -0.006305769590966443, "vf_loss": 8.285663885035843, "vf_explained_var": -0.18126269345561033, "kl": 0.009052528558963793, "entropy": 1.239833129272259, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 74655.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 160000, "num_env_steps_trained": 160000, "num_agent_steps_sampled": 640000, "num_agent_steps_trained": 640000}, "env_runners": {"episode_reward_max": 368.5000000000003, "episode_reward_min": -498.79999999999995, "episode_reward_mean": 55.14899999999979, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 196.39999999999998, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -21.155500000000032, "predator_policy": 48.73}, "custom_metrics": {}, "hist_stats": {"episode_reward": [6.4000000000001585, 23.800000000000118, 210.09999999999926, 113.29999999999987, 32.20000000000019, 304.70000000000005, 24.000000000000043, 277.69999999999993, 162.89999999999958, 200.29999999999933, 29.100000000000126, 169.0999999999995, 24.600000000000048, 125.19999999999985, -205.80000000000098, 315.4999999999999, 167.39999999999932, 22.500000000000014, 367.0, 189.29999999999941, 261.59999999999985, 149.6999999999995, 160.79999999999959, 92.0, 220.39999999999992, 155.89999999999955, 175.19999999999933, 295.5, 102.19999999999993, 178.99999999999937, 336.20000000000016, 144.6999999999997, 129.09999999999965, -13.89999999999954, 142.79999999999967, 326.3999999999998, 135.19999999999968, 143.8999999999997, 208.19999999999933, 168.29999999999947, 157.09999999999923, 162.09999999999957, 89.39999999999996, 142.3999999999996, 188.19999999999936, -13.10000000000017, 72.9000000000001, 224.39999999999978, 139.9, -60.0000000000001, 157.89999999999964, 8.90000000000012, 159.0999999999996, 95.99999999999984, 212.79999999999924, 147.29999999999933, 308.1999999999998, 108.79999999999983, 283.1000000000001, -44.000000000000085, -12.800000000000312, 169.0, 194.2999999999993, -77.70000000000086, 122.79999999999993, -441.9999999999997, 179.49999999999932, 34.79999999999986, 368.5000000000003, 127.89999999999989, 168.9, -393.29999999999995, -77.90000000000006, 133.29999999999956, 239.29999999999993, 177.99999999999943, -320.0, -322.7, -1.2000000000000268, -406.1, -67.29999999999995, -84.20000000000002, -138.20000000000041, -405.9, -2.4000000000000057, -400.0, -226.00000000000065, 121.49999999999972, -397.5, -453.0999999999998, 230.5999999999998, -189.20000000000095, -401.9999999999998, 63.199999999999896, -41.79999999999995, 340.60000000000014, 32.29999999999998, -126.70000000000061, -498.79999999999995, -316.70000000000005], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-0.9999999999999917, -13.599999999999783, 83.00000000000003, -194.20000000000041, 13.699999999999964, 190.39999999999998, -70.30000000000086, 131.6, -9.399999999999855, 23.600000000000065, 132.5, 144.2, -21.999999999999744, 20.000000000000014, 112.7, 125.0, 11.599999999999964, 122.30000000000001, 155.3, 20.000000000000014, 7.399999999999965, 13.699999999999964, 158.60000000000002, -23.49999999999975, 3.1999999999999615, 7.399999999999965, 44.59999999999997, 5.599999999999916, -278.19999999999965, -160.60000000000065, 180.8, 112.70000000000005, 123.80000000000001, 20.600000000000026, 1.0999999999999865, 7.399999999999965, 185.59999999999997, 154.4, 17.899999999999988, 166.4, 84.80000000000004, 117.8, -2.199999999999975, 119.89999999999998, 131.0, -5.1999999999999265, 132.79999999999998, -122.80000000000075, 85.40000000000002, 74.0, -17.799999999999756, 145.7, 17.899999999999988, 137.2999999999999, 112.1, 151.4, 15.200000000000038, 20.000000000000014, 17.899999999999988, 154.1, 178.4, 111.79999999999995, 92.0, 13.699999999999964, -3.099999999999958, 87.19999999999993, -68.2000000000009, 5.299999999999965, -49.299999999999905, 139.1, 163.6999999999999, 127.69999999999999, 123.8, -34.5999999999999, 77.9, 20.000000000000014, 189.20000000000002, -0.9999999999999846, 119.9, 19.39999999999999, 155.89999999999972, -17.79999999999974, 20.000000000000014, 118.1, 20.000000000000014, -1.5999999999999943, 37.400000000000006, 20.000000000000014, -7.299999999999891, 177.49999999999997, -39.10000000000011, -64.00000000000014, 127.69999999999997, -143.80000000000067, 71.89999999999998, 66.5, 41.29999999999997, 35.6, -136.60000000000005, -63.40000000000005, 141.50000000000003, 7.399999999999965, 20.000000000000014, -111.1000000000002, -5.1999999999999265, 143.3, 20.000000000000014, -40.0, 7.399999999999965, 196.39999999999998, -110.20000000000078, 168.49999999999983, 133.10000000000002, 157.09999999999994, 175.6999999999999, -271.8999999999994, 125.3, 105.79999999999993, -120.70000000000076, -28.29999999999975, -148.00000000000068, -11.80000000000001, 77.0, 5.0, 187.39999999999995, -24.099999999999746, -112.30000000000044, -72.40000000000089, 3.200000000000024, 20.599999999999916, -316.00000000000006, -333.9999999999999, 161.89999999999995, -9.399999999999855, -32.20000000000016, -21.999999999999744, 187.99999999999997, 153.49999999999997, 16.699999999999903, 39.20000000000003, 48.800000000000026, 37.10000000000004, -318.7, -325.5999999999999, -168.10000000000005, -83.80000000000001, 44.3, 20.000000000000014, 49.40000000000002, 137.89999999999992, -200.50000000000054, 195.49999999999997, -208.9, -288.1, -231.7, -304.0, -194.20000000000002, 46.999999999999986, -392.8, -385.3, 20.000000000000014, -355.30000000000007, -143.50000000000006, -99.69999999999999, 20.000000000000014, -344.2, -393.69999999999993, -383.2, -126.39999999999999, -10.0, -376.29999999999995, -360.70000000000005, -114.40000000000063, -361.6, -53.50000000000019, 95.0, -400.0, -311.50000000000006, -394.0, -375.0999999999999, 70.99999999999996, 113.59999999999998, -40.89999999999976, -385.30000000000007, -297.70000000000005, -325.29999999999995, -32.49999999999975, 13.69999999999999, -80.8, -109.0, 180.19999999999993, 160.39999999999992, -67.60000000000005, -39.10000000000001, -28.299999999999763, -270.4000000000001, -313.0, -389.79999999999995, -315.70000000000005, -394.0], "policy_predator_policy_reward": [16.0, 5.0, 102.0, 33.0, 3.0, 3.0, 43.0, 9.0, 14.0, 4.0, 12.0, 16.0, 6.0, 20.0, 35.0, 5.0, 25.0, 4.0, 11.0, 14.0, 2.0, 6.0, 12.0, 22.0, 6.0, 8.0, 39.0, 36.0, 105.0, 128.0, 1.0, 21.0, 3.0, 20.0, 9.0, 5.0, 13.0, 14.0, 4.0, 1.0, 33.0, 26.0, 21.0, 11.0, 12.0, 23.0, 68.0, 14.0, 52.0, 9.0, 6.0, 22.0, 9.0, 11.0, 20.0, 12.0, 40.0, 27.0, 6.0, 1.0, 18.0, 28.0, 3.0, 36.0, 11.0, 34.0, 42.0, 7.0, 33.0, 20.0, 18.0, 17.0, 5.0, 41.0, 11.0, 35.0, 10.0, 10.0, 8.0, 21.0, 18.0, 1.0, 13.0, 11.0, 10.0, 61.0, 37.0, 48.0, 5.0, 13.0, 16.0, 74.0, 77.0, 12.0, 46.0, 40.0, 9.0, 54.0, 95.0, 45.0, 6.0, 3.0, 39.0, 61.0, 12.0, 9.0, 69.0, 47.0, 6.0, 3.0, 58.0, 31.0, 5.0, 13.0, 120.0, 85.0, 21.0, 31.0, 55.0, 50.0, 80.0, 67.0, 73.0, 14.0, 11.0, 20.0, 7.0, 100.0, 52.0, 47.0, 184.0, 24.0, 14.0, 13.0, 20.0, 69.0, 14.0, 13.0, 14.0, 58.0, 61.0, 22.0, 180.0, 71.0, 109.0, 65.0, 44.0, 25.0, 33.0, 19.0, 104.0, 79.0, 170.0, 7.0, 98.0, 115.0, 1.0, 145.0, 194.0, 178.0, 103.0, 165.0, 64.0, 95.0, 7.0, 179.0, 183.0, 188.0, 25.0, 109.0, 197.0, 140.0, 64.0, 186.0, 33.0, 47.0, 194.0, 120.0, 192.0, 124.0, 46.0, 0.0, 47.0, 190.0, 36.0, 185.0, 25.0, 57.0, 88.0, 60.0, 0.0, 0.0, 61.0, 78.0, 149.0, 23.0, 6.0, 198.0, 193.0, 200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6468227314153593, "mean_inference_ms": 2.026327836344244, "mean_action_processing_ms": 0.2922443644189232, "mean_env_wait_ms": 0.22017508842856548, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003570556640625, "StateBufferConnector_ms": 0.0031011104583740234, "ViewRequirementAgentConnector_ms": 0.09099364280700684}, "num_episodes": 22, "episode_return_max": 368.5000000000003, "episode_return_min": -498.79999999999995, "episode_return_mean": 55.14899999999979, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 640000, "num_agent_steps_trained": 640000, "num_env_steps_sampled": 160000, "num_env_steps_trained": 160000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 371.1729600362686, "num_env_steps_trained_throughput_per_sec": 371.1729600362686, "timesteps_total": 160000, "num_env_steps_sampled_lifetime": 160000, "num_agent_steps_sampled_lifetime": 640000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 640000, "timers": {"training_iteration_time_ms": 10903.813, "restore_workers_time_ms": 0.014, "training_step_time_ms": 10903.76, "sample_time_ms": 1342.833, "learn_time_ms": 9545.809, "learn_throughput": 419.032, "synch_weights_time_ms": 13.663}, "counters": {"num_env_steps_sampled": 160000, "num_env_steps_trained": 160000, "num_agent_steps_sampled": 640000, "num_agent_steps_trained": 640000}, "done": false, "training_iteration": 40, "trial_id": "3dae5_00000", "date": "2024-08-14_09-14-16", "timestamp": 1723641256, "time_this_iter_s": 10.784895896911621, "time_total_s": 2076.305475473404, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0feadc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2076.305475473404, "iterations_since_restore": 40, "perf": {"cpu_util_percent": 27.36875, "ram_util_percent": 83.45000000000002}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.0495347971638673, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.292104256090033, "policy_loss": -0.010950279677848495, "vf_loss": 6.300029213970931, "vf_explained_var": 0.3446824200569637, "kl": 0.013445853559179346, "entropy": 1.1865686743347734, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 76545.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9739229178617872, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.491811465207862, "policy_loss": -0.004552056862376433, "vf_loss": 7.495362523245433, "vf_explained_var": -0.15083831343701276, "kl": 0.006673211596900546, "entropy": 1.2331874631700062, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 76545.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 164000, "num_env_steps_trained": 164000, "num_agent_steps_sampled": 656000, "num_agent_steps_trained": 656000}, "env_runners": {"episode_reward_max": 368.5000000000003, "episode_reward_min": -498.79999999999995, "episode_reward_mean": -2.7290000000001853, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 196.39999999999998, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -65.78950000000005, "predator_policy": 64.425}, "custom_metrics": {}, "hist_stats": {"episode_reward": [92.0, 220.39999999999992, 155.89999999999955, 175.19999999999933, 295.5, 102.19999999999993, 178.99999999999937, 336.20000000000016, 144.6999999999997, 129.09999999999965, -13.89999999999954, 142.79999999999967, 326.3999999999998, 135.19999999999968, 143.8999999999997, 208.19999999999933, 168.29999999999947, 157.09999999999923, 162.09999999999957, 89.39999999999996, 142.3999999999996, 188.19999999999936, -13.10000000000017, 72.9000000000001, 224.39999999999978, 139.9, -60.0000000000001, 157.89999999999964, 8.90000000000012, 159.0999999999996, 95.99999999999984, 212.79999999999924, 147.29999999999933, 308.1999999999998, 108.79999999999983, 283.1000000000001, -44.000000000000085, -12.800000000000312, 169.0, 194.2999999999993, -77.70000000000086, 122.79999999999993, -441.9999999999997, 179.49999999999932, 34.79999999999986, 368.5000000000003, 127.89999999999989, 168.9, -393.29999999999995, -77.90000000000006, 133.29999999999956, 239.29999999999993, 177.99999999999943, -320.0, -322.7, -1.2000000000000268, -406.1, -67.29999999999995, -84.20000000000002, -138.20000000000041, -405.9, -2.4000000000000057, -400.0, -226.00000000000065, 121.49999999999972, -397.5, -453.0999999999998, 230.5999999999998, -189.20000000000095, -401.9999999999998, 63.199999999999896, -41.79999999999995, 340.60000000000014, 32.29999999999998, -126.70000000000061, -498.79999999999995, -316.70000000000005, 192.49999999999935, -200.80000000000086, -475.89999999999964, -388.9, -327.89999999999975, 96.19999999999968, -388.99999999999994, -359.59999999999945, 181.49999999999926, -57.80000000000004, 363.9000000000002, -410.4, 120.99999999999957, -47.999999999999545, -360.30000000000007, -63.90000000000012, -418.3999999999996, 30.900000000000126, -1.4000000000001265, -307.6, 139.49999999999986, 166.59999999999906, -138.60000000000062], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [132.79999999999998, -122.80000000000075, 85.40000000000002, 74.0, -17.799999999999756, 145.7, 17.899999999999988, 137.2999999999999, 112.1, 151.4, 15.200000000000038, 20.000000000000014, 17.899999999999988, 154.1, 178.4, 111.79999999999995, 92.0, 13.699999999999964, -3.099999999999958, 87.19999999999993, -68.2000000000009, 5.299999999999965, -49.299999999999905, 139.1, 163.6999999999999, 127.69999999999999, 123.8, -34.5999999999999, 77.9, 20.000000000000014, 189.20000000000002, -0.9999999999999846, 119.9, 19.39999999999999, 155.89999999999972, -17.79999999999974, 20.000000000000014, 118.1, 20.000000000000014, -1.5999999999999943, 37.400000000000006, 20.000000000000014, -7.299999999999891, 177.49999999999997, -39.10000000000011, -64.00000000000014, 127.69999999999997, -143.80000000000067, 71.89999999999998, 66.5, 41.29999999999997, 35.6, -136.60000000000005, -63.40000000000005, 141.50000000000003, 7.399999999999965, 20.000000000000014, -111.1000000000002, -5.1999999999999265, 143.3, 20.000000000000014, -40.0, 7.399999999999965, 196.39999999999998, -110.20000000000078, 168.49999999999983, 133.10000000000002, 157.09999999999994, 175.6999999999999, -271.8999999999994, 125.3, 105.79999999999993, -120.70000000000076, -28.29999999999975, -148.00000000000068, -11.80000000000001, 77.0, 5.0, 187.39999999999995, -24.099999999999746, -112.30000000000044, -72.40000000000089, 3.200000000000024, 20.599999999999916, -316.00000000000006, -333.9999999999999, 161.89999999999995, -9.399999999999855, -32.20000000000016, -21.999999999999744, 187.99999999999997, 153.49999999999997, 16.699999999999903, 39.20000000000003, 48.800000000000026, 37.10000000000004, -318.7, -325.5999999999999, -168.10000000000005, -83.80000000000001, 44.3, 20.000000000000014, 49.40000000000002, 137.89999999999992, -200.50000000000054, 195.49999999999997, -208.9, -288.1, -231.7, -304.0, -194.20000000000002, 46.999999999999986, -392.8, -385.3, 20.000000000000014, -355.30000000000007, -143.50000000000006, -99.69999999999999, 20.000000000000014, -344.2, -393.69999999999993, -383.2, -126.39999999999999, -10.0, -376.29999999999995, -360.70000000000005, -114.40000000000063, -361.6, -53.50000000000019, 95.0, -400.0, -311.50000000000006, -394.0, -375.0999999999999, 70.99999999999996, 113.59999999999998, -40.89999999999976, -385.30000000000007, -297.70000000000005, -325.29999999999995, -32.49999999999975, 13.69999999999999, -80.8, -109.0, 180.19999999999993, 160.39999999999992, -67.60000000000005, -39.10000000000001, -28.299999999999763, -270.4000000000001, -313.0, -389.79999999999995, -315.70000000000005, -394.0, 184.69999999999996, -26.199999999999747, -150.10000000000065, -288.70000000000005, -339.69999999999976, -359.19999999999993, -335.2, -381.7, -328.5999999999999, -304.29999999999984, 11.600000000000009, 11.599999999999964, -393.69999999999993, -385.3, -262.30000000000007, -277.2999999999994, -87.10000000000085, 185.5999999999999, -288.6999999999989, -3.099999999999958, 184.39999999999992, 177.49999999999994, -384.4, -376.0, 20.000000000000014, 67.99999999999999, -127.00000000000071, -0.9999999999999846, -311.8, -332.5, -128.20000000000005, -84.70000000000007, -261.69999999999993, -342.69999999999993, 74.89999999999996, -169.00000000000063, -64.3000000000001, -27.100000000000094, -379.5999999999999, -271.0, -83.50000000000003, 85.99999999999989, 148.99999999999974, 11.599999999999964, 3.1999999999999615, -368.8], "policy_predator_policy_reward": [68.0, 14.0, 52.0, 9.0, 6.0, 22.0, 9.0, 11.0, 20.0, 12.0, 40.0, 27.0, 6.0, 1.0, 18.0, 28.0, 3.0, 36.0, 11.0, 34.0, 42.0, 7.0, 33.0, 20.0, 18.0, 17.0, 5.0, 41.0, 11.0, 35.0, 10.0, 10.0, 8.0, 21.0, 18.0, 1.0, 13.0, 11.0, 10.0, 61.0, 37.0, 48.0, 5.0, 13.0, 16.0, 74.0, 77.0, 12.0, 46.0, 40.0, 9.0, 54.0, 95.0, 45.0, 6.0, 3.0, 39.0, 61.0, 12.0, 9.0, 69.0, 47.0, 6.0, 3.0, 58.0, 31.0, 5.0, 13.0, 120.0, 85.0, 21.0, 31.0, 55.0, 50.0, 80.0, 67.0, 73.0, 14.0, 11.0, 20.0, 7.0, 100.0, 52.0, 47.0, 184.0, 24.0, 14.0, 13.0, 20.0, 69.0, 14.0, 13.0, 14.0, 58.0, 61.0, 22.0, 180.0, 71.0, 109.0, 65.0, 44.0, 25.0, 33.0, 19.0, 104.0, 79.0, 170.0, 7.0, 98.0, 115.0, 1.0, 145.0, 194.0, 178.0, 103.0, 165.0, 64.0, 95.0, 7.0, 179.0, 183.0, 188.0, 25.0, 109.0, 197.0, 140.0, 64.0, 186.0, 33.0, 47.0, 194.0, 120.0, 192.0, 124.0, 46.0, 0.0, 47.0, 190.0, 36.0, 185.0, 25.0, 57.0, 88.0, 60.0, 0.0, 0.0, 61.0, 78.0, 149.0, 23.0, 6.0, 198.0, 193.0, 200.0, 16.0, 18.0, 102.0, 136.0, 34.0, 189.0, 141.0, 187.0, 147.0, 158.0, 49.0, 24.0, 193.0, 197.0, 162.0, 18.0, 36.0, 47.0, 98.0, 136.0, 1.0, 1.0, 171.0, 179.0, 11.0, 22.0, 47.0, 33.0, 109.0, 175.0, 35.0, 114.0, 185.0, 1.0, 36.0, 89.0, 90.0, 0.0, 176.0, 167.0, 90.0, 47.0, 4.0, 2.0, 189.0, 38.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6442066676633776, "mean_inference_ms": 2.014055462365515, "mean_action_processing_ms": 0.29239721399420743, "mean_env_wait_ms": 0.21913151507312204, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0035979747772216797, "StateBufferConnector_ms": 0.0030814409255981445, "ViewRequirementAgentConnector_ms": 0.09361028671264648}, "num_episodes": 23, "episode_return_max": 368.5000000000003, "episode_return_min": -498.79999999999995, "episode_return_mean": -2.7290000000001853, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 656000, "num_agent_steps_trained": 656000, "num_env_steps_sampled": 164000, "num_env_steps_trained": 164000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 374.9533325774915, "num_env_steps_trained_throughput_per_sec": 374.9533325774915, "timesteps_total": 164000, "num_env_steps_sampled_lifetime": 164000, "num_agent_steps_sampled_lifetime": 656000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 656000, "timers": {"training_iteration_time_ms": 10872.745, "restore_workers_time_ms": 0.014, "training_step_time_ms": 10872.689, "sample_time_ms": 1321.776, "learn_time_ms": 9535.194, "learn_throughput": 419.499, "synch_weights_time_ms": 14.174}, "counters": {"num_env_steps_sampled": 164000, "num_env_steps_trained": 164000, "num_agent_steps_sampled": 656000, "num_agent_steps_trained": 656000}, "done": false, "training_iteration": 41, "trial_id": "3dae5_00000", "date": "2024-08-14_09-14-26", "timestamp": 1723641266, "time_this_iter_s": 10.712646245956421, "time_total_s": 2087.0181217193604, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b36180d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2087.0181217193604, "iterations_since_restore": 41, "perf": {"cpu_util_percent": 28.573333333333338, "ram_util_percent": 83.22000000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.158557370951567, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.682691756758109, "policy_loss": -0.009016693155429075, "vf_loss": 8.689130254775758, "vf_explained_var": 0.3251039071688576, "kl": 0.011458635747586597, "entropy": 1.176203375581711, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 78435.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5419297159979584, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.68579948667496, "policy_loss": -0.004614487762695976, "vf_loss": 8.688929083738378, "vf_explained_var": -0.2229183942552597, "kl": 0.009899064104983786, "entropy": 1.2423676001962531, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 78435.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 168000, "num_env_steps_trained": 168000, "num_agent_steps_sampled": 672000, "num_agent_steps_trained": 672000}, "env_runners": {"episode_reward_max": 368.5000000000003, "episode_reward_min": -506.5, "episode_reward_mean": -77.99000000000015, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 196.39999999999998, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -124.34500000000004, "predator_policy": 85.35}, "custom_metrics": {}, "hist_stats": {"episode_reward": [162.09999999999957, 89.39999999999996, 142.3999999999996, 188.19999999999936, -13.10000000000017, 72.9000000000001, 224.39999999999978, 139.9, -60.0000000000001, 157.89999999999964, 8.90000000000012, 159.0999999999996, 95.99999999999984, 212.79999999999924, 147.29999999999933, 308.1999999999998, 108.79999999999983, 283.1000000000001, -44.000000000000085, -12.800000000000312, 169.0, 194.2999999999993, -77.70000000000086, 122.79999999999993, -441.9999999999997, 179.49999999999932, 34.79999999999986, 368.5000000000003, 127.89999999999989, 168.9, -393.29999999999995, -77.90000000000006, 133.29999999999956, 239.29999999999993, 177.99999999999943, -320.0, -322.7, -1.2000000000000268, -406.1, -67.29999999999995, -84.20000000000002, -138.20000000000041, -405.9, -2.4000000000000057, -400.0, -226.00000000000065, 121.49999999999972, -397.5, -453.0999999999998, 230.5999999999998, -189.20000000000095, -401.9999999999998, 63.199999999999896, -41.79999999999995, 340.60000000000014, 32.29999999999998, -126.70000000000061, -498.79999999999995, -316.70000000000005, 192.49999999999935, -200.80000000000086, -475.89999999999964, -388.9, -327.89999999999975, 96.19999999999968, -388.99999999999994, -359.59999999999945, 181.49999999999926, -57.80000000000004, 363.9000000000002, -410.4, 120.99999999999957, -47.999999999999545, -360.30000000000007, -63.90000000000012, -418.3999999999996, 30.900000000000126, -1.4000000000001265, -307.6, 139.49999999999986, 166.59999999999906, -138.60000000000062, -391.29999999999995, -74.79999999999998, -287.7999999999999, -168.90000000000097, 46.39999999999995, -506.5, -192.80000000000092, -409.1999999999997, -92.10000000000059, -350.5999999999999, -433.1999999999999, -328.4, -16.699999999999907, -327.70000000000005, 114.39999999999944, -409.69999999999993, -241.39999999999998, -357.5999999999999], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 118.1, 20.000000000000014, -1.5999999999999943, 37.400000000000006, 20.000000000000014, -7.299999999999891, 177.49999999999997, -39.10000000000011, -64.00000000000014, 127.69999999999997, -143.80000000000067, 71.89999999999998, 66.5, 41.29999999999997, 35.6, -136.60000000000005, -63.40000000000005, 141.50000000000003, 7.399999999999965, 20.000000000000014, -111.1000000000002, -5.1999999999999265, 143.3, 20.000000000000014, -40.0, 7.399999999999965, 196.39999999999998, -110.20000000000078, 168.49999999999983, 133.10000000000002, 157.09999999999994, 175.6999999999999, -271.8999999999994, 125.3, 105.79999999999993, -120.70000000000076, -28.29999999999975, -148.00000000000068, -11.80000000000001, 77.0, 5.0, 187.39999999999995, -24.099999999999746, -112.30000000000044, -72.40000000000089, 3.200000000000024, 20.599999999999916, -316.00000000000006, -333.9999999999999, 161.89999999999995, -9.399999999999855, -32.20000000000016, -21.999999999999744, 187.99999999999997, 153.49999999999997, 16.699999999999903, 39.20000000000003, 48.800000000000026, 37.10000000000004, -318.7, -325.5999999999999, -168.10000000000005, -83.80000000000001, 44.3, 20.000000000000014, 49.40000000000002, 137.89999999999992, -200.50000000000054, 195.49999999999997, -208.9, -288.1, -231.7, -304.0, -194.20000000000002, 46.999999999999986, -392.8, -385.3, 20.000000000000014, -355.30000000000007, -143.50000000000006, -99.69999999999999, 20.000000000000014, -344.2, -393.69999999999993, -383.2, -126.39999999999999, -10.0, -376.29999999999995, -360.70000000000005, -114.40000000000063, -361.6, -53.50000000000019, 95.0, -400.0, -311.50000000000006, -394.0, -375.0999999999999, 70.99999999999996, 113.59999999999998, -40.89999999999976, -385.30000000000007, -297.70000000000005, -325.29999999999995, -32.49999999999975, 13.69999999999999, -80.8, -109.0, 180.19999999999993, 160.39999999999992, -67.60000000000005, -39.10000000000001, -28.299999999999763, -270.4000000000001, -313.0, -389.79999999999995, -315.70000000000005, -394.0, 184.69999999999996, -26.199999999999747, -150.10000000000065, -288.70000000000005, -339.69999999999976, -359.19999999999993, -335.2, -381.7, -328.5999999999999, -304.29999999999984, 11.600000000000009, 11.599999999999964, -393.69999999999993, -385.3, -262.30000000000007, -277.2999999999994, -87.10000000000085, 185.5999999999999, -288.6999999999989, -3.099999999999958, 184.39999999999992, 177.49999999999994, -384.4, -376.0, 20.000000000000014, 67.99999999999999, -127.00000000000071, -0.9999999999999846, -311.8, -332.5, -128.20000000000005, -84.70000000000007, -261.69999999999993, -342.69999999999993, 74.89999999999996, -169.00000000000063, -64.3000000000001, -27.100000000000094, -379.5999999999999, -271.0, -83.50000000000003, 85.99999999999989, 148.99999999999974, 11.599999999999964, 3.1999999999999615, -368.8, -334.29999999999995, -382.0, -381.1, -81.7, -314.7999999999999, -304.0, -284.8000000000002, -87.10000000000082, -21.69999999999997, -34.9, -379.9, -358.6, -384.4, -51.400000000000006, -340.2999999999997, -319.9, -386.5, 7.399999999999965, -287.8, -350.79999999999995, -311.49999999999994, -381.69999999999993, -348.69999999999993, -342.7, -393.70000000000005, 20.000000000000014, -295.0, -291.70000000000005, 20.000000000000014, -1.6000000000000512, -393.69999999999993, -400.0, -247.89999999999998, -272.5, -241.0, -376.6], "policy_predator_policy_reward": [13.0, 11.0, 10.0, 61.0, 37.0, 48.0, 5.0, 13.0, 16.0, 74.0, 77.0, 12.0, 46.0, 40.0, 9.0, 54.0, 95.0, 45.0, 6.0, 3.0, 39.0, 61.0, 12.0, 9.0, 69.0, 47.0, 6.0, 3.0, 58.0, 31.0, 5.0, 13.0, 120.0, 85.0, 21.0, 31.0, 55.0, 50.0, 80.0, 67.0, 73.0, 14.0, 11.0, 20.0, 7.0, 100.0, 52.0, 47.0, 184.0, 24.0, 14.0, 13.0, 20.0, 69.0, 14.0, 13.0, 14.0, 58.0, 61.0, 22.0, 180.0, 71.0, 109.0, 65.0, 44.0, 25.0, 33.0, 19.0, 104.0, 79.0, 170.0, 7.0, 98.0, 115.0, 1.0, 145.0, 194.0, 178.0, 103.0, 165.0, 64.0, 95.0, 7.0, 179.0, 183.0, 188.0, 25.0, 109.0, 197.0, 140.0, 64.0, 186.0, 33.0, 47.0, 194.0, 120.0, 192.0, 124.0, 46.0, 0.0, 47.0, 190.0, 36.0, 185.0, 25.0, 57.0, 88.0, 60.0, 0.0, 0.0, 61.0, 78.0, 149.0, 23.0, 6.0, 198.0, 193.0, 200.0, 16.0, 18.0, 102.0, 136.0, 34.0, 189.0, 141.0, 187.0, 147.0, 158.0, 49.0, 24.0, 193.0, 197.0, 162.0, 18.0, 36.0, 47.0, 98.0, 136.0, 1.0, 1.0, 171.0, 179.0, 11.0, 22.0, 47.0, 33.0, 109.0, 175.0, 35.0, 114.0, 185.0, 1.0, 36.0, 89.0, 90.0, 0.0, 176.0, 167.0, 90.0, 47.0, 4.0, 2.0, 189.0, 38.0, 138.0, 187.0, 197.0, 191.0, 164.0, 167.0, 51.0, 152.0, 99.0, 4.0, 180.0, 52.0, 50.0, 193.0, 174.0, 77.0, 183.0, 104.0, 119.0, 169.0, 87.0, 173.0, 199.0, 164.0, 179.0, 178.0, 109.0, 150.0, 43.0, 53.0, 184.0, 200.0, 136.0, 143.0, 111.0, 149.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.642407770085054, "mean_inference_ms": 2.0084615419049543, "mean_action_processing_ms": 0.2901749249772351, "mean_env_wait_ms": 0.21823233473647943, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0035625696182250977, "StateBufferConnector_ms": 0.0030689239501953125, "ViewRequirementAgentConnector_ms": 0.09377861022949219}, "num_episodes": 18, "episode_return_max": 368.5000000000003, "episode_return_min": -506.5, "episode_return_mean": -77.99000000000015, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 672000, "num_agent_steps_trained": 672000, "num_env_steps_sampled": 168000, "num_env_steps_trained": 168000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 358.678510010031, "num_env_steps_trained_throughput_per_sec": 358.678510010031, "timesteps_total": 168000, "num_env_steps_sampled_lifetime": 168000, "num_agent_steps_sampled_lifetime": 672000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 672000, "timers": {"training_iteration_time_ms": 10850.149, "restore_workers_time_ms": 0.014, "training_step_time_ms": 10850.082, "sample_time_ms": 1321.95, "learn_time_ms": 9512.383, "learn_throughput": 420.504, "synch_weights_time_ms": 14.141}, "counters": {"num_env_steps_sampled": 168000, "num_env_steps_trained": 168000, "num_agent_steps_sampled": 672000, "num_agent_steps_trained": 672000}, "done": false, "training_iteration": 42, "trial_id": "3dae5_00000", "date": "2024-08-14_09-14-38", "timestamp": 1723641278, "time_this_iter_s": 11.188879013061523, "time_total_s": 2098.207000732422, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0fd18b0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2098.207000732422, "iterations_since_restore": 42, "perf": {"cpu_util_percent": 31.043750000000003, "ram_util_percent": 83.69999999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7402230552264621, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.583082942861728, "policy_loss": -0.006099626420203734, "vf_loss": 7.587534243719919, "vf_explained_var": 0.40910135961714245, "kl": 0.007325816720060806, "entropy": 1.1820938691891059, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 80325.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5347671684291628, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.483583722291169, "policy_loss": -0.0059877623567387225, "vf_loss": 8.488242238917678, "vf_explained_var": -0.18431164549772072, "kl": 0.008861688595648797, "entropy": 1.2250628268277204, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 80325.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 172000, "num_env_steps_trained": 172000, "num_agent_steps_sampled": 688000, "num_agent_steps_trained": 688000}, "env_runners": {"episode_reward_max": 368.5000000000003, "episode_reward_min": -506.5, "episode_reward_mean": -145.92500000000015, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 195.49999999999997, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -175.09750000000003, "predator_policy": 102.135}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-44.000000000000085, -12.800000000000312, 169.0, 194.2999999999993, -77.70000000000086, 122.79999999999993, -441.9999999999997, 179.49999999999932, 34.79999999999986, 368.5000000000003, 127.89999999999989, 168.9, -393.29999999999995, -77.90000000000006, 133.29999999999956, 239.29999999999993, 177.99999999999943, -320.0, -322.7, -1.2000000000000268, -406.1, -67.29999999999995, -84.20000000000002, -138.20000000000041, -405.9, -2.4000000000000057, -400.0, -226.00000000000065, 121.49999999999972, -397.5, -453.0999999999998, 230.5999999999998, -189.20000000000095, -401.9999999999998, 63.199999999999896, -41.79999999999995, 340.60000000000014, 32.29999999999998, -126.70000000000061, -498.79999999999995, -316.70000000000005, 192.49999999999935, -200.80000000000086, -475.89999999999964, -388.9, -327.89999999999975, 96.19999999999968, -388.99999999999994, -359.59999999999945, 181.49999999999926, -57.80000000000004, 363.9000000000002, -410.4, 120.99999999999957, -47.999999999999545, -360.30000000000007, -63.90000000000012, -418.3999999999996, 30.900000000000126, -1.4000000000001265, -307.6, 139.49999999999986, 166.59999999999906, -138.60000000000062, -391.29999999999995, -74.79999999999998, -287.7999999999999, -168.90000000000097, 46.39999999999995, -506.5, -192.80000000000092, -409.1999999999997, -92.10000000000059, -350.5999999999999, -433.1999999999999, -328.4, -16.699999999999907, -327.70000000000005, 114.39999999999944, -409.69999999999993, -241.39999999999998, -357.5999999999999, -344.5, -485.9, -229.20000000000005, -325.20000000000005, -415.8, -196.70000000000076, -242.10000000000005, -239.40000000000077, 193.8999999999998, -437.9, -379.9000000000001, -382.79999999999995, -167.90000000000072, -179.70000000000093, -19.1999999999999, -157.70000000000073, 94.49999999999962, -449.69999999999993], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-120.70000000000076, -28.29999999999975, -148.00000000000068, -11.80000000000001, 77.0, 5.0, 187.39999999999995, -24.099999999999746, -112.30000000000044, -72.40000000000089, 3.200000000000024, 20.599999999999916, -316.00000000000006, -333.9999999999999, 161.89999999999995, -9.399999999999855, -32.20000000000016, -21.999999999999744, 187.99999999999997, 153.49999999999997, 16.699999999999903, 39.20000000000003, 48.800000000000026, 37.10000000000004, -318.7, -325.5999999999999, -168.10000000000005, -83.80000000000001, 44.3, 20.000000000000014, 49.40000000000002, 137.89999999999992, -200.50000000000054, 195.49999999999997, -208.9, -288.1, -231.7, -304.0, -194.20000000000002, 46.999999999999986, -392.8, -385.3, 20.000000000000014, -355.30000000000007, -143.50000000000006, -99.69999999999999, 20.000000000000014, -344.2, -393.69999999999993, -383.2, -126.39999999999999, -10.0, -376.29999999999995, -360.70000000000005, -114.40000000000063, -361.6, -53.50000000000019, 95.0, -400.0, -311.50000000000006, -394.0, -375.0999999999999, 70.99999999999996, 113.59999999999998, -40.89999999999976, -385.30000000000007, -297.70000000000005, -325.29999999999995, -32.49999999999975, 13.69999999999999, -80.8, -109.0, 180.19999999999993, 160.39999999999992, -67.60000000000005, -39.10000000000001, -28.299999999999763, -270.4000000000001, -313.0, -389.79999999999995, -315.70000000000005, -394.0, 184.69999999999996, -26.199999999999747, -150.10000000000065, -288.70000000000005, -339.69999999999976, -359.19999999999993, -335.2, -381.7, -328.5999999999999, -304.29999999999984, 11.600000000000009, 11.599999999999964, -393.69999999999993, -385.3, -262.30000000000007, -277.2999999999994, -87.10000000000085, 185.5999999999999, -288.6999999999989, -3.099999999999958, 184.39999999999992, 177.49999999999994, -384.4, -376.0, 20.000000000000014, 67.99999999999999, -127.00000000000071, -0.9999999999999846, -311.8, -332.5, -128.20000000000005, -84.70000000000007, -261.69999999999993, -342.69999999999993, 74.89999999999996, -169.00000000000063, -64.3000000000001, -27.100000000000094, -379.5999999999999, -271.0, -83.50000000000003, 85.99999999999989, 148.99999999999974, 11.599999999999964, 3.1999999999999615, -368.8, -334.29999999999995, -382.0, -381.1, -81.7, -314.7999999999999, -304.0, -284.8000000000002, -87.10000000000082, -21.69999999999997, -34.9, -379.9, -358.6, -384.4, -51.400000000000006, -340.2999999999997, -319.9, -386.5, 7.399999999999965, -287.8, -350.79999999999995, -311.49999999999994, -381.69999999999993, -348.69999999999993, -342.7, -393.70000000000005, 20.000000000000014, -295.0, -291.70000000000005, 20.000000000000014, -1.6000000000000512, -393.69999999999993, -400.0, -247.89999999999998, -272.5, -241.0, -376.6, -262.0, -272.5, -385.9, -400.0, -236.8, -258.40000000000003, -296.5, -393.70000000000005, -374.8, -352.0, -66.10000000000072, -355.59999999999997, -223.90000000000006, -170.20000000000002, -400.0, -93.40000000000076, 83.6, 59.30000000000001, -395.79999999999995, -381.1, -359.20000000000005, -369.70000000000005, -393.69999999999993, -360.1, -40.89999999999976, -334.0, -358.5999999999999, -24.099999999999746, -266.20000000000005, 20.000000000000014, -108.10000000000075, -259.6, -383.1999999999998, 133.69999999999965, -371.8, -355.9], "policy_predator_policy_reward": [55.0, 50.0, 80.0, 67.0, 73.0, 14.0, 11.0, 20.0, 7.0, 100.0, 52.0, 47.0, 184.0, 24.0, 14.0, 13.0, 20.0, 69.0, 14.0, 13.0, 14.0, 58.0, 61.0, 22.0, 180.0, 71.0, 109.0, 65.0, 44.0, 25.0, 33.0, 19.0, 104.0, 79.0, 170.0, 7.0, 98.0, 115.0, 1.0, 145.0, 194.0, 178.0, 103.0, 165.0, 64.0, 95.0, 7.0, 179.0, 183.0, 188.0, 25.0, 109.0, 197.0, 140.0, 64.0, 186.0, 33.0, 47.0, 194.0, 120.0, 192.0, 124.0, 46.0, 0.0, 47.0, 190.0, 36.0, 185.0, 25.0, 57.0, 88.0, 60.0, 0.0, 0.0, 61.0, 78.0, 149.0, 23.0, 6.0, 198.0, 193.0, 200.0, 16.0, 18.0, 102.0, 136.0, 34.0, 189.0, 141.0, 187.0, 147.0, 158.0, 49.0, 24.0, 193.0, 197.0, 162.0, 18.0, 36.0, 47.0, 98.0, 136.0, 1.0, 1.0, 171.0, 179.0, 11.0, 22.0, 47.0, 33.0, 109.0, 175.0, 35.0, 114.0, 185.0, 1.0, 36.0, 89.0, 90.0, 0.0, 176.0, 167.0, 90.0, 47.0, 4.0, 2.0, 189.0, 38.0, 138.0, 187.0, 197.0, 191.0, 164.0, 167.0, 51.0, 152.0, 99.0, 4.0, 180.0, 52.0, 50.0, 193.0, 174.0, 77.0, 183.0, 104.0, 119.0, 169.0, 87.0, 173.0, 199.0, 164.0, 179.0, 178.0, 109.0, 150.0, 43.0, 53.0, 184.0, 200.0, 136.0, 143.0, 111.0, 149.0, 152.0, 38.0, 100.0, 200.0, 147.0, 119.0, 179.0, 186.0, 193.0, 118.0, 41.0, 184.0, 152.0, 0.0, 54.0, 200.0, 38.0, 13.0, 200.0, 139.0, 178.0, 171.0, 173.0, 198.0, 29.0, 178.0, 182.0, 21.0, 86.0, 141.0, 149.0, 61.0, 181.0, 163.0, 136.0, 142.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6407289966997268, "mean_inference_ms": 2.0016625247160884, "mean_action_processing_ms": 0.2888317186943092, "mean_env_wait_ms": 0.21752664580573988, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003582477569580078, "StateBufferConnector_ms": 0.0030843019485473633, "ViewRequirementAgentConnector_ms": 0.09674227237701416}, "num_episodes": 18, "episode_return_max": 368.5000000000003, "episode_return_min": -506.5, "episode_return_mean": -145.92500000000015, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 688000, "num_agent_steps_trained": 688000, "num_env_steps_sampled": 172000, "num_env_steps_trained": 172000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 359.8650355111455, "num_env_steps_trained_throughput_per_sec": 359.8650355111455, "timesteps_total": 172000, "num_env_steps_sampled_lifetime": 172000, "num_agent_steps_sampled_lifetime": 688000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 688000, "timers": {"training_iteration_time_ms": 10882.798, "restore_workers_time_ms": 0.014, "training_step_time_ms": 10882.731, "sample_time_ms": 1301.639, "learn_time_ms": 9565.702, "learn_throughput": 418.161, "synch_weights_time_ms": 13.783}, "counters": {"num_env_steps_sampled": 172000, "num_env_steps_trained": 172000, "num_agent_steps_sampled": 688000, "num_agent_steps_trained": 688000}, "done": false, "training_iteration": 43, "trial_id": "3dae5_00000", "date": "2024-08-14_09-14-49", "timestamp": 1723641289, "time_this_iter_s": 11.147934913635254, "time_total_s": 2109.354935646057, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0feae50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2109.354935646057, "iterations_since_restore": 43, "perf": {"cpu_util_percent": 30.787499999999998, "ram_util_percent": 83.73750000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9501972658924325, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.451530874847735, "policy_loss": -0.008849943079369723, "vf_loss": 7.457974505802942, "vf_explained_var": 0.38918947804541815, "kl": 0.010694743022028731, "entropy": 1.1776118795707744, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 82215.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4419274193584604, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.6521381895378155, "policy_loss": -0.005682388845604485, "vf_loss": 7.656053412402118, "vf_explained_var": -0.37559651552684725, "kl": 0.011781115685273598, "entropy": 1.1995933255190572, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 82215.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 176000, "num_env_steps_trained": 176000, "num_agent_steps_sampled": 704000, "num_agent_steps_trained": 704000}, "env_runners": {"episode_reward_max": 363.9000000000002, "episode_reward_min": -506.5, "episode_reward_mean": -183.86300000000014, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 190.99999999999994, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -206.5165, "predator_policy": 114.585}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-322.7, -1.2000000000000268, -406.1, -67.29999999999995, -84.20000000000002, -138.20000000000041, -405.9, -2.4000000000000057, -400.0, -226.00000000000065, 121.49999999999972, -397.5, -453.0999999999998, 230.5999999999998, -189.20000000000095, -401.9999999999998, 63.199999999999896, -41.79999999999995, 340.60000000000014, 32.29999999999998, -126.70000000000061, -498.79999999999995, -316.70000000000005, 192.49999999999935, -200.80000000000086, -475.89999999999964, -388.9, -327.89999999999975, 96.19999999999968, -388.99999999999994, -359.59999999999945, 181.49999999999926, -57.80000000000004, 363.9000000000002, -410.4, 120.99999999999957, -47.999999999999545, -360.30000000000007, -63.90000000000012, -418.3999999999996, 30.900000000000126, -1.4000000000001265, -307.6, 139.49999999999986, 166.59999999999906, -138.60000000000062, -391.29999999999995, -74.79999999999998, -287.7999999999999, -168.90000000000097, 46.39999999999995, -506.5, -192.80000000000092, -409.1999999999997, -92.10000000000059, -350.5999999999999, -433.1999999999999, -328.4, -16.699999999999907, -327.70000000000005, 114.39999999999944, -409.69999999999993, -241.39999999999998, -357.5999999999999, -344.5, -485.9, -229.20000000000005, -325.20000000000005, -415.8, -196.70000000000076, -242.10000000000005, -239.40000000000077, 193.8999999999998, -437.9, -379.9000000000001, -382.79999999999995, -167.90000000000072, -179.70000000000093, -19.1999999999999, -157.70000000000073, 94.49999999999962, -449.69999999999993, -189.29999999999995, -331.2999999999996, 135.59999999999957, -353.30000000000007, 262.5999999999997, -367.1, -243.70000000000005, -366.59999999999997, -172.20000000000076, -325.2999999999996, -429.39999999999986, -94.10000000000022, 187.39999999999932, -34.09999999999985, -182.2000000000008, -399.9999999999998, -306.0, -36.19999999999986], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-231.7, -304.0, -194.20000000000002, 46.999999999999986, -392.8, -385.3, 20.000000000000014, -355.30000000000007, -143.50000000000006, -99.69999999999999, 20.000000000000014, -344.2, -393.69999999999993, -383.2, -126.39999999999999, -10.0, -376.29999999999995, -360.70000000000005, -114.40000000000063, -361.6, -53.50000000000019, 95.0, -400.0, -311.50000000000006, -394.0, -375.0999999999999, 70.99999999999996, 113.59999999999998, -40.89999999999976, -385.30000000000007, -297.70000000000005, -325.29999999999995, -32.49999999999975, 13.69999999999999, -80.8, -109.0, 180.19999999999993, 160.39999999999992, -67.60000000000005, -39.10000000000001, -28.299999999999763, -270.4000000000001, -313.0, -389.79999999999995, -315.70000000000005, -394.0, 184.69999999999996, -26.199999999999747, -150.10000000000065, -288.70000000000005, -339.69999999999976, -359.19999999999993, -335.2, -381.7, -328.5999999999999, -304.29999999999984, 11.600000000000009, 11.599999999999964, -393.69999999999993, -385.3, -262.30000000000007, -277.2999999999994, -87.10000000000085, 185.5999999999999, -288.6999999999989, -3.099999999999958, 184.39999999999992, 177.49999999999994, -384.4, -376.0, 20.000000000000014, 67.99999999999999, -127.00000000000071, -0.9999999999999846, -311.8, -332.5, -128.20000000000005, -84.70000000000007, -261.69999999999993, -342.69999999999993, 74.89999999999996, -169.00000000000063, -64.3000000000001, -27.100000000000094, -379.5999999999999, -271.0, -83.50000000000003, 85.99999999999989, 148.99999999999974, 11.599999999999964, 3.1999999999999615, -368.8, -334.29999999999995, -382.0, -381.1, -81.7, -314.7999999999999, -304.0, -284.8000000000002, -87.10000000000082, -21.69999999999997, -34.9, -379.9, -358.6, -384.4, -51.400000000000006, -340.2999999999997, -319.9, -386.5, 7.399999999999965, -287.8, -350.79999999999995, -311.49999999999994, -381.69999999999993, -348.69999999999993, -342.7, -393.70000000000005, 20.000000000000014, -295.0, -291.70000000000005, 20.000000000000014, -1.6000000000000512, -393.69999999999993, -400.0, -247.89999999999998, -272.5, -241.0, -376.6, -262.0, -272.5, -385.9, -400.0, -236.8, -258.40000000000003, -296.5, -393.70000000000005, -374.8, -352.0, -66.10000000000072, -355.59999999999997, -223.90000000000006, -170.20000000000002, -400.0, -93.40000000000076, 83.6, 59.30000000000001, -395.79999999999995, -381.1, -359.20000000000005, -369.70000000000005, -393.69999999999993, -360.1, -40.89999999999976, -334.0, -358.5999999999999, -24.099999999999746, -266.20000000000005, 20.000000000000014, -108.10000000000075, -259.6, -383.1999999999998, 133.69999999999965, -371.8, -355.9, -171.10000000000005, -335.19999999999993, -365.79999999999995, -344.49999999999966, 190.99999999999994, -198.40000000000055, -334.30000000000007, -337.00000000000006, 93.80000000000001, 165.79999999999984, -336.1, -373.0, -316.59999999999997, -216.10000000000002, -400.0, -286.6, -95.50000000000082, -282.70000000000005, -385.0, -304.2999999999996, -393.69999999999993, -378.69999999999993, -19.899999999999764, -236.20000000000005, 185.89999999999995, -53.50000000000009, -360.1000000000001, 20.000000000000014, -372.6999999999998, -11.499999999999822, -322.2999999999999, -375.69999999999993, -235.0, -382.0, -127.9000000000001, -28.29999999999975], "policy_predator_policy_reward": [98.0, 115.0, 1.0, 145.0, 194.0, 178.0, 103.0, 165.0, 64.0, 95.0, 7.0, 179.0, 183.0, 188.0, 25.0, 109.0, 197.0, 140.0, 64.0, 186.0, 33.0, 47.0, 194.0, 120.0, 192.0, 124.0, 46.0, 0.0, 47.0, 190.0, 36.0, 185.0, 25.0, 57.0, 88.0, 60.0, 0.0, 0.0, 61.0, 78.0, 149.0, 23.0, 6.0, 198.0, 193.0, 200.0, 16.0, 18.0, 102.0, 136.0, 34.0, 189.0, 141.0, 187.0, 147.0, 158.0, 49.0, 24.0, 193.0, 197.0, 162.0, 18.0, 36.0, 47.0, 98.0, 136.0, 1.0, 1.0, 171.0, 179.0, 11.0, 22.0, 47.0, 33.0, 109.0, 175.0, 35.0, 114.0, 185.0, 1.0, 36.0, 89.0, 90.0, 0.0, 176.0, 167.0, 90.0, 47.0, 4.0, 2.0, 189.0, 38.0, 138.0, 187.0, 197.0, 191.0, 164.0, 167.0, 51.0, 152.0, 99.0, 4.0, 180.0, 52.0, 50.0, 193.0, 174.0, 77.0, 183.0, 104.0, 119.0, 169.0, 87.0, 173.0, 199.0, 164.0, 179.0, 178.0, 109.0, 150.0, 43.0, 53.0, 184.0, 200.0, 136.0, 143.0, 111.0, 149.0, 152.0, 38.0, 100.0, 200.0, 147.0, 119.0, 179.0, 186.0, 193.0, 118.0, 41.0, 184.0, 152.0, 0.0, 54.0, 200.0, 38.0, 13.0, 200.0, 139.0, 178.0, 171.0, 173.0, 198.0, 29.0, 178.0, 182.0, 21.0, 86.0, 141.0, 149.0, 61.0, 181.0, 163.0, 136.0, 142.0, 152.0, 165.0, 192.0, 187.0, 100.0, 43.0, 142.0, 176.0, 0.0, 3.0, 192.0, 150.0, 175.0, 114.0, 200.0, 120.0, 55.0, 151.0, 176.0, 188.0, 149.0, 194.0, 24.0, 138.0, 35.0, 20.0, 148.0, 158.0, 15.0, 187.0, 105.0, 193.0, 182.0, 129.0, 23.0, 97.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6393331810525752, "mean_inference_ms": 1.9954827956402463, "mean_action_processing_ms": 0.2875607161787543, "mean_env_wait_ms": 0.21690470135366355, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004888176918029785, "StateBufferConnector_ms": 0.0031529664993286133, "ViewRequirementAgentConnector_ms": 0.09805691242218018}, "num_episodes": 18, "episode_return_max": 363.9000000000002, "episode_return_min": -506.5, "episode_return_mean": -183.86300000000014, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 704000, "num_agent_steps_trained": 704000, "num_env_steps_sampled": 176000, "num_env_steps_trained": 176000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 368.5000293662869, "num_env_steps_trained_throughput_per_sec": 368.5000293662869, "timesteps_total": 176000, "num_env_steps_sampled_lifetime": 176000, "num_agent_steps_sampled_lifetime": 704000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 704000, "timers": {"training_iteration_time_ms": 10839.459, "restore_workers_time_ms": 0.014, "training_step_time_ms": 10839.393, "sample_time_ms": 1297.427, "learn_time_ms": 9527.23, "learn_throughput": 419.849, "synch_weights_time_ms": 13.651}, "counters": {"num_env_steps_sampled": 176000, "num_env_steps_trained": 176000, "num_agent_steps_sampled": 704000, "num_agent_steps_trained": 704000}, "done": false, "training_iteration": 44, "trial_id": "3dae5_00000", "date": "2024-08-14_09-15-00", "timestamp": 1723641300, "time_this_iter_s": 10.860328197479248, "time_total_s": 2120.2152638435364, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0f81dc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2120.2152638435364, "iterations_since_restore": 44, "perf": {"cpu_util_percent": 28.493333333333336, "ram_util_percent": 83.55999999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8941582240755597, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.097045302769494, "policy_loss": -0.008539718912579316, "vf_loss": 8.103677099974698, "vf_explained_var": 0.2828792691861511, "kl": 0.008479708390141049, "entropy": 1.1947793297666722, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 84105.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7421463193716826, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.27471385254431, "policy_loss": -0.0030824805213207447, "vf_loss": 7.276751916875284, "vf_explained_var": -0.37517638484006205, "kl": 0.0069628864455516595, "entropy": 1.2216975258140967, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 84105.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 180000, "num_env_steps_trained": 180000, "num_agent_steps_sampled": 720000, "num_agent_steps_trained": 720000}, "env_runners": {"episode_reward_max": 363.9000000000002, "episode_reward_min": -506.5, "episode_reward_mean": -192.81300000000013, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 190.99999999999994, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -217.46650000000002, "predator_policy": 121.06}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-316.70000000000005, 192.49999999999935, -200.80000000000086, -475.89999999999964, -388.9, -327.89999999999975, 96.19999999999968, -388.99999999999994, -359.59999999999945, 181.49999999999926, -57.80000000000004, 363.9000000000002, -410.4, 120.99999999999957, -47.999999999999545, -360.30000000000007, -63.90000000000012, -418.3999999999996, 30.900000000000126, -1.4000000000001265, -307.6, 139.49999999999986, 166.59999999999906, -138.60000000000062, -391.29999999999995, -74.79999999999998, -287.7999999999999, -168.90000000000097, 46.39999999999995, -506.5, -192.80000000000092, -409.1999999999997, -92.10000000000059, -350.5999999999999, -433.1999999999999, -328.4, -16.699999999999907, -327.70000000000005, 114.39999999999944, -409.69999999999993, -241.39999999999998, -357.5999999999999, -344.5, -485.9, -229.20000000000005, -325.20000000000005, -415.8, -196.70000000000076, -242.10000000000005, -239.40000000000077, 193.8999999999998, -437.9, -379.9000000000001, -382.79999999999995, -167.90000000000072, -179.70000000000093, -19.1999999999999, -157.70000000000073, 94.49999999999962, -449.69999999999993, -189.29999999999995, -331.2999999999996, 135.59999999999957, -353.30000000000007, 262.5999999999997, -367.1, -243.70000000000005, -366.59999999999997, -172.20000000000076, -325.2999999999996, -429.39999999999986, -94.10000000000022, 187.39999999999932, -34.09999999999985, -182.2000000000008, -399.9999999999998, -306.0, -36.19999999999986, 34.80000000000024, -172.00000000000082, -403.0, -44.19999999999983, -42.19999999999981, -0.799999999999743, -367.69999999999993, -342.5999999999997, -297.20000000000005, -66.49999999999991, -398.39999999999986, -52.89999999999983, -326.1, -269.8000000000005, -171.30000000000075, -57.20000000000006, -122.80000000000022, -205.00000000000009, -36.499999999999936, -379.3, -201.70000000000002, -347.50000000000045], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-315.70000000000005, -394.0, 184.69999999999996, -26.199999999999747, -150.10000000000065, -288.70000000000005, -339.69999999999976, -359.19999999999993, -335.2, -381.7, -328.5999999999999, -304.29999999999984, 11.600000000000009, 11.599999999999964, -393.69999999999993, -385.3, -262.30000000000007, -277.2999999999994, -87.10000000000085, 185.5999999999999, -288.6999999999989, -3.099999999999958, 184.39999999999992, 177.49999999999994, -384.4, -376.0, 20.000000000000014, 67.99999999999999, -127.00000000000071, -0.9999999999999846, -311.8, -332.5, -128.20000000000005, -84.70000000000007, -261.69999999999993, -342.69999999999993, 74.89999999999996, -169.00000000000063, -64.3000000000001, -27.100000000000094, -379.5999999999999, -271.0, -83.50000000000003, 85.99999999999989, 148.99999999999974, 11.599999999999964, 3.1999999999999615, -368.8, -334.29999999999995, -382.0, -381.1, -81.7, -314.7999999999999, -304.0, -284.8000000000002, -87.10000000000082, -21.69999999999997, -34.9, -379.9, -358.6, -384.4, -51.400000000000006, -340.2999999999997, -319.9, -386.5, 7.399999999999965, -287.8, -350.79999999999995, -311.49999999999994, -381.69999999999993, -348.69999999999993, -342.7, -393.70000000000005, 20.000000000000014, -295.0, -291.70000000000005, 20.000000000000014, -1.6000000000000512, -393.69999999999993, -400.0, -247.89999999999998, -272.5, -241.0, -376.6, -262.0, -272.5, -385.9, -400.0, -236.8, -258.40000000000003, -296.5, -393.70000000000005, -374.8, -352.0, -66.10000000000072, -355.59999999999997, -223.90000000000006, -170.20000000000002, -400.0, -93.40000000000076, 83.6, 59.30000000000001, -395.79999999999995, -381.1, -359.20000000000005, -369.70000000000005, -393.69999999999993, -360.1, -40.89999999999976, -334.0, -358.5999999999999, -24.099999999999746, -266.20000000000005, 20.000000000000014, -108.10000000000075, -259.6, -383.1999999999998, 133.69999999999965, -371.8, -355.9, -171.10000000000005, -335.19999999999993, -365.79999999999995, -344.49999999999966, 190.99999999999994, -198.40000000000055, -334.30000000000007, -337.00000000000006, 93.80000000000001, 165.79999999999984, -336.1, -373.0, -316.59999999999997, -216.10000000000002, -400.0, -286.6, -95.50000000000082, -282.70000000000005, -385.0, -304.2999999999996, -393.69999999999993, -378.69999999999993, -19.899999999999764, -236.20000000000005, 185.89999999999995, -53.50000000000009, -360.1000000000001, 20.000000000000014, -372.6999999999998, -11.499999999999822, -322.2999999999999, -375.69999999999993, -235.0, -382.0, -127.9000000000001, -28.29999999999975, 3.1999999999999615, -213.4, -329.20000000000005, -38.799999999999756, -400.0, -385.0, -47.19999999999976, -151.0, 11.599999999999964, -332.79999999999995, -11.499999999999819, -28.29999999999975, -332.5000000000001, -335.20000000000005, -355.2999999999996, -379.30000000000007, -395.8, -282.4, 9.499999999999964, -193.00000000000026, -350.5000000000001, -397.9, -169.00000000000009, -19.89999999999975, -400.0, -321.1, -358.0000000000001, -206.79999999999998, -358.9000000000001, -9.399999999999855, -397.0, -5.1999999999999265, -263.49999999999994, -7.299999999999891, -185.8, -350.19999999999993, -32.49999999999975, -133.0, -329.5, -383.8, -171.70000000000002, -400.0, -339.10000000000014, -183.4000000000003], "policy_predator_policy_reward": [193.0, 200.0, 16.0, 18.0, 102.0, 136.0, 34.0, 189.0, 141.0, 187.0, 147.0, 158.0, 49.0, 24.0, 193.0, 197.0, 162.0, 18.0, 36.0, 47.0, 98.0, 136.0, 1.0, 1.0, 171.0, 179.0, 11.0, 22.0, 47.0, 33.0, 109.0, 175.0, 35.0, 114.0, 185.0, 1.0, 36.0, 89.0, 90.0, 0.0, 176.0, 167.0, 90.0, 47.0, 4.0, 2.0, 189.0, 38.0, 138.0, 187.0, 197.0, 191.0, 164.0, 167.0, 51.0, 152.0, 99.0, 4.0, 180.0, 52.0, 50.0, 193.0, 174.0, 77.0, 183.0, 104.0, 119.0, 169.0, 87.0, 173.0, 199.0, 164.0, 179.0, 178.0, 109.0, 150.0, 43.0, 53.0, 184.0, 200.0, 136.0, 143.0, 111.0, 149.0, 152.0, 38.0, 100.0, 200.0, 147.0, 119.0, 179.0, 186.0, 193.0, 118.0, 41.0, 184.0, 152.0, 0.0, 54.0, 200.0, 38.0, 13.0, 200.0, 139.0, 178.0, 171.0, 173.0, 198.0, 29.0, 178.0, 182.0, 21.0, 86.0, 141.0, 149.0, 61.0, 181.0, 163.0, 136.0, 142.0, 152.0, 165.0, 192.0, 187.0, 100.0, 43.0, 142.0, 176.0, 0.0, 3.0, 192.0, 150.0, 175.0, 114.0, 200.0, 120.0, 55.0, 151.0, 176.0, 188.0, 149.0, 194.0, 24.0, 138.0, 35.0, 20.0, 148.0, 158.0, 15.0, 187.0, 105.0, 193.0, 182.0, 129.0, 23.0, 97.0, 111.0, 134.0, 28.0, 168.0, 186.0, 196.0, 122.0, 32.0, 144.0, 135.0, 22.0, 17.0, 198.0, 102.0, 198.0, 194.0, 182.0, 199.0, 112.0, 5.0, 187.0, 163.0, 117.0, 19.0, 197.0, 198.0, 122.0, 173.0, 14.0, 183.0, 187.0, 158.0, 13.0, 135.0, 186.0, 145.0, 105.0, 24.0, 189.0, 145.0, 198.0, 172.0, 172.0, 3.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6376943265915678, "mean_inference_ms": 1.9888903403443492, "mean_action_processing_ms": 0.28607527407503974, "mean_env_wait_ms": 0.2161941049181892, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004889726638793945, "StateBufferConnector_ms": 0.003425002098083496, "ViewRequirementAgentConnector_ms": 0.09815871715545654}, "num_episodes": 22, "episode_return_max": 363.9000000000002, "episode_return_min": -506.5, "episode_return_mean": -192.81300000000013, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 720000, "num_agent_steps_trained": 720000, "num_env_steps_sampled": 180000, "num_env_steps_trained": 180000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 376.5272982255305, "num_env_steps_trained_throughput_per_sec": 376.5272982255305, "timesteps_total": 180000, "num_env_steps_sampled_lifetime": 180000, "num_agent_steps_sampled_lifetime": 720000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 720000, "timers": {"training_iteration_time_ms": 10804.059, "restore_workers_time_ms": 0.014, "training_step_time_ms": 10804.005, "sample_time_ms": 1281.19, "learn_time_ms": 9508.376, "learn_throughput": 420.682, "synch_weights_time_ms": 13.35}, "counters": {"num_env_steps_sampled": 180000, "num_env_steps_trained": 180000, "num_agent_steps_sampled": 720000, "num_agent_steps_trained": 720000}, "done": false, "training_iteration": 45, "trial_id": "3dae5_00000", "date": "2024-08-14_09-15-10", "timestamp": 1723641310, "time_this_iter_s": 10.637991189956665, "time_total_s": 2130.853255033493, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b116af70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2130.853255033493, "iterations_since_restore": 45, "perf": {"cpu_util_percent": 29.166666666666664, "ram_util_percent": 83.66666666666667}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8244049275678302, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.276334430301, "policy_loss": -0.009026466511071675, "vf_loss": 8.28303062625663, "vf_explained_var": 0.32310190188190924, "kl": 0.010356732807436434, "entropy": 1.191748732107657, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 85995.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.1669030178160895, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.119969415916968, "policy_loss": -0.002765654538703895, "vf_loss": 8.121742055781935, "vf_explained_var": -0.15958099768906042, "kl": 0.006620009531655693, "entropy": 1.2289202764551475, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 85995.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 184000, "num_env_steps_trained": 184000, "num_agent_steps_sampled": 736000, "num_agent_steps_trained": 736000}, "env_runners": {"episode_reward_max": 340.3999999999999, "episode_reward_min": -506.5, "episode_reward_mean": -200.18200000000004, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 190.99999999999994, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -232.48600000000002, "predator_policy": 132.395}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-138.60000000000062, -391.29999999999995, -74.79999999999998, -287.7999999999999, -168.90000000000097, 46.39999999999995, -506.5, -192.80000000000092, -409.1999999999997, -92.10000000000059, -350.5999999999999, -433.1999999999999, -328.4, -16.699999999999907, -327.70000000000005, 114.39999999999944, -409.69999999999993, -241.39999999999998, -357.5999999999999, -344.5, -485.9, -229.20000000000005, -325.20000000000005, -415.8, -196.70000000000076, -242.10000000000005, -239.40000000000077, 193.8999999999998, -437.9, -379.9000000000001, -382.79999999999995, -167.90000000000072, -179.70000000000093, -19.1999999999999, -157.70000000000073, 94.49999999999962, -449.69999999999993, -189.29999999999995, -331.2999999999996, 135.59999999999957, -353.30000000000007, 262.5999999999997, -367.1, -243.70000000000005, -366.59999999999997, -172.20000000000076, -325.2999999999996, -429.39999999999986, -94.10000000000022, 187.39999999999932, -34.09999999999985, -182.2000000000008, -399.9999999999998, -306.0, -36.19999999999986, 34.80000000000024, -172.00000000000082, -403.0, -44.19999999999983, -42.19999999999981, -0.799999999999743, -367.69999999999993, -342.5999999999997, -297.20000000000005, -66.49999999999991, -398.39999999999986, -52.89999999999983, -326.1, -269.8000000000005, -171.30000000000075, -57.20000000000006, -122.80000000000022, -205.00000000000009, -36.499999999999936, -379.3, -201.70000000000002, -347.50000000000045, -395.7, -389.29999999999984, -10.699999999999974, -321.1, -263.2, -0.999999999999814, -277.9, -34.899999999999835, -383.0, -379.6, -231.4000000000007, 22.500000000000213, -354.5, -230.50000000000009, 30.100000000000144, 8.799999999999843, 20.700000000000273, -29.299999999999734, -135.8, 12.699999999999996, -230.8000000000004, 340.3999999999999, -337.8999999999994], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [3.1999999999999615, -368.8, -334.29999999999995, -382.0, -381.1, -81.7, -314.7999999999999, -304.0, -284.8000000000002, -87.10000000000082, -21.69999999999997, -34.9, -379.9, -358.6, -384.4, -51.400000000000006, -340.2999999999997, -319.9, -386.5, 7.399999999999965, -287.8, -350.79999999999995, -311.49999999999994, -381.69999999999993, -348.69999999999993, -342.7, -393.70000000000005, 20.000000000000014, -295.0, -291.70000000000005, 20.000000000000014, -1.6000000000000512, -393.69999999999993, -400.0, -247.89999999999998, -272.5, -241.0, -376.6, -262.0, -272.5, -385.9, -400.0, -236.8, -258.40000000000003, -296.5, -393.70000000000005, -374.8, -352.0, -66.10000000000072, -355.59999999999997, -223.90000000000006, -170.20000000000002, -400.0, -93.40000000000076, 83.6, 59.30000000000001, -395.79999999999995, -381.1, -359.20000000000005, -369.70000000000005, -393.69999999999993, -360.1, -40.89999999999976, -334.0, -358.5999999999999, -24.099999999999746, -266.20000000000005, 20.000000000000014, -108.10000000000075, -259.6, -383.1999999999998, 133.69999999999965, -371.8, -355.9, -171.10000000000005, -335.19999999999993, -365.79999999999995, -344.49999999999966, 190.99999999999994, -198.40000000000055, -334.30000000000007, -337.00000000000006, 93.80000000000001, 165.79999999999984, -336.1, -373.0, -316.59999999999997, -216.10000000000002, -400.0, -286.6, -95.50000000000082, -282.70000000000005, -385.0, -304.2999999999996, -393.69999999999993, -378.69999999999993, -19.899999999999764, -236.20000000000005, 185.89999999999995, -53.50000000000009, -360.1000000000001, 20.000000000000014, -372.6999999999998, -11.499999999999822, -322.2999999999999, -375.69999999999993, -235.0, -382.0, -127.9000000000001, -28.29999999999975, 3.1999999999999615, -213.4, -329.20000000000005, -38.799999999999756, -400.0, -385.0, -47.19999999999976, -151.0, 11.599999999999964, -332.79999999999995, -11.499999999999819, -28.29999999999975, -332.5000000000001, -335.20000000000005, -355.2999999999996, -379.30000000000007, -395.8, -282.4, 9.499999999999964, -193.00000000000026, -350.5000000000001, -397.9, -169.00000000000009, -19.89999999999975, -400.0, -321.1, -358.0000000000001, -206.79999999999998, -358.9000000000001, -9.399999999999855, -397.0, -5.1999999999999265, -263.49999999999994, -7.299999999999891, -185.8, -350.19999999999993, -32.49999999999975, -133.0, -329.5, -383.8, -171.70000000000002, -400.0, -339.10000000000014, -183.4000000000003, -328.0, -330.7, -385.29999999999984, -400.0, 20.000000000000014, -393.69999999999993, -380.79999999999995, -304.3, -328.5999999999996, -328.5999999999998, 3.1999999999999615, -152.20000000000067, -307.9000000000001, -286.0, 20.000000000000014, -313.90000000000015, -394.0, -388.0, -383.20000000000005, -384.4, -341.79999999999967, -139.60000000000056, -55.600000000000335, -202.9, -380.5, -358.0, -388.0, -212.50000000000009, 7.399999999999965, 13.699999999999964, -47.19999999999976, -64.0, -241.0000000000001, -7.299999999999891, -24.099999999999746, -299.2, -391.9, -124.9, 29.0, -298.30000000000007, -265.0, -248.8000000000004, 178.3999999999999, 125.0, -294.1, -326.80000000000007], "policy_predator_policy_reward": [189.0, 38.0, 138.0, 187.0, 197.0, 191.0, 164.0, 167.0, 51.0, 152.0, 99.0, 4.0, 180.0, 52.0, 50.0, 193.0, 174.0, 77.0, 183.0, 104.0, 119.0, 169.0, 87.0, 173.0, 199.0, 164.0, 179.0, 178.0, 109.0, 150.0, 43.0, 53.0, 184.0, 200.0, 136.0, 143.0, 111.0, 149.0, 152.0, 38.0, 100.0, 200.0, 147.0, 119.0, 179.0, 186.0, 193.0, 118.0, 41.0, 184.0, 152.0, 0.0, 54.0, 200.0, 38.0, 13.0, 200.0, 139.0, 178.0, 171.0, 173.0, 198.0, 29.0, 178.0, 182.0, 21.0, 86.0, 141.0, 149.0, 61.0, 181.0, 163.0, 136.0, 142.0, 152.0, 165.0, 192.0, 187.0, 100.0, 43.0, 142.0, 176.0, 0.0, 3.0, 192.0, 150.0, 175.0, 114.0, 200.0, 120.0, 55.0, 151.0, 176.0, 188.0, 149.0, 194.0, 24.0, 138.0, 35.0, 20.0, 148.0, 158.0, 15.0, 187.0, 105.0, 193.0, 182.0, 129.0, 23.0, 97.0, 111.0, 134.0, 28.0, 168.0, 186.0, 196.0, 122.0, 32.0, 144.0, 135.0, 22.0, 17.0, 198.0, 102.0, 198.0, 194.0, 182.0, 199.0, 112.0, 5.0, 187.0, 163.0, 117.0, 19.0, 197.0, 198.0, 122.0, 173.0, 14.0, 183.0, 187.0, 158.0, 13.0, 135.0, 186.0, 145.0, 105.0, 24.0, 189.0, 145.0, 198.0, 172.0, 172.0, 3.0, 195.0, 68.0, 197.0, 199.0, 183.0, 180.0, 173.0, 191.0, 200.0, 194.0, 76.0, 72.0, 150.0, 166.0, 148.0, 111.0, 199.0, 200.0, 188.0, 200.0, 76.0, 174.0, 133.0, 148.0, 192.0, 192.0, 189.0, 181.0, 6.0, 3.0, 32.0, 88.0, 120.0, 149.0, 136.0, 158.0, 183.0, 198.0, 147.0, 135.0, 128.0, 155.0, 19.0, 18.0, 151.0, 132.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6362027607845443, "mean_inference_ms": 1.9825627614903294, "mean_action_processing_ms": 0.28444541059365525, "mean_env_wait_ms": 0.21551800198734242, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005281329154968262, "StateBufferConnector_ms": 0.0033998489379882812, "ViewRequirementAgentConnector_ms": 0.09467291831970215}, "num_episodes": 23, "episode_return_max": 340.3999999999999, "episode_return_min": -506.5, "episode_return_mean": -200.18200000000004, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 736000, "num_agent_steps_trained": 736000, "num_env_steps_sampled": 184000, "num_env_steps_trained": 184000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 369.6322414748562, "num_env_steps_trained_throughput_per_sec": 369.6322414748562, "timesteps_total": 184000, "num_env_steps_sampled_lifetime": 184000, "num_agent_steps_sampled_lifetime": 736000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 736000, "timers": {"training_iteration_time_ms": 10811.492, "restore_workers_time_ms": 0.014, "training_step_time_ms": 10811.437, "sample_time_ms": 1287.147, "learn_time_ms": 9506.946, "learn_throughput": 420.745, "synch_weights_time_ms": 16.206}, "counters": {"num_env_steps_sampled": 184000, "num_env_steps_trained": 184000, "num_agent_steps_sampled": 736000, "num_agent_steps_trained": 736000}, "done": false, "training_iteration": 46, "trial_id": "3dae5_00000", "date": "2024-08-14_09-15-21", "timestamp": 1723641321, "time_this_iter_s": 10.829577207565308, "time_total_s": 2141.6828322410583, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0feae50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2141.6828322410583, "iterations_since_restore": 46, "perf": {"cpu_util_percent": 27.55, "ram_util_percent": 83.41875}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.0992314772315757, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.754005673322728, "policy_loss": -0.004433178612173944, "vf_loss": 8.75643506378093, "vf_explained_var": 0.32748061976735554, "kl": 0.008905703539496162, "entropy": 1.1664334663007625, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 87885.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.044209068729764, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.092764343786492, "policy_loss": -0.00520557615679329, "vf_loss": 7.096308798512454, "vf_explained_var": -0.2747619498974432, "kl": 0.011074102243583043, "entropy": 1.2127763631482604, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 87885.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 188000, "num_env_steps_trained": 188000, "num_agent_steps_sampled": 752000, "num_agent_steps_trained": 752000}, "env_runners": {"episode_reward_max": 340.3999999999999, "episode_reward_min": -485.9, "episode_reward_mean": -188.1190000000001, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 190.99999999999994, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -227.59450000000004, "predator_policy": 133.535}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-357.5999999999999, -344.5, -485.9, -229.20000000000005, -325.20000000000005, -415.8, -196.70000000000076, -242.10000000000005, -239.40000000000077, 193.8999999999998, -437.9, -379.9000000000001, -382.79999999999995, -167.90000000000072, -179.70000000000093, -19.1999999999999, -157.70000000000073, 94.49999999999962, -449.69999999999993, -189.29999999999995, -331.2999999999996, 135.59999999999957, -353.30000000000007, 262.5999999999997, -367.1, -243.70000000000005, -366.59999999999997, -172.20000000000076, -325.2999999999996, -429.39999999999986, -94.10000000000022, 187.39999999999932, -34.09999999999985, -182.2000000000008, -399.9999999999998, -306.0, -36.19999999999986, 34.80000000000024, -172.00000000000082, -403.0, -44.19999999999983, -42.19999999999981, -0.799999999999743, -367.69999999999993, -342.5999999999997, -297.20000000000005, -66.49999999999991, -398.39999999999986, -52.89999999999983, -326.1, -269.8000000000005, -171.30000000000075, -57.20000000000006, -122.80000000000022, -205.00000000000009, -36.499999999999936, -379.3, -201.70000000000002, -347.50000000000045, -395.7, -389.29999999999984, -10.699999999999974, -321.1, -263.2, -0.999999999999814, -277.9, -34.899999999999835, -383.0, -379.6, -231.4000000000007, 22.500000000000213, -354.5, -230.50000000000009, 30.100000000000144, 8.799999999999843, 20.700000000000273, -29.299999999999734, -135.8, 12.699999999999996, -230.8000000000004, 340.3999999999999, -337.8999999999994, -273.5, -111.80000000000027, -31.299999999999834, -383.9, -474.6, -9.900000000000036, -118.20000000000005, -214.10000000000068, -216.0, -123.10000000000076, -194.8, 27.6000000000001, -344.99999999999994, 11.599999999999957, -108.60000000000053, -70.80000000000007, 4.099999999999998, -370.30000000000007], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-241.0, -376.6, -262.0, -272.5, -385.9, -400.0, -236.8, -258.40000000000003, -296.5, -393.70000000000005, -374.8, -352.0, -66.10000000000072, -355.59999999999997, -223.90000000000006, -170.20000000000002, -400.0, -93.40000000000076, 83.6, 59.30000000000001, -395.79999999999995, -381.1, -359.20000000000005, -369.70000000000005, -393.69999999999993, -360.1, -40.89999999999976, -334.0, -358.5999999999999, -24.099999999999746, -266.20000000000005, 20.000000000000014, -108.10000000000075, -259.6, -383.1999999999998, 133.69999999999965, -371.8, -355.9, -171.10000000000005, -335.19999999999993, -365.79999999999995, -344.49999999999966, 190.99999999999994, -198.40000000000055, -334.30000000000007, -337.00000000000006, 93.80000000000001, 165.79999999999984, -336.1, -373.0, -316.59999999999997, -216.10000000000002, -400.0, -286.6, -95.50000000000082, -282.70000000000005, -385.0, -304.2999999999996, -393.69999999999993, -378.69999999999993, -19.899999999999764, -236.20000000000005, 185.89999999999995, -53.50000000000009, -360.1000000000001, 20.000000000000014, -372.6999999999998, -11.499999999999822, -322.2999999999999, -375.69999999999993, -235.0, -382.0, -127.9000000000001, -28.29999999999975, 3.1999999999999615, -213.4, -329.20000000000005, -38.799999999999756, -400.0, -385.0, -47.19999999999976, -151.0, 11.599999999999964, -332.79999999999995, -11.499999999999819, -28.29999999999975, -332.5000000000001, -335.20000000000005, -355.2999999999996, -379.30000000000007, -395.8, -282.4, 9.499999999999964, -193.00000000000026, -350.5000000000001, -397.9, -169.00000000000009, -19.89999999999975, -400.0, -321.1, -358.0000000000001, -206.79999999999998, -358.9000000000001, -9.399999999999855, -397.0, -5.1999999999999265, -263.49999999999994, -7.299999999999891, -185.8, -350.19999999999993, -32.49999999999975, -133.0, -329.5, -383.8, -171.70000000000002, -400.0, -339.10000000000014, -183.4000000000003, -328.0, -330.7, -385.29999999999984, -400.0, 20.000000000000014, -393.69999999999993, -380.79999999999995, -304.3, -328.5999999999996, -328.5999999999998, 3.1999999999999615, -152.20000000000067, -307.9000000000001, -286.0, 20.000000000000014, -313.90000000000015, -394.0, -388.0, -383.20000000000005, -384.4, -341.79999999999967, -139.60000000000056, -55.600000000000335, -202.9, -380.5, -358.0, -388.0, -212.50000000000009, 7.399999999999965, 13.699999999999964, -47.19999999999976, -64.0, -241.0000000000001, -7.299999999999891, -24.099999999999746, -299.2, -391.9, -124.9, 29.0, -298.30000000000007, -265.0, -248.8000000000004, 178.3999999999999, 125.0, -294.1, -326.80000000000007, -391.6, -166.90000000000063, -309.7, 17.899999999999988, 16.69999999999997, -370.0, -376.9, -400.0, -280.6, -400.0, -397.9, 20.000000000000014, -385.29999999999984, -91.9, -400.0, -108.10000000000055, -73.0, -343.0, -28.29999999999975, -377.8, -146.8, -400.0, 9.499999999999964, 1.0999999999999865, -324.4, -391.6, 11.599999999999964, -400.0, -271.9000000000001, 5.299999999999965, -11.499999999999819, -247.30000000000007, 20.000000000000014, -355.9000000000001, -400.0, -358.30000000000007], "policy_predator_policy_reward": [111.0, 149.0, 152.0, 38.0, 100.0, 200.0, 147.0, 119.0, 179.0, 186.0, 193.0, 118.0, 41.0, 184.0, 152.0, 0.0, 54.0, 200.0, 38.0, 13.0, 200.0, 139.0, 178.0, 171.0, 173.0, 198.0, 29.0, 178.0, 182.0, 21.0, 86.0, 141.0, 149.0, 61.0, 181.0, 163.0, 136.0, 142.0, 152.0, 165.0, 192.0, 187.0, 100.0, 43.0, 142.0, 176.0, 0.0, 3.0, 192.0, 150.0, 175.0, 114.0, 200.0, 120.0, 55.0, 151.0, 176.0, 188.0, 149.0, 194.0, 24.0, 138.0, 35.0, 20.0, 148.0, 158.0, 15.0, 187.0, 105.0, 193.0, 182.0, 129.0, 23.0, 97.0, 111.0, 134.0, 28.0, 168.0, 186.0, 196.0, 122.0, 32.0, 144.0, 135.0, 22.0, 17.0, 198.0, 102.0, 198.0, 194.0, 182.0, 199.0, 112.0, 5.0, 187.0, 163.0, 117.0, 19.0, 197.0, 198.0, 122.0, 173.0, 14.0, 183.0, 187.0, 158.0, 13.0, 135.0, 186.0, 145.0, 105.0, 24.0, 189.0, 145.0, 198.0, 172.0, 172.0, 3.0, 195.0, 68.0, 197.0, 199.0, 183.0, 180.0, 173.0, 191.0, 200.0, 194.0, 76.0, 72.0, 150.0, 166.0, 148.0, 111.0, 199.0, 200.0, 188.0, 200.0, 76.0, 174.0, 133.0, 148.0, 192.0, 192.0, 189.0, 181.0, 6.0, 3.0, 32.0, 88.0, 120.0, 149.0, 136.0, 158.0, 183.0, 198.0, 147.0, 135.0, 128.0, 155.0, 19.0, 18.0, 151.0, 132.0, 196.0, 89.0, 41.0, 139.0, 180.0, 142.0, 200.0, 193.0, 6.0, 200.0, 188.0, 180.0, 193.0, 166.0, 185.0, 109.0, 4.0, 196.0, 91.0, 192.0, 200.0, 152.0, 9.0, 8.0, 193.0, 178.0, 200.0, 200.0, 1.0, 157.0, 134.0, 54.0, 173.0, 167.0, 195.0, 193.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6346809188394483, "mean_inference_ms": 1.9763387700466801, "mean_action_processing_ms": 0.28311694458331227, "mean_env_wait_ms": 0.21485712204536425, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00584566593170166, "StateBufferConnector_ms": 0.003319382667541504, "ViewRequirementAgentConnector_ms": 0.09323406219482422}, "num_episodes": 18, "episode_return_max": 340.3999999999999, "episode_return_min": -485.9, "episode_return_mean": -188.1190000000001, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 752000, "num_agent_steps_trained": 752000, "num_env_steps_sampled": 188000, "num_env_steps_trained": 188000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 348.93013848024276, "num_env_steps_trained_throughput_per_sec": 348.93013848024276, "timesteps_total": 188000, "num_env_steps_sampled_lifetime": 188000, "num_agent_steps_sampled_lifetime": 752000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 752000, "timers": {"training_iteration_time_ms": 10880.928, "restore_workers_time_ms": 0.014, "training_step_time_ms": 10880.857, "sample_time_ms": 1283.648, "learn_time_ms": 9579.533, "learn_throughput": 417.557, "synch_weights_time_ms": 16.272}, "counters": {"num_env_steps_sampled": 188000, "num_env_steps_trained": 188000, "num_agent_steps_sampled": 752000, "num_agent_steps_trained": 752000}, "done": false, "training_iteration": 47, "trial_id": "3dae5_00000", "date": "2024-08-14_09-15-33", "timestamp": 1723641333, "time_this_iter_s": 11.505913019180298, "time_total_s": 2153.1887452602386, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0fef790>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2153.1887452602386, "iterations_since_restore": 47, "perf": {"cpu_util_percent": 32.26875, "ram_util_percent": 83.7125}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.3499940775689625, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.11965289544807, "policy_loss": -0.007328989920231006, "vf_loss": 9.125074956278322, "vf_explained_var": -0.20111572729847418, "kl": 0.008475200149741806, "entropy": 1.1681859199962918, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 89775.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.3201014697867097, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.010292581527952, "policy_loss": -0.009090047458029061, "vf_loss": 6.017460586406567, "vf_explained_var": -0.21552515439886263, "kl": 0.012813636367811448, "entropy": 1.2428884966663583, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 89775.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 192000, "num_env_steps_trained": 192000, "num_agent_steps_sampled": 768000, "num_agent_steps_trained": 768000}, "env_runners": {"episode_reward_max": 340.3999999999999, "episode_reward_min": -474.6, "episode_reward_mean": -161.57000000000005, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 190.99999999999994, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -215.77, "predator_policy": 134.985}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-449.69999999999993, -189.29999999999995, -331.2999999999996, 135.59999999999957, -353.30000000000007, 262.5999999999997, -367.1, -243.70000000000005, -366.59999999999997, -172.20000000000076, -325.2999999999996, -429.39999999999986, -94.10000000000022, 187.39999999999932, -34.09999999999985, -182.2000000000008, -399.9999999999998, -306.0, -36.19999999999986, 34.80000000000024, -172.00000000000082, -403.0, -44.19999999999983, -42.19999999999981, -0.799999999999743, -367.69999999999993, -342.5999999999997, -297.20000000000005, -66.49999999999991, -398.39999999999986, -52.89999999999983, -326.1, -269.8000000000005, -171.30000000000075, -57.20000000000006, -122.80000000000022, -205.00000000000009, -36.499999999999936, -379.3, -201.70000000000002, -347.50000000000045, -395.7, -389.29999999999984, -10.699999999999974, -321.1, -263.2, -0.999999999999814, -277.9, -34.899999999999835, -383.0, -379.6, -231.4000000000007, 22.500000000000213, -354.5, -230.50000000000009, 30.100000000000144, 8.799999999999843, 20.700000000000273, -29.299999999999734, -135.8, 12.699999999999996, -230.8000000000004, 340.3999999999999, -337.8999999999994, -273.5, -111.80000000000027, -31.299999999999834, -383.9, -474.6, -9.900000000000036, -118.20000000000005, -214.10000000000068, -216.0, -123.10000000000076, -194.8, 27.6000000000001, -344.99999999999994, 11.599999999999957, -108.60000000000053, -70.80000000000007, 4.099999999999998, -370.30000000000007, -368.09999999999997, -11.200000000000028, -345.20000000000005, -79.0000000000009, 39.20000000000022, -8.999999999999943, -295.89999999999975, 32.800000000000196, -15.399999999999885, -13.999999999999778, -204.6000000000007, -20.19999999999997, -82.99999999999989, 3.999999999999987, 95.2999999999999, -14.999999999999979, -406.9, 77.9999999999995], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-371.8, -355.9, -171.10000000000005, -335.19999999999993, -365.79999999999995, -344.49999999999966, 190.99999999999994, -198.40000000000055, -334.30000000000007, -337.00000000000006, 93.80000000000001, 165.79999999999984, -336.1, -373.0, -316.59999999999997, -216.10000000000002, -400.0, -286.6, -95.50000000000082, -282.70000000000005, -385.0, -304.2999999999996, -393.69999999999993, -378.69999999999993, -19.899999999999764, -236.20000000000005, 185.89999999999995, -53.50000000000009, -360.1000000000001, 20.000000000000014, -372.6999999999998, -11.499999999999822, -322.2999999999999, -375.69999999999993, -235.0, -382.0, -127.9000000000001, -28.29999999999975, 3.1999999999999615, -213.4, -329.20000000000005, -38.799999999999756, -400.0, -385.0, -47.19999999999976, -151.0, 11.599999999999964, -332.79999999999995, -11.499999999999819, -28.29999999999975, -332.5000000000001, -335.20000000000005, -355.2999999999996, -379.30000000000007, -395.8, -282.4, 9.499999999999964, -193.00000000000026, -350.5000000000001, -397.9, -169.00000000000009, -19.89999999999975, -400.0, -321.1, -358.0000000000001, -206.79999999999998, -358.9000000000001, -9.399999999999855, -397.0, -5.1999999999999265, -263.49999999999994, -7.299999999999891, -185.8, -350.19999999999993, -32.49999999999975, -133.0, -329.5, -383.8, -171.70000000000002, -400.0, -339.10000000000014, -183.4000000000003, -328.0, -330.7, -385.29999999999984, -400.0, 20.000000000000014, -393.69999999999993, -380.79999999999995, -304.3, -328.5999999999996, -328.5999999999998, 3.1999999999999615, -152.20000000000067, -307.9000000000001, -286.0, 20.000000000000014, -313.90000000000015, -394.0, -388.0, -383.20000000000005, -384.4, -341.79999999999967, -139.60000000000056, -55.600000000000335, -202.9, -380.5, -358.0, -388.0, -212.50000000000009, 7.399999999999965, 13.699999999999964, -47.19999999999976, -64.0, -241.0000000000001, -7.299999999999891, -24.099999999999746, -299.2, -391.9, -124.9, 29.0, -298.30000000000007, -265.0, -248.8000000000004, 178.3999999999999, 125.0, -294.1, -326.80000000000007, -391.6, -166.90000000000063, -309.7, 17.899999999999988, 16.69999999999997, -370.0, -376.9, -400.0, -280.6, -400.0, -397.9, 20.000000000000014, -385.29999999999984, -91.9, -400.0, -108.10000000000055, -73.0, -343.0, -28.29999999999975, -377.8, -146.8, -400.0, 9.499999999999964, 1.0999999999999865, -324.4, -391.6, 11.599999999999964, -400.0, -271.9000000000001, 5.299999999999965, -11.499999999999819, -247.30000000000007, 20.000000000000014, -355.9000000000001, -400.0, -358.30000000000007, -370.0, -321.09999999999997, 5.299999999999965, -263.50000000000006, -397.9, -322.3, -337.00000000000017, -0.9999999999999846, -233.8, -0.9999999999999846, -7.299999999999891, -297.70000000000005, -330.7, -341.1999999999998, 20.000000000000014, -5.1999999999999265, -51.39999999999992, -292.0, -355.0000000000001, 20.000000000000014, -331.0, -139.6000000000007, -248.80000000000015, -9.399999999999855, -100.90000000000006, -291.10000000000014, -253.0, 20.000000000000014, 5.299999999999965, -73.0, -355.0, 20.000000000000014, -400.0, -397.9, 20.000000000000014, -115.0], "policy_predator_policy_reward": [136.0, 142.0, 152.0, 165.0, 192.0, 187.0, 100.0, 43.0, 142.0, 176.0, 0.0, 3.0, 192.0, 150.0, 175.0, 114.0, 200.0, 120.0, 55.0, 151.0, 176.0, 188.0, 149.0, 194.0, 24.0, 138.0, 35.0, 20.0, 148.0, 158.0, 15.0, 187.0, 105.0, 193.0, 182.0, 129.0, 23.0, 97.0, 111.0, 134.0, 28.0, 168.0, 186.0, 196.0, 122.0, 32.0, 144.0, 135.0, 22.0, 17.0, 198.0, 102.0, 198.0, 194.0, 182.0, 199.0, 112.0, 5.0, 187.0, 163.0, 117.0, 19.0, 197.0, 198.0, 122.0, 173.0, 14.0, 183.0, 187.0, 158.0, 13.0, 135.0, 186.0, 145.0, 105.0, 24.0, 189.0, 145.0, 198.0, 172.0, 172.0, 3.0, 195.0, 68.0, 197.0, 199.0, 183.0, 180.0, 173.0, 191.0, 200.0, 194.0, 76.0, 72.0, 150.0, 166.0, 148.0, 111.0, 199.0, 200.0, 188.0, 200.0, 76.0, 174.0, 133.0, 148.0, 192.0, 192.0, 189.0, 181.0, 6.0, 3.0, 32.0, 88.0, 120.0, 149.0, 136.0, 158.0, 183.0, 198.0, 147.0, 135.0, 128.0, 155.0, 19.0, 18.0, 151.0, 132.0, 196.0, 89.0, 41.0, 139.0, 180.0, 142.0, 200.0, 193.0, 6.0, 200.0, 188.0, 180.0, 193.0, 166.0, 185.0, 109.0, 4.0, 196.0, 91.0, 192.0, 200.0, 152.0, 9.0, 8.0, 193.0, 178.0, 200.0, 200.0, 1.0, 157.0, 134.0, 54.0, 173.0, 167.0, 195.0, 193.0, 190.0, 133.0, 133.0, 114.0, 182.0, 193.0, 116.0, 143.0, 140.0, 134.0, 159.0, 137.0, 187.0, 189.0, 12.0, 6.0, 170.0, 158.0, 149.0, 172.0, 160.0, 106.0, 100.0, 138.0, 143.0, 166.0, 102.0, 135.0, 74.0, 89.0, 147.0, 173.0, 193.0, 198.0, 104.0, 69.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6331044990383585, "mean_inference_ms": 1.9706193201200717, "mean_action_processing_ms": 0.28190703242570136, "mean_env_wait_ms": 0.214254972753257, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006192564964294434, "StateBufferConnector_ms": 0.0032993555068969727, "ViewRequirementAgentConnector_ms": 0.09042108058929443}, "num_episodes": 18, "episode_return_max": 340.3999999999999, "episode_return_min": -474.6, "episode_return_mean": -161.57000000000005, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 768000, "num_agent_steps_trained": 768000, "num_env_steps_sampled": 192000, "num_env_steps_trained": 192000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 372.9542493484833, "num_env_steps_trained_throughput_per_sec": 372.9542493484833, "timesteps_total": 192000, "num_env_steps_sampled_lifetime": 192000, "num_agent_steps_sampled_lifetime": 768000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 768000, "timers": {"training_iteration_time_ms": 10894.491, "restore_workers_time_ms": 0.014, "training_step_time_ms": 10894.421, "sample_time_ms": 1289.604, "learn_time_ms": 9587.152, "learn_throughput": 417.225, "synch_weights_time_ms": 16.277}, "counters": {"num_env_steps_sampled": 192000, "num_env_steps_trained": 192000, "num_agent_steps_sampled": 768000, "num_agent_steps_trained": 768000}, "done": false, "training_iteration": 48, "trial_id": "3dae5_00000", "date": "2024-08-14_09-15-43", "timestamp": 1723641343, "time_this_iter_s": 10.731242179870605, "time_total_s": 2163.9199874401093, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0fd1a60>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2163.9199874401093, "iterations_since_restore": 48, "perf": {"cpu_util_percent": 29.086666666666662, "ram_util_percent": 83.6}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.279796866702024, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.736111359621482, "policy_loss": -0.0016601423963303209, "vf_loss": 8.735009275668512, "vf_explained_var": -0.15080123348210855, "kl": 0.01227649115948184, "entropy": 1.1215184795793403, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 91665.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.8263935428132454, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.792990707089661, "policy_loss": -0.008098871632671308, "vf_loss": 5.7996053264254614, "vf_explained_var": -0.08582995351029452, "kl": 0.009894947470345186, "entropy": 1.296636575428897, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 91665.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 196000, "num_env_steps_trained": 196000, "num_agent_steps_sampled": 784000, "num_agent_steps_trained": 784000}, "env_runners": {"episode_reward_max": 340.3999999999999, "episode_reward_min": -474.6, "episode_reward_mean": -117.70700000000006, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 1.0}, "policy_reward_max": {"prey_policy": 178.3999999999999, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -182.86350000000002, "predator_policy": 124.01}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-44.19999999999983, -42.19999999999981, -0.799999999999743, -367.69999999999993, -342.5999999999997, -297.20000000000005, -66.49999999999991, -398.39999999999986, -52.89999999999983, -326.1, -269.8000000000005, -171.30000000000075, -57.20000000000006, -122.80000000000022, -205.00000000000009, -36.499999999999936, -379.3, -201.70000000000002, -347.50000000000045, -395.7, -389.29999999999984, -10.699999999999974, -321.1, -263.2, -0.999999999999814, -277.9, -34.899999999999835, -383.0, -379.6, -231.4000000000007, 22.500000000000213, -354.5, -230.50000000000009, 30.100000000000144, 8.799999999999843, 20.700000000000273, -29.299999999999734, -135.8, 12.699999999999996, -230.8000000000004, 340.3999999999999, -337.8999999999994, -273.5, -111.80000000000027, -31.299999999999834, -383.9, -474.6, -9.900000000000036, -118.20000000000005, -214.10000000000068, -216.0, -123.10000000000076, -194.8, 27.6000000000001, -344.99999999999994, 11.599999999999957, -108.60000000000053, -70.80000000000007, 4.099999999999998, -370.30000000000007, -368.09999999999997, -11.200000000000028, -345.20000000000005, -79.0000000000009, 39.20000000000022, -8.999999999999943, -295.89999999999975, 32.800000000000196, -15.399999999999885, -13.999999999999778, -204.6000000000007, -20.19999999999997, -82.99999999999989, 3.999999999999987, 95.2999999999999, -14.999999999999979, -406.9, 77.9999999999995, 180.0, 146.99999999999926, 52.90000000000021, 14.700000000000056, -114.20000000000081, -22.69999999999954, -61.69999999999999, -52.80000000000044, 25.999999999999936, -108.50000000000097, -112.0, 74.1, -13.799999999999704, 28.69999999999999, -70.30000000000089, 33.80000000000021, 117.39999999999989, -12.899999999999608, -72.10000000000039, 38.10000000000004, 11.49999999999993, 67.99999999999959], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-47.19999999999976, -151.0, 11.599999999999964, -332.79999999999995, -11.499999999999819, -28.29999999999975, -332.5000000000001, -335.20000000000005, -355.2999999999996, -379.30000000000007, -395.8, -282.4, 9.499999999999964, -193.00000000000026, -350.5000000000001, -397.9, -169.00000000000009, -19.89999999999975, -400.0, -321.1, -358.0000000000001, -206.79999999999998, -358.9000000000001, -9.399999999999855, -397.0, -5.1999999999999265, -263.49999999999994, -7.299999999999891, -185.8, -350.19999999999993, -32.49999999999975, -133.0, -329.5, -383.8, -171.70000000000002, -400.0, -339.10000000000014, -183.4000000000003, -328.0, -330.7, -385.29999999999984, -400.0, 20.000000000000014, -393.69999999999993, -380.79999999999995, -304.3, -328.5999999999996, -328.5999999999998, 3.1999999999999615, -152.20000000000067, -307.9000000000001, -286.0, 20.000000000000014, -313.90000000000015, -394.0, -388.0, -383.20000000000005, -384.4, -341.79999999999967, -139.60000000000056, -55.600000000000335, -202.9, -380.5, -358.0, -388.0, -212.50000000000009, 7.399999999999965, 13.699999999999964, -47.19999999999976, -64.0, -241.0000000000001, -7.299999999999891, -24.099999999999746, -299.2, -391.9, -124.9, 29.0, -298.30000000000007, -265.0, -248.8000000000004, 178.3999999999999, 125.0, -294.1, -326.80000000000007, -391.6, -166.90000000000063, -309.7, 17.899999999999988, 16.69999999999997, -370.0, -376.9, -400.0, -280.6, -400.0, -397.9, 20.000000000000014, -385.29999999999984, -91.9, -400.0, -108.10000000000055, -73.0, -343.0, -28.29999999999975, -377.8, -146.8, -400.0, 9.499999999999964, 1.0999999999999865, -324.4, -391.6, 11.599999999999964, -400.0, -271.9000000000001, 5.299999999999965, -11.499999999999819, -247.30000000000007, 20.000000000000014, -355.9000000000001, -400.0, -358.30000000000007, -370.0, -321.09999999999997, 5.299999999999965, -263.50000000000006, -397.9, -322.3, -337.00000000000017, -0.9999999999999846, -233.8, -0.9999999999999846, -7.299999999999891, -297.70000000000005, -330.7, -341.1999999999998, 20.000000000000014, -5.1999999999999265, -51.39999999999992, -292.0, -355.0000000000001, 20.000000000000014, -331.0, -139.6000000000007, -248.80000000000015, -9.399999999999855, -100.90000000000006, -291.10000000000014, -253.0, 20.000000000000014, 5.299999999999965, -73.0, -355.0, 20.000000000000014, -400.0, -397.9, 20.000000000000014, -115.0, -31.0, 83.0, -80.00000000000001, 163.99999999999977, -3.099999999999958, -133.0, -112.30000000000075, -7.0, -103.9000000000008, -175.30000000000027, -87.10000000000079, 7.399999999999965, -372.7, -37.0, -53.50000000000015, -145.3, -121.0, 20.000000000000014, -103.9000000000008, -238.60000000000016, -133.0, -229.0, -175.0, -4.899999999999999, -124.90000000000057, 1.0999999999999865, -3.399999999999764, -46.90000000000002, -49.29999999999976, -181.0, 20.000000000000014, -5.1999999999999265, -13.599999999999783, 38.0, -70.30000000000035, -13.599999999999786, -32.49999999999975, -196.6000000000003, 1.3999999999999726, -40.300000000000004, -287.5000000000002, 20.000000000000014, -196.0, 20.000000000000014], "policy_predator_policy_reward": [122.0, 32.0, 144.0, 135.0, 22.0, 17.0, 198.0, 102.0, 198.0, 194.0, 182.0, 199.0, 112.0, 5.0, 187.0, 163.0, 117.0, 19.0, 197.0, 198.0, 122.0, 173.0, 14.0, 183.0, 187.0, 158.0, 13.0, 135.0, 186.0, 145.0, 105.0, 24.0, 189.0, 145.0, 198.0, 172.0, 172.0, 3.0, 195.0, 68.0, 197.0, 199.0, 183.0, 180.0, 173.0, 191.0, 200.0, 194.0, 76.0, 72.0, 150.0, 166.0, 148.0, 111.0, 199.0, 200.0, 188.0, 200.0, 76.0, 174.0, 133.0, 148.0, 192.0, 192.0, 189.0, 181.0, 6.0, 3.0, 32.0, 88.0, 120.0, 149.0, 136.0, 158.0, 183.0, 198.0, 147.0, 135.0, 128.0, 155.0, 19.0, 18.0, 151.0, 132.0, 196.0, 89.0, 41.0, 139.0, 180.0, 142.0, 200.0, 193.0, 6.0, 200.0, 188.0, 180.0, 193.0, 166.0, 185.0, 109.0, 4.0, 196.0, 91.0, 192.0, 200.0, 152.0, 9.0, 8.0, 193.0, 178.0, 200.0, 200.0, 1.0, 157.0, 134.0, 54.0, 173.0, 167.0, 195.0, 193.0, 190.0, 133.0, 133.0, 114.0, 182.0, 193.0, 116.0, 143.0, 140.0, 134.0, 159.0, 137.0, 187.0, 189.0, 12.0, 6.0, 170.0, 158.0, 149.0, 172.0, 160.0, 106.0, 100.0, 138.0, 143.0, 166.0, 102.0, 135.0, 74.0, 89.0, 147.0, 173.0, 193.0, 198.0, 104.0, 69.0, 43.0, 85.0, 57.0, 6.0, 106.0, 83.0, 41.0, 93.0, 81.0, 84.0, 51.0, 6.0, 175.0, 173.0, 103.0, 43.0, 68.0, 59.0, 116.0, 118.0, 78.0, 172.0, 139.0, 115.0, 61.0, 49.0, 33.0, 46.0, 117.0, 43.0, 12.0, 7.0, 47.0, 46.0, 49.0, 22.0, 78.0, 79.0, 47.0, 30.0, 133.0, 146.0, 124.0, 120.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6308613709918887, "mean_inference_ms": 1.9642992771218297, "mean_action_processing_ms": 0.2795806449337851, "mean_env_wait_ms": 0.21365505655294342, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005479931831359863, "StateBufferConnector_ms": 0.0032012462615966797, "ViewRequirementAgentConnector_ms": 0.08884561061859131}, "num_episodes": 22, "episode_return_max": 340.3999999999999, "episode_return_min": -474.6, "episode_return_mean": -117.70700000000006, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 784000, "num_agent_steps_trained": 784000, "num_env_steps_sampled": 196000, "num_env_steps_trained": 196000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 379.7017502312084, "num_env_steps_trained_throughput_per_sec": 379.7017502312084, "timesteps_total": 196000, "num_env_steps_sampled_lifetime": 196000, "num_agent_steps_sampled_lifetime": 784000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 784000, "timers": {"training_iteration_time_ms": 10873.522, "restore_workers_time_ms": 0.014, "training_step_time_ms": 10873.453, "sample_time_ms": 1282.682, "learn_time_ms": 9573.229, "learn_throughput": 417.832, "synch_weights_time_ms": 16.122}, "counters": {"num_env_steps_sampled": 196000, "num_env_steps_trained": 196000, "num_agent_steps_sampled": 784000, "num_agent_steps_trained": 784000}, "done": false, "training_iteration": 49, "trial_id": "3dae5_00000", "date": "2024-08-14_09-15-54", "timestamp": 1723641354, "time_this_iter_s": 10.539726972579956, "time_total_s": 2174.459714412689, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0fd1f70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2174.459714412689, "iterations_since_restore": 49, "perf": {"cpu_util_percent": 27.19333333333333, "ram_util_percent": 83.48666666666666}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.445852653690116, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.954750637781052, "policy_loss": -0.0035103059951560917, "vf_loss": 8.9567585771046, "vf_explained_var": -0.24089259580960348, "kl": 0.0066771119108057905, "entropy": 1.1315321090360166, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 93555.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.747439562485962, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.610830879211425, "policy_loss": -0.00855443648939765, "vf_loss": 6.6180806414790885, "vf_explained_var": -0.03249761310834733, "kl": 0.00869776031671275, "entropy": 1.2967978271227034, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 93555.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 200000, "num_env_steps_trained": 200000, "num_agent_steps_sampled": 800000, "num_agent_steps_trained": 800000}, "env_runners": {"episode_reward_max": 340.3999999999999, "episode_reward_min": -474.6, "episode_reward_mean": -65.22500000000005, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 1.0}, "policy_reward_max": {"prey_policy": 178.3999999999999, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -144.12750000000005, "predator_policy": 111.515}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-263.2, -0.999999999999814, -277.9, -34.899999999999835, -383.0, -379.6, -231.4000000000007, 22.500000000000213, -354.5, -230.50000000000009, 30.100000000000144, 8.799999999999843, 20.700000000000273, -29.299999999999734, -135.8, 12.699999999999996, -230.8000000000004, 340.3999999999999, -337.8999999999994, -273.5, -111.80000000000027, -31.299999999999834, -383.9, -474.6, -9.900000000000036, -118.20000000000005, -214.10000000000068, -216.0, -123.10000000000076, -194.8, 27.6000000000001, -344.99999999999994, 11.599999999999957, -108.60000000000053, -70.80000000000007, 4.099999999999998, -370.30000000000007, -368.09999999999997, -11.200000000000028, -345.20000000000005, -79.0000000000009, 39.20000000000022, -8.999999999999943, -295.89999999999975, 32.800000000000196, -15.399999999999885, -13.999999999999778, -204.6000000000007, -20.19999999999997, -82.99999999999989, 3.999999999999987, 95.2999999999999, -14.999999999999979, -406.9, 77.9999999999995, 180.0, 146.99999999999926, 52.90000000000021, 14.700000000000056, -114.20000000000081, -22.69999999999954, -61.69999999999999, -52.80000000000044, 25.999999999999936, -108.50000000000097, -112.0, 74.1, -13.799999999999704, 28.69999999999999, -70.30000000000089, 33.80000000000021, 117.39999999999989, -12.899999999999608, -72.10000000000039, 38.10000000000004, 11.49999999999993, 67.99999999999959, 79.60000000000008, 22.40000000000004, -50.0, 92.70000000000002, 74.20000000000006, 126.1, -5.400000000000066, 75.50000000000007, -193.89999999999995, -15.599999999999506, -9.69999999999963, -245.00000000000017, 268.0, 124.19999999999999, -10.399999999999602, 44.30000000000011, -26.400000000000006, 114.89999999999964, 65.50000000000026, -40.99999999999981, -48.90000000000048, -68.29999999999987, 28.900000000000126], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-328.5999999999996, -328.5999999999998, 3.1999999999999615, -152.20000000000067, -307.9000000000001, -286.0, 20.000000000000014, -313.90000000000015, -394.0, -388.0, -383.20000000000005, -384.4, -341.79999999999967, -139.60000000000056, -55.600000000000335, -202.9, -380.5, -358.0, -388.0, -212.50000000000009, 7.399999999999965, 13.699999999999964, -47.19999999999976, -64.0, -241.0000000000001, -7.299999999999891, -24.099999999999746, -299.2, -391.9, -124.9, 29.0, -298.30000000000007, -265.0, -248.8000000000004, 178.3999999999999, 125.0, -294.1, -326.80000000000007, -391.6, -166.90000000000063, -309.7, 17.899999999999988, 16.69999999999997, -370.0, -376.9, -400.0, -280.6, -400.0, -397.9, 20.000000000000014, -385.29999999999984, -91.9, -400.0, -108.10000000000055, -73.0, -343.0, -28.29999999999975, -377.8, -146.8, -400.0, 9.499999999999964, 1.0999999999999865, -324.4, -391.6, 11.599999999999964, -400.0, -271.9000000000001, 5.299999999999965, -11.499999999999819, -247.30000000000007, 20.000000000000014, -355.9000000000001, -400.0, -358.30000000000007, -370.0, -321.09999999999997, 5.299999999999965, -263.50000000000006, -397.9, -322.3, -337.00000000000017, -0.9999999999999846, -233.8, -0.9999999999999846, -7.299999999999891, -297.70000000000005, -330.7, -341.1999999999998, 20.000000000000014, -5.1999999999999265, -51.39999999999992, -292.0, -355.0000000000001, 20.000000000000014, -331.0, -139.6000000000007, -248.80000000000015, -9.399999999999855, -100.90000000000006, -291.10000000000014, -253.0, 20.000000000000014, 5.299999999999965, -73.0, -355.0, 20.000000000000014, -400.0, -397.9, 20.000000000000014, -115.0, -31.0, 83.0, -80.00000000000001, 163.99999999999977, -3.099999999999958, -133.0, -112.30000000000075, -7.0, -103.9000000000008, -175.30000000000027, -87.10000000000079, 7.399999999999965, -372.7, -37.0, -53.50000000000015, -145.3, -121.0, 20.000000000000014, -103.9000000000008, -238.60000000000016, -133.0, -229.0, -175.0, -4.899999999999999, -124.90000000000057, 1.0999999999999865, -3.399999999999764, -46.90000000000002, -49.29999999999976, -181.0, 20.000000000000014, -5.1999999999999265, -13.599999999999783, 38.0, -70.30000000000035, -13.599999999999786, -32.49999999999975, -196.6000000000003, 1.3999999999999726, -40.300000000000004, -287.5000000000002, 20.000000000000014, -196.0, 20.000000000000014, 11.599999999999964, -97.0, -76.59999999999985, -67.0, 113.0, -400.0, -136.60000000000002, 11.299999999999999, -182.80000000000058, 107.0, -13.0, -4.900000000000006, -229.9, -53.50000000000019, -11.499999999999819, 5.0, -179.50000000000017, -276.4000000000001, -7.299999999999905, -49.29999999999985, -61.900000000000084, 3.1999999999999615, -256.30000000000007, -330.70000000000016, 125.0, 86.0, 141.2, -283.0, -45.09999999999976, -7.299999999999898, 20.000000000000014, -129.7, -225.4, -97.0, 9.499999999999964, 52.400000000000006, 9.499999999999964, -157.0, -78.7000000000005, -46.299999999999955, -135.1, -80.80000000000084, -19.899999999999743, -324.4, -3.0999999999999615, 20.000000000000014], "policy_predator_policy_reward": [200.0, 194.0, 76.0, 72.0, 150.0, 166.0, 148.0, 111.0, 199.0, 200.0, 188.0, 200.0, 76.0, 174.0, 133.0, 148.0, 192.0, 192.0, 189.0, 181.0, 6.0, 3.0, 32.0, 88.0, 120.0, 149.0, 136.0, 158.0, 183.0, 198.0, 147.0, 135.0, 128.0, 155.0, 19.0, 18.0, 151.0, 132.0, 196.0, 89.0, 41.0, 139.0, 180.0, 142.0, 200.0, 193.0, 6.0, 200.0, 188.0, 180.0, 193.0, 166.0, 185.0, 109.0, 4.0, 196.0, 91.0, 192.0, 200.0, 152.0, 9.0, 8.0, 193.0, 178.0, 200.0, 200.0, 1.0, 157.0, 134.0, 54.0, 173.0, 167.0, 195.0, 193.0, 190.0, 133.0, 133.0, 114.0, 182.0, 193.0, 116.0, 143.0, 140.0, 134.0, 159.0, 137.0, 187.0, 189.0, 12.0, 6.0, 170.0, 158.0, 149.0, 172.0, 160.0, 106.0, 100.0, 138.0, 143.0, 166.0, 102.0, 135.0, 74.0, 89.0, 147.0, 173.0, 193.0, 198.0, 104.0, 69.0, 43.0, 85.0, 57.0, 6.0, 106.0, 83.0, 41.0, 93.0, 81.0, 84.0, 51.0, 6.0, 175.0, 173.0, 103.0, 43.0, 68.0, 59.0, 116.0, 118.0, 78.0, 172.0, 139.0, 115.0, 61.0, 49.0, 33.0, 46.0, 117.0, 43.0, 12.0, 7.0, 47.0, 46.0, 49.0, 22.0, 78.0, 79.0, 47.0, 30.0, 133.0, 146.0, 124.0, 120.0, 86.0, 79.0, 98.0, 68.0, 200.0, 37.0, 89.0, 129.0, 83.0, 67.0, 124.0, 20.0, 148.0, 130.0, 57.0, 25.0, 137.0, 125.0, 33.0, 8.0, 22.0, 27.0, 183.0, 159.0, 21.0, 36.0, 105.0, 161.0, 11.0, 31.0, 93.0, 61.0, 145.0, 151.0, 23.0, 30.0, 96.0, 117.0, 76.0, 8.0, 76.0, 91.0, 147.0, 129.0, 2.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6290269079404202, "mean_inference_ms": 1.9550459852577147, "mean_action_processing_ms": 0.2799461825582102, "mean_env_wait_ms": 0.21284194568937512, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005881667137145996, "StateBufferConnector_ms": 0.002934098243713379, "ViewRequirementAgentConnector_ms": 0.09414160251617432}, "num_episodes": 23, "episode_return_max": 340.3999999999999, "episode_return_min": -474.6, "episode_return_mean": -65.22500000000005, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 800000, "num_agent_steps_trained": 800000, "num_env_steps_sampled": 200000, "num_env_steps_trained": 200000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 367.68683382274696, "num_env_steps_trained_throughput_per_sec": 367.68683382274696, "timesteps_total": 200000, "num_env_steps_sampled_lifetime": 200000, "num_agent_steps_sampled_lifetime": 800000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 800000, "timers": {"training_iteration_time_ms": 10883.74, "restore_workers_time_ms": 0.013, "training_step_time_ms": 10883.671, "sample_time_ms": 1282.794, "learn_time_ms": 9583.39, "learn_throughput": 417.389, "synch_weights_time_ms": 16.055}, "counters": {"num_env_steps_sampled": 200000, "num_env_steps_trained": 200000, "num_agent_steps_sampled": 800000, "num_agent_steps_trained": 800000}, "done": false, "training_iteration": 50, "trial_id": "3dae5_00000", "date": "2024-08-14_09-16-05", "timestamp": 1723641365, "time_this_iter_s": 10.893980026245117, "time_total_s": 2185.3536944389343, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3629ca0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2185.3536944389343, "iterations_since_restore": 50, "perf": {"cpu_util_percent": 28.206666666666663, "ram_util_percent": 83.70666666666668}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.7763366267794654, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.82902033038871, "policy_loss": -0.004279587147868282, "vf_loss": 8.83165611262044, "vf_explained_var": -0.29851938129732847, "kl": 0.007305821694377372, "entropy": 1.1454055115028663, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 95445.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.6661574533376746, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.50322286363632, "policy_loss": -0.008538091483540716, "vf_loss": 5.509923571632022, "vf_explained_var": 0.05477807083457866, "kl": 0.01224919857546199, "entropy": 1.365102347242769, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 95445.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 204000, "num_env_steps_trained": 204000, "num_agent_steps_sampled": 816000, "num_agent_steps_trained": 816000}, "env_runners": {"episode_reward_max": 268.0, "episode_reward_min": -474.6, "episode_reward_mean": -36.37500000000006, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 1.0}, "policy_reward_max": {"prey_policy": 163.99999999999977, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -115.56750000000005, "predator_policy": 97.38}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-337.8999999999994, -273.5, -111.80000000000027, -31.299999999999834, -383.9, -474.6, -9.900000000000036, -118.20000000000005, -214.10000000000068, -216.0, -123.10000000000076, -194.8, 27.6000000000001, -344.99999999999994, 11.599999999999957, -108.60000000000053, -70.80000000000007, 4.099999999999998, -370.30000000000007, -368.09999999999997, -11.200000000000028, -345.20000000000005, -79.0000000000009, 39.20000000000022, -8.999999999999943, -295.89999999999975, 32.800000000000196, -15.399999999999885, -13.999999999999778, -204.6000000000007, -20.19999999999997, -82.99999999999989, 3.999999999999987, 95.2999999999999, -14.999999999999979, -406.9, 77.9999999999995, 180.0, 146.99999999999926, 52.90000000000021, 14.700000000000056, -114.20000000000081, -22.69999999999954, -61.69999999999999, -52.80000000000044, 25.999999999999936, -108.50000000000097, -112.0, 74.1, -13.799999999999704, 28.69999999999999, -70.30000000000089, 33.80000000000021, 117.39999999999989, -12.899999999999608, -72.10000000000039, 38.10000000000004, 11.49999999999993, 67.99999999999959, 79.60000000000008, 22.40000000000004, -50.0, 92.70000000000002, 74.20000000000006, 126.1, -5.400000000000066, 75.50000000000007, -193.89999999999995, -15.599999999999506, -9.69999999999963, -245.00000000000017, 268.0, 124.19999999999999, -10.399999999999602, 44.30000000000011, -26.400000000000006, 114.89999999999964, 65.50000000000026, -40.99999999999981, -48.90000000000048, -68.29999999999987, 28.900000000000126, -88.80000000000035, 0.4000000000002285, 70.40000000000035, 9.299999999999939, 28.90000000000027, 53.30000000000012, -4.299999999999823, 59.700000000000315, 175.9999999999995, 90.50000000000007, -57.20000000000138, 59.300000000000004, 189.79999999999933, 112.4999999999998, -10.699999999999784, -31.29999999999952, 9.500000000000053, 100.99999999999994], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-294.1, -326.80000000000007, -391.6, -166.90000000000063, -309.7, 17.899999999999988, 16.69999999999997, -370.0, -376.9, -400.0, -280.6, -400.0, -397.9, 20.000000000000014, -385.29999999999984, -91.9, -400.0, -108.10000000000055, -73.0, -343.0, -28.29999999999975, -377.8, -146.8, -400.0, 9.499999999999964, 1.0999999999999865, -324.4, -391.6, 11.599999999999964, -400.0, -271.9000000000001, 5.299999999999965, -11.499999999999819, -247.30000000000007, 20.000000000000014, -355.9000000000001, -400.0, -358.30000000000007, -370.0, -321.09999999999997, 5.299999999999965, -263.50000000000006, -397.9, -322.3, -337.00000000000017, -0.9999999999999846, -233.8, -0.9999999999999846, -7.299999999999891, -297.70000000000005, -330.7, -341.1999999999998, 20.000000000000014, -5.1999999999999265, -51.39999999999992, -292.0, -355.0000000000001, 20.000000000000014, -331.0, -139.6000000000007, -248.80000000000015, -9.399999999999855, -100.90000000000006, -291.10000000000014, -253.0, 20.000000000000014, 5.299999999999965, -73.0, -355.0, 20.000000000000014, -400.0, -397.9, 20.000000000000014, -115.0, -31.0, 83.0, -80.00000000000001, 163.99999999999977, -3.099999999999958, -133.0, -112.30000000000075, -7.0, -103.9000000000008, -175.30000000000027, -87.10000000000079, 7.399999999999965, -372.7, -37.0, -53.50000000000015, -145.3, -121.0, 20.000000000000014, -103.9000000000008, -238.60000000000016, -133.0, -229.0, -175.0, -4.899999999999999, -124.90000000000057, 1.0999999999999865, -3.399999999999764, -46.90000000000002, -49.29999999999976, -181.0, 20.000000000000014, -5.1999999999999265, -13.599999999999783, 38.0, -70.30000000000035, -13.599999999999786, -32.49999999999975, -196.6000000000003, 1.3999999999999726, -40.300000000000004, -287.5000000000002, 20.000000000000014, -196.0, 20.000000000000014, 11.599999999999964, -97.0, -76.59999999999985, -67.0, 113.0, -400.0, -136.60000000000002, 11.299999999999999, -182.80000000000058, 107.0, -13.0, -4.900000000000006, -229.9, -53.50000000000019, -11.499999999999819, 5.0, -179.50000000000017, -276.4000000000001, -7.299999999999905, -49.29999999999985, -61.900000000000084, 3.1999999999999615, -256.30000000000007, -330.70000000000016, 125.0, 86.0, 141.2, -283.0, -45.09999999999976, -7.299999999999898, 20.000000000000014, -129.7, -225.4, -97.0, 9.499999999999964, 52.400000000000006, 9.499999999999964, -157.0, -78.7000000000005, -46.299999999999955, -135.1, -80.80000000000084, -19.899999999999743, -324.4, -3.0999999999999615, 20.000000000000014, -53.80000000000001, -250.00000000000037, -0.9999999999999992, -55.600000000000264, 48.80000000000024, -27.399999999999835, -162.70000000000064, 20.000000000000014, 17.899999999999988, -1.0000000000000346, -15.699999999999747, -22.0, -49.29999999999984, -82.0, -26.199999999999875, -24.099999999999746, 17.899999999999988, 88.1, 18.80000000000001, -25.29999999999989, -57.70000000000048, -53.50000000000019, -192.7, 20.000000000000014, 150.79999999999995, 20.000000000000014, 20.0, 9.499999999999964, -254.8, -19.89999999999999, -24.099999999999746, -68.20000000000087, -88.60000000000059, -19.899999999999885, 59.00000000000017, -184.0], "policy_predator_policy_reward": [151.0, 132.0, 196.0, 89.0, 41.0, 139.0, 180.0, 142.0, 200.0, 193.0, 6.0, 200.0, 188.0, 180.0, 193.0, 166.0, 185.0, 109.0, 4.0, 196.0, 91.0, 192.0, 200.0, 152.0, 9.0, 8.0, 193.0, 178.0, 200.0, 200.0, 1.0, 157.0, 134.0, 54.0, 173.0, 167.0, 195.0, 193.0, 190.0, 133.0, 133.0, 114.0, 182.0, 193.0, 116.0, 143.0, 140.0, 134.0, 159.0, 137.0, 187.0, 189.0, 12.0, 6.0, 170.0, 158.0, 149.0, 172.0, 160.0, 106.0, 100.0, 138.0, 143.0, 166.0, 102.0, 135.0, 74.0, 89.0, 147.0, 173.0, 193.0, 198.0, 104.0, 69.0, 43.0, 85.0, 57.0, 6.0, 106.0, 83.0, 41.0, 93.0, 81.0, 84.0, 51.0, 6.0, 175.0, 173.0, 103.0, 43.0, 68.0, 59.0, 116.0, 118.0, 78.0, 172.0, 139.0, 115.0, 61.0, 49.0, 33.0, 46.0, 117.0, 43.0, 12.0, 7.0, 47.0, 46.0, 49.0, 22.0, 78.0, 79.0, 47.0, 30.0, 133.0, 146.0, 124.0, 120.0, 86.0, 79.0, 98.0, 68.0, 200.0, 37.0, 89.0, 129.0, 83.0, 67.0, 124.0, 20.0, 148.0, 130.0, 57.0, 25.0, 137.0, 125.0, 33.0, 8.0, 22.0, 27.0, 183.0, 159.0, 21.0, 36.0, 105.0, 161.0, 11.0, 31.0, 93.0, 61.0, 145.0, 151.0, 23.0, 30.0, 96.0, 117.0, 76.0, 8.0, 76.0, 91.0, 147.0, 129.0, 2.0, 10.0, 134.0, 81.0, 36.0, 21.0, 8.0, 41.0, 72.0, 80.0, 10.0, 2.0, 58.0, 33.0, 85.0, 42.0, 52.0, 58.0, 36.0, 34.0, 27.0, 70.0, 17.0, 37.0, 123.0, 109.0, 14.0, 5.0, 59.0, 24.0, 128.0, 136.0, 47.0, 14.0, 42.0, 76.0, 108.0, 118.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6273155276218334, "mean_inference_ms": 1.950592453847, "mean_action_processing_ms": 0.27824710522755197, "mean_env_wait_ms": 0.2120910125374985, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005600452423095703, "StateBufferConnector_ms": 0.002957940101623535, "ViewRequirementAgentConnector_ms": 0.09534454345703125}, "num_episodes": 18, "episode_return_max": 268.0, "episode_return_min": -474.6, "episode_return_mean": -36.37500000000006, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 816000, "num_agent_steps_trained": 816000, "num_env_steps_sampled": 204000, "num_env_steps_trained": 204000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 373.6277812830681, "num_env_steps_trained_throughput_per_sec": 373.6277812830681, "timesteps_total": 204000, "num_env_steps_sampled_lifetime": 204000, "num_agent_steps_sampled_lifetime": 816000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 816000, "timers": {"training_iteration_time_ms": 10887.533, "restore_workers_time_ms": 0.014, "training_step_time_ms": 10887.457, "sample_time_ms": 1286.346, "learn_time_ms": 9584.273, "learn_throughput": 417.35, "synch_weights_time_ms": 15.465}, "counters": {"num_env_steps_sampled": 204000, "num_env_steps_trained": 204000, "num_agent_steps_sampled": 816000, "num_agent_steps_trained": 816000}, "done": false, "training_iteration": 51, "trial_id": "3dae5_00000", "date": "2024-08-14_09-16-16", "timestamp": 1723641376, "time_this_iter_s": 10.719375133514404, "time_total_s": 2196.0730695724487, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0f81dc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2196.0730695724487, "iterations_since_restore": 51, "perf": {"cpu_util_percent": 29.03125, "ram_util_percent": 83.35624999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.147581836912367, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.639392551795515, "policy_loss": -0.005409705562630382, "vf_loss": 8.642350926222624, "vf_explained_var": -0.5665917401591306, "kl": 0.010894825564854403, "entropy": 1.155656450198441, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 97335.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.26161601568656, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.261008877476687, "policy_loss": -0.010605130547770944, "vf_loss": 4.270431906079489, "vf_explained_var": 0.23087914179241847, "kl": 0.007880681891015831, "entropy": 1.3720955462682816, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 97335.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 208000, "num_env_steps_trained": 208000, "num_agent_steps_sampled": 832000, "num_agent_steps_trained": 832000}, "env_runners": {"episode_reward_max": 268.0, "episode_reward_min": -406.9, "episode_reward_mean": 5.521999999999939, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 163.99999999999977, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -76.04400000000003, "predator_policy": 78.805}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-370.30000000000007, -368.09999999999997, -11.200000000000028, -345.20000000000005, -79.0000000000009, 39.20000000000022, -8.999999999999943, -295.89999999999975, 32.800000000000196, -15.399999999999885, -13.999999999999778, -204.6000000000007, -20.19999999999997, -82.99999999999989, 3.999999999999987, 95.2999999999999, -14.999999999999979, -406.9, 77.9999999999995, 180.0, 146.99999999999926, 52.90000000000021, 14.700000000000056, -114.20000000000081, -22.69999999999954, -61.69999999999999, -52.80000000000044, 25.999999999999936, -108.50000000000097, -112.0, 74.1, -13.799999999999704, 28.69999999999999, -70.30000000000089, 33.80000000000021, 117.39999999999989, -12.899999999999608, -72.10000000000039, 38.10000000000004, 11.49999999999993, 67.99999999999959, 79.60000000000008, 22.40000000000004, -50.0, 92.70000000000002, 74.20000000000006, 126.1, -5.400000000000066, 75.50000000000007, -193.89999999999995, -15.599999999999506, -9.69999999999963, -245.00000000000017, 268.0, 124.19999999999999, -10.399999999999602, 44.30000000000011, -26.400000000000006, 114.89999999999964, 65.50000000000026, -40.99999999999981, -48.90000000000048, -68.29999999999987, 28.900000000000126, -88.80000000000035, 0.4000000000002285, 70.40000000000035, 9.299999999999939, 28.90000000000027, 53.30000000000012, -4.299999999999823, 59.700000000000315, 175.9999999999995, 90.50000000000007, -57.20000000000138, 59.300000000000004, 189.79999999999933, 112.4999999999998, -10.699999999999784, -31.29999999999952, 9.500000000000053, 100.99999999999994, 13.499999999999902, 41.70000000000033, -5.099999999999685, 128.39999999999975, 2.399999999999587, 175.69999999999928, 53.00000000000012, 9.900000000000096, 83.19999999999982, 77.40000000000002, 71.39999999999998, 5.600000000000083, 84.79999999999933, 123.59999999999971, 25.70000000000007, 59.5000000000002, 164.49999999999952, 104.29999999999961], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-400.0, -358.30000000000007, -370.0, -321.09999999999997, 5.299999999999965, -263.50000000000006, -397.9, -322.3, -337.00000000000017, -0.9999999999999846, -233.8, -0.9999999999999846, -7.299999999999891, -297.70000000000005, -330.7, -341.1999999999998, 20.000000000000014, -5.1999999999999265, -51.39999999999992, -292.0, -355.0000000000001, 20.000000000000014, -331.0, -139.6000000000007, -248.80000000000015, -9.399999999999855, -100.90000000000006, -291.10000000000014, -253.0, 20.000000000000014, 5.299999999999965, -73.0, -355.0, 20.000000000000014, -400.0, -397.9, 20.000000000000014, -115.0, -31.0, 83.0, -80.00000000000001, 163.99999999999977, -3.099999999999958, -133.0, -112.30000000000075, -7.0, -103.9000000000008, -175.30000000000027, -87.10000000000079, 7.399999999999965, -372.7, -37.0, -53.50000000000015, -145.3, -121.0, 20.000000000000014, -103.9000000000008, -238.60000000000016, -133.0, -229.0, -175.0, -4.899999999999999, -124.90000000000057, 1.0999999999999865, -3.399999999999764, -46.90000000000002, -49.29999999999976, -181.0, 20.000000000000014, -5.1999999999999265, -13.599999999999783, 38.0, -70.30000000000035, -13.599999999999786, -32.49999999999975, -196.6000000000003, 1.3999999999999726, -40.300000000000004, -287.5000000000002, 20.000000000000014, -196.0, 20.000000000000014, 11.599999999999964, -97.0, -76.59999999999985, -67.0, 113.0, -400.0, -136.60000000000002, 11.299999999999999, -182.80000000000058, 107.0, -13.0, -4.900000000000006, -229.9, -53.50000000000019, -11.499999999999819, 5.0, -179.50000000000017, -276.4000000000001, -7.299999999999905, -49.29999999999985, -61.900000000000084, 3.1999999999999615, -256.30000000000007, -330.70000000000016, 125.0, 86.0, 141.2, -283.0, -45.09999999999976, -7.299999999999898, 20.000000000000014, -129.7, -225.4, -97.0, 9.499999999999964, 52.400000000000006, 9.499999999999964, -157.0, -78.7000000000005, -46.299999999999955, -135.1, -80.80000000000084, -19.899999999999743, -324.4, -3.0999999999999615, 20.000000000000014, -53.80000000000001, -250.00000000000037, -0.9999999999999992, -55.600000000000264, 48.80000000000024, -27.399999999999835, -162.70000000000064, 20.000000000000014, 17.899999999999988, -1.0000000000000346, -15.699999999999747, -22.0, -49.29999999999984, -82.0, -26.199999999999875, -24.099999999999746, 17.899999999999988, 88.1, 18.80000000000001, -25.29999999999989, -57.70000000000048, -53.50000000000019, -192.7, 20.000000000000014, 150.79999999999995, 20.000000000000014, 20.0, 9.499999999999964, -254.8, -19.89999999999999, -24.099999999999746, -68.20000000000087, -88.60000000000059, -19.899999999999885, 59.00000000000017, -184.0, 20.000000000000014, -32.49999999999975, -26.199999999999747, 17.89999999999999, -34.59999999999975, -11.499999999999819, 20.000000000000014, 13.400000000000006, -163.0, -52.60000000000001, 55.70000000000019, 41.0, 59.0, -148.00000000000068, 2.8999999999999613, -21.999999999999744, -3.099999999999958, 5.300000000000004, -19.900000000000006, 5.299999999999965, -7.0, -28.599999999999973, -13.599999999999914, -14.799999999999772, 1.0999999999999865, 31.700000000000095, -30.39999999999975, 95.0, 20.000000000000014, -7.299999999999891, 25.400000000000098, -1.8999999999998627, 9.499999999999964, 101.0, 40.400000000000034, -12.099999999999888], "policy_predator_policy_reward": [195.0, 193.0, 190.0, 133.0, 133.0, 114.0, 182.0, 193.0, 116.0, 143.0, 140.0, 134.0, 159.0, 137.0, 187.0, 189.0, 12.0, 6.0, 170.0, 158.0, 149.0, 172.0, 160.0, 106.0, 100.0, 138.0, 143.0, 166.0, 102.0, 135.0, 74.0, 89.0, 147.0, 173.0, 193.0, 198.0, 104.0, 69.0, 43.0, 85.0, 57.0, 6.0, 106.0, 83.0, 41.0, 93.0, 81.0, 84.0, 51.0, 6.0, 175.0, 173.0, 103.0, 43.0, 68.0, 59.0, 116.0, 118.0, 78.0, 172.0, 139.0, 115.0, 61.0, 49.0, 33.0, 46.0, 117.0, 43.0, 12.0, 7.0, 47.0, 46.0, 49.0, 22.0, 78.0, 79.0, 47.0, 30.0, 133.0, 146.0, 124.0, 120.0, 86.0, 79.0, 98.0, 68.0, 200.0, 37.0, 89.0, 129.0, 83.0, 67.0, 124.0, 20.0, 148.0, 130.0, 57.0, 25.0, 137.0, 125.0, 33.0, 8.0, 22.0, 27.0, 183.0, 159.0, 21.0, 36.0, 105.0, 161.0, 11.0, 31.0, 93.0, 61.0, 145.0, 151.0, 23.0, 30.0, 96.0, 117.0, 76.0, 8.0, 76.0, 91.0, 147.0, 129.0, 2.0, 10.0, 134.0, 81.0, 36.0, 21.0, 8.0, 41.0, 72.0, 80.0, 10.0, 2.0, 58.0, 33.0, 85.0, 42.0, 52.0, 58.0, 36.0, 34.0, 27.0, 70.0, 17.0, 37.0, 123.0, 109.0, 14.0, 5.0, 59.0, 24.0, 128.0, 136.0, 47.0, 14.0, 42.0, 76.0, 108.0, 118.0, 18.0, 8.0, 12.0, 38.0, 26.0, 15.0, 48.0, 47.0, 113.0, 105.0, 26.0, 53.0, 70.0, 72.0, 9.0, 20.0, 49.0, 32.0, 45.0, 47.0, 70.0, 37.0, 13.0, 21.0, 26.0, 26.0, 14.0, 45.0, 13.0, 0.0, 22.0, 14.0, 28.0, 26.0, 45.0, 31.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6258985209907446, "mean_inference_ms": 1.9456551476805493, "mean_action_processing_ms": 0.2773402230997455, "mean_env_wait_ms": 0.21157640607450076, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0050656795501708984, "StateBufferConnector_ms": 0.003069281578063965, "ViewRequirementAgentConnector_ms": 0.0965261459350586}, "num_episodes": 18, "episode_return_max": 268.0, "episode_return_min": -406.9, "episode_return_mean": 5.521999999999939, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 832000, "num_agent_steps_trained": 832000, "num_env_steps_sampled": 208000, "num_env_steps_trained": 208000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 368.85831981910894, "num_env_steps_trained_throughput_per_sec": 368.85831981910894, "timesteps_total": 208000, "num_env_steps_sampled_lifetime": 208000, "num_agent_steps_sampled_lifetime": 832000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 832000, "timers": {"training_iteration_time_ms": 10856.755, "restore_workers_time_ms": 0.014, "training_step_time_ms": 10856.689, "sample_time_ms": 1274.817, "learn_time_ms": 9564.999, "learn_throughput": 418.191, "synch_weights_time_ms": 15.584}, "counters": {"num_env_steps_sampled": 208000, "num_env_steps_trained": 208000, "num_agent_steps_sampled": 832000, "num_agent_steps_trained": 832000}, "done": false, "training_iteration": 52, "trial_id": "3dae5_00000", "date": "2024-08-14_09-16-27", "timestamp": 1723641387, "time_this_iter_s": 10.906215190887451, "time_total_s": 2206.979284763336, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b36180d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2206.979284763336, "iterations_since_restore": 52, "perf": {"cpu_util_percent": 29.23333333333333, "ram_util_percent": 83.43333333333334}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.720649716715333, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.983814056588228, "policy_loss": -0.009347259313503782, "vf_loss": 7.989544001332035, "vf_explained_var": -0.3382378538449605, "kl": 0.016076917156057566, "entropy": 1.142025471049011, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 99225.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.1439984056684707, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.687491916979432, "policy_loss": -0.00930382088762979, "vf_loss": 4.695399044808887, "vf_explained_var": 0.17664079208853384, "kl": 0.009311184289988337, "entropy": 1.375402302905996, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 99225.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 212000, "num_env_steps_trained": 212000, "num_agent_steps_sampled": 848000, "num_agent_steps_trained": 848000}, "env_runners": {"episode_reward_max": 268.0, "episode_reward_min": -245.00000000000017, "episode_reward_mean": 34.53899999999989, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 190.1, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -43.22550000000005, "predator_policy": 60.495}, "custom_metrics": {}, "hist_stats": {"episode_reward": [77.9999999999995, 180.0, 146.99999999999926, 52.90000000000021, 14.700000000000056, -114.20000000000081, -22.69999999999954, -61.69999999999999, -52.80000000000044, 25.999999999999936, -108.50000000000097, -112.0, 74.1, -13.799999999999704, 28.69999999999999, -70.30000000000089, 33.80000000000021, 117.39999999999989, -12.899999999999608, -72.10000000000039, 38.10000000000004, 11.49999999999993, 67.99999999999959, 79.60000000000008, 22.40000000000004, -50.0, 92.70000000000002, 74.20000000000006, 126.1, -5.400000000000066, 75.50000000000007, -193.89999999999995, -15.599999999999506, -9.69999999999963, -245.00000000000017, 268.0, 124.19999999999999, -10.399999999999602, 44.30000000000011, -26.400000000000006, 114.89999999999964, 65.50000000000026, -40.99999999999981, -48.90000000000048, -68.29999999999987, 28.900000000000126, -88.80000000000035, 0.4000000000002285, 70.40000000000035, 9.299999999999939, 28.90000000000027, 53.30000000000012, -4.299999999999823, 59.700000000000315, 175.9999999999995, 90.50000000000007, -57.20000000000138, 59.300000000000004, 189.79999999999933, 112.4999999999998, -10.699999999999784, -31.29999999999952, 9.500000000000053, 100.99999999999994, 13.499999999999902, 41.70000000000033, -5.099999999999685, 128.39999999999975, 2.399999999999587, 175.69999999999928, 53.00000000000012, 9.900000000000096, 83.19999999999982, 77.40000000000002, 71.39999999999998, 5.600000000000083, 84.79999999999933, 123.59999999999971, 25.70000000000007, 59.5000000000002, 164.49999999999952, 104.29999999999961, 23.50000000000003, 177.99999999999983, 220.19999999999993, 167.09999999999934, -14.9, -201.2000000000004, 135.99999999999963, -55.700000000000024, 50.90000000000005, -63.60000000000181, 40.40000000000034, 107.09999999999984, 15.800000000000004, -44.69999999999968, 137.59999999999957, -70.8000000000016, 32.700000000000195, 176.79999999999947], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, -115.0, -31.0, 83.0, -80.00000000000001, 163.99999999999977, -3.099999999999958, -133.0, -112.30000000000075, -7.0, -103.9000000000008, -175.30000000000027, -87.10000000000079, 7.399999999999965, -372.7, -37.0, -53.50000000000015, -145.3, -121.0, 20.000000000000014, -103.9000000000008, -238.60000000000016, -133.0, -229.0, -175.0, -4.899999999999999, -124.90000000000057, 1.0999999999999865, -3.399999999999764, -46.90000000000002, -49.29999999999976, -181.0, 20.000000000000014, -5.1999999999999265, -13.599999999999783, 38.0, -70.30000000000035, -13.599999999999786, -32.49999999999975, -196.6000000000003, 1.3999999999999726, -40.300000000000004, -287.5000000000002, 20.000000000000014, -196.0, 20.000000000000014, 11.599999999999964, -97.0, -76.59999999999985, -67.0, 113.0, -400.0, -136.60000000000002, 11.299999999999999, -182.80000000000058, 107.0, -13.0, -4.900000000000006, -229.9, -53.50000000000019, -11.499999999999819, 5.0, -179.50000000000017, -276.4000000000001, -7.299999999999905, -49.29999999999985, -61.900000000000084, 3.1999999999999615, -256.30000000000007, -330.70000000000016, 125.0, 86.0, 141.2, -283.0, -45.09999999999976, -7.299999999999898, 20.000000000000014, -129.7, -225.4, -97.0, 9.499999999999964, 52.400000000000006, 9.499999999999964, -157.0, -78.7000000000005, -46.299999999999955, -135.1, -80.80000000000084, -19.899999999999743, -324.4, -3.0999999999999615, 20.000000000000014, -53.80000000000001, -250.00000000000037, -0.9999999999999992, -55.600000000000264, 48.80000000000024, -27.399999999999835, -162.70000000000064, 20.000000000000014, 17.899999999999988, -1.0000000000000346, -15.699999999999747, -22.0, -49.29999999999984, -82.0, -26.199999999999875, -24.099999999999746, 17.899999999999988, 88.1, 18.80000000000001, -25.29999999999989, -57.70000000000048, -53.50000000000019, -192.7, 20.000000000000014, 150.79999999999995, 20.000000000000014, 20.0, 9.499999999999964, -254.8, -19.89999999999999, -24.099999999999746, -68.20000000000087, -88.60000000000059, -19.899999999999885, 59.00000000000017, -184.0, 20.000000000000014, -32.49999999999975, -26.199999999999747, 17.89999999999999, -34.59999999999975, -11.499999999999819, 20.000000000000014, 13.400000000000006, -163.0, -52.60000000000001, 55.70000000000019, 41.0, 59.0, -148.00000000000068, 2.8999999999999613, -21.999999999999744, -3.099999999999958, 5.300000000000004, -19.900000000000006, 5.299999999999965, -7.0, -28.599999999999973, -13.599999999999914, -14.799999999999772, 1.0999999999999865, 31.700000000000095, -30.39999999999975, 95.0, 20.000000000000014, -7.299999999999891, 25.400000000000098, -1.8999999999998627, 9.499999999999964, 101.0, 40.400000000000034, -12.099999999999888, 11.599999999999964, -3.099999999999958, 38.900000000000034, 37.1, -19.899999999999892, 190.1, 11.599999999999964, 123.49999999999991, -142.0, -19.899999999999743, -157.30000000000044, -208.9, 20.000000000000014, 41.00000000000002, -114.40000000000076, -94.29999999999995, -47.80000000000001, 13.699999999999955, -64.00000000000082, -55.60000000000011, 20.000000000000014, -13.599999999999868, 71.30000000000001, -89.20000000000081, -0.9999999999999846, -5.1999999999999265, -186.70000000000047, 20.000000000000014, -94.60000000000082, 90.19999999999999, -70.30000000000089, -95.50000000000071, 20.000000000000014, -7.299999999999891, 134.0, 15.799999999999962], "policy_predator_policy_reward": [104.0, 69.0, 43.0, 85.0, 57.0, 6.0, 106.0, 83.0, 41.0, 93.0, 81.0, 84.0, 51.0, 6.0, 175.0, 173.0, 103.0, 43.0, 68.0, 59.0, 116.0, 118.0, 78.0, 172.0, 139.0, 115.0, 61.0, 49.0, 33.0, 46.0, 117.0, 43.0, 12.0, 7.0, 47.0, 46.0, 49.0, 22.0, 78.0, 79.0, 47.0, 30.0, 133.0, 146.0, 124.0, 120.0, 86.0, 79.0, 98.0, 68.0, 200.0, 37.0, 89.0, 129.0, 83.0, 67.0, 124.0, 20.0, 148.0, 130.0, 57.0, 25.0, 137.0, 125.0, 33.0, 8.0, 22.0, 27.0, 183.0, 159.0, 21.0, 36.0, 105.0, 161.0, 11.0, 31.0, 93.0, 61.0, 145.0, 151.0, 23.0, 30.0, 96.0, 117.0, 76.0, 8.0, 76.0, 91.0, 147.0, 129.0, 2.0, 10.0, 134.0, 81.0, 36.0, 21.0, 8.0, 41.0, 72.0, 80.0, 10.0, 2.0, 58.0, 33.0, 85.0, 42.0, 52.0, 58.0, 36.0, 34.0, 27.0, 70.0, 17.0, 37.0, 123.0, 109.0, 14.0, 5.0, 59.0, 24.0, 128.0, 136.0, 47.0, 14.0, 42.0, 76.0, 108.0, 118.0, 18.0, 8.0, 12.0, 38.0, 26.0, 15.0, 48.0, 47.0, 113.0, 105.0, 26.0, 53.0, 70.0, 72.0, 9.0, 20.0, 49.0, 32.0, 45.0, 47.0, 70.0, 37.0, 13.0, 21.0, 26.0, 26.0, 14.0, 45.0, 13.0, 0.0, 22.0, 14.0, 28.0, 26.0, 45.0, 31.0, 11.0, 4.0, 57.0, 45.0, 1.0, 49.0, 21.0, 11.0, 71.0, 76.0, 31.0, 134.0, 30.0, 45.0, 75.0, 78.0, 3.0, 82.0, 14.0, 42.0, 24.0, 10.0, 75.0, 50.0, 10.0, 12.0, 14.0, 108.0, 77.0, 65.0, 23.0, 72.0, 13.0, 7.0, 9.0, 18.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6246936075551768, "mean_inference_ms": 1.9410967266982515, "mean_action_processing_ms": 0.27647509017307853, "mean_env_wait_ms": 0.21113433014154162, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004722714424133301, "StateBufferConnector_ms": 0.0033621788024902344, "ViewRequirementAgentConnector_ms": 0.1030418872833252}, "num_episodes": 18, "episode_return_max": 268.0, "episode_return_min": -245.00000000000017, "episode_return_mean": 34.53899999999989, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 848000, "num_agent_steps_trained": 848000, "num_env_steps_sampled": 212000, "num_env_steps_trained": 212000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 361.9048465460804, "num_env_steps_trained_throughput_per_sec": 361.9048465460804, "timesteps_total": 212000, "num_env_steps_sampled_lifetime": 212000, "num_agent_steps_sampled_lifetime": 848000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 848000, "timers": {"training_iteration_time_ms": 10850.491, "restore_workers_time_ms": 0.015, "training_step_time_ms": 10850.421, "sample_time_ms": 1284.771, "learn_time_ms": 9548.902, "learn_throughput": 418.896, "synch_weights_time_ms": 15.514}, "counters": {"num_env_steps_sampled": 212000, "num_env_steps_trained": 212000, "num_agent_steps_sampled": 848000, "num_agent_steps_trained": 848000}, "done": false, "training_iteration": 53, "trial_id": "3dae5_00000", "date": "2024-08-14_09-16-38", "timestamp": 1723641398, "time_this_iter_s": 11.06121015548706, "time_total_s": 2218.0404949188232, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3636a60>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2218.0404949188232, "iterations_since_restore": 53, "perf": {"cpu_util_percent": 30.3375, "ram_util_percent": 83.7375}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.5393674340828385, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.581629205128503, "policy_loss": -0.0032460570360026346, "vf_loss": 7.582457229069301, "vf_explained_var": -0.22093897629036474, "kl": 0.010746830797997431, "entropy": 1.1370796307684883, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 101115.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.5557362342006944, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.7760552720418055, "policy_loss": -0.005894861921234421, "vf_loss": 4.780578177694291, "vf_explained_var": 0.0003185669581095378, "kl": 0.009146384947436031, "entropy": 1.3826399934354914, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 101115.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 216000, "num_env_steps_trained": 216000, "num_agent_steps_sampled": 864000, "num_agent_steps_trained": 864000}, "env_runners": {"episode_reward_max": 272.50000000000006, "episode_reward_min": -245.00000000000017, "episode_reward_mean": 40.79199999999989, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 190.1, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -31.939000000000036, "predator_policy": 52.335}, "custom_metrics": {}, "hist_stats": {"episode_reward": [67.99999999999959, 79.60000000000008, 22.40000000000004, -50.0, 92.70000000000002, 74.20000000000006, 126.1, -5.400000000000066, 75.50000000000007, -193.89999999999995, -15.599999999999506, -9.69999999999963, -245.00000000000017, 268.0, 124.19999999999999, -10.399999999999602, 44.30000000000011, -26.400000000000006, 114.89999999999964, 65.50000000000026, -40.99999999999981, -48.90000000000048, -68.29999999999987, 28.900000000000126, -88.80000000000035, 0.4000000000002285, 70.40000000000035, 9.299999999999939, 28.90000000000027, 53.30000000000012, -4.299999999999823, 59.700000000000315, 175.9999999999995, 90.50000000000007, -57.20000000000138, 59.300000000000004, 189.79999999999933, 112.4999999999998, -10.699999999999784, -31.29999999999952, 9.500000000000053, 100.99999999999994, 13.499999999999902, 41.70000000000033, -5.099999999999685, 128.39999999999975, 2.399999999999587, 175.69999999999928, 53.00000000000012, 9.900000000000096, 83.19999999999982, 77.40000000000002, 71.39999999999998, 5.600000000000083, 84.79999999999933, 123.59999999999971, 25.70000000000007, 59.5000000000002, 164.49999999999952, 104.29999999999961, 23.50000000000003, 177.99999999999983, 220.19999999999993, 167.09999999999934, -14.9, -201.2000000000004, 135.99999999999963, -55.700000000000024, 50.90000000000005, -63.60000000000181, 40.40000000000034, 107.09999999999984, 15.800000000000004, -44.69999999999968, 137.59999999999957, -70.8000000000016, 32.700000000000195, 176.79999999999947, 253.79999999999973, 272.50000000000006, 59.00000000000048, 2.90000000000018, -141.30000000000123, 53.20000000000003, 146.9999999999997, -50.20000000000077, -15.099999999999543, 25.700000000000067, -50.9999999999999, 4.8000000000001855, 72.7999999999998, 113.89999999999935, 0.49999999999988043, 35.600000000000236, 33.50000000000019, -72.60000000000078, 112.59999999999937, 158.19999999999936, -18.200000000000124, -211.10000000000093], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-196.0, 20.000000000000014, 11.599999999999964, -97.0, -76.59999999999985, -67.0, 113.0, -400.0, -136.60000000000002, 11.299999999999999, -182.80000000000058, 107.0, -13.0, -4.900000000000006, -229.9, -53.50000000000019, -11.499999999999819, 5.0, -179.50000000000017, -276.4000000000001, -7.299999999999905, -49.29999999999985, -61.900000000000084, 3.1999999999999615, -256.30000000000007, -330.70000000000016, 125.0, 86.0, 141.2, -283.0, -45.09999999999976, -7.299999999999898, 20.000000000000014, -129.7, -225.4, -97.0, 9.499999999999964, 52.400000000000006, 9.499999999999964, -157.0, -78.7000000000005, -46.299999999999955, -135.1, -80.80000000000084, -19.899999999999743, -324.4, -3.0999999999999615, 20.000000000000014, -53.80000000000001, -250.00000000000037, -0.9999999999999992, -55.600000000000264, 48.80000000000024, -27.399999999999835, -162.70000000000064, 20.000000000000014, 17.899999999999988, -1.0000000000000346, -15.699999999999747, -22.0, -49.29999999999984, -82.0, -26.199999999999875, -24.099999999999746, 17.899999999999988, 88.1, 18.80000000000001, -25.29999999999989, -57.70000000000048, -53.50000000000019, -192.7, 20.000000000000014, 150.79999999999995, 20.000000000000014, 20.0, 9.499999999999964, -254.8, -19.89999999999999, -24.099999999999746, -68.20000000000087, -88.60000000000059, -19.899999999999885, 59.00000000000017, -184.0, 20.000000000000014, -32.49999999999975, -26.199999999999747, 17.89999999999999, -34.59999999999975, -11.499999999999819, 20.000000000000014, 13.400000000000006, -163.0, -52.60000000000001, 55.70000000000019, 41.0, 59.0, -148.00000000000068, 2.8999999999999613, -21.999999999999744, -3.099999999999958, 5.300000000000004, -19.900000000000006, 5.299999999999965, -7.0, -28.599999999999973, -13.599999999999914, -14.799999999999772, 1.0999999999999865, 31.700000000000095, -30.39999999999975, 95.0, 20.000000000000014, -7.299999999999891, 25.400000000000098, -1.8999999999998627, 9.499999999999964, 101.0, 40.400000000000034, -12.099999999999888, 11.599999999999964, -3.099999999999958, 38.900000000000034, 37.1, -19.899999999999892, 190.1, 11.599999999999964, 123.49999999999991, -142.0, -19.899999999999743, -157.30000000000044, -208.9, 20.000000000000014, 41.00000000000002, -114.40000000000076, -94.29999999999995, -47.80000000000001, 13.699999999999955, -64.00000000000082, -55.60000000000011, 20.000000000000014, -13.599999999999868, 71.30000000000001, -89.20000000000081, -0.9999999999999846, -5.1999999999999265, -186.70000000000047, 20.000000000000014, -94.60000000000082, 90.19999999999999, -70.30000000000089, -95.50000000000071, 20.000000000000014, -7.299999999999891, 134.0, 15.799999999999962, 145.39999999999998, 37.40000000000006, 126.49999999999966, 80.0, 46.10000000000024, -45.09999999999976, 7.399999999999965, -53.49999999999991, -127.00000000000057, -112.30000000000067, -83.80000000000001, 1.9999999999999856, 13.699999999999966, 101.3, -91.30000000000084, -40.89999999999976, 9.499999999999964, -76.60000000000086, 13.699999999999964, -0.9999999999999846, -190.0, -15.999999999999774, -17.79999999999974, -9.399999999999855, 20.000000000000014, 21.800000000000054, 61.099999999999994, -5.1999999999999265, -105.70000000000002, -32.799999999999976, 15.799999999999963, 15.799999999999963, 20.000000000000014, -32.49999999999975, -68.19999999999986, -93.4000000000004, 82.09999999999977, -11.499999999999819, -49.299999999999905, 138.5, -84.4, -80.80000000000078, -164.80000000000058, -259.2999999999985], "policy_predator_policy_reward": [124.0, 120.0, 86.0, 79.0, 98.0, 68.0, 200.0, 37.0, 89.0, 129.0, 83.0, 67.0, 124.0, 20.0, 148.0, 130.0, 57.0, 25.0, 137.0, 125.0, 33.0, 8.0, 22.0, 27.0, 183.0, 159.0, 21.0, 36.0, 105.0, 161.0, 11.0, 31.0, 93.0, 61.0, 145.0, 151.0, 23.0, 30.0, 96.0, 117.0, 76.0, 8.0, 76.0, 91.0, 147.0, 129.0, 2.0, 10.0, 134.0, 81.0, 36.0, 21.0, 8.0, 41.0, 72.0, 80.0, 10.0, 2.0, 58.0, 33.0, 85.0, 42.0, 52.0, 58.0, 36.0, 34.0, 27.0, 70.0, 17.0, 37.0, 123.0, 109.0, 14.0, 5.0, 59.0, 24.0, 128.0, 136.0, 47.0, 14.0, 42.0, 76.0, 108.0, 118.0, 18.0, 8.0, 12.0, 38.0, 26.0, 15.0, 48.0, 47.0, 113.0, 105.0, 26.0, 53.0, 70.0, 72.0, 9.0, 20.0, 49.0, 32.0, 45.0, 47.0, 70.0, 37.0, 13.0, 21.0, 26.0, 26.0, 14.0, 45.0, 13.0, 0.0, 22.0, 14.0, 28.0, 26.0, 45.0, 31.0, 11.0, 4.0, 57.0, 45.0, 1.0, 49.0, 21.0, 11.0, 71.0, 76.0, 31.0, 134.0, 30.0, 45.0, 75.0, 78.0, 3.0, 82.0, 14.0, 42.0, 24.0, 10.0, 75.0, 50.0, 10.0, 12.0, 14.0, 108.0, 77.0, 65.0, 23.0, 72.0, 13.0, 7.0, 9.0, 18.0, 42.0, 29.0, 39.0, 27.0, 28.0, 30.0, 20.0, 29.0, 15.0, 83.0, 94.0, 41.0, 29.0, 3.0, 29.0, 53.0, 42.0, 10.0, 10.0, 3.0, 87.0, 68.0, 14.0, 18.0, 15.0, 16.0, 12.0, 46.0, 89.0, 50.0, 2.0, 2.0, 21.0, 25.0, 25.0, 64.0, 8.0, 34.0, 32.0, 37.0, 100.0, 47.0, 110.0, 103.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6232005027680744, "mean_inference_ms": 1.9356304166987734, "mean_action_processing_ms": 0.2754941197556105, "mean_env_wait_ms": 0.2105811953250596, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0041800737380981445, "StateBufferConnector_ms": 0.0033974647521972656, "ViewRequirementAgentConnector_ms": 0.10386252403259277}, "num_episodes": 22, "episode_return_max": 272.50000000000006, "episode_return_min": -245.00000000000017, "episode_return_mean": 40.79199999999989, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 864000, "num_agent_steps_trained": 864000, "num_env_steps_sampled": 216000, "num_env_steps_trained": 216000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 373.04912738268524, "num_env_steps_trained_throughput_per_sec": 373.04912738268524, "timesteps_total": 216000, "num_env_steps_sampled_lifetime": 216000, "num_agent_steps_sampled_lifetime": 864000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 864000, "timers": {"training_iteration_time_ms": 10837.254, "restore_workers_time_ms": 0.015, "training_step_time_ms": 10837.184, "sample_time_ms": 1274.334, "learn_time_ms": 9546.062, "learn_throughput": 419.021, "synch_weights_time_ms": 15.548}, "counters": {"num_env_steps_sampled": 216000, "num_env_steps_trained": 216000, "num_agent_steps_sampled": 864000, "num_agent_steps_trained": 864000}, "done": false, "training_iteration": 54, "trial_id": "3dae5_00000", "date": "2024-08-14_09-16-48", "timestamp": 1723641408, "time_this_iter_s": 10.726411819458008, "time_total_s": 2228.7669067382812, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3636f70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2228.7669067382812, "iterations_since_restore": 54, "perf": {"cpu_util_percent": 27.860000000000003, "ram_util_percent": 83.31333333333332}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.434632953827974, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.905427005555895, "policy_loss": -0.00898087121270321, "vf_loss": 6.911832242541843, "vf_explained_var": -0.05116948365534424, "kl": 0.011447373360001453, "entropy": 1.1328240487310621, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 103005.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9300193798289729, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.511423918305251, "policy_loss": -0.006983870354347995, "vf_loss": 4.516894725012401, "vf_explained_var": -0.05054880257636782, "kl": 0.010087086434960393, "entropy": 1.3781815441827925, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 103005.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 220000, "num_env_steps_trained": 220000, "num_agent_steps_sampled": 880000, "num_agent_steps_trained": 880000}, "env_runners": {"episode_reward_max": 272.50000000000006, "episode_reward_min": -211.10000000000093, "episode_reward_mean": 36.68599999999984, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -374.7999999999997, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 190.1, "predator_policy": 187.0}, "policy_reward_mean": {"prey_policy": -25.807000000000045, "predator_policy": 44.15}, "custom_metrics": {}, "hist_stats": {"episode_reward": [28.900000000000126, -88.80000000000035, 0.4000000000002285, 70.40000000000035, 9.299999999999939, 28.90000000000027, 53.30000000000012, -4.299999999999823, 59.700000000000315, 175.9999999999995, 90.50000000000007, -57.20000000000138, 59.300000000000004, 189.79999999999933, 112.4999999999998, -10.699999999999784, -31.29999999999952, 9.500000000000053, 100.99999999999994, 13.499999999999902, 41.70000000000033, -5.099999999999685, 128.39999999999975, 2.399999999999587, 175.69999999999928, 53.00000000000012, 9.900000000000096, 83.19999999999982, 77.40000000000002, 71.39999999999998, 5.600000000000083, 84.79999999999933, 123.59999999999971, 25.70000000000007, 59.5000000000002, 164.49999999999952, 104.29999999999961, 23.50000000000003, 177.99999999999983, 220.19999999999993, 167.09999999999934, -14.9, -201.2000000000004, 135.99999999999963, -55.700000000000024, 50.90000000000005, -63.60000000000181, 40.40000000000034, 107.09999999999984, 15.800000000000004, -44.69999999999968, 137.59999999999957, -70.8000000000016, 32.700000000000195, 176.79999999999947, 253.79999999999973, 272.50000000000006, 59.00000000000048, 2.90000000000018, -141.30000000000123, 53.20000000000003, 146.9999999999997, -50.20000000000077, -15.099999999999543, 25.700000000000067, -50.9999999999999, 4.8000000000001855, 72.7999999999998, 113.89999999999935, 0.49999999999988043, 35.600000000000236, 33.50000000000019, -72.60000000000078, 112.59999999999937, 158.19999999999936, -18.200000000000124, -211.10000000000093, -57.39999999999983, 73.59999999999955, 54.80000000000008, 33.70000000000021, -50.19999999999991, 3.700000000000188, 17.199999999999964, 21.900000000000006, -72.7000000000001, -204.3000000000005, -22.299999999999542, 100.09999999999978, -26.000000000000355, 40.70000000000031, 44.50000000000017, -160.50000000000088, -37.79999999999965, 110.09999999999945, -77.70000000000158, -16.29999999999967, 128.59999999999926, 10.400000000000126, 116.0999999999998], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-3.0999999999999615, 20.000000000000014, -53.80000000000001, -250.00000000000037, -0.9999999999999992, -55.600000000000264, 48.80000000000024, -27.399999999999835, -162.70000000000064, 20.000000000000014, 17.899999999999988, -1.0000000000000346, -15.699999999999747, -22.0, -49.29999999999984, -82.0, -26.199999999999875, -24.099999999999746, 17.899999999999988, 88.1, 18.80000000000001, -25.29999999999989, -57.70000000000048, -53.50000000000019, -192.7, 20.000000000000014, 150.79999999999995, 20.000000000000014, 20.0, 9.499999999999964, -254.8, -19.89999999999999, -24.099999999999746, -68.20000000000087, -88.60000000000059, -19.899999999999885, 59.00000000000017, -184.0, 20.000000000000014, -32.49999999999975, -26.199999999999747, 17.89999999999999, -34.59999999999975, -11.499999999999819, 20.000000000000014, 13.400000000000006, -163.0, -52.60000000000001, 55.70000000000019, 41.0, 59.0, -148.00000000000068, 2.8999999999999613, -21.999999999999744, -3.099999999999958, 5.300000000000004, -19.900000000000006, 5.299999999999965, -7.0, -28.599999999999973, -13.599999999999914, -14.799999999999772, 1.0999999999999865, 31.700000000000095, -30.39999999999975, 95.0, 20.000000000000014, -7.299999999999891, 25.400000000000098, -1.8999999999998627, 9.499999999999964, 101.0, 40.400000000000034, -12.099999999999888, 11.599999999999964, -3.099999999999958, 38.900000000000034, 37.1, -19.899999999999892, 190.1, 11.599999999999964, 123.49999999999991, -142.0, -19.899999999999743, -157.30000000000044, -208.9, 20.000000000000014, 41.00000000000002, -114.40000000000076, -94.29999999999995, -47.80000000000001, 13.699999999999955, -64.00000000000082, -55.60000000000011, 20.000000000000014, -13.599999999999868, 71.30000000000001, -89.20000000000081, -0.9999999999999846, -5.1999999999999265, -186.70000000000047, 20.000000000000014, -94.60000000000082, 90.19999999999999, -70.30000000000089, -95.50000000000071, 20.000000000000014, -7.299999999999891, 134.0, 15.799999999999962, 145.39999999999998, 37.40000000000006, 126.49999999999966, 80.0, 46.10000000000024, -45.09999999999976, 7.399999999999965, -53.49999999999991, -127.00000000000057, -112.30000000000067, -83.80000000000001, 1.9999999999999856, 13.699999999999966, 101.3, -91.30000000000084, -40.89999999999976, 9.499999999999964, -76.60000000000086, 13.699999999999964, -0.9999999999999846, -190.0, -15.999999999999774, -17.79999999999974, -9.399999999999855, 20.000000000000014, 21.800000000000054, 61.099999999999994, -5.1999999999999265, -105.70000000000002, -32.799999999999976, 15.799999999999963, 15.799999999999963, 20.000000000000014, -32.49999999999975, -68.19999999999986, -93.4000000000004, 82.09999999999977, -11.499999999999819, -49.299999999999905, 138.5, -84.4, -80.80000000000078, -164.80000000000058, -259.2999999999985, 3.1999999999999615, -226.6, 107.59999999999985, -127.00000000000045, 15.19999999999996, -150.4, -7.299999999999891, 20.000000000000014, 11.599999999999964, -317.8, -42.99999999999976, 13.699999999999964, -20.49999999999975, 13.699999999999964, -3.099999999999958, -12.9999999999998, 15.799999999999963, -245.5, -150.1000000000002, -173.20000000000033, -55.60000000000022, -15.699999999999797, 104.59999999999991, -101.50000000000054, -21.999999999999872, -136.0, 6.7999999999999705, 17.899999999999988, -35.499999999999936, -0.9999999999999846, -374.7999999999997, -15.699999999999747, -15.699999999999811, -132.10000000000062, 19.1, 20.000000000000014, -150.10000000000068, -34.59999999999975, 20.000000000000014, -91.30000000000061, 65.0, 11.599999999999964, -118.59999999999988, 20.000000000000014, 50.60000000000012, -77.50000000000009], "policy_predator_policy_reward": [2.0, 10.0, 134.0, 81.0, 36.0, 21.0, 8.0, 41.0, 72.0, 80.0, 10.0, 2.0, 58.0, 33.0, 85.0, 42.0, 52.0, 58.0, 36.0, 34.0, 27.0, 70.0, 17.0, 37.0, 123.0, 109.0, 14.0, 5.0, 59.0, 24.0, 128.0, 136.0, 47.0, 14.0, 42.0, 76.0, 108.0, 118.0, 18.0, 8.0, 12.0, 38.0, 26.0, 15.0, 48.0, 47.0, 113.0, 105.0, 26.0, 53.0, 70.0, 72.0, 9.0, 20.0, 49.0, 32.0, 45.0, 47.0, 70.0, 37.0, 13.0, 21.0, 26.0, 26.0, 14.0, 45.0, 13.0, 0.0, 22.0, 14.0, 28.0, 26.0, 45.0, 31.0, 11.0, 4.0, 57.0, 45.0, 1.0, 49.0, 21.0, 11.0, 71.0, 76.0, 31.0, 134.0, 30.0, 45.0, 75.0, 78.0, 3.0, 82.0, 14.0, 42.0, 24.0, 10.0, 75.0, 50.0, 10.0, 12.0, 14.0, 108.0, 77.0, 65.0, 23.0, 72.0, 13.0, 7.0, 9.0, 18.0, 42.0, 29.0, 39.0, 27.0, 28.0, 30.0, 20.0, 29.0, 15.0, 83.0, 94.0, 41.0, 29.0, 3.0, 29.0, 53.0, 42.0, 10.0, 10.0, 3.0, 87.0, 68.0, 14.0, 18.0, 15.0, 16.0, 12.0, 46.0, 89.0, 50.0, 2.0, 2.0, 21.0, 25.0, 25.0, 64.0, 8.0, 34.0, 32.0, 37.0, 100.0, 47.0, 110.0, 103.0, 25.0, 141.0, 70.0, 23.0, 92.0, 98.0, 8.0, 13.0, 147.0, 109.0, 30.0, 3.0, 21.0, 3.0, 18.0, 20.0, 33.0, 124.0, 3.0, 116.0, 43.0, 6.0, 30.0, 67.0, 112.0, 20.0, 5.0, 11.0, 50.0, 31.0, 43.0, 187.0, 56.0, 54.0, 40.0, 31.0, 26.0, 81.0, 2.0, 53.0, 4.0, 48.0, 62.0, 47.0, 88.0, 55.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6216408635656931, "mean_inference_ms": 1.9301092213558604, "mean_action_processing_ms": 0.2743602404244102, "mean_env_wait_ms": 0.2099967231437761, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00377500057220459, "StateBufferConnector_ms": 0.003371596336364746, "ViewRequirementAgentConnector_ms": 0.09677159786224365}, "num_episodes": 23, "episode_return_max": 272.50000000000006, "episode_return_min": -211.10000000000093, "episode_return_mean": 36.68599999999984, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 880000, "num_agent_steps_trained": 880000, "num_env_steps_sampled": 220000, "num_env_steps_trained": 220000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 377.1456839247841, "num_env_steps_trained_throughput_per_sec": 377.1456839247841, "timesteps_total": 220000, "num_env_steps_sampled_lifetime": 220000, "num_agent_steps_sampled_lifetime": 880000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 880000, "timers": {"training_iteration_time_ms": 10835.512, "restore_workers_time_ms": 0.015, "training_step_time_ms": 10835.442, "sample_time_ms": 1266.855, "learn_time_ms": 9551.302, "learn_throughput": 418.791, "synch_weights_time_ms": 16.002}, "counters": {"num_env_steps_sampled": 220000, "num_env_steps_trained": 220000, "num_agent_steps_sampled": 880000, "num_agent_steps_trained": 880000}, "done": false, "training_iteration": 55, "trial_id": "3dae5_00000", "date": "2024-08-14_09-16-59", "timestamp": 1723641419, "time_this_iter_s": 10.653637886047363, "time_total_s": 2239.4205446243286, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3618d30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2239.4205446243286, "iterations_since_restore": 55, "perf": {"cpu_util_percent": 27.41333333333333, "ram_util_percent": 83.53999999999998}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.736814133326212, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.244858069646926, "policy_loss": -0.010070545884297677, "vf_loss": 7.2519324065516235, "vf_explained_var": -0.22988033149608228, "kl": 0.013316483761902044, "entropy": 1.1189500291511496, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 104895.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.84409820380665, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.657436150974697, "policy_loss": -0.002398986264043266, "vf_loss": 4.658941221615625, "vf_explained_var": -0.011739844966817785, "kl": 0.0059593693616784285, "entropy": 1.4012433033771616, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 104895.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 224000, "num_env_steps_trained": 224000, "num_agent_steps_sampled": 896000, "num_agent_steps_trained": 896000}, "env_runners": {"episode_reward_max": 272.50000000000006, "episode_reward_min": -301.29999999999995, "episode_reward_mean": 33.03299999999982, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -374.7999999999997, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 192.79999999999998, "predator_policy": 187.0}, "policy_reward_mean": {"prey_policy": -25.928500000000053, "predator_policy": 42.445}, "custom_metrics": {}, "hist_stats": {"episode_reward": [100.99999999999994, 13.499999999999902, 41.70000000000033, -5.099999999999685, 128.39999999999975, 2.399999999999587, 175.69999999999928, 53.00000000000012, 9.900000000000096, 83.19999999999982, 77.40000000000002, 71.39999999999998, 5.600000000000083, 84.79999999999933, 123.59999999999971, 25.70000000000007, 59.5000000000002, 164.49999999999952, 104.29999999999961, 23.50000000000003, 177.99999999999983, 220.19999999999993, 167.09999999999934, -14.9, -201.2000000000004, 135.99999999999963, -55.700000000000024, 50.90000000000005, -63.60000000000181, 40.40000000000034, 107.09999999999984, 15.800000000000004, -44.69999999999968, 137.59999999999957, -70.8000000000016, 32.700000000000195, 176.79999999999947, 253.79999999999973, 272.50000000000006, 59.00000000000048, 2.90000000000018, -141.30000000000123, 53.20000000000003, 146.9999999999997, -50.20000000000077, -15.099999999999543, 25.700000000000067, -50.9999999999999, 4.8000000000001855, 72.7999999999998, 113.89999999999935, 0.49999999999988043, 35.600000000000236, 33.50000000000019, -72.60000000000078, 112.59999999999937, 158.19999999999936, -18.200000000000124, -211.10000000000093, -57.39999999999983, 73.59999999999955, 54.80000000000008, 33.70000000000021, -50.19999999999991, 3.700000000000188, 17.199999999999964, 21.900000000000006, -72.7000000000001, -204.3000000000005, -22.299999999999542, 100.09999999999978, -26.000000000000355, 40.70000000000031, 44.50000000000017, -160.50000000000088, -37.79999999999965, 110.09999999999945, -77.70000000000158, -16.29999999999967, 128.59999999999926, 10.400000000000126, 116.0999999999998, -90.30000000000163, 39.800000000000296, 31.90000000000023, 13.199999999999957, -19.39999999999951, -39.49999999999991, -34.90000000000022, 126.69999999999962, -161.3000000000003, 38.10000000000027, -301.29999999999995, 12.500000000000059, 180.09999999999923, 43.40000000000036, 188.9999999999997, -8.100000000000232, 154.59999999999954, 156.39999999999955], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [59.00000000000017, -184.0, 20.000000000000014, -32.49999999999975, -26.199999999999747, 17.89999999999999, -34.59999999999975, -11.499999999999819, 20.000000000000014, 13.400000000000006, -163.0, -52.60000000000001, 55.70000000000019, 41.0, 59.0, -148.00000000000068, 2.8999999999999613, -21.999999999999744, -3.099999999999958, 5.300000000000004, -19.900000000000006, 5.299999999999965, -7.0, -28.599999999999973, -13.599999999999914, -14.799999999999772, 1.0999999999999865, 31.700000000000095, -30.39999999999975, 95.0, 20.000000000000014, -7.299999999999891, 25.400000000000098, -1.8999999999998627, 9.499999999999964, 101.0, 40.400000000000034, -12.099999999999888, 11.599999999999964, -3.099999999999958, 38.900000000000034, 37.1, -19.899999999999892, 190.1, 11.599999999999964, 123.49999999999991, -142.0, -19.899999999999743, -157.30000000000044, -208.9, 20.000000000000014, 41.00000000000002, -114.40000000000076, -94.29999999999995, -47.80000000000001, 13.699999999999955, -64.00000000000082, -55.60000000000011, 20.000000000000014, -13.599999999999868, 71.30000000000001, -89.20000000000081, -0.9999999999999846, -5.1999999999999265, -186.70000000000047, 20.000000000000014, -94.60000000000082, 90.19999999999999, -70.30000000000089, -95.50000000000071, 20.000000000000014, -7.299999999999891, 134.0, 15.799999999999962, 145.39999999999998, 37.40000000000006, 126.49999999999966, 80.0, 46.10000000000024, -45.09999999999976, 7.399999999999965, -53.49999999999991, -127.00000000000057, -112.30000000000067, -83.80000000000001, 1.9999999999999856, 13.699999999999966, 101.3, -91.30000000000084, -40.89999999999976, 9.499999999999964, -76.60000000000086, 13.699999999999964, -0.9999999999999846, -190.0, -15.999999999999774, -17.79999999999974, -9.399999999999855, 20.000000000000014, 21.800000000000054, 61.099999999999994, -5.1999999999999265, -105.70000000000002, -32.799999999999976, 15.799999999999963, 15.799999999999963, 20.000000000000014, -32.49999999999975, -68.19999999999986, -93.4000000000004, 82.09999999999977, -11.499999999999819, -49.299999999999905, 138.5, -84.4, -80.80000000000078, -164.80000000000058, -259.2999999999985, 3.1999999999999615, -226.6, 107.59999999999985, -127.00000000000045, 15.19999999999996, -150.4, -7.299999999999891, 20.000000000000014, 11.599999999999964, -317.8, -42.99999999999976, 13.699999999999964, -20.49999999999975, 13.699999999999964, -3.099999999999958, -12.9999999999998, 15.799999999999963, -245.5, -150.1000000000002, -173.20000000000033, -55.60000000000022, -15.699999999999797, 104.59999999999991, -101.50000000000054, -21.999999999999872, -136.0, 6.7999999999999705, 17.899999999999988, -35.499999999999936, -0.9999999999999846, -374.7999999999997, -15.699999999999747, -15.699999999999811, -132.10000000000062, 19.1, 20.000000000000014, -150.10000000000068, -34.59999999999975, 20.000000000000014, -91.30000000000061, 65.0, 11.599999999999964, -118.59999999999988, 20.000000000000014, 50.60000000000012, -77.50000000000009, -87.10000000000085, -110.20000000000078, 15.799999999999963, 20.000000000000014, 13.699999999999958, 3.1999999999999615, -38.799999999999756, 20.000000000000014, -30.39999999999975, -42.99999999999976, -82.30000000000082, -47.19999999999976, 9.499999999999964, -210.4, 5.299999999999965, 91.3999999999999, -246.70000000000041, -196.60000000000002, 1.0999999999999865, 20.000000000000014, -346.29999999999995, -268.00000000000006, -5.1999999999999265, -7.299999999999891, 166.69999999999987, 7.399999999999965, 20.000000000000014, 22.400000000000055, 65.59999999999998, 46.40000000000002, -85.89999999999998, -53.19999999999988, 160.39999999999992, -80.80000000000086, -93.40000000000069, 192.79999999999998], "policy_predator_policy_reward": [108.0, 118.0, 18.0, 8.0, 12.0, 38.0, 26.0, 15.0, 48.0, 47.0, 113.0, 105.0, 26.0, 53.0, 70.0, 72.0, 9.0, 20.0, 49.0, 32.0, 45.0, 47.0, 70.0, 37.0, 13.0, 21.0, 26.0, 26.0, 14.0, 45.0, 13.0, 0.0, 22.0, 14.0, 28.0, 26.0, 45.0, 31.0, 11.0, 4.0, 57.0, 45.0, 1.0, 49.0, 21.0, 11.0, 71.0, 76.0, 31.0, 134.0, 30.0, 45.0, 75.0, 78.0, 3.0, 82.0, 14.0, 42.0, 24.0, 10.0, 75.0, 50.0, 10.0, 12.0, 14.0, 108.0, 77.0, 65.0, 23.0, 72.0, 13.0, 7.0, 9.0, 18.0, 42.0, 29.0, 39.0, 27.0, 28.0, 30.0, 20.0, 29.0, 15.0, 83.0, 94.0, 41.0, 29.0, 3.0, 29.0, 53.0, 42.0, 10.0, 10.0, 3.0, 87.0, 68.0, 14.0, 18.0, 15.0, 16.0, 12.0, 46.0, 89.0, 50.0, 2.0, 2.0, 21.0, 25.0, 25.0, 64.0, 8.0, 34.0, 32.0, 37.0, 100.0, 47.0, 110.0, 103.0, 25.0, 141.0, 70.0, 23.0, 92.0, 98.0, 8.0, 13.0, 147.0, 109.0, 30.0, 3.0, 21.0, 3.0, 18.0, 20.0, 33.0, 124.0, 3.0, 116.0, 43.0, 6.0, 30.0, 67.0, 112.0, 20.0, 5.0, 11.0, 50.0, 31.0, 43.0, 187.0, 56.0, 54.0, 40.0, 31.0, 26.0, 81.0, 2.0, 53.0, 4.0, 48.0, 62.0, 47.0, 88.0, 55.0, 64.0, 43.0, 2.0, 2.0, 8.0, 7.0, 24.0, 8.0, 30.0, 24.0, 43.0, 47.0, 128.0, 38.0, 14.0, 16.0, 105.0, 177.0, 8.0, 9.0, 166.0, 147.0, 13.0, 12.0, 0.0, 6.0, 0.0, 1.0, 33.0, 44.0, 88.0, 43.0, 48.0, 27.0, 23.0, 34.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6204613987300618, "mean_inference_ms": 1.9264063612696054, "mean_action_processing_ms": 0.27356075856001877, "mean_env_wait_ms": 0.2095650461136071, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0038880109786987305, "StateBufferConnector_ms": 0.0041506290435791016, "ViewRequirementAgentConnector_ms": 0.10364842414855957}, "num_episodes": 18, "episode_return_max": 272.50000000000006, "episode_return_min": -301.29999999999995, "episode_return_mean": 33.03299999999982, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 896000, "num_agent_steps_trained": 896000, "num_env_steps_sampled": 224000, "num_env_steps_trained": 224000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 364.09155162441186, "num_env_steps_trained_throughput_per_sec": 364.09155162441186, "timesteps_total": 224000, "num_env_steps_sampled_lifetime": 224000, "num_agent_steps_sampled_lifetime": 896000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 896000, "timers": {"training_iteration_time_ms": 10851.981, "restore_workers_time_ms": 0.015, "training_step_time_ms": 10851.911, "sample_time_ms": 1269.141, "learn_time_ms": 9568.274, "learn_throughput": 418.048, "synch_weights_time_ms": 13.265}, "counters": {"num_env_steps_sampled": 224000, "num_env_steps_trained": 224000, "num_agent_steps_sampled": 896000, "num_agent_steps_trained": 896000}, "done": false, "training_iteration": 56, "trial_id": "3dae5_00000", "date": "2024-08-14_09-17-10", "timestamp": 1723641430, "time_this_iter_s": 10.991198301315308, "time_total_s": 2250.411742925644, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3618040>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2250.411742925644, "iterations_since_restore": 56, "perf": {"cpu_util_percent": 28.61333333333333, "ram_util_percent": 83.5}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.706336182513565, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.315028260246156, "policy_loss": -0.006318870477289671, "vf_loss": 7.31823182156477, "vf_explained_var": -0.0426904561027648, "kl": 0.013845876551028225, "entropy": 1.14959504440348, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 106785.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.3838930630810045, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.722296479391673, "policy_loss": -0.005129320579260667, "vf_loss": 5.726092208882489, "vf_explained_var": 0.009643431914546502, "kl": 0.00889067015749328, "entropy": 1.389048907870338, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 106785.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 228000, "num_env_steps_trained": 228000, "num_agent_steps_sampled": 912000, "num_agent_steps_trained": 912000}, "env_runners": {"episode_reward_max": 272.50000000000006, "episode_reward_min": -301.29999999999995, "episode_reward_mean": 23.3929999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -374.7999999999997, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 192.79999999999998, "predator_policy": 187.0}, "policy_reward_mean": {"prey_policy": -32.328500000000076, "predator_policy": 44.025}, "custom_metrics": {}, "hist_stats": {"episode_reward": [104.29999999999961, 23.50000000000003, 177.99999999999983, 220.19999999999993, 167.09999999999934, -14.9, -201.2000000000004, 135.99999999999963, -55.700000000000024, 50.90000000000005, -63.60000000000181, 40.40000000000034, 107.09999999999984, 15.800000000000004, -44.69999999999968, 137.59999999999957, -70.8000000000016, 32.700000000000195, 176.79999999999947, 253.79999999999973, 272.50000000000006, 59.00000000000048, 2.90000000000018, -141.30000000000123, 53.20000000000003, 146.9999999999997, -50.20000000000077, -15.099999999999543, 25.700000000000067, -50.9999999999999, 4.8000000000001855, 72.7999999999998, 113.89999999999935, 0.49999999999988043, 35.600000000000236, 33.50000000000019, -72.60000000000078, 112.59999999999937, 158.19999999999936, -18.200000000000124, -211.10000000000093, -57.39999999999983, 73.59999999999955, 54.80000000000008, 33.70000000000021, -50.19999999999991, 3.700000000000188, 17.199999999999964, 21.900000000000006, -72.7000000000001, -204.3000000000005, -22.299999999999542, 100.09999999999978, -26.000000000000355, 40.70000000000031, 44.50000000000017, -160.50000000000088, -37.79999999999965, 110.09999999999945, -77.70000000000158, -16.29999999999967, 128.59999999999926, 10.400000000000126, 116.0999999999998, -90.30000000000163, 39.800000000000296, 31.90000000000023, 13.199999999999957, -19.39999999999951, -39.49999999999991, -34.90000000000022, 126.69999999999962, -161.3000000000003, 38.10000000000027, -301.29999999999995, 12.500000000000059, 180.09999999999923, 43.40000000000036, 188.9999999999997, -8.100000000000232, 154.59999999999954, 156.39999999999955, 47.09999999999992, 13.200000000000067, 87.50000000000006, -193.30000000000027, 104.39999999999878, -249.60000000000076, 86.79999999999997, -115.30000000000032, 182.79999999999947, -75.29999999999984, 60.30000000000006, -90.70000000000013, -5.099999999999699, 142.89999999999964, 20.19999999999998, 121.59999999999974, 16.900000000000002, 97.79999999999981], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [40.400000000000034, -12.099999999999888, 11.599999999999964, -3.099999999999958, 38.900000000000034, 37.1, -19.899999999999892, 190.1, 11.599999999999964, 123.49999999999991, -142.0, -19.899999999999743, -157.30000000000044, -208.9, 20.000000000000014, 41.00000000000002, -114.40000000000076, -94.29999999999995, -47.80000000000001, 13.699999999999955, -64.00000000000082, -55.60000000000011, 20.000000000000014, -13.599999999999868, 71.30000000000001, -89.20000000000081, -0.9999999999999846, -5.1999999999999265, -186.70000000000047, 20.000000000000014, -94.60000000000082, 90.19999999999999, -70.30000000000089, -95.50000000000071, 20.000000000000014, -7.299999999999891, 134.0, 15.799999999999962, 145.39999999999998, 37.40000000000006, 126.49999999999966, 80.0, 46.10000000000024, -45.09999999999976, 7.399999999999965, -53.49999999999991, -127.00000000000057, -112.30000000000067, -83.80000000000001, 1.9999999999999856, 13.699999999999966, 101.3, -91.30000000000084, -40.89999999999976, 9.499999999999964, -76.60000000000086, 13.699999999999964, -0.9999999999999846, -190.0, -15.999999999999774, -17.79999999999974, -9.399999999999855, 20.000000000000014, 21.800000000000054, 61.099999999999994, -5.1999999999999265, -105.70000000000002, -32.799999999999976, 15.799999999999963, 15.799999999999963, 20.000000000000014, -32.49999999999975, -68.19999999999986, -93.4000000000004, 82.09999999999977, -11.499999999999819, -49.299999999999905, 138.5, -84.4, -80.80000000000078, -164.80000000000058, -259.2999999999985, 3.1999999999999615, -226.6, 107.59999999999985, -127.00000000000045, 15.19999999999996, -150.4, -7.299999999999891, 20.000000000000014, 11.599999999999964, -317.8, -42.99999999999976, 13.699999999999964, -20.49999999999975, 13.699999999999964, -3.099999999999958, -12.9999999999998, 15.799999999999963, -245.5, -150.1000000000002, -173.20000000000033, -55.60000000000022, -15.699999999999797, 104.59999999999991, -101.50000000000054, -21.999999999999872, -136.0, 6.7999999999999705, 17.899999999999988, -35.499999999999936, -0.9999999999999846, -374.7999999999997, -15.699999999999747, -15.699999999999811, -132.10000000000062, 19.1, 20.000000000000014, -150.10000000000068, -34.59999999999975, 20.000000000000014, -91.30000000000061, 65.0, 11.599999999999964, -118.59999999999988, 20.000000000000014, 50.60000000000012, -77.50000000000009, -87.10000000000085, -110.20000000000078, 15.799999999999963, 20.000000000000014, 13.699999999999958, 3.1999999999999615, -38.799999999999756, 20.000000000000014, -30.39999999999975, -42.99999999999976, -82.30000000000082, -47.19999999999976, 9.499999999999964, -210.4, 5.299999999999965, 91.3999999999999, -246.70000000000041, -196.60000000000002, 1.0999999999999865, 20.000000000000014, -346.29999999999995, -268.00000000000006, -5.1999999999999265, -7.299999999999891, 166.69999999999987, 7.399999999999965, 20.000000000000014, 22.400000000000055, 65.59999999999998, 46.40000000000002, -85.89999999999998, -53.19999999999988, 160.39999999999992, -80.80000000000086, -93.40000000000069, 192.79999999999998, -58.900000000000496, -7.000000000000043, -311.8, 20.000000000000014, 16.1, -7.600000000000065, -208.90000000000052, -93.40000000000018, 15.799999999999946, 62.60000000000015, -279.09999999999934, -200.50000000000048, 15.799999999999946, -7.000000000000066, -7.299999999999919, -271.0, 15.799999999999963, 152.0, 20.000000000000014, -225.3000000000003, -208.9000000000005, 150.2, -169.30000000000004, -60.40000000000009, -57.70000000000048, 11.599999999999964, 105.19999999999997, 13.699999999999964, -15.699999999999761, 17.899999999999988, 127.39999999999998, -80.80000000000086, -3.099999999999958, -0.9999999999999846, -7.299999999999894, 40.099999999999994], "policy_predator_policy_reward": [45.0, 31.0, 11.0, 4.0, 57.0, 45.0, 1.0, 49.0, 21.0, 11.0, 71.0, 76.0, 31.0, 134.0, 30.0, 45.0, 75.0, 78.0, 3.0, 82.0, 14.0, 42.0, 24.0, 10.0, 75.0, 50.0, 10.0, 12.0, 14.0, 108.0, 77.0, 65.0, 23.0, 72.0, 13.0, 7.0, 9.0, 18.0, 42.0, 29.0, 39.0, 27.0, 28.0, 30.0, 20.0, 29.0, 15.0, 83.0, 94.0, 41.0, 29.0, 3.0, 29.0, 53.0, 42.0, 10.0, 10.0, 3.0, 87.0, 68.0, 14.0, 18.0, 15.0, 16.0, 12.0, 46.0, 89.0, 50.0, 2.0, 2.0, 21.0, 25.0, 25.0, 64.0, 8.0, 34.0, 32.0, 37.0, 100.0, 47.0, 110.0, 103.0, 25.0, 141.0, 70.0, 23.0, 92.0, 98.0, 8.0, 13.0, 147.0, 109.0, 30.0, 3.0, 21.0, 3.0, 18.0, 20.0, 33.0, 124.0, 3.0, 116.0, 43.0, 6.0, 30.0, 67.0, 112.0, 20.0, 5.0, 11.0, 50.0, 31.0, 43.0, 187.0, 56.0, 54.0, 40.0, 31.0, 26.0, 81.0, 2.0, 53.0, 4.0, 48.0, 62.0, 47.0, 88.0, 55.0, 64.0, 43.0, 2.0, 2.0, 8.0, 7.0, 24.0, 8.0, 30.0, 24.0, 43.0, 47.0, 128.0, 38.0, 14.0, 16.0, 105.0, 177.0, 8.0, 9.0, 166.0, 147.0, 13.0, 12.0, 0.0, 6.0, 0.0, 1.0, 33.0, 44.0, 88.0, 43.0, 48.0, 27.0, 23.0, 34.0, 70.0, 43.0, 141.0, 164.0, 66.0, 13.0, 41.0, 68.0, 14.0, 12.0, 149.0, 81.0, 14.0, 64.0, 141.0, 22.0, 13.0, 2.0, 8.0, 122.0, 10.0, 109.0, 21.0, 118.0, 4.0, 37.0, 19.0, 5.0, 17.0, 1.0, 48.0, 27.0, 11.0, 10.0, 50.0, 15.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6192087681108979, "mean_inference_ms": 1.922706344987663, "mean_action_processing_ms": 0.2727464764779493, "mean_env_wait_ms": 0.20910751059938168, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003845810890197754, "StateBufferConnector_ms": 0.004052519798278809, "ViewRequirementAgentConnector_ms": 0.10230147838592529}, "num_episodes": 18, "episode_return_max": 272.50000000000006, "episode_return_min": -301.29999999999995, "episode_return_mean": 23.3929999999998, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 912000, "num_agent_steps_trained": 912000, "num_env_steps_sampled": 228000, "num_env_steps_trained": 228000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 378.2264229405203, "num_env_steps_trained_throughput_per_sec": 378.2264229405203, "timesteps_total": 228000, "num_env_steps_sampled_lifetime": 228000, "num_agent_steps_sampled_lifetime": 912000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 912000, "timers": {"training_iteration_time_ms": 10763.185, "restore_workers_time_ms": 0.015, "training_step_time_ms": 10763.131, "sample_time_ms": 1269.659, "learn_time_ms": 9479.649, "learn_throughput": 421.957, "synch_weights_time_ms": 12.862}, "counters": {"num_env_steps_sampled": 228000, "num_env_steps_trained": 228000, "num_agent_steps_sampled": 912000, "num_agent_steps_trained": 912000}, "done": false, "training_iteration": 57, "trial_id": "3dae5_00000", "date": "2024-08-14_09-17-21", "timestamp": 1723641441, "time_this_iter_s": 10.585076332092285, "time_total_s": 2260.996819257736, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0fef040>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2260.996819257736, "iterations_since_restore": 57, "perf": {"cpu_util_percent": 27.646666666666665, "ram_util_percent": 83.50666666666666}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.213273354623683, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.071855083344475, "policy_loss": -0.006002211270523725, "vf_loss": 7.075852536398267, "vf_explained_var": 0.04597546146029518, "kl": 0.008910007471565454, "entropy": 1.1153187717079485, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 108675.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.0675963149184273, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.3630421956380205, "policy_loss": -0.006746689814620863, "vf_loss": 6.368451381612707, "vf_explained_var": -0.15288022999410275, "kl": 0.008916638672644453, "entropy": 1.391552456409212, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 108675.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 232000, "num_env_steps_trained": 232000, "num_agent_steps_sampled": 928000, "num_agent_steps_trained": 928000}, "env_runners": {"episode_reward_max": 188.9999999999997, "episode_reward_min": -366.9, "episode_reward_mean": -3.862000000000172, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -392.79999999999995, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 199.1, "predator_policy": 187.0}, "policy_reward_mean": {"prey_policy": -56.846000000000075, "predator_policy": 54.915}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.90000000000018, -141.30000000000123, 53.20000000000003, 146.9999999999997, -50.20000000000077, -15.099999999999543, 25.700000000000067, -50.9999999999999, 4.8000000000001855, 72.7999999999998, 113.89999999999935, 0.49999999999988043, 35.600000000000236, 33.50000000000019, -72.60000000000078, 112.59999999999937, 158.19999999999936, -18.200000000000124, -211.10000000000093, -57.39999999999983, 73.59999999999955, 54.80000000000008, 33.70000000000021, -50.19999999999991, 3.700000000000188, 17.199999999999964, 21.900000000000006, -72.7000000000001, -204.3000000000005, -22.299999999999542, 100.09999999999978, -26.000000000000355, 40.70000000000031, 44.50000000000017, -160.50000000000088, -37.79999999999965, 110.09999999999945, -77.70000000000158, -16.29999999999967, 128.59999999999926, 10.400000000000126, 116.0999999999998, -90.30000000000163, 39.800000000000296, 31.90000000000023, 13.199999999999957, -19.39999999999951, -39.49999999999991, -34.90000000000022, 126.69999999999962, -161.3000000000003, 38.10000000000027, -301.29999999999995, 12.500000000000059, 180.09999999999923, 43.40000000000036, 188.9999999999997, -8.100000000000232, 154.59999999999954, 156.39999999999955, 47.09999999999992, 13.200000000000067, 87.50000000000006, -193.30000000000027, 104.39999999999878, -249.60000000000076, 86.79999999999997, -115.30000000000032, 182.79999999999947, -75.29999999999984, 60.30000000000006, -90.70000000000013, -5.099999999999699, 142.89999999999964, 20.19999999999998, 121.59999999999974, 16.900000000000002, 97.79999999999981, -182.00000000000117, 50.600000000000094, -201.1000000000003, 26.20000000000011, -115.20000000000061, -61.79999999999997, 28.10000000000003, -26.099999999999625, -270.0000000000001, 105.29999999999974, -87.30000000000013, 53.00000000000007, -21.599999999999696, -366.9, -81.20000000000016, 172.19999999999945, -122.20000000000101, 4.8000000000001855, -83.30000000000001, -26.99999999999993, 33.1000000000001, -28.299999999999734], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [7.399999999999965, -53.49999999999991, -127.00000000000057, -112.30000000000067, -83.80000000000001, 1.9999999999999856, 13.699999999999966, 101.3, -91.30000000000084, -40.89999999999976, 9.499999999999964, -76.60000000000086, 13.699999999999964, -0.9999999999999846, -190.0, -15.999999999999774, -17.79999999999974, -9.399999999999855, 20.000000000000014, 21.800000000000054, 61.099999999999994, -5.1999999999999265, -105.70000000000002, -32.799999999999976, 15.799999999999963, 15.799999999999963, 20.000000000000014, -32.49999999999975, -68.19999999999986, -93.4000000000004, 82.09999999999977, -11.499999999999819, -49.299999999999905, 138.5, -84.4, -80.80000000000078, -164.80000000000058, -259.2999999999985, 3.1999999999999615, -226.6, 107.59999999999985, -127.00000000000045, 15.19999999999996, -150.4, -7.299999999999891, 20.000000000000014, 11.599999999999964, -317.8, -42.99999999999976, 13.699999999999964, -20.49999999999975, 13.699999999999964, -3.099999999999958, -12.9999999999998, 15.799999999999963, -245.5, -150.1000000000002, -173.20000000000033, -55.60000000000022, -15.699999999999797, 104.59999999999991, -101.50000000000054, -21.999999999999872, -136.0, 6.7999999999999705, 17.899999999999988, -35.499999999999936, -0.9999999999999846, -374.7999999999997, -15.699999999999747, -15.699999999999811, -132.10000000000062, 19.1, 20.000000000000014, -150.10000000000068, -34.59999999999975, 20.000000000000014, -91.30000000000061, 65.0, 11.599999999999964, -118.59999999999988, 20.000000000000014, 50.60000000000012, -77.50000000000009, -87.10000000000085, -110.20000000000078, 15.799999999999963, 20.000000000000014, 13.699999999999958, 3.1999999999999615, -38.799999999999756, 20.000000000000014, -30.39999999999975, -42.99999999999976, -82.30000000000082, -47.19999999999976, 9.499999999999964, -210.4, 5.299999999999965, 91.3999999999999, -246.70000000000041, -196.60000000000002, 1.0999999999999865, 20.000000000000014, -346.29999999999995, -268.00000000000006, -5.1999999999999265, -7.299999999999891, 166.69999999999987, 7.399999999999965, 20.000000000000014, 22.400000000000055, 65.59999999999998, 46.40000000000002, -85.89999999999998, -53.19999999999988, 160.39999999999992, -80.80000000000086, -93.40000000000069, 192.79999999999998, -58.900000000000496, -7.000000000000043, -311.8, 20.000000000000014, 16.1, -7.600000000000065, -208.90000000000052, -93.40000000000018, 15.799999999999946, 62.60000000000015, -279.09999999999934, -200.50000000000048, 15.799999999999946, -7.000000000000066, -7.299999999999919, -271.0, 15.799999999999963, 152.0, 20.000000000000014, -225.3000000000003, -208.9000000000005, 150.2, -169.30000000000004, -60.40000000000009, -57.70000000000048, 11.599999999999964, 105.19999999999997, 13.699999999999964, -15.699999999999761, 17.899999999999988, 127.39999999999998, -80.80000000000086, -3.099999999999958, -0.9999999999999846, -7.299999999999894, 40.099999999999994, -183.70000000000059, -175.30000000000058, -15.699999999999875, -6.700000000000152, -253.00000000000014, -207.10000000000016, 20.000000000000014, -38.799999999999756, -277.8000000000002, 11.59999999999997, -359.8, 20.000000000000014, -90.10000000000045, -8.800000000000011, -70.30000000000084, -35.79999999999986, -234.10000000000045, -292.8999999999994, 78.50000000000001, -26.199999999999747, 5.299999999999967, -349.6, 20.000000000000014, -175.0, -66.40000000000046, -139.20000000000073, -256.6, -292.30000000000007, 20.000000000000014, -215.20000000000041, 199.1, -145.9000000000006, -68.2000000000009, -354.9999999999998, -21.999999999999744, -5.1999999999999265, 20.000000000000014, -267.3000000000004, 15.799999999999963, -392.79999999999995, 15.799999999999963, -126.70000000000013, -382.0, -7.299999999999891], "policy_predator_policy_reward": [20.0, 29.0, 15.0, 83.0, 94.0, 41.0, 29.0, 3.0, 29.0, 53.0, 42.0, 10.0, 10.0, 3.0, 87.0, 68.0, 14.0, 18.0, 15.0, 16.0, 12.0, 46.0, 89.0, 50.0, 2.0, 2.0, 21.0, 25.0, 25.0, 64.0, 8.0, 34.0, 32.0, 37.0, 100.0, 47.0, 110.0, 103.0, 25.0, 141.0, 70.0, 23.0, 92.0, 98.0, 8.0, 13.0, 147.0, 109.0, 30.0, 3.0, 21.0, 3.0, 18.0, 20.0, 33.0, 124.0, 3.0, 116.0, 43.0, 6.0, 30.0, 67.0, 112.0, 20.0, 5.0, 11.0, 50.0, 31.0, 43.0, 187.0, 56.0, 54.0, 40.0, 31.0, 26.0, 81.0, 2.0, 53.0, 4.0, 48.0, 62.0, 47.0, 88.0, 55.0, 64.0, 43.0, 2.0, 2.0, 8.0, 7.0, 24.0, 8.0, 30.0, 24.0, 43.0, 47.0, 128.0, 38.0, 14.0, 16.0, 105.0, 177.0, 8.0, 9.0, 166.0, 147.0, 13.0, 12.0, 0.0, 6.0, 0.0, 1.0, 33.0, 44.0, 88.0, 43.0, 48.0, 27.0, 23.0, 34.0, 70.0, 43.0, 141.0, 164.0, 66.0, 13.0, 41.0, 68.0, 14.0, 12.0, 149.0, 81.0, 14.0, 64.0, 141.0, 22.0, 13.0, 2.0, 8.0, 122.0, 10.0, 109.0, 21.0, 118.0, 4.0, 37.0, 19.0, 5.0, 17.0, 1.0, 48.0, 27.0, 11.0, 10.0, 50.0, 15.0, 100.0, 77.0, 24.0, 49.0, 133.0, 126.0, 25.0, 20.0, 4.0, 147.0, 94.0, 184.0, 67.0, 60.0, 27.0, 53.0, 98.0, 159.0, 4.0, 49.0, 179.0, 78.0, 89.0, 119.0, 109.0, 75.0, 127.0, 55.0, 2.0, 112.0, 50.0, 69.0, 164.0, 137.0, 12.0, 20.0, 43.0, 121.0, 179.0, 171.0, 102.0, 42.0, 175.0, 186.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6174996829617441, "mean_inference_ms": 1.9182227026359226, "mean_action_processing_ms": 0.2709441484901018, "mean_env_wait_ms": 0.2086337171826155, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003825068473815918, "StateBufferConnector_ms": 0.0038107633590698242, "ViewRequirementAgentConnector_ms": 0.09789645671844482}, "num_episodes": 22, "episode_return_max": 188.9999999999997, "episode_return_min": -366.9, "episode_return_mean": -3.862000000000172, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 928000, "num_agent_steps_trained": 928000, "num_env_steps_sampled": 232000, "num_env_steps_trained": 232000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 360.41572237867535, "num_env_steps_trained_throughput_per_sec": 360.41572237867535, "timesteps_total": 232000, "num_env_steps_sampled_lifetime": 232000, "num_agent_steps_sampled_lifetime": 928000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 928000, "timers": {"training_iteration_time_ms": 10800.497, "restore_workers_time_ms": 0.015, "training_step_time_ms": 10800.442, "sample_time_ms": 1268.861, "learn_time_ms": 9517.436, "learn_throughput": 420.281, "synch_weights_time_ms": 13.047}, "counters": {"num_env_steps_sampled": 232000, "num_env_steps_trained": 232000, "num_agent_steps_sampled": 928000, "num_agent_steps_trained": 928000}, "done": false, "training_iteration": 58, "trial_id": "3dae5_00000", "date": "2024-08-14_09-17-32", "timestamp": 1723641452, "time_this_iter_s": 11.149155855178833, "time_total_s": 2272.145975112915, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3618d30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2272.145975112915, "iterations_since_restore": 58, "perf": {"cpu_util_percent": 30.14375, "ram_util_percent": 83.4625}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.5983903736664504, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.2889373138468105, "policy_loss": -0.005949757443790241, "vf_loss": 7.293177528229971, "vf_explained_var": 0.09878762991970809, "kl": 0.007597908105614166, "entropy": 1.0757399361284952, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 110565.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.3276596150701008, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.379258932133831, "policy_loss": -0.0054013883308187205, "vf_loss": 7.38341534907225, "vf_explained_var": -0.12562280101750894, "kl": 0.008299776306317364, "entropy": 1.3814090653702065, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 110565.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 236000, "num_env_steps_trained": 236000, "num_agent_steps_sampled": 944000, "num_agent_steps_trained": 944000}, "env_runners": {"episode_reward_max": 188.9999999999997, "episode_reward_min": -390.5000000000001, "episode_reward_mean": -28.725000000000147, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 199.1, "predator_policy": 199.0}, "policy_reward_mean": {"prey_policy": -81.72250000000008, "predator_policy": 67.36}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-211.10000000000093, -57.39999999999983, 73.59999999999955, 54.80000000000008, 33.70000000000021, -50.19999999999991, 3.700000000000188, 17.199999999999964, 21.900000000000006, -72.7000000000001, -204.3000000000005, -22.299999999999542, 100.09999999999978, -26.000000000000355, 40.70000000000031, 44.50000000000017, -160.50000000000088, -37.79999999999965, 110.09999999999945, -77.70000000000158, -16.29999999999967, 128.59999999999926, 10.400000000000126, 116.0999999999998, -90.30000000000163, 39.800000000000296, 31.90000000000023, 13.199999999999957, -19.39999999999951, -39.49999999999991, -34.90000000000022, 126.69999999999962, -161.3000000000003, 38.10000000000027, -301.29999999999995, 12.500000000000059, 180.09999999999923, 43.40000000000036, 188.9999999999997, -8.100000000000232, 154.59999999999954, 156.39999999999955, 47.09999999999992, 13.200000000000067, 87.50000000000006, -193.30000000000027, 104.39999999999878, -249.60000000000076, 86.79999999999997, -115.30000000000032, 182.79999999999947, -75.29999999999984, 60.30000000000006, -90.70000000000013, -5.099999999999699, 142.89999999999964, 20.19999999999998, 121.59999999999974, 16.900000000000002, 97.79999999999981, -182.00000000000117, 50.600000000000094, -201.1000000000003, 26.20000000000011, -115.20000000000061, -61.79999999999997, 28.10000000000003, -26.099999999999625, -270.0000000000001, 105.29999999999974, -87.30000000000013, 53.00000000000007, -21.599999999999696, -366.9, -81.20000000000016, 172.19999999999945, -122.20000000000101, 4.8000000000001855, -83.30000000000001, -26.99999999999993, 33.1000000000001, -28.299999999999734, -50.199999999999754, 2.199999999999997, -267.6999999999998, -6.899999999999851, -298.00000000000006, -34.799999999999805, -107.99999999999999, -196.40000000000043, 180.29999999999913, -33.49999999999955, 70.29999999999919, -37.79999999999982, -372.0, -390.5000000000001, 6.700000000000093, -20.40000000000051, -224.60000000000028, -292.70000000000005], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-164.80000000000058, -259.2999999999985, 3.1999999999999615, -226.6, 107.59999999999985, -127.00000000000045, 15.19999999999996, -150.4, -7.299999999999891, 20.000000000000014, 11.599999999999964, -317.8, -42.99999999999976, 13.699999999999964, -20.49999999999975, 13.699999999999964, -3.099999999999958, -12.9999999999998, 15.799999999999963, -245.5, -150.1000000000002, -173.20000000000033, -55.60000000000022, -15.699999999999797, 104.59999999999991, -101.50000000000054, -21.999999999999872, -136.0, 6.7999999999999705, 17.899999999999988, -35.499999999999936, -0.9999999999999846, -374.7999999999997, -15.699999999999747, -15.699999999999811, -132.10000000000062, 19.1, 20.000000000000014, -150.10000000000068, -34.59999999999975, 20.000000000000014, -91.30000000000061, 65.0, 11.599999999999964, -118.59999999999988, 20.000000000000014, 50.60000000000012, -77.50000000000009, -87.10000000000085, -110.20000000000078, 15.799999999999963, 20.000000000000014, 13.699999999999958, 3.1999999999999615, -38.799999999999756, 20.000000000000014, -30.39999999999975, -42.99999999999976, -82.30000000000082, -47.19999999999976, 9.499999999999964, -210.4, 5.299999999999965, 91.3999999999999, -246.70000000000041, -196.60000000000002, 1.0999999999999865, 20.000000000000014, -346.29999999999995, -268.00000000000006, -5.1999999999999265, -7.299999999999891, 166.69999999999987, 7.399999999999965, 20.000000000000014, 22.400000000000055, 65.59999999999998, 46.40000000000002, -85.89999999999998, -53.19999999999988, 160.39999999999992, -80.80000000000086, -93.40000000000069, 192.79999999999998, -58.900000000000496, -7.000000000000043, -311.8, 20.000000000000014, 16.1, -7.600000000000065, -208.90000000000052, -93.40000000000018, 15.799999999999946, 62.60000000000015, -279.09999999999934, -200.50000000000048, 15.799999999999946, -7.000000000000066, -7.299999999999919, -271.0, 15.799999999999963, 152.0, 20.000000000000014, -225.3000000000003, -208.9000000000005, 150.2, -169.30000000000004, -60.40000000000009, -57.70000000000048, 11.599999999999964, 105.19999999999997, 13.699999999999964, -15.699999999999761, 17.899999999999988, 127.39999999999998, -80.80000000000086, -3.099999999999958, -0.9999999999999846, -7.299999999999894, 40.099999999999994, -183.70000000000059, -175.30000000000058, -15.699999999999875, -6.700000000000152, -253.00000000000014, -207.10000000000016, 20.000000000000014, -38.799999999999756, -277.8000000000002, 11.59999999999997, -359.8, 20.000000000000014, -90.10000000000045, -8.800000000000011, -70.30000000000084, -35.79999999999986, -234.10000000000045, -292.8999999999994, 78.50000000000001, -26.199999999999747, 5.299999999999967, -349.6, 20.000000000000014, -175.0, -66.40000000000046, -139.20000000000073, -256.6, -292.30000000000007, 20.000000000000014, -215.20000000000041, 199.1, -145.9000000000006, -68.2000000000009, -354.9999999999998, -21.999999999999744, -5.1999999999999265, 20.000000000000014, -267.3000000000004, 15.799999999999963, -392.79999999999995, 15.799999999999963, -126.70000000000013, -382.0, -7.299999999999891, 20.000000000000014, -173.20000000000033, -253.00000000000017, 111.20000000000002, -283.29999999999984, -255.40000000000006, 7.399999999999984, -118.29999999999995, -370.5999999999999, -264.4000000000001, -330.1, 5.299999999999965, -125.20000000000007, -298.8000000000002, -160.60000000000014, -143.80000000000015, 170.2999999999999, -1.0000000000000506, -95.50000000000082, -21.999999999999886, 13.69999999999997, -3.400000000000084, -318.70000000000005, 2.8999999999999613, -352.0, -400.0, -318.70000000000016, -371.80000000000007, -252.60000000000042, 101.29999999999981, -15.999999999999746, -117.40000000000015, -222.70000000000007, -340.9000000000002, -336.69999999999993, -322.0], "policy_predator_policy_reward": [110.0, 103.0, 25.0, 141.0, 70.0, 23.0, 92.0, 98.0, 8.0, 13.0, 147.0, 109.0, 30.0, 3.0, 21.0, 3.0, 18.0, 20.0, 33.0, 124.0, 3.0, 116.0, 43.0, 6.0, 30.0, 67.0, 112.0, 20.0, 5.0, 11.0, 50.0, 31.0, 43.0, 187.0, 56.0, 54.0, 40.0, 31.0, 26.0, 81.0, 2.0, 53.0, 4.0, 48.0, 62.0, 47.0, 88.0, 55.0, 64.0, 43.0, 2.0, 2.0, 8.0, 7.0, 24.0, 8.0, 30.0, 24.0, 43.0, 47.0, 128.0, 38.0, 14.0, 16.0, 105.0, 177.0, 8.0, 9.0, 166.0, 147.0, 13.0, 12.0, 0.0, 6.0, 0.0, 1.0, 33.0, 44.0, 88.0, 43.0, 48.0, 27.0, 23.0, 34.0, 70.0, 43.0, 141.0, 164.0, 66.0, 13.0, 41.0, 68.0, 14.0, 12.0, 149.0, 81.0, 14.0, 64.0, 141.0, 22.0, 13.0, 2.0, 8.0, 122.0, 10.0, 109.0, 21.0, 118.0, 4.0, 37.0, 19.0, 5.0, 17.0, 1.0, 48.0, 27.0, 11.0, 10.0, 50.0, 15.0, 100.0, 77.0, 24.0, 49.0, 133.0, 126.0, 25.0, 20.0, 4.0, 147.0, 94.0, 184.0, 67.0, 60.0, 27.0, 53.0, 98.0, 159.0, 4.0, 49.0, 179.0, 78.0, 89.0, 119.0, 109.0, 75.0, 127.0, 55.0, 2.0, 112.0, 50.0, 69.0, 164.0, 137.0, 12.0, 20.0, 43.0, 121.0, 179.0, 171.0, 102.0, 42.0, 175.0, 186.0, 12.0, 91.0, 130.0, 14.0, 112.0, 159.0, 98.0, 6.0, 192.0, 145.0, 153.0, 137.0, 160.0, 156.0, 95.0, 13.0, 7.0, 4.0, 48.0, 36.0, 0.0, 60.0, 123.0, 155.0, 188.0, 192.0, 171.0, 129.0, 135.0, 23.0, 15.0, 98.0, 199.0, 140.0, 183.0, 183.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6164597794852634, "mean_inference_ms": 1.9143486139035373, "mean_action_processing_ms": 0.2710252657093005, "mean_env_wait_ms": 0.20806139077367092, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0038428306579589844, "StateBufferConnector_ms": 0.003806591033935547, "ViewRequirementAgentConnector_ms": 0.09760165214538574}, "num_episodes": 18, "episode_return_max": 188.9999999999997, "episode_return_min": -390.5000000000001, "episode_return_mean": -28.725000000000147, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 944000, "num_agent_steps_trained": 944000, "num_env_steps_sampled": 236000, "num_env_steps_trained": 236000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 377.5070781384589, "num_env_steps_trained_throughput_per_sec": 377.5070781384589, "timesteps_total": 236000, "num_env_steps_sampled_lifetime": 236000, "num_agent_steps_sampled_lifetime": 944000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 944000, "timers": {"training_iteration_time_ms": 10806.621, "restore_workers_time_ms": 0.015, "training_step_time_ms": 10806.565, "sample_time_ms": 1271.302, "learn_time_ms": 9521.277, "learn_throughput": 420.112, "synch_weights_time_ms": 12.839}, "counters": {"num_env_steps_sampled": 236000, "num_env_steps_trained": 236000, "num_agent_steps_sampled": 944000, "num_agent_steps_trained": 944000}, "done": false, "training_iteration": 59, "trial_id": "3dae5_00000", "date": "2024-08-14_09-17-43", "timestamp": 1723641463, "time_this_iter_s": 10.601243019104004, "time_total_s": 2282.747218132019, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0fd1e50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2282.747218132019, "iterations_since_restore": 59, "perf": {"cpu_util_percent": 29.320000000000007, "ram_util_percent": 83.54}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.9360909024243633, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.367361252396195, "policy_loss": -0.006502154171861038, "vf_loss": 6.3720650945390975, "vf_explained_var": 0.11139408447755077, "kl": 0.00799245075500627, "entropy": 1.025937587495834, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 112455.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.5944364988299276, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.01884225209554, "policy_loss": -0.002860498466164307, "vf_loss": 6.020122718306445, "vf_explained_var": -0.19571281214239736, "kl": 0.010533525444428907, "entropy": 1.3963417582410984, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 112455.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 240000, "num_env_steps_trained": 240000, "num_agent_steps_sampled": 960000, "num_agent_steps_trained": 960000}, "env_runners": {"episode_reward_max": 188.9999999999997, "episode_reward_min": -390.5000000000001, "episode_reward_mean": -41.09200000000017, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 199.1, "predator_policy": 199.0}, "policy_reward_mean": {"prey_policy": -96.47600000000007, "predator_policy": 75.93}, "custom_metrics": {}, "hist_stats": {"episode_reward": [116.0999999999998, -90.30000000000163, 39.800000000000296, 31.90000000000023, 13.199999999999957, -19.39999999999951, -39.49999999999991, -34.90000000000022, 126.69999999999962, -161.3000000000003, 38.10000000000027, -301.29999999999995, 12.500000000000059, 180.09999999999923, 43.40000000000036, 188.9999999999997, -8.100000000000232, 154.59999999999954, 156.39999999999955, 47.09999999999992, 13.200000000000067, 87.50000000000006, -193.30000000000027, 104.39999999999878, -249.60000000000076, 86.79999999999997, -115.30000000000032, 182.79999999999947, -75.29999999999984, 60.30000000000006, -90.70000000000013, -5.099999999999699, 142.89999999999964, 20.19999999999998, 121.59999999999974, 16.900000000000002, 97.79999999999981, -182.00000000000117, 50.600000000000094, -201.1000000000003, 26.20000000000011, -115.20000000000061, -61.79999999999997, 28.10000000000003, -26.099999999999625, -270.0000000000001, 105.29999999999974, -87.30000000000013, 53.00000000000007, -21.599999999999696, -366.9, -81.20000000000016, 172.19999999999945, -122.20000000000101, 4.8000000000001855, -83.30000000000001, -26.99999999999993, 33.1000000000001, -28.299999999999734, -50.199999999999754, 2.199999999999997, -267.6999999999998, -6.899999999999851, -298.00000000000006, -34.799999999999805, -107.99999999999999, -196.40000000000043, 180.29999999999913, -33.49999999999955, 70.29999999999919, -37.79999999999982, -372.0, -390.5000000000001, 6.700000000000093, -20.40000000000051, -224.60000000000028, -292.70000000000005, 10.000000000000096, 87.19999999999882, -147.60000000000065, 33.400000000000205, -35.39999999999987, -289.4000000000004, -106.30000000000024, -212.40000000000063, -6.100000000000064, -189.20000000000064, -145.5000000000013, -35.399999999999864, -235.50000000000077, -166.5, 73.09999999999985, 23.200000000000244, -177.80000000000084, -38.69999999999978, 56.300000000000075, 37.70000000000027, 133.2999999999993, 0.5999999999999965, -202.70000000000022], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [50.60000000000012, -77.50000000000009, -87.10000000000085, -110.20000000000078, 15.799999999999963, 20.000000000000014, 13.699999999999958, 3.1999999999999615, -38.799999999999756, 20.000000000000014, -30.39999999999975, -42.99999999999976, -82.30000000000082, -47.19999999999976, 9.499999999999964, -210.4, 5.299999999999965, 91.3999999999999, -246.70000000000041, -196.60000000000002, 1.0999999999999865, 20.000000000000014, -346.29999999999995, -268.00000000000006, -5.1999999999999265, -7.299999999999891, 166.69999999999987, 7.399999999999965, 20.000000000000014, 22.400000000000055, 65.59999999999998, 46.40000000000002, -85.89999999999998, -53.19999999999988, 160.39999999999992, -80.80000000000086, -93.40000000000069, 192.79999999999998, -58.900000000000496, -7.000000000000043, -311.8, 20.000000000000014, 16.1, -7.600000000000065, -208.90000000000052, -93.40000000000018, 15.799999999999946, 62.60000000000015, -279.09999999999934, -200.50000000000048, 15.799999999999946, -7.000000000000066, -7.299999999999919, -271.0, 15.799999999999963, 152.0, 20.000000000000014, -225.3000000000003, -208.9000000000005, 150.2, -169.30000000000004, -60.40000000000009, -57.70000000000048, 11.599999999999964, 105.19999999999997, 13.699999999999964, -15.699999999999761, 17.899999999999988, 127.39999999999998, -80.80000000000086, -3.099999999999958, -0.9999999999999846, -7.299999999999894, 40.099999999999994, -183.70000000000059, -175.30000000000058, -15.699999999999875, -6.700000000000152, -253.00000000000014, -207.10000000000016, 20.000000000000014, -38.799999999999756, -277.8000000000002, 11.59999999999997, -359.8, 20.000000000000014, -90.10000000000045, -8.800000000000011, -70.30000000000084, -35.79999999999986, -234.10000000000045, -292.8999999999994, 78.50000000000001, -26.199999999999747, 5.299999999999967, -349.6, 20.000000000000014, -175.0, -66.40000000000046, -139.20000000000073, -256.6, -292.30000000000007, 20.000000000000014, -215.20000000000041, 199.1, -145.9000000000006, -68.2000000000009, -354.9999999999998, -21.999999999999744, -5.1999999999999265, 20.000000000000014, -267.3000000000004, 15.799999999999963, -392.79999999999995, 15.799999999999963, -126.70000000000013, -382.0, -7.299999999999891, 20.000000000000014, -173.20000000000033, -253.00000000000017, 111.20000000000002, -283.29999999999984, -255.40000000000006, 7.399999999999984, -118.29999999999995, -370.5999999999999, -264.4000000000001, -330.1, 5.299999999999965, -125.20000000000007, -298.8000000000002, -160.60000000000014, -143.80000000000015, 170.2999999999999, -1.0000000000000506, -95.50000000000082, -21.999999999999886, 13.69999999999997, -3.400000000000084, -318.70000000000005, 2.8999999999999613, -352.0, -400.0, -318.70000000000016, -371.80000000000007, -252.60000000000042, 101.29999999999981, -15.999999999999746, -117.40000000000015, -222.70000000000007, -340.9000000000002, -336.69999999999993, -322.0, -0.9999999999999846, -21.999999999999744, 20.000000000000014, 51.20000000000016, -324.40000000000003, -5.1999999999999265, 7.399999999999965, 20.000000000000014, -349.0, 11.599999999999964, -214.30000000000035, -246.10000000000016, 20.000000000000014, -259.29999999999995, -226.0000000000002, -240.40000000000043, -271.8999999999992, 15.799999999999963, -225.7000000000004, -182.50000000000026, -106.00000000000061, -116.50000000000057, -47.20000000000001, -26.200000000000017, -177.4000000000006, -315.0999999999995, -148.6, -300.9000000000001, -378.9999999999998, 127.09999999999994, 45.200000000000244, -397.0, -343.29999999999967, -32.499999999999766, -330.69999999999925, 20.000000000000014, -65.50000000000006, 27.80000000000009, 7.699999999999978, -6.999999999999934, 67.4, 35.900000000000205, -362.19999999999993, 9.799999999999974, -144.40000000000015, -286.3], "policy_predator_policy_reward": [88.0, 55.0, 64.0, 43.0, 2.0, 2.0, 8.0, 7.0, 24.0, 8.0, 30.0, 24.0, 43.0, 47.0, 128.0, 38.0, 14.0, 16.0, 105.0, 177.0, 8.0, 9.0, 166.0, 147.0, 13.0, 12.0, 0.0, 6.0, 0.0, 1.0, 33.0, 44.0, 88.0, 43.0, 48.0, 27.0, 23.0, 34.0, 70.0, 43.0, 141.0, 164.0, 66.0, 13.0, 41.0, 68.0, 14.0, 12.0, 149.0, 81.0, 14.0, 64.0, 141.0, 22.0, 13.0, 2.0, 8.0, 122.0, 10.0, 109.0, 21.0, 118.0, 4.0, 37.0, 19.0, 5.0, 17.0, 1.0, 48.0, 27.0, 11.0, 10.0, 50.0, 15.0, 100.0, 77.0, 24.0, 49.0, 133.0, 126.0, 25.0, 20.0, 4.0, 147.0, 94.0, 184.0, 67.0, 60.0, 27.0, 53.0, 98.0, 159.0, 4.0, 49.0, 179.0, 78.0, 89.0, 119.0, 109.0, 75.0, 127.0, 55.0, 2.0, 112.0, 50.0, 69.0, 164.0, 137.0, 12.0, 20.0, 43.0, 121.0, 179.0, 171.0, 102.0, 42.0, 175.0, 186.0, 12.0, 91.0, 130.0, 14.0, 112.0, 159.0, 98.0, 6.0, 192.0, 145.0, 153.0, 137.0, 160.0, 156.0, 95.0, 13.0, 7.0, 4.0, 48.0, 36.0, 0.0, 60.0, 123.0, 155.0, 188.0, 192.0, 171.0, 129.0, 135.0, 23.0, 15.0, 98.0, 199.0, 140.0, 183.0, 183.0, 20.0, 13.0, 16.0, 0.0, 12.0, 170.0, 0.0, 6.0, 152.0, 150.0, 164.0, 7.0, 133.0, 0.0, 124.0, 130.0, 121.0, 129.0, 52.0, 167.0, 17.0, 60.0, 34.0, 4.0, 94.0, 163.0, 140.0, 143.0, 172.0, 153.0, 192.0, 183.0, 25.0, 173.0, 112.0, 160.0, 75.0, 19.0, 15.0, 22.0, 16.0, 14.0, 172.0, 181.0, 64.0, 164.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6150468684302399, "mean_inference_ms": 1.9099346074966124, "mean_action_processing_ms": 0.2700814868025164, "mean_env_wait_ms": 0.20755428171215065, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003823399543762207, "StateBufferConnector_ms": 0.0039021968841552734, "ViewRequirementAgentConnector_ms": 0.1026921272277832}, "num_episodes": 23, "episode_return_max": 188.9999999999997, "episode_return_min": -390.5000000000001, "episode_return_mean": -41.09200000000017, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 960000, "num_agent_steps_trained": 960000, "num_env_steps_sampled": 240000, "num_env_steps_trained": 240000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 381.73910332853006, "num_env_steps_trained_throughput_per_sec": 381.73910332853006, "timesteps_total": 240000, "num_env_steps_sampled_lifetime": 240000, "num_agent_steps_sampled_lifetime": 960000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 960000, "timers": {"training_iteration_time_ms": 10766.575, "restore_workers_time_ms": 0.016, "training_step_time_ms": 10766.519, "sample_time_ms": 1267.575, "learn_time_ms": 9485.066, "learn_throughput": 421.716, "synch_weights_time_ms": 12.748}, "counters": {"num_env_steps_sampled": 240000, "num_env_steps_trained": 240000, "num_agent_steps_sampled": 960000, "num_agent_steps_trained": 960000}, "done": false, "training_iteration": 60, "trial_id": "3dae5_00000", "date": "2024-08-14_09-17-53", "timestamp": 1723641473, "time_this_iter_s": 10.484621047973633, "time_total_s": 2293.2318391799927, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3635dc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2293.2318391799927, "iterations_since_restore": 60, "perf": {"cpu_util_percent": 27.44, "ram_util_percent": 83.37999999999998}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.9408947576290716, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.281626864589711, "policy_loss": -0.006911611749923655, "vf_loss": 4.286925888061523, "vf_explained_var": 0.2481673837338806, "kl": 0.007167013879191927, "entropy": 1.0035928565673726, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 114345.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.421521102215247, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.162326488797627, "policy_loss": -0.005380901099286146, "vf_loss": 4.166506268612292, "vf_explained_var": -0.07905309134059482, "kl": 0.00800746103197527, "entropy": 1.4082295735046346, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 114345.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 244000, "num_env_steps_trained": 244000, "num_agent_steps_sampled": 976000, "num_agent_steps_trained": 976000}, "env_runners": {"episode_reward_max": 182.79999999999947, "episode_reward_min": -390.5000000000001, "episode_reward_mean": -49.06700000000014, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -438.40000000000003, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 199.1, "predator_policy": 252.0}, "policy_reward_mean": {"prey_policy": -104.04850000000006, "predator_policy": 79.515}, "custom_metrics": {}, "hist_stats": {"episode_reward": [156.39999999999955, 47.09999999999992, 13.200000000000067, 87.50000000000006, -193.30000000000027, 104.39999999999878, -249.60000000000076, 86.79999999999997, -115.30000000000032, 182.79999999999947, -75.29999999999984, 60.30000000000006, -90.70000000000013, -5.099999999999699, 142.89999999999964, 20.19999999999998, 121.59999999999974, 16.900000000000002, 97.79999999999981, -182.00000000000117, 50.600000000000094, -201.1000000000003, 26.20000000000011, -115.20000000000061, -61.79999999999997, 28.10000000000003, -26.099999999999625, -270.0000000000001, 105.29999999999974, -87.30000000000013, 53.00000000000007, -21.599999999999696, -366.9, -81.20000000000016, 172.19999999999945, -122.20000000000101, 4.8000000000001855, -83.30000000000001, -26.99999999999993, 33.1000000000001, -28.299999999999734, -50.199999999999754, 2.199999999999997, -267.6999999999998, -6.899999999999851, -298.00000000000006, -34.799999999999805, -107.99999999999999, -196.40000000000043, 180.29999999999913, -33.49999999999955, 70.29999999999919, -37.79999999999982, -372.0, -390.5000000000001, 6.700000000000093, -20.40000000000051, -224.60000000000028, -292.70000000000005, 10.000000000000096, 87.19999999999882, -147.60000000000065, 33.400000000000205, -35.39999999999987, -289.4000000000004, -106.30000000000024, -212.40000000000063, -6.100000000000064, -189.20000000000064, -145.5000000000013, -35.399999999999864, -235.50000000000077, -166.5, 73.09999999999985, 23.200000000000244, -177.80000000000084, -38.69999999999978, 56.300000000000075, 37.70000000000027, 133.2999999999993, 0.5999999999999965, -202.70000000000022, -163.20000000000093, 58.20000000000039, -61.8999999999998, 75.59999999999962, -365.4999999999996, -182.5, 72.49999999999977, 14.700000000000022, -4.099999999999703, 9.400000000000164, 69.50000000000003, -25.099999999999618, -41.399999999999714, 80.0999999999994, 48.00000000000046, -121.20000000000113, 0.9000000000000258, 29.100000000000126], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-93.40000000000069, 192.79999999999998, -58.900000000000496, -7.000000000000043, -311.8, 20.000000000000014, 16.1, -7.600000000000065, -208.90000000000052, -93.40000000000018, 15.799999999999946, 62.60000000000015, -279.09999999999934, -200.50000000000048, 15.799999999999946, -7.000000000000066, -7.299999999999919, -271.0, 15.799999999999963, 152.0, 20.000000000000014, -225.3000000000003, -208.9000000000005, 150.2, -169.30000000000004, -60.40000000000009, -57.70000000000048, 11.599999999999964, 105.19999999999997, 13.699999999999964, -15.699999999999761, 17.899999999999988, 127.39999999999998, -80.80000000000086, -3.099999999999958, -0.9999999999999846, -7.299999999999894, 40.099999999999994, -183.70000000000059, -175.30000000000058, -15.699999999999875, -6.700000000000152, -253.00000000000014, -207.10000000000016, 20.000000000000014, -38.799999999999756, -277.8000000000002, 11.59999999999997, -359.8, 20.000000000000014, -90.10000000000045, -8.800000000000011, -70.30000000000084, -35.79999999999986, -234.10000000000045, -292.8999999999994, 78.50000000000001, -26.199999999999747, 5.299999999999967, -349.6, 20.000000000000014, -175.0, -66.40000000000046, -139.20000000000073, -256.6, -292.30000000000007, 20.000000000000014, -215.20000000000041, 199.1, -145.9000000000006, -68.2000000000009, -354.9999999999998, -21.999999999999744, -5.1999999999999265, 20.000000000000014, -267.3000000000004, 15.799999999999963, -392.79999999999995, 15.799999999999963, -126.70000000000013, -382.0, -7.299999999999891, 20.000000000000014, -173.20000000000033, -253.00000000000017, 111.20000000000002, -283.29999999999984, -255.40000000000006, 7.399999999999984, -118.29999999999995, -370.5999999999999, -264.4000000000001, -330.1, 5.299999999999965, -125.20000000000007, -298.8000000000002, -160.60000000000014, -143.80000000000015, 170.2999999999999, -1.0000000000000506, -95.50000000000082, -21.999999999999886, 13.69999999999997, -3.400000000000084, -318.70000000000005, 2.8999999999999613, -352.0, -400.0, -318.70000000000016, -371.80000000000007, -252.60000000000042, 101.29999999999981, -15.999999999999746, -117.40000000000015, -222.70000000000007, -340.9000000000002, -336.69999999999993, -322.0, -0.9999999999999846, -21.999999999999744, 20.000000000000014, 51.20000000000016, -324.40000000000003, -5.1999999999999265, 7.399999999999965, 20.000000000000014, -349.0, 11.599999999999964, -214.30000000000035, -246.10000000000016, 20.000000000000014, -259.29999999999995, -226.0000000000002, -240.40000000000043, -271.8999999999992, 15.799999999999963, -225.7000000000004, -182.50000000000026, -106.00000000000061, -116.50000000000057, -47.20000000000001, -26.200000000000017, -177.4000000000006, -315.0999999999995, -148.6, -300.9000000000001, -378.9999999999998, 127.09999999999994, 45.200000000000244, -397.0, -343.29999999999967, -32.499999999999766, -330.69999999999925, 20.000000000000014, -65.50000000000006, 27.80000000000009, 7.699999999999978, -6.999999999999934, 67.4, 35.900000000000205, -362.19999999999993, 9.799999999999974, -144.40000000000015, -286.3, -58.30000000000043, -292.9000000000001, 15.199999999999962, 20.000000000000014, 20.000000000000014, -304.90000000000003, 91.99999999999952, -51.39999999999988, -261.4, -276.0999999999999, -438.40000000000003, -199.09999999999997, 20.000000000000014, 27.500000000000163, -3.099999999999958, -5.1999999999999265, -36.699999999999754, -9.399999999999855, 36.500000000000234, -339.0999999999999, -9.399999999999862, 59.9000000000002, -77.80000000000086, -25.299999999999834, 20.000000000000014, -303.4000000000002, 16.099999999999866, 20.000000000000014, 20.000000000000014, -12.999999999999842, -211.9000000000004, -127.30000000000072, -246.70000000000024, 110.59999999999962, 11.599999999999964, 9.499999999999964], "policy_predator_policy_reward": [23.0, 34.0, 70.0, 43.0, 141.0, 164.0, 66.0, 13.0, 41.0, 68.0, 14.0, 12.0, 149.0, 81.0, 14.0, 64.0, 141.0, 22.0, 13.0, 2.0, 8.0, 122.0, 10.0, 109.0, 21.0, 118.0, 4.0, 37.0, 19.0, 5.0, 17.0, 1.0, 48.0, 27.0, 11.0, 10.0, 50.0, 15.0, 100.0, 77.0, 24.0, 49.0, 133.0, 126.0, 25.0, 20.0, 4.0, 147.0, 94.0, 184.0, 67.0, 60.0, 27.0, 53.0, 98.0, 159.0, 4.0, 49.0, 179.0, 78.0, 89.0, 119.0, 109.0, 75.0, 127.0, 55.0, 2.0, 112.0, 50.0, 69.0, 164.0, 137.0, 12.0, 20.0, 43.0, 121.0, 179.0, 171.0, 102.0, 42.0, 175.0, 186.0, 12.0, 91.0, 130.0, 14.0, 112.0, 159.0, 98.0, 6.0, 192.0, 145.0, 153.0, 137.0, 160.0, 156.0, 95.0, 13.0, 7.0, 4.0, 48.0, 36.0, 0.0, 60.0, 123.0, 155.0, 188.0, 192.0, 171.0, 129.0, 135.0, 23.0, 15.0, 98.0, 199.0, 140.0, 183.0, 183.0, 20.0, 13.0, 16.0, 0.0, 12.0, 170.0, 0.0, 6.0, 152.0, 150.0, 164.0, 7.0, 133.0, 0.0, 124.0, 130.0, 121.0, 129.0, 52.0, 167.0, 17.0, 60.0, 34.0, 4.0, 94.0, 163.0, 140.0, 143.0, 172.0, 153.0, 192.0, 183.0, 25.0, 173.0, 112.0, 160.0, 75.0, 19.0, 15.0, 22.0, 16.0, 14.0, 172.0, 181.0, 64.0, 164.0, 39.0, 149.0, 19.0, 4.0, 144.0, 79.0, 34.0, 1.0, 24.0, 148.0, 252.0, 203.0, 16.0, 9.0, 11.0, 12.0, 27.0, 15.0, 153.0, 159.0, 14.0, 5.0, 66.0, 12.0, 147.0, 95.0, 7.0, 37.0, 22.0, 19.0, 111.0, 107.0, 127.0, 10.0, 5.0, 3.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6138895235076822, "mean_inference_ms": 1.90611840788981, "mean_action_processing_ms": 0.26934956268898325, "mean_env_wait_ms": 0.2071098741603442, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0036967992782592773, "StateBufferConnector_ms": 0.00312197208404541, "ViewRequirementAgentConnector_ms": 0.09496891498565674}, "num_episodes": 18, "episode_return_max": 182.79999999999947, "episode_return_min": -390.5000000000001, "episode_return_mean": -49.06700000000014, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 976000, "num_agent_steps_trained": 976000, "num_env_steps_sampled": 244000, "num_env_steps_trained": 244000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 373.7760479140103, "num_env_steps_trained_throughput_per_sec": 373.7760479140103, "timesteps_total": 244000, "num_env_steps_sampled_lifetime": 244000, "num_agent_steps_sampled_lifetime": 976000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 976000, "timers": {"training_iteration_time_ms": 10766.142, "restore_workers_time_ms": 0.015, "training_step_time_ms": 10766.097, "sample_time_ms": 1261.878, "learn_time_ms": 9490.224, "learn_throughput": 421.486, "synch_weights_time_ms": 12.796}, "counters": {"num_env_steps_sampled": 244000, "num_env_steps_trained": 244000, "num_agent_steps_sampled": 976000, "num_agent_steps_trained": 976000}, "done": false, "training_iteration": 61, "trial_id": "3dae5_00000", "date": "2024-08-14_09-18-04", "timestamp": 1723641484, "time_this_iter_s": 10.707294225692749, "time_total_s": 2303.9391334056854, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b36078b0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2303.9391334056854, "iterations_since_restore": 61, "perf": {"cpu_util_percent": 27.459999999999997, "ram_util_percent": 83.52000000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.6822923410191106, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.755301794551668, "policy_loss": -0.006723908549322495, "vf_loss": 3.7608891904669464, "vf_explained_var": 0.21799384724526177, "kl": 0.005051171025021205, "entropy": 0.9582520566604755, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 116235.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7769535531127263, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.9292463389654007, "policy_loss": -0.004097202015429656, "vf_loss": 3.932282533595171, "vf_explained_var": 0.008958884048714208, "kl": 0.00707333603022262, "entropy": 1.3911993204601227, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 116235.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 248000, "num_env_steps_trained": 248000, "num_agent_steps_sampled": 992000, "num_agent_steps_trained": 992000}, "env_runners": {"episode_reward_max": 180.29999999999913, "episode_reward_min": -413.7999999999994, "episode_reward_mean": -60.78100000000014, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -844.6999999999999, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 199.1, "predator_policy": 748.0}, "policy_reward_mean": {"prey_policy": -119.76050000000006, "predator_policy": 89.37}, "custom_metrics": {}, "hist_stats": {"episode_reward": [97.79999999999981, -182.00000000000117, 50.600000000000094, -201.1000000000003, 26.20000000000011, -115.20000000000061, -61.79999999999997, 28.10000000000003, -26.099999999999625, -270.0000000000001, 105.29999999999974, -87.30000000000013, 53.00000000000007, -21.599999999999696, -366.9, -81.20000000000016, 172.19999999999945, -122.20000000000101, 4.8000000000001855, -83.30000000000001, -26.99999999999993, 33.1000000000001, -28.299999999999734, -50.199999999999754, 2.199999999999997, -267.6999999999998, -6.899999999999851, -298.00000000000006, -34.799999999999805, -107.99999999999999, -196.40000000000043, 180.29999999999913, -33.49999999999955, 70.29999999999919, -37.79999999999982, -372.0, -390.5000000000001, 6.700000000000093, -20.40000000000051, -224.60000000000028, -292.70000000000005, 10.000000000000096, 87.19999999999882, -147.60000000000065, 33.400000000000205, -35.39999999999987, -289.4000000000004, -106.30000000000024, -212.40000000000063, -6.100000000000064, -189.20000000000064, -145.5000000000013, -35.399999999999864, -235.50000000000077, -166.5, 73.09999999999985, 23.200000000000244, -177.80000000000084, -38.69999999999978, 56.300000000000075, 37.70000000000027, 133.2999999999993, 0.5999999999999965, -202.70000000000022, -163.20000000000093, 58.20000000000039, -61.8999999999998, 75.59999999999962, -365.4999999999996, -182.5, 72.49999999999977, 14.700000000000022, -4.099999999999703, 9.400000000000164, 69.50000000000003, -25.099999999999618, -41.399999999999714, 80.0999999999994, 48.00000000000046, -121.20000000000113, 0.9000000000000258, 29.100000000000126, -138.00000000000037, 78.79999999999976, -97.80000000000084, 121.29999999999848, 0.09999999999998854, 29.600000000000158, 34.90000000000007, -127.7000000000003, 32.10000000000018, -40.49999999999982, -82.50000000000114, -382.20000000000016, 69.60000000000008, 0.6000000000002, 33.3000000000002, 33.7000000000002, -413.7999999999994, -12.100000000000012], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-7.299999999999894, 40.099999999999994, -183.70000000000059, -175.30000000000058, -15.699999999999875, -6.700000000000152, -253.00000000000014, -207.10000000000016, 20.000000000000014, -38.799999999999756, -277.8000000000002, 11.59999999999997, -359.8, 20.000000000000014, -90.10000000000045, -8.800000000000011, -70.30000000000084, -35.79999999999986, -234.10000000000045, -292.8999999999994, 78.50000000000001, -26.199999999999747, 5.299999999999967, -349.6, 20.000000000000014, -175.0, -66.40000000000046, -139.20000000000073, -256.6, -292.30000000000007, 20.000000000000014, -215.20000000000041, 199.1, -145.9000000000006, -68.2000000000009, -354.9999999999998, -21.999999999999744, -5.1999999999999265, 20.000000000000014, -267.3000000000004, 15.799999999999963, -392.79999999999995, 15.799999999999963, -126.70000000000013, -382.0, -7.299999999999891, 20.000000000000014, -173.20000000000033, -253.00000000000017, 111.20000000000002, -283.29999999999984, -255.40000000000006, 7.399999999999984, -118.29999999999995, -370.5999999999999, -264.4000000000001, -330.1, 5.299999999999965, -125.20000000000007, -298.8000000000002, -160.60000000000014, -143.80000000000015, 170.2999999999999, -1.0000000000000506, -95.50000000000082, -21.999999999999886, 13.69999999999997, -3.400000000000084, -318.70000000000005, 2.8999999999999613, -352.0, -400.0, -318.70000000000016, -371.80000000000007, -252.60000000000042, 101.29999999999981, -15.999999999999746, -117.40000000000015, -222.70000000000007, -340.9000000000002, -336.69999999999993, -322.0, -0.9999999999999846, -21.999999999999744, 20.000000000000014, 51.20000000000016, -324.40000000000003, -5.1999999999999265, 7.399999999999965, 20.000000000000014, -349.0, 11.599999999999964, -214.30000000000035, -246.10000000000016, 20.000000000000014, -259.29999999999995, -226.0000000000002, -240.40000000000043, -271.8999999999992, 15.799999999999963, -225.7000000000004, -182.50000000000026, -106.00000000000061, -116.50000000000057, -47.20000000000001, -26.200000000000017, -177.4000000000006, -315.0999999999995, -148.6, -300.9000000000001, -378.9999999999998, 127.09999999999994, 45.200000000000244, -397.0, -343.29999999999967, -32.499999999999766, -330.69999999999925, 20.000000000000014, -65.50000000000006, 27.80000000000009, 7.699999999999978, -6.999999999999934, 67.4, 35.900000000000205, -362.19999999999993, 9.799999999999974, -144.40000000000015, -286.3, -58.30000000000043, -292.9000000000001, 15.199999999999962, 20.000000000000014, 20.000000000000014, -304.90000000000003, 91.99999999999952, -51.39999999999988, -261.4, -276.0999999999999, -438.40000000000003, -199.09999999999997, 20.000000000000014, 27.500000000000163, -3.099999999999958, -5.1999999999999265, -36.699999999999754, -9.399999999999855, 36.500000000000234, -339.0999999999999, -9.399999999999862, 59.9000000000002, -77.80000000000086, -25.299999999999834, 20.000000000000014, -303.4000000000002, 16.099999999999866, 20.000000000000014, 20.000000000000014, -12.999999999999842, -211.9000000000004, -127.30000000000072, -246.70000000000024, 110.59999999999962, 11.599999999999964, 9.499999999999964, -281.60000000000014, -30.39999999999978, -21.699999999999996, 33.50000000000021, 13.699999999999964, -242.50000000000034, 67.39999999999992, 47.900000000000226, -257.2000000000003, 125.29999999999998, 17.899999999999988, -55.30000000000019, 15.799999999999963, -178.90000000000023, 20.000000000000014, -567.7, 15.799999999999963, 5.299999999999965, 20.000000000000014, -440.5000000000001, -22.29999999999975, -173.2000000000005, -314.4999999999999, -844.6999999999999, 48.800000000000225, 15.799999999999963, -0.9999999999999846, -75.40000000000083, 9.499999999999964, 15.799999999999963, -64.9000000000008, 11.599999999999964, -342.7999999999996, -605.9999999999998, -557.0999999999999, 20.000000000000014], "policy_predator_policy_reward": [50.0, 15.0, 100.0, 77.0, 24.0, 49.0, 133.0, 126.0, 25.0, 20.0, 4.0, 147.0, 94.0, 184.0, 67.0, 60.0, 27.0, 53.0, 98.0, 159.0, 4.0, 49.0, 179.0, 78.0, 89.0, 119.0, 109.0, 75.0, 127.0, 55.0, 2.0, 112.0, 50.0, 69.0, 164.0, 137.0, 12.0, 20.0, 43.0, 121.0, 179.0, 171.0, 102.0, 42.0, 175.0, 186.0, 12.0, 91.0, 130.0, 14.0, 112.0, 159.0, 98.0, 6.0, 192.0, 145.0, 153.0, 137.0, 160.0, 156.0, 95.0, 13.0, 7.0, 4.0, 48.0, 36.0, 0.0, 60.0, 123.0, 155.0, 188.0, 192.0, 171.0, 129.0, 135.0, 23.0, 15.0, 98.0, 199.0, 140.0, 183.0, 183.0, 20.0, 13.0, 16.0, 0.0, 12.0, 170.0, 0.0, 6.0, 152.0, 150.0, 164.0, 7.0, 133.0, 0.0, 124.0, 130.0, 121.0, 129.0, 52.0, 167.0, 17.0, 60.0, 34.0, 4.0, 94.0, 163.0, 140.0, 143.0, 172.0, 153.0, 192.0, 183.0, 25.0, 173.0, 112.0, 160.0, 75.0, 19.0, 15.0, 22.0, 16.0, 14.0, 172.0, 181.0, 64.0, 164.0, 39.0, 149.0, 19.0, 4.0, 144.0, 79.0, 34.0, 1.0, 24.0, 148.0, 252.0, 203.0, 16.0, 9.0, 11.0, 12.0, 27.0, 15.0, 153.0, 159.0, 14.0, 5.0, 66.0, 12.0, 147.0, 95.0, 7.0, 37.0, 22.0, 19.0, 111.0, 107.0, 127.0, 10.0, 5.0, 3.0, 168.0, 6.0, 31.0, 36.0, 3.0, 128.0, 4.0, 2.0, 0.0, 132.0, 37.0, 30.0, 101.0, 97.0, 420.0, 0.0, 6.0, 5.0, 151.0, 229.0, 21.0, 92.0, 29.0, 748.0, 3.0, 2.0, 45.0, 32.0, 3.0, 5.0, 46.0, 41.0, 494.0, 41.0, 377.0, 148.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6126985559351225, "mean_inference_ms": 1.9019552486644795, "mean_action_processing_ms": 0.2686278412313362, "mean_env_wait_ms": 0.2066395726939672, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0037043094635009766, "StateBufferConnector_ms": 0.0030630826950073242, "ViewRequirementAgentConnector_ms": 0.09363424777984619}, "num_episodes": 18, "episode_return_max": 180.29999999999913, "episode_return_min": -413.7999999999994, "episode_return_mean": -60.78100000000014, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 992000, "num_agent_steps_trained": 992000, "num_env_steps_sampled": 248000, "num_env_steps_trained": 248000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 373.2761480835964, "num_env_steps_trained_throughput_per_sec": 373.2761480835964, "timesteps_total": 248000, "num_env_steps_sampled_lifetime": 248000, "num_agent_steps_sampled_lifetime": 992000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 992000, "timers": {"training_iteration_time_ms": 10753.307, "restore_workers_time_ms": 0.015, "training_step_time_ms": 10753.263, "sample_time_ms": 1249.93, "learn_time_ms": 9489.535, "learn_throughput": 421.517, "synch_weights_time_ms": 12.602}, "counters": {"num_env_steps_sampled": 248000, "num_env_steps_trained": 248000, "num_agent_steps_sampled": 992000, "num_agent_steps_trained": 992000}, "done": false, "training_iteration": 62, "trial_id": "3dae5_00000", "date": "2024-08-14_09-18-15", "timestamp": 1723641495, "time_this_iter_s": 10.720607995986938, "time_total_s": 2314.6597414016724, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3635d30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2314.6597414016724, "iterations_since_restore": 62, "perf": {"cpu_util_percent": 27.40625, "ram_util_percent": 83.575}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.6472608753928433, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.6789147725180973, "policy_loss": -0.004223853114391209, "vf_loss": 3.682596420232581, "vf_explained_var": 0.23632127529098873, "kl": 0.002409822892164205, "entropy": 0.99505897372488, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 118125.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8992082796084186, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.222711340334049, "policy_loss": -0.008186164159923988, "vf_loss": 4.228919977107376, "vf_explained_var": -0.01465222507557541, "kl": 0.013183440983827604, "entropy": 1.4007852707590376, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 118125.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 252000, "num_env_steps_trained": 252000, "num_agent_steps_sampled": 1008000, "num_agent_steps_trained": 1008000}, "env_runners": {"episode_reward_max": 180.29999999999913, "episode_reward_min": -413.7999999999994, "episode_reward_mean": -60.12200000000018, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -856.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 170.2999999999999, "predator_policy": 748.0}, "policy_reward_mean": {"prey_policy": -116.60600000000004, "predator_policy": 86.545}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-28.299999999999734, -50.199999999999754, 2.199999999999997, -267.6999999999998, -6.899999999999851, -298.00000000000006, -34.799999999999805, -107.99999999999999, -196.40000000000043, 180.29999999999913, -33.49999999999955, 70.29999999999919, -37.79999999999982, -372.0, -390.5000000000001, 6.700000000000093, -20.40000000000051, -224.60000000000028, -292.70000000000005, 10.000000000000096, 87.19999999999882, -147.60000000000065, 33.400000000000205, -35.39999999999987, -289.4000000000004, -106.30000000000024, -212.40000000000063, -6.100000000000064, -189.20000000000064, -145.5000000000013, -35.399999999999864, -235.50000000000077, -166.5, 73.09999999999985, 23.200000000000244, -177.80000000000084, -38.69999999999978, 56.300000000000075, 37.70000000000027, 133.2999999999993, 0.5999999999999965, -202.70000000000022, -163.20000000000093, 58.20000000000039, -61.8999999999998, 75.59999999999962, -365.4999999999996, -182.5, 72.49999999999977, 14.700000000000022, -4.099999999999703, 9.400000000000164, 69.50000000000003, -25.099999999999618, -41.399999999999714, 80.0999999999994, 48.00000000000046, -121.20000000000113, 0.9000000000000258, 29.100000000000126, -138.00000000000037, 78.79999999999976, -97.80000000000084, 121.29999999999848, 0.09999999999998854, 29.600000000000158, 34.90000000000007, -127.7000000000003, 32.10000000000018, -40.49999999999982, -82.50000000000114, -382.20000000000016, 69.60000000000008, 0.6000000000002, 33.3000000000002, 33.7000000000002, -413.7999999999994, -12.100000000000012, -210.5000000000004, 140.59999999999866, -297.4000000000001, -37.899999999999835, 21.2, -28.09999999999959, 87.19999999999881, 23.90000000000007, -169.5000000000012, 41.90000000000033, -83.60000000000146, 70.69999999999985, 24.000000000000053, -184.9000000000003, 40.0000000000003, -110.7000000000011, 34.70000000000022, -165.2000000000006, -96.30000000000052, 9.100000000000028, -60.29999999999984, -57.60000000000133], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-382.0, -7.299999999999891, 20.000000000000014, -173.20000000000033, -253.00000000000017, 111.20000000000002, -283.29999999999984, -255.40000000000006, 7.399999999999984, -118.29999999999995, -370.5999999999999, -264.4000000000001, -330.1, 5.299999999999965, -125.20000000000007, -298.8000000000002, -160.60000000000014, -143.80000000000015, 170.2999999999999, -1.0000000000000506, -95.50000000000082, -21.999999999999886, 13.69999999999997, -3.400000000000084, -318.70000000000005, 2.8999999999999613, -352.0, -400.0, -318.70000000000016, -371.80000000000007, -252.60000000000042, 101.29999999999981, -15.999999999999746, -117.40000000000015, -222.70000000000007, -340.9000000000002, -336.69999999999993, -322.0, -0.9999999999999846, -21.999999999999744, 20.000000000000014, 51.20000000000016, -324.40000000000003, -5.1999999999999265, 7.399999999999965, 20.000000000000014, -349.0, 11.599999999999964, -214.30000000000035, -246.10000000000016, 20.000000000000014, -259.29999999999995, -226.0000000000002, -240.40000000000043, -271.8999999999992, 15.799999999999963, -225.7000000000004, -182.50000000000026, -106.00000000000061, -116.50000000000057, -47.20000000000001, -26.200000000000017, -177.4000000000006, -315.0999999999995, -148.6, -300.9000000000001, -378.9999999999998, 127.09999999999994, 45.200000000000244, -397.0, -343.29999999999967, -32.499999999999766, -330.69999999999925, 20.000000000000014, -65.50000000000006, 27.80000000000009, 7.699999999999978, -6.999999999999934, 67.4, 35.900000000000205, -362.19999999999993, 9.799999999999974, -144.40000000000015, -286.3, -58.30000000000043, -292.9000000000001, 15.199999999999962, 20.000000000000014, 20.000000000000014, -304.90000000000003, 91.99999999999952, -51.39999999999988, -261.4, -276.0999999999999, -438.40000000000003, -199.09999999999997, 20.000000000000014, 27.500000000000163, -3.099999999999958, -5.1999999999999265, -36.699999999999754, -9.399999999999855, 36.500000000000234, -339.0999999999999, -9.399999999999862, 59.9000000000002, -77.80000000000086, -25.299999999999834, 20.000000000000014, -303.4000000000002, 16.099999999999866, 20.000000000000014, 20.000000000000014, -12.999999999999842, -211.9000000000004, -127.30000000000072, -246.70000000000024, 110.59999999999962, 11.599999999999964, 9.499999999999964, -281.60000000000014, -30.39999999999978, -21.699999999999996, 33.50000000000021, 13.699999999999964, -242.50000000000034, 67.39999999999992, 47.900000000000226, -257.2000000000003, 125.29999999999998, 17.899999999999988, -55.30000000000019, 15.799999999999963, -178.90000000000023, 20.000000000000014, -567.7, 15.799999999999963, 5.299999999999965, 20.000000000000014, -440.5000000000001, -22.29999999999975, -173.2000000000005, -314.4999999999999, -844.6999999999999, 48.800000000000225, 15.799999999999963, -0.9999999999999846, -75.40000000000083, 9.499999999999964, 15.799999999999963, -64.9000000000008, 11.599999999999964, -342.7999999999996, -605.9999999999998, -557.0999999999999, 20.000000000000014, -164.80000000000018, -162.70000000000024, 69.49999999999976, 52.100000000000186, -210.10000000000016, -260.3000000000002, 37.10000000000025, -357.9999999999998, 9.499999999999964, -10.299999999999859, -84.70000000000081, -6.399999999999965, 21.800000000000047, 61.400000000000205, -166.90000000000023, 15.799999999999963, -229.30000000000032, -89.20000000000084, 7.399999999999965, 3.4999999999999742, -148.0000000000006, -34.59999999999976, 4.700000000000002, 20.000000000000014, -36.69999999999978, 13.699999999999964, -591.6, -28.299999999999876, 20.000000000000014, 20.000000000000014, -217.3000000000005, -9.399999999999968, -9.399999999999855, 22.100000000000048, -47.19999999999979, -856.0, -322.29999999999933, 20.000000000000014, -59.20000000000056, -6.6999999999999496, -309.69999999999965, 76.39999999999947, -76.60000000000088, -42.99999999999976], "policy_predator_policy_reward": [175.0, 186.0, 12.0, 91.0, 130.0, 14.0, 112.0, 159.0, 98.0, 6.0, 192.0, 145.0, 153.0, 137.0, 160.0, 156.0, 95.0, 13.0, 7.0, 4.0, 48.0, 36.0, 0.0, 60.0, 123.0, 155.0, 188.0, 192.0, 171.0, 129.0, 135.0, 23.0, 15.0, 98.0, 199.0, 140.0, 183.0, 183.0, 20.0, 13.0, 16.0, 0.0, 12.0, 170.0, 0.0, 6.0, 152.0, 150.0, 164.0, 7.0, 133.0, 0.0, 124.0, 130.0, 121.0, 129.0, 52.0, 167.0, 17.0, 60.0, 34.0, 4.0, 94.0, 163.0, 140.0, 143.0, 172.0, 153.0, 192.0, 183.0, 25.0, 173.0, 112.0, 160.0, 75.0, 19.0, 15.0, 22.0, 16.0, 14.0, 172.0, 181.0, 64.0, 164.0, 39.0, 149.0, 19.0, 4.0, 144.0, 79.0, 34.0, 1.0, 24.0, 148.0, 252.0, 203.0, 16.0, 9.0, 11.0, 12.0, 27.0, 15.0, 153.0, 159.0, 14.0, 5.0, 66.0, 12.0, 147.0, 95.0, 7.0, 37.0, 22.0, 19.0, 111.0, 107.0, 127.0, 10.0, 5.0, 3.0, 168.0, 6.0, 31.0, 36.0, 3.0, 128.0, 4.0, 2.0, 0.0, 132.0, 37.0, 30.0, 101.0, 97.0, 420.0, 0.0, 6.0, 5.0, 151.0, 229.0, 21.0, 92.0, 29.0, 748.0, 3.0, 2.0, 45.0, 32.0, 3.0, 5.0, 46.0, 41.0, 494.0, 41.0, 377.0, 148.0, 0.0, 117.0, 10.0, 9.0, 161.0, 12.0, 111.0, 172.0, 5.0, 17.0, 54.0, 9.0, 3.0, 1.0, 86.0, 89.0, 25.0, 124.0, 16.0, 15.0, 13.0, 86.0, 22.0, 24.0, 16.0, 31.0, 14.0, 421.0, 0.0, 0.0, 113.0, 3.0, 8.0, 14.0, 25.0, 713.0, 43.0, 163.0, 37.0, 38.0, 16.0, 157.0, 16.0, 46.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6113062170284438, "mean_inference_ms": 1.897198965240036, "mean_action_processing_ms": 0.2678439969853861, "mean_env_wait_ms": 0.2060790199251301, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003762483596801758, "StateBufferConnector_ms": 0.0030622482299804688, "ViewRequirementAgentConnector_ms": 0.09421789646148682}, "num_episodes": 22, "episode_return_max": 180.29999999999913, "episode_return_min": -413.7999999999994, "episode_return_mean": -60.12200000000018, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1008000, "num_agent_steps_trained": 1008000, "num_env_steps_sampled": 252000, "num_env_steps_trained": 252000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 363.92995385435404, "num_env_steps_trained_throughput_per_sec": 363.92995385435404, "timesteps_total": 252000, "num_env_steps_sampled_lifetime": 252000, "num_agent_steps_sampled_lifetime": 1008000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1008000, "timers": {"training_iteration_time_ms": 10747.156, "restore_workers_time_ms": 0.014, "training_step_time_ms": 10747.115, "sample_time_ms": 1244.279, "learn_time_ms": 9488.477, "learn_throughput": 421.564, "synch_weights_time_ms": 13.061}, "counters": {"num_env_steps_sampled": 252000, "num_env_steps_trained": 252000, "num_agent_steps_sampled": 1008000, "num_agent_steps_trained": 1008000}, "done": false, "training_iteration": 63, "trial_id": "3dae5_00000", "date": "2024-08-14_09-18-26", "timestamp": 1723641506, "time_this_iter_s": 11.103256702423096, "time_total_s": 2325.7629981040955, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b36185e0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2325.7629981040955, "iterations_since_restore": 63, "perf": {"cpu_util_percent": 28.7, "ram_util_percent": 83.59333333333332}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.0610892431130483, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.910230398430395, "policy_loss": -0.006121264499730415, "vf_loss": 3.9152564024799084, "vf_explained_var": 0.08973017271864352, "kl": 0.009735592942050942, "entropy": 0.990494808728102, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 120015.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.2962995217906106, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.6736941106735714, "policy_loss": -0.011431958403305284, "vf_loss": 3.6836466794291503, "vf_explained_var": -0.010359592570198906, "kl": 0.009862581754052089, "entropy": 1.344359906009896, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 120015.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 256000, "num_env_steps_trained": 256000, "num_agent_steps_sampled": 1024000, "num_agent_steps_trained": 1024000}, "env_runners": {"episode_reward_max": 140.59999999999866, "episode_reward_min": -413.7999999999994, "episode_reward_mean": -38.62400000000014, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -856.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 156.79999999999984, "predator_policy": 748.0}, "policy_reward_mean": {"prey_policy": -92.68700000000004, "predator_policy": 73.375}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-35.39999999999987, -289.4000000000004, -106.30000000000024, -212.40000000000063, -6.100000000000064, -189.20000000000064, -145.5000000000013, -35.399999999999864, -235.50000000000077, -166.5, 73.09999999999985, 23.200000000000244, -177.80000000000084, -38.69999999999978, 56.300000000000075, 37.70000000000027, 133.2999999999993, 0.5999999999999965, -202.70000000000022, -163.20000000000093, 58.20000000000039, -61.8999999999998, 75.59999999999962, -365.4999999999996, -182.5, 72.49999999999977, 14.700000000000022, -4.099999999999703, 9.400000000000164, 69.50000000000003, -25.099999999999618, -41.399999999999714, 80.0999999999994, 48.00000000000046, -121.20000000000113, 0.9000000000000258, 29.100000000000126, -138.00000000000037, 78.79999999999976, -97.80000000000084, 121.29999999999848, 0.09999999999998854, 29.600000000000158, 34.90000000000007, -127.7000000000003, 32.10000000000018, -40.49999999999982, -82.50000000000114, -382.20000000000016, 69.60000000000008, 0.6000000000002, 33.3000000000002, 33.7000000000002, -413.7999999999994, -12.100000000000012, -210.5000000000004, 140.59999999999866, -297.4000000000001, -37.899999999999835, 21.2, -28.09999999999959, 87.19999999999881, 23.90000000000007, -169.5000000000012, 41.90000000000033, -83.60000000000146, 70.69999999999985, 24.000000000000053, -184.9000000000003, 40.0000000000003, -110.7000000000011, 34.70000000000022, -165.2000000000006, -96.30000000000052, 9.100000000000028, -60.29999999999984, -57.60000000000133, 3.9000000000000674, -5.499999999999922, 53.300000000000466, -39.19999999999954, 35.600000000000236, 33.30000000000009, 36.50000000000025, -26.399999999999984, 24.60000000000005, 135.59999999999965, -66.09999999999992, -63.200000000001125, -54.400000000001015, 68.99999999999979, 60.400000000000325, 31.000000000000195, 0.30000000000011123, -268.19999999999817, 15.799999999999939, -102.50000000000063, 62.80000000000034, 48.80000000000046, 45.10000000000034], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-349.0, 11.599999999999964, -214.30000000000035, -246.10000000000016, 20.000000000000014, -259.29999999999995, -226.0000000000002, -240.40000000000043, -271.8999999999992, 15.799999999999963, -225.7000000000004, -182.50000000000026, -106.00000000000061, -116.50000000000057, -47.20000000000001, -26.200000000000017, -177.4000000000006, -315.0999999999995, -148.6, -300.9000000000001, -378.9999999999998, 127.09999999999994, 45.200000000000244, -397.0, -343.29999999999967, -32.499999999999766, -330.69999999999925, 20.000000000000014, -65.50000000000006, 27.80000000000009, 7.699999999999978, -6.999999999999934, 67.4, 35.900000000000205, -362.19999999999993, 9.799999999999974, -144.40000000000015, -286.3, -58.30000000000043, -292.9000000000001, 15.199999999999962, 20.000000000000014, 20.000000000000014, -304.90000000000003, 91.99999999999952, -51.39999999999988, -261.4, -276.0999999999999, -438.40000000000003, -199.09999999999997, 20.000000000000014, 27.500000000000163, -3.099999999999958, -5.1999999999999265, -36.699999999999754, -9.399999999999855, 36.500000000000234, -339.0999999999999, -9.399999999999862, 59.9000000000002, -77.80000000000086, -25.299999999999834, 20.000000000000014, -303.4000000000002, 16.099999999999866, 20.000000000000014, 20.000000000000014, -12.999999999999842, -211.9000000000004, -127.30000000000072, -246.70000000000024, 110.59999999999962, 11.599999999999964, 9.499999999999964, -281.60000000000014, -30.39999999999978, -21.699999999999996, 33.50000000000021, 13.699999999999964, -242.50000000000034, 67.39999999999992, 47.900000000000226, -257.2000000000003, 125.29999999999998, 17.899999999999988, -55.30000000000019, 15.799999999999963, -178.90000000000023, 20.000000000000014, -567.7, 15.799999999999963, 5.299999999999965, 20.000000000000014, -440.5000000000001, -22.29999999999975, -173.2000000000005, -314.4999999999999, -844.6999999999999, 48.800000000000225, 15.799999999999963, -0.9999999999999846, -75.40000000000083, 9.499999999999964, 15.799999999999963, -64.9000000000008, 11.599999999999964, -342.7999999999996, -605.9999999999998, -557.0999999999999, 20.000000000000014, -164.80000000000018, -162.70000000000024, 69.49999999999976, 52.100000000000186, -210.10000000000016, -260.3000000000002, 37.10000000000025, -357.9999999999998, 9.499999999999964, -10.299999999999859, -84.70000000000081, -6.399999999999965, 21.800000000000047, 61.400000000000205, -166.90000000000023, 15.799999999999963, -229.30000000000032, -89.20000000000084, 7.399999999999965, 3.4999999999999742, -148.0000000000006, -34.59999999999976, 4.700000000000002, 20.000000000000014, -36.69999999999978, 13.699999999999964, -591.6, -28.299999999999876, 20.000000000000014, 20.000000000000014, -217.3000000000005, -9.399999999999968, -9.399999999999855, 22.100000000000048, -47.19999999999979, -856.0, -322.29999999999933, 20.000000000000014, -59.20000000000056, -6.6999999999999496, -309.69999999999965, 76.39999999999947, -76.60000000000088, -42.99999999999976, 11.599999999999964, -60.70000000000032, -200.50000000000048, 20.000000000000014, 27.500000000000146, 15.799999999999963, 1.0999999999999772, -112.30000000000078, 20.000000000000014, 11.599999999999964, -263.499999999999, 156.79999999999984, 1.0999999999999865, -10.599999999999865, -101.20000000000002, -14.199999999999909, 17.899999999999988, -7.299999999999891, 20.000000000000014, 86.60000000000011, -263.50000000000034, 61.40000000000018, 20.000000000000014, -188.20000000000056, -47.19999999999979, -89.20000000000084, 20.900000000000183, 10.099999999999994, -19.599999999999866, -21.999999999999744, 0.7999999999999652, 3.1999999999999615, -172.30000000000038, 11.599999999999964, -266.99999999999926, -220.2000000000004, 20.000000000000014, -26.199999999999847, -269.79999999999995, 26.300000000000118, -2.800000000000015, 26.600000000000136, 28.700000000000223, 1.0999999999999865, 26.30000000000008, 15.799999999999963], "policy_predator_policy_reward": [152.0, 150.0, 164.0, 7.0, 133.0, 0.0, 124.0, 130.0, 121.0, 129.0, 52.0, 167.0, 17.0, 60.0, 34.0, 4.0, 94.0, 163.0, 140.0, 143.0, 172.0, 153.0, 192.0, 183.0, 25.0, 173.0, 112.0, 160.0, 75.0, 19.0, 15.0, 22.0, 16.0, 14.0, 172.0, 181.0, 64.0, 164.0, 39.0, 149.0, 19.0, 4.0, 144.0, 79.0, 34.0, 1.0, 24.0, 148.0, 252.0, 203.0, 16.0, 9.0, 11.0, 12.0, 27.0, 15.0, 153.0, 159.0, 14.0, 5.0, 66.0, 12.0, 147.0, 95.0, 7.0, 37.0, 22.0, 19.0, 111.0, 107.0, 127.0, 10.0, 5.0, 3.0, 168.0, 6.0, 31.0, 36.0, 3.0, 128.0, 4.0, 2.0, 0.0, 132.0, 37.0, 30.0, 101.0, 97.0, 420.0, 0.0, 6.0, 5.0, 151.0, 229.0, 21.0, 92.0, 29.0, 748.0, 3.0, 2.0, 45.0, 32.0, 3.0, 5.0, 46.0, 41.0, 494.0, 41.0, 377.0, 148.0, 0.0, 117.0, 10.0, 9.0, 161.0, 12.0, 111.0, 172.0, 5.0, 17.0, 54.0, 9.0, 3.0, 1.0, 86.0, 89.0, 25.0, 124.0, 16.0, 15.0, 13.0, 86.0, 22.0, 24.0, 16.0, 31.0, 14.0, 421.0, 0.0, 0.0, 113.0, 3.0, 8.0, 14.0, 25.0, 713.0, 43.0, 163.0, 37.0, 38.0, 16.0, 157.0, 16.0, 46.0, 9.0, 44.0, 80.0, 95.0, 8.0, 2.0, 6.0, 66.0, 4.0, 0.0, 5.0, 135.0, 24.0, 22.0, 13.0, 76.0, 13.0, 1.0, 15.0, 14.0, 134.0, 2.0, 88.0, 17.0, 32.0, 50.0, 15.0, 23.0, 48.0, 54.0, 19.0, 8.0, 63.0, 98.0, 218.0, 1.0, 0.0, 22.0, 138.0, 3.0, 37.0, 2.0, 9.0, 10.0, 1.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6102860526357194, "mean_inference_ms": 1.89157482681022, "mean_action_processing_ms": 0.26759086247641783, "mean_env_wait_ms": 0.20560267460699122, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003878474235534668, "StateBufferConnector_ms": 0.0031223297119140625, "ViewRequirementAgentConnector_ms": 0.09587883949279785}, "num_episodes": 23, "episode_return_max": 140.59999999999866, "episode_return_min": -413.7999999999994, "episode_return_mean": -38.62400000000014, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1024000, "num_agent_steps_trained": 1024000, "num_env_steps_sampled": 256000, "num_env_steps_trained": 256000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 372.4804002391019, "num_env_steps_trained_throughput_per_sec": 372.4804002391019, "timesteps_total": 256000, "num_env_steps_sampled_lifetime": 256000, "num_agent_steps_sampled_lifetime": 1024000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1024000, "timers": {"training_iteration_time_ms": 10748.793, "restore_workers_time_ms": 0.014, "training_step_time_ms": 10748.752, "sample_time_ms": 1253.279, "learn_time_ms": 9481.179, "learn_throughput": 421.888, "synch_weights_time_ms": 12.97}, "counters": {"num_env_steps_sampled": 256000, "num_env_steps_trained": 256000, "num_agent_steps_sampled": 1024000, "num_agent_steps_trained": 1024000}, "done": false, "training_iteration": 64, "trial_id": "3dae5_00000", "date": "2024-08-14_09-18-36", "timestamp": 1723641516, "time_this_iter_s": 10.752429008483887, "time_total_s": 2336.5154271125793, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3636e50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2336.5154271125793, "iterations_since_restore": 64, "perf": {"cpu_util_percent": 29.712500000000002, "ram_util_percent": 83.6375}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.584752413204738, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.64292792151214, "policy_loss": -0.004713450284630415, "vf_loss": 4.647188189042308, "vf_explained_var": 0.15372717503517394, "kl": 0.004028166358396277, "entropy": 0.9997307258938987, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 121905.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.320770972525632, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.187331245311354, "policy_loss": -0.01290246508843093, "vf_loss": 6.197995707345387, "vf_explained_var": 0.06367845979947892, "kl": 0.014919904798050224, "entropy": 1.3565098614289017, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 121905.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 260000, "num_env_steps_trained": 260000, "num_agent_steps_sampled": 1040000, "num_agent_steps_trained": 1040000}, "env_runners": {"episode_reward_max": 196.99999999999952, "episode_reward_min": -413.7999999999994, "episode_reward_mean": -14.793000000000145, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -856.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 156.79999999999984, "predator_policy": 748.0}, "policy_reward_mean": {"prey_policy": -70.84150000000005, "predator_policy": 63.445}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-202.70000000000022, -163.20000000000093, 58.20000000000039, -61.8999999999998, 75.59999999999962, -365.4999999999996, -182.5, 72.49999999999977, 14.700000000000022, -4.099999999999703, 9.400000000000164, 69.50000000000003, -25.099999999999618, -41.399999999999714, 80.0999999999994, 48.00000000000046, -121.20000000000113, 0.9000000000000258, 29.100000000000126, -138.00000000000037, 78.79999999999976, -97.80000000000084, 121.29999999999848, 0.09999999999998854, 29.600000000000158, 34.90000000000007, -127.7000000000003, 32.10000000000018, -40.49999999999982, -82.50000000000114, -382.20000000000016, 69.60000000000008, 0.6000000000002, 33.3000000000002, 33.7000000000002, -413.7999999999994, -12.100000000000012, -210.5000000000004, 140.59999999999866, -297.4000000000001, -37.899999999999835, 21.2, -28.09999999999959, 87.19999999999881, 23.90000000000007, -169.5000000000012, 41.90000000000033, -83.60000000000146, 70.69999999999985, 24.000000000000053, -184.9000000000003, 40.0000000000003, -110.7000000000011, 34.70000000000022, -165.2000000000006, -96.30000000000052, 9.100000000000028, -60.29999999999984, -57.60000000000133, 3.9000000000000674, -5.499999999999922, 53.300000000000466, -39.19999999999954, 35.600000000000236, 33.30000000000009, 36.50000000000025, -26.399999999999984, 24.60000000000005, 135.59999999999965, -66.09999999999992, -63.200000000001125, -54.400000000001015, 68.99999999999979, 60.400000000000325, 31.000000000000195, 0.30000000000011123, -268.19999999999817, 15.799999999999939, -102.50000000000063, 62.80000000000034, 48.80000000000046, 45.10000000000034, 169.89999999999978, -23.8999999999998, 116.69999999999868, 72.49999999999987, -148.30000000000078, -87.20000000000007, 104.89999999999964, 32.000000000000185, 154.20000000000002, 25.500000000000068, 125.79999999999907, 145.89999999999864, 112.2999999999995, 196.99999999999952, -18.19999999999999, 84.6, 33.10000000000019, -27.699999999999584], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-144.40000000000015, -286.3, -58.30000000000043, -292.9000000000001, 15.199999999999962, 20.000000000000014, 20.000000000000014, -304.90000000000003, 91.99999999999952, -51.39999999999988, -261.4, -276.0999999999999, -438.40000000000003, -199.09999999999997, 20.000000000000014, 27.500000000000163, -3.099999999999958, -5.1999999999999265, -36.699999999999754, -9.399999999999855, 36.500000000000234, -339.0999999999999, -9.399999999999862, 59.9000000000002, -77.80000000000086, -25.299999999999834, 20.000000000000014, -303.4000000000002, 16.099999999999866, 20.000000000000014, 20.000000000000014, -12.999999999999842, -211.9000000000004, -127.30000000000072, -246.70000000000024, 110.59999999999962, 11.599999999999964, 9.499999999999964, -281.60000000000014, -30.39999999999978, -21.699999999999996, 33.50000000000021, 13.699999999999964, -242.50000000000034, 67.39999999999992, 47.900000000000226, -257.2000000000003, 125.29999999999998, 17.899999999999988, -55.30000000000019, 15.799999999999963, -178.90000000000023, 20.000000000000014, -567.7, 15.799999999999963, 5.299999999999965, 20.000000000000014, -440.5000000000001, -22.29999999999975, -173.2000000000005, -314.4999999999999, -844.6999999999999, 48.800000000000225, 15.799999999999963, -0.9999999999999846, -75.40000000000083, 9.499999999999964, 15.799999999999963, -64.9000000000008, 11.599999999999964, -342.7999999999996, -605.9999999999998, -557.0999999999999, 20.000000000000014, -164.80000000000018, -162.70000000000024, 69.49999999999976, 52.100000000000186, -210.10000000000016, -260.3000000000002, 37.10000000000025, -357.9999999999998, 9.499999999999964, -10.299999999999859, -84.70000000000081, -6.399999999999965, 21.800000000000047, 61.400000000000205, -166.90000000000023, 15.799999999999963, -229.30000000000032, -89.20000000000084, 7.399999999999965, 3.4999999999999742, -148.0000000000006, -34.59999999999976, 4.700000000000002, 20.000000000000014, -36.69999999999978, 13.699999999999964, -591.6, -28.299999999999876, 20.000000000000014, 20.000000000000014, -217.3000000000005, -9.399999999999968, -9.399999999999855, 22.100000000000048, -47.19999999999979, -856.0, -322.29999999999933, 20.000000000000014, -59.20000000000056, -6.6999999999999496, -309.69999999999965, 76.39999999999947, -76.60000000000088, -42.99999999999976, 11.599999999999964, -60.70000000000032, -200.50000000000048, 20.000000000000014, 27.500000000000146, 15.799999999999963, 1.0999999999999772, -112.30000000000078, 20.000000000000014, 11.599999999999964, -263.499999999999, 156.79999999999984, 1.0999999999999865, -10.599999999999865, -101.20000000000002, -14.199999999999909, 17.899999999999988, -7.299999999999891, 20.000000000000014, 86.60000000000011, -263.50000000000034, 61.40000000000018, 20.000000000000014, -188.20000000000056, -47.19999999999979, -89.20000000000084, 20.900000000000183, 10.099999999999994, -19.599999999999866, -21.999999999999744, 0.7999999999999652, 3.1999999999999615, -172.30000000000038, 11.599999999999964, -266.99999999999926, -220.2000000000004, 20.000000000000014, -26.199999999999847, -269.79999999999995, 26.300000000000118, -2.800000000000015, 26.600000000000136, 28.700000000000223, 1.0999999999999865, 26.30000000000008, 15.799999999999963, 29.29999999999996, 128.6, -26.199999999999747, -87.6999999999999, 32.60000000000009, 43.10000000000023, 55.10000000000023, 7.399999999999965, -45.40000000000043, -266.899999999999, -1.9000000000000177, -295.3000000000003, 20.000000000000014, 29.900000000000027, 20.900000000000027, -40.89999999999976, 104.59999999999997, -84.40000000000049, 3.1999999999999633, 5.299999999999965, 59.89999999999996, 29.900000000000023, 40.40000000000019, 87.49999999999976, -59.80000000000007, 88.09999999999965, 91.69999999999993, -191.70000000000033, 105.2000000000001, -261.39999999999947, -44.49999999999984, 64.1, -114.40000000000076, 24.500000000000092, 1.0999999999999865, -164.80000000000038], "policy_predator_policy_reward": [64.0, 164.0, 39.0, 149.0, 19.0, 4.0, 144.0, 79.0, 34.0, 1.0, 24.0, 148.0, 252.0, 203.0, 16.0, 9.0, 11.0, 12.0, 27.0, 15.0, 153.0, 159.0, 14.0, 5.0, 66.0, 12.0, 147.0, 95.0, 7.0, 37.0, 22.0, 19.0, 111.0, 107.0, 127.0, 10.0, 5.0, 3.0, 168.0, 6.0, 31.0, 36.0, 3.0, 128.0, 4.0, 2.0, 0.0, 132.0, 37.0, 30.0, 101.0, 97.0, 420.0, 0.0, 6.0, 5.0, 151.0, 229.0, 21.0, 92.0, 29.0, 748.0, 3.0, 2.0, 45.0, 32.0, 3.0, 5.0, 46.0, 41.0, 494.0, 41.0, 377.0, 148.0, 0.0, 117.0, 10.0, 9.0, 161.0, 12.0, 111.0, 172.0, 5.0, 17.0, 54.0, 9.0, 3.0, 1.0, 86.0, 89.0, 25.0, 124.0, 16.0, 15.0, 13.0, 86.0, 22.0, 24.0, 16.0, 31.0, 14.0, 421.0, 0.0, 0.0, 113.0, 3.0, 8.0, 14.0, 25.0, 713.0, 43.0, 163.0, 37.0, 38.0, 16.0, 157.0, 16.0, 46.0, 9.0, 44.0, 80.0, 95.0, 8.0, 2.0, 6.0, 66.0, 4.0, 0.0, 5.0, 135.0, 24.0, 22.0, 13.0, 76.0, 13.0, 1.0, 15.0, 14.0, 134.0, 2.0, 88.0, 17.0, 32.0, 50.0, 15.0, 23.0, 48.0, 54.0, 19.0, 8.0, 63.0, 98.0, 218.0, 1.0, 0.0, 22.0, 138.0, 3.0, 37.0, 2.0, 9.0, 10.0, 1.0, 2.0, 8.0, 4.0, 67.0, 23.0, 24.0, 17.0, 6.0, 4.0, 152.0, 12.0, 95.0, 115.0, 45.0, 10.0, 26.0, 26.0, 65.0, 69.0, 4.0, 13.0, 23.0, 13.0, 5.0, 13.0, 64.0, 20.0, 158.0, 139.0, 134.0, 4.0, 43.0, 22.0, 61.0, 62.0, 77.0, 59.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6093577884018098, "mean_inference_ms": 1.8898932742792496, "mean_action_processing_ms": 0.26641824241198814, "mean_env_wait_ms": 0.205053117278988, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003785848617553711, "StateBufferConnector_ms": 0.00311279296875, "ViewRequirementAgentConnector_ms": 0.09463155269622803}, "num_episodes": 18, "episode_return_max": 196.99999999999952, "episode_return_min": -413.7999999999994, "episode_return_mean": -14.793000000000145, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1040000, "num_agent_steps_trained": 1040000, "num_env_steps_sampled": 260000, "num_env_steps_trained": 260000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 380.7699078853716, "num_env_steps_trained_throughput_per_sec": 380.7699078853716, "timesteps_total": 260000, "num_env_steps_sampled_lifetime": 260000, "num_agent_steps_sampled_lifetime": 1040000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1040000, "timers": {"training_iteration_time_ms": 10738.698, "restore_workers_time_ms": 0.014, "training_step_time_ms": 10738.656, "sample_time_ms": 1258.685, "learn_time_ms": 9466.025, "learn_throughput": 422.564, "synch_weights_time_ms": 12.65}, "counters": {"num_env_steps_sampled": 260000, "num_env_steps_trained": 260000, "num_agent_steps_sampled": 1040000, "num_agent_steps_trained": 1040000}, "done": false, "training_iteration": 65, "trial_id": "3dae5_00000", "date": "2024-08-14_09-18-47", "timestamp": 1723641527, "time_this_iter_s": 10.511037826538086, "time_total_s": 2347.0264649391174, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b381b700>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2347.0264649391174, "iterations_since_restore": 65, "perf": {"cpu_util_percent": 28.621428571428574, "ram_util_percent": 83.60000000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.195486614060781, "cur_kl_coeff": 0.056250000000000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.54092256278588, "policy_loss": -0.003495983192302957, "vf_loss": 4.544046881842235, "vf_explained_var": 0.09050256691912495, "kl": 0.0066076684305244274, "entropy": 0.9925478234808282, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 123795.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.3866145266426932, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.958083499424041, "policy_loss": -0.008589292424188917, "vf_loss": 6.964530325440503, "vf_explained_var": 0.13169677169234664, "kl": 0.014283177503508262, "entropy": 1.2935759502743918, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 123795.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 264000, "num_env_steps_trained": 264000, "num_agent_steps_sampled": 1056000, "num_agent_steps_trained": 1056000}, "env_runners": {"episode_reward_max": 290.8000000000004, "episode_reward_min": -414.4999999999999, "episode_reward_mean": 14.664999999999832, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -856.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 191.6, "predator_policy": 748.0}, "policy_reward_mean": {"prey_policy": -51.01250000000004, "predator_policy": 58.345}, "custom_metrics": {}, "hist_stats": {"episode_reward": [29.100000000000126, -138.00000000000037, 78.79999999999976, -97.80000000000084, 121.29999999999848, 0.09999999999998854, 29.600000000000158, 34.90000000000007, -127.7000000000003, 32.10000000000018, -40.49999999999982, -82.50000000000114, -382.20000000000016, 69.60000000000008, 0.6000000000002, 33.3000000000002, 33.7000000000002, -413.7999999999994, -12.100000000000012, -210.5000000000004, 140.59999999999866, -297.4000000000001, -37.899999999999835, 21.2, -28.09999999999959, 87.19999999999881, 23.90000000000007, -169.5000000000012, 41.90000000000033, -83.60000000000146, 70.69999999999985, 24.000000000000053, -184.9000000000003, 40.0000000000003, -110.7000000000011, 34.70000000000022, -165.2000000000006, -96.30000000000052, 9.100000000000028, -60.29999999999984, -57.60000000000133, 3.9000000000000674, -5.499999999999922, 53.300000000000466, -39.19999999999954, 35.600000000000236, 33.30000000000009, 36.50000000000025, -26.399999999999984, 24.60000000000005, 135.59999999999965, -66.09999999999992, -63.200000000001125, -54.400000000001015, 68.99999999999979, 60.400000000000325, 31.000000000000195, 0.30000000000011123, -268.19999999999817, 15.799999999999939, -102.50000000000063, 62.80000000000034, 48.80000000000046, 45.10000000000034, 169.89999999999978, -23.8999999999998, 116.69999999999868, 72.49999999999987, -148.30000000000078, -87.20000000000007, 104.89999999999964, 32.000000000000185, 154.20000000000002, 25.500000000000068, 125.79999999999907, 145.89999999999864, 112.2999999999995, 196.99999999999952, -18.19999999999999, 84.6, 33.10000000000019, -27.699999999999584, 263.8999999999995, 172.09999999999937, 115.70000000000014, -414.4999999999999, -18.39999999999999, 220.29999999999984, 157.1999999999995, 35.600000000000236, 94.70000000000013, 290.8000000000004, -34.700000000000365, 208.09999999999928, 199.39999999999958, 183.8999999999996, 179.9999999999994, 273.0000000000003, 152.2999999999996, 127.69999999999972], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [11.599999999999964, 9.499999999999964, -281.60000000000014, -30.39999999999978, -21.699999999999996, 33.50000000000021, 13.699999999999964, -242.50000000000034, 67.39999999999992, 47.900000000000226, -257.2000000000003, 125.29999999999998, 17.899999999999988, -55.30000000000019, 15.799999999999963, -178.90000000000023, 20.000000000000014, -567.7, 15.799999999999963, 5.299999999999965, 20.000000000000014, -440.5000000000001, -22.29999999999975, -173.2000000000005, -314.4999999999999, -844.6999999999999, 48.800000000000225, 15.799999999999963, -0.9999999999999846, -75.40000000000083, 9.499999999999964, 15.799999999999963, -64.9000000000008, 11.599999999999964, -342.7999999999996, -605.9999999999998, -557.0999999999999, 20.000000000000014, -164.80000000000018, -162.70000000000024, 69.49999999999976, 52.100000000000186, -210.10000000000016, -260.3000000000002, 37.10000000000025, -357.9999999999998, 9.499999999999964, -10.299999999999859, -84.70000000000081, -6.399999999999965, 21.800000000000047, 61.400000000000205, -166.90000000000023, 15.799999999999963, -229.30000000000032, -89.20000000000084, 7.399999999999965, 3.4999999999999742, -148.0000000000006, -34.59999999999976, 4.700000000000002, 20.000000000000014, -36.69999999999978, 13.699999999999964, -591.6, -28.299999999999876, 20.000000000000014, 20.000000000000014, -217.3000000000005, -9.399999999999968, -9.399999999999855, 22.100000000000048, -47.19999999999979, -856.0, -322.29999999999933, 20.000000000000014, -59.20000000000056, -6.6999999999999496, -309.69999999999965, 76.39999999999947, -76.60000000000088, -42.99999999999976, 11.599999999999964, -60.70000000000032, -200.50000000000048, 20.000000000000014, 27.500000000000146, 15.799999999999963, 1.0999999999999772, -112.30000000000078, 20.000000000000014, 11.599999999999964, -263.499999999999, 156.79999999999984, 1.0999999999999865, -10.599999999999865, -101.20000000000002, -14.199999999999909, 17.899999999999988, -7.299999999999891, 20.000000000000014, 86.60000000000011, -263.50000000000034, 61.40000000000018, 20.000000000000014, -188.20000000000056, -47.19999999999979, -89.20000000000084, 20.900000000000183, 10.099999999999994, -19.599999999999866, -21.999999999999744, 0.7999999999999652, 3.1999999999999615, -172.30000000000038, 11.599999999999964, -266.99999999999926, -220.2000000000004, 20.000000000000014, -26.199999999999847, -269.79999999999995, 26.300000000000118, -2.800000000000015, 26.600000000000136, 28.700000000000223, 1.0999999999999865, 26.30000000000008, 15.799999999999963, 29.29999999999996, 128.6, -26.199999999999747, -87.6999999999999, 32.60000000000009, 43.10000000000023, 55.10000000000023, 7.399999999999965, -45.40000000000043, -266.899999999999, -1.9000000000000177, -295.3000000000003, 20.000000000000014, 29.900000000000027, 20.900000000000027, -40.89999999999976, 104.59999999999997, -84.40000000000049, 3.1999999999999633, 5.299999999999965, 59.89999999999996, 29.900000000000023, 40.40000000000019, 87.49999999999976, -59.80000000000007, 88.09999999999965, 91.69999999999993, -191.70000000000033, 105.2000000000001, -261.39999999999947, -44.49999999999984, 64.1, -114.40000000000076, 24.500000000000092, 1.0999999999999865, -164.80000000000038, 94.39999999999941, 156.50000000000003, 130.39999999999972, -4.299999999999901, -53.50000000000054, 102.20000000000002, -381.09999999999997, -348.3999999999999, 9.499999999999964, -310.9, -9.100000000000044, 121.39999999999988, 54.500000000000156, 55.70000000000007, 17.899999999999988, 13.699999999999964, -5.199999999999939, 50.900000000000105, 106.69999999999987, 160.09999999999988, -118.9, -59.80000000000061, -53.50000000000019, 191.6, 169.70000000000002, -64.30000000000004, 75.80000000000001, 40.10000000000009, 144.2, 15.799999999999963, 137.0, 112.9999999999998, 32.6, 52.700000000000124, 20.000000000000014, 64.7], "policy_predator_policy_reward": [5.0, 3.0, 168.0, 6.0, 31.0, 36.0, 3.0, 128.0, 4.0, 2.0, 0.0, 132.0, 37.0, 30.0, 101.0, 97.0, 420.0, 0.0, 6.0, 5.0, 151.0, 229.0, 21.0, 92.0, 29.0, 748.0, 3.0, 2.0, 45.0, 32.0, 3.0, 5.0, 46.0, 41.0, 494.0, 41.0, 377.0, 148.0, 0.0, 117.0, 10.0, 9.0, 161.0, 12.0, 111.0, 172.0, 5.0, 17.0, 54.0, 9.0, 3.0, 1.0, 86.0, 89.0, 25.0, 124.0, 16.0, 15.0, 13.0, 86.0, 22.0, 24.0, 16.0, 31.0, 14.0, 421.0, 0.0, 0.0, 113.0, 3.0, 8.0, 14.0, 25.0, 713.0, 43.0, 163.0, 37.0, 38.0, 16.0, 157.0, 16.0, 46.0, 9.0, 44.0, 80.0, 95.0, 8.0, 2.0, 6.0, 66.0, 4.0, 0.0, 5.0, 135.0, 24.0, 22.0, 13.0, 76.0, 13.0, 1.0, 15.0, 14.0, 134.0, 2.0, 88.0, 17.0, 32.0, 50.0, 15.0, 23.0, 48.0, 54.0, 19.0, 8.0, 63.0, 98.0, 218.0, 1.0, 0.0, 22.0, 138.0, 3.0, 37.0, 2.0, 9.0, 10.0, 1.0, 2.0, 8.0, 4.0, 67.0, 23.0, 24.0, 17.0, 6.0, 4.0, 152.0, 12.0, 95.0, 115.0, 45.0, 10.0, 26.0, 26.0, 65.0, 69.0, 4.0, 13.0, 23.0, 13.0, 5.0, 13.0, 64.0, 20.0, 158.0, 139.0, 134.0, 4.0, 43.0, 22.0, 61.0, 62.0, 77.0, 59.0, 11.0, 2.0, 1.0, 45.0, 11.0, 56.0, 220.0, 95.0, 137.0, 146.0, 49.0, 59.0, 38.0, 9.0, 3.0, 1.0, 3.0, 46.0, 24.0, 0.0, 106.0, 38.0, 35.0, 35.0, 52.0, 42.0, 43.0, 25.0, 8.0, 12.0, 10.0, 13.0, 29.0, 38.0, 37.0, 6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6085323500661092, "mean_inference_ms": 1.8868193034265834, "mean_action_processing_ms": 0.2658375808628473, "mean_env_wait_ms": 0.20463563393378897, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0037844181060791016, "StateBufferConnector_ms": 0.0031042098999023438, "ViewRequirementAgentConnector_ms": 0.09431946277618408}, "num_episodes": 18, "episode_return_max": 290.8000000000004, "episode_return_min": -414.4999999999999, "episode_return_mean": 14.664999999999832, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1056000, "num_agent_steps_trained": 1056000, "num_env_steps_sampled": 264000, "num_env_steps_trained": 264000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 375.1597404778642, "num_env_steps_trained_throughput_per_sec": 375.1597404778642, "timesteps_total": 264000, "num_env_steps_sampled_lifetime": 264000, "num_agent_steps_sampled_lifetime": 1056000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1056000, "timers": {"training_iteration_time_ms": 10706.286, "restore_workers_time_ms": 0.014, "training_step_time_ms": 10706.244, "sample_time_ms": 1250.612, "learn_time_ms": 9441.916, "learn_throughput": 423.643, "synch_weights_time_ms": 12.406}, "counters": {"num_env_steps_sampled": 264000, "num_env_steps_trained": 264000, "num_agent_steps_sampled": 1056000, "num_agent_steps_trained": 1056000}, "done": false, "training_iteration": 66, "trial_id": "3dae5_00000", "date": "2024-08-14_09-18-58", "timestamp": 1723641538, "time_this_iter_s": 10.699690103530884, "time_total_s": 2357.7261550426483, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3680160>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2357.7261550426483, "iterations_since_restore": 66, "perf": {"cpu_util_percent": 28.98125, "ram_util_percent": 83.4375}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.757881850603396, "cur_kl_coeff": 0.056250000000000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.089264406413628, "policy_loss": -0.0035848596189959497, "vf_loss": 3.09209619823587, "vf_explained_var": 0.07729284845331989, "kl": 0.013388107907108272, "entropy": 1.0383033551551677, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 125685.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.2773771036554264, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.80441239094608, "policy_loss": -0.005585624543437488, "vf_loss": 6.807934445426578, "vf_explained_var": 0.3289351855005537, "kl": 0.013757197246538958, "entropy": 1.363231412506608, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 125685.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 268000, "num_env_steps_trained": 268000, "num_agent_steps_sampled": 1072000, "num_agent_steps_trained": 1072000}, "env_runners": {"episode_reward_max": 306.09999999999997, "episode_reward_min": -414.4999999999999, "episode_reward_mean": 60.503999999999806, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -856.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 191.6, "predator_policy": 713.0}, "policy_reward_mean": {"prey_policy": -13.063000000000038, "predator_policy": 43.315}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-37.899999999999835, 21.2, -28.09999999999959, 87.19999999999881, 23.90000000000007, -169.5000000000012, 41.90000000000033, -83.60000000000146, 70.69999999999985, 24.000000000000053, -184.9000000000003, 40.0000000000003, -110.7000000000011, 34.70000000000022, -165.2000000000006, -96.30000000000052, 9.100000000000028, -60.29999999999984, -57.60000000000133, 3.9000000000000674, -5.499999999999922, 53.300000000000466, -39.19999999999954, 35.600000000000236, 33.30000000000009, 36.50000000000025, -26.399999999999984, 24.60000000000005, 135.59999999999965, -66.09999999999992, -63.200000000001125, -54.400000000001015, 68.99999999999979, 60.400000000000325, 31.000000000000195, 0.30000000000011123, -268.19999999999817, 15.799999999999939, -102.50000000000063, 62.80000000000034, 48.80000000000046, 45.10000000000034, 169.89999999999978, -23.8999999999998, 116.69999999999868, 72.49999999999987, -148.30000000000078, -87.20000000000007, 104.89999999999964, 32.000000000000185, 154.20000000000002, 25.500000000000068, 125.79999999999907, 145.89999999999864, 112.2999999999995, 196.99999999999952, -18.19999999999999, 84.6, 33.10000000000019, -27.699999999999584, 263.8999999999995, 172.09999999999937, 115.70000000000014, -414.4999999999999, -18.39999999999999, 220.29999999999984, 157.1999999999995, 35.600000000000236, 94.70000000000013, 290.8000000000004, -34.700000000000365, 208.09999999999928, 199.39999999999958, 183.8999999999996, 179.9999999999994, 273.0000000000003, 152.2999999999996, 127.69999999999972, 213.29999999999956, 172.79999999999924, 1.7000000000000388, 211.09999999999977, 234.00000000000006, 221.1, 131.8999999999999, 185.59999999999954, 164.6999999999995, 101.79999999999946, 159.0999999999992, 163.39999999999986, 183.29999999999924, 79.10000000000004, 29.500000000000156, -85.00000000000156, 227.19999999999973, 300.8999999999999, 107.99999999999972, 306.09999999999997, 121.19999999999959, 154.29999999999959], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [37.10000000000025, -357.9999999999998, 9.499999999999964, -10.299999999999859, -84.70000000000081, -6.399999999999965, 21.800000000000047, 61.400000000000205, -166.90000000000023, 15.799999999999963, -229.30000000000032, -89.20000000000084, 7.399999999999965, 3.4999999999999742, -148.0000000000006, -34.59999999999976, 4.700000000000002, 20.000000000000014, -36.69999999999978, 13.699999999999964, -591.6, -28.299999999999876, 20.000000000000014, 20.000000000000014, -217.3000000000005, -9.399999999999968, -9.399999999999855, 22.100000000000048, -47.19999999999979, -856.0, -322.29999999999933, 20.000000000000014, -59.20000000000056, -6.6999999999999496, -309.69999999999965, 76.39999999999947, -76.60000000000088, -42.99999999999976, 11.599999999999964, -60.70000000000032, -200.50000000000048, 20.000000000000014, 27.500000000000146, 15.799999999999963, 1.0999999999999772, -112.30000000000078, 20.000000000000014, 11.599999999999964, -263.499999999999, 156.79999999999984, 1.0999999999999865, -10.599999999999865, -101.20000000000002, -14.199999999999909, 17.899999999999988, -7.299999999999891, 20.000000000000014, 86.60000000000011, -263.50000000000034, 61.40000000000018, 20.000000000000014, -188.20000000000056, -47.19999999999979, -89.20000000000084, 20.900000000000183, 10.099999999999994, -19.599999999999866, -21.999999999999744, 0.7999999999999652, 3.1999999999999615, -172.30000000000038, 11.599999999999964, -266.99999999999926, -220.2000000000004, 20.000000000000014, -26.199999999999847, -269.79999999999995, 26.300000000000118, -2.800000000000015, 26.600000000000136, 28.700000000000223, 1.0999999999999865, 26.30000000000008, 15.799999999999963, 29.29999999999996, 128.6, -26.199999999999747, -87.6999999999999, 32.60000000000009, 43.10000000000023, 55.10000000000023, 7.399999999999965, -45.40000000000043, -266.899999999999, -1.9000000000000177, -295.3000000000003, 20.000000000000014, 29.900000000000027, 20.900000000000027, -40.89999999999976, 104.59999999999997, -84.40000000000049, 3.1999999999999633, 5.299999999999965, 59.89999999999996, 29.900000000000023, 40.40000000000019, 87.49999999999976, -59.80000000000007, 88.09999999999965, 91.69999999999993, -191.70000000000033, 105.2000000000001, -261.39999999999947, -44.49999999999984, 64.1, -114.40000000000076, 24.500000000000092, 1.0999999999999865, -164.80000000000038, 94.39999999999941, 156.50000000000003, 130.39999999999972, -4.299999999999901, -53.50000000000054, 102.20000000000002, -381.09999999999997, -348.3999999999999, 9.499999999999964, -310.9, -9.100000000000044, 121.39999999999988, 54.500000000000156, 55.70000000000007, 17.899999999999988, 13.699999999999964, -5.199999999999939, 50.900000000000105, 106.69999999999987, 160.09999999999988, -118.9, -59.80000000000061, -53.50000000000019, 191.6, 169.70000000000002, -64.30000000000004, 75.80000000000001, 40.10000000000009, 144.2, 15.799999999999963, 137.0, 112.9999999999998, 32.6, 52.700000000000124, 20.000000000000014, 64.7, 96.20000000000012, 88.09999999999975, 20.000000000000014, 129.79999999999987, 134.0, -301.30000000000007, 120.79999999999997, 77.29999999999971, 17.000000000000007, 167.0, 141.8, 8.300000000000011, 20.000000000000014, 98.90000000000003, -19.59999999999989, 141.2, 122.0, 13.699999999999964, 17.899999999999988, 44.900000000000084, 20.000000000000014, 127.0999999999998, 42.50000000000002, 35.900000000000006, 20.000000000000014, 146.29999999999993, 5.299999999999965, 12.799999999999997, 17.899999999999988, -72.40000000000089, -87.10000000000079, -61.900000000000595, 122.0, 78.1999999999997, 174.79999999999998, 58.10000000000002, 22.70000000000006, 44.300000000000004, 139.99999999999991, 142.1, 20.000000000000014, 69.20000000000002, 127.39999999999998, 17.899999999999988], "policy_predator_policy_reward": [111.0, 172.0, 5.0, 17.0, 54.0, 9.0, 3.0, 1.0, 86.0, 89.0, 25.0, 124.0, 16.0, 15.0, 13.0, 86.0, 22.0, 24.0, 16.0, 31.0, 14.0, 421.0, 0.0, 0.0, 113.0, 3.0, 8.0, 14.0, 25.0, 713.0, 43.0, 163.0, 37.0, 38.0, 16.0, 157.0, 16.0, 46.0, 9.0, 44.0, 80.0, 95.0, 8.0, 2.0, 6.0, 66.0, 4.0, 0.0, 5.0, 135.0, 24.0, 22.0, 13.0, 76.0, 13.0, 1.0, 15.0, 14.0, 134.0, 2.0, 88.0, 17.0, 32.0, 50.0, 15.0, 23.0, 48.0, 54.0, 19.0, 8.0, 63.0, 98.0, 218.0, 1.0, 0.0, 22.0, 138.0, 3.0, 37.0, 2.0, 9.0, 10.0, 1.0, 2.0, 8.0, 4.0, 67.0, 23.0, 24.0, 17.0, 6.0, 4.0, 152.0, 12.0, 95.0, 115.0, 45.0, 10.0, 26.0, 26.0, 65.0, 69.0, 4.0, 13.0, 23.0, 13.0, 5.0, 13.0, 64.0, 20.0, 158.0, 139.0, 134.0, 4.0, 43.0, 22.0, 61.0, 62.0, 77.0, 59.0, 11.0, 2.0, 1.0, 45.0, 11.0, 56.0, 220.0, 95.0, 137.0, 146.0, 49.0, 59.0, 38.0, 9.0, 3.0, 1.0, 3.0, 46.0, 24.0, 0.0, 106.0, 38.0, 35.0, 35.0, 52.0, 42.0, 43.0, 25.0, 8.0, 12.0, 10.0, 13.0, 29.0, 38.0, 37.0, 6.0, 4.0, 25.0, 10.0, 13.0, 147.0, 22.0, 6.0, 7.0, 41.0, 9.0, 57.0, 14.0, 6.0, 7.0, 32.0, 32.0, 3.0, 26.0, 30.0, 9.0, 4.0, 8.0, 29.0, 56.0, 6.0, 11.0, 7.0, 54.0, 41.0, 43.0, 59.0, 5.0, 26.0, 1.0, 30.0, 38.0, 36.0, 5.0, 19.0, 5.0, 19.0, 13.0, 5.0, 4.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6076219723413456, "mean_inference_ms": 1.883953087293774, "mean_action_processing_ms": 0.26452406973558285, "mean_env_wait_ms": 0.20437625140734642, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0037277936935424805, "StateBufferConnector_ms": 0.0031622648239135742, "ViewRequirementAgentConnector_ms": 0.09594511985778809}, "num_episodes": 22, "episode_return_max": 306.09999999999997, "episode_return_min": -414.4999999999999, "episode_return_mean": 60.503999999999806, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1072000, "num_agent_steps_trained": 1072000, "num_env_steps_sampled": 268000, "num_env_steps_trained": 268000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 369.9882911692075, "num_env_steps_trained_throughput_per_sec": 369.9882911692075, "timesteps_total": 268000, "num_env_steps_sampled_lifetime": 268000, "num_agent_steps_sampled_lifetime": 1072000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1072000, "timers": {"training_iteration_time_ms": 10729.834, "restore_workers_time_ms": 0.014, "training_step_time_ms": 10729.792, "sample_time_ms": 1255.946, "learn_time_ms": 9459.933, "learn_throughput": 422.836, "synch_weights_time_ms": 12.604}, "counters": {"num_env_steps_sampled": 268000, "num_env_steps_trained": 268000, "num_agent_steps_sampled": 1072000, "num_agent_steps_trained": 1072000}, "done": false, "training_iteration": 67, "trial_id": "3dae5_00000", "date": "2024-08-14_09-19-09", "timestamp": 1723641549, "time_this_iter_s": 10.816381931304932, "time_total_s": 2368.5425369739532, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3636dc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2368.5425369739532, "iterations_since_restore": 67, "perf": {"cpu_util_percent": 28.700000000000006, "ram_util_percent": 83.45333333333333}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.775078241913407, "cur_kl_coeff": 0.056250000000000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.3313409302600476, "policy_loss": -0.006512308998338917, "vf_loss": 2.3371507616900895, "vf_explained_var": 0.027538858456586403, "kl": 0.012488564988196654, "entropy": 0.9677934360251855, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 127575.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.305673309671816, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.798538205232569, "policy_loss": -0.008066010352214256, "vf_loss": 7.804740358282019, "vf_explained_var": 0.3706552365469554, "kl": 0.01242581364138361, "entropy": 1.378126891454061, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 127575.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 272000, "num_env_steps_trained": 272000, "num_agent_steps_sampled": 1088000, "num_agent_steps_trained": 1088000}, "env_runners": {"episode_reward_max": 360.10000000000025, "episode_reward_min": -414.4999999999999, "episode_reward_mean": 112.46299999999981, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -381.09999999999997, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 191.6, "predator_policy": 220.0}, "policy_reward_mean": {"prey_policy": 24.211499999999955, "predator_policy": 32.02}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-57.60000000000133, 3.9000000000000674, -5.499999999999922, 53.300000000000466, -39.19999999999954, 35.600000000000236, 33.30000000000009, 36.50000000000025, -26.399999999999984, 24.60000000000005, 135.59999999999965, -66.09999999999992, -63.200000000001125, -54.400000000001015, 68.99999999999979, 60.400000000000325, 31.000000000000195, 0.30000000000011123, -268.19999999999817, 15.799999999999939, -102.50000000000063, 62.80000000000034, 48.80000000000046, 45.10000000000034, 169.89999999999978, -23.8999999999998, 116.69999999999868, 72.49999999999987, -148.30000000000078, -87.20000000000007, 104.89999999999964, 32.000000000000185, 154.20000000000002, 25.500000000000068, 125.79999999999907, 145.89999999999864, 112.2999999999995, 196.99999999999952, -18.19999999999999, 84.6, 33.10000000000019, -27.699999999999584, 263.8999999999995, 172.09999999999937, 115.70000000000014, -414.4999999999999, -18.39999999999999, 220.29999999999984, 157.1999999999995, 35.600000000000236, 94.70000000000013, 290.8000000000004, -34.700000000000365, 208.09999999999928, 199.39999999999958, 183.8999999999996, 179.9999999999994, 273.0000000000003, 152.2999999999996, 127.69999999999972, 213.29999999999956, 172.79999999999924, 1.7000000000000388, 211.09999999999977, 234.00000000000006, 221.1, 131.8999999999999, 185.59999999999954, 164.6999999999995, 101.79999999999946, 159.0999999999992, 163.39999999999986, 183.29999999999924, 79.10000000000004, 29.500000000000156, -85.00000000000156, 227.19999999999973, 300.8999999999999, 107.99999999999972, 306.09999999999997, 121.19999999999959, 154.29999999999959, 324.0999999999999, 183.5999999999993, 316.80000000000007, 318.5000000000004, 201.69999999999925, 189.19999999999942, 195.2999999999993, 245.69999999999993, 301.5, 329.4, 348.70000000000005, 202.69999999999933, 200.7999999999993, 75.60000000000005, 360.10000000000025, 327.6, 158.49999999999946, 332.3000000000001], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-76.60000000000088, -42.99999999999976, 11.599999999999964, -60.70000000000032, -200.50000000000048, 20.000000000000014, 27.500000000000146, 15.799999999999963, 1.0999999999999772, -112.30000000000078, 20.000000000000014, 11.599999999999964, -263.499999999999, 156.79999999999984, 1.0999999999999865, -10.599999999999865, -101.20000000000002, -14.199999999999909, 17.899999999999988, -7.299999999999891, 20.000000000000014, 86.60000000000011, -263.50000000000034, 61.40000000000018, 20.000000000000014, -188.20000000000056, -47.19999999999979, -89.20000000000084, 20.900000000000183, 10.099999999999994, -19.599999999999866, -21.999999999999744, 0.7999999999999652, 3.1999999999999615, -172.30000000000038, 11.599999999999964, -266.99999999999926, -220.2000000000004, 20.000000000000014, -26.199999999999847, -269.79999999999995, 26.300000000000118, -2.800000000000015, 26.600000000000136, 28.700000000000223, 1.0999999999999865, 26.30000000000008, 15.799999999999963, 29.29999999999996, 128.6, -26.199999999999747, -87.6999999999999, 32.60000000000009, 43.10000000000023, 55.10000000000023, 7.399999999999965, -45.40000000000043, -266.899999999999, -1.9000000000000177, -295.3000000000003, 20.000000000000014, 29.900000000000027, 20.900000000000027, -40.89999999999976, 104.59999999999997, -84.40000000000049, 3.1999999999999633, 5.299999999999965, 59.89999999999996, 29.900000000000023, 40.40000000000019, 87.49999999999976, -59.80000000000007, 88.09999999999965, 91.69999999999993, -191.70000000000033, 105.2000000000001, -261.39999999999947, -44.49999999999984, 64.1, -114.40000000000076, 24.500000000000092, 1.0999999999999865, -164.80000000000038, 94.39999999999941, 156.50000000000003, 130.39999999999972, -4.299999999999901, -53.50000000000054, 102.20000000000002, -381.09999999999997, -348.3999999999999, 9.499999999999964, -310.9, -9.100000000000044, 121.39999999999988, 54.500000000000156, 55.70000000000007, 17.899999999999988, 13.699999999999964, -5.199999999999939, 50.900000000000105, 106.69999999999987, 160.09999999999988, -118.9, -59.80000000000061, -53.50000000000019, 191.6, 169.70000000000002, -64.30000000000004, 75.80000000000001, 40.10000000000009, 144.2, 15.799999999999963, 137.0, 112.9999999999998, 32.6, 52.700000000000124, 20.000000000000014, 64.7, 96.20000000000012, 88.09999999999975, 20.000000000000014, 129.79999999999987, 134.0, -301.30000000000007, 120.79999999999997, 77.29999999999971, 17.000000000000007, 167.0, 141.8, 8.300000000000011, 20.000000000000014, 98.90000000000003, -19.59999999999989, 141.2, 122.0, 13.699999999999964, 17.899999999999988, 44.900000000000084, 20.000000000000014, 127.0999999999998, 42.50000000000002, 35.900000000000006, 20.000000000000014, 146.29999999999993, 5.299999999999965, 12.799999999999997, 17.899999999999988, -72.40000000000089, -87.10000000000079, -61.900000000000595, 122.0, 78.1999999999997, 174.79999999999998, 58.10000000000002, 22.70000000000006, 44.300000000000004, 139.99999999999991, 142.1, 20.000000000000014, 69.20000000000002, 127.39999999999998, 17.899999999999988, 145.9999999999998, 163.1, 158.89999999999992, 13.699999999999966, 146.29999999999998, 150.5, 176.59999999999997, 116.89999999999992, 175.69999999999996, 20.000000000000014, 171.2, -0.9999999999999846, 7.399999999999965, 176.89999999999998, 127.69999999999999, 50.000000000000014, 161.0, 120.50000000000004, 145.39999999999998, 146.0, 147.49999999999997, 174.2, 179.0, 13.699999999999964, 17.899999999999988, 179.89999999999998, 134.6, -148.00000000000063, 182.29999999999998, 156.79999999999995, 151.39999999999998, 156.2, 140.89999999999998, 11.599999999999964, 173.0, 143.29999999999998], "policy_predator_policy_reward": [16.0, 46.0, 9.0, 44.0, 80.0, 95.0, 8.0, 2.0, 6.0, 66.0, 4.0, 0.0, 5.0, 135.0, 24.0, 22.0, 13.0, 76.0, 13.0, 1.0, 15.0, 14.0, 134.0, 2.0, 88.0, 17.0, 32.0, 50.0, 15.0, 23.0, 48.0, 54.0, 19.0, 8.0, 63.0, 98.0, 218.0, 1.0, 0.0, 22.0, 138.0, 3.0, 37.0, 2.0, 9.0, 10.0, 1.0, 2.0, 8.0, 4.0, 67.0, 23.0, 24.0, 17.0, 6.0, 4.0, 152.0, 12.0, 95.0, 115.0, 45.0, 10.0, 26.0, 26.0, 65.0, 69.0, 4.0, 13.0, 23.0, 13.0, 5.0, 13.0, 64.0, 20.0, 158.0, 139.0, 134.0, 4.0, 43.0, 22.0, 61.0, 62.0, 77.0, 59.0, 11.0, 2.0, 1.0, 45.0, 11.0, 56.0, 220.0, 95.0, 137.0, 146.0, 49.0, 59.0, 38.0, 9.0, 3.0, 1.0, 3.0, 46.0, 24.0, 0.0, 106.0, 38.0, 35.0, 35.0, 52.0, 42.0, 43.0, 25.0, 8.0, 12.0, 10.0, 13.0, 29.0, 38.0, 37.0, 6.0, 4.0, 25.0, 10.0, 13.0, 147.0, 22.0, 6.0, 7.0, 41.0, 9.0, 57.0, 14.0, 6.0, 7.0, 32.0, 32.0, 3.0, 26.0, 30.0, 9.0, 4.0, 8.0, 29.0, 56.0, 6.0, 11.0, 7.0, 54.0, 41.0, 43.0, 59.0, 5.0, 26.0, 1.0, 30.0, 38.0, 36.0, 5.0, 19.0, 5.0, 19.0, 13.0, 5.0, 4.0, 3.0, 12.0, 8.0, 3.0, 13.0, 7.0, 6.0, 19.0, 5.0, 1.0, 10.0, 9.0, 5.0, 6.0, 48.0, 20.0, 10.0, 10.0, 14.0, 24.0, 14.0, 13.0, 7.0, 3.0, 2.0, 1.0, 82.0, 7.0, 6.0, 15.0, 10.0, 10.0, 5.0, 1.0, 5.0, 11.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6070748408260057, "mean_inference_ms": 1.8812441394358574, "mean_action_processing_ms": 0.26470692903426063, "mean_env_wait_ms": 0.20391505347171557, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003779888153076172, "StateBufferConnector_ms": 0.0031409263610839844, "ViewRequirementAgentConnector_ms": 0.09405791759490967}, "num_episodes": 18, "episode_return_max": 360.10000000000025, "episode_return_min": -414.4999999999999, "episode_return_mean": 112.46299999999981, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1088000, "num_agent_steps_trained": 1088000, "num_env_steps_sampled": 272000, "num_env_steps_trained": 272000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 380.44939345555196, "num_env_steps_trained_throughput_per_sec": 380.44939345555196, "timesteps_total": 272000, "num_env_steps_sampled_lifetime": 272000, "num_agent_steps_sampled_lifetime": 1088000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1088000, "timers": {"training_iteration_time_ms": 10671.392, "restore_workers_time_ms": 0.014, "training_step_time_ms": 10671.352, "sample_time_ms": 1251.268, "learn_time_ms": 9406.223, "learn_throughput": 425.25, "synch_weights_time_ms": 12.688}, "counters": {"num_env_steps_sampled": 272000, "num_env_steps_trained": 272000, "num_agent_steps_sampled": 1088000, "num_agent_steps_trained": 1088000}, "done": false, "training_iteration": 68, "trial_id": "3dae5_00000", "date": "2024-08-14_09-19-19", "timestamp": 1723641559, "time_this_iter_s": 10.521140813827515, "time_total_s": 2379.0636777877808, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3636f70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2379.0636777877808, "iterations_since_restore": 68, "perf": {"cpu_util_percent": 27.306666666666665, "ram_util_percent": 83.47333333333334}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.138890462956101, "cur_kl_coeff": 0.056250000000000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.0709686776948355, "policy_loss": -0.004166960056560735, "vf_loss": 2.0746626463516677, "vf_explained_var": 0.005186117515362129, "kl": 0.008408857584748738, "entropy": 0.9525212370529377, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 129465.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.7072162190442364, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.197738436290196, "policy_loss": -0.010295433951812802, "vf_loss": 7.2051137404467065, "vf_explained_var": 0.48693981716241785, "kl": 0.01946743278562142, "entropy": 1.3986425939060392, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 129465.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 276000, "num_env_steps_trained": 276000, "num_agent_steps_sampled": 1104000, "num_agent_steps_trained": 1104000}, "env_runners": {"episode_reward_max": 377.9, "episode_reward_min": -414.4999999999999, "episode_reward_mean": 169.82399999999978, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -381.09999999999997, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 194.59999999999997, "predator_policy": 220.0}, "policy_reward_mean": {"prey_policy": 56.13199999999997, "predator_policy": 28.78}, "custom_metrics": {}, "hist_stats": {"episode_reward": [45.10000000000034, 169.89999999999978, -23.8999999999998, 116.69999999999868, 72.49999999999987, -148.30000000000078, -87.20000000000007, 104.89999999999964, 32.000000000000185, 154.20000000000002, 25.500000000000068, 125.79999999999907, 145.89999999999864, 112.2999999999995, 196.99999999999952, -18.19999999999999, 84.6, 33.10000000000019, -27.699999999999584, 263.8999999999995, 172.09999999999937, 115.70000000000014, -414.4999999999999, -18.39999999999999, 220.29999999999984, 157.1999999999995, 35.600000000000236, 94.70000000000013, 290.8000000000004, -34.700000000000365, 208.09999999999928, 199.39999999999958, 183.8999999999996, 179.9999999999994, 273.0000000000003, 152.2999999999996, 127.69999999999972, 213.29999999999956, 172.79999999999924, 1.7000000000000388, 211.09999999999977, 234.00000000000006, 221.1, 131.8999999999999, 185.59999999999954, 164.6999999999995, 101.79999999999946, 159.0999999999992, 163.39999999999986, 183.29999999999924, 79.10000000000004, 29.500000000000156, -85.00000000000156, 227.19999999999973, 300.8999999999999, 107.99999999999972, 306.09999999999997, 121.19999999999959, 154.29999999999959, 324.0999999999999, 183.5999999999993, 316.80000000000007, 318.5000000000004, 201.69999999999925, 189.19999999999942, 195.2999999999993, 245.69999999999993, 301.5, 329.4, 348.70000000000005, 202.69999999999933, 200.7999999999993, 75.60000000000005, 360.10000000000025, 327.6, 158.49999999999946, 332.3000000000001, 179.29999999999941, 353.0, -57.29999999999993, 362.60000000000014, 187.49999999999935, 143.69999999999965, 109.9999999999999, 357.10000000000025, 275.5000000000001, 162.9999999999994, 313.20000000000005, 324.60000000000025, 177.39999999999944, 317.19999999999993, 274.0999999999999, 203.19999999999933, 377.9, 250.9, 174.2999999999995, 346.0, 346.9, 307.9, 175.89999999999947], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [26.30000000000008, 15.799999999999963, 29.29999999999996, 128.6, -26.199999999999747, -87.6999999999999, 32.60000000000009, 43.10000000000023, 55.10000000000023, 7.399999999999965, -45.40000000000043, -266.899999999999, -1.9000000000000177, -295.3000000000003, 20.000000000000014, 29.900000000000027, 20.900000000000027, -40.89999999999976, 104.59999999999997, -84.40000000000049, 3.1999999999999633, 5.299999999999965, 59.89999999999996, 29.900000000000023, 40.40000000000019, 87.49999999999976, -59.80000000000007, 88.09999999999965, 91.69999999999993, -191.70000000000033, 105.2000000000001, -261.39999999999947, -44.49999999999984, 64.1, -114.40000000000076, 24.500000000000092, 1.0999999999999865, -164.80000000000038, 94.39999999999941, 156.50000000000003, 130.39999999999972, -4.299999999999901, -53.50000000000054, 102.20000000000002, -381.09999999999997, -348.3999999999999, 9.499999999999964, -310.9, -9.100000000000044, 121.39999999999988, 54.500000000000156, 55.70000000000007, 17.899999999999988, 13.699999999999964, -5.199999999999939, 50.900000000000105, 106.69999999999987, 160.09999999999988, -118.9, -59.80000000000061, -53.50000000000019, 191.6, 169.70000000000002, -64.30000000000004, 75.80000000000001, 40.10000000000009, 144.2, 15.799999999999963, 137.0, 112.9999999999998, 32.6, 52.700000000000124, 20.000000000000014, 64.7, 96.20000000000012, 88.09999999999975, 20.000000000000014, 129.79999999999987, 134.0, -301.30000000000007, 120.79999999999997, 77.29999999999971, 17.000000000000007, 167.0, 141.8, 8.300000000000011, 20.000000000000014, 98.90000000000003, -19.59999999999989, 141.2, 122.0, 13.699999999999964, 17.899999999999988, 44.900000000000084, 20.000000000000014, 127.0999999999998, 42.50000000000002, 35.900000000000006, 20.000000000000014, 146.29999999999993, 5.299999999999965, 12.799999999999997, 17.899999999999988, -72.40000000000089, -87.10000000000079, -61.900000000000595, 122.0, 78.1999999999997, 174.79999999999998, 58.10000000000002, 22.70000000000006, 44.300000000000004, 139.99999999999991, 142.1, 20.000000000000014, 69.20000000000002, 127.39999999999998, 17.899999999999988, 145.9999999999998, 163.1, 158.89999999999992, 13.699999999999966, 146.29999999999998, 150.5, 176.59999999999997, 116.89999999999992, 175.69999999999996, 20.000000000000014, 171.2, -0.9999999999999846, 7.399999999999965, 176.89999999999998, 127.69999999999999, 50.000000000000014, 161.0, 120.50000000000004, 145.39999999999998, 146.0, 147.49999999999997, 174.2, 179.0, 13.699999999999964, 17.899999999999988, 179.89999999999998, 134.6, -148.00000000000063, 182.29999999999998, 156.79999999999995, 151.39999999999998, 156.2, 140.89999999999998, 11.599999999999964, 173.0, 143.29999999999998, -9.399999999999855, 163.7, 187.70000000000002, 155.29999999999998, -376.90000000000003, 110.6, 194.59999999999997, 134.0, 154.69999999999996, 15.799999999999963, 9.499999999999964, 45.2, 11.599999999999964, 43.400000000000006, 165.19999999999993, 179.9, 155.89999999999995, 86.59999999999971, 13.699999999999964, 122.29999999999993, 127.1, 148.1, 165.5, 130.09999999999994, 152.29999999999998, 1.0999999999999865, 155.60000000000002, 107.60000000000001, 31.099999999999998, 134.0, 168.2, 20.000000000000014, 191.89999999999995, 164.0, 92.89999999999999, 92.0, 20.000000000000014, 92.30000000000001, 146.0, 158.0, 162.49999999999994, 175.39999999999998, 68.9, 164.0, 89.6, 5.299999999999965], "policy_predator_policy_reward": [1.0, 2.0, 8.0, 4.0, 67.0, 23.0, 24.0, 17.0, 6.0, 4.0, 152.0, 12.0, 95.0, 115.0, 45.0, 10.0, 26.0, 26.0, 65.0, 69.0, 4.0, 13.0, 23.0, 13.0, 5.0, 13.0, 64.0, 20.0, 158.0, 139.0, 134.0, 4.0, 43.0, 22.0, 61.0, 62.0, 77.0, 59.0, 11.0, 2.0, 1.0, 45.0, 11.0, 56.0, 220.0, 95.0, 137.0, 146.0, 49.0, 59.0, 38.0, 9.0, 3.0, 1.0, 3.0, 46.0, 24.0, 0.0, 106.0, 38.0, 35.0, 35.0, 52.0, 42.0, 43.0, 25.0, 8.0, 12.0, 10.0, 13.0, 29.0, 38.0, 37.0, 6.0, 4.0, 25.0, 10.0, 13.0, 147.0, 22.0, 6.0, 7.0, 41.0, 9.0, 57.0, 14.0, 6.0, 7.0, 32.0, 32.0, 3.0, 26.0, 30.0, 9.0, 4.0, 8.0, 29.0, 56.0, 6.0, 11.0, 7.0, 54.0, 41.0, 43.0, 59.0, 5.0, 26.0, 1.0, 30.0, 38.0, 36.0, 5.0, 19.0, 5.0, 19.0, 13.0, 5.0, 4.0, 3.0, 12.0, 8.0, 3.0, 13.0, 7.0, 6.0, 19.0, 5.0, 1.0, 10.0, 9.0, 5.0, 6.0, 48.0, 20.0, 10.0, 10.0, 14.0, 24.0, 14.0, 13.0, 7.0, 3.0, 2.0, 1.0, 82.0, 7.0, 6.0, 15.0, 10.0, 10.0, 5.0, 1.0, 5.0, 11.0, 19.0, 6.0, 6.0, 4.0, 189.0, 20.0, 16.0, 18.0, 12.0, 5.0, 41.0, 48.0, 21.0, 34.0, 8.0, 4.0, 16.0, 17.0, 11.0, 16.0, 25.0, 13.0, 5.0, 24.0, 9.0, 15.0, 25.0, 29.0, 54.0, 55.0, 9.0, 6.0, 12.0, 10.0, 40.0, 26.0, 35.0, 27.0, 20.0, 22.0, 8.0, 1.0, 38.0, 37.0, 40.0, 41.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6060946542041742, "mean_inference_ms": 1.8776643791363037, "mean_action_processing_ms": 0.26399263647736027, "mean_env_wait_ms": 0.2034567884900224, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005070090293884277, "StateBufferConnector_ms": 0.003186821937561035, "ViewRequirementAgentConnector_ms": 0.09694886207580566}, "num_episodes": 23, "episode_return_max": 377.9, "episode_return_min": -414.4999999999999, "episode_return_mean": 169.82399999999978, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1104000, "num_agent_steps_trained": 1104000, "num_env_steps_sampled": 276000, "num_env_steps_trained": 276000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 363.5208323659684, "num_env_steps_trained_throughput_per_sec": 363.5208323659684, "timesteps_total": 276000, "num_env_steps_sampled_lifetime": 276000, "num_agent_steps_sampled_lifetime": 1104000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1104000, "timers": {"training_iteration_time_ms": 10712.159, "restore_workers_time_ms": 0.013, "training_step_time_ms": 10712.119, "sample_time_ms": 1252.667, "learn_time_ms": 9445.319, "learn_throughput": 423.49, "synch_weights_time_ms": 13.013}, "counters": {"num_env_steps_sampled": 276000, "num_env_steps_trained": 276000, "num_agent_steps_sampled": 1104000, "num_agent_steps_trained": 1104000}, "done": false, "training_iteration": 69, "trial_id": "3dae5_00000", "date": "2024-08-14_09-19-30", "timestamp": 1723641570, "time_this_iter_s": 11.032408237457275, "time_total_s": 2390.096086025238, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0fef160>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2390.096086025238, "iterations_since_restore": 69, "perf": {"cpu_util_percent": 28.526666666666664, "ram_util_percent": 83.37333333333332}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.398799732500914, "cur_kl_coeff": 0.056250000000000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.3658322847078717, "policy_loss": -0.0057604279633976085, "vf_loss": 1.3710114890147769, "vf_explained_var": 0.032673475225135765, "kl": 0.010332880245983358, "entropy": 0.9387383001822013, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 131355.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.961061873606273, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.301188825173353, "policy_loss": -0.007649213654388275, "vf_loss": 8.306538592192231, "vf_explained_var": 0.5274185378084738, "kl": 0.015329682853415452, "entropy": 1.4101008150312635, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 131355.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 280000, "num_env_steps_trained": 280000, "num_agent_steps_sampled": 1120000, "num_agent_steps_trained": 1120000}, "env_runners": {"episode_reward_max": 383.0, "episode_reward_min": -414.4999999999999, "episode_reward_mean": 211.4739999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -381.09999999999997, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 220.0}, "policy_reward_mean": {"prey_policy": 82.08199999999995, "predator_policy": 23.655}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-27.699999999999584, 263.8999999999995, 172.09999999999937, 115.70000000000014, -414.4999999999999, -18.39999999999999, 220.29999999999984, 157.1999999999995, 35.600000000000236, 94.70000000000013, 290.8000000000004, -34.700000000000365, 208.09999999999928, 199.39999999999958, 183.8999999999996, 179.9999999999994, 273.0000000000003, 152.2999999999996, 127.69999999999972, 213.29999999999956, 172.79999999999924, 1.7000000000000388, 211.09999999999977, 234.00000000000006, 221.1, 131.8999999999999, 185.59999999999954, 164.6999999999995, 101.79999999999946, 159.0999999999992, 163.39999999999986, 183.29999999999924, 79.10000000000004, 29.500000000000156, -85.00000000000156, 227.19999999999973, 300.8999999999999, 107.99999999999972, 306.09999999999997, 121.19999999999959, 154.29999999999959, 324.0999999999999, 183.5999999999993, 316.80000000000007, 318.5000000000004, 201.69999999999925, 189.19999999999942, 195.2999999999993, 245.69999999999993, 301.5, 329.4, 348.70000000000005, 202.69999999999933, 200.7999999999993, 75.60000000000005, 360.10000000000025, 327.6, 158.49999999999946, 332.3000000000001, 179.29999999999941, 353.0, -57.29999999999993, 362.60000000000014, 187.49999999999935, 143.69999999999965, 109.9999999999999, 357.10000000000025, 275.5000000000001, 162.9999999999994, 313.20000000000005, 324.60000000000025, 177.39999999999944, 317.19999999999993, 274.0999999999999, 203.19999999999933, 377.9, 250.9, 174.2999999999995, 346.0, 346.9, 307.9, 175.89999999999947, 164.89999999999952, 287.09999999999997, 346.0, 349.1, 180.2999999999994, 325.70000000000016, 329.60000000000014, 161.69999999999948, 326.69999999999993, 329.19999999999993, 333.5, 344.19999999999993, 339.29999999999995, 205.0999999999992, 202.99999999999926, 339.9, 358.6, 383.0], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [1.0999999999999865, -164.80000000000038, 94.39999999999941, 156.50000000000003, 130.39999999999972, -4.299999999999901, -53.50000000000054, 102.20000000000002, -381.09999999999997, -348.3999999999999, 9.499999999999964, -310.9, -9.100000000000044, 121.39999999999988, 54.500000000000156, 55.70000000000007, 17.899999999999988, 13.699999999999964, -5.199999999999939, 50.900000000000105, 106.69999999999987, 160.09999999999988, -118.9, -59.80000000000061, -53.50000000000019, 191.6, 169.70000000000002, -64.30000000000004, 75.80000000000001, 40.10000000000009, 144.2, 15.799999999999963, 137.0, 112.9999999999998, 32.6, 52.700000000000124, 20.000000000000014, 64.7, 96.20000000000012, 88.09999999999975, 20.000000000000014, 129.79999999999987, 134.0, -301.30000000000007, 120.79999999999997, 77.29999999999971, 17.000000000000007, 167.0, 141.8, 8.300000000000011, 20.000000000000014, 98.90000000000003, -19.59999999999989, 141.2, 122.0, 13.699999999999964, 17.899999999999988, 44.900000000000084, 20.000000000000014, 127.0999999999998, 42.50000000000002, 35.900000000000006, 20.000000000000014, 146.29999999999993, 5.299999999999965, 12.799999999999997, 17.899999999999988, -72.40000000000089, -87.10000000000079, -61.900000000000595, 122.0, 78.1999999999997, 174.79999999999998, 58.10000000000002, 22.70000000000006, 44.300000000000004, 139.99999999999991, 142.1, 20.000000000000014, 69.20000000000002, 127.39999999999998, 17.899999999999988, 145.9999999999998, 163.1, 158.89999999999992, 13.699999999999966, 146.29999999999998, 150.5, 176.59999999999997, 116.89999999999992, 175.69999999999996, 20.000000000000014, 171.2, -0.9999999999999846, 7.399999999999965, 176.89999999999998, 127.69999999999999, 50.000000000000014, 161.0, 120.50000000000004, 145.39999999999998, 146.0, 147.49999999999997, 174.2, 179.0, 13.699999999999964, 17.899999999999988, 179.89999999999998, 134.6, -148.00000000000063, 182.29999999999998, 156.79999999999995, 151.39999999999998, 156.2, 140.89999999999998, 11.599999999999964, 173.0, 143.29999999999998, -9.399999999999855, 163.7, 187.70000000000002, 155.29999999999998, -376.90000000000003, 110.6, 194.59999999999997, 134.0, 154.69999999999996, 15.799999999999963, 9.499999999999964, 45.2, 11.599999999999964, 43.400000000000006, 165.19999999999993, 179.9, 155.89999999999995, 86.59999999999971, 13.699999999999964, 122.29999999999993, 127.1, 148.1, 165.5, 130.09999999999994, 152.29999999999998, 1.0999999999999865, 155.60000000000002, 107.60000000000001, 31.099999999999998, 134.0, 168.2, 20.000000000000014, 191.89999999999995, 164.0, 92.89999999999999, 92.0, 20.000000000000014, 92.30000000000001, 146.0, 158.0, 162.49999999999994, 175.39999999999998, 68.9, 164.0, 89.6, 5.299999999999965, 119.0, 17.899999999999988, 128.29999999999998, 105.80000000000001, 179.6, 106.4, 191.9, 111.19999999999999, 20.000000000000014, 143.3, 158.29999999999995, 133.40000000000003, 156.2, 151.39999999999998, -3.099999999999958, 147.79999999999998, 164.0, 142.6999999999999, 143.29999999999998, 155.9, 151.39999999999998, 142.1, 170.5999999999999, 152.6, 140.3, 176.0, 13.699999999999964, 187.39999999999992, 11.599999999999964, 181.39999999999998, 102.5, 187.4, 140.6, 194.0, 200.0, 158.0], "policy_predator_policy_reward": [77.0, 59.0, 11.0, 2.0, 1.0, 45.0, 11.0, 56.0, 220.0, 95.0, 137.0, 146.0, 49.0, 59.0, 38.0, 9.0, 3.0, 1.0, 3.0, 46.0, 24.0, 0.0, 106.0, 38.0, 35.0, 35.0, 52.0, 42.0, 43.0, 25.0, 8.0, 12.0, 10.0, 13.0, 29.0, 38.0, 37.0, 6.0, 4.0, 25.0, 10.0, 13.0, 147.0, 22.0, 6.0, 7.0, 41.0, 9.0, 57.0, 14.0, 6.0, 7.0, 32.0, 32.0, 3.0, 26.0, 30.0, 9.0, 4.0, 8.0, 29.0, 56.0, 6.0, 11.0, 7.0, 54.0, 41.0, 43.0, 59.0, 5.0, 26.0, 1.0, 30.0, 38.0, 36.0, 5.0, 19.0, 5.0, 19.0, 13.0, 5.0, 4.0, 3.0, 12.0, 8.0, 3.0, 13.0, 7.0, 6.0, 19.0, 5.0, 1.0, 10.0, 9.0, 5.0, 6.0, 48.0, 20.0, 10.0, 10.0, 14.0, 24.0, 14.0, 13.0, 7.0, 3.0, 2.0, 1.0, 82.0, 7.0, 6.0, 15.0, 10.0, 10.0, 5.0, 1.0, 5.0, 11.0, 19.0, 6.0, 6.0, 4.0, 189.0, 20.0, 16.0, 18.0, 12.0, 5.0, 41.0, 48.0, 21.0, 34.0, 8.0, 4.0, 16.0, 17.0, 11.0, 16.0, 25.0, 13.0, 5.0, 24.0, 9.0, 15.0, 25.0, 29.0, 54.0, 55.0, 9.0, 6.0, 12.0, 10.0, 40.0, 26.0, 35.0, 27.0, 20.0, 22.0, 8.0, 1.0, 38.0, 37.0, 40.0, 41.0, 6.0, 22.0, 25.0, 28.0, 31.0, 29.0, 22.0, 24.0, 9.0, 8.0, 13.0, 21.0, 2.0, 20.0, 6.0, 11.0, 8.0, 12.0, 17.0, 13.0, 22.0, 18.0, 16.0, 5.0, 22.0, 1.0, 3.0, 1.0, 6.0, 4.0, 24.0, 26.0, 17.0, 7.0, 11.0, 14.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6053661103299036, "mean_inference_ms": 1.8749867802572766, "mean_action_processing_ms": 0.2634696546059934, "mean_env_wait_ms": 0.20312113980895027, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005600094795227051, "StateBufferConnector_ms": 0.0031511783599853516, "ViewRequirementAgentConnector_ms": 0.09726071357727051}, "num_episodes": 18, "episode_return_max": 383.0, "episode_return_min": -414.4999999999999, "episode_return_mean": 211.4739999999998, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1120000, "num_agent_steps_trained": 1120000, "num_env_steps_sampled": 280000, "num_env_steps_trained": 280000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 371.20606432758746, "num_env_steps_trained_throughput_per_sec": 371.20606432758746, "timesteps_total": 280000, "num_env_steps_sampled_lifetime": 280000, "num_agent_steps_sampled_lifetime": 1120000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1120000, "timers": {"training_iteration_time_ms": 10741.892, "restore_workers_time_ms": 0.013, "training_step_time_ms": 10741.851, "sample_time_ms": 1256.791, "learn_time_ms": 9470.594, "learn_throughput": 422.36, "synch_weights_time_ms": 13.3}, "counters": {"num_env_steps_sampled": 280000, "num_env_steps_trained": 280000, "num_agent_steps_sampled": 1120000, "num_agent_steps_trained": 1120000}, "done": false, "training_iteration": 70, "trial_id": "3dae5_00000", "date": "2024-08-14_09-19-41", "timestamp": 1723641581, "time_this_iter_s": 10.781000852584839, "time_total_s": 2400.877086877823, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3607c10>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2400.877086877823, "iterations_since_restore": 70, "perf": {"cpu_util_percent": 28.625, "ram_util_percent": 83.43125}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.8181644456411794, "cur_kl_coeff": 0.056250000000000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.173079161795359, "policy_loss": -0.0038570982793336194, "vf_loss": 2.1766479161050585, "vf_explained_var": -0.003255915011047686, "kl": 0.005126122822663081, "entropy": 0.9155212423473439, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 133245.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.976985192803479, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.6906629143568574, "policy_loss": -0.010085093903616464, "vf_loss": 7.698575251947635, "vf_explained_var": 0.5314414312599828, "kl": 0.014485009773322061, "entropy": 1.4098748828998948, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 133245.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 284000, "num_env_steps_trained": 284000, "num_agent_steps_sampled": 1136000, "num_agent_steps_trained": 1136000}, "env_runners": {"episode_reward_max": 383.0, "episode_reward_min": -486.69999999999953, "episode_reward_mean": 229.25499999999977, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -376.90000000000003, "predator_policy": 1.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 189.0}, "policy_reward_mean": {"prey_policy": 94.12749999999997, "predator_policy": 20.5}, "custom_metrics": {}, "hist_stats": {"episode_reward": [127.69999999999972, 213.29999999999956, 172.79999999999924, 1.7000000000000388, 211.09999999999977, 234.00000000000006, 221.1, 131.8999999999999, 185.59999999999954, 164.6999999999995, 101.79999999999946, 159.0999999999992, 163.39999999999986, 183.29999999999924, 79.10000000000004, 29.500000000000156, -85.00000000000156, 227.19999999999973, 300.8999999999999, 107.99999999999972, 306.09999999999997, 121.19999999999959, 154.29999999999959, 324.0999999999999, 183.5999999999993, 316.80000000000007, 318.5000000000004, 201.69999999999925, 189.19999999999942, 195.2999999999993, 245.69999999999993, 301.5, 329.4, 348.70000000000005, 202.69999999999933, 200.7999999999993, 75.60000000000005, 360.10000000000025, 327.6, 158.49999999999946, 332.3000000000001, 179.29999999999941, 353.0, -57.29999999999993, 362.60000000000014, 187.49999999999935, 143.69999999999965, 109.9999999999999, 357.10000000000025, 275.5000000000001, 162.9999999999994, 313.20000000000005, 324.60000000000025, 177.39999999999944, 317.19999999999993, 274.0999999999999, 203.19999999999933, 377.9, 250.9, 174.2999999999995, 346.0, 346.9, 307.9, 175.89999999999947, 164.89999999999952, 287.09999999999997, 346.0, 349.1, 180.2999999999994, 325.70000000000016, 329.60000000000014, 161.69999999999948, 326.69999999999993, 329.19999999999993, 333.5, 344.19999999999993, 339.29999999999995, 205.0999999999992, 202.99999999999926, 339.9, 358.6, 383.0, 367.79999999999995, 305.70000000000005, 244.59999999999997, 342.0, 357.4000000000001, 168.79999999999953, 370.0, 286.0, -486.69999999999953, 320.5, 23.200000000000003, 186.89999999999938, 153.39999999999952, 291.2, 160.69999999999953, 297.2, 107.79999999999994, 333.3], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 64.7, 96.20000000000012, 88.09999999999975, 20.000000000000014, 129.79999999999987, 134.0, -301.30000000000007, 120.79999999999997, 77.29999999999971, 17.000000000000007, 167.0, 141.8, 8.300000000000011, 20.000000000000014, 98.90000000000003, -19.59999999999989, 141.2, 122.0, 13.699999999999964, 17.899999999999988, 44.900000000000084, 20.000000000000014, 127.0999999999998, 42.50000000000002, 35.900000000000006, 20.000000000000014, 146.29999999999993, 5.299999999999965, 12.799999999999997, 17.899999999999988, -72.40000000000089, -87.10000000000079, -61.900000000000595, 122.0, 78.1999999999997, 174.79999999999998, 58.10000000000002, 22.70000000000006, 44.300000000000004, 139.99999999999991, 142.1, 20.000000000000014, 69.20000000000002, 127.39999999999998, 17.899999999999988, 145.9999999999998, 163.1, 158.89999999999992, 13.699999999999966, 146.29999999999998, 150.5, 176.59999999999997, 116.89999999999992, 175.69999999999996, 20.000000000000014, 171.2, -0.9999999999999846, 7.399999999999965, 176.89999999999998, 127.69999999999999, 50.000000000000014, 161.0, 120.50000000000004, 145.39999999999998, 146.0, 147.49999999999997, 174.2, 179.0, 13.699999999999964, 17.899999999999988, 179.89999999999998, 134.6, -148.00000000000063, 182.29999999999998, 156.79999999999995, 151.39999999999998, 156.2, 140.89999999999998, 11.599999999999964, 173.0, 143.29999999999998, -9.399999999999855, 163.7, 187.70000000000002, 155.29999999999998, -376.90000000000003, 110.6, 194.59999999999997, 134.0, 154.69999999999996, 15.799999999999963, 9.499999999999964, 45.2, 11.599999999999964, 43.400000000000006, 165.19999999999993, 179.9, 155.89999999999995, 86.59999999999971, 13.699999999999964, 122.29999999999993, 127.1, 148.1, 165.5, 130.09999999999994, 152.29999999999998, 1.0999999999999865, 155.60000000000002, 107.60000000000001, 31.099999999999998, 134.0, 168.2, 20.000000000000014, 191.89999999999995, 164.0, 92.89999999999999, 92.0, 20.000000000000014, 92.30000000000001, 146.0, 158.0, 162.49999999999994, 175.39999999999998, 68.9, 164.0, 89.6, 5.299999999999965, 119.0, 17.899999999999988, 128.29999999999998, 105.80000000000001, 179.6, 106.4, 191.9, 111.19999999999999, 20.000000000000014, 143.3, 158.29999999999995, 133.40000000000003, 156.2, 151.39999999999998, -3.099999999999958, 147.79999999999998, 164.0, 142.6999999999999, 143.29999999999998, 155.9, 151.39999999999998, 142.1, 170.5999999999999, 152.6, 140.3, 176.0, 13.699999999999964, 187.39999999999992, 11.599999999999964, 181.39999999999998, 102.5, 187.4, 140.6, 194.0, 200.0, 158.0, 146.0, 192.79999999999995, 79.7, 155.0, 86.6, 104.0, 161.0, 152.0, 164.0, 172.39999999999998, -5.1999999999999265, 143.0, 185.0, 170.0, 128.0, 116.0, -336.9999999999999, -330.69999999999993, 144.5, 128.0, -319.79999999999995, 152.0, 175.4, -11.499999999999819, 136.99999999999994, -13.599999999999783, 96.5, 145.70000000000002, 116.0, 13.699999999999966, 183.2, 65.0, 81.50000000000004, 5.299999999999965, 152.0, 149.3], "policy_predator_policy_reward": [37.0, 6.0, 4.0, 25.0, 10.0, 13.0, 147.0, 22.0, 6.0, 7.0, 41.0, 9.0, 57.0, 14.0, 6.0, 7.0, 32.0, 32.0, 3.0, 26.0, 30.0, 9.0, 4.0, 8.0, 29.0, 56.0, 6.0, 11.0, 7.0, 54.0, 41.0, 43.0, 59.0, 5.0, 26.0, 1.0, 30.0, 38.0, 36.0, 5.0, 19.0, 5.0, 19.0, 13.0, 5.0, 4.0, 3.0, 12.0, 8.0, 3.0, 13.0, 7.0, 6.0, 19.0, 5.0, 1.0, 10.0, 9.0, 5.0, 6.0, 48.0, 20.0, 10.0, 10.0, 14.0, 24.0, 14.0, 13.0, 7.0, 3.0, 2.0, 1.0, 82.0, 7.0, 6.0, 15.0, 10.0, 10.0, 5.0, 1.0, 5.0, 11.0, 19.0, 6.0, 6.0, 4.0, 189.0, 20.0, 16.0, 18.0, 12.0, 5.0, 41.0, 48.0, 21.0, 34.0, 8.0, 4.0, 16.0, 17.0, 11.0, 16.0, 25.0, 13.0, 5.0, 24.0, 9.0, 15.0, 25.0, 29.0, 54.0, 55.0, 9.0, 6.0, 12.0, 10.0, 40.0, 26.0, 35.0, 27.0, 20.0, 22.0, 8.0, 1.0, 38.0, 37.0, 40.0, 41.0, 6.0, 22.0, 25.0, 28.0, 31.0, 29.0, 22.0, 24.0, 9.0, 8.0, 13.0, 21.0, 2.0, 20.0, 6.0, 11.0, 8.0, 12.0, 17.0, 13.0, 22.0, 18.0, 16.0, 5.0, 22.0, 1.0, 3.0, 1.0, 6.0, 4.0, 24.0, 26.0, 17.0, 7.0, 11.0, 14.0, 11.0, 18.0, 32.0, 39.0, 46.0, 8.0, 16.0, 13.0, 7.0, 14.0, 16.0, 15.0, 7.0, 8.0, 33.0, 9.0, 1.0, 180.0, 22.0, 26.0, 14.0, 177.0, 16.0, 7.0, 14.0, 16.0, 39.0, 10.0, 19.0, 12.0, 28.0, 21.0, 4.0, 17.0, 16.0, 16.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6046472431849075, "mean_inference_ms": 1.872400413781999, "mean_action_processing_ms": 0.26294773133799465, "mean_env_wait_ms": 0.2027885205530897, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006122589111328125, "StateBufferConnector_ms": 0.003194093704223633, "ViewRequirementAgentConnector_ms": 0.09900498390197754}, "num_episodes": 18, "episode_return_max": 383.0, "episode_return_min": -486.69999999999953, "episode_return_mean": 229.25499999999977, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1136000, "num_agent_steps_trained": 1136000, "num_env_steps_sampled": 284000, "num_env_steps_trained": 284000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 369.87712882744705, "num_env_steps_trained_throughput_per_sec": 369.87712882744705, "timesteps_total": 284000, "num_env_steps_sampled_lifetime": 284000, "num_agent_steps_sampled_lifetime": 1136000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1136000, "timers": {"training_iteration_time_ms": 10753.172, "restore_workers_time_ms": 0.013, "training_step_time_ms": 10753.132, "sample_time_ms": 1256.366, "learn_time_ms": 9482.096, "learn_throughput": 421.848, "synch_weights_time_ms": 13.519}, "counters": {"num_env_steps_sampled": 284000, "num_env_steps_trained": 284000, "num_agent_steps_sampled": 1136000, "num_agent_steps_trained": 1136000}, "done": false, "training_iteration": 71, "trial_id": "3dae5_00000", "date": "2024-08-14_09-19-52", "timestamp": 1723641592, "time_this_iter_s": 10.82029414176941, "time_total_s": 2411.6973810195923, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3680040>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2411.6973810195923, "iterations_since_restore": 71, "perf": {"cpu_util_percent": 29.026666666666664, "ram_util_percent": 83.63333333333334}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.400204360989666, "cur_kl_coeff": 0.056250000000000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.2528837578637257, "policy_loss": -0.0033931020364564445, "vf_loss": 2.255852025621152, "vf_explained_var": 0.012805178745713814, "kl": 0.007552662743155668, "entropy": 0.914226660053566, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 135135.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.705812359896917, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.679929779446315, "policy_loss": -0.001017089724225342, "vf_loss": 8.678264092642163, "vf_explained_var": 0.4561027337949743, "kl": 0.01788516787729595, "entropy": 1.4527932038382878, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 135135.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 288000, "num_env_steps_trained": 288000, "num_agent_steps_sampled": 1152000, "num_agent_steps_trained": 1152000}, "env_runners": {"episode_reward_max": 383.0, "episode_reward_min": -486.69999999999953, "episode_reward_mean": 257.47499999999985, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -376.90000000000003, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 189.0}, "policy_reward_mean": {"prey_policy": 108.1525, "predator_policy": 20.585}, "custom_metrics": {}, "hist_stats": {"episode_reward": [154.29999999999959, 324.0999999999999, 183.5999999999993, 316.80000000000007, 318.5000000000004, 201.69999999999925, 189.19999999999942, 195.2999999999993, 245.69999999999993, 301.5, 329.4, 348.70000000000005, 202.69999999999933, 200.7999999999993, 75.60000000000005, 360.10000000000025, 327.6, 158.49999999999946, 332.3000000000001, 179.29999999999941, 353.0, -57.29999999999993, 362.60000000000014, 187.49999999999935, 143.69999999999965, 109.9999999999999, 357.10000000000025, 275.5000000000001, 162.9999999999994, 313.20000000000005, 324.60000000000025, 177.39999999999944, 317.19999999999993, 274.0999999999999, 203.19999999999933, 377.9, 250.9, 174.2999999999995, 346.0, 346.9, 307.9, 175.89999999999947, 164.89999999999952, 287.09999999999997, 346.0, 349.1, 180.2999999999994, 325.70000000000016, 329.60000000000014, 161.69999999999948, 326.69999999999993, 329.19999999999993, 333.5, 344.19999999999993, 339.29999999999995, 205.0999999999992, 202.99999999999926, 339.9, 358.6, 383.0, 367.79999999999995, 305.70000000000005, 244.59999999999997, 342.0, 357.4000000000001, 168.79999999999953, 370.0, 286.0, -486.69999999999953, 320.5, 23.200000000000003, 186.89999999999938, 153.39999999999952, 291.2, 160.69999999999953, 297.2, 107.79999999999994, 333.3, 71.30000000000001, 353.4, 316.3000000000002, 207.09999999999928, 286.5, 28.60000000000001, 325.79999999999995, 347.19999999999993, 343.3, 319.69999999999993, 319.59999999999997, 356.1, 352.59999999999997, 315.4, 364.5, 320.7, 353.3, 358.0, 32.30000000000018, 363.2, 187.9999999999994, 257.6], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [127.39999999999998, 17.899999999999988, 145.9999999999998, 163.1, 158.89999999999992, 13.699999999999966, 146.29999999999998, 150.5, 176.59999999999997, 116.89999999999992, 175.69999999999996, 20.000000000000014, 171.2, -0.9999999999999846, 7.399999999999965, 176.89999999999998, 127.69999999999999, 50.000000000000014, 161.0, 120.50000000000004, 145.39999999999998, 146.0, 147.49999999999997, 174.2, 179.0, 13.699999999999964, 17.899999999999988, 179.89999999999998, 134.6, -148.00000000000063, 182.29999999999998, 156.79999999999995, 151.39999999999998, 156.2, 140.89999999999998, 11.599999999999964, 173.0, 143.29999999999998, -9.399999999999855, 163.7, 187.70000000000002, 155.29999999999998, -376.90000000000003, 110.6, 194.59999999999997, 134.0, 154.69999999999996, 15.799999999999963, 9.499999999999964, 45.2, 11.599999999999964, 43.400000000000006, 165.19999999999993, 179.9, 155.89999999999995, 86.59999999999971, 13.699999999999964, 122.29999999999993, 127.1, 148.1, 165.5, 130.09999999999994, 152.29999999999998, 1.0999999999999865, 155.60000000000002, 107.60000000000001, 31.099999999999998, 134.0, 168.2, 20.000000000000014, 191.89999999999995, 164.0, 92.89999999999999, 92.0, 20.000000000000014, 92.30000000000001, 146.0, 158.0, 162.49999999999994, 175.39999999999998, 68.9, 164.0, 89.6, 5.299999999999965, 119.0, 17.899999999999988, 128.29999999999998, 105.80000000000001, 179.6, 106.4, 191.9, 111.19999999999999, 20.000000000000014, 143.3, 158.29999999999995, 133.40000000000003, 156.2, 151.39999999999998, -3.099999999999958, 147.79999999999998, 164.0, 142.6999999999999, 143.29999999999998, 155.9, 151.39999999999998, 142.1, 170.5999999999999, 152.6, 140.3, 176.0, 13.699999999999964, 187.39999999999992, 11.599999999999964, 181.39999999999998, 102.5, 187.4, 140.6, 194.0, 200.0, 158.0, 146.0, 192.79999999999995, 79.7, 155.0, 86.6, 104.0, 161.0, 152.0, 164.0, 172.39999999999998, -5.1999999999999265, 143.0, 185.0, 170.0, 128.0, 116.0, -336.9999999999999, -330.69999999999993, 144.5, 128.0, -319.79999999999995, 152.0, 175.4, -11.499999999999819, 136.99999999999994, -13.599999999999783, 96.5, 145.70000000000002, 116.0, 13.699999999999966, 183.2, 65.0, 81.50000000000004, 5.299999999999965, 152.0, 149.3, 152.9, -352.59999999999934, 191.3, 118.1, 122.0, 161.29999999999998, 20.000000000000014, 181.1, 134.29999999999998, 105.2, 146.0, -282.3999999999996, 148.4, 160.4, 148.4, 168.79999999999995, 161.0, 146.3, 176.6, 115.10000000000002, 181.1, 96.5, 182.0, 154.1, 167.3, 161.3, 125.0, 109.4, 180.5, 158.0, 127.69999999999999, 158.0, 166.1, 153.2, 173.0, 164.0, 11.599999999999964, 13.699999999999964, 147.2, 179.0, 20.000000000000014, 143.0, 125.6, 86.0], "policy_predator_policy_reward": [5.0, 4.0, 3.0, 12.0, 8.0, 3.0, 13.0, 7.0, 6.0, 19.0, 5.0, 1.0, 10.0, 9.0, 5.0, 6.0, 48.0, 20.0, 10.0, 10.0, 14.0, 24.0, 14.0, 13.0, 7.0, 3.0, 2.0, 1.0, 82.0, 7.0, 6.0, 15.0, 10.0, 10.0, 5.0, 1.0, 5.0, 11.0, 19.0, 6.0, 6.0, 4.0, 189.0, 20.0, 16.0, 18.0, 12.0, 5.0, 41.0, 48.0, 21.0, 34.0, 8.0, 4.0, 16.0, 17.0, 11.0, 16.0, 25.0, 13.0, 5.0, 24.0, 9.0, 15.0, 25.0, 29.0, 54.0, 55.0, 9.0, 6.0, 12.0, 10.0, 40.0, 26.0, 35.0, 27.0, 20.0, 22.0, 8.0, 1.0, 38.0, 37.0, 40.0, 41.0, 6.0, 22.0, 25.0, 28.0, 31.0, 29.0, 22.0, 24.0, 9.0, 8.0, 13.0, 21.0, 2.0, 20.0, 6.0, 11.0, 8.0, 12.0, 17.0, 13.0, 22.0, 18.0, 16.0, 5.0, 22.0, 1.0, 3.0, 1.0, 6.0, 4.0, 24.0, 26.0, 17.0, 7.0, 11.0, 14.0, 11.0, 18.0, 32.0, 39.0, 46.0, 8.0, 16.0, 13.0, 7.0, 14.0, 16.0, 15.0, 7.0, 8.0, 33.0, 9.0, 1.0, 180.0, 22.0, 26.0, 14.0, 177.0, 16.0, 7.0, 14.0, 16.0, 39.0, 10.0, 19.0, 12.0, 28.0, 21.0, 4.0, 17.0, 16.0, 16.0, 119.0, 152.0, 27.0, 17.0, 27.0, 6.0, 0.0, 6.0, 31.0, 16.0, 160.0, 5.0, 7.0, 10.0, 12.0, 18.0, 17.0, 19.0, 13.0, 15.0, 27.0, 15.0, 2.0, 18.0, 13.0, 11.0, 42.0, 39.0, 15.0, 11.0, 28.0, 7.0, 18.0, 16.0, 10.0, 11.0, 3.0, 4.0, 19.0, 18.0, 13.0, 12.0, 27.0, 19.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6037499172484244, "mean_inference_ms": 1.8690488887472732, "mean_action_processing_ms": 0.26235240649769287, "mean_env_wait_ms": 0.2023795241708972, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006784558296203613, "StateBufferConnector_ms": 0.003265857696533203, "ViewRequirementAgentConnector_ms": 0.09991967678070068}, "num_episodes": 22, "episode_return_max": 383.0, "episode_return_min": -486.69999999999953, "episode_return_mean": 257.47499999999985, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1152000, "num_agent_steps_trained": 1152000, "num_env_steps_sampled": 288000, "num_env_steps_trained": 288000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 372.06910917862297, "num_env_steps_trained_throughput_per_sec": 372.06910917862297, "timesteps_total": 288000, "num_env_steps_sampled_lifetime": 288000, "num_agent_steps_sampled_lifetime": 1152000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1152000, "timers": {"training_iteration_time_ms": 10756.649, "restore_workers_time_ms": 0.013, "training_step_time_ms": 10756.591, "sample_time_ms": 1259.56, "learn_time_ms": 9481.374, "learn_throughput": 421.88, "synch_weights_time_ms": 13.976}, "counters": {"num_env_steps_sampled": 288000, "num_env_steps_trained": 288000, "num_agent_steps_sampled": 1152000, "num_agent_steps_trained": 1152000}, "done": false, "training_iteration": 72, "trial_id": "3dae5_00000", "date": "2024-08-14_09-20-03", "timestamp": 1723641603, "time_this_iter_s": 10.770262002944946, "time_total_s": 2422.4676430225372, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b384b550>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2422.4676430225372, "iterations_since_restore": 72, "perf": {"cpu_util_percent": 28.106666666666666, "ram_util_percent": 83.63333333333335}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.849027923301414, "cur_kl_coeff": 0.056250000000000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.9949564856196207, "policy_loss": -0.00520634033825623, "vf_loss": 1.9996725757286031, "vf_explained_var": 0.021202102792326104, "kl": 0.008715566751238371, "entropy": 0.8987788207001156, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 137025.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.7051045753337717, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.010364646760245, "policy_loss": 0.0022631518501497645, "vf_loss": 8.004798872760995, "vf_explained_var": 0.5742765864367207, "kl": 0.022017358848934254, "entropy": 1.4834932501984652, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 137025.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 292000, "num_env_steps_trained": 292000, "num_agent_steps_sampled": 1168000, "num_agent_steps_trained": 1168000}, "env_runners": {"episode_reward_max": 383.0, "episode_reward_min": -486.69999999999953, "episode_reward_mean": 275.5579999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -352.59999999999934, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 180.0}, "policy_reward_mean": {"prey_policy": 116.94400000000002, "predator_policy": 20.835}, "custom_metrics": {}, "hist_stats": {"episode_reward": [187.49999999999935, 143.69999999999965, 109.9999999999999, 357.10000000000025, 275.5000000000001, 162.9999999999994, 313.20000000000005, 324.60000000000025, 177.39999999999944, 317.19999999999993, 274.0999999999999, 203.19999999999933, 377.9, 250.9, 174.2999999999995, 346.0, 346.9, 307.9, 175.89999999999947, 164.89999999999952, 287.09999999999997, 346.0, 349.1, 180.2999999999994, 325.70000000000016, 329.60000000000014, 161.69999999999948, 326.69999999999993, 329.19999999999993, 333.5, 344.19999999999993, 339.29999999999995, 205.0999999999992, 202.99999999999926, 339.9, 358.6, 383.0, 367.79999999999995, 305.70000000000005, 244.59999999999997, 342.0, 357.4000000000001, 168.79999999999953, 370.0, 286.0, -486.69999999999953, 320.5, 23.200000000000003, 186.89999999999938, 153.39999999999952, 291.2, 160.69999999999953, 297.2, 107.79999999999994, 333.3, 71.30000000000001, 353.4, 316.3000000000002, 207.09999999999928, 286.5, 28.60000000000001, 325.79999999999995, 347.19999999999993, 343.3, 319.69999999999993, 319.59999999999997, 356.1, 352.59999999999997, 315.4, 364.5, 320.7, 353.3, 358.0, 32.30000000000018, 363.2, 187.9999999999994, 257.6, 343.3, 351.0, 279.0, 81.69999999999996, 357.7, 193.19999999999936, 313.0, 367.0, 366.0, 362.0, 304.7, 356.0, 196.39999999999938, 373.0, 367.2, 360.4, 340.0, 368.4, 350.0, 312.0, 359.0, 366.6, 344.7000000000001], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [154.69999999999996, 15.799999999999963, 9.499999999999964, 45.2, 11.599999999999964, 43.400000000000006, 165.19999999999993, 179.9, 155.89999999999995, 86.59999999999971, 13.699999999999964, 122.29999999999993, 127.1, 148.1, 165.5, 130.09999999999994, 152.29999999999998, 1.0999999999999865, 155.60000000000002, 107.60000000000001, 31.099999999999998, 134.0, 168.2, 20.000000000000014, 191.89999999999995, 164.0, 92.89999999999999, 92.0, 20.000000000000014, 92.30000000000001, 146.0, 158.0, 162.49999999999994, 175.39999999999998, 68.9, 164.0, 89.6, 5.299999999999965, 119.0, 17.899999999999988, 128.29999999999998, 105.80000000000001, 179.6, 106.4, 191.9, 111.19999999999999, 20.000000000000014, 143.3, 158.29999999999995, 133.40000000000003, 156.2, 151.39999999999998, -3.099999999999958, 147.79999999999998, 164.0, 142.6999999999999, 143.29999999999998, 155.9, 151.39999999999998, 142.1, 170.5999999999999, 152.6, 140.3, 176.0, 13.699999999999964, 187.39999999999992, 11.599999999999964, 181.39999999999998, 102.5, 187.4, 140.6, 194.0, 200.0, 158.0, 146.0, 192.79999999999995, 79.7, 155.0, 86.6, 104.0, 161.0, 152.0, 164.0, 172.39999999999998, -5.1999999999999265, 143.0, 185.0, 170.0, 128.0, 116.0, -336.9999999999999, -330.69999999999993, 144.5, 128.0, -319.79999999999995, 152.0, 175.4, -11.499999999999819, 136.99999999999994, -13.599999999999783, 96.5, 145.70000000000002, 116.0, 13.699999999999966, 183.2, 65.0, 81.50000000000004, 5.299999999999965, 152.0, 149.3, 152.9, -352.59999999999934, 191.3, 118.1, 122.0, 161.29999999999998, 20.000000000000014, 181.1, 134.29999999999998, 105.2, 146.0, -282.3999999999996, 148.4, 160.4, 148.4, 168.79999999999995, 161.0, 146.3, 176.6, 115.10000000000002, 181.1, 96.5, 182.0, 154.1, 167.3, 161.3, 125.0, 109.4, 180.5, 158.0, 127.69999999999999, 158.0, 166.1, 153.2, 173.0, 164.0, 11.599999999999964, 13.699999999999964, 147.2, 179.0, 20.000000000000014, 143.0, 125.6, 86.0, 101.0, 191.3, 167.0, 161.0, 125.0, 101.0, -262.29999999999916, 191.0, 164.6, 175.1, 3.1999999999999615, 173.0, 164.0, 86.0, 190.4, 155.60000000000002, 177.2, 174.8, 128.0, 194.0, 142.7, 131.0, 176.0, 164.0, 20.000000000000014, 163.39999999999998, 164.0, 191.0, 171.2, 173.0, 189.2, 135.2, 161.0, 164.0, 156.2, 189.2, 176.0, 140.0, 161.0, 107.0, 161.0, 173.0, 177.2, 175.4, 151.7, 176.0], "policy_predator_policy_reward": [12.0, 5.0, 41.0, 48.0, 21.0, 34.0, 8.0, 4.0, 16.0, 17.0, 11.0, 16.0, 25.0, 13.0, 5.0, 24.0, 9.0, 15.0, 25.0, 29.0, 54.0, 55.0, 9.0, 6.0, 12.0, 10.0, 40.0, 26.0, 35.0, 27.0, 20.0, 22.0, 8.0, 1.0, 38.0, 37.0, 40.0, 41.0, 6.0, 22.0, 25.0, 28.0, 31.0, 29.0, 22.0, 24.0, 9.0, 8.0, 13.0, 21.0, 2.0, 20.0, 6.0, 11.0, 8.0, 12.0, 17.0, 13.0, 22.0, 18.0, 16.0, 5.0, 22.0, 1.0, 3.0, 1.0, 6.0, 4.0, 24.0, 26.0, 17.0, 7.0, 11.0, 14.0, 11.0, 18.0, 32.0, 39.0, 46.0, 8.0, 16.0, 13.0, 7.0, 14.0, 16.0, 15.0, 7.0, 8.0, 33.0, 9.0, 1.0, 180.0, 22.0, 26.0, 14.0, 177.0, 16.0, 7.0, 14.0, 16.0, 39.0, 10.0, 19.0, 12.0, 28.0, 21.0, 4.0, 17.0, 16.0, 16.0, 119.0, 152.0, 27.0, 17.0, 27.0, 6.0, 0.0, 6.0, 31.0, 16.0, 160.0, 5.0, 7.0, 10.0, 12.0, 18.0, 17.0, 19.0, 13.0, 15.0, 27.0, 15.0, 2.0, 18.0, 13.0, 11.0, 42.0, 39.0, 15.0, 11.0, 28.0, 7.0, 18.0, 16.0, 10.0, 11.0, 3.0, 4.0, 19.0, 18.0, 13.0, 12.0, 27.0, 19.0, 24.0, 27.0, 10.0, 13.0, 19.0, 34.0, 3.0, 150.0, 11.0, 7.0, 8.0, 9.0, 28.0, 35.0, 9.0, 12.0, 5.0, 9.0, 22.0, 18.0, 19.0, 12.0, 12.0, 4.0, 5.0, 8.0, 5.0, 13.0, 10.0, 13.0, 18.0, 18.0, 3.0, 12.0, 9.0, 14.0, 20.0, 14.0, 17.0, 27.0, 11.0, 14.0, 7.0, 7.0, 8.0, 9.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6029694785171117, "mean_inference_ms": 1.8642445358466246, "mean_action_processing_ms": 0.26222107048626975, "mean_env_wait_ms": 0.20210544492111332, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006807088851928711, "StateBufferConnector_ms": 0.003278970718383789, "ViewRequirementAgentConnector_ms": 0.10129356384277344}, "num_episodes": 23, "episode_return_max": 383.0, "episode_return_min": -486.69999999999953, "episode_return_mean": 275.5579999999999, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1168000, "num_agent_steps_trained": 1168000, "num_env_steps_sampled": 292000, "num_env_steps_trained": 292000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 377.8957462645519, "num_env_steps_trained_throughput_per_sec": 377.8957462645519, "timesteps_total": 292000, "num_env_steps_sampled_lifetime": 292000, "num_agent_steps_sampled_lifetime": 1168000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1168000, "timers": {"training_iteration_time_ms": 10716.029, "restore_workers_time_ms": 0.013, "training_step_time_ms": 10715.972, "sample_time_ms": 1259.31, "learn_time_ms": 9441.633, "learn_throughput": 423.656, "synch_weights_time_ms": 13.481}, "counters": {"num_env_steps_sampled": 292000, "num_env_steps_trained": 292000, "num_agent_steps_sampled": 1168000, "num_agent_steps_trained": 1168000}, "done": false, "training_iteration": 73, "trial_id": "3dae5_00000", "date": "2024-08-14_09-20-13", "timestamp": 1723641613, "time_this_iter_s": 10.592971086502075, "time_total_s": 2433.0606141090393, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b384bf70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2433.0606141090393, "iterations_since_restore": 73, "perf": {"cpu_util_percent": 27.839999999999996, "ram_util_percent": 83.38666666666667}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.259025241205932, "cur_kl_coeff": 0.056250000000000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.1261417474696245, "policy_loss": -0.008877221738707728, "vf_loss": 4.134546207750915, "vf_explained_var": 0.13966112903186254, "kl": 0.008404409485684107, "entropy": 0.9089973722500776, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 138915.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.197448985160343, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.696905545330552, "policy_loss": -0.0025037099112061754, "vf_loss": 7.696975365391484, "vf_explained_var": 0.47314172642571584, "kl": 0.010817266088742828, "entropy": 1.4681196881980492, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 138915.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 296000, "num_env_steps_trained": 296000, "num_agent_steps_sampled": 1184000, "num_agent_steps_trained": 1184000}, "env_runners": {"episode_reward_max": 383.0, "episode_reward_min": -486.69999999999953, "episode_reward_mean": 279.2229999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -352.59999999999934, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 180.0}, "policy_reward_mean": {"prey_policy": 118.34650000000002, "predator_policy": 21.265}, "custom_metrics": {}, "hist_stats": {"episode_reward": [175.89999999999947, 164.89999999999952, 287.09999999999997, 346.0, 349.1, 180.2999999999994, 325.70000000000016, 329.60000000000014, 161.69999999999948, 326.69999999999993, 329.19999999999993, 333.5, 344.19999999999993, 339.29999999999995, 205.0999999999992, 202.99999999999926, 339.9, 358.6, 383.0, 367.79999999999995, 305.70000000000005, 244.59999999999997, 342.0, 357.4000000000001, 168.79999999999953, 370.0, 286.0, -486.69999999999953, 320.5, 23.200000000000003, 186.89999999999938, 153.39999999999952, 291.2, 160.69999999999953, 297.2, 107.79999999999994, 333.3, 71.30000000000001, 353.4, 316.3000000000002, 207.09999999999928, 286.5, 28.60000000000001, 325.79999999999995, 347.19999999999993, 343.3, 319.69999999999993, 319.59999999999997, 356.1, 352.59999999999997, 315.4, 364.5, 320.7, 353.3, 358.0, 32.30000000000018, 363.2, 187.9999999999994, 257.6, 343.3, 351.0, 279.0, 81.69999999999996, 357.7, 193.19999999999936, 313.0, 367.0, 366.0, 362.0, 304.7, 356.0, 196.39999999999938, 373.0, 367.2, 360.4, 340.0, 368.4, 350.0, 312.0, 359.0, 366.6, 344.7000000000001, 340.99999999999994, 289.0, 336.0, 184.09999999999928, 355.7, 295.4, 332.79999999999995, 329.0000000000001, 211.2, 302.9, 207.69999999999996, 208.99999999999997, 316.9, 311.10000000000025, 276.69999999999993, 177.39999999999935, 245.89999999999998, 295.10000000000014], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [89.6, 5.299999999999965, 119.0, 17.899999999999988, 128.29999999999998, 105.80000000000001, 179.6, 106.4, 191.9, 111.19999999999999, 20.000000000000014, 143.3, 158.29999999999995, 133.40000000000003, 156.2, 151.39999999999998, -3.099999999999958, 147.79999999999998, 164.0, 142.6999999999999, 143.29999999999998, 155.9, 151.39999999999998, 142.1, 170.5999999999999, 152.6, 140.3, 176.0, 13.699999999999964, 187.39999999999992, 11.599999999999964, 181.39999999999998, 102.5, 187.4, 140.6, 194.0, 200.0, 158.0, 146.0, 192.79999999999995, 79.7, 155.0, 86.6, 104.0, 161.0, 152.0, 164.0, 172.39999999999998, -5.1999999999999265, 143.0, 185.0, 170.0, 128.0, 116.0, -336.9999999999999, -330.69999999999993, 144.5, 128.0, -319.79999999999995, 152.0, 175.4, -11.499999999999819, 136.99999999999994, -13.599999999999783, 96.5, 145.70000000000002, 116.0, 13.699999999999966, 183.2, 65.0, 81.50000000000004, 5.299999999999965, 152.0, 149.3, 152.9, -352.59999999999934, 191.3, 118.1, 122.0, 161.29999999999998, 20.000000000000014, 181.1, 134.29999999999998, 105.2, 146.0, -282.3999999999996, 148.4, 160.4, 148.4, 168.79999999999995, 161.0, 146.3, 176.6, 115.10000000000002, 181.1, 96.5, 182.0, 154.1, 167.3, 161.3, 125.0, 109.4, 180.5, 158.0, 127.69999999999999, 158.0, 166.1, 153.2, 173.0, 164.0, 11.599999999999964, 13.699999999999964, 147.2, 179.0, 20.000000000000014, 143.0, 125.6, 86.0, 101.0, 191.3, 167.0, 161.0, 125.0, 101.0, -262.29999999999916, 191.0, 164.6, 175.1, 3.1999999999999615, 173.0, 164.0, 86.0, 190.4, 155.60000000000002, 177.2, 174.8, 128.0, 194.0, 142.7, 131.0, 176.0, 164.0, 20.000000000000014, 163.39999999999998, 164.0, 191.0, 171.2, 173.0, 189.2, 135.2, 161.0, 164.0, 156.2, 189.2, 176.0, 140.0, 161.0, 107.0, 161.0, 173.0, 177.2, 175.4, 151.7, 176.0, 134.9, 169.1, 88.7, 140.3, 128.0, 176.0, 20.000000000000014, 139.1, 167.3, 178.4, 133.4, 92.0, 134.0, 168.79999999999995, 150.49999999999997, 138.5, 56.0, 72.2, 91.1, 171.8, 55.70000000000001, 95.0, 53.6, 67.4, 140.6, 140.29999999999998, 134.59999999999994, 150.5, 176.29999999999998, 16.4, 20.000000000000014, 130.39999999999995, 51.5, 130.39999999999998, 118.4, 121.69999999999996], "policy_predator_policy_reward": [40.0, 41.0, 6.0, 22.0, 25.0, 28.0, 31.0, 29.0, 22.0, 24.0, 9.0, 8.0, 13.0, 21.0, 2.0, 20.0, 6.0, 11.0, 8.0, 12.0, 17.0, 13.0, 22.0, 18.0, 16.0, 5.0, 22.0, 1.0, 3.0, 1.0, 6.0, 4.0, 24.0, 26.0, 17.0, 7.0, 11.0, 14.0, 11.0, 18.0, 32.0, 39.0, 46.0, 8.0, 16.0, 13.0, 7.0, 14.0, 16.0, 15.0, 7.0, 8.0, 33.0, 9.0, 1.0, 180.0, 22.0, 26.0, 14.0, 177.0, 16.0, 7.0, 14.0, 16.0, 39.0, 10.0, 19.0, 12.0, 28.0, 21.0, 4.0, 17.0, 16.0, 16.0, 119.0, 152.0, 27.0, 17.0, 27.0, 6.0, 0.0, 6.0, 31.0, 16.0, 160.0, 5.0, 7.0, 10.0, 12.0, 18.0, 17.0, 19.0, 13.0, 15.0, 27.0, 15.0, 2.0, 18.0, 13.0, 11.0, 42.0, 39.0, 15.0, 11.0, 28.0, 7.0, 18.0, 16.0, 10.0, 11.0, 3.0, 4.0, 19.0, 18.0, 13.0, 12.0, 27.0, 19.0, 24.0, 27.0, 10.0, 13.0, 19.0, 34.0, 3.0, 150.0, 11.0, 7.0, 8.0, 9.0, 28.0, 35.0, 9.0, 12.0, 5.0, 9.0, 22.0, 18.0, 19.0, 12.0, 12.0, 4.0, 5.0, 8.0, 5.0, 13.0, 10.0, 13.0, 18.0, 18.0, 3.0, 12.0, 9.0, 14.0, 20.0, 14.0, 17.0, 27.0, 11.0, 14.0, 7.0, 7.0, 8.0, 9.0, 16.0, 21.0, 29.0, 31.0, 24.0, 8.0, 7.0, 18.0, 9.0, 1.0, 35.0, 35.0, 20.0, 10.0, 12.0, 28.0, 50.0, 33.0, 2.0, 38.0, 39.0, 18.0, 44.0, 44.0, 16.0, 20.0, 1.0, 25.0, 33.0, 51.0, 17.0, 10.0, 26.0, 38.0, 29.0, 26.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6020002866877833, "mean_inference_ms": 1.8629452002415274, "mean_action_processing_ms": 0.26125553245604133, "mean_env_wait_ms": 0.20170723110040634, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005541324615478516, "StateBufferConnector_ms": 0.003140091896057129, "ViewRequirementAgentConnector_ms": 0.09477782249450684}, "num_episodes": 18, "episode_return_max": 383.0, "episode_return_min": -486.69999999999953, "episode_return_mean": 279.2229999999999, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1184000, "num_agent_steps_trained": 1184000, "num_env_steps_sampled": 296000, "num_env_steps_trained": 296000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 361.49849485660434, "num_env_steps_trained_throughput_per_sec": 361.49849485660434, "timesteps_total": 296000, "num_env_steps_sampled_lifetime": 296000, "num_agent_steps_sampled_lifetime": 1184000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1184000, "timers": {"training_iteration_time_ms": 10748.654, "restore_workers_time_ms": 0.014, "training_step_time_ms": 10748.588, "sample_time_ms": 1248.768, "learn_time_ms": 9483.121, "learn_throughput": 421.802, "synch_weights_time_ms": 15.076}, "counters": {"num_env_steps_sampled": 296000, "num_env_steps_trained": 296000, "num_agent_steps_sampled": 1184000, "num_agent_steps_trained": 1184000}, "done": false, "training_iteration": 74, "trial_id": "3dae5_00000", "date": "2024-08-14_09-20-24", "timestamp": 1723641624, "time_this_iter_s": 11.092556953430176, "time_total_s": 2444.1531710624695, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3680160>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2444.1531710624695, "iterations_since_restore": 74, "perf": {"cpu_util_percent": 29.65, "ram_util_percent": 83.64999999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.494386934351038, "cur_kl_coeff": 0.056250000000000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.097064140738634, "policy_loss": -0.010455661846038999, "vf_loss": 4.106789323766396, "vf_explained_var": 0.0994327965552214, "kl": 0.012986421441577776, "entropy": 0.9638873967228743, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 140805.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.029108681628313, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.237188107374484, "policy_loss": 0.0017762969929242024, "vf_loss": 7.2306743339256005, "vf_explained_var": 0.5606363093726849, "kl": 0.02105543680149312, "entropy": 1.4551290887373465, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 140805.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 300000, "num_env_steps_trained": 300000, "num_agent_steps_sampled": 1200000, "num_agent_steps_trained": 1200000}, "env_runners": {"episode_reward_max": 391.3, "episode_reward_min": -486.69999999999953, "episode_reward_mean": 275.846, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -352.59999999999934, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 180.0}, "policy_reward_mean": {"prey_policy": 114.56800000000001, "predator_policy": 23.355}, "custom_metrics": {}, "hist_stats": {"episode_reward": [383.0, 367.79999999999995, 305.70000000000005, 244.59999999999997, 342.0, 357.4000000000001, 168.79999999999953, 370.0, 286.0, -486.69999999999953, 320.5, 23.200000000000003, 186.89999999999938, 153.39999999999952, 291.2, 160.69999999999953, 297.2, 107.79999999999994, 333.3, 71.30000000000001, 353.4, 316.3000000000002, 207.09999999999928, 286.5, 28.60000000000001, 325.79999999999995, 347.19999999999993, 343.3, 319.69999999999993, 319.59999999999997, 356.1, 352.59999999999997, 315.4, 364.5, 320.7, 353.3, 358.0, 32.30000000000018, 363.2, 187.9999999999994, 257.6, 343.3, 351.0, 279.0, 81.69999999999996, 357.7, 193.19999999999936, 313.0, 367.0, 366.0, 362.0, 304.7, 356.0, 196.39999999999938, 373.0, 367.2, 360.4, 340.0, 368.4, 350.0, 312.0, 359.0, 366.6, 344.7000000000001, 340.99999999999994, 289.0, 336.0, 184.09999999999928, 355.7, 295.4, 332.79999999999995, 329.0000000000001, 211.2, 302.9, 207.69999999999996, 208.99999999999997, 316.9, 311.10000000000025, 276.69999999999993, 177.39999999999935, 245.89999999999998, 295.10000000000014, 257.7, 325.2000000000001, 391.3, 288.19999999999993, 321.7000000000001, 310.29999999999995, 178.99999999999937, 255.69999999999996, 296.29999999999995, 161.79999999999995, 262.8, 276.2, 236.79999999999987, 179.69999999999996, 179.29999999999947, 279.70000000000005, 282.19999999999993, 278.20000000000005], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [200.0, 158.0, 146.0, 192.79999999999995, 79.7, 155.0, 86.6, 104.0, 161.0, 152.0, 164.0, 172.39999999999998, -5.1999999999999265, 143.0, 185.0, 170.0, 128.0, 116.0, -336.9999999999999, -330.69999999999993, 144.5, 128.0, -319.79999999999995, 152.0, 175.4, -11.499999999999819, 136.99999999999994, -13.599999999999783, 96.5, 145.70000000000002, 116.0, 13.699999999999966, 183.2, 65.0, 81.50000000000004, 5.299999999999965, 152.0, 149.3, 152.9, -352.59999999999934, 191.3, 118.1, 122.0, 161.29999999999998, 20.000000000000014, 181.1, 134.29999999999998, 105.2, 146.0, -282.3999999999996, 148.4, 160.4, 148.4, 168.79999999999995, 161.0, 146.3, 176.6, 115.10000000000002, 181.1, 96.5, 182.0, 154.1, 167.3, 161.3, 125.0, 109.4, 180.5, 158.0, 127.69999999999999, 158.0, 166.1, 153.2, 173.0, 164.0, 11.599999999999964, 13.699999999999964, 147.2, 179.0, 20.000000000000014, 143.0, 125.6, 86.0, 101.0, 191.3, 167.0, 161.0, 125.0, 101.0, -262.29999999999916, 191.0, 164.6, 175.1, 3.1999999999999615, 173.0, 164.0, 86.0, 190.4, 155.60000000000002, 177.2, 174.8, 128.0, 194.0, 142.7, 131.0, 176.0, 164.0, 20.000000000000014, 163.39999999999998, 164.0, 191.0, 171.2, 173.0, 189.2, 135.2, 161.0, 164.0, 156.2, 189.2, 176.0, 140.0, 161.0, 107.0, 161.0, 173.0, 177.2, 175.4, 151.7, 176.0, 134.9, 169.1, 88.7, 140.3, 128.0, 176.0, 20.000000000000014, 139.1, 167.3, 178.4, 133.4, 92.0, 134.0, 168.79999999999995, 150.49999999999997, 138.5, 56.0, 72.2, 91.1, 171.8, 55.70000000000001, 95.0, 53.6, 67.4, 140.6, 140.29999999999998, 134.59999999999994, 150.5, 176.29999999999998, 16.4, 20.000000000000014, 130.39999999999995, 51.5, 130.39999999999998, 118.4, 121.69999999999996, 119.0, 73.70000000000002, 126.19999999999995, 167.0, 200.0, 182.3, 60.80000000000001, 151.39999999999998, 172.7, 122.0, 175.1, 69.2, 138.5, 9.499999999999964, 84.2, 93.49999999999999, 137.29999999999998, 98.0, -24.099999999999994, 95.9, 87.8, 119.0, 140.0, 78.2, 78.80000000000001, 104.00000000000003, 0.5000000000000142, 72.19999999999999, 143.29999999999998, 20.000000000000014, 91.4, 116.3, 133.1, 103.09999999999998, 70.39999999999998, 153.79999999999995], "policy_predator_policy_reward": [11.0, 14.0, 11.0, 18.0, 32.0, 39.0, 46.0, 8.0, 16.0, 13.0, 7.0, 14.0, 16.0, 15.0, 7.0, 8.0, 33.0, 9.0, 1.0, 180.0, 22.0, 26.0, 14.0, 177.0, 16.0, 7.0, 14.0, 16.0, 39.0, 10.0, 19.0, 12.0, 28.0, 21.0, 4.0, 17.0, 16.0, 16.0, 119.0, 152.0, 27.0, 17.0, 27.0, 6.0, 0.0, 6.0, 31.0, 16.0, 160.0, 5.0, 7.0, 10.0, 12.0, 18.0, 17.0, 19.0, 13.0, 15.0, 27.0, 15.0, 2.0, 18.0, 13.0, 11.0, 42.0, 39.0, 15.0, 11.0, 28.0, 7.0, 18.0, 16.0, 10.0, 11.0, 3.0, 4.0, 19.0, 18.0, 13.0, 12.0, 27.0, 19.0, 24.0, 27.0, 10.0, 13.0, 19.0, 34.0, 3.0, 150.0, 11.0, 7.0, 8.0, 9.0, 28.0, 35.0, 9.0, 12.0, 5.0, 9.0, 22.0, 18.0, 19.0, 12.0, 12.0, 4.0, 5.0, 8.0, 5.0, 13.0, 10.0, 13.0, 18.0, 18.0, 3.0, 12.0, 9.0, 14.0, 20.0, 14.0, 17.0, 27.0, 11.0, 14.0, 7.0, 7.0, 8.0, 9.0, 16.0, 21.0, 29.0, 31.0, 24.0, 8.0, 7.0, 18.0, 9.0, 1.0, 35.0, 35.0, 20.0, 10.0, 12.0, 28.0, 50.0, 33.0, 2.0, 38.0, 39.0, 18.0, 44.0, 44.0, 16.0, 20.0, 1.0, 25.0, 33.0, 51.0, 17.0, 10.0, 26.0, 38.0, 29.0, 26.0, 11.0, 54.0, 11.0, 21.0, 4.0, 5.0, 37.0, 39.0, 4.0, 23.0, 22.0, 44.0, 16.0, 15.0, 38.0, 40.0, 33.0, 28.0, 46.0, 44.0, 44.0, 12.0, 37.0, 21.0, 48.0, 6.0, 68.0, 39.0, 12.0, 4.0, 35.0, 37.0, 14.0, 32.0, 42.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6011733192463954, "mean_inference_ms": 1.8600754740239482, "mean_action_processing_ms": 0.26078537159644816, "mean_env_wait_ms": 0.20140542431622832, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0049135684967041016, "StateBufferConnector_ms": 0.0031414031982421875, "ViewRequirementAgentConnector_ms": 0.09271872043609619}, "num_episodes": 18, "episode_return_max": 391.3, "episode_return_min": -486.69999999999953, "episode_return_mean": 275.846, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1200000, "num_agent_steps_trained": 1200000, "num_env_steps_sampled": 300000, "num_env_steps_trained": 300000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 341.41222656391017, "num_env_steps_trained_throughput_per_sec": 341.41222656391017, "timesteps_total": 300000, "num_env_steps_sampled_lifetime": 300000, "num_agent_steps_sampled_lifetime": 1200000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1200000, "timers": {"training_iteration_time_ms": 10869.755, "restore_workers_time_ms": 0.014, "training_step_time_ms": 10869.689, "sample_time_ms": 1257.746, "learn_time_ms": 9595.098, "learn_throughput": 416.88, "synch_weights_time_ms": 15.178}, "counters": {"num_env_steps_sampled": 300000, "num_env_steps_trained": 300000, "num_agent_steps_sampled": 1200000, "num_agent_steps_trained": 1200000}, "done": false, "training_iteration": 75, "trial_id": "3dae5_00000", "date": "2024-08-14_09-20-36", "timestamp": 1723641636, "time_this_iter_s": 11.76737093925476, "time_total_s": 2455.9205420017242, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3680c10>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2455.9205420017242, "iterations_since_restore": 75, "perf": {"cpu_util_percent": 37.08823529411765, "ram_util_percent": 83.48823529411764}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.623526024629199, "cur_kl_coeff": 0.056250000000000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.940393916513554, "policy_loss": -0.0119094504887317, "vf_loss": 3.9513654413677397, "vf_explained_var": 0.051325358537139085, "kl": 0.016674360220305086, "entropy": 0.9145909510276936, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 142695.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.1089547909441446, "cur_kl_coeff": 0.3375, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.2611440345723794, "policy_loss": 0.008930374942375002, "vf_loss": 7.243258302678507, "vf_explained_var": 0.45788607124298336, "kl": 0.026534329944443838, "entropy": 1.4489741361961164, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 142695.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 304000, "num_env_steps_trained": 304000, "num_agent_steps_sampled": 1216000, "num_agent_steps_trained": 1216000}, "env_runners": {"episode_reward_max": 391.3, "episode_reward_min": 6.800000000000164, "episode_reward_mean": 276.7459999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -282.3999999999996, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 160.0}, "policy_reward_mean": {"prey_policy": 115.76299999999999, "predator_policy": 22.61}, "custom_metrics": {}, "hist_stats": {"episode_reward": [207.09999999999928, 286.5, 28.60000000000001, 325.79999999999995, 347.19999999999993, 343.3, 319.69999999999993, 319.59999999999997, 356.1, 352.59999999999997, 315.4, 364.5, 320.7, 353.3, 358.0, 32.30000000000018, 363.2, 187.9999999999994, 257.6, 343.3, 351.0, 279.0, 81.69999999999996, 357.7, 193.19999999999936, 313.0, 367.0, 366.0, 362.0, 304.7, 356.0, 196.39999999999938, 373.0, 367.2, 360.4, 340.0, 368.4, 350.0, 312.0, 359.0, 366.6, 344.7000000000001, 340.99999999999994, 289.0, 336.0, 184.09999999999928, 355.7, 295.4, 332.79999999999995, 329.0000000000001, 211.2, 302.9, 207.69999999999996, 208.99999999999997, 316.9, 311.10000000000025, 276.69999999999993, 177.39999999999935, 245.89999999999998, 295.10000000000014, 257.7, 325.2000000000001, 391.3, 288.19999999999993, 321.7000000000001, 310.29999999999995, 178.99999999999937, 255.69999999999996, 296.29999999999995, 161.79999999999995, 262.8, 276.2, 236.79999999999987, 179.69999999999996, 179.29999999999947, 279.70000000000005, 282.19999999999993, 278.20000000000005, 364.0, 299.1, 89.89999999999992, 83.29999999999988, 269.40000000000003, 383.29999999999995, 193.69999999999933, 184.3999999999999, 237.69999999999996, 6.800000000000164, 193.79999999999936, 249.59999999999997, 338.70000000000005, 148.69999999999965, 167.09999999999937, 179.5, 353.0, 270.50000000000006, 269.59999999999997, 256.79999999999995, 254.2, 250.69999999999996], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 181.1, 134.29999999999998, 105.2, 146.0, -282.3999999999996, 148.4, 160.4, 148.4, 168.79999999999995, 161.0, 146.3, 176.6, 115.10000000000002, 181.1, 96.5, 182.0, 154.1, 167.3, 161.3, 125.0, 109.4, 180.5, 158.0, 127.69999999999999, 158.0, 166.1, 153.2, 173.0, 164.0, 11.599999999999964, 13.699999999999964, 147.2, 179.0, 20.000000000000014, 143.0, 125.6, 86.0, 101.0, 191.3, 167.0, 161.0, 125.0, 101.0, -262.29999999999916, 191.0, 164.6, 175.1, 3.1999999999999615, 173.0, 164.0, 86.0, 190.4, 155.60000000000002, 177.2, 174.8, 128.0, 194.0, 142.7, 131.0, 176.0, 164.0, 20.000000000000014, 163.39999999999998, 164.0, 191.0, 171.2, 173.0, 189.2, 135.2, 161.0, 164.0, 156.2, 189.2, 176.0, 140.0, 161.0, 107.0, 161.0, 173.0, 177.2, 175.4, 151.7, 176.0, 134.9, 169.1, 88.7, 140.3, 128.0, 176.0, 20.000000000000014, 139.1, 167.3, 178.4, 133.4, 92.0, 134.0, 168.79999999999995, 150.49999999999997, 138.5, 56.0, 72.2, 91.1, 171.8, 55.70000000000001, 95.0, 53.6, 67.4, 140.6, 140.29999999999998, 134.59999999999994, 150.5, 176.29999999999998, 16.4, 20.000000000000014, 130.39999999999995, 51.5, 130.39999999999998, 118.4, 121.69999999999996, 119.0, 73.70000000000002, 126.19999999999995, 167.0, 200.0, 182.3, 60.80000000000001, 151.39999999999998, 172.7, 122.0, 175.1, 69.2, 138.5, 9.499999999999964, 84.2, 93.49999999999999, 137.29999999999998, 98.0, -24.099999999999994, 95.9, 87.8, 119.0, 140.0, 78.2, 78.80000000000001, 104.00000000000003, 0.5000000000000142, 72.19999999999999, 143.29999999999998, 20.000000000000014, 91.4, 116.3, 133.1, 103.09999999999998, 70.39999999999998, 153.79999999999995, 158.0, 170.0, 148.1, 118.99999999999999, 15.200000000000003, 13.699999999999964, -156.40000000000066, 136.69999999999996, 99.19999999999999, 96.2, 197.3, 170.0, 20.000000000000014, 136.70000000000002, 129.79999999999998, -45.40000000000006, 126.49999999999997, 30.200000000000003, -3.099999999999958, -3.099999999999958, 159.79999999999998, 20.000000000000014, 71.60000000000001, 119.0, 152.29999999999998, 160.4, 112.70000000000002, -0.9999999999999846, 140.59999999999997, 9.499999999999964, -89.5, 164.0, 190.1, 143.89999999999998, 111.49999999999996, 83.0, 134.59999999999997, 74.0, 97.10000000000002, 94.70000000000002, 35.0, 150.2, 63.50000000000003, 117.20000000000002], "policy_predator_policy_reward": [0.0, 6.0, 31.0, 16.0, 160.0, 5.0, 7.0, 10.0, 12.0, 18.0, 17.0, 19.0, 13.0, 15.0, 27.0, 15.0, 2.0, 18.0, 13.0, 11.0, 42.0, 39.0, 15.0, 11.0, 28.0, 7.0, 18.0, 16.0, 10.0, 11.0, 3.0, 4.0, 19.0, 18.0, 13.0, 12.0, 27.0, 19.0, 24.0, 27.0, 10.0, 13.0, 19.0, 34.0, 3.0, 150.0, 11.0, 7.0, 8.0, 9.0, 28.0, 35.0, 9.0, 12.0, 5.0, 9.0, 22.0, 18.0, 19.0, 12.0, 12.0, 4.0, 5.0, 8.0, 5.0, 13.0, 10.0, 13.0, 18.0, 18.0, 3.0, 12.0, 9.0, 14.0, 20.0, 14.0, 17.0, 27.0, 11.0, 14.0, 7.0, 7.0, 8.0, 9.0, 16.0, 21.0, 29.0, 31.0, 24.0, 8.0, 7.0, 18.0, 9.0, 1.0, 35.0, 35.0, 20.0, 10.0, 12.0, 28.0, 50.0, 33.0, 2.0, 38.0, 39.0, 18.0, 44.0, 44.0, 16.0, 20.0, 1.0, 25.0, 33.0, 51.0, 17.0, 10.0, 26.0, 38.0, 29.0, 26.0, 11.0, 54.0, 11.0, 21.0, 4.0, 5.0, 37.0, 39.0, 4.0, 23.0, 22.0, 44.0, 16.0, 15.0, 38.0, 40.0, 33.0, 28.0, 46.0, 44.0, 44.0, 12.0, 37.0, 21.0, 48.0, 6.0, 68.0, 39.0, 12.0, 4.0, 35.0, 37.0, 14.0, 32.0, 42.0, 12.0, 19.0, 17.0, 11.0, 21.0, 50.0, 11.0, 84.0, 19.0, 36.0, 38.0, 9.0, 7.0, 18.0, 19.0, 56.0, 44.0, 60.0, 21.0, 12.0, 1.0, 9.0, 5.0, 29.0, 30.0, 21.0, 5.0, 32.0, 5.0, 11.0, 6.0, 42.0, 63.0, 3.0, 16.0, 45.0, 31.0, 19.0, 42.0, 29.0, 36.0, 56.0, 13.0, 16.0, 54.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6003142696412868, "mean_inference_ms": 1.8571460913445912, "mean_action_processing_ms": 0.25963949433833106, "mean_env_wait_ms": 0.20123278301550077, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004319310188293457, "StateBufferConnector_ms": 0.0031365156173706055, "ViewRequirementAgentConnector_ms": 0.09297752380371094}, "num_episodes": 22, "episode_return_max": 391.3, "episode_return_min": 6.800000000000164, "episode_return_mean": 276.7459999999999, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1216000, "num_agent_steps_trained": 1216000, "num_env_steps_sampled": 304000, "num_env_steps_trained": 304000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 371.78294006072815, "num_env_steps_trained_throughput_per_sec": 371.78294006072815, "timesteps_total": 304000, "num_env_steps_sampled_lifetime": 304000, "num_agent_steps_sampled_lifetime": 1216000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1216000, "timers": {"training_iteration_time_ms": 10879.439, "restore_workers_time_ms": 0.014, "training_step_time_ms": 10879.373, "sample_time_ms": 1266.623, "learn_time_ms": 9595.711, "learn_throughput": 416.853, "synch_weights_time_ms": 15.403}, "counters": {"num_env_steps_sampled": 304000, "num_env_steps_trained": 304000, "num_agent_steps_sampled": 1216000, "num_agent_steps_trained": 1216000}, "done": false, "training_iteration": 76, "trial_id": "3dae5_00000", "date": "2024-08-14_09-20-47", "timestamp": 1723641647, "time_this_iter_s": 10.764863967895508, "time_total_s": 2466.6854059696198, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b36b6040>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2466.6854059696198, "iterations_since_restore": 76, "perf": {"cpu_util_percent": 30.053333333333335, "ram_util_percent": 83.59333333333332}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.63155620318872, "cur_kl_coeff": 0.056250000000000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.843264124002406, "policy_loss": -0.009542695679529398, "vf_loss": 3.8519745280502966, "vf_explained_var": 0.037706227403469184, "kl": 0.01479609016458977, "entropy": 0.8784828110977455, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 144585.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.119643168001579, "cur_kl_coeff": 0.5062499999999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.6708295388196515, "policy_loss": 0.010761384349242445, "vf_loss": 6.650668554457408, "vf_explained_var": 0.4640938266875252, "kl": 0.018567077762027512, "entropy": 1.4678922192129509, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 144585.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 308000, "num_env_steps_trained": 308000, "num_agent_steps_sampled": 1232000, "num_agent_steps_trained": 1232000}, "env_runners": {"episode_reward_max": 391.3, "episode_reward_min": 6.800000000000164, "episode_reward_mean": 270.78, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -262.29999999999916, "predator_policy": 1.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 150.0}, "policy_reward_mean": {"prey_policy": 110.495, "predator_policy": 24.895}, "custom_metrics": {}, "hist_stats": {"episode_reward": [257.6, 343.3, 351.0, 279.0, 81.69999999999996, 357.7, 193.19999999999936, 313.0, 367.0, 366.0, 362.0, 304.7, 356.0, 196.39999999999938, 373.0, 367.2, 360.4, 340.0, 368.4, 350.0, 312.0, 359.0, 366.6, 344.7000000000001, 340.99999999999994, 289.0, 336.0, 184.09999999999928, 355.7, 295.4, 332.79999999999995, 329.0000000000001, 211.2, 302.9, 207.69999999999996, 208.99999999999997, 316.9, 311.10000000000025, 276.69999999999993, 177.39999999999935, 245.89999999999998, 295.10000000000014, 257.7, 325.2000000000001, 391.3, 288.19999999999993, 321.7000000000001, 310.29999999999995, 178.99999999999937, 255.69999999999996, 296.29999999999995, 161.79999999999995, 262.8, 276.2, 236.79999999999987, 179.69999999999996, 179.29999999999947, 279.70000000000005, 282.19999999999993, 278.20000000000005, 364.0, 299.1, 89.89999999999992, 83.29999999999988, 269.40000000000003, 383.29999999999995, 193.69999999999933, 184.3999999999999, 237.69999999999996, 6.800000000000164, 193.79999999999936, 249.59999999999997, 338.70000000000005, 148.69999999999965, 167.09999999999937, 179.5, 353.0, 270.50000000000006, 269.59999999999997, 256.79999999999995, 254.2, 250.69999999999996, 162.39999999999935, 156.3999999999999, 333.20000000000005, 202.89999999999986, 310.5, 190.49999999999997, 369.0000000000001, 178.29999999999941, 251.89999999999998, 185.20000000000002, 300.29999999999995, 336.80000000000024, 321.0000000000002, 204.29999999999998, 235.9, 283.7999999999999, 327.70000000000016, 235.2], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [125.6, 86.0, 101.0, 191.3, 167.0, 161.0, 125.0, 101.0, -262.29999999999916, 191.0, 164.6, 175.1, 3.1999999999999615, 173.0, 164.0, 86.0, 190.4, 155.60000000000002, 177.2, 174.8, 128.0, 194.0, 142.7, 131.0, 176.0, 164.0, 20.000000000000014, 163.39999999999998, 164.0, 191.0, 171.2, 173.0, 189.2, 135.2, 161.0, 164.0, 156.2, 189.2, 176.0, 140.0, 161.0, 107.0, 161.0, 173.0, 177.2, 175.4, 151.7, 176.0, 134.9, 169.1, 88.7, 140.3, 128.0, 176.0, 20.000000000000014, 139.1, 167.3, 178.4, 133.4, 92.0, 134.0, 168.79999999999995, 150.49999999999997, 138.5, 56.0, 72.2, 91.1, 171.8, 55.70000000000001, 95.0, 53.6, 67.4, 140.6, 140.29999999999998, 134.59999999999994, 150.5, 176.29999999999998, 16.4, 20.000000000000014, 130.39999999999995, 51.5, 130.39999999999998, 118.4, 121.69999999999996, 119.0, 73.70000000000002, 126.19999999999995, 167.0, 200.0, 182.3, 60.80000000000001, 151.39999999999998, 172.7, 122.0, 175.1, 69.2, 138.5, 9.499999999999964, 84.2, 93.49999999999999, 137.29999999999998, 98.0, -24.099999999999994, 95.9, 87.8, 119.0, 140.0, 78.2, 78.80000000000001, 104.00000000000003, 0.5000000000000142, 72.19999999999999, 143.29999999999998, 20.000000000000014, 91.4, 116.3, 133.1, 103.09999999999998, 70.39999999999998, 153.79999999999995, 158.0, 170.0, 148.1, 118.99999999999999, 15.200000000000003, 13.699999999999964, -156.40000000000066, 136.69999999999996, 99.19999999999999, 96.2, 197.3, 170.0, 20.000000000000014, 136.70000000000002, 129.79999999999998, -45.40000000000006, 126.49999999999997, 30.200000000000003, -3.099999999999958, -3.099999999999958, 159.79999999999998, 20.000000000000014, 71.60000000000001, 119.0, 152.29999999999998, 160.4, 112.70000000000002, -0.9999999999999846, 140.59999999999997, 9.499999999999964, -89.5, 164.0, 190.1, 143.89999999999998, 111.49999999999996, 83.0, 134.59999999999997, 74.0, 97.10000000000002, 94.70000000000002, 35.0, 150.2, 63.50000000000003, 117.20000000000002, 100.39999999999998, 20.000000000000014, 40.40000000000001, -25.0, 162.2, 128.0, 98.30000000000001, 14.599999999999996, 96.2, 119.29999999999998, 170.29999999999993, -104.80000000000001, 155.59999999999997, 190.39999999999998, 20.000000000000014, 122.29999999999998, 160.1, 12.800000000000008, 4.100000000000001, 94.10000000000001, 91.7, 143.5999999999999, 167.59999999999997, 153.19999999999993, 154.39999999999998, 143.5999999999999, 109.7, 32.6, 24.200000000000003, 124.69999999999999, 89.60000000000002, 165.2, 144.2, 156.49999999999997, 50.3, 116.89999999999999], "policy_predator_policy_reward": [27.0, 19.0, 24.0, 27.0, 10.0, 13.0, 19.0, 34.0, 3.0, 150.0, 11.0, 7.0, 8.0, 9.0, 28.0, 35.0, 9.0, 12.0, 5.0, 9.0, 22.0, 18.0, 19.0, 12.0, 12.0, 4.0, 5.0, 8.0, 5.0, 13.0, 10.0, 13.0, 18.0, 18.0, 3.0, 12.0, 9.0, 14.0, 20.0, 14.0, 17.0, 27.0, 11.0, 14.0, 7.0, 7.0, 8.0, 9.0, 16.0, 21.0, 29.0, 31.0, 24.0, 8.0, 7.0, 18.0, 9.0, 1.0, 35.0, 35.0, 20.0, 10.0, 12.0, 28.0, 50.0, 33.0, 2.0, 38.0, 39.0, 18.0, 44.0, 44.0, 16.0, 20.0, 1.0, 25.0, 33.0, 51.0, 17.0, 10.0, 26.0, 38.0, 29.0, 26.0, 11.0, 54.0, 11.0, 21.0, 4.0, 5.0, 37.0, 39.0, 4.0, 23.0, 22.0, 44.0, 16.0, 15.0, 38.0, 40.0, 33.0, 28.0, 46.0, 44.0, 44.0, 12.0, 37.0, 21.0, 48.0, 6.0, 68.0, 39.0, 12.0, 4.0, 35.0, 37.0, 14.0, 32.0, 42.0, 12.0, 19.0, 17.0, 11.0, 21.0, 50.0, 11.0, 84.0, 19.0, 36.0, 38.0, 9.0, 7.0, 18.0, 19.0, 56.0, 44.0, 60.0, 21.0, 12.0, 1.0, 9.0, 5.0, 29.0, 30.0, 21.0, 5.0, 32.0, 5.0, 11.0, 6.0, 42.0, 63.0, 3.0, 16.0, 45.0, 31.0, 19.0, 42.0, 29.0, 36.0, 56.0, 13.0, 16.0, 54.0, 17.0, 25.0, 62.0, 79.0, 25.0, 18.0, 39.0, 51.0, 53.0, 42.0, 74.0, 51.0, 11.0, 12.0, 25.0, 11.0, 24.0, 55.0, 42.0, 45.0, 47.0, 18.0, 4.0, 12.0, 14.0, 9.0, 1.0, 61.0, 57.0, 30.0, 22.0, 7.0, 11.0, 16.0, 23.0, 45.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5998081058983408, "mean_inference_ms": 1.855322590702687, "mean_action_processing_ms": 0.25988480621978494, "mean_env_wait_ms": 0.20092774956243217, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0037615299224853516, "StateBufferConnector_ms": 0.003032684326171875, "ViewRequirementAgentConnector_ms": 0.09222793579101562}, "num_episodes": 18, "episode_return_max": 391.3, "episode_return_min": 6.800000000000164, "episode_return_mean": 270.78, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1232000, "num_agent_steps_trained": 1232000, "num_env_steps_sampled": 308000, "num_env_steps_trained": 308000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 375.1332413545389, "num_env_steps_trained_throughput_per_sec": 375.1332413545389, "timesteps_total": 308000, "num_env_steps_sampled_lifetime": 308000, "num_agent_steps_sampled_lifetime": 1232000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1232000, "timers": {"training_iteration_time_ms": 10864.612, "restore_workers_time_ms": 0.014, "training_step_time_ms": 10864.545, "sample_time_ms": 1272.125, "learn_time_ms": 9574.927, "learn_throughput": 417.758, "synch_weights_time_ms": 15.825}, "counters": {"num_env_steps_sampled": 308000, "num_env_steps_trained": 308000, "num_agent_steps_sampled": 1232000, "num_agent_steps_trained": 1232000}, "done": false, "training_iteration": 77, "trial_id": "3dae5_00000", "date": "2024-08-14_09-20-58", "timestamp": 1723641658, "time_this_iter_s": 10.669594049453735, "time_total_s": 2477.3550000190735, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b36b6430>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2477.3550000190735, "iterations_since_restore": 77, "perf": {"cpu_util_percent": 29.046666666666667, "ram_util_percent": 83.56}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.195906461735881, "cur_kl_coeff": 0.056250000000000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.083254868643625, "policy_loss": -0.007680480383711044, "vf_loss": 4.0904091944770204, "vf_explained_var": 0.03723538070128708, "kl": 0.009353753155610043, "entropy": 0.8286295272685863, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 146475.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.3828734456231353, "cur_kl_coeff": 0.5062499999999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.483196561298673, "policy_loss": -0.006897742787829389, "vf_loss": 6.486733363418983, "vf_explained_var": 0.49582007498968217, "kl": 0.006638919881407149, "entropy": 1.4139221299262275, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 146475.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 312000, "num_env_steps_trained": 312000, "num_agent_steps_sampled": 1248000, "num_agent_steps_trained": 1248000}, "env_runners": {"episode_reward_max": 391.3, "episode_reward_min": 6.800000000000164, "episode_reward_mean": 248.77399999999992, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -156.40000000000066, "predator_policy": 1.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 87.0}, "policy_reward_mean": {"prey_policy": 96.93199999999997, "predator_policy": 27.455}, "custom_metrics": {}, "hist_stats": {"episode_reward": [344.7000000000001, 340.99999999999994, 289.0, 336.0, 184.09999999999928, 355.7, 295.4, 332.79999999999995, 329.0000000000001, 211.2, 302.9, 207.69999999999996, 208.99999999999997, 316.9, 311.10000000000025, 276.69999999999993, 177.39999999999935, 245.89999999999998, 295.10000000000014, 257.7, 325.2000000000001, 391.3, 288.19999999999993, 321.7000000000001, 310.29999999999995, 178.99999999999937, 255.69999999999996, 296.29999999999995, 161.79999999999995, 262.8, 276.2, 236.79999999999987, 179.69999999999996, 179.29999999999947, 279.70000000000005, 282.19999999999993, 278.20000000000005, 364.0, 299.1, 89.89999999999992, 83.29999999999988, 269.40000000000003, 383.29999999999995, 193.69999999999933, 184.3999999999999, 237.69999999999996, 6.800000000000164, 193.79999999999936, 249.59999999999997, 338.70000000000005, 148.69999999999965, 167.09999999999937, 179.5, 353.0, 270.50000000000006, 269.59999999999997, 256.79999999999995, 254.2, 250.69999999999996, 162.39999999999935, 156.3999999999999, 333.20000000000005, 202.89999999999986, 310.5, 190.49999999999997, 369.0000000000001, 178.29999999999941, 251.89999999999998, 185.20000000000002, 300.29999999999995, 336.80000000000024, 321.0000000000002, 204.29999999999998, 235.9, 283.7999999999999, 327.70000000000016, 235.2, 168.89999999999972, 216.9999999999999, 301.3000000000004, 271.50000000000045, 173.99999999999932, 269.5, 285.5, 294.4999999999998, 266.3999999999999, 128.89999999999978, 145.89999999999938, 198.79999999999927, 321.3000000000004, 221.4999999999999, 259.8, 227.1999999999999, 124.79999999999964, 335.79999999999995, 252.6999999999998, 141.89999999999998, 175.2999999999994, 319.49999999999994, 22.600000000000012], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [151.7, 176.0, 134.9, 169.1, 88.7, 140.3, 128.0, 176.0, 20.000000000000014, 139.1, 167.3, 178.4, 133.4, 92.0, 134.0, 168.79999999999995, 150.49999999999997, 138.5, 56.0, 72.2, 91.1, 171.8, 55.70000000000001, 95.0, 53.6, 67.4, 140.6, 140.29999999999998, 134.59999999999994, 150.5, 176.29999999999998, 16.4, 20.000000000000014, 130.39999999999995, 51.5, 130.39999999999998, 118.4, 121.69999999999996, 119.0, 73.70000000000002, 126.19999999999995, 167.0, 200.0, 182.3, 60.80000000000001, 151.39999999999998, 172.7, 122.0, 175.1, 69.2, 138.5, 9.499999999999964, 84.2, 93.49999999999999, 137.29999999999998, 98.0, -24.099999999999994, 95.9, 87.8, 119.0, 140.0, 78.2, 78.80000000000001, 104.00000000000003, 0.5000000000000142, 72.19999999999999, 143.29999999999998, 20.000000000000014, 91.4, 116.3, 133.1, 103.09999999999998, 70.39999999999998, 153.79999999999995, 158.0, 170.0, 148.1, 118.99999999999999, 15.200000000000003, 13.699999999999964, -156.40000000000066, 136.69999999999996, 99.19999999999999, 96.2, 197.3, 170.0, 20.000000000000014, 136.70000000000002, 129.79999999999998, -45.40000000000006, 126.49999999999997, 30.200000000000003, -3.099999999999958, -3.099999999999958, 159.79999999999998, 20.000000000000014, 71.60000000000001, 119.0, 152.29999999999998, 160.4, 112.70000000000002, -0.9999999999999846, 140.59999999999997, 9.499999999999964, -89.5, 164.0, 190.1, 143.89999999999998, 111.49999999999996, 83.0, 134.59999999999997, 74.0, 97.10000000000002, 94.70000000000002, 35.0, 150.2, 63.50000000000003, 117.20000000000002, 100.39999999999998, 20.000000000000014, 40.40000000000001, -25.0, 162.2, 128.0, 98.30000000000001, 14.599999999999996, 96.2, 119.29999999999998, 170.29999999999993, -104.80000000000001, 155.59999999999997, 190.39999999999998, 20.000000000000014, 122.29999999999998, 160.1, 12.800000000000008, 4.100000000000001, 94.10000000000001, 91.7, 143.5999999999999, 167.59999999999997, 153.19999999999993, 154.39999999999998, 143.5999999999999, 109.7, 32.6, 24.200000000000003, 124.69999999999999, 89.60000000000002, 165.2, 144.2, 156.49999999999997, 50.3, 116.89999999999999, 43.70000000000006, 60.200000000000045, 1.3999999999999844, 140.59999999999997, 163.0999999999998, 45.20000000000002, 97.99999999999991, 156.49999999999986, 116.29999999999995, 13.699999999999964, 192.79999999999995, -34.29999999999999, 93.2, 113.29999999999998, 112.4, 136.09999999999997, 19.39999999999994, 154.99999999999997, 95.5999999999997, -51.70000000000005, 11.599999999999964, 89.29999999999993, 20.000000000000014, 171.79999999999998, 144.49999999999991, 156.79999999999978, 120.19999999999993, 29.299999999999997, 49.70000000000001, 145.1, 134.3, 50.90000000000001, 20.000000000000014, 36.79999999999998, 171.79999999999993, 142.99999999999997, 38.599999999999994, 157.09999999999988, -37.00000000000008, 35.89999999999999, 7.399999999999965, 143.89999999999995, 143.60000000000002, 155.89999999999998, 5.299999999999965, 5.299999999999965], "policy_predator_policy_reward": [8.0, 9.0, 16.0, 21.0, 29.0, 31.0, 24.0, 8.0, 7.0, 18.0, 9.0, 1.0, 35.0, 35.0, 20.0, 10.0, 12.0, 28.0, 50.0, 33.0, 2.0, 38.0, 39.0, 18.0, 44.0, 44.0, 16.0, 20.0, 1.0, 25.0, 33.0, 51.0, 17.0, 10.0, 26.0, 38.0, 29.0, 26.0, 11.0, 54.0, 11.0, 21.0, 4.0, 5.0, 37.0, 39.0, 4.0, 23.0, 22.0, 44.0, 16.0, 15.0, 38.0, 40.0, 33.0, 28.0, 46.0, 44.0, 44.0, 12.0, 37.0, 21.0, 48.0, 6.0, 68.0, 39.0, 12.0, 4.0, 35.0, 37.0, 14.0, 32.0, 42.0, 12.0, 19.0, 17.0, 11.0, 21.0, 50.0, 11.0, 84.0, 19.0, 36.0, 38.0, 9.0, 7.0, 18.0, 19.0, 56.0, 44.0, 60.0, 21.0, 12.0, 1.0, 9.0, 5.0, 29.0, 30.0, 21.0, 5.0, 32.0, 5.0, 11.0, 6.0, 42.0, 63.0, 3.0, 16.0, 45.0, 31.0, 19.0, 42.0, 29.0, 36.0, 56.0, 13.0, 16.0, 54.0, 17.0, 25.0, 62.0, 79.0, 25.0, 18.0, 39.0, 51.0, 53.0, 42.0, 74.0, 51.0, 11.0, 12.0, 25.0, 11.0, 24.0, 55.0, 42.0, 45.0, 47.0, 18.0, 4.0, 12.0, 14.0, 9.0, 1.0, 61.0, 57.0, 30.0, 22.0, 7.0, 11.0, 16.0, 23.0, 45.0, 37.0, 28.0, 13.0, 62.0, 46.0, 47.0, 8.0, 9.0, 21.0, 23.0, 64.0, 47.0, 35.0, 44.0, 24.0, 22.0, 43.0, 49.0, 77.0, 8.0, 25.0, 20.0, 3.0, 4.0, 9.0, 11.0, 23.0, 49.0, 42.0, 23.0, 20.0, 22.0, 29.0, 39.0, 11.0, 10.0, 49.0, 8.0, 87.0, 56.0, 13.0, 11.0, 14.0, 6.0, 7.0, 5.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5994592170698764, "mean_inference_ms": 1.8534147570051036, "mean_action_processing_ms": 0.2594389312488811, "mean_env_wait_ms": 0.20074467583334346, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0036777257919311523, "StateBufferConnector_ms": 0.0031827688217163086, "ViewRequirementAgentConnector_ms": 0.10299932956695557}, "num_episodes": 23, "episode_return_max": 391.3, "episode_return_min": 6.800000000000164, "episode_return_mean": 248.77399999999992, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1248000, "num_agent_steps_trained": 1248000, "num_env_steps_sampled": 312000, "num_env_steps_trained": 312000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 364.53161918549733, "num_env_steps_trained_throughput_per_sec": 364.53161918549733, "timesteps_total": 312000, "num_env_steps_sampled_lifetime": 312000, "num_agent_steps_sampled_lifetime": 1248000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1248000, "timers": {"training_iteration_time_ms": 10910.522, "restore_workers_time_ms": 0.014, "training_step_time_ms": 10910.454, "sample_time_ms": 1286.595, "learn_time_ms": 9606.517, "learn_throughput": 416.384, "synch_weights_time_ms": 15.655}, "counters": {"num_env_steps_sampled": 312000, "num_env_steps_trained": 312000, "num_agent_steps_sampled": 1248000, "num_agent_steps_trained": 1248000}, "done": false, "training_iteration": 78, "trial_id": "3dae5_00000", "date": "2024-08-14_09-21-09", "timestamp": 1723641669, "time_this_iter_s": 10.992026090621948, "time_total_s": 2488.3470261096954, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b36b6e50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2488.3470261096954, "iterations_since_restore": 78, "perf": {"cpu_util_percent": 31.50625, "ram_util_percent": 83.525}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.210891434912959, "cur_kl_coeff": 0.056250000000000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.7204217148836327, "policy_loss": -0.007680189938200687, "vf_loss": 2.7275462212385952, "vf_explained_var": 0.04603949419405094, "kl": 0.009878806226003635, "entropy": 0.7624238611844482, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 148365.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.492142684245236, "cur_kl_coeff": 0.5062499999999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.51504073546677, "policy_loss": -0.006527178946675526, "vf_loss": 5.518212582068468, "vf_explained_var": 0.7269936167689227, "kl": 0.006627805078181034, "entropy": 1.4153758700562533, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 148365.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 316000, "num_env_steps_trained": 316000, "num_agent_steps_sampled": 1264000, "num_agent_steps_trained": 1264000}, "env_runners": {"episode_reward_max": 391.3, "episode_reward_min": 6.800000000000164, "episode_reward_mean": 235.65599999999986, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -156.40000000000066, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 87.0}, "policy_reward_mean": {"prey_policy": 89.79799999999996, "predator_policy": 28.03}, "custom_metrics": {}, "hist_stats": {"episode_reward": [295.10000000000014, 257.7, 325.2000000000001, 391.3, 288.19999999999993, 321.7000000000001, 310.29999999999995, 178.99999999999937, 255.69999999999996, 296.29999999999995, 161.79999999999995, 262.8, 276.2, 236.79999999999987, 179.69999999999996, 179.29999999999947, 279.70000000000005, 282.19999999999993, 278.20000000000005, 364.0, 299.1, 89.89999999999992, 83.29999999999988, 269.40000000000003, 383.29999999999995, 193.69999999999933, 184.3999999999999, 237.69999999999996, 6.800000000000164, 193.79999999999936, 249.59999999999997, 338.70000000000005, 148.69999999999965, 167.09999999999937, 179.5, 353.0, 270.50000000000006, 269.59999999999997, 256.79999999999995, 254.2, 250.69999999999996, 162.39999999999935, 156.3999999999999, 333.20000000000005, 202.89999999999986, 310.5, 190.49999999999997, 369.0000000000001, 178.29999999999941, 251.89999999999998, 185.20000000000002, 300.29999999999995, 336.80000000000024, 321.0000000000002, 204.29999999999998, 235.9, 283.7999999999999, 327.70000000000016, 235.2, 168.89999999999972, 216.9999999999999, 301.3000000000004, 271.50000000000045, 173.99999999999932, 269.5, 285.5, 294.4999999999998, 266.3999999999999, 128.89999999999978, 145.89999999999938, 198.79999999999927, 321.3000000000004, 221.4999999999999, 259.8, 227.1999999999999, 124.79999999999964, 335.79999999999995, 252.6999999999998, 141.89999999999998, 175.2999999999994, 319.49999999999994, 22.600000000000012, 275.7000000000003, 288.89999999999975, 327.1, 97.19999999999965, 105.99999999999977, 267.1999999999998, 282.3000000000002, 286.10000000000014, 152.19999999999956, 149.99999999999937, 226.29999999999993, 88.80000000000011, 284.19999999999976, 313.4000000000002, 35.600000000000236, 329.9000000000008, 96.39999999999998, 147.3999999999991], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [118.4, 121.69999999999996, 119.0, 73.70000000000002, 126.19999999999995, 167.0, 200.0, 182.3, 60.80000000000001, 151.39999999999998, 172.7, 122.0, 175.1, 69.2, 138.5, 9.499999999999964, 84.2, 93.49999999999999, 137.29999999999998, 98.0, -24.099999999999994, 95.9, 87.8, 119.0, 140.0, 78.2, 78.80000000000001, 104.00000000000003, 0.5000000000000142, 72.19999999999999, 143.29999999999998, 20.000000000000014, 91.4, 116.3, 133.1, 103.09999999999998, 70.39999999999998, 153.79999999999995, 158.0, 170.0, 148.1, 118.99999999999999, 15.200000000000003, 13.699999999999964, -156.40000000000066, 136.69999999999996, 99.19999999999999, 96.2, 197.3, 170.0, 20.000000000000014, 136.70000000000002, 129.79999999999998, -45.40000000000006, 126.49999999999997, 30.200000000000003, -3.099999999999958, -3.099999999999958, 159.79999999999998, 20.000000000000014, 71.60000000000001, 119.0, 152.29999999999998, 160.4, 112.70000000000002, -0.9999999999999846, 140.59999999999997, 9.499999999999964, -89.5, 164.0, 190.1, 143.89999999999998, 111.49999999999996, 83.0, 134.59999999999997, 74.0, 97.10000000000002, 94.70000000000002, 35.0, 150.2, 63.50000000000003, 117.20000000000002, 100.39999999999998, 20.000000000000014, 40.40000000000001, -25.0, 162.2, 128.0, 98.30000000000001, 14.599999999999996, 96.2, 119.29999999999998, 170.29999999999993, -104.80000000000001, 155.59999999999997, 190.39999999999998, 20.000000000000014, 122.29999999999998, 160.1, 12.800000000000008, 4.100000000000001, 94.10000000000001, 91.7, 143.5999999999999, 167.59999999999997, 153.19999999999993, 154.39999999999998, 143.5999999999999, 109.7, 32.6, 24.200000000000003, 124.69999999999999, 89.60000000000002, 165.2, 144.2, 156.49999999999997, 50.3, 116.89999999999999, 43.70000000000006, 60.200000000000045, 1.3999999999999844, 140.59999999999997, 163.0999999999998, 45.20000000000002, 97.99999999999991, 156.49999999999986, 116.29999999999995, 13.699999999999964, 192.79999999999995, -34.29999999999999, 93.2, 113.29999999999998, 112.4, 136.09999999999997, 19.39999999999994, 154.99999999999997, 95.5999999999997, -51.70000000000005, 11.599999999999964, 89.29999999999993, 20.000000000000014, 171.79999999999998, 144.49999999999991, 156.79999999999978, 120.19999999999993, 29.299999999999997, 49.70000000000001, 145.1, 134.3, 50.90000000000001, 20.000000000000014, 36.79999999999998, 171.79999999999993, 142.99999999999997, 38.599999999999994, 157.09999999999988, -37.00000000000008, 35.89999999999999, 7.399999999999965, 143.89999999999995, 143.60000000000002, 155.89999999999998, 5.299999999999965, 5.299999999999965, 42.800000000000004, 149.89999999999995, 72.80000000000001, 148.09999999999997, 151.7, 136.39999999999998, 43.400000000000006, -5.1999999999999265, 10.400000000000015, 11.599999999999964, 29.599999999999987, 152.59999999999985, 90.49999999999994, 162.79999999999984, 110.29999999999995, 141.79999999999984, 20.000000000000014, 87.20000000000002, 20.000000000000014, 115.99999999999991, -76.3000000000001, 152.6, 9.499999999999966, 14.30000000000004, 122.59999999999982, 116.59999999999985, 149.29999999999998, 142.09999999999997, 11.599999999999964, 20.000000000000014, 166.69999999999987, 153.1999999999999, 13.699999999999964, -10.300000000000018, 119.59999999999988, 15.799999999999963], "policy_predator_policy_reward": [29.0, 26.0, 11.0, 54.0, 11.0, 21.0, 4.0, 5.0, 37.0, 39.0, 4.0, 23.0, 22.0, 44.0, 16.0, 15.0, 38.0, 40.0, 33.0, 28.0, 46.0, 44.0, 44.0, 12.0, 37.0, 21.0, 48.0, 6.0, 68.0, 39.0, 12.0, 4.0, 35.0, 37.0, 14.0, 32.0, 42.0, 12.0, 19.0, 17.0, 11.0, 21.0, 50.0, 11.0, 84.0, 19.0, 36.0, 38.0, 9.0, 7.0, 18.0, 19.0, 56.0, 44.0, 60.0, 21.0, 12.0, 1.0, 9.0, 5.0, 29.0, 30.0, 21.0, 5.0, 32.0, 5.0, 11.0, 6.0, 42.0, 63.0, 3.0, 16.0, 45.0, 31.0, 19.0, 42.0, 29.0, 36.0, 56.0, 13.0, 16.0, 54.0, 17.0, 25.0, 62.0, 79.0, 25.0, 18.0, 39.0, 51.0, 53.0, 42.0, 74.0, 51.0, 11.0, 12.0, 25.0, 11.0, 24.0, 55.0, 42.0, 45.0, 47.0, 18.0, 4.0, 12.0, 14.0, 9.0, 1.0, 61.0, 57.0, 30.0, 22.0, 7.0, 11.0, 16.0, 23.0, 45.0, 37.0, 28.0, 13.0, 62.0, 46.0, 47.0, 8.0, 9.0, 21.0, 23.0, 64.0, 47.0, 35.0, 44.0, 24.0, 22.0, 43.0, 49.0, 77.0, 8.0, 25.0, 20.0, 3.0, 4.0, 9.0, 11.0, 23.0, 49.0, 42.0, 23.0, 20.0, 22.0, 29.0, 39.0, 11.0, 10.0, 49.0, 8.0, 87.0, 56.0, 13.0, 11.0, 14.0, 6.0, 7.0, 5.0, 41.0, 42.0, 42.0, 26.0, 20.0, 19.0, 40.0, 19.0, 44.0, 40.0, 43.0, 42.0, 11.0, 18.0, 22.0, 12.0, 34.0, 11.0, 7.0, 7.0, 65.0, 85.0, 42.0, 23.0, 20.0, 25.0, 5.0, 17.0, 4.0, 0.0, 6.0, 4.0, 63.0, 30.0, 2.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5992524417358264, "mean_inference_ms": 1.8521142454800197, "mean_action_processing_ms": 0.2591201752965409, "mean_env_wait_ms": 0.20062409727895336, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004162788391113281, "StateBufferConnector_ms": 0.0033588409423828125, "ViewRequirementAgentConnector_ms": 0.10512161254882812}, "num_episodes": 18, "episode_return_max": 391.3, "episode_return_min": 6.800000000000164, "episode_return_mean": 235.65599999999986, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1264000, "num_agent_steps_trained": 1264000, "num_env_steps_sampled": 316000, "num_env_steps_trained": 316000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 366.82722867684845, "num_env_steps_trained_throughput_per_sec": 366.82722867684845, "timesteps_total": 316000, "num_env_steps_sampled_lifetime": 316000, "num_agent_steps_sampled_lifetime": 1264000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1264000, "timers": {"training_iteration_time_ms": 10900.604, "restore_workers_time_ms": 0.014, "training_step_time_ms": 10900.537, "sample_time_ms": 1281.915, "learn_time_ms": 9601.346, "learn_throughput": 416.608, "synch_weights_time_ms": 15.554}, "counters": {"num_env_steps_sampled": 316000, "num_env_steps_trained": 316000, "num_agent_steps_sampled": 1264000, "num_agent_steps_trained": 1264000}, "done": false, "training_iteration": 79, "trial_id": "3dae5_00000", "date": "2024-08-14_09-21-20", "timestamp": 1723641680, "time_this_iter_s": 10.909647941589355, "time_total_s": 2499.256674051285, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b381b8b0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2499.256674051285, "iterations_since_restore": 79, "perf": {"cpu_util_percent": 31.20666666666667, "ram_util_percent": 83.63333333333334}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.8336308114427737, "cur_kl_coeff": 0.056250000000000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.8327513705485712, "policy_loss": -0.0067254284570466664, "vf_loss": 1.839055936708652, "vf_explained_var": 0.06869382631211053, "kl": 0.007482086950866683, "entropy": 0.6865655725595181, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 150255.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.5298879017274847, "cur_kl_coeff": 0.5062499999999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.000636651276281, "policy_loss": -0.00980124235813501, "vf_loss": 6.007443519370265, "vf_explained_var": 0.7980579014177676, "kl": 0.005914799571523131, "entropy": 1.4275383802948804, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 150255.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 320000, "num_env_steps_trained": 320000, "num_agent_steps_sampled": 1280000, "num_agent_steps_trained": 1280000}, "env_runners": {"episode_reward_max": 383.29999999999995, "episode_reward_min": 6.800000000000164, "episode_reward_mean": 229.0469999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -156.40000000000066, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 197.3, "predator_policy": 87.0}, "policy_reward_mean": {"prey_policy": 87.67849999999997, "predator_policy": 26.845}, "custom_metrics": {}, "hist_stats": {"episode_reward": [83.29999999999988, 269.40000000000003, 383.29999999999995, 193.69999999999933, 184.3999999999999, 237.69999999999996, 6.800000000000164, 193.79999999999936, 249.59999999999997, 338.70000000000005, 148.69999999999965, 167.09999999999937, 179.5, 353.0, 270.50000000000006, 269.59999999999997, 256.79999999999995, 254.2, 250.69999999999996, 162.39999999999935, 156.3999999999999, 333.20000000000005, 202.89999999999986, 310.5, 190.49999999999997, 369.0000000000001, 178.29999999999941, 251.89999999999998, 185.20000000000002, 300.29999999999995, 336.80000000000024, 321.0000000000002, 204.29999999999998, 235.9, 283.7999999999999, 327.70000000000016, 235.2, 168.89999999999972, 216.9999999999999, 301.3000000000004, 271.50000000000045, 173.99999999999932, 269.5, 285.5, 294.4999999999998, 266.3999999999999, 128.89999999999978, 145.89999999999938, 198.79999999999927, 321.3000000000004, 221.4999999999999, 259.8, 227.1999999999999, 124.79999999999964, 335.79999999999995, 252.6999999999998, 141.89999999999998, 175.2999999999994, 319.49999999999994, 22.600000000000012, 275.7000000000003, 288.89999999999975, 327.1, 97.19999999999965, 105.99999999999977, 267.1999999999998, 282.3000000000002, 286.10000000000014, 152.19999999999956, 149.99999999999937, 226.29999999999993, 88.80000000000011, 284.19999999999976, 313.4000000000002, 35.600000000000236, 329.9000000000008, 96.39999999999998, 147.3999999999991, 348.5000000000002, 256.09999999999997, 283.9000000000001, 28.00000000000011, 255.1999999999997, 291.50000000000017, 233.49999999999966, 184.49999999999943, 307.0999999999999, 221.59999999999962, 314.8000000000002, 217.0999999999998, 238.69999999999956, 130.6999999999997, 256.49999999999966, 293.4999999999999, 295.0999999999998, 158.2999999999995, 226.69999999999996, 158.29999999999941, 200.99999999999994, 248.6999999999997], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-156.40000000000066, 136.69999999999996, 99.19999999999999, 96.2, 197.3, 170.0, 20.000000000000014, 136.70000000000002, 129.79999999999998, -45.40000000000006, 126.49999999999997, 30.200000000000003, -3.099999999999958, -3.099999999999958, 159.79999999999998, 20.000000000000014, 71.60000000000001, 119.0, 152.29999999999998, 160.4, 112.70000000000002, -0.9999999999999846, 140.59999999999997, 9.499999999999964, -89.5, 164.0, 190.1, 143.89999999999998, 111.49999999999996, 83.0, 134.59999999999997, 74.0, 97.10000000000002, 94.70000000000002, 35.0, 150.2, 63.50000000000003, 117.20000000000002, 100.39999999999998, 20.000000000000014, 40.40000000000001, -25.0, 162.2, 128.0, 98.30000000000001, 14.599999999999996, 96.2, 119.29999999999998, 170.29999999999993, -104.80000000000001, 155.59999999999997, 190.39999999999998, 20.000000000000014, 122.29999999999998, 160.1, 12.800000000000008, 4.100000000000001, 94.10000000000001, 91.7, 143.5999999999999, 167.59999999999997, 153.19999999999993, 154.39999999999998, 143.5999999999999, 109.7, 32.6, 24.200000000000003, 124.69999999999999, 89.60000000000002, 165.2, 144.2, 156.49999999999997, 50.3, 116.89999999999999, 43.70000000000006, 60.200000000000045, 1.3999999999999844, 140.59999999999997, 163.0999999999998, 45.20000000000002, 97.99999999999991, 156.49999999999986, 116.29999999999995, 13.699999999999964, 192.79999999999995, -34.29999999999999, 93.2, 113.29999999999998, 112.4, 136.09999999999997, 19.39999999999994, 154.99999999999997, 95.5999999999997, -51.70000000000005, 11.599999999999964, 89.29999999999993, 20.000000000000014, 171.79999999999998, 144.49999999999991, 156.79999999999978, 120.19999999999993, 29.299999999999997, 49.70000000000001, 145.1, 134.3, 50.90000000000001, 20.000000000000014, 36.79999999999998, 171.79999999999993, 142.99999999999997, 38.599999999999994, 157.09999999999988, -37.00000000000008, 35.89999999999999, 7.399999999999965, 143.89999999999995, 143.60000000000002, 155.89999999999998, 5.299999999999965, 5.299999999999965, 42.800000000000004, 149.89999999999995, 72.80000000000001, 148.09999999999997, 151.7, 136.39999999999998, 43.400000000000006, -5.1999999999999265, 10.400000000000015, 11.599999999999964, 29.599999999999987, 152.59999999999985, 90.49999999999994, 162.79999999999984, 110.29999999999995, 141.79999999999984, 20.000000000000014, 87.20000000000002, 20.000000000000014, 115.99999999999991, -76.3000000000001, 152.6, 9.499999999999966, 14.30000000000004, 122.59999999999982, 116.59999999999985, 149.29999999999998, 142.09999999999997, 11.599999999999964, 20.000000000000014, 166.69999999999987, 153.1999999999999, 13.699999999999964, -10.300000000000018, 119.59999999999988, 15.799999999999963, 141.79999999999993, 193.7, 95.00000000000001, 91.10000000000002, 135.49999999999986, 124.39999999999999, 1.0999999999999865, 17.899999999999988, 102.79999999999987, 112.39999999999995, 119.89999999999989, 140.59999999999994, 79.40000000000003, 112.1, -5.1999999999999265, 154.70000000000002, 152.5999999999999, 141.49999999999974, 111.49999999999986, 97.09999999999994, 162.49999999999986, 143.29999999999984, 68.89999999999998, 39.19999999999997, 68.00000000000006, 115.69999999999987, 46.69999999999999, 20.000000000000014, 132.19999999999987, 95.30000000000007, 140.29999999999998, 129.1999999999999, 120.80000000000001, 137.2999999999999, 17.899999999999988, 133.39999999999995, 7.399999999999901, 161.29999999999998, 89.30000000000001, 20.000000000000014, 74.9, -4.900000000000091, 10.400000000000034, 155.29999999999993], "policy_predator_policy_reward": [84.0, 19.0, 36.0, 38.0, 9.0, 7.0, 18.0, 19.0, 56.0, 44.0, 60.0, 21.0, 12.0, 1.0, 9.0, 5.0, 29.0, 30.0, 21.0, 5.0, 32.0, 5.0, 11.0, 6.0, 42.0, 63.0, 3.0, 16.0, 45.0, 31.0, 19.0, 42.0, 29.0, 36.0, 56.0, 13.0, 16.0, 54.0, 17.0, 25.0, 62.0, 79.0, 25.0, 18.0, 39.0, 51.0, 53.0, 42.0, 74.0, 51.0, 11.0, 12.0, 25.0, 11.0, 24.0, 55.0, 42.0, 45.0, 47.0, 18.0, 4.0, 12.0, 14.0, 9.0, 1.0, 61.0, 57.0, 30.0, 22.0, 7.0, 11.0, 16.0, 23.0, 45.0, 37.0, 28.0, 13.0, 62.0, 46.0, 47.0, 8.0, 9.0, 21.0, 23.0, 64.0, 47.0, 35.0, 44.0, 24.0, 22.0, 43.0, 49.0, 77.0, 8.0, 25.0, 20.0, 3.0, 4.0, 9.0, 11.0, 23.0, 49.0, 42.0, 23.0, 20.0, 22.0, 29.0, 39.0, 11.0, 10.0, 49.0, 8.0, 87.0, 56.0, 13.0, 11.0, 14.0, 6.0, 7.0, 5.0, 41.0, 42.0, 42.0, 26.0, 20.0, 19.0, 40.0, 19.0, 44.0, 40.0, 43.0, 42.0, 11.0, 18.0, 22.0, 12.0, 34.0, 11.0, 7.0, 7.0, 65.0, 85.0, 42.0, 23.0, 20.0, 25.0, 5.0, 17.0, 4.0, 0.0, 6.0, 4.0, 63.0, 30.0, 2.0, 10.0, 5.0, 8.0, 36.0, 34.0, 12.0, 12.0, 0.0, 9.0, 22.0, 18.0, 13.0, 18.0, 12.0, 30.0, 11.0, 24.0, 5.0, 8.0, 7.0, 6.0, 3.0, 6.0, 56.0, 53.0, 40.0, 15.0, 15.0, 49.0, 19.0, 10.0, 11.0, 13.0, 12.0, 25.0, 6.0, 1.0, 55.0, 3.0, 27.0, 22.0, 62.0, 69.0, 33.0, 50.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5989336516922656, "mean_inference_ms": 1.8507170770227106, "mean_action_processing_ms": 0.25818003949477997, "mean_env_wait_ms": 0.2006205586005652, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004095911979675293, "StateBufferConnector_ms": 0.0033832788467407227, "ViewRequirementAgentConnector_ms": 0.10345542430877686}, "num_episodes": 22, "episode_return_max": 383.29999999999995, "episode_return_min": 6.800000000000164, "episode_return_mean": 229.0469999999999, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1280000, "num_agent_steps_trained": 1280000, "num_env_steps_sampled": 320000, "num_env_steps_trained": 320000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 387.74925950829163, "num_env_steps_trained_throughput_per_sec": 387.74925950829163, "timesteps_total": 320000, "num_env_steps_sampled_lifetime": 320000, "num_agent_steps_sampled_lifetime": 1280000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1280000, "timers": {"training_iteration_time_ms": 10854.63, "restore_workers_time_ms": 0.014, "training_step_time_ms": 10854.563, "sample_time_ms": 1283.549, "learn_time_ms": 9554.008, "learn_throughput": 418.672, "synch_weights_time_ms": 15.323}, "counters": {"num_env_steps_sampled": 320000, "num_env_steps_trained": 320000, "num_agent_steps_sampled": 1280000, "num_agent_steps_trained": 1280000}, "done": false, "training_iteration": 80, "trial_id": "3dae5_00000", "date": "2024-08-14_09-21-30", "timestamp": 1723641690, "time_this_iter_s": 10.34995412826538, "time_total_s": 2509.60662817955, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3636820>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2509.60662817955, "iterations_since_restore": 80, "perf": {"cpu_util_percent": 28.746666666666666, "ram_util_percent": 83.46666666666667}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.4312121585878748, "cur_kl_coeff": 0.056250000000000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.9758640414192563, "policy_loss": -0.004938317666313163, "vf_loss": 1.9804712310985282, "vf_explained_var": 0.06695476637946235, "kl": 0.005886706965157417, "entropy": 0.5748016028650224, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 152145.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.6026227160736366, "cur_kl_coeff": 0.5062499999999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.063180985778728, "policy_loss": -0.0024833956531313045, "vf_loss": 5.061795292960273, "vf_explained_var": 0.7141924293583664, "kl": 0.007642645152936988, "entropy": 1.430339312742627, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 152145.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 324000, "num_env_steps_trained": 324000, "num_agent_steps_sampled": 1296000, "num_agent_steps_trained": 1296000}, "env_runners": {"episode_reward_max": 369.0000000000001, "episode_reward_min": 22.600000000000012, "episode_reward_mean": 235.97599999999989, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -104.80000000000001, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 193.7, "predator_policy": 87.0}, "policy_reward_mean": {"prey_policy": 91.10299999999998, "predator_policy": 26.885}, "custom_metrics": {}, "hist_stats": {"episode_reward": [250.69999999999996, 162.39999999999935, 156.3999999999999, 333.20000000000005, 202.89999999999986, 310.5, 190.49999999999997, 369.0000000000001, 178.29999999999941, 251.89999999999998, 185.20000000000002, 300.29999999999995, 336.80000000000024, 321.0000000000002, 204.29999999999998, 235.9, 283.7999999999999, 327.70000000000016, 235.2, 168.89999999999972, 216.9999999999999, 301.3000000000004, 271.50000000000045, 173.99999999999932, 269.5, 285.5, 294.4999999999998, 266.3999999999999, 128.89999999999978, 145.89999999999938, 198.79999999999927, 321.3000000000004, 221.4999999999999, 259.8, 227.1999999999999, 124.79999999999964, 335.79999999999995, 252.6999999999998, 141.89999999999998, 175.2999999999994, 319.49999999999994, 22.600000000000012, 275.7000000000003, 288.89999999999975, 327.1, 97.19999999999965, 105.99999999999977, 267.1999999999998, 282.3000000000002, 286.10000000000014, 152.19999999999956, 149.99999999999937, 226.29999999999993, 88.80000000000011, 284.19999999999976, 313.4000000000002, 35.600000000000236, 329.9000000000008, 96.39999999999998, 147.3999999999991, 348.5000000000002, 256.09999999999997, 283.9000000000001, 28.00000000000011, 255.1999999999997, 291.50000000000017, 233.49999999999966, 184.49999999999943, 307.0999999999999, 221.59999999999962, 314.8000000000002, 217.0999999999998, 238.69999999999956, 130.6999999999997, 256.49999999999966, 293.4999999999999, 295.0999999999998, 158.2999999999995, 226.69999999999996, 158.29999999999941, 200.99999999999994, 248.6999999999997, 180.09999999999926, 360.5, 272.79999999999995, 300.7999999999999, 288.6999999999999, 186.6999999999999, 248.29999999999993, 349.3000000000002, 197.79999999999995, 310.59999999999997, 38.400000000000276, 140.49999999999972, 332.0, 293.50000000000006, 286.5, 297.6, 305.8999999999998, 343.00000000000017], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [63.50000000000003, 117.20000000000002, 100.39999999999998, 20.000000000000014, 40.40000000000001, -25.0, 162.2, 128.0, 98.30000000000001, 14.599999999999996, 96.2, 119.29999999999998, 170.29999999999993, -104.80000000000001, 155.59999999999997, 190.39999999999998, 20.000000000000014, 122.29999999999998, 160.1, 12.800000000000008, 4.100000000000001, 94.10000000000001, 91.7, 143.5999999999999, 167.59999999999997, 153.19999999999993, 154.39999999999998, 143.5999999999999, 109.7, 32.6, 24.200000000000003, 124.69999999999999, 89.60000000000002, 165.2, 144.2, 156.49999999999997, 50.3, 116.89999999999999, 43.70000000000006, 60.200000000000045, 1.3999999999999844, 140.59999999999997, 163.0999999999998, 45.20000000000002, 97.99999999999991, 156.49999999999986, 116.29999999999995, 13.699999999999964, 192.79999999999995, -34.29999999999999, 93.2, 113.29999999999998, 112.4, 136.09999999999997, 19.39999999999994, 154.99999999999997, 95.5999999999997, -51.70000000000005, 11.599999999999964, 89.29999999999993, 20.000000000000014, 171.79999999999998, 144.49999999999991, 156.79999999999978, 120.19999999999993, 29.299999999999997, 49.70000000000001, 145.1, 134.3, 50.90000000000001, 20.000000000000014, 36.79999999999998, 171.79999999999993, 142.99999999999997, 38.599999999999994, 157.09999999999988, -37.00000000000008, 35.89999999999999, 7.399999999999965, 143.89999999999995, 143.60000000000002, 155.89999999999998, 5.299999999999965, 5.299999999999965, 42.800000000000004, 149.89999999999995, 72.80000000000001, 148.09999999999997, 151.7, 136.39999999999998, 43.400000000000006, -5.1999999999999265, 10.400000000000015, 11.599999999999964, 29.599999999999987, 152.59999999999985, 90.49999999999994, 162.79999999999984, 110.29999999999995, 141.79999999999984, 20.000000000000014, 87.20000000000002, 20.000000000000014, 115.99999999999991, -76.3000000000001, 152.6, 9.499999999999966, 14.30000000000004, 122.59999999999982, 116.59999999999985, 149.29999999999998, 142.09999999999997, 11.599999999999964, 20.000000000000014, 166.69999999999987, 153.1999999999999, 13.699999999999964, -10.300000000000018, 119.59999999999988, 15.799999999999963, 141.79999999999993, 193.7, 95.00000000000001, 91.10000000000002, 135.49999999999986, 124.39999999999999, 1.0999999999999865, 17.899999999999988, 102.79999999999987, 112.39999999999995, 119.89999999999989, 140.59999999999994, 79.40000000000003, 112.1, -5.1999999999999265, 154.70000000000002, 152.5999999999999, 141.49999999999974, 111.49999999999986, 97.09999999999994, 162.49999999999986, 143.29999999999984, 68.89999999999998, 39.19999999999997, 68.00000000000006, 115.69999999999987, 46.69999999999999, 20.000000000000014, 132.19999999999987, 95.30000000000007, 140.29999999999998, 129.1999999999999, 120.80000000000001, 137.2999999999999, 17.899999999999988, 133.39999999999995, 7.399999999999901, 161.29999999999998, 89.30000000000001, 20.000000000000014, 74.9, -4.900000000000091, 10.400000000000034, 155.29999999999993, 162.4999999999999, 11.599999999999964, 192.79999999999998, 115.69999999999999, 118.99999999999997, 72.79999999999998, 71.0, 159.79999999999995, 66.79999999999993, 173.89999999999992, 5.000000000000007, 64.69999999999999, 97.7, 86.60000000000002, 179.6, 154.69999999999993, -43.600000000000016, 112.4, 124.99999999999996, 155.59999999999985, 20.000000000000014, 7.399999999999965, 44.0, 9.499999999999964, 138.5, 144.5, 149.9, 98.59999999999998, 166.4, 46.09999999999997, 149.6, 124.99999999999996, 139.1, 105.80000000000001, 167.89999999999998, 157.0999999999999], "policy_predator_policy_reward": [16.0, 54.0, 17.0, 25.0, 62.0, 79.0, 25.0, 18.0, 39.0, 51.0, 53.0, 42.0, 74.0, 51.0, 11.0, 12.0, 25.0, 11.0, 24.0, 55.0, 42.0, 45.0, 47.0, 18.0, 4.0, 12.0, 14.0, 9.0, 1.0, 61.0, 57.0, 30.0, 22.0, 7.0, 11.0, 16.0, 23.0, 45.0, 37.0, 28.0, 13.0, 62.0, 46.0, 47.0, 8.0, 9.0, 21.0, 23.0, 64.0, 47.0, 35.0, 44.0, 24.0, 22.0, 43.0, 49.0, 77.0, 8.0, 25.0, 20.0, 3.0, 4.0, 9.0, 11.0, 23.0, 49.0, 42.0, 23.0, 20.0, 22.0, 29.0, 39.0, 11.0, 10.0, 49.0, 8.0, 87.0, 56.0, 13.0, 11.0, 14.0, 6.0, 7.0, 5.0, 41.0, 42.0, 42.0, 26.0, 20.0, 19.0, 40.0, 19.0, 44.0, 40.0, 43.0, 42.0, 11.0, 18.0, 22.0, 12.0, 34.0, 11.0, 7.0, 7.0, 65.0, 85.0, 42.0, 23.0, 20.0, 25.0, 5.0, 17.0, 4.0, 0.0, 6.0, 4.0, 63.0, 30.0, 2.0, 10.0, 5.0, 8.0, 36.0, 34.0, 12.0, 12.0, 0.0, 9.0, 22.0, 18.0, 13.0, 18.0, 12.0, 30.0, 11.0, 24.0, 5.0, 8.0, 7.0, 6.0, 3.0, 6.0, 56.0, 53.0, 40.0, 15.0, 15.0, 49.0, 19.0, 10.0, 11.0, 13.0, 12.0, 25.0, 6.0, 1.0, 55.0, 3.0, 27.0, 22.0, 62.0, 69.0, 33.0, 50.0, 2.0, 4.0, 26.0, 26.0, 31.0, 50.0, 29.0, 41.0, 25.0, 23.0, 59.0, 58.0, 38.0, 26.0, 12.0, 3.0, 74.0, 55.0, 19.0, 11.0, 6.0, 5.0, 35.0, 52.0, 32.0, 17.0, 13.0, 32.0, 48.0, 26.0, 2.0, 21.0, 32.0, 29.0, 8.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.598735923078543, "mean_inference_ms": 1.8495190554856027, "mean_action_processing_ms": 0.25847971187999447, "mean_env_wait_ms": 0.20040871954189968, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004067778587341309, "StateBufferConnector_ms": 0.003319382667541504, "ViewRequirementAgentConnector_ms": 0.10165393352508545}, "num_episodes": 18, "episode_return_max": 369.0000000000001, "episode_return_min": 22.600000000000012, "episode_return_mean": 235.97599999999989, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1296000, "num_agent_steps_trained": 1296000, "num_env_steps_sampled": 324000, "num_env_steps_trained": 324000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 370.62033229174244, "num_env_steps_trained_throughput_per_sec": 370.62033229174244, "timesteps_total": 324000, "num_env_steps_sampled_lifetime": 324000, "num_agent_steps_sampled_lifetime": 1296000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1296000, "timers": {"training_iteration_time_ms": 10852.462, "restore_workers_time_ms": 0.014, "training_step_time_ms": 10852.393, "sample_time_ms": 1289.274, "learn_time_ms": 9546.149, "learn_throughput": 419.017, "synch_weights_time_ms": 15.31}, "counters": {"num_env_steps_sampled": 324000, "num_env_steps_trained": 324000, "num_agent_steps_sampled": 1296000, "num_agent_steps_trained": 1296000}, "done": false, "training_iteration": 81, "trial_id": "3dae5_00000", "date": "2024-08-14_09-21-41", "timestamp": 1723641701, "time_this_iter_s": 10.798449993133545, "time_total_s": 2520.4050781726837, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3635af0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2520.4050781726837, "iterations_since_restore": 81, "perf": {"cpu_util_percent": 28.706666666666667, "ram_util_percent": 83.66000000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.5089021591597764, "cur_kl_coeff": 0.056250000000000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.8690553027801413, "policy_loss": -0.007064306471378557, "vf_loss": 0.8757731308460867, "vf_explained_var": 0.12578464948311055, "kl": 0.0061596331387860385, "entropy": 0.5834983576384801, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 154035.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.625661938846427, "cur_kl_coeff": 0.5062499999999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.125193548328662, "policy_loss": 0.004418741042661683, "vf_loss": 4.115759112090661, "vf_explained_var": 0.9243978835602916, "kl": 0.009907562074023725, "entropy": 1.4445269897501305, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 154035.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 328000, "num_env_steps_trained": 328000, "num_agent_steps_sampled": 1312000, "num_agent_steps_trained": 1312000}, "env_runners": {"episode_reward_max": 360.5, "episode_reward_min": 22.40000000000001, "episode_reward_mean": 238.56999999999985, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -76.3000000000001, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 194.60000000000002, "predator_policy": 87.0}, "policy_reward_mean": {"prey_policy": 94.71499999999996, "predator_policy": 24.57}, "custom_metrics": {}, "hist_stats": {"episode_reward": [173.99999999999932, 269.5, 285.5, 294.4999999999998, 266.3999999999999, 128.89999999999978, 145.89999999999938, 198.79999999999927, 321.3000000000004, 221.4999999999999, 259.8, 227.1999999999999, 124.79999999999964, 335.79999999999995, 252.6999999999998, 141.89999999999998, 175.2999999999994, 319.49999999999994, 22.600000000000012, 275.7000000000003, 288.89999999999975, 327.1, 97.19999999999965, 105.99999999999977, 267.1999999999998, 282.3000000000002, 286.10000000000014, 152.19999999999956, 149.99999999999937, 226.29999999999993, 88.80000000000011, 284.19999999999976, 313.4000000000002, 35.600000000000236, 329.9000000000008, 96.39999999999998, 147.3999999999991, 348.5000000000002, 256.09999999999997, 283.9000000000001, 28.00000000000011, 255.1999999999997, 291.50000000000017, 233.49999999999966, 184.49999999999943, 307.0999999999999, 221.59999999999962, 314.8000000000002, 217.0999999999998, 238.69999999999956, 130.6999999999997, 256.49999999999966, 293.4999999999999, 295.0999999999998, 158.2999999999995, 226.69999999999996, 158.29999999999941, 200.99999999999994, 248.6999999999997, 180.09999999999926, 360.5, 272.79999999999995, 300.7999999999999, 288.6999999999999, 186.6999999999999, 248.29999999999993, 349.3000000000002, 197.79999999999995, 310.59999999999997, 38.400000000000276, 140.49999999999972, 332.0, 293.50000000000006, 286.5, 297.6, 305.8999999999998, 343.00000000000017, 295.8999999999999, 189.19999999999942, 328.29999999999984, 332.19999999999976, 303.9, 286.79999999999995, 22.40000000000001, 164.19999999999956, 306.29999999999995, 304.2000000000001, 307.1000000000001, 292.20000000000016, 142.4999999999993, 345.9999999999999, 294.40000000000003, 166.29999999999956, 259.59999999999997, 275.2, 335.9, 280.00000000000006, 275.2000000000002, 351.00000000000006, 195.29999999999936], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [116.29999999999995, 13.699999999999964, 192.79999999999995, -34.29999999999999, 93.2, 113.29999999999998, 112.4, 136.09999999999997, 19.39999999999994, 154.99999999999997, 95.5999999999997, -51.70000000000005, 11.599999999999964, 89.29999999999993, 20.000000000000014, 171.79999999999998, 144.49999999999991, 156.79999999999978, 120.19999999999993, 29.299999999999997, 49.70000000000001, 145.1, 134.3, 50.90000000000001, 20.000000000000014, 36.79999999999998, 171.79999999999993, 142.99999999999997, 38.599999999999994, 157.09999999999988, -37.00000000000008, 35.89999999999999, 7.399999999999965, 143.89999999999995, 143.60000000000002, 155.89999999999998, 5.299999999999965, 5.299999999999965, 42.800000000000004, 149.89999999999995, 72.80000000000001, 148.09999999999997, 151.7, 136.39999999999998, 43.400000000000006, -5.1999999999999265, 10.400000000000015, 11.599999999999964, 29.599999999999987, 152.59999999999985, 90.49999999999994, 162.79999999999984, 110.29999999999995, 141.79999999999984, 20.000000000000014, 87.20000000000002, 20.000000000000014, 115.99999999999991, -76.3000000000001, 152.6, 9.499999999999966, 14.30000000000004, 122.59999999999982, 116.59999999999985, 149.29999999999998, 142.09999999999997, 11.599999999999964, 20.000000000000014, 166.69999999999987, 153.1999999999999, 13.699999999999964, -10.300000000000018, 119.59999999999988, 15.799999999999963, 141.79999999999993, 193.7, 95.00000000000001, 91.10000000000002, 135.49999999999986, 124.39999999999999, 1.0999999999999865, 17.899999999999988, 102.79999999999987, 112.39999999999995, 119.89999999999989, 140.59999999999994, 79.40000000000003, 112.1, -5.1999999999999265, 154.70000000000002, 152.5999999999999, 141.49999999999974, 111.49999999999986, 97.09999999999994, 162.49999999999986, 143.29999999999984, 68.89999999999998, 39.19999999999997, 68.00000000000006, 115.69999999999987, 46.69999999999999, 20.000000000000014, 132.19999999999987, 95.30000000000007, 140.29999999999998, 129.1999999999999, 120.80000000000001, 137.2999999999999, 17.899999999999988, 133.39999999999995, 7.399999999999901, 161.29999999999998, 89.30000000000001, 20.000000000000014, 74.9, -4.900000000000091, 10.400000000000034, 155.29999999999993, 162.4999999999999, 11.599999999999964, 192.79999999999998, 115.69999999999999, 118.99999999999997, 72.79999999999998, 71.0, 159.79999999999995, 66.79999999999993, 173.89999999999992, 5.000000000000007, 64.69999999999999, 97.7, 86.60000000000002, 179.6, 154.69999999999993, -43.600000000000016, 112.4, 124.99999999999996, 155.59999999999985, 20.000000000000014, 7.399999999999965, 44.0, 9.499999999999964, 138.5, 144.5, 149.9, 98.59999999999998, 166.4, 46.09999999999997, 149.6, 124.99999999999996, 139.1, 105.80000000000001, 167.89999999999998, 157.0999999999999, 113.59999999999998, 170.29999999999998, 20.000000000000014, 114.2, 162.50000000000003, 153.79999999999995, 175.6999999999999, 96.5, 75.2, 154.7, 75.8, 139.9999999999999, 5.299999999999965, 1.0999999999999865, 83.30000000000001, 17.899999999999988, 167.89999999999998, 58.40000000000002, 154.99999999999994, 114.19999999999993, 131.6, 105.49999999999999, 164.59999999999997, 62.599999999999994, 15.799999999999963, 100.69999999999985, 139.39999999999992, 194.60000000000002, 100.1, 143.29999999999998, 131.0, 5.299999999999965, 108.8, 105.80000000000001, 55.69999999999999, 147.5, 179.3, 131.6, 92.0, 137.00000000000003, 89.0, 138.19999999999996, 163.4, 173.59999999999997, 179.89999999999998, 7.399999999999965], "policy_predator_policy_reward": [21.0, 23.0, 64.0, 47.0, 35.0, 44.0, 24.0, 22.0, 43.0, 49.0, 77.0, 8.0, 25.0, 20.0, 3.0, 4.0, 9.0, 11.0, 23.0, 49.0, 42.0, 23.0, 20.0, 22.0, 29.0, 39.0, 11.0, 10.0, 49.0, 8.0, 87.0, 56.0, 13.0, 11.0, 14.0, 6.0, 7.0, 5.0, 41.0, 42.0, 42.0, 26.0, 20.0, 19.0, 40.0, 19.0, 44.0, 40.0, 43.0, 42.0, 11.0, 18.0, 22.0, 12.0, 34.0, 11.0, 7.0, 7.0, 65.0, 85.0, 42.0, 23.0, 20.0, 25.0, 5.0, 17.0, 4.0, 0.0, 6.0, 4.0, 63.0, 30.0, 2.0, 10.0, 5.0, 8.0, 36.0, 34.0, 12.0, 12.0, 0.0, 9.0, 22.0, 18.0, 13.0, 18.0, 12.0, 30.0, 11.0, 24.0, 5.0, 8.0, 7.0, 6.0, 3.0, 6.0, 56.0, 53.0, 40.0, 15.0, 15.0, 49.0, 19.0, 10.0, 11.0, 13.0, 12.0, 25.0, 6.0, 1.0, 55.0, 3.0, 27.0, 22.0, 62.0, 69.0, 33.0, 50.0, 2.0, 4.0, 26.0, 26.0, 31.0, 50.0, 29.0, 41.0, 25.0, 23.0, 59.0, 58.0, 38.0, 26.0, 12.0, 3.0, 74.0, 55.0, 19.0, 11.0, 6.0, 5.0, 35.0, 52.0, 32.0, 17.0, 13.0, 32.0, 48.0, 26.0, 2.0, 21.0, 32.0, 29.0, 8.0, 10.0, 5.0, 7.0, 28.0, 27.0, 8.0, 4.0, 30.0, 30.0, 41.0, 33.0, 32.0, 39.0, 7.0, 9.0, 32.0, 31.0, 43.0, 37.0, 10.0, 25.0, 35.0, 35.0, 41.0, 24.0, 16.0, 10.0, 5.0, 7.0, 18.0, 33.0, 8.0, 22.0, 28.0, 17.0, 40.0, 32.0, 21.0, 4.0, 36.0, 15.0, 17.0, 31.0, 0.0, 14.0, 1.0, 7.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5984801890168643, "mean_inference_ms": 1.8456855140469066, "mean_action_processing_ms": 0.25843503312555155, "mean_env_wait_ms": 0.20029965400708177, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004052639007568359, "StateBufferConnector_ms": 0.003315448760986328, "ViewRequirementAgentConnector_ms": 0.10109460353851318}, "num_episodes": 23, "episode_return_max": 360.5, "episode_return_min": 22.40000000000001, "episode_return_mean": 238.56999999999985, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1312000, "num_agent_steps_trained": 1312000, "num_env_steps_sampled": 328000, "num_env_steps_trained": 328000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 382.31926184733504, "num_env_steps_trained_throughput_per_sec": 382.31926184733504, "timesteps_total": 328000, "num_env_steps_sampled_lifetime": 328000, "num_agent_steps_sampled_lifetime": 1312000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1312000, "timers": {"training_iteration_time_ms": 10823.639, "restore_workers_time_ms": 0.014, "training_step_time_ms": 10823.587, "sample_time_ms": 1291.92, "learn_time_ms": 9515.887, "learn_throughput": 420.35, "synch_weights_time_ms": 14.657}, "counters": {"num_env_steps_sampled": 328000, "num_env_steps_trained": 328000, "num_agent_steps_sampled": 1312000, "num_agent_steps_trained": 1312000}, "done": false, "training_iteration": 82, "trial_id": "3dae5_00000", "date": "2024-08-14_09-21-51", "timestamp": 1723641711, "time_this_iter_s": 10.467103004455566, "time_total_s": 2530.8721811771393, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b384bd30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2530.8721811771393, "iterations_since_restore": 82, "perf": {"cpu_util_percent": 28.673333333333336, "ram_util_percent": 83.76666666666667}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.250474668589849, "cur_kl_coeff": 0.056250000000000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.1114537597333314, "policy_loss": -0.0048384904255351375, "vf_loss": 3.1159171506841346, "vf_explained_var": 0.07355308113274751, "kl": 0.006668480739759741, "entropy": 0.540668380985815, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 155925.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.287134371516566, "cur_kl_coeff": 0.5062499999999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.223173081559479, "policy_loss": -0.008632280596743815, "vf_loss": 5.228261205254409, "vf_explained_var": 0.7013192730921286, "kl": 0.007000794100189215, "entropy": 1.4117376330668334, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 155925.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 332000, "num_env_steps_trained": 332000, "num_agent_steps_sampled": 1328000, "num_agent_steps_trained": 1328000}, "env_runners": {"episode_reward_max": 362.9, "episode_reward_min": 22.40000000000001, "episode_reward_mean": 246.98599999999996, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -76.3000000000001, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 194.60000000000002, "predator_policy": 85.0}, "policy_reward_mean": {"prey_policy": 99.77299999999997, "predator_policy": 23.72}, "custom_metrics": {}, "hist_stats": {"episode_reward": [22.600000000000012, 275.7000000000003, 288.89999999999975, 327.1, 97.19999999999965, 105.99999999999977, 267.1999999999998, 282.3000000000002, 286.10000000000014, 152.19999999999956, 149.99999999999937, 226.29999999999993, 88.80000000000011, 284.19999999999976, 313.4000000000002, 35.600000000000236, 329.9000000000008, 96.39999999999998, 147.3999999999991, 348.5000000000002, 256.09999999999997, 283.9000000000001, 28.00000000000011, 255.1999999999997, 291.50000000000017, 233.49999999999966, 184.49999999999943, 307.0999999999999, 221.59999999999962, 314.8000000000002, 217.0999999999998, 238.69999999999956, 130.6999999999997, 256.49999999999966, 293.4999999999999, 295.0999999999998, 158.2999999999995, 226.69999999999996, 158.29999999999941, 200.99999999999994, 248.6999999999997, 180.09999999999926, 360.5, 272.79999999999995, 300.7999999999999, 288.6999999999999, 186.6999999999999, 248.29999999999993, 349.3000000000002, 197.79999999999995, 310.59999999999997, 38.400000000000276, 140.49999999999972, 332.0, 293.50000000000006, 286.5, 297.6, 305.8999999999998, 343.00000000000017, 295.8999999999999, 189.19999999999942, 328.29999999999984, 332.19999999999976, 303.9, 286.79999999999995, 22.40000000000001, 164.19999999999956, 306.29999999999995, 304.2000000000001, 307.1000000000001, 292.20000000000016, 142.4999999999993, 345.9999999999999, 294.40000000000003, 166.29999999999956, 259.59999999999997, 275.2, 335.9, 280.00000000000006, 275.2000000000002, 351.00000000000006, 195.29999999999936, 333.19999999999993, 240.59999999999985, 331.5999999999999, 335.6, 204.89999999999932, 316.0999999999999, 335.90000000000003, 307.0, 304.29999999999995, 302.4000000000001, 127.49999999999979, 319.5000000000002, 148.79999999999959, 252.79999999999995, 165.19999999999956, 262.4, 334.19999999999993, 362.9], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [5.299999999999965, 5.299999999999965, 42.800000000000004, 149.89999999999995, 72.80000000000001, 148.09999999999997, 151.7, 136.39999999999998, 43.400000000000006, -5.1999999999999265, 10.400000000000015, 11.599999999999964, 29.599999999999987, 152.59999999999985, 90.49999999999994, 162.79999999999984, 110.29999999999995, 141.79999999999984, 20.000000000000014, 87.20000000000002, 20.000000000000014, 115.99999999999991, -76.3000000000001, 152.6, 9.499999999999966, 14.30000000000004, 122.59999999999982, 116.59999999999985, 149.29999999999998, 142.09999999999997, 11.599999999999964, 20.000000000000014, 166.69999999999987, 153.1999999999999, 13.699999999999964, -10.300000000000018, 119.59999999999988, 15.799999999999963, 141.79999999999993, 193.7, 95.00000000000001, 91.10000000000002, 135.49999999999986, 124.39999999999999, 1.0999999999999865, 17.899999999999988, 102.79999999999987, 112.39999999999995, 119.89999999999989, 140.59999999999994, 79.40000000000003, 112.1, -5.1999999999999265, 154.70000000000002, 152.5999999999999, 141.49999999999974, 111.49999999999986, 97.09999999999994, 162.49999999999986, 143.29999999999984, 68.89999999999998, 39.19999999999997, 68.00000000000006, 115.69999999999987, 46.69999999999999, 20.000000000000014, 132.19999999999987, 95.30000000000007, 140.29999999999998, 129.1999999999999, 120.80000000000001, 137.2999999999999, 17.899999999999988, 133.39999999999995, 7.399999999999901, 161.29999999999998, 89.30000000000001, 20.000000000000014, 74.9, -4.900000000000091, 10.400000000000034, 155.29999999999993, 162.4999999999999, 11.599999999999964, 192.79999999999998, 115.69999999999999, 118.99999999999997, 72.79999999999998, 71.0, 159.79999999999995, 66.79999999999993, 173.89999999999992, 5.000000000000007, 64.69999999999999, 97.7, 86.60000000000002, 179.6, 154.69999999999993, -43.600000000000016, 112.4, 124.99999999999996, 155.59999999999985, 20.000000000000014, 7.399999999999965, 44.0, 9.499999999999964, 138.5, 144.5, 149.9, 98.59999999999998, 166.4, 46.09999999999997, 149.6, 124.99999999999996, 139.1, 105.80000000000001, 167.89999999999998, 157.0999999999999, 113.59999999999998, 170.29999999999998, 20.000000000000014, 114.2, 162.50000000000003, 153.79999999999995, 175.6999999999999, 96.5, 75.2, 154.7, 75.8, 139.9999999999999, 5.299999999999965, 1.0999999999999865, 83.30000000000001, 17.899999999999988, 167.89999999999998, 58.40000000000002, 154.99999999999994, 114.19999999999993, 131.6, 105.49999999999999, 164.59999999999997, 62.599999999999994, 15.799999999999963, 100.69999999999985, 139.39999999999992, 194.60000000000002, 100.1, 143.29999999999998, 131.0, 5.299999999999965, 108.8, 105.80000000000001, 55.69999999999999, 147.5, 179.3, 131.6, 92.0, 137.00000000000003, 89.0, 138.19999999999996, 163.4, 173.59999999999997, 179.89999999999998, 7.399999999999965, 182.89999999999995, 131.30000000000007, 101.9, 58.700000000000024, 171.19999999999993, 151.4, 174.79999999999998, 72.80000000000001, 176.9, 20.000000000000014, 178.39999999999992, 115.70000000000002, 166.39999999999998, 156.4999999999999, 144.2, 114.79999999999998, 181.99999999999994, 92.30000000000001, 141.1999999999998, 147.2, 64.39999999999999, 1.0999999999999865, 64.69999999999999, 183.79999999999995, 20.000000000000014, 75.80000000000001, 55.1, 103.69999999999997, 20.000000000000014, 57.20000000000002, 151.99999999999997, 10.400000000000034, 191.0, 72.20000000000002, 169.09999999999997, 192.79999999999998], "policy_predator_policy_reward": [7.0, 5.0, 41.0, 42.0, 42.0, 26.0, 20.0, 19.0, 40.0, 19.0, 44.0, 40.0, 43.0, 42.0, 11.0, 18.0, 22.0, 12.0, 34.0, 11.0, 7.0, 7.0, 65.0, 85.0, 42.0, 23.0, 20.0, 25.0, 5.0, 17.0, 4.0, 0.0, 6.0, 4.0, 63.0, 30.0, 2.0, 10.0, 5.0, 8.0, 36.0, 34.0, 12.0, 12.0, 0.0, 9.0, 22.0, 18.0, 13.0, 18.0, 12.0, 30.0, 11.0, 24.0, 5.0, 8.0, 7.0, 6.0, 3.0, 6.0, 56.0, 53.0, 40.0, 15.0, 15.0, 49.0, 19.0, 10.0, 11.0, 13.0, 12.0, 25.0, 6.0, 1.0, 55.0, 3.0, 27.0, 22.0, 62.0, 69.0, 33.0, 50.0, 2.0, 4.0, 26.0, 26.0, 31.0, 50.0, 29.0, 41.0, 25.0, 23.0, 59.0, 58.0, 38.0, 26.0, 12.0, 3.0, 74.0, 55.0, 19.0, 11.0, 6.0, 5.0, 35.0, 52.0, 32.0, 17.0, 13.0, 32.0, 48.0, 26.0, 2.0, 21.0, 32.0, 29.0, 8.0, 10.0, 5.0, 7.0, 28.0, 27.0, 8.0, 4.0, 30.0, 30.0, 41.0, 33.0, 32.0, 39.0, 7.0, 9.0, 32.0, 31.0, 43.0, 37.0, 10.0, 25.0, 35.0, 35.0, 41.0, 24.0, 16.0, 10.0, 5.0, 7.0, 18.0, 33.0, 8.0, 22.0, 28.0, 17.0, 40.0, 32.0, 21.0, 4.0, 36.0, 15.0, 17.0, 31.0, 0.0, 14.0, 1.0, 7.0, 9.0, 10.0, 42.0, 38.0, 3.0, 6.0, 44.0, 44.0, 5.0, 3.0, 8.0, 14.0, 3.0, 10.0, 24.0, 24.0, 20.0, 10.0, 9.0, 5.0, 40.0, 22.0, 34.0, 37.0, 18.0, 35.0, 40.0, 54.0, 44.0, 44.0, 54.0, 46.0, 32.0, 39.0, 0.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.597864554949687, "mean_inference_ms": 1.8456048832764835, "mean_action_processing_ms": 0.2576457979633968, "mean_env_wait_ms": 0.2000716185576848, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004033803939819336, "StateBufferConnector_ms": 0.00327301025390625, "ViewRequirementAgentConnector_ms": 0.09934425354003906}, "num_episodes": 18, "episode_return_max": 362.9, "episode_return_min": 22.40000000000001, "episode_return_mean": 246.98599999999996, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1328000, "num_agent_steps_trained": 1328000, "num_env_steps_sampled": 332000, "num_env_steps_trained": 332000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 371.68583108519874, "num_env_steps_trained_throughput_per_sec": 371.68583108519874, "timesteps_total": 332000, "num_env_steps_sampled_lifetime": 332000, "num_agent_steps_sampled_lifetime": 1328000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1328000, "timers": {"training_iteration_time_ms": 10841.323, "restore_workers_time_ms": 0.014, "training_step_time_ms": 10841.271, "sample_time_ms": 1297.563, "learn_time_ms": 9527.428, "learn_throughput": 419.84, "synch_weights_time_ms": 15.157}, "counters": {"num_env_steps_sampled": 332000, "num_env_steps_trained": 332000, "num_agent_steps_sampled": 1328000, "num_agent_steps_trained": 1328000}, "done": false, "training_iteration": 83, "trial_id": "3dae5_00000", "date": "2024-08-14_09-22-02", "timestamp": 1723641722, "time_this_iter_s": 10.770745992660522, "time_total_s": 2541.6429271698, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b36d65e0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2541.6429271698, "iterations_since_restore": 83, "perf": {"cpu_util_percent": 28.90625, "ram_util_percent": 83.58125000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.2770755044682316, "cur_kl_coeff": 0.056250000000000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.708692957074554, "policy_loss": -0.006838338379378593, "vf_loss": 1.715219856317712, "vf_explained_var": 0.14378776487219272, "kl": 0.00553673318720198, "entropy": 0.5335673033560394, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 157815.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.199085016982265, "cur_kl_coeff": 0.5062499999999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.3138039228146665, "policy_loss": -0.004142152183201342, "vf_loss": 4.316031205086481, "vf_explained_var": 0.862235882862535, "kl": 0.0037824748541594815, "entropy": 1.4574846527563832, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 157815.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 336000, "num_env_steps_trained": 336000, "num_agent_steps_sampled": 1344000, "num_agent_steps_trained": 1344000}, "env_runners": {"episode_reward_max": 362.9, "episode_reward_min": 22.40000000000001, "episode_reward_mean": 259.77299999999985, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -66.1000000000009, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 194.60000000000002, "predator_policy": 74.0}, "policy_reward_mean": {"prey_policy": 106.86649999999997, "predator_policy": 23.02}, "custom_metrics": {}, "hist_stats": {"episode_reward": [147.3999999999991, 348.5000000000002, 256.09999999999997, 283.9000000000001, 28.00000000000011, 255.1999999999997, 291.50000000000017, 233.49999999999966, 184.49999999999943, 307.0999999999999, 221.59999999999962, 314.8000000000002, 217.0999999999998, 238.69999999999956, 130.6999999999997, 256.49999999999966, 293.4999999999999, 295.0999999999998, 158.2999999999995, 226.69999999999996, 158.29999999999941, 200.99999999999994, 248.6999999999997, 180.09999999999926, 360.5, 272.79999999999995, 300.7999999999999, 288.6999999999999, 186.6999999999999, 248.29999999999993, 349.3000000000002, 197.79999999999995, 310.59999999999997, 38.400000000000276, 140.49999999999972, 332.0, 293.50000000000006, 286.5, 297.6, 305.8999999999998, 343.00000000000017, 295.8999999999999, 189.19999999999942, 328.29999999999984, 332.19999999999976, 303.9, 286.79999999999995, 22.40000000000001, 164.19999999999956, 306.29999999999995, 304.2000000000001, 307.1000000000001, 292.20000000000016, 142.4999999999993, 345.9999999999999, 294.40000000000003, 166.29999999999956, 259.59999999999997, 275.2, 335.9, 280.00000000000006, 275.2000000000002, 351.00000000000006, 195.29999999999936, 333.19999999999993, 240.59999999999985, 331.5999999999999, 335.6, 204.89999999999932, 316.0999999999999, 335.90000000000003, 307.0, 304.29999999999995, 302.4000000000001, 127.49999999999979, 319.5000000000002, 148.79999999999959, 252.79999999999995, 165.19999999999956, 262.4, 334.19999999999993, 362.9, 304.5999999999999, 193.19999999999936, 313.7999999999999, 350.5, 347.29999999999995, 136.5999999999997, 323.70000000000005, 261.19999999999993, 272.8, 283.5, 183.09999999999943, 337.79999999999995, 192.39999999999935, 183.79999999999936, 270.30000000000007, 279.5000000000001, 320.6, 353.90000000000015], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [119.59999999999988, 15.799999999999963, 141.79999999999993, 193.7, 95.00000000000001, 91.10000000000002, 135.49999999999986, 124.39999999999999, 1.0999999999999865, 17.899999999999988, 102.79999999999987, 112.39999999999995, 119.89999999999989, 140.59999999999994, 79.40000000000003, 112.1, -5.1999999999999265, 154.70000000000002, 152.5999999999999, 141.49999999999974, 111.49999999999986, 97.09999999999994, 162.49999999999986, 143.29999999999984, 68.89999999999998, 39.19999999999997, 68.00000000000006, 115.69999999999987, 46.69999999999999, 20.000000000000014, 132.19999999999987, 95.30000000000007, 140.29999999999998, 129.1999999999999, 120.80000000000001, 137.2999999999999, 17.899999999999988, 133.39999999999995, 7.399999999999901, 161.29999999999998, 89.30000000000001, 20.000000000000014, 74.9, -4.900000000000091, 10.400000000000034, 155.29999999999993, 162.4999999999999, 11.599999999999964, 192.79999999999998, 115.69999999999999, 118.99999999999997, 72.79999999999998, 71.0, 159.79999999999995, 66.79999999999993, 173.89999999999992, 5.000000000000007, 64.69999999999999, 97.7, 86.60000000000002, 179.6, 154.69999999999993, -43.600000000000016, 112.4, 124.99999999999996, 155.59999999999985, 20.000000000000014, 7.399999999999965, 44.0, 9.499999999999964, 138.5, 144.5, 149.9, 98.59999999999998, 166.4, 46.09999999999997, 149.6, 124.99999999999996, 139.1, 105.80000000000001, 167.89999999999998, 157.0999999999999, 113.59999999999998, 170.29999999999998, 20.000000000000014, 114.2, 162.50000000000003, 153.79999999999995, 175.6999999999999, 96.5, 75.2, 154.7, 75.8, 139.9999999999999, 5.299999999999965, 1.0999999999999865, 83.30000000000001, 17.899999999999988, 167.89999999999998, 58.40000000000002, 154.99999999999994, 114.19999999999993, 131.6, 105.49999999999999, 164.59999999999997, 62.599999999999994, 15.799999999999963, 100.69999999999985, 139.39999999999992, 194.60000000000002, 100.1, 143.29999999999998, 131.0, 5.299999999999965, 108.8, 105.80000000000001, 55.69999999999999, 147.5, 179.3, 131.6, 92.0, 137.00000000000003, 89.0, 138.19999999999996, 163.4, 173.59999999999997, 179.89999999999998, 7.399999999999965, 182.89999999999995, 131.30000000000007, 101.9, 58.700000000000024, 171.19999999999993, 151.4, 174.79999999999998, 72.80000000000001, 176.9, 20.000000000000014, 178.39999999999992, 115.70000000000002, 166.39999999999998, 156.4999999999999, 144.2, 114.79999999999998, 181.99999999999994, 92.30000000000001, 141.1999999999998, 147.2, 64.39999999999999, 1.0999999999999865, 64.69999999999999, 183.79999999999995, 20.000000000000014, 75.80000000000001, 55.1, 103.69999999999997, 20.000000000000014, 57.20000000000002, 151.99999999999997, 10.400000000000034, 191.0, 72.20000000000002, 169.09999999999997, 192.79999999999998, 164.29999999999995, 41.30000000000001, 20.000000000000014, 153.2, 140.29999999999995, 126.49999999999997, 116.9, 185.6, 175.7, 164.6, -34.59999999999975, 123.2, 139.09999999999997, 158.59999999999997, 97.69999999999997, 99.5, 187.1, -16.300000000000047, 108.19999999999999, 131.29999999999995, 11.599999999999964, 156.49999999999997, 167.6, 156.2, 169.39999999999998, 20.000000000000014, -66.1000000000009, 173.89999999999995, 127.99999999999987, 107.29999999999995, 107.29999999999997, 132.2, 181.1, 75.5, 121.1, 183.79999999999993], "policy_predator_policy_reward": [2.0, 10.0, 5.0, 8.0, 36.0, 34.0, 12.0, 12.0, 0.0, 9.0, 22.0, 18.0, 13.0, 18.0, 12.0, 30.0, 11.0, 24.0, 5.0, 8.0, 7.0, 6.0, 3.0, 6.0, 56.0, 53.0, 40.0, 15.0, 15.0, 49.0, 19.0, 10.0, 11.0, 13.0, 12.0, 25.0, 6.0, 1.0, 55.0, 3.0, 27.0, 22.0, 62.0, 69.0, 33.0, 50.0, 2.0, 4.0, 26.0, 26.0, 31.0, 50.0, 29.0, 41.0, 25.0, 23.0, 59.0, 58.0, 38.0, 26.0, 12.0, 3.0, 74.0, 55.0, 19.0, 11.0, 6.0, 5.0, 35.0, 52.0, 32.0, 17.0, 13.0, 32.0, 48.0, 26.0, 2.0, 21.0, 32.0, 29.0, 8.0, 10.0, 5.0, 7.0, 28.0, 27.0, 8.0, 4.0, 30.0, 30.0, 41.0, 33.0, 32.0, 39.0, 7.0, 9.0, 32.0, 31.0, 43.0, 37.0, 10.0, 25.0, 35.0, 35.0, 41.0, 24.0, 16.0, 10.0, 5.0, 7.0, 18.0, 33.0, 8.0, 22.0, 28.0, 17.0, 40.0, 32.0, 21.0, 4.0, 36.0, 15.0, 17.0, 31.0, 0.0, 14.0, 1.0, 7.0, 9.0, 10.0, 42.0, 38.0, 3.0, 6.0, 44.0, 44.0, 5.0, 3.0, 8.0, 14.0, 3.0, 10.0, 24.0, 24.0, 20.0, 10.0, 9.0, 5.0, 40.0, 22.0, 34.0, 37.0, 18.0, 35.0, 40.0, 54.0, 44.0, 44.0, 54.0, 46.0, 32.0, 39.0, 0.0, 1.0, 47.0, 52.0, 14.0, 6.0, 28.0, 19.0, 23.0, 25.0, 7.0, 0.0, 22.0, 26.0, 13.0, 13.0, 32.0, 32.0, 37.0, 65.0, 28.0, 16.0, 14.0, 1.0, 8.0, 6.0, 0.0, 3.0, 35.0, 41.0, 24.0, 11.0, 13.0, 27.0, 35.0, 29.0, 23.0, 26.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5974026644751543, "mean_inference_ms": 1.8441805043577966, "mean_action_processing_ms": 0.25730099138452944, "mean_env_wait_ms": 0.19994223759792285, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0036334991455078125, "StateBufferConnector_ms": 0.0032001733779907227, "ViewRequirementAgentConnector_ms": 0.0988457202911377}, "num_episodes": 18, "episode_return_max": 362.9, "episode_return_min": 22.40000000000001, "episode_return_mean": 259.77299999999985, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1344000, "num_agent_steps_trained": 1344000, "num_env_steps_sampled": 336000, "num_env_steps_trained": 336000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 380.07870429922224, "num_env_steps_trained_throughput_per_sec": 380.07870429922224, "timesteps_total": 336000, "num_env_steps_sampled_lifetime": 336000, "num_agent_steps_sampled_lifetime": 1344000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1344000, "timers": {"training_iteration_time_ms": 10787.231, "restore_workers_time_ms": 0.013, "training_step_time_ms": 10787.188, "sample_time_ms": 1304.327, "learn_time_ms": 9468.154, "learn_throughput": 422.469, "synch_weights_time_ms": 13.695}, "counters": {"num_env_steps_sampled": 336000, "num_env_steps_trained": 336000, "num_agent_steps_sampled": 1344000, "num_agent_steps_trained": 1344000}, "done": false, "training_iteration": 84, "trial_id": "3dae5_00000", "date": "2024-08-14_09-22-13", "timestamp": 1723641733, "time_this_iter_s": 10.529003858566284, "time_total_s": 2552.171931028366, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3895550>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2552.171931028366, "iterations_since_restore": 84, "perf": {"cpu_util_percent": 28.353333333333335, "ram_util_percent": 83.50666666666666}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.2918999201406245, "cur_kl_coeff": 0.056250000000000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.4262198709306262, "policy_loss": -0.007510815004980753, "vf_loss": 1.4332727203293452, "vf_explained_var": 0.18122382624439462, "kl": 0.00814161007951772, "entropy": 0.5712722130553433, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 159705.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.3359409317137705, "cur_kl_coeff": 0.25312499999999993, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.8282542077321855, "policy_loss": -0.004683289433356433, "vf_loss": 4.831139429410299, "vf_explained_var": 0.6771821796894073, "kl": 0.0071034124420224975, "entropy": 1.4244079406299288, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 159705.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 340000, "num_env_steps_trained": 340000, "num_agent_steps_sampled": 1360000, "num_agent_steps_trained": 1360000}, "env_runners": {"episode_reward_max": 362.9, "episode_reward_min": 22.40000000000001, "episode_reward_mean": 272.70199999999994, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -66.1000000000009, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 194.60000000000002, "predator_policy": 74.0}, "policy_reward_mean": {"prey_policy": 112.96099999999998, "predator_policy": 23.39}, "custom_metrics": {}, "hist_stats": {"episode_reward": [248.6999999999997, 180.09999999999926, 360.5, 272.79999999999995, 300.7999999999999, 288.6999999999999, 186.6999999999999, 248.29999999999993, 349.3000000000002, 197.79999999999995, 310.59999999999997, 38.400000000000276, 140.49999999999972, 332.0, 293.50000000000006, 286.5, 297.6, 305.8999999999998, 343.00000000000017, 295.8999999999999, 189.19999999999942, 328.29999999999984, 332.19999999999976, 303.9, 286.79999999999995, 22.40000000000001, 164.19999999999956, 306.29999999999995, 304.2000000000001, 307.1000000000001, 292.20000000000016, 142.4999999999993, 345.9999999999999, 294.40000000000003, 166.29999999999956, 259.59999999999997, 275.2, 335.9, 280.00000000000006, 275.2000000000002, 351.00000000000006, 195.29999999999936, 333.19999999999993, 240.59999999999985, 331.5999999999999, 335.6, 204.89999999999932, 316.0999999999999, 335.90000000000003, 307.0, 304.29999999999995, 302.4000000000001, 127.49999999999979, 319.5000000000002, 148.79999999999959, 252.79999999999995, 165.19999999999956, 262.4, 334.19999999999993, 362.9, 304.5999999999999, 193.19999999999936, 313.7999999999999, 350.5, 347.29999999999995, 136.5999999999997, 323.70000000000005, 261.19999999999993, 272.8, 283.5, 183.09999999999943, 337.79999999999995, 192.39999999999935, 183.79999999999936, 270.30000000000007, 279.5000000000001, 320.6, 353.90000000000015, 337.40000000000026, 254.7, 337.1000000000002, 295.70000000000005, 279.69999999999993, 307.6, 314.10000000000025, 268.40000000000003, 290.2000000000003, 255.99999999999991, 209.09999999999934, 316.8000000000004, 178.59999999999945, 292.79999999999984, 291.9999999999999, 309.89999999999986, 336.09999999999997, 249.49999999999994, 292.50000000000017, 320.80000000000007, 252.89999999999986, 349.0000000000002], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [10.400000000000034, 155.29999999999993, 162.4999999999999, 11.599999999999964, 192.79999999999998, 115.69999999999999, 118.99999999999997, 72.79999999999998, 71.0, 159.79999999999995, 66.79999999999993, 173.89999999999992, 5.000000000000007, 64.69999999999999, 97.7, 86.60000000000002, 179.6, 154.69999999999993, -43.600000000000016, 112.4, 124.99999999999996, 155.59999999999985, 20.000000000000014, 7.399999999999965, 44.0, 9.499999999999964, 138.5, 144.5, 149.9, 98.59999999999998, 166.4, 46.09999999999997, 149.6, 124.99999999999996, 139.1, 105.80000000000001, 167.89999999999998, 157.0999999999999, 113.59999999999998, 170.29999999999998, 20.000000000000014, 114.2, 162.50000000000003, 153.79999999999995, 175.6999999999999, 96.5, 75.2, 154.7, 75.8, 139.9999999999999, 5.299999999999965, 1.0999999999999865, 83.30000000000001, 17.899999999999988, 167.89999999999998, 58.40000000000002, 154.99999999999994, 114.19999999999993, 131.6, 105.49999999999999, 164.59999999999997, 62.599999999999994, 15.799999999999963, 100.69999999999985, 139.39999999999992, 194.60000000000002, 100.1, 143.29999999999998, 131.0, 5.299999999999965, 108.8, 105.80000000000001, 55.69999999999999, 147.5, 179.3, 131.6, 92.0, 137.00000000000003, 89.0, 138.19999999999996, 163.4, 173.59999999999997, 179.89999999999998, 7.399999999999965, 182.89999999999995, 131.30000000000007, 101.9, 58.700000000000024, 171.19999999999993, 151.4, 174.79999999999998, 72.80000000000001, 176.9, 20.000000000000014, 178.39999999999992, 115.70000000000002, 166.39999999999998, 156.4999999999999, 144.2, 114.79999999999998, 181.99999999999994, 92.30000000000001, 141.1999999999998, 147.2, 64.39999999999999, 1.0999999999999865, 64.69999999999999, 183.79999999999995, 20.000000000000014, 75.80000000000001, 55.1, 103.69999999999997, 20.000000000000014, 57.20000000000002, 151.99999999999997, 10.400000000000034, 191.0, 72.20000000000002, 169.09999999999997, 192.79999999999998, 164.29999999999995, 41.30000000000001, 20.000000000000014, 153.2, 140.29999999999995, 126.49999999999997, 116.9, 185.6, 175.7, 164.6, -34.59999999999975, 123.2, 139.09999999999997, 158.59999999999997, 97.69999999999997, 99.5, 187.1, -16.300000000000047, 108.19999999999999, 131.29999999999995, 11.599999999999964, 156.49999999999997, 167.6, 156.2, 169.39999999999998, 20.000000000000014, -66.1000000000009, 173.89999999999995, 127.99999999999987, 107.29999999999995, 107.29999999999997, 132.2, 181.1, 75.5, 121.1, 183.79999999999993, 177.49999999999994, 143.89999999999992, 49.39999999999999, 104.30000000000001, 136.99999999999994, 160.1, 127.4, 119.30000000000001, 124.1, 116.59999999999997, 104.29999999999998, 155.3, 165.19999999999993, 101.89999999999993, 163.39999999999998, 64.99999999999997, 141.8, 112.39999999999995, 93.49999999999994, 60.50000000000001, 194.60000000000002, 9.499999999999964, 156.5, 149.2999999999999, 13.699999999999964, 110.9, 119.59999999999995, 138.19999999999993, 80.0, 146.0, 141.2, 136.6999999999999, 172.0999999999999, 137.0, 37.399999999999984, 133.09999999999994, 129.20000000000002, 128.29999999999995, 121.99999999999994, 168.79999999999998, 108.50000000000003, 91.39999999999998, 171.19999999999993, 174.79999999999998], "policy_predator_policy_reward": [33.0, 50.0, 2.0, 4.0, 26.0, 26.0, 31.0, 50.0, 29.0, 41.0, 25.0, 23.0, 59.0, 58.0, 38.0, 26.0, 12.0, 3.0, 74.0, 55.0, 19.0, 11.0, 6.0, 5.0, 35.0, 52.0, 32.0, 17.0, 13.0, 32.0, 48.0, 26.0, 2.0, 21.0, 32.0, 29.0, 8.0, 10.0, 5.0, 7.0, 28.0, 27.0, 8.0, 4.0, 30.0, 30.0, 41.0, 33.0, 32.0, 39.0, 7.0, 9.0, 32.0, 31.0, 43.0, 37.0, 10.0, 25.0, 35.0, 35.0, 41.0, 24.0, 16.0, 10.0, 5.0, 7.0, 18.0, 33.0, 8.0, 22.0, 28.0, 17.0, 40.0, 32.0, 21.0, 4.0, 36.0, 15.0, 17.0, 31.0, 0.0, 14.0, 1.0, 7.0, 9.0, 10.0, 42.0, 38.0, 3.0, 6.0, 44.0, 44.0, 5.0, 3.0, 8.0, 14.0, 3.0, 10.0, 24.0, 24.0, 20.0, 10.0, 9.0, 5.0, 40.0, 22.0, 34.0, 37.0, 18.0, 35.0, 40.0, 54.0, 44.0, 44.0, 54.0, 46.0, 32.0, 39.0, 0.0, 1.0, 47.0, 52.0, 14.0, 6.0, 28.0, 19.0, 23.0, 25.0, 7.0, 0.0, 22.0, 26.0, 13.0, 13.0, 32.0, 32.0, 37.0, 65.0, 28.0, 16.0, 14.0, 1.0, 8.0, 6.0, 0.0, 3.0, 35.0, 41.0, 24.0, 11.0, 13.0, 27.0, 35.0, 29.0, 23.0, 26.0, 5.0, 11.0, 52.0, 49.0, 13.0, 27.0, 20.0, 29.0, 7.0, 32.0, 18.0, 30.0, 24.0, 23.0, 36.0, 4.0, 9.0, 27.0, 50.0, 52.0, 0.0, 5.0, 7.0, 4.0, 27.0, 27.0, 22.0, 13.0, 33.0, 33.0, 16.0, 16.0, 21.0, 6.0, 33.0, 46.0, 24.0, 11.0, 23.0, 7.0, 21.0, 32.0, 0.0, 3.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.596806255091386, "mean_inference_ms": 1.8422689275983588, "mean_action_processing_ms": 0.25689769706704807, "mean_env_wait_ms": 0.19975602045236754, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0036177635192871094, "StateBufferConnector_ms": 0.0031813383102416992, "ViewRequirementAgentConnector_ms": 0.09981489181518555}, "num_episodes": 22, "episode_return_max": 362.9, "episode_return_min": 22.40000000000001, "episode_return_mean": 272.70199999999994, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1360000, "num_agent_steps_trained": 1360000, "num_env_steps_sampled": 340000, "num_env_steps_trained": 340000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 383.87337087298255, "num_env_steps_trained_throughput_per_sec": 383.87337087298255, "timesteps_total": 340000, "num_env_steps_sampled_lifetime": 340000, "num_agent_steps_sampled_lifetime": 1360000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1360000, "timers": {"training_iteration_time_ms": 10657.636, "restore_workers_time_ms": 0.013, "training_step_time_ms": 10657.595, "sample_time_ms": 1296.104, "learn_time_ms": 9346.842, "learn_throughput": 427.952, "synch_weights_time_ms": 13.627}, "counters": {"num_env_steps_sampled": 340000, "num_env_steps_trained": 340000, "num_agent_steps_sampled": 1360000, "num_agent_steps_trained": 1360000}, "done": false, "training_iteration": 85, "trial_id": "3dae5_00000", "date": "2024-08-14_09-22-23", "timestamp": 1723641743, "time_this_iter_s": 10.427655220031738, "time_total_s": 2562.599586248398, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b36d6040>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2562.599586248398, "iterations_since_restore": 85, "perf": {"cpu_util_percent": 28.664285714285715, "ram_util_percent": 83.45000000000002}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.837198930379575, "cur_kl_coeff": 0.056250000000000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.572405938812034, "policy_loss": -0.00538113710504991, "vf_loss": 1.5774257861747945, "vf_explained_var": 0.09263322602504145, "kl": 0.006422970667887382, "entropy": 0.4840238444546543, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 161595.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.333523910543906, "cur_kl_coeff": 0.25312499999999993, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.381229491460891, "policy_loss": -0.004025972515058817, "vf_loss": 4.383695049639101, "vf_explained_var": 0.6610139109785594, "kl": 0.006164599414826301, "entropy": 1.4142185349943777, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 161595.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 344000, "num_env_steps_trained": 344000, "num_agent_steps_sampled": 1376000, "num_agent_steps_trained": 1376000}, "env_runners": {"episode_reward_max": 362.9, "episode_reward_min": 22.40000000000001, "episode_reward_mean": 278.3429999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -66.1000000000009, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 194.60000000000002, "predator_policy": 65.0}, "policy_reward_mean": {"prey_policy": 116.94649999999997, "predator_policy": 22.225}, "custom_metrics": {}, "hist_stats": {"episode_reward": [343.00000000000017, 295.8999999999999, 189.19999999999942, 328.29999999999984, 332.19999999999976, 303.9, 286.79999999999995, 22.40000000000001, 164.19999999999956, 306.29999999999995, 304.2000000000001, 307.1000000000001, 292.20000000000016, 142.4999999999993, 345.9999999999999, 294.40000000000003, 166.29999999999956, 259.59999999999997, 275.2, 335.9, 280.00000000000006, 275.2000000000002, 351.00000000000006, 195.29999999999936, 333.19999999999993, 240.59999999999985, 331.5999999999999, 335.6, 204.89999999999932, 316.0999999999999, 335.90000000000003, 307.0, 304.29999999999995, 302.4000000000001, 127.49999999999979, 319.5000000000002, 148.79999999999959, 252.79999999999995, 165.19999999999956, 262.4, 334.19999999999993, 362.9, 304.5999999999999, 193.19999999999936, 313.7999999999999, 350.5, 347.29999999999995, 136.5999999999997, 323.70000000000005, 261.19999999999993, 272.8, 283.5, 183.09999999999943, 337.79999999999995, 192.39999999999935, 183.79999999999936, 270.30000000000007, 279.5000000000001, 320.6, 353.90000000000015, 337.40000000000026, 254.7, 337.1000000000002, 295.70000000000005, 279.69999999999993, 307.6, 314.10000000000025, 268.40000000000003, 290.2000000000003, 255.99999999999991, 209.09999999999934, 316.8000000000004, 178.59999999999945, 292.79999999999984, 291.9999999999999, 309.89999999999986, 336.09999999999997, 249.49999999999994, 292.50000000000017, 320.80000000000007, 252.89999999999986, 349.0000000000002, 292.0, 335.0999999999999, 293.1, 246.60000000000008, 331.1, 330.9999999999999, 292.39999999999986, 340.10000000000014, 112.19999999999993, 276.2000000000001, 312.4, 321.8, 317.80000000000007, 160.59999999999968, 326.30000000000007, 296.4, 300.1, 317.59999999999997], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [167.89999999999998, 157.0999999999999, 113.59999999999998, 170.29999999999998, 20.000000000000014, 114.2, 162.50000000000003, 153.79999999999995, 175.6999999999999, 96.5, 75.2, 154.7, 75.8, 139.9999999999999, 5.299999999999965, 1.0999999999999865, 83.30000000000001, 17.899999999999988, 167.89999999999998, 58.40000000000002, 154.99999999999994, 114.19999999999993, 131.6, 105.49999999999999, 164.59999999999997, 62.599999999999994, 15.799999999999963, 100.69999999999985, 139.39999999999992, 194.60000000000002, 100.1, 143.29999999999998, 131.0, 5.299999999999965, 108.8, 105.80000000000001, 55.69999999999999, 147.5, 179.3, 131.6, 92.0, 137.00000000000003, 89.0, 138.19999999999996, 163.4, 173.59999999999997, 179.89999999999998, 7.399999999999965, 182.89999999999995, 131.30000000000007, 101.9, 58.700000000000024, 171.19999999999993, 151.4, 174.79999999999998, 72.80000000000001, 176.9, 20.000000000000014, 178.39999999999992, 115.70000000000002, 166.39999999999998, 156.4999999999999, 144.2, 114.79999999999998, 181.99999999999994, 92.30000000000001, 141.1999999999998, 147.2, 64.39999999999999, 1.0999999999999865, 64.69999999999999, 183.79999999999995, 20.000000000000014, 75.80000000000001, 55.1, 103.69999999999997, 20.000000000000014, 57.20000000000002, 151.99999999999997, 10.400000000000034, 191.0, 72.20000000000002, 169.09999999999997, 192.79999999999998, 164.29999999999995, 41.30000000000001, 20.000000000000014, 153.2, 140.29999999999995, 126.49999999999997, 116.9, 185.6, 175.7, 164.6, -34.59999999999975, 123.2, 139.09999999999997, 158.59999999999997, 97.69999999999997, 99.5, 187.1, -16.300000000000047, 108.19999999999999, 131.29999999999995, 11.599999999999964, 156.49999999999997, 167.6, 156.2, 169.39999999999998, 20.000000000000014, -66.1000000000009, 173.89999999999995, 127.99999999999987, 107.29999999999995, 107.29999999999997, 132.2, 181.1, 75.5, 121.1, 183.79999999999993, 177.49999999999994, 143.89999999999992, 49.39999999999999, 104.30000000000001, 136.99999999999994, 160.1, 127.4, 119.30000000000001, 124.1, 116.59999999999997, 104.29999999999998, 155.3, 165.19999999999993, 101.89999999999993, 163.39999999999998, 64.99999999999997, 141.8, 112.39999999999995, 93.49999999999994, 60.50000000000001, 194.60000000000002, 9.499999999999964, 156.5, 149.2999999999999, 13.699999999999964, 110.9, 119.59999999999995, 138.19999999999993, 80.0, 146.0, 141.2, 136.6999999999999, 172.0999999999999, 137.0, 37.399999999999984, 133.09999999999994, 129.20000000000002, 128.29999999999995, 121.99999999999994, 168.79999999999998, 108.50000000000003, 91.39999999999998, 171.19999999999993, 174.79999999999998, 132.49999999999997, 123.50000000000003, 162.19999999999996, 149.89999999999995, 113.3, 135.79999999999995, 89.30000000000007, 122.30000000000003, 165.8, 134.29999999999995, 156.5, 153.49999999999994, 132.20000000000002, 135.2, 191.0, 142.09999999999988, 119.60000000000005, -51.40000000000005, 86.89999999999995, 119.3, 154.4, 131.0, 162.79999999999998, 107.0, 127.39999999999999, 157.39999999999998, 116.59999999999997, -7.000000000000028, 172.09999999999994, 87.19999999999999, 34.400000000000006, 155.0, 182.90000000000003, 33.19999999999996, 94.10000000000002, 168.49999999999994], "policy_predator_policy_reward": [8.0, 10.0, 5.0, 7.0, 28.0, 27.0, 8.0, 4.0, 30.0, 30.0, 41.0, 33.0, 32.0, 39.0, 7.0, 9.0, 32.0, 31.0, 43.0, 37.0, 10.0, 25.0, 35.0, 35.0, 41.0, 24.0, 16.0, 10.0, 5.0, 7.0, 18.0, 33.0, 8.0, 22.0, 28.0, 17.0, 40.0, 32.0, 21.0, 4.0, 36.0, 15.0, 17.0, 31.0, 0.0, 14.0, 1.0, 7.0, 9.0, 10.0, 42.0, 38.0, 3.0, 6.0, 44.0, 44.0, 5.0, 3.0, 8.0, 14.0, 3.0, 10.0, 24.0, 24.0, 20.0, 10.0, 9.0, 5.0, 40.0, 22.0, 34.0, 37.0, 18.0, 35.0, 40.0, 54.0, 44.0, 44.0, 54.0, 46.0, 32.0, 39.0, 0.0, 1.0, 47.0, 52.0, 14.0, 6.0, 28.0, 19.0, 23.0, 25.0, 7.0, 0.0, 22.0, 26.0, 13.0, 13.0, 32.0, 32.0, 37.0, 65.0, 28.0, 16.0, 14.0, 1.0, 8.0, 6.0, 0.0, 3.0, 35.0, 41.0, 24.0, 11.0, 13.0, 27.0, 35.0, 29.0, 23.0, 26.0, 5.0, 11.0, 52.0, 49.0, 13.0, 27.0, 20.0, 29.0, 7.0, 32.0, 18.0, 30.0, 24.0, 23.0, 36.0, 4.0, 9.0, 27.0, 50.0, 52.0, 0.0, 5.0, 7.0, 4.0, 27.0, 27.0, 22.0, 13.0, 33.0, 33.0, 16.0, 16.0, 21.0, 6.0, 33.0, 46.0, 24.0, 11.0, 23.0, 7.0, 21.0, 32.0, 0.0, 3.0, 16.0, 20.0, 9.0, 14.0, 18.0, 26.0, 11.0, 24.0, 18.0, 13.0, 12.0, 9.0, 19.0, 6.0, 3.0, 4.0, 34.0, 10.0, 29.0, 41.0, 22.0, 5.0, 30.0, 22.0, 22.0, 11.0, 17.0, 34.0, 33.0, 34.0, 54.0, 53.0, 50.0, 34.0, 32.0, 23.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5962806729478183, "mean_inference_ms": 1.84078678935293, "mean_action_processing_ms": 0.25656023960306046, "mean_env_wait_ms": 0.19957584659542704, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003626227378845215, "StateBufferConnector_ms": 0.0032007694244384766, "ViewRequirementAgentConnector_ms": 0.10044634342193604}, "num_episodes": 18, "episode_return_max": 362.9, "episode_return_min": 22.40000000000001, "episode_return_mean": 278.3429999999999, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1376000, "num_agent_steps_trained": 1376000, "num_env_steps_sampled": 344000, "num_env_steps_trained": 344000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 361.8220283395067, "num_env_steps_trained_throughput_per_sec": 361.8220283395067, "timesteps_total": 344000, "num_env_steps_sampled_lifetime": 344000, "num_agent_steps_sampled_lifetime": 1376000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1376000, "timers": {"training_iteration_time_ms": 10687.256, "restore_workers_time_ms": 0.014, "training_step_time_ms": 10687.212, "sample_time_ms": 1292.162, "learn_time_ms": 9379.634, "learn_throughput": 426.456, "synch_weights_time_ms": 13.961}, "counters": {"num_env_steps_sampled": 344000, "num_env_steps_trained": 344000, "num_agent_steps_sampled": 1376000, "num_agent_steps_trained": 1376000}, "done": false, "training_iteration": 86, "trial_id": "3dae5_00000", "date": "2024-08-14_09-22-34", "timestamp": 1723641754, "time_this_iter_s": 11.089810132980347, "time_total_s": 2573.689396381378, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b36d6790>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2573.689396381378, "iterations_since_restore": 86, "perf": {"cpu_util_percent": 30.53125, "ram_util_percent": 83.41250000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.4130058210047465, "cur_kl_coeff": 0.056250000000000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.2339218231736035, "policy_loss": -0.009189211475914196, "vf_loss": 2.2425453110977456, "vf_explained_var": 0.16963446859329465, "kl": 0.0100573278104208, "entropy": 0.5320825062258534, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 163485.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.2573133242508723, "cur_kl_coeff": 0.25312499999999993, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.8577767679931, "policy_loss": -0.0054232627456446015, "vf_loss": 5.861232240616329, "vf_explained_var": 0.5281262578787627, "kl": 0.007774077924407824, "entropy": 1.374995881539804, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 163485.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 348000, "num_env_steps_trained": 348000, "num_agent_steps_sampled": 1392000, "num_agent_steps_trained": 1392000}, "env_runners": {"episode_reward_max": 362.9, "episode_reward_min": 112.19999999999993, "episode_reward_mean": 275.268, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -66.1000000000009, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 194.60000000000002, "predator_policy": 65.0}, "policy_reward_mean": {"prey_policy": 114.28399999999998, "predator_policy": 23.35}, "custom_metrics": {}, "hist_stats": {"episode_reward": [195.29999999999936, 333.19999999999993, 240.59999999999985, 331.5999999999999, 335.6, 204.89999999999932, 316.0999999999999, 335.90000000000003, 307.0, 304.29999999999995, 302.4000000000001, 127.49999999999979, 319.5000000000002, 148.79999999999959, 252.79999999999995, 165.19999999999956, 262.4, 334.19999999999993, 362.9, 304.5999999999999, 193.19999999999936, 313.7999999999999, 350.5, 347.29999999999995, 136.5999999999997, 323.70000000000005, 261.19999999999993, 272.8, 283.5, 183.09999999999943, 337.79999999999995, 192.39999999999935, 183.79999999999936, 270.30000000000007, 279.5000000000001, 320.6, 353.90000000000015, 337.40000000000026, 254.7, 337.1000000000002, 295.70000000000005, 279.69999999999993, 307.6, 314.10000000000025, 268.40000000000003, 290.2000000000003, 255.99999999999991, 209.09999999999934, 316.8000000000004, 178.59999999999945, 292.79999999999984, 291.9999999999999, 309.89999999999986, 336.09999999999997, 249.49999999999994, 292.50000000000017, 320.80000000000007, 252.89999999999986, 349.0000000000002, 292.0, 335.0999999999999, 293.1, 246.60000000000008, 331.1, 330.9999999999999, 292.39999999999986, 340.10000000000014, 112.19999999999993, 276.2000000000001, 312.4, 321.8, 317.80000000000007, 160.59999999999968, 326.30000000000007, 296.4, 300.1, 317.59999999999997, 164.29999999999959, 301.6, 324.1, 305.00000000000006, 308.5999999999998, 229.8, 275.19999999999976, 359.9000000000002, 302.79999999999984, 235.79999999999978, 260.9999999999999, 184.09999999999928, 203.69999999999996, 166.89999999999947, 335.80000000000007, 193.39999999999995, 280.70000000000005, 205.9, 305.10000000000036, 170.69999999999985, 317.9, 268.6999999999999, 193.30000000000004], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [179.89999999999998, 7.399999999999965, 182.89999999999995, 131.30000000000007, 101.9, 58.700000000000024, 171.19999999999993, 151.4, 174.79999999999998, 72.80000000000001, 176.9, 20.000000000000014, 178.39999999999992, 115.70000000000002, 166.39999999999998, 156.4999999999999, 144.2, 114.79999999999998, 181.99999999999994, 92.30000000000001, 141.1999999999998, 147.2, 64.39999999999999, 1.0999999999999865, 64.69999999999999, 183.79999999999995, 20.000000000000014, 75.80000000000001, 55.1, 103.69999999999997, 20.000000000000014, 57.20000000000002, 151.99999999999997, 10.400000000000034, 191.0, 72.20000000000002, 169.09999999999997, 192.79999999999998, 164.29999999999995, 41.30000000000001, 20.000000000000014, 153.2, 140.29999999999995, 126.49999999999997, 116.9, 185.6, 175.7, 164.6, -34.59999999999975, 123.2, 139.09999999999997, 158.59999999999997, 97.69999999999997, 99.5, 187.1, -16.300000000000047, 108.19999999999999, 131.29999999999995, 11.599999999999964, 156.49999999999997, 167.6, 156.2, 169.39999999999998, 20.000000000000014, -66.1000000000009, 173.89999999999995, 127.99999999999987, 107.29999999999995, 107.29999999999997, 132.2, 181.1, 75.5, 121.1, 183.79999999999993, 177.49999999999994, 143.89999999999992, 49.39999999999999, 104.30000000000001, 136.99999999999994, 160.1, 127.4, 119.30000000000001, 124.1, 116.59999999999997, 104.29999999999998, 155.3, 165.19999999999993, 101.89999999999993, 163.39999999999998, 64.99999999999997, 141.8, 112.39999999999995, 93.49999999999994, 60.50000000000001, 194.60000000000002, 9.499999999999964, 156.5, 149.2999999999999, 13.699999999999964, 110.9, 119.59999999999995, 138.19999999999993, 80.0, 146.0, 141.2, 136.6999999999999, 172.0999999999999, 137.0, 37.399999999999984, 133.09999999999994, 129.20000000000002, 128.29999999999995, 121.99999999999994, 168.79999999999998, 108.50000000000003, 91.39999999999998, 171.19999999999993, 174.79999999999998, 132.49999999999997, 123.50000000000003, 162.19999999999996, 149.89999999999995, 113.3, 135.79999999999995, 89.30000000000007, 122.30000000000003, 165.8, 134.29999999999995, 156.5, 153.49999999999994, 132.20000000000002, 135.2, 191.0, 142.09999999999988, 119.60000000000005, -51.40000000000005, 86.89999999999995, 119.3, 154.4, 131.0, 162.79999999999998, 107.0, 127.39999999999999, 157.39999999999998, 116.59999999999997, -7.000000000000028, 172.09999999999994, 87.19999999999999, 34.400000000000006, 155.0, 182.90000000000003, 33.19999999999996, 94.10000000000002, 168.49999999999994, 141.20000000000005, 1.0999999999999865, 144.19999999999993, 133.39999999999998, 144.49999999999994, 155.60000000000002, 99.79999999999997, 150.19999999999993, 138.7999999999999, 111.80000000000004, 115.39999999999999, 43.40000000000002, 99.80000000000004, 85.4, 183.8, 148.09999999999994, 149.89999999999992, 122.89999999999998, 98.29999999999993, 87.50000000000003, 133.39999999999992, 71.60000000000004, 5.299999999999965, 162.79999999999993, 16.699999999999996, 110.0, 128.89999999999998, 20.000000000000014, 88.1, 190.7, 35.29999999999998, 70.09999999999998, 142.69999999999996, 112.99999999999987, 46.09999999999998, 90.8, 155.89999999999972, 78.2, 54.20000000000003, 36.5, 142.4, 111.50000000000001, 161.89999999999998, 36.80000000000001, 66.5, 39.79999999999998], "policy_predator_policy_reward": [1.0, 7.0, 9.0, 10.0, 42.0, 38.0, 3.0, 6.0, 44.0, 44.0, 5.0, 3.0, 8.0, 14.0, 3.0, 10.0, 24.0, 24.0, 20.0, 10.0, 9.0, 5.0, 40.0, 22.0, 34.0, 37.0, 18.0, 35.0, 40.0, 54.0, 44.0, 44.0, 54.0, 46.0, 32.0, 39.0, 0.0, 1.0, 47.0, 52.0, 14.0, 6.0, 28.0, 19.0, 23.0, 25.0, 7.0, 0.0, 22.0, 26.0, 13.0, 13.0, 32.0, 32.0, 37.0, 65.0, 28.0, 16.0, 14.0, 1.0, 8.0, 6.0, 0.0, 3.0, 35.0, 41.0, 24.0, 11.0, 13.0, 27.0, 35.0, 29.0, 23.0, 26.0, 5.0, 11.0, 52.0, 49.0, 13.0, 27.0, 20.0, 29.0, 7.0, 32.0, 18.0, 30.0, 24.0, 23.0, 36.0, 4.0, 9.0, 27.0, 50.0, 52.0, 0.0, 5.0, 7.0, 4.0, 27.0, 27.0, 22.0, 13.0, 33.0, 33.0, 16.0, 16.0, 21.0, 6.0, 33.0, 46.0, 24.0, 11.0, 23.0, 7.0, 21.0, 32.0, 0.0, 3.0, 16.0, 20.0, 9.0, 14.0, 18.0, 26.0, 11.0, 24.0, 18.0, 13.0, 12.0, 9.0, 19.0, 6.0, 3.0, 4.0, 34.0, 10.0, 29.0, 41.0, 22.0, 5.0, 30.0, 22.0, 22.0, 11.0, 17.0, 34.0, 33.0, 34.0, 54.0, 53.0, 50.0, 34.0, 32.0, 23.0, 13.0, 9.0, 3.0, 21.0, 14.0, 10.0, 27.0, 28.0, 29.0, 29.0, 47.0, 24.0, 45.0, 45.0, 14.0, 14.0, 7.0, 23.0, 20.0, 30.0, 30.0, 26.0, 9.0, 7.0, 59.0, 18.0, 18.0, 0.0, 29.0, 28.0, 30.0, 58.0, 17.0, 8.0, 53.0, 16.0, 37.0, 34.0, 51.0, 29.0, 32.0, 32.0, 49.0, 21.0, 26.0, 61.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5956735489787697, "mean_inference_ms": 1.8394341811764858, "mean_action_processing_ms": 0.2561262151107352, "mean_env_wait_ms": 0.19938169853890944, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003609776496887207, "StateBufferConnector_ms": 0.0031554698944091797, "ViewRequirementAgentConnector_ms": 0.09897291660308838}, "num_episodes": 23, "episode_return_max": 362.9, "episode_return_min": 112.19999999999993, "episode_return_mean": 275.268, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1392000, "num_agent_steps_trained": 1392000, "num_env_steps_sampled": 348000, "num_env_steps_trained": 348000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 378.3309728072674, "num_env_steps_trained_throughput_per_sec": 378.3309728072674, "timesteps_total": 348000, "num_env_steps_sampled_lifetime": 348000, "num_agent_steps_sampled_lifetime": 1392000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1392000, "timers": {"training_iteration_time_ms": 10678.244, "restore_workers_time_ms": 0.014, "training_step_time_ms": 10678.2, "sample_time_ms": 1285.702, "learn_time_ms": 9377.199, "learn_throughput": 426.567, "synch_weights_time_ms": 13.858}, "counters": {"num_env_steps_sampled": 348000, "num_env_steps_trained": 348000, "num_agent_steps_sampled": 1392000, "num_agent_steps_trained": 1392000}, "done": false, "training_iteration": 87, "trial_id": "3dae5_00000", "date": "2024-08-14_09-22-45", "timestamp": 1723641765, "time_this_iter_s": 10.578978776931763, "time_total_s": 2584.26837515831, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3680e50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2584.26837515831, "iterations_since_restore": 87, "perf": {"cpu_util_percent": 28.55333333333333, "ram_util_percent": 83.66666666666667}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.584552464031038, "cur_kl_coeff": 0.056250000000000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.6438519612821954, "policy_loss": -0.005416619601886148, "vf_loss": 2.6488125259914095, "vf_explained_var": 0.19857859050155316, "kl": 0.008107466420055614, "entropy": 0.5598229350394042, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 165375.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.041962142816927, "cur_kl_coeff": 0.25312499999999993, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.780848466151606, "policy_loss": -0.004301295884411841, "vf_loss": 5.78276138015525, "vf_explained_var": 0.10441278433673597, "kl": 0.009435534080389113, "entropy": 1.3932215014462748, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 165375.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 352000, "num_env_steps_trained": 352000, "num_agent_steps_sampled": 1408000, "num_agent_steps_trained": 1408000}, "env_runners": {"episode_reward_max": 362.9, "episode_reward_min": 42.7, "episode_reward_mean": 268.68899999999996, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -101.80000000000001, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 194.60000000000002, "predator_policy": 113.0}, "policy_reward_mean": {"prey_policy": 109.26949999999997, "predator_policy": 25.075}, "custom_metrics": {}, "hist_stats": {"episode_reward": [362.9, 304.5999999999999, 193.19999999999936, 313.7999999999999, 350.5, 347.29999999999995, 136.5999999999997, 323.70000000000005, 261.19999999999993, 272.8, 283.5, 183.09999999999943, 337.79999999999995, 192.39999999999935, 183.79999999999936, 270.30000000000007, 279.5000000000001, 320.6, 353.90000000000015, 337.40000000000026, 254.7, 337.1000000000002, 295.70000000000005, 279.69999999999993, 307.6, 314.10000000000025, 268.40000000000003, 290.2000000000003, 255.99999999999991, 209.09999999999934, 316.8000000000004, 178.59999999999945, 292.79999999999984, 291.9999999999999, 309.89999999999986, 336.09999999999997, 249.49999999999994, 292.50000000000017, 320.80000000000007, 252.89999999999986, 349.0000000000002, 292.0, 335.0999999999999, 293.1, 246.60000000000008, 331.1, 330.9999999999999, 292.39999999999986, 340.10000000000014, 112.19999999999993, 276.2000000000001, 312.4, 321.8, 317.80000000000007, 160.59999999999968, 326.30000000000007, 296.4, 300.1, 317.59999999999997, 164.29999999999959, 301.6, 324.1, 305.00000000000006, 308.5999999999998, 229.8, 275.19999999999976, 359.9000000000002, 302.79999999999984, 235.79999999999978, 260.9999999999999, 184.09999999999928, 203.69999999999996, 166.89999999999947, 335.80000000000007, 193.39999999999995, 280.70000000000005, 205.9, 305.10000000000036, 170.69999999999985, 317.9, 268.6999999999999, 193.30000000000004, 297.6, 341.1, 325.7, 228.09999999999997, 162.70000000000002, 202.2999999999999, 245.99999999999994, 351.5000000000002, 317.59999999999997, 135.6, 156.99999999999997, 332.10000000000025, 337.2000000000001, 299.40000000000015, 42.7, 52.7, 283.7999999999999, 46.299999999999955], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [169.09999999999997, 192.79999999999998, 164.29999999999995, 41.30000000000001, 20.000000000000014, 153.2, 140.29999999999995, 126.49999999999997, 116.9, 185.6, 175.7, 164.6, -34.59999999999975, 123.2, 139.09999999999997, 158.59999999999997, 97.69999999999997, 99.5, 187.1, -16.300000000000047, 108.19999999999999, 131.29999999999995, 11.599999999999964, 156.49999999999997, 167.6, 156.2, 169.39999999999998, 20.000000000000014, -66.1000000000009, 173.89999999999995, 127.99999999999987, 107.29999999999995, 107.29999999999997, 132.2, 181.1, 75.5, 121.1, 183.79999999999993, 177.49999999999994, 143.89999999999992, 49.39999999999999, 104.30000000000001, 136.99999999999994, 160.1, 127.4, 119.30000000000001, 124.1, 116.59999999999997, 104.29999999999998, 155.3, 165.19999999999993, 101.89999999999993, 163.39999999999998, 64.99999999999997, 141.8, 112.39999999999995, 93.49999999999994, 60.50000000000001, 194.60000000000002, 9.499999999999964, 156.5, 149.2999999999999, 13.699999999999964, 110.9, 119.59999999999995, 138.19999999999993, 80.0, 146.0, 141.2, 136.6999999999999, 172.0999999999999, 137.0, 37.399999999999984, 133.09999999999994, 129.20000000000002, 128.29999999999995, 121.99999999999994, 168.79999999999998, 108.50000000000003, 91.39999999999998, 171.19999999999993, 174.79999999999998, 132.49999999999997, 123.50000000000003, 162.19999999999996, 149.89999999999995, 113.3, 135.79999999999995, 89.30000000000007, 122.30000000000003, 165.8, 134.29999999999995, 156.5, 153.49999999999994, 132.20000000000002, 135.2, 191.0, 142.09999999999988, 119.60000000000005, -51.40000000000005, 86.89999999999995, 119.3, 154.4, 131.0, 162.79999999999998, 107.0, 127.39999999999999, 157.39999999999998, 116.59999999999997, -7.000000000000028, 172.09999999999994, 87.19999999999999, 34.400000000000006, 155.0, 182.90000000000003, 33.19999999999996, 94.10000000000002, 168.49999999999994, 141.20000000000005, 1.0999999999999865, 144.19999999999993, 133.39999999999998, 144.49999999999994, 155.60000000000002, 99.79999999999997, 150.19999999999993, 138.7999999999999, 111.80000000000004, 115.39999999999999, 43.40000000000002, 99.80000000000004, 85.4, 183.8, 148.09999999999994, 149.89999999999992, 122.89999999999998, 98.29999999999993, 87.50000000000003, 133.39999999999992, 71.60000000000004, 5.299999999999965, 162.79999999999993, 16.699999999999996, 110.0, 128.89999999999998, 20.000000000000014, 88.1, 190.7, 35.29999999999998, 70.09999999999998, 142.69999999999996, 112.99999999999987, 46.09999999999998, 90.8, 155.89999999999972, 78.2, 54.20000000000003, 36.5, 142.4, 111.50000000000001, 161.89999999999998, 36.80000000000001, 66.5, 39.79999999999998, 145.99999999999997, 104.6, 141.8, 170.29999999999998, 103.4, 173.3, 47.90000000000001, 99.2, 56.3, 13.399999999999949, 61.400000000000034, 65.89999999999999, 82.70000000000002, 101.30000000000001, 162.79999999999995, 178.69999999999993, 109.10000000000001, 177.5, 21.200000000000017, 16.4, -10.0, 20.000000000000014, 169.4, 136.69999999999993, 140.59999999999997, 176.6, 127.39999999999996, 130.99999999999997, -12.699999999999974, -34.599999999999994, 0.20000000000000284, -86.5, 84.80000000000001, 155.0, -101.80000000000001, 7.1000000000000085], "policy_predator_policy_reward": [0.0, 1.0, 47.0, 52.0, 14.0, 6.0, 28.0, 19.0, 23.0, 25.0, 7.0, 0.0, 22.0, 26.0, 13.0, 13.0, 32.0, 32.0, 37.0, 65.0, 28.0, 16.0, 14.0, 1.0, 8.0, 6.0, 0.0, 3.0, 35.0, 41.0, 24.0, 11.0, 13.0, 27.0, 35.0, 29.0, 23.0, 26.0, 5.0, 11.0, 52.0, 49.0, 13.0, 27.0, 20.0, 29.0, 7.0, 32.0, 18.0, 30.0, 24.0, 23.0, 36.0, 4.0, 9.0, 27.0, 50.0, 52.0, 0.0, 5.0, 7.0, 4.0, 27.0, 27.0, 22.0, 13.0, 33.0, 33.0, 16.0, 16.0, 21.0, 6.0, 33.0, 46.0, 24.0, 11.0, 23.0, 7.0, 21.0, 32.0, 0.0, 3.0, 16.0, 20.0, 9.0, 14.0, 18.0, 26.0, 11.0, 24.0, 18.0, 13.0, 12.0, 9.0, 19.0, 6.0, 3.0, 4.0, 34.0, 10.0, 29.0, 41.0, 22.0, 5.0, 30.0, 22.0, 22.0, 11.0, 17.0, 34.0, 33.0, 34.0, 54.0, 53.0, 50.0, 34.0, 32.0, 23.0, 13.0, 9.0, 3.0, 21.0, 14.0, 10.0, 27.0, 28.0, 29.0, 29.0, 47.0, 24.0, 45.0, 45.0, 14.0, 14.0, 7.0, 23.0, 20.0, 30.0, 30.0, 26.0, 9.0, 7.0, 59.0, 18.0, 18.0, 0.0, 29.0, 28.0, 30.0, 58.0, 17.0, 8.0, 53.0, 16.0, 37.0, 34.0, 51.0, 29.0, 32.0, 32.0, 49.0, 21.0, 26.0, 61.0, 26.0, 21.0, 17.0, 12.0, 20.0, 29.0, 51.0, 30.0, 50.0, 43.0, 30.0, 45.0, 50.0, 12.0, 7.0, 3.0, 13.0, 18.0, 19.0, 79.0, 76.0, 71.0, 16.0, 10.0, 9.0, 11.0, 19.0, 22.0, 0.0, 90.0, 26.0, 113.0, 8.0, 36.0, 70.0, 71.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5950502958424355, "mean_inference_ms": 1.8379430772604806, "mean_action_processing_ms": 0.25576806235161365, "mean_env_wait_ms": 0.19917365604823128, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00354921817779541, "StateBufferConnector_ms": 0.0030744075775146484, "ViewRequirementAgentConnector_ms": 0.08928823471069336}, "num_episodes": 18, "episode_return_max": 362.9, "episode_return_min": 42.7, "episode_return_mean": 268.68899999999996, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1408000, "num_agent_steps_trained": 1408000, "num_env_steps_sampled": 352000, "num_env_steps_trained": 352000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 389.7591650651675, "num_env_steps_trained_throughput_per_sec": 389.7591650651675, "timesteps_total": 352000, "num_env_steps_sampled_lifetime": 352000, "num_agent_steps_sampled_lifetime": 1408000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1408000, "timers": {"training_iteration_time_ms": 10607.22, "restore_workers_time_ms": 0.014, "training_step_time_ms": 10607.176, "sample_time_ms": 1271.076, "learn_time_ms": 9320.264, "learn_throughput": 429.172, "synch_weights_time_ms": 14.385}, "counters": {"num_env_steps_sampled": 352000, "num_env_steps_trained": 352000, "num_agent_steps_sampled": 1408000, "num_agent_steps_trained": 1408000}, "done": false, "training_iteration": 88, "trial_id": "3dae5_00000", "date": "2024-08-14_09-22-55", "timestamp": 1723641775, "time_this_iter_s": 10.292337894439697, "time_total_s": 2594.5607130527496, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b0fef160>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2594.5607130527496, "iterations_since_restore": 88, "perf": {"cpu_util_percent": 27.093333333333327, "ram_util_percent": 83.70666666666666}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.586703120999866, "cur_kl_coeff": 0.056250000000000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.8119834875934338, "policy_loss": -0.007462849961372003, "vf_loss": 3.8187676330092093, "vf_explained_var": 0.14965899410071196, "kl": 0.012065886395219534, "entropy": 0.5178941455467668, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 167265.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.379644373548094, "cur_kl_coeff": 0.25312499999999993, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.47534118833996, "policy_loss": -0.003994093078223092, "vf_loss": 6.477935306861918, "vf_explained_var": 0.23424809903064103, "kl": 0.005530817047948493, "entropy": 1.3642065373047318, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 167265.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 356000, "num_env_steps_trained": 356000, "num_agent_steps_sampled": 1424000, "num_agent_steps_trained": 1424000}, "env_runners": {"episode_reward_max": 359.9000000000002, "episode_reward_min": 20.599999999999852, "episode_reward_mean": 245.03499999999997, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -101.80000000000001, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 194.60000000000002, "predator_policy": 113.0}, "policy_reward_mean": {"prey_policy": 94.01749999999998, "predator_policy": 28.5}, "custom_metrics": {}, "hist_stats": {"episode_reward": [295.70000000000005, 279.69999999999993, 307.6, 314.10000000000025, 268.40000000000003, 290.2000000000003, 255.99999999999991, 209.09999999999934, 316.8000000000004, 178.59999999999945, 292.79999999999984, 291.9999999999999, 309.89999999999986, 336.09999999999997, 249.49999999999994, 292.50000000000017, 320.80000000000007, 252.89999999999986, 349.0000000000002, 292.0, 335.0999999999999, 293.1, 246.60000000000008, 331.1, 330.9999999999999, 292.39999999999986, 340.10000000000014, 112.19999999999993, 276.2000000000001, 312.4, 321.8, 317.80000000000007, 160.59999999999968, 326.30000000000007, 296.4, 300.1, 317.59999999999997, 164.29999999999959, 301.6, 324.1, 305.00000000000006, 308.5999999999998, 229.8, 275.19999999999976, 359.9000000000002, 302.79999999999984, 235.79999999999978, 260.9999999999999, 184.09999999999928, 203.69999999999996, 166.89999999999947, 335.80000000000007, 193.39999999999995, 280.70000000000005, 205.9, 305.10000000000036, 170.69999999999985, 317.9, 268.6999999999999, 193.30000000000004, 297.6, 341.1, 325.7, 228.09999999999997, 162.70000000000002, 202.2999999999999, 245.99999999999994, 351.5000000000002, 317.59999999999997, 135.6, 156.99999999999997, 332.10000000000025, 337.2000000000001, 299.40000000000015, 42.7, 52.7, 283.7999999999999, 46.299999999999955, 109.90000000000006, 184.19999999999942, 171.19999999999993, 329.9, 92.69999999999993, 80.20000000000003, 152.7, 301.39999999999975, 30.599999999999838, 253.29999999999993, 266.9999999999999, 72.60000000000012, 334.5000000000003, 89.39999999999999, 199.89999999999932, 175.99999999999974, 293.29999999999995, 166.39999999999998, 150.4, 20.599999999999852, 140.2, 218.89999999999995], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [127.4, 119.30000000000001, 124.1, 116.59999999999997, 104.29999999999998, 155.3, 165.19999999999993, 101.89999999999993, 163.39999999999998, 64.99999999999997, 141.8, 112.39999999999995, 93.49999999999994, 60.50000000000001, 194.60000000000002, 9.499999999999964, 156.5, 149.2999999999999, 13.699999999999964, 110.9, 119.59999999999995, 138.19999999999993, 80.0, 146.0, 141.2, 136.6999999999999, 172.0999999999999, 137.0, 37.399999999999984, 133.09999999999994, 129.20000000000002, 128.29999999999995, 121.99999999999994, 168.79999999999998, 108.50000000000003, 91.39999999999998, 171.19999999999993, 174.79999999999998, 132.49999999999997, 123.50000000000003, 162.19999999999996, 149.89999999999995, 113.3, 135.79999999999995, 89.30000000000007, 122.30000000000003, 165.8, 134.29999999999995, 156.5, 153.49999999999994, 132.20000000000002, 135.2, 191.0, 142.09999999999988, 119.60000000000005, -51.40000000000005, 86.89999999999995, 119.3, 154.4, 131.0, 162.79999999999998, 107.0, 127.39999999999999, 157.39999999999998, 116.59999999999997, -7.000000000000028, 172.09999999999994, 87.19999999999999, 34.400000000000006, 155.0, 182.90000000000003, 33.19999999999996, 94.10000000000002, 168.49999999999994, 141.20000000000005, 1.0999999999999865, 144.19999999999993, 133.39999999999998, 144.49999999999994, 155.60000000000002, 99.79999999999997, 150.19999999999993, 138.7999999999999, 111.80000000000004, 115.39999999999999, 43.40000000000002, 99.80000000000004, 85.4, 183.8, 148.09999999999994, 149.89999999999992, 122.89999999999998, 98.29999999999993, 87.50000000000003, 133.39999999999992, 71.60000000000004, 5.299999999999965, 162.79999999999993, 16.699999999999996, 110.0, 128.89999999999998, 20.000000000000014, 88.1, 190.7, 35.29999999999998, 70.09999999999998, 142.69999999999996, 112.99999999999987, 46.09999999999998, 90.8, 155.89999999999972, 78.2, 54.20000000000003, 36.5, 142.4, 111.50000000000001, 161.89999999999998, 36.80000000000001, 66.5, 39.79999999999998, 145.99999999999997, 104.6, 141.8, 170.29999999999998, 103.4, 173.3, 47.90000000000001, 99.2, 56.3, 13.399999999999949, 61.400000000000034, 65.89999999999999, 82.70000000000002, 101.30000000000001, 162.79999999999995, 178.69999999999993, 109.10000000000001, 177.5, 21.200000000000017, 16.4, -10.0, 20.000000000000014, 169.4, 136.69999999999993, 140.59999999999997, 176.6, 127.39999999999996, 130.99999999999997, -12.699999999999974, -34.599999999999994, 0.20000000000000284, -86.5, 84.80000000000001, 155.0, -101.80000000000001, 7.1000000000000085, 2.300000000000047, 5.599999999999994, 108.2, 20.000000000000014, 59.00000000000001, 45.2, 157.99999999999997, 152.9, -0.3999999999999666, -19.89999999999997, 2.900000000000002, -39.69999999999998, -20.20000000000003, 83.89999999999999, 139.99999999999997, 124.39999999999995, -65.80000000000001, -4.599999999999996, 93.49999999999999, 117.8, 82.4, 134.5999999999999, 3.1999999999999615, -1.5999999999999819, 172.9999999999999, 117.5, -73.0, 37.400000000000006, 5.299999999999965, 182.59999999999997, 113.6, 7.399999999999977, 97.99999999999997, 161.3, 43.400000000000006, 44.00000000000003, 43.400000000000006, -1.0, -70.30000000000001, -15.100000000000122, 13.400000000000006, 3.799999999999997, 44.900000000000006, 80.00000000000001], "policy_predator_policy_reward": [20.0, 29.0, 7.0, 32.0, 18.0, 30.0, 24.0, 23.0, 36.0, 4.0, 9.0, 27.0, 50.0, 52.0, 0.0, 5.0, 7.0, 4.0, 27.0, 27.0, 22.0, 13.0, 33.0, 33.0, 16.0, 16.0, 21.0, 6.0, 33.0, 46.0, 24.0, 11.0, 23.0, 7.0, 21.0, 32.0, 0.0, 3.0, 16.0, 20.0, 9.0, 14.0, 18.0, 26.0, 11.0, 24.0, 18.0, 13.0, 12.0, 9.0, 19.0, 6.0, 3.0, 4.0, 34.0, 10.0, 29.0, 41.0, 22.0, 5.0, 30.0, 22.0, 22.0, 11.0, 17.0, 34.0, 33.0, 34.0, 54.0, 53.0, 50.0, 34.0, 32.0, 23.0, 13.0, 9.0, 3.0, 21.0, 14.0, 10.0, 27.0, 28.0, 29.0, 29.0, 47.0, 24.0, 45.0, 45.0, 14.0, 14.0, 7.0, 23.0, 20.0, 30.0, 30.0, 26.0, 9.0, 7.0, 59.0, 18.0, 18.0, 0.0, 29.0, 28.0, 30.0, 58.0, 17.0, 8.0, 53.0, 16.0, 37.0, 34.0, 51.0, 29.0, 32.0, 32.0, 49.0, 21.0, 26.0, 61.0, 26.0, 21.0, 17.0, 12.0, 20.0, 29.0, 51.0, 30.0, 50.0, 43.0, 30.0, 45.0, 50.0, 12.0, 7.0, 3.0, 13.0, 18.0, 19.0, 79.0, 76.0, 71.0, 16.0, 10.0, 9.0, 11.0, 19.0, 22.0, 0.0, 90.0, 26.0, 113.0, 8.0, 36.0, 70.0, 71.0, 36.0, 66.0, 26.0, 30.0, 11.0, 56.0, 4.0, 15.0, 37.0, 76.0, 12.0, 105.0, 39.0, 50.0, 22.0, 15.0, 55.0, 46.0, 30.0, 12.0, 9.0, 41.0, 27.0, 44.0, 25.0, 19.0, 13.0, 112.0, 7.0, 5.0, 40.0, 15.0, 8.0, 26.0, 12.0, 67.0, 77.0, 31.0, 2.0, 104.0, 54.0, 69.0, 37.0, 57.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5944080221714881, "mean_inference_ms": 1.8362047529722987, "mean_action_processing_ms": 0.2548889689908962, "mean_env_wait_ms": 0.19914651184657978, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0036351680755615234, "StateBufferConnector_ms": 0.003003239631652832, "ViewRequirementAgentConnector_ms": 0.09075260162353516}, "num_episodes": 22, "episode_return_max": 359.9000000000002, "episode_return_min": 20.599999999999852, "episode_return_mean": 245.03499999999997, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1424000, "num_agent_steps_trained": 1424000, "num_env_steps_sampled": 356000, "num_env_steps_trained": 356000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 375.2894380009564, "num_env_steps_trained_throughput_per_sec": 375.2894380009564, "timesteps_total": 356000, "num_env_steps_sampled_lifetime": 356000, "num_agent_steps_sampled_lifetime": 1424000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1424000, "timers": {"training_iteration_time_ms": 10582.633, "restore_workers_time_ms": 0.014, "training_step_time_ms": 10582.588, "sample_time_ms": 1281.525, "learn_time_ms": 9284.848, "learn_throughput": 430.809, "synch_weights_time_ms": 14.764}, "counters": {"num_env_steps_sampled": 356000, "num_env_steps_trained": 356000, "num_agent_steps_sampled": 1424000, "num_agent_steps_trained": 1424000}, "done": false, "training_iteration": 89, "trial_id": "3dae5_00000", "date": "2024-08-14_09-23-06", "timestamp": 1723641786, "time_this_iter_s": 10.663954973220825, "time_total_s": 2605.2246680259705, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b36b6c10>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2605.2246680259705, "iterations_since_restore": 89, "perf": {"cpu_util_percent": 29.42666666666667, "ram_util_percent": 83.31999999999998}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.6336566722582258, "cur_kl_coeff": 0.056250000000000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.4609533780466313, "policy_loss": -0.004804640177578207, "vf_loss": 3.4655510280498123, "vf_explained_var": 0.104787309522982, "kl": 0.0036797664525928904, "entropy": 0.4496223978106938, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 169155.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.4531035177291387, "cur_kl_coeff": 0.25312499999999993, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.385252278443997, "policy_loss": -0.003679387091422483, "vf_loss": 6.38677282333374, "vf_explained_var": 0.2426825170794492, "kl": 0.008528805296508301, "entropy": 1.3163314981435341, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 169155.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 360000, "num_env_steps_trained": 360000, "num_agent_steps_sampled": 1440000, "num_agent_steps_trained": 1440000}, "env_runners": {"episode_reward_max": 365.20000000000016, "episode_reward_min": -130.10000000000002, "episode_reward_mean": 228.45499999999993, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -188.20000000000002, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 191.0, "predator_policy": 131.0}, "policy_reward_mean": {"prey_policy": 83.47249999999998, "predator_policy": 30.755}, "custom_metrics": {}, "hist_stats": {"episode_reward": [349.0000000000002, 292.0, 335.0999999999999, 293.1, 246.60000000000008, 331.1, 330.9999999999999, 292.39999999999986, 340.10000000000014, 112.19999999999993, 276.2000000000001, 312.4, 321.8, 317.80000000000007, 160.59999999999968, 326.30000000000007, 296.4, 300.1, 317.59999999999997, 164.29999999999959, 301.6, 324.1, 305.00000000000006, 308.5999999999998, 229.8, 275.19999999999976, 359.9000000000002, 302.79999999999984, 235.79999999999978, 260.9999999999999, 184.09999999999928, 203.69999999999996, 166.89999999999947, 335.80000000000007, 193.39999999999995, 280.70000000000005, 205.9, 305.10000000000036, 170.69999999999985, 317.9, 268.6999999999999, 193.30000000000004, 297.6, 341.1, 325.7, 228.09999999999997, 162.70000000000002, 202.2999999999999, 245.99999999999994, 351.5000000000002, 317.59999999999997, 135.6, 156.99999999999997, 332.10000000000025, 337.2000000000001, 299.40000000000015, 42.7, 52.7, 283.7999999999999, 46.299999999999955, 109.90000000000006, 184.19999999999942, 171.19999999999993, 329.9, 92.69999999999993, 80.20000000000003, 152.7, 301.39999999999975, 30.599999999999838, 253.29999999999993, 266.9999999999999, 72.60000000000012, 334.5000000000003, 89.39999999999999, 199.89999999999932, 175.99999999999974, 293.29999999999995, 166.39999999999998, 150.4, 20.599999999999852, 140.2, 218.89999999999995, 199.0, 89.99999999999952, 148.49999999999994, 333.90000000000026, -130.10000000000002, 164.39999999999955, 218.59999999999988, 208.2999999999992, 138.19999999999987, 336.0, 255.99999999999991, 302.09999999999997, -96.20000000000016, 294.60000000000025, 365.20000000000016, 125.49999999999963, 339.4000000000002, 111.29999999999984], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [171.19999999999993, 174.79999999999998, 132.49999999999997, 123.50000000000003, 162.19999999999996, 149.89999999999995, 113.3, 135.79999999999995, 89.30000000000007, 122.30000000000003, 165.8, 134.29999999999995, 156.5, 153.49999999999994, 132.20000000000002, 135.2, 191.0, 142.09999999999988, 119.60000000000005, -51.40000000000005, 86.89999999999995, 119.3, 154.4, 131.0, 162.79999999999998, 107.0, 127.39999999999999, 157.39999999999998, 116.59999999999997, -7.000000000000028, 172.09999999999994, 87.19999999999999, 34.400000000000006, 155.0, 182.90000000000003, 33.19999999999996, 94.10000000000002, 168.49999999999994, 141.20000000000005, 1.0999999999999865, 144.19999999999993, 133.39999999999998, 144.49999999999994, 155.60000000000002, 99.79999999999997, 150.19999999999993, 138.7999999999999, 111.80000000000004, 115.39999999999999, 43.40000000000002, 99.80000000000004, 85.4, 183.8, 148.09999999999994, 149.89999999999992, 122.89999999999998, 98.29999999999993, 87.50000000000003, 133.39999999999992, 71.60000000000004, 5.299999999999965, 162.79999999999993, 16.699999999999996, 110.0, 128.89999999999998, 20.000000000000014, 88.1, 190.7, 35.29999999999998, 70.09999999999998, 142.69999999999996, 112.99999999999987, 46.09999999999998, 90.8, 155.89999999999972, 78.2, 54.20000000000003, 36.5, 142.4, 111.50000000000001, 161.89999999999998, 36.80000000000001, 66.5, 39.79999999999998, 145.99999999999997, 104.6, 141.8, 170.29999999999998, 103.4, 173.3, 47.90000000000001, 99.2, 56.3, 13.399999999999949, 61.400000000000034, 65.89999999999999, 82.70000000000002, 101.30000000000001, 162.79999999999995, 178.69999999999993, 109.10000000000001, 177.5, 21.200000000000017, 16.4, -10.0, 20.000000000000014, 169.4, 136.69999999999993, 140.59999999999997, 176.6, 127.39999999999996, 130.99999999999997, -12.699999999999974, -34.599999999999994, 0.20000000000000284, -86.5, 84.80000000000001, 155.0, -101.80000000000001, 7.1000000000000085, 2.300000000000047, 5.599999999999994, 108.2, 20.000000000000014, 59.00000000000001, 45.2, 157.99999999999997, 152.9, -0.3999999999999666, -19.89999999999997, 2.900000000000002, -39.69999999999998, -20.20000000000003, 83.89999999999999, 139.99999999999997, 124.39999999999995, -65.80000000000001, -4.599999999999996, 93.49999999999999, 117.8, 82.4, 134.5999999999999, 3.1999999999999615, -1.5999999999999819, 172.9999999999999, 117.5, -73.0, 37.400000000000006, 5.299999999999965, 182.59999999999997, 113.6, 7.399999999999977, 97.99999999999997, 161.3, 43.400000000000006, 44.00000000000003, 43.400000000000006, -1.0, -70.30000000000001, -15.100000000000122, 13.400000000000006, 3.799999999999997, 44.900000000000006, 80.00000000000001, 125.29999999999993, 13.699999999999982, 7.400000000000018, 14.599999999999966, 40.70000000000003, 18.800000000000008, 178.39999999999992, 99.50000000000001, -88.9, -188.20000000000002, 109.4, 20.000000000000014, 55.70000000000004, 68.89999999999998, 20.000000000000014, 188.29999999999993, -44.8, 2.000000000000024, 147.49999999999994, 168.49999999999994, 29.59999999999995, 130.4, 128.0, 124.1, -91.3000000000001, -157.90000000000006, 125.89999999999996, 136.69999999999996, 126.19999999999999, 190.99999999999997, 69.50000000000003, 20.000000000000014, 181.99999999999997, 136.39999999999992, 38.29999999999999, 20.000000000000014], "policy_predator_policy_reward": [0.0, 3.0, 16.0, 20.0, 9.0, 14.0, 18.0, 26.0, 11.0, 24.0, 18.0, 13.0, 12.0, 9.0, 19.0, 6.0, 3.0, 4.0, 34.0, 10.0, 29.0, 41.0, 22.0, 5.0, 30.0, 22.0, 22.0, 11.0, 17.0, 34.0, 33.0, 34.0, 54.0, 53.0, 50.0, 34.0, 32.0, 23.0, 13.0, 9.0, 3.0, 21.0, 14.0, 10.0, 27.0, 28.0, 29.0, 29.0, 47.0, 24.0, 45.0, 45.0, 14.0, 14.0, 7.0, 23.0, 20.0, 30.0, 30.0, 26.0, 9.0, 7.0, 59.0, 18.0, 18.0, 0.0, 29.0, 28.0, 30.0, 58.0, 17.0, 8.0, 53.0, 16.0, 37.0, 34.0, 51.0, 29.0, 32.0, 32.0, 49.0, 21.0, 26.0, 61.0, 26.0, 21.0, 17.0, 12.0, 20.0, 29.0, 51.0, 30.0, 50.0, 43.0, 30.0, 45.0, 50.0, 12.0, 7.0, 3.0, 13.0, 18.0, 19.0, 79.0, 76.0, 71.0, 16.0, 10.0, 9.0, 11.0, 19.0, 22.0, 0.0, 90.0, 26.0, 113.0, 8.0, 36.0, 70.0, 71.0, 36.0, 66.0, 26.0, 30.0, 11.0, 56.0, 4.0, 15.0, 37.0, 76.0, 12.0, 105.0, 39.0, 50.0, 22.0, 15.0, 55.0, 46.0, 30.0, 12.0, 9.0, 41.0, 27.0, 44.0, 25.0, 19.0, 13.0, 112.0, 7.0, 5.0, 40.0, 15.0, 8.0, 26.0, 12.0, 67.0, 77.0, 31.0, 2.0, 104.0, 54.0, 69.0, 37.0, 57.0, 33.0, 27.0, 10.0, 58.0, 68.0, 21.0, 29.0, 27.0, 16.0, 131.0, 10.0, 25.0, 38.0, 56.0, 0.0, 0.0, 75.0, 106.0, 10.0, 10.0, 49.0, 47.0, 25.0, 25.0, 111.0, 42.0, 16.0, 16.0, 24.0, 24.0, 0.0, 36.0, 13.0, 8.0, 0.0, 53.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5938661264970542, "mean_inference_ms": 1.8349973765679704, "mean_action_processing_ms": 0.2550845122785631, "mean_env_wait_ms": 0.1988705186762052, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00359189510345459, "StateBufferConnector_ms": 0.0029544830322265625, "ViewRequirementAgentConnector_ms": 0.09014296531677246}, "num_episodes": 18, "episode_return_max": 365.20000000000016, "episode_return_min": -130.10000000000002, "episode_return_mean": 228.45499999999993, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1440000, "num_agent_steps_trained": 1440000, "num_env_steps_sampled": 360000, "num_env_steps_trained": 360000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 382.97338285938486, "num_env_steps_trained_throughput_per_sec": 382.97338285938486, "timesteps_total": 360000, "num_env_steps_sampled_lifetime": 360000, "num_agent_steps_sampled_lifetime": 1440000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1440000, "timers": {"training_iteration_time_ms": 10595.497, "restore_workers_time_ms": 0.014, "training_step_time_ms": 10595.452, "sample_time_ms": 1276.659, "learn_time_ms": 9302.663, "learn_throughput": 429.984, "synch_weights_time_ms": 14.665}, "counters": {"num_env_steps_sampled": 360000, "num_env_steps_trained": 360000, "num_agent_steps_sampled": 1440000, "num_agent_steps_trained": 1440000}, "done": false, "training_iteration": 90, "trial_id": "3dae5_00000", "date": "2024-08-14_09-23-16", "timestamp": 1723641796, "time_this_iter_s": 10.474185228347778, "time_total_s": 2615.6988532543182, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b381b8b0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2615.6988532543182, "iterations_since_restore": 90, "perf": {"cpu_util_percent": 28.286666666666672, "ram_util_percent": 83.37333333333332}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.872897167779781, "cur_kl_coeff": 0.028125000000000008, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.191552969892189, "policy_loss": -0.00437496386729575, "vf_loss": 3.1957752041085055, "vf_explained_var": 0.08991722735778365, "kl": 0.005430717334479475, "entropy": 0.3957669826254012, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 171045.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.3376537415085648, "cur_kl_coeff": 0.25312499999999993, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.945840374880998, "policy_loss": -0.004183690472279316, "vf_loss": 5.948262063283769, "vf_explained_var": 0.1355943851054661, "kl": 0.0069609745465307165, "entropy": 1.335704877830687, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 171045.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 364000, "num_env_steps_trained": 364000, "num_agent_steps_sampled": 1456000, "num_agent_steps_trained": 1456000}, "env_runners": {"episode_reward_max": 365.20000000000016, "episode_reward_min": -206.70000000000022, "episode_reward_mean": 193.2949999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -216.10000000000005, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 190.99999999999997, "predator_policy": 164.0}, "policy_reward_mean": {"prey_policy": 61.07749999999999, "predator_policy": 35.57}, "custom_metrics": {}, "hist_stats": {"episode_reward": [308.5999999999998, 229.8, 275.19999999999976, 359.9000000000002, 302.79999999999984, 235.79999999999978, 260.9999999999999, 184.09999999999928, 203.69999999999996, 166.89999999999947, 335.80000000000007, 193.39999999999995, 280.70000000000005, 205.9, 305.10000000000036, 170.69999999999985, 317.9, 268.6999999999999, 193.30000000000004, 297.6, 341.1, 325.7, 228.09999999999997, 162.70000000000002, 202.2999999999999, 245.99999999999994, 351.5000000000002, 317.59999999999997, 135.6, 156.99999999999997, 332.10000000000025, 337.2000000000001, 299.40000000000015, 42.7, 52.7, 283.7999999999999, 46.299999999999955, 109.90000000000006, 184.19999999999942, 171.19999999999993, 329.9, 92.69999999999993, 80.20000000000003, 152.7, 301.39999999999975, 30.599999999999838, 253.29999999999993, 266.9999999999999, 72.60000000000012, 334.5000000000003, 89.39999999999999, 199.89999999999932, 175.99999999999974, 293.29999999999995, 166.39999999999998, 150.4, 20.599999999999852, 140.2, 218.89999999999995, 199.0, 89.99999999999952, 148.49999999999994, 333.90000000000026, -130.10000000000002, 164.39999999999955, 218.59999999999988, 208.2999999999992, 138.19999999999987, 336.0, 255.99999999999991, 302.09999999999997, -96.20000000000016, 294.60000000000025, 365.20000000000016, 125.49999999999963, 339.4000000000002, 111.29999999999984, 160.69999999999982, 305.7000000000001, -58.99999999999999, 281.19999999999993, 268.1999999999999, -20.300000000000068, 193.6999999999999, 139.6999999999999, 210.69999999999987, -57.49999999999988, 325.4, 295.79999999999995, 8.600000000000026, 36.80000000000003, 113.90000000000003, -206.70000000000022, 269.5, 9.500000000000016, 325.6000000000001, 177.89999999999938, -34.199999999999825, 222.69999999999993, 162.89999999999944], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [138.7999999999999, 111.80000000000004, 115.39999999999999, 43.40000000000002, 99.80000000000004, 85.4, 183.8, 148.09999999999994, 149.89999999999992, 122.89999999999998, 98.29999999999993, 87.50000000000003, 133.39999999999992, 71.60000000000004, 5.299999999999965, 162.79999999999993, 16.699999999999996, 110.0, 128.89999999999998, 20.000000000000014, 88.1, 190.7, 35.29999999999998, 70.09999999999998, 142.69999999999996, 112.99999999999987, 46.09999999999998, 90.8, 155.89999999999972, 78.2, 54.20000000000003, 36.5, 142.4, 111.50000000000001, 161.89999999999998, 36.80000000000001, 66.5, 39.79999999999998, 145.99999999999997, 104.6, 141.8, 170.29999999999998, 103.4, 173.3, 47.90000000000001, 99.2, 56.3, 13.399999999999949, 61.400000000000034, 65.89999999999999, 82.70000000000002, 101.30000000000001, 162.79999999999995, 178.69999999999993, 109.10000000000001, 177.5, 21.200000000000017, 16.4, -10.0, 20.000000000000014, 169.4, 136.69999999999993, 140.59999999999997, 176.6, 127.39999999999996, 130.99999999999997, -12.699999999999974, -34.599999999999994, 0.20000000000000284, -86.5, 84.80000000000001, 155.0, -101.80000000000001, 7.1000000000000085, 2.300000000000047, 5.599999999999994, 108.2, 20.000000000000014, 59.00000000000001, 45.2, 157.99999999999997, 152.9, -0.3999999999999666, -19.89999999999997, 2.900000000000002, -39.69999999999998, -20.20000000000003, 83.89999999999999, 139.99999999999997, 124.39999999999995, -65.80000000000001, -4.599999999999996, 93.49999999999999, 117.8, 82.4, 134.5999999999999, 3.1999999999999615, -1.5999999999999819, 172.9999999999999, 117.5, -73.0, 37.400000000000006, 5.299999999999965, 182.59999999999997, 113.6, 7.399999999999977, 97.99999999999997, 161.3, 43.400000000000006, 44.00000000000003, 43.400000000000006, -1.0, -70.30000000000001, -15.100000000000122, 13.400000000000006, 3.799999999999997, 44.900000000000006, 80.00000000000001, 125.29999999999993, 13.699999999999982, 7.400000000000018, 14.599999999999966, 40.70000000000003, 18.800000000000008, 178.39999999999992, 99.50000000000001, -88.9, -188.20000000000002, 109.4, 20.000000000000014, 55.70000000000004, 68.89999999999998, 20.000000000000014, 188.29999999999993, -44.8, 2.000000000000024, 147.49999999999994, 168.49999999999994, 29.59999999999995, 130.4, 128.0, 124.1, -91.3000000000001, -157.90000000000006, 125.89999999999996, 136.69999999999996, 126.19999999999999, 190.99999999999997, 69.50000000000003, 20.000000000000014, 181.99999999999997, 136.39999999999992, 38.29999999999999, 20.000000000000014, -18.099999999999966, 84.80000000000004, 151.69999999999993, 136.99999999999997, -115.6, -60.4, 95.60000000000001, 125.59999999999997, 124.39999999999999, 93.79999999999998, -85.90000000000003, -48.400000000000034, 48.200000000000024, 66.50000000000003, 22.699999999999996, 19.999999999999996, 46.400000000000034, 71.30000000000001, -207.40000000000003, 17.899999999999988, 123.19999999999996, 135.19999999999996, 101.90000000000002, 146.89999999999998, -105.4000000000001, 20.000000000000014, -26.499999999999993, -45.70000000000002, 11.900000000000013, -13.000000000000007, -172.60000000000016, -216.10000000000005, 62.90000000000001, 143.5999999999999, -39.099999999999994, -54.399999999999984, 148.69999999999996, 146.9, 20.000000000000014, 119.89999999999998, -137.20000000000007, -21.999999999999744, 88.69999999999999, 77.0, 158.59999999999994, -15.699999999999747], "policy_predator_policy_reward": [29.0, 29.0, 47.0, 24.0, 45.0, 45.0, 14.0, 14.0, 7.0, 23.0, 20.0, 30.0, 30.0, 26.0, 9.0, 7.0, 59.0, 18.0, 18.0, 0.0, 29.0, 28.0, 30.0, 58.0, 17.0, 8.0, 53.0, 16.0, 37.0, 34.0, 51.0, 29.0, 32.0, 32.0, 49.0, 21.0, 26.0, 61.0, 26.0, 21.0, 17.0, 12.0, 20.0, 29.0, 51.0, 30.0, 50.0, 43.0, 30.0, 45.0, 50.0, 12.0, 7.0, 3.0, 13.0, 18.0, 19.0, 79.0, 76.0, 71.0, 16.0, 10.0, 9.0, 11.0, 19.0, 22.0, 0.0, 90.0, 26.0, 113.0, 8.0, 36.0, 70.0, 71.0, 36.0, 66.0, 26.0, 30.0, 11.0, 56.0, 4.0, 15.0, 37.0, 76.0, 12.0, 105.0, 39.0, 50.0, 22.0, 15.0, 55.0, 46.0, 30.0, 12.0, 9.0, 41.0, 27.0, 44.0, 25.0, 19.0, 13.0, 112.0, 7.0, 5.0, 40.0, 15.0, 8.0, 26.0, 12.0, 67.0, 77.0, 31.0, 2.0, 104.0, 54.0, 69.0, 37.0, 57.0, 33.0, 27.0, 10.0, 58.0, 68.0, 21.0, 29.0, 27.0, 16.0, 131.0, 10.0, 25.0, 38.0, 56.0, 0.0, 0.0, 75.0, 106.0, 10.0, 10.0, 49.0, 47.0, 25.0, 25.0, 111.0, 42.0, 16.0, 16.0, 24.0, 24.0, 0.0, 36.0, 13.0, 8.0, 0.0, 53.0, 63.0, 31.0, 6.0, 11.0, 116.0, 1.0, 30.0, 30.0, 21.0, 29.0, 89.0, 25.0, 50.0, 29.0, 16.0, 81.0, 60.0, 33.0, 131.0, 1.0, 33.0, 34.0, 21.0, 26.0, 0.0, 94.0, 6.0, 103.0, 28.0, 87.0, 18.0, 164.0, 45.0, 18.0, 62.0, 41.0, 16.0, 14.0, 16.0, 22.0, 95.0, 30.0, 38.0, 19.0, 3.0, 17.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5933952952393664, "mean_inference_ms": 1.8318410281881683, "mean_action_processing_ms": 0.2550770949681882, "mean_env_wait_ms": 0.1987942851332457, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003966212272644043, "StateBufferConnector_ms": 0.0030900239944458008, "ViewRequirementAgentConnector_ms": 0.08997964859008789}, "num_episodes": 23, "episode_return_max": 365.20000000000016, "episode_return_min": -206.70000000000022, "episode_return_mean": 193.2949999999999, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1456000, "num_agent_steps_trained": 1456000, "num_env_steps_sampled": 364000, "num_env_steps_trained": 364000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 365.7051899583709, "num_env_steps_trained_throughput_per_sec": 365.7051899583709, "timesteps_total": 364000, "num_env_steps_sampled_lifetime": 364000, "num_agent_steps_sampled_lifetime": 1456000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1456000, "timers": {"training_iteration_time_ms": 10610.003, "restore_workers_time_ms": 0.014, "training_step_time_ms": 10609.958, "sample_time_ms": 1279.204, "learn_time_ms": 9313.633, "learn_throughput": 429.478, "synch_weights_time_ms": 15.516}, "counters": {"num_env_steps_sampled": 364000, "num_env_steps_trained": 364000, "num_agent_steps_sampled": 1456000, "num_agent_steps_trained": 1456000}, "done": false, "training_iteration": 91, "trial_id": "3dae5_00000", "date": "2024-08-14_09-23-27", "timestamp": 1723641807, "time_this_iter_s": 10.989874839782715, "time_total_s": 2626.688728094101, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b36e0430>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2626.688728094101, "iterations_since_restore": 91, "perf": {"cpu_util_percent": 30.08125, "ram_util_percent": 83.25625}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.0743343789741475, "cur_kl_coeff": 0.028125000000000008, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.740155868177061, "policy_loss": -0.004701395544085513, "vf_loss": 4.744675007068291, "vf_explained_var": 0.10742838776931561, "kl": 0.006480447257568071, "entropy": 0.3892319974918214, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 172935.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.9500572575778556, "cur_kl_coeff": 0.25312499999999993, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.347300407621596, "policy_loss": -0.002507437234769068, "vf_loss": 7.348335919556795, "vf_explained_var": -0.14931698365816995, "kl": 0.005814903702044815, "entropy": 1.299202153670094, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 172935.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 368000, "num_env_steps_trained": 368000, "num_agent_steps_sampled": 1472000, "num_agent_steps_trained": 1472000}, "env_runners": {"episode_reward_max": 365.20000000000016, "episode_reward_min": -342.6999999999998, "episode_reward_mean": 156.9239999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -320.5, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 190.99999999999997, "predator_policy": 181.0}, "policy_reward_mean": {"prey_policy": 38.85199999999999, "predator_policy": 39.61}, "custom_metrics": {}, "hist_stats": {"episode_reward": [193.30000000000004, 297.6, 341.1, 325.7, 228.09999999999997, 162.70000000000002, 202.2999999999999, 245.99999999999994, 351.5000000000002, 317.59999999999997, 135.6, 156.99999999999997, 332.10000000000025, 337.2000000000001, 299.40000000000015, 42.7, 52.7, 283.7999999999999, 46.299999999999955, 109.90000000000006, 184.19999999999942, 171.19999999999993, 329.9, 92.69999999999993, 80.20000000000003, 152.7, 301.39999999999975, 30.599999999999838, 253.29999999999993, 266.9999999999999, 72.60000000000012, 334.5000000000003, 89.39999999999999, 199.89999999999932, 175.99999999999974, 293.29999999999995, 166.39999999999998, 150.4, 20.599999999999852, 140.2, 218.89999999999995, 199.0, 89.99999999999952, 148.49999999999994, 333.90000000000026, -130.10000000000002, 164.39999999999955, 218.59999999999988, 208.2999999999992, 138.19999999999987, 336.0, 255.99999999999991, 302.09999999999997, -96.20000000000016, 294.60000000000025, 365.20000000000016, 125.49999999999963, 339.4000000000002, 111.29999999999984, 160.69999999999982, 305.7000000000001, -58.99999999999999, 281.19999999999993, 268.1999999999999, -20.300000000000068, 193.6999999999999, 139.6999999999999, 210.69999999999987, -57.49999999999988, 325.4, 295.79999999999995, 8.600000000000026, 36.80000000000003, 113.90000000000003, -206.70000000000022, 269.5, 9.500000000000016, 325.6000000000001, 177.89999999999938, -34.199999999999825, 222.69999999999993, 162.89999999999944, 251.19999999999985, -171.2000000000002, 156.10000000000002, -119.90000000000038, 25.600000000000065, 150.29999999999953, 140.39999999999998, -106.50000000000003, 201.19999999999973, 275.9000000000001, 268.59999999999985, 230.19999999999982, 195.3999999999993, 46.00000000000008, -342.6999999999998, -277.70000000000005, -260.8000000000002, 306.8000000000002], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [66.5, 39.79999999999998, 145.99999999999997, 104.6, 141.8, 170.29999999999998, 103.4, 173.3, 47.90000000000001, 99.2, 56.3, 13.399999999999949, 61.400000000000034, 65.89999999999999, 82.70000000000002, 101.30000000000001, 162.79999999999995, 178.69999999999993, 109.10000000000001, 177.5, 21.200000000000017, 16.4, -10.0, 20.000000000000014, 169.4, 136.69999999999993, 140.59999999999997, 176.6, 127.39999999999996, 130.99999999999997, -12.699999999999974, -34.599999999999994, 0.20000000000000284, -86.5, 84.80000000000001, 155.0, -101.80000000000001, 7.1000000000000085, 2.300000000000047, 5.599999999999994, 108.2, 20.000000000000014, 59.00000000000001, 45.2, 157.99999999999997, 152.9, -0.3999999999999666, -19.89999999999997, 2.900000000000002, -39.69999999999998, -20.20000000000003, 83.89999999999999, 139.99999999999997, 124.39999999999995, -65.80000000000001, -4.599999999999996, 93.49999999999999, 117.8, 82.4, 134.5999999999999, 3.1999999999999615, -1.5999999999999819, 172.9999999999999, 117.5, -73.0, 37.400000000000006, 5.299999999999965, 182.59999999999997, 113.6, 7.399999999999977, 97.99999999999997, 161.3, 43.400000000000006, 44.00000000000003, 43.400000000000006, -1.0, -70.30000000000001, -15.100000000000122, 13.400000000000006, 3.799999999999997, 44.900000000000006, 80.00000000000001, 125.29999999999993, 13.699999999999982, 7.400000000000018, 14.599999999999966, 40.70000000000003, 18.800000000000008, 178.39999999999992, 99.50000000000001, -88.9, -188.20000000000002, 109.4, 20.000000000000014, 55.70000000000004, 68.89999999999998, 20.000000000000014, 188.29999999999993, -44.8, 2.000000000000024, 147.49999999999994, 168.49999999999994, 29.59999999999995, 130.4, 128.0, 124.1, -91.3000000000001, -157.90000000000006, 125.89999999999996, 136.69999999999996, 126.19999999999999, 190.99999999999997, 69.50000000000003, 20.000000000000014, 181.99999999999997, 136.39999999999992, 38.29999999999999, 20.000000000000014, -18.099999999999966, 84.80000000000004, 151.69999999999993, 136.99999999999997, -115.6, -60.4, 95.60000000000001, 125.59999999999997, 124.39999999999999, 93.79999999999998, -85.90000000000003, -48.400000000000034, 48.200000000000024, 66.50000000000003, 22.699999999999996, 19.999999999999996, 46.400000000000034, 71.30000000000001, -207.40000000000003, 17.899999999999988, 123.19999999999996, 135.19999999999996, 101.90000000000002, 146.89999999999998, -105.4000000000001, 20.000000000000014, -26.499999999999993, -45.70000000000002, 11.900000000000013, -13.000000000000007, -172.60000000000016, -216.10000000000005, 62.90000000000001, 143.5999999999999, -39.099999999999994, -54.399999999999984, 148.69999999999996, 146.9, 20.000000000000014, 119.89999999999998, -137.20000000000007, -21.999999999999744, 88.69999999999999, 77.0, 158.59999999999994, -15.699999999999747, 84.8, 109.4, -164.50000000000014, -162.70000000000002, 17.3, 42.8, -289.5999999999999, 13.699999999999964, 9.499999999999964, 1.0999999999999723, 131.59999999999997, 13.699999999999964, 49.70000000000001, 1.6999999999999695, -129.7, -194.80000000000004, 153.1999999999999, 7.999999999999988, 116.59999999999994, 134.29999999999995, 94.39999999999998, 126.19999999999997, 110.60000000000001, 83.6000000000001, 5.299999999999965, 181.09999999999997, -48.09999999999999, -64.9000000000001, -272.2000000000001, -320.5, -303.09999999999997, -250.60000000000002, -204.10000000000014, -240.70000000000007, 156.7999999999999, 142.99999999999997], "policy_predator_policy_reward": [26.0, 61.0, 26.0, 21.0, 17.0, 12.0, 20.0, 29.0, 51.0, 30.0, 50.0, 43.0, 30.0, 45.0, 50.0, 12.0, 7.0, 3.0, 13.0, 18.0, 19.0, 79.0, 76.0, 71.0, 16.0, 10.0, 9.0, 11.0, 19.0, 22.0, 0.0, 90.0, 26.0, 113.0, 8.0, 36.0, 70.0, 71.0, 36.0, 66.0, 26.0, 30.0, 11.0, 56.0, 4.0, 15.0, 37.0, 76.0, 12.0, 105.0, 39.0, 50.0, 22.0, 15.0, 55.0, 46.0, 30.0, 12.0, 9.0, 41.0, 27.0, 44.0, 25.0, 19.0, 13.0, 112.0, 7.0, 5.0, 40.0, 15.0, 8.0, 26.0, 12.0, 67.0, 77.0, 31.0, 2.0, 104.0, 54.0, 69.0, 37.0, 57.0, 33.0, 27.0, 10.0, 58.0, 68.0, 21.0, 29.0, 27.0, 16.0, 131.0, 10.0, 25.0, 38.0, 56.0, 0.0, 0.0, 75.0, 106.0, 10.0, 10.0, 49.0, 47.0, 25.0, 25.0, 111.0, 42.0, 16.0, 16.0, 24.0, 24.0, 0.0, 36.0, 13.0, 8.0, 0.0, 53.0, 63.0, 31.0, 6.0, 11.0, 116.0, 1.0, 30.0, 30.0, 21.0, 29.0, 89.0, 25.0, 50.0, 29.0, 16.0, 81.0, 60.0, 33.0, 131.0, 1.0, 33.0, 34.0, 21.0, 26.0, 0.0, 94.0, 6.0, 103.0, 28.0, 87.0, 18.0, 164.0, 45.0, 18.0, 62.0, 41.0, 16.0, 14.0, 16.0, 22.0, 95.0, 30.0, 38.0, 19.0, 3.0, 17.0, 36.0, 21.0, 12.0, 144.0, 28.0, 68.0, 153.0, 3.0, 11.0, 4.0, 2.0, 3.0, 13.0, 76.0, 107.0, 111.0, 17.0, 23.0, 8.0, 17.0, 24.0, 24.0, 19.0, 17.0, 2.0, 7.0, 99.0, 60.0, 69.0, 181.0, 151.0, 125.0, 166.0, 18.0, 3.0, 4.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5927186336268297, "mean_inference_ms": 1.8321948555460568, "mean_action_processing_ms": 0.2544449376971084, "mean_env_wait_ms": 0.19868787190019715, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004387259483337402, "StateBufferConnector_ms": 0.0030975341796875, "ViewRequirementAgentConnector_ms": 0.09020280838012695}, "num_episodes": 18, "episode_return_max": 365.20000000000016, "episode_return_min": -342.6999999999998, "episode_return_mean": 156.9239999999999, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1472000, "num_agent_steps_trained": 1472000, "num_env_steps_sampled": 368000, "num_env_steps_trained": 368000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 372.1988333024595, "num_env_steps_trained_throughput_per_sec": 372.1988333024595, "timesteps_total": 368000, "num_env_steps_sampled_lifetime": 368000, "num_agent_steps_sampled_lifetime": 1472000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1472000, "timers": {"training_iteration_time_ms": 10638.451, "restore_workers_time_ms": 0.013, "training_step_time_ms": 10638.408, "sample_time_ms": 1291.529, "learn_time_ms": 9329.398, "learn_throughput": 428.752, "synch_weights_time_ms": 15.882}, "counters": {"num_env_steps_sampled": 368000, "num_env_steps_trained": 368000, "num_agent_steps_sampled": 1472000, "num_agent_steps_trained": 1472000}, "done": false, "training_iteration": 92, "trial_id": "3dae5_00000", "date": "2024-08-14_09-23-38", "timestamp": 1723641818, "time_this_iter_s": 10.752557039260864, "time_total_s": 2637.441285133362, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b36b6e50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2637.441285133362, "iterations_since_restore": 92, "perf": {"cpu_util_percent": 29.80666666666667, "ram_util_percent": 83.5}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.4842731492544607, "cur_kl_coeff": 0.028125000000000008, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.148058084331493, "policy_loss": -0.003505201758964667, "vf_loss": 5.1514253008302555, "vf_explained_var": 0.11513982818870948, "kl": 0.0049063262073541555, "entropy": 0.35014771241990345, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 174825.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.7998961868740264, "cur_kl_coeff": 0.25312499999999993, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.757690609825982, "policy_loss": -0.0038263346706689507, "vf_loss": 8.75991472516741, "vf_explained_var": -0.03233744104703267, "kl": 0.006329716901915211, "entropy": 1.3096359134351134, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 174825.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 372000, "num_env_steps_trained": 372000, "num_agent_steps_sampled": 1488000, "num_agent_steps_trained": 1488000}, "env_runners": {"episode_reward_max": 365.20000000000016, "episode_reward_min": -342.6999999999998, "episode_reward_mean": 104.15099999999991, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -353.5, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 190.99999999999997, "predator_policy": 191.0}, "policy_reward_mean": {"prey_policy": 4.155499999999979, "predator_policy": 47.92}, "custom_metrics": {}, "hist_stats": {"episode_reward": [46.299999999999955, 109.90000000000006, 184.19999999999942, 171.19999999999993, 329.9, 92.69999999999993, 80.20000000000003, 152.7, 301.39999999999975, 30.599999999999838, 253.29999999999993, 266.9999999999999, 72.60000000000012, 334.5000000000003, 89.39999999999999, 199.89999999999932, 175.99999999999974, 293.29999999999995, 166.39999999999998, 150.4, 20.599999999999852, 140.2, 218.89999999999995, 199.0, 89.99999999999952, 148.49999999999994, 333.90000000000026, -130.10000000000002, 164.39999999999955, 218.59999999999988, 208.2999999999992, 138.19999999999987, 336.0, 255.99999999999991, 302.09999999999997, -96.20000000000016, 294.60000000000025, 365.20000000000016, 125.49999999999963, 339.4000000000002, 111.29999999999984, 160.69999999999982, 305.7000000000001, -58.99999999999999, 281.19999999999993, 268.1999999999999, -20.300000000000068, 193.6999999999999, 139.6999999999999, 210.69999999999987, -57.49999999999988, 325.4, 295.79999999999995, 8.600000000000026, 36.80000000000003, 113.90000000000003, -206.70000000000022, 269.5, 9.500000000000016, 325.6000000000001, 177.89999999999938, -34.199999999999825, 222.69999999999993, 162.89999999999944, 251.19999999999985, -171.2000000000002, 156.10000000000002, -119.90000000000038, 25.600000000000065, 150.29999999999953, 140.39999999999998, -106.50000000000003, 201.19999999999973, 275.9000000000001, 268.59999999999985, 230.19999999999982, 195.3999999999993, 46.00000000000008, -342.6999999999998, -277.70000000000005, -260.8000000000002, 306.8000000000002, -112.90000000000023, -227.00000000000009, 102.39999999999989, 261.39999999999986, -302.29999999999995, 306.0000000000001, -219.1000000000001, -267.20000000000016, -182.30000000000013, 161.69999999999987, -329.70000000000016, 270.20000000000005, -291.89999999999884, -132.70000000000024, 282.4999999999998, -253.60000000000016, 265.90000000000015, -302.3000000000002], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-101.80000000000001, 7.1000000000000085, 2.300000000000047, 5.599999999999994, 108.2, 20.000000000000014, 59.00000000000001, 45.2, 157.99999999999997, 152.9, -0.3999999999999666, -19.89999999999997, 2.900000000000002, -39.69999999999998, -20.20000000000003, 83.89999999999999, 139.99999999999997, 124.39999999999995, -65.80000000000001, -4.599999999999996, 93.49999999999999, 117.8, 82.4, 134.5999999999999, 3.1999999999999615, -1.5999999999999819, 172.9999999999999, 117.5, -73.0, 37.400000000000006, 5.299999999999965, 182.59999999999997, 113.6, 7.399999999999977, 97.99999999999997, 161.3, 43.400000000000006, 44.00000000000003, 43.400000000000006, -1.0, -70.30000000000001, -15.100000000000122, 13.400000000000006, 3.799999999999997, 44.900000000000006, 80.00000000000001, 125.29999999999993, 13.699999999999982, 7.400000000000018, 14.599999999999966, 40.70000000000003, 18.800000000000008, 178.39999999999992, 99.50000000000001, -88.9, -188.20000000000002, 109.4, 20.000000000000014, 55.70000000000004, 68.89999999999998, 20.000000000000014, 188.29999999999993, -44.8, 2.000000000000024, 147.49999999999994, 168.49999999999994, 29.59999999999995, 130.4, 128.0, 124.1, -91.3000000000001, -157.90000000000006, 125.89999999999996, 136.69999999999996, 126.19999999999999, 190.99999999999997, 69.50000000000003, 20.000000000000014, 181.99999999999997, 136.39999999999992, 38.29999999999999, 20.000000000000014, -18.099999999999966, 84.80000000000004, 151.69999999999993, 136.99999999999997, -115.6, -60.4, 95.60000000000001, 125.59999999999997, 124.39999999999999, 93.79999999999998, -85.90000000000003, -48.400000000000034, 48.200000000000024, 66.50000000000003, 22.699999999999996, 19.999999999999996, 46.400000000000034, 71.30000000000001, -207.40000000000003, 17.899999999999988, 123.19999999999996, 135.19999999999996, 101.90000000000002, 146.89999999999998, -105.4000000000001, 20.000000000000014, -26.499999999999993, -45.70000000000002, 11.900000000000013, -13.000000000000007, -172.60000000000016, -216.10000000000005, 62.90000000000001, 143.5999999999999, -39.099999999999994, -54.399999999999984, 148.69999999999996, 146.9, 20.000000000000014, 119.89999999999998, -137.20000000000007, -21.999999999999744, 88.69999999999999, 77.0, 158.59999999999994, -15.699999999999747, 84.8, 109.4, -164.50000000000014, -162.70000000000002, 17.3, 42.8, -289.5999999999999, 13.699999999999964, 9.499999999999964, 1.0999999999999723, 131.59999999999997, 13.699999999999964, 49.70000000000001, 1.6999999999999695, -129.7, -194.80000000000004, 153.1999999999999, 7.999999999999988, 116.59999999999994, 134.29999999999995, 94.39999999999998, 126.19999999999997, 110.60000000000001, 83.6000000000001, 5.299999999999965, 181.09999999999997, -48.09999999999999, -64.9000000000001, -272.2000000000001, -320.5, -303.09999999999997, -250.60000000000002, -204.10000000000014, -240.70000000000007, 156.7999999999999, 142.99999999999997, -113.80000000000007, -120.10000000000011, -188.80000000000007, -191.20000000000005, 61.69999999999998, -7.299999999999891, 135.5, 80.9, -263.2, -294.1, 163.99999999999991, 94.99999999999991, -278.49999999999994, -250.60000000000014, -257.20000000000005, -274.00000000000006, -164.20000000000007, -168.10000000000008, 56.900000000000034, -11.199999999999985, -204.70000000000005, -295.0, 122.29999999999998, 134.89999999999992, -229.60000000000025, -241.30000000000024, -206.80000000000013, -211.90000000000018, 125.5999999999999, 128.89999999999992, -197.20000000000013, -273.40000000000003, 161.29999999999978, 44.60000000000004, -353.5, -317.80000000000007], "policy_predator_policy_reward": [70.0, 71.0, 36.0, 66.0, 26.0, 30.0, 11.0, 56.0, 4.0, 15.0, 37.0, 76.0, 12.0, 105.0, 39.0, 50.0, 22.0, 15.0, 55.0, 46.0, 30.0, 12.0, 9.0, 41.0, 27.0, 44.0, 25.0, 19.0, 13.0, 112.0, 7.0, 5.0, 40.0, 15.0, 8.0, 26.0, 12.0, 67.0, 77.0, 31.0, 2.0, 104.0, 54.0, 69.0, 37.0, 57.0, 33.0, 27.0, 10.0, 58.0, 68.0, 21.0, 29.0, 27.0, 16.0, 131.0, 10.0, 25.0, 38.0, 56.0, 0.0, 0.0, 75.0, 106.0, 10.0, 10.0, 49.0, 47.0, 25.0, 25.0, 111.0, 42.0, 16.0, 16.0, 24.0, 24.0, 0.0, 36.0, 13.0, 8.0, 0.0, 53.0, 63.0, 31.0, 6.0, 11.0, 116.0, 1.0, 30.0, 30.0, 21.0, 29.0, 89.0, 25.0, 50.0, 29.0, 16.0, 81.0, 60.0, 33.0, 131.0, 1.0, 33.0, 34.0, 21.0, 26.0, 0.0, 94.0, 6.0, 103.0, 28.0, 87.0, 18.0, 164.0, 45.0, 18.0, 62.0, 41.0, 16.0, 14.0, 16.0, 22.0, 95.0, 30.0, 38.0, 19.0, 3.0, 17.0, 36.0, 21.0, 12.0, 144.0, 28.0, 68.0, 153.0, 3.0, 11.0, 4.0, 2.0, 3.0, 13.0, 76.0, 107.0, 111.0, 17.0, 23.0, 8.0, 17.0, 24.0, 24.0, 19.0, 17.0, 2.0, 7.0, 99.0, 60.0, 69.0, 181.0, 151.0, 125.0, 166.0, 18.0, 3.0, 4.0, 118.0, 3.0, 13.0, 140.0, 22.0, 26.0, 26.0, 19.0, 182.0, 73.0, 26.0, 21.0, 166.0, 144.0, 168.0, 96.0, 147.0, 3.0, 33.0, 83.0, 5.0, 165.0, 6.0, 7.0, 25.0, 154.0, 164.0, 122.0, 14.0, 14.0, 154.0, 63.0, 35.0, 25.0, 178.0, 191.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5923207594989254, "mean_inference_ms": 1.8311629939317988, "mean_action_processing_ms": 0.2542202093426329, "mean_env_wait_ms": 0.19867253102774568, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00492405891418457, "StateBufferConnector_ms": 0.003148317337036133, "ViewRequirementAgentConnector_ms": 0.0918428897857666}, "num_episodes": 18, "episode_return_max": 365.20000000000016, "episode_return_min": -342.6999999999998, "episode_return_mean": 104.15099999999991, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1488000, "num_agent_steps_trained": 1488000, "num_env_steps_sampled": 372000, "num_env_steps_trained": 372000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 373.3259682306962, "num_env_steps_trained_throughput_per_sec": 373.3259682306962, "timesteps_total": 372000, "num_env_steps_sampled_lifetime": 372000, "num_agent_steps_sampled_lifetime": 1488000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1488000, "timers": {"training_iteration_time_ms": 10633.723, "restore_workers_time_ms": 0.013, "training_step_time_ms": 10633.68, "sample_time_ms": 1286.126, "learn_time_ms": 9330.291, "learn_throughput": 428.711, "synch_weights_time_ms": 15.676}, "counters": {"num_env_steps_sampled": 372000, "num_env_steps_trained": 372000, "num_agent_steps_sampled": 1488000, "num_agent_steps_trained": 1488000}, "done": false, "training_iteration": 93, "trial_id": "3dae5_00000", "date": "2024-08-14_09-23-49", "timestamp": 1723641829, "time_this_iter_s": 10.718931198120117, "time_total_s": 2648.160216331482, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3636a60>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2648.160216331482, "iterations_since_restore": 93, "perf": {"cpu_util_percent": 27.366666666666667, "ram_util_percent": 83.37333333333332}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.614203953932202, "cur_kl_coeff": 0.014062500000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.030087750677079, "policy_loss": -0.003686097333523095, "vf_loss": 5.033711012835225, "vf_explained_var": 0.12501789157983487, "kl": 0.004468627323405656, "entropy": 0.3259262448738492, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 176715.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.1239303973301378, "cur_kl_coeff": 0.25312499999999993, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.798374864790174, "policy_loss": -0.005051401972021691, "vf_loss": 8.80096683174214, "vf_explained_var": -0.02540293676512582, "kl": 0.009716291521050436, "entropy": 1.2879121784810668, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 176715.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 376000, "num_env_steps_trained": 376000, "num_agent_steps_sampled": 1504000, "num_agent_steps_trained": 1504000}, "env_runners": {"episode_reward_max": 365.20000000000016, "episode_reward_min": -342.6999999999998, "episode_reward_mean": 74.94199999999992, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -353.5, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 190.99999999999997, "predator_policy": 191.0}, "policy_reward_mean": {"prey_policy": -17.40400000000003, "predator_policy": 54.875}, "custom_metrics": {}, "hist_stats": {"episode_reward": [218.89999999999995, 199.0, 89.99999999999952, 148.49999999999994, 333.90000000000026, -130.10000000000002, 164.39999999999955, 218.59999999999988, 208.2999999999992, 138.19999999999987, 336.0, 255.99999999999991, 302.09999999999997, -96.20000000000016, 294.60000000000025, 365.20000000000016, 125.49999999999963, 339.4000000000002, 111.29999999999984, 160.69999999999982, 305.7000000000001, -58.99999999999999, 281.19999999999993, 268.1999999999999, -20.300000000000068, 193.6999999999999, 139.6999999999999, 210.69999999999987, -57.49999999999988, 325.4, 295.79999999999995, 8.600000000000026, 36.80000000000003, 113.90000000000003, -206.70000000000022, 269.5, 9.500000000000016, 325.6000000000001, 177.89999999999938, -34.199999999999825, 222.69999999999993, 162.89999999999944, 251.19999999999985, -171.2000000000002, 156.10000000000002, -119.90000000000038, 25.600000000000065, 150.29999999999953, 140.39999999999998, -106.50000000000003, 201.19999999999973, 275.9000000000001, 268.59999999999985, 230.19999999999982, 195.3999999999993, 46.00000000000008, -342.6999999999998, -277.70000000000005, -260.8000000000002, 306.8000000000002, -112.90000000000023, -227.00000000000009, 102.39999999999989, 261.39999999999986, -302.29999999999995, 306.0000000000001, -219.1000000000001, -267.20000000000016, -182.30000000000013, 161.69999999999987, -329.70000000000016, 270.20000000000005, -291.89999999999884, -132.70000000000024, 282.4999999999998, -253.60000000000016, 265.90000000000015, -302.3000000000002, 281.4999999999998, 40.300000000000104, -186.20000000000005, -58.90000000000016, -259.3000000000003, 260.4999999999999, 5.200000000000053, -72.10000000000045, 229.39999999999978, -49.799999999999955, -0.3999999999999746, 186.59999999999954, 272.09999999999974, -337.99999999999966, -101.30000000000028, 297.19999999999993, 268.1, 229.89999999999964, 78.30000000000004, -199.30000000000024, 160.39999999999992, -302.39999999999986], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [44.900000000000006, 80.00000000000001, 125.29999999999993, 13.699999999999982, 7.400000000000018, 14.599999999999966, 40.70000000000003, 18.800000000000008, 178.39999999999992, 99.50000000000001, -88.9, -188.20000000000002, 109.4, 20.000000000000014, 55.70000000000004, 68.89999999999998, 20.000000000000014, 188.29999999999993, -44.8, 2.000000000000024, 147.49999999999994, 168.49999999999994, 29.59999999999995, 130.4, 128.0, 124.1, -91.3000000000001, -157.90000000000006, 125.89999999999996, 136.69999999999996, 126.19999999999999, 190.99999999999997, 69.50000000000003, 20.000000000000014, 181.99999999999997, 136.39999999999992, 38.29999999999999, 20.000000000000014, -18.099999999999966, 84.80000000000004, 151.69999999999993, 136.99999999999997, -115.6, -60.4, 95.60000000000001, 125.59999999999997, 124.39999999999999, 93.79999999999998, -85.90000000000003, -48.400000000000034, 48.200000000000024, 66.50000000000003, 22.699999999999996, 19.999999999999996, 46.400000000000034, 71.30000000000001, -207.40000000000003, 17.899999999999988, 123.19999999999996, 135.19999999999996, 101.90000000000002, 146.89999999999998, -105.4000000000001, 20.000000000000014, -26.499999999999993, -45.70000000000002, 11.900000000000013, -13.000000000000007, -172.60000000000016, -216.10000000000005, 62.90000000000001, 143.5999999999999, -39.099999999999994, -54.399999999999984, 148.69999999999996, 146.9, 20.000000000000014, 119.89999999999998, -137.20000000000007, -21.999999999999744, 88.69999999999999, 77.0, 158.59999999999994, -15.699999999999747, 84.8, 109.4, -164.50000000000014, -162.70000000000002, 17.3, 42.8, -289.5999999999999, 13.699999999999964, 9.499999999999964, 1.0999999999999723, 131.59999999999997, 13.699999999999964, 49.70000000000001, 1.6999999999999695, -129.7, -194.80000000000004, 153.1999999999999, 7.999999999999988, 116.59999999999994, 134.29999999999995, 94.39999999999998, 126.19999999999997, 110.60000000000001, 83.6000000000001, 5.299999999999965, 181.09999999999997, -48.09999999999999, -64.9000000000001, -272.2000000000001, -320.5, -303.09999999999997, -250.60000000000002, -204.10000000000014, -240.70000000000007, 156.7999999999999, 142.99999999999997, -113.80000000000007, -120.10000000000011, -188.80000000000007, -191.20000000000005, 61.69999999999998, -7.299999999999891, 135.5, 80.9, -263.2, -294.1, 163.99999999999991, 94.99999999999991, -278.49999999999994, -250.60000000000014, -257.20000000000005, -274.00000000000006, -164.20000000000007, -168.10000000000008, 56.900000000000034, -11.199999999999985, -204.70000000000005, -295.0, 122.29999999999998, 134.89999999999992, -229.60000000000025, -241.30000000000024, -206.80000000000013, -211.90000000000018, 125.5999999999999, 128.89999999999992, -197.20000000000013, -273.40000000000003, 161.29999999999978, 44.60000000000004, -353.5, -317.80000000000007, 136.09999999999997, 112.4, -64.00000000000001, -12.700000000000028, -291.39999999999986, -230.8, -128.50000000000009, -135.40000000000015, -247.00000000000017, -205.30000000000027, 107.0, 66.50000000000003, -24.39999999999999, -90.4000000000001, -89.50000000000031, -118.6000000000002, 58.10000000000006, 62.300000000000026, -111.40000000000009, -75.40000000000006, -90.70000000000013, -51.69999999999999, 114.49999999999989, 7.099999999999986, 123.49999999999991, 104.60000000000002, -264.10000000000014, -262.9000000000002, -141.1000000000001, -110.20000000000017, 136.10000000000002, 112.09999999999994, 120.19999999999982, 92.89999999999998, 118.09999999999982, 81.79999999999998, 5.900000000000045, -19.60000000000001, -217.0000000000002, -304.2999999999997, 10.700000000000006, 19.700000000000024, -294.6999999999998, -348.69999999999993], "policy_predator_policy_reward": [37.0, 57.0, 33.0, 27.0, 10.0, 58.0, 68.0, 21.0, 29.0, 27.0, 16.0, 131.0, 10.0, 25.0, 38.0, 56.0, 0.0, 0.0, 75.0, 106.0, 10.0, 10.0, 49.0, 47.0, 25.0, 25.0, 111.0, 42.0, 16.0, 16.0, 24.0, 24.0, 0.0, 36.0, 13.0, 8.0, 0.0, 53.0, 63.0, 31.0, 6.0, 11.0, 116.0, 1.0, 30.0, 30.0, 21.0, 29.0, 89.0, 25.0, 50.0, 29.0, 16.0, 81.0, 60.0, 33.0, 131.0, 1.0, 33.0, 34.0, 21.0, 26.0, 0.0, 94.0, 6.0, 103.0, 28.0, 87.0, 18.0, 164.0, 45.0, 18.0, 62.0, 41.0, 16.0, 14.0, 16.0, 22.0, 95.0, 30.0, 38.0, 19.0, 3.0, 17.0, 36.0, 21.0, 12.0, 144.0, 28.0, 68.0, 153.0, 3.0, 11.0, 4.0, 2.0, 3.0, 13.0, 76.0, 107.0, 111.0, 17.0, 23.0, 8.0, 17.0, 24.0, 24.0, 19.0, 17.0, 2.0, 7.0, 99.0, 60.0, 69.0, 181.0, 151.0, 125.0, 166.0, 18.0, 3.0, 4.0, 118.0, 3.0, 13.0, 140.0, 22.0, 26.0, 26.0, 19.0, 182.0, 73.0, 26.0, 21.0, 166.0, 144.0, 168.0, 96.0, 147.0, 3.0, 33.0, 83.0, 5.0, 165.0, 6.0, 7.0, 25.0, 154.0, 164.0, 122.0, 14.0, 14.0, 154.0, 63.0, 35.0, 25.0, 178.0, 191.0, 7.0, 26.0, 112.0, 5.0, 173.0, 163.0, 66.0, 139.0, 163.0, 30.0, 41.0, 46.0, 98.0, 22.0, 123.0, 13.0, 53.0, 56.0, 10.0, 127.0, 129.0, 13.0, 33.0, 32.0, 24.0, 20.0, 22.0, 167.0, 16.0, 134.0, 26.0, 23.0, 26.0, 29.0, 15.0, 15.0, 88.0, 4.0, 153.0, 169.0, 53.0, 77.0, 168.0, 173.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5917944600552993, "mean_inference_ms": 1.8298334623421042, "mean_action_processing_ms": 0.253945119271031, "mean_env_wait_ms": 0.19858665482920998, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005505800247192383, "StateBufferConnector_ms": 0.0031442642211914062, "ViewRequirementAgentConnector_ms": 0.0907750129699707}, "num_episodes": 22, "episode_return_max": 365.20000000000016, "episode_return_min": -342.6999999999998, "episode_return_mean": 74.94199999999992, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1504000, "num_agent_steps_trained": 1504000, "num_env_steps_sampled": 376000, "num_env_steps_trained": 376000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 383.358143021251, "num_env_steps_trained_throughput_per_sec": 383.358143021251, "timesteps_total": 376000, "num_env_steps_sampled_lifetime": 376000, "num_agent_steps_sampled_lifetime": 1504000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1504000, "timers": {"training_iteration_time_ms": 10624.72, "restore_workers_time_ms": 0.013, "training_step_time_ms": 10624.677, "sample_time_ms": 1290.701, "learn_time_ms": 9316.829, "learn_throughput": 429.331, "synch_weights_time_ms": 15.54}, "counters": {"num_env_steps_sampled": 376000, "num_env_steps_trained": 376000, "num_agent_steps_sampled": 1504000, "num_agent_steps_trained": 1504000}, "done": false, "training_iteration": 94, "trial_id": "3dae5_00000", "date": "2024-08-14_09-23-59", "timestamp": 1723641839, "time_this_iter_s": 10.439745664596558, "time_total_s": 2658.5999619960785, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b36d6700>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2658.5999619960785, "iterations_since_restore": 94, "perf": {"cpu_util_percent": 29.02, "ram_util_percent": 83.25333333333333}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.8113455279163584, "cur_kl_coeff": 0.007031250000000002, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.426597510191499, "policy_loss": -0.0041335854563546715, "vf_loss": 5.430709157923542, "vf_explained_var": 0.13478614366243755, "kl": 0.0031219564956694148, "entropy": 0.33228542566614805, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 178605.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.2878768741138398, "cur_kl_coeff": 0.25312499999999993, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.862075749906912, "policy_loss": -0.0024252115731575974, "vf_loss": 8.863035590560347, "vf_explained_var": 0.030984932468051, "kl": 0.0057890793316478706, "entropy": 1.3138720801898411, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 178605.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 380000, "num_env_steps_trained": 380000, "num_agent_steps_sampled": 1520000, "num_agent_steps_trained": 1520000}, "env_runners": {"episode_reward_max": 325.6000000000001, "episode_reward_min": -367.4999999999999, "episode_reward_mean": 40.73799999999991, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -353.5, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 181.09999999999997, "predator_policy": 193.0}, "policy_reward_mean": {"prey_policy": -41.64100000000005, "predator_policy": 62.01}, "custom_metrics": {}, "hist_stats": {"episode_reward": [111.29999999999984, 160.69999999999982, 305.7000000000001, -58.99999999999999, 281.19999999999993, 268.1999999999999, -20.300000000000068, 193.6999999999999, 139.6999999999999, 210.69999999999987, -57.49999999999988, 325.4, 295.79999999999995, 8.600000000000026, 36.80000000000003, 113.90000000000003, -206.70000000000022, 269.5, 9.500000000000016, 325.6000000000001, 177.89999999999938, -34.199999999999825, 222.69999999999993, 162.89999999999944, 251.19999999999985, -171.2000000000002, 156.10000000000002, -119.90000000000038, 25.600000000000065, 150.29999999999953, 140.39999999999998, -106.50000000000003, 201.19999999999973, 275.9000000000001, 268.59999999999985, 230.19999999999982, 195.3999999999993, 46.00000000000008, -342.6999999999998, -277.70000000000005, -260.8000000000002, 306.8000000000002, -112.90000000000023, -227.00000000000009, 102.39999999999989, 261.39999999999986, -302.29999999999995, 306.0000000000001, -219.1000000000001, -267.20000000000016, -182.30000000000013, 161.69999999999987, -329.70000000000016, 270.20000000000005, -291.89999999999884, -132.70000000000024, 282.4999999999998, -253.60000000000016, 265.90000000000015, -302.3000000000002, 281.4999999999998, 40.300000000000104, -186.20000000000005, -58.90000000000016, -259.3000000000003, 260.4999999999999, 5.200000000000053, -72.10000000000045, 229.39999999999978, -49.799999999999955, -0.3999999999999746, 186.59999999999954, 272.09999999999974, -337.99999999999966, -101.30000000000028, 297.19999999999993, 268.1, 229.89999999999964, 78.30000000000004, -199.30000000000024, 160.39999999999992, -302.39999999999986, 321.60000000000025, 282.1000000000005, 117.29999999999998, 264.9999999999997, -81.80000000000007, -367.4999999999999, -212.00000000000009, -68.6000000000005, -157.00000000000017, 231.49999999999963, 262.7999999999997, -263.0000000000003, 251.4999999999999, -260.10000000000036, -100.90000000000023, -136.5000000000002, 258.4999999999998, -251.00000000000043], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [38.29999999999999, 20.000000000000014, -18.099999999999966, 84.80000000000004, 151.69999999999993, 136.99999999999997, -115.6, -60.4, 95.60000000000001, 125.59999999999997, 124.39999999999999, 93.79999999999998, -85.90000000000003, -48.400000000000034, 48.200000000000024, 66.50000000000003, 22.699999999999996, 19.999999999999996, 46.400000000000034, 71.30000000000001, -207.40000000000003, 17.899999999999988, 123.19999999999996, 135.19999999999996, 101.90000000000002, 146.89999999999998, -105.4000000000001, 20.000000000000014, -26.499999999999993, -45.70000000000002, 11.900000000000013, -13.000000000000007, -172.60000000000016, -216.10000000000005, 62.90000000000001, 143.5999999999999, -39.099999999999994, -54.399999999999984, 148.69999999999996, 146.9, 20.000000000000014, 119.89999999999998, -137.20000000000007, -21.999999999999744, 88.69999999999999, 77.0, 158.59999999999994, -15.699999999999747, 84.8, 109.4, -164.50000000000014, -162.70000000000002, 17.3, 42.8, -289.5999999999999, 13.699999999999964, 9.499999999999964, 1.0999999999999723, 131.59999999999997, 13.699999999999964, 49.70000000000001, 1.6999999999999695, -129.7, -194.80000000000004, 153.1999999999999, 7.999999999999988, 116.59999999999994, 134.29999999999995, 94.39999999999998, 126.19999999999997, 110.60000000000001, 83.6000000000001, 5.299999999999965, 181.09999999999997, -48.09999999999999, -64.9000000000001, -272.2000000000001, -320.5, -303.09999999999997, -250.60000000000002, -204.10000000000014, -240.70000000000007, 156.7999999999999, 142.99999999999997, -113.80000000000007, -120.10000000000011, -188.80000000000007, -191.20000000000005, 61.69999999999998, -7.299999999999891, 135.5, 80.9, -263.2, -294.1, 163.99999999999991, 94.99999999999991, -278.49999999999994, -250.60000000000014, -257.20000000000005, -274.00000000000006, -164.20000000000007, -168.10000000000008, 56.900000000000034, -11.199999999999985, -204.70000000000005, -295.0, 122.29999999999998, 134.89999999999992, -229.60000000000025, -241.30000000000024, -206.80000000000013, -211.90000000000018, 125.5999999999999, 128.89999999999992, -197.20000000000013, -273.40000000000003, 161.29999999999978, 44.60000000000004, -353.5, -317.80000000000007, 136.09999999999997, 112.4, -64.00000000000001, -12.700000000000028, -291.39999999999986, -230.8, -128.50000000000009, -135.40000000000015, -247.00000000000017, -205.30000000000027, 107.0, 66.50000000000003, -24.39999999999999, -90.4000000000001, -89.50000000000031, -118.6000000000002, 58.10000000000006, 62.300000000000026, -111.40000000000009, -75.40000000000006, -90.70000000000013, -51.69999999999999, 114.49999999999989, 7.099999999999986, 123.49999999999991, 104.60000000000002, -264.10000000000014, -262.9000000000002, -141.1000000000001, -110.20000000000017, 136.10000000000002, 112.09999999999994, 120.19999999999982, 92.89999999999998, 118.09999999999982, 81.79999999999998, 5.900000000000045, -19.60000000000001, -217.0000000000002, -304.2999999999997, 10.700000000000006, 19.700000000000024, -294.6999999999998, -348.69999999999993, 159.19999999999982, 154.3999999999998, 130.09999999999988, 115.99999999999997, -58.60000000000029, -15.099999999999978, 61.40000000000007, 149.59999999999974, -158.5000000000001, -181.30000000000007, -278.20000000000016, -289.30000000000007, -257.8000000000002, -197.20000000000005, -134.20000000000022, -114.40000000000026, -190.60000000000008, -198.4000000000001, 68.30000000000007, 120.19999999999996, 94.69999999999992, 121.09999999999997, -252.70000000000016, -172.3000000000003, 144.49999999999994, 17.0, -216.7000000000001, -219.40000000000032, -173.20000000000016, -147.70000000000013, -210.10000000000022, -261.40000000000015, 114.49999999999994, 95.0, -278.8, -155.20000000000024], "policy_predator_policy_reward": [0.0, 53.0, 63.0, 31.0, 6.0, 11.0, 116.0, 1.0, 30.0, 30.0, 21.0, 29.0, 89.0, 25.0, 50.0, 29.0, 16.0, 81.0, 60.0, 33.0, 131.0, 1.0, 33.0, 34.0, 21.0, 26.0, 0.0, 94.0, 6.0, 103.0, 28.0, 87.0, 18.0, 164.0, 45.0, 18.0, 62.0, 41.0, 16.0, 14.0, 16.0, 22.0, 95.0, 30.0, 38.0, 19.0, 3.0, 17.0, 36.0, 21.0, 12.0, 144.0, 28.0, 68.0, 153.0, 3.0, 11.0, 4.0, 2.0, 3.0, 13.0, 76.0, 107.0, 111.0, 17.0, 23.0, 8.0, 17.0, 24.0, 24.0, 19.0, 17.0, 2.0, 7.0, 99.0, 60.0, 69.0, 181.0, 151.0, 125.0, 166.0, 18.0, 3.0, 4.0, 118.0, 3.0, 13.0, 140.0, 22.0, 26.0, 26.0, 19.0, 182.0, 73.0, 26.0, 21.0, 166.0, 144.0, 168.0, 96.0, 147.0, 3.0, 33.0, 83.0, 5.0, 165.0, 6.0, 7.0, 25.0, 154.0, 164.0, 122.0, 14.0, 14.0, 154.0, 63.0, 35.0, 25.0, 178.0, 191.0, 7.0, 26.0, 112.0, 5.0, 173.0, 163.0, 66.0, 139.0, 163.0, 30.0, 41.0, 46.0, 98.0, 22.0, 123.0, 13.0, 53.0, 56.0, 10.0, 127.0, 129.0, 13.0, 33.0, 32.0, 24.0, 20.0, 22.0, 167.0, 16.0, 134.0, 26.0, 23.0, 26.0, 29.0, 15.0, 15.0, 88.0, 4.0, 153.0, 169.0, 53.0, 77.0, 168.0, 173.0, 4.0, 4.0, 17.0, 19.0, 109.0, 82.0, 30.0, 24.0, 118.0, 140.0, 193.0, 7.0, 148.0, 95.0, 79.0, 101.0, 143.0, 89.0, 22.0, 21.0, 24.0, 23.0, 153.0, 9.0, 33.0, 57.0, 12.0, 164.0, 87.0, 133.0, 172.0, 163.0, 26.0, 23.0, 162.0, 21.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5914148153214753, "mean_inference_ms": 1.8287556644133334, "mean_action_processing_ms": 0.2537427965941698, "mean_env_wait_ms": 0.19852683431702553, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0059435367584228516, "StateBufferConnector_ms": 0.003275752067565918, "ViewRequirementAgentConnector_ms": 0.09288203716278076}, "num_episodes": 18, "episode_return_max": 325.6000000000001, "episode_return_min": -367.4999999999999, "episode_return_mean": 40.73799999999991, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1520000, "num_agent_steps_trained": 1520000, "num_env_steps_sampled": 380000, "num_env_steps_trained": 380000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 369.5948739831425, "num_env_steps_trained_throughput_per_sec": 369.5948739831425, "timesteps_total": 380000, "num_env_steps_sampled_lifetime": 380000, "num_agent_steps_sampled_lifetime": 1520000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1520000, "timers": {"training_iteration_time_ms": 10664.976, "restore_workers_time_ms": 0.014, "training_step_time_ms": 10664.934, "sample_time_ms": 1289.544, "learn_time_ms": 9358.136, "learn_throughput": 427.436, "synch_weights_time_ms": 15.719}, "counters": {"num_env_steps_sampled": 380000, "num_env_steps_trained": 380000, "num_agent_steps_sampled": 1520000, "num_agent_steps_trained": 1520000}, "done": false, "training_iteration": 95, "trial_id": "3dae5_00000", "date": "2024-08-14_09-24-10", "timestamp": 1723641850, "time_this_iter_s": 10.826892852783203, "time_total_s": 2669.4268548488617, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b36ef160>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2669.4268548488617, "iterations_since_restore": 95, "perf": {"cpu_util_percent": 28.5875, "ram_util_percent": 83.24375}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.836706739979446, "cur_kl_coeff": 0.003515625000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.550263579434188, "policy_loss": -0.003874996278395571, "vf_loss": 6.554127474436684, "vf_explained_var": 0.13629796262140628, "kl": 0.0031627230297966483, "entropy": 0.33535656142171727, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 180495.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.366379974380372, "cur_kl_coeff": 0.25312499999999993, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.30240721929641, "policy_loss": -0.003941391583620792, "vf_loss": 9.304081083731676, "vf_explained_var": -0.044229780460791616, "kl": 0.00895810609348114, "entropy": 1.307847284198438, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 180495.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 384000, "num_env_steps_trained": 384000, "num_agent_steps_sampled": 1536000, "num_agent_steps_trained": 1536000}, "env_runners": {"episode_reward_max": 321.60000000000025, "episode_reward_min": -367.4999999999999, "episode_reward_mean": -8.37000000000016, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -353.5, "predator_policy": 2.0}, "policy_reward_max": {"prey_policy": 181.09999999999997, "predator_policy": 193.0}, "policy_reward_mean": {"prey_policy": -77.56000000000009, "predator_policy": 73.375}, "custom_metrics": {}, "hist_stats": {"episode_reward": [162.89999999999944, 251.19999999999985, -171.2000000000002, 156.10000000000002, -119.90000000000038, 25.600000000000065, 150.29999999999953, 140.39999999999998, -106.50000000000003, 201.19999999999973, 275.9000000000001, 268.59999999999985, 230.19999999999982, 195.3999999999993, 46.00000000000008, -342.6999999999998, -277.70000000000005, -260.8000000000002, 306.8000000000002, -112.90000000000023, -227.00000000000009, 102.39999999999989, 261.39999999999986, -302.29999999999995, 306.0000000000001, -219.1000000000001, -267.20000000000016, -182.30000000000013, 161.69999999999987, -329.70000000000016, 270.20000000000005, -291.89999999999884, -132.70000000000024, 282.4999999999998, -253.60000000000016, 265.90000000000015, -302.3000000000002, 281.4999999999998, 40.300000000000104, -186.20000000000005, -58.90000000000016, -259.3000000000003, 260.4999999999999, 5.200000000000053, -72.10000000000045, 229.39999999999978, -49.799999999999955, -0.3999999999999746, 186.59999999999954, 272.09999999999974, -337.99999999999966, -101.30000000000028, 297.19999999999993, 268.1, 229.89999999999964, 78.30000000000004, -199.30000000000024, 160.39999999999992, -302.39999999999986, 321.60000000000025, 282.1000000000005, 117.29999999999998, 264.9999999999997, -81.80000000000007, -367.4999999999999, -212.00000000000009, -68.6000000000005, -157.00000000000017, 231.49999999999963, 262.7999999999997, -263.0000000000003, 251.4999999999999, -260.10000000000036, -100.90000000000023, -136.5000000000002, 258.4999999999998, -251.00000000000043, -229.5000000000004, 91.49999999999984, -114.50000000000014, -266.6, -212.9000000000006, -117.10000000000073, -152.10000000000028, -196.50000000000057, 261.9000000000002, -157.70000000000002, 272.29999999999984, -292.8000000000002, -217.0000000000007, -205.80000000000038, 254.39999999999958, -108.10000000000049, -165.0000000000003, 263.0999999999998, -71.60000000000048, -197.00000000000045, -212.70000000000041, 228.49999999999972, -286.40000000000026], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [158.59999999999994, -15.699999999999747, 84.8, 109.4, -164.50000000000014, -162.70000000000002, 17.3, 42.8, -289.5999999999999, 13.699999999999964, 9.499999999999964, 1.0999999999999723, 131.59999999999997, 13.699999999999964, 49.70000000000001, 1.6999999999999695, -129.7, -194.80000000000004, 153.1999999999999, 7.999999999999988, 116.59999999999994, 134.29999999999995, 94.39999999999998, 126.19999999999997, 110.60000000000001, 83.6000000000001, 5.299999999999965, 181.09999999999997, -48.09999999999999, -64.9000000000001, -272.2000000000001, -320.5, -303.09999999999997, -250.60000000000002, -204.10000000000014, -240.70000000000007, 156.7999999999999, 142.99999999999997, -113.80000000000007, -120.10000000000011, -188.80000000000007, -191.20000000000005, 61.69999999999998, -7.299999999999891, 135.5, 80.9, -263.2, -294.1, 163.99999999999991, 94.99999999999991, -278.49999999999994, -250.60000000000014, -257.20000000000005, -274.00000000000006, -164.20000000000007, -168.10000000000008, 56.900000000000034, -11.199999999999985, -204.70000000000005, -295.0, 122.29999999999998, 134.89999999999992, -229.60000000000025, -241.30000000000024, -206.80000000000013, -211.90000000000018, 125.5999999999999, 128.89999999999992, -197.20000000000013, -273.40000000000003, 161.29999999999978, 44.60000000000004, -353.5, -317.80000000000007, 136.09999999999997, 112.4, -64.00000000000001, -12.700000000000028, -291.39999999999986, -230.8, -128.50000000000009, -135.40000000000015, -247.00000000000017, -205.30000000000027, 107.0, 66.50000000000003, -24.39999999999999, -90.4000000000001, -89.50000000000031, -118.6000000000002, 58.10000000000006, 62.300000000000026, -111.40000000000009, -75.40000000000006, -90.70000000000013, -51.69999999999999, 114.49999999999989, 7.099999999999986, 123.49999999999991, 104.60000000000002, -264.10000000000014, -262.9000000000002, -141.1000000000001, -110.20000000000017, 136.10000000000002, 112.09999999999994, 120.19999999999982, 92.89999999999998, 118.09999999999982, 81.79999999999998, 5.900000000000045, -19.60000000000001, -217.0000000000002, -304.2999999999997, 10.700000000000006, 19.700000000000024, -294.6999999999998, -348.69999999999993, 159.19999999999982, 154.3999999999998, 130.09999999999988, 115.99999999999997, -58.60000000000029, -15.099999999999978, 61.40000000000007, 149.59999999999974, -158.5000000000001, -181.30000000000007, -278.20000000000016, -289.30000000000007, -257.8000000000002, -197.20000000000005, -134.20000000000022, -114.40000000000026, -190.60000000000008, -198.4000000000001, 68.30000000000007, 120.19999999999996, 94.69999999999992, 121.09999999999997, -252.70000000000016, -172.3000000000003, 144.49999999999994, 17.0, -216.7000000000001, -219.40000000000032, -173.20000000000016, -147.70000000000013, -210.10000000000022, -261.40000000000015, 114.49999999999994, 95.0, -278.8, -155.20000000000024, -259.6000000000002, -238.9000000000002, -2.1999999999999904, 7.699999999999996, -236.50000000000026, -181.0000000000004, -247.60000000000005, -190.00000000000023, -195.10000000000025, -248.8000000000003, -227.80000000000047, -190.30000000000038, -99.99999999999997, -237.10000000000025, -234.4000000000003, -249.10000000000025, 63.80000000000007, 145.0999999999999, -174.40000000000003, -148.30000000000018, 81.50000000000003, 138.79999999999987, -196.9, -277.9000000000001, -206.50000000000028, -158.5000000000004, -199.30000000000015, -254.5000000000002, 115.09999999999982, 56.30000000000004, -104.50000000000034, -136.60000000000025, -216.10000000000028, -253.90000000000015, 152.29999999999987, 30.80000000000002, -98.80000000000018, -104.8000000000003, -154.30000000000024, -192.7000000000002, -293.49999999999966, -257.2000000000001, 77.6, 98.89999999999993, -278.20000000000005, -263.20000000000016], "policy_predator_policy_reward": [3.0, 17.0, 36.0, 21.0, 12.0, 144.0, 28.0, 68.0, 153.0, 3.0, 11.0, 4.0, 2.0, 3.0, 13.0, 76.0, 107.0, 111.0, 17.0, 23.0, 8.0, 17.0, 24.0, 24.0, 19.0, 17.0, 2.0, 7.0, 99.0, 60.0, 69.0, 181.0, 151.0, 125.0, 166.0, 18.0, 3.0, 4.0, 118.0, 3.0, 13.0, 140.0, 22.0, 26.0, 26.0, 19.0, 182.0, 73.0, 26.0, 21.0, 166.0, 144.0, 168.0, 96.0, 147.0, 3.0, 33.0, 83.0, 5.0, 165.0, 6.0, 7.0, 25.0, 154.0, 164.0, 122.0, 14.0, 14.0, 154.0, 63.0, 35.0, 25.0, 178.0, 191.0, 7.0, 26.0, 112.0, 5.0, 173.0, 163.0, 66.0, 139.0, 163.0, 30.0, 41.0, 46.0, 98.0, 22.0, 123.0, 13.0, 53.0, 56.0, 10.0, 127.0, 129.0, 13.0, 33.0, 32.0, 24.0, 20.0, 22.0, 167.0, 16.0, 134.0, 26.0, 23.0, 26.0, 29.0, 15.0, 15.0, 88.0, 4.0, 153.0, 169.0, 53.0, 77.0, 168.0, 173.0, 4.0, 4.0, 17.0, 19.0, 109.0, 82.0, 30.0, 24.0, 118.0, 140.0, 193.0, 7.0, 148.0, 95.0, 79.0, 101.0, 143.0, 89.0, 22.0, 21.0, 24.0, 23.0, 153.0, 9.0, 33.0, 57.0, 12.0, 164.0, 87.0, 133.0, 172.0, 163.0, 26.0, 23.0, 162.0, 21.0, 112.0, 157.0, 21.0, 65.0, 148.0, 155.0, 15.0, 156.0, 154.0, 77.0, 141.0, 160.0, 86.0, 99.0, 162.0, 125.0, 25.0, 28.0, 36.0, 129.0, 26.0, 26.0, 132.0, 50.0, 145.0, 3.0, 94.0, 154.0, 36.0, 47.0, 17.0, 116.0, 163.0, 142.0, 48.0, 32.0, 112.0, 20.0, 131.0, 19.0, 172.0, 166.0, 26.0, 26.0, 71.0, 184.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5909754130286382, "mean_inference_ms": 1.8275638282457496, "mean_action_processing_ms": 0.25347566624887274, "mean_env_wait_ms": 0.19843839832416793, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005631685256958008, "StateBufferConnector_ms": 0.003200054168701172, "ViewRequirementAgentConnector_ms": 0.09603357315063477}, "num_episodes": 23, "episode_return_max": 321.60000000000025, "episode_return_min": -367.4999999999999, "episode_return_mean": -8.37000000000016, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1536000, "num_agent_steps_trained": 1536000, "num_env_steps_sampled": 384000, "num_env_steps_trained": 384000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 380.9090661411459, "num_env_steps_trained_throughput_per_sec": 380.9090661411459, "timesteps_total": 384000, "num_env_steps_sampled_lifetime": 384000, "num_agent_steps_sampled_lifetime": 1536000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1536000, "timers": {"training_iteration_time_ms": 10609.579, "restore_workers_time_ms": 0.013, "training_step_time_ms": 10609.538, "sample_time_ms": 1292.19, "learn_time_ms": 9301.04, "learn_throughput": 430.059, "synch_weights_time_ms": 15.178}, "counters": {"num_env_steps_sampled": 384000, "num_env_steps_trained": 384000, "num_agent_steps_sampled": 1536000, "num_agent_steps_trained": 1536000}, "done": false, "training_iteration": 96, "trial_id": "3dae5_00000", "date": "2024-08-14_09-24-21", "timestamp": 1723641861, "time_this_iter_s": 10.51905083656311, "time_total_s": 2679.945905685425, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b36efaf0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2679.945905685425, "iterations_since_restore": 96, "perf": {"cpu_util_percent": 28.17333333333334, "ram_util_percent": 83.37333333333332}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.055966462376256, "cur_kl_coeff": 0.0017578125000000005, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.8725175233114335, "policy_loss": -0.002526542245504008, "vf_loss": 4.875038090710918, "vf_explained_var": 0.15594611366589864, "kl": 0.0033917029162994824, "entropy": 0.27233072345061277, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 182385.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.322036752688191, "cur_kl_coeff": 0.25312499999999993, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.873165789861527, "policy_loss": -0.0027457585486844577, "vf_loss": 8.874230771089987, "vf_explained_var": 0.008258681795584462, "kl": 0.006640152744834961, "entropy": 1.2828887631653478, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 182385.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 388000, "num_env_steps_trained": 388000, "num_agent_steps_sampled": 1552000, "num_agent_steps_trained": 1552000}, "env_runners": {"episode_reward_max": 321.60000000000025, "episode_reward_min": -367.4999999999999, "episode_reward_mean": -12.37700000000021, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -353.5, "predator_policy": 2.0}, "policy_reward_max": {"prey_policy": 163.99999999999991, "predator_policy": 193.0}, "policy_reward_mean": {"prey_policy": -81.6535000000001, "predator_policy": 75.465}, "custom_metrics": {}, "hist_stats": {"episode_reward": [306.8000000000002, -112.90000000000023, -227.00000000000009, 102.39999999999989, 261.39999999999986, -302.29999999999995, 306.0000000000001, -219.1000000000001, -267.20000000000016, -182.30000000000013, 161.69999999999987, -329.70000000000016, 270.20000000000005, -291.89999999999884, -132.70000000000024, 282.4999999999998, -253.60000000000016, 265.90000000000015, -302.3000000000002, 281.4999999999998, 40.300000000000104, -186.20000000000005, -58.90000000000016, -259.3000000000003, 260.4999999999999, 5.200000000000053, -72.10000000000045, 229.39999999999978, -49.799999999999955, -0.3999999999999746, 186.59999999999954, 272.09999999999974, -337.99999999999966, -101.30000000000028, 297.19999999999993, 268.1, 229.89999999999964, 78.30000000000004, -199.30000000000024, 160.39999999999992, -302.39999999999986, 321.60000000000025, 282.1000000000005, 117.29999999999998, 264.9999999999997, -81.80000000000007, -367.4999999999999, -212.00000000000009, -68.6000000000005, -157.00000000000017, 231.49999999999963, 262.7999999999997, -263.0000000000003, 251.4999999999999, -260.10000000000036, -100.90000000000023, -136.5000000000002, 258.4999999999998, -251.00000000000043, -229.5000000000004, 91.49999999999984, -114.50000000000014, -266.6, -212.9000000000006, -117.10000000000073, -152.10000000000028, -196.50000000000057, 261.9000000000002, -157.70000000000002, 272.29999999999984, -292.8000000000002, -217.0000000000007, -205.80000000000038, 254.39999999999958, -108.10000000000049, -165.0000000000003, 263.0999999999998, -71.60000000000048, -197.00000000000045, -212.70000000000041, 228.49999999999972, -286.40000000000026, 239.89999999999935, 190.29999999999956, 247.39999999999966, -137.00000000000088, -21.599999999999902, 200.8999999999996, -161.70000000000036, -225.2000000000007, 188.9999999999996, 197.39999999999966, 210.39999999999958, -206.70000000000024, -150.10000000000065, -205.50000000000028, -170.80000000000044, -100.30000000000044, 190.59999999999962, 137.29999999999956], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [156.7999999999999, 142.99999999999997, -113.80000000000007, -120.10000000000011, -188.80000000000007, -191.20000000000005, 61.69999999999998, -7.299999999999891, 135.5, 80.9, -263.2, -294.1, 163.99999999999991, 94.99999999999991, -278.49999999999994, -250.60000000000014, -257.20000000000005, -274.00000000000006, -164.20000000000007, -168.10000000000008, 56.900000000000034, -11.199999999999985, -204.70000000000005, -295.0, 122.29999999999998, 134.89999999999992, -229.60000000000025, -241.30000000000024, -206.80000000000013, -211.90000000000018, 125.5999999999999, 128.89999999999992, -197.20000000000013, -273.40000000000003, 161.29999999999978, 44.60000000000004, -353.5, -317.80000000000007, 136.09999999999997, 112.4, -64.00000000000001, -12.700000000000028, -291.39999999999986, -230.8, -128.50000000000009, -135.40000000000015, -247.00000000000017, -205.30000000000027, 107.0, 66.50000000000003, -24.39999999999999, -90.4000000000001, -89.50000000000031, -118.6000000000002, 58.10000000000006, 62.300000000000026, -111.40000000000009, -75.40000000000006, -90.70000000000013, -51.69999999999999, 114.49999999999989, 7.099999999999986, 123.49999999999991, 104.60000000000002, -264.10000000000014, -262.9000000000002, -141.1000000000001, -110.20000000000017, 136.10000000000002, 112.09999999999994, 120.19999999999982, 92.89999999999998, 118.09999999999982, 81.79999999999998, 5.900000000000045, -19.60000000000001, -217.0000000000002, -304.2999999999997, 10.700000000000006, 19.700000000000024, -294.6999999999998, -348.69999999999993, 159.19999999999982, 154.3999999999998, 130.09999999999988, 115.99999999999997, -58.60000000000029, -15.099999999999978, 61.40000000000007, 149.59999999999974, -158.5000000000001, -181.30000000000007, -278.20000000000016, -289.30000000000007, -257.8000000000002, -197.20000000000005, -134.20000000000022, -114.40000000000026, -190.60000000000008, -198.4000000000001, 68.30000000000007, 120.19999999999996, 94.69999999999992, 121.09999999999997, -252.70000000000016, -172.3000000000003, 144.49999999999994, 17.0, -216.7000000000001, -219.40000000000032, -173.20000000000016, -147.70000000000013, -210.10000000000022, -261.40000000000015, 114.49999999999994, 95.0, -278.8, -155.20000000000024, -259.6000000000002, -238.9000000000002, -2.1999999999999904, 7.699999999999996, -236.50000000000026, -181.0000000000004, -247.60000000000005, -190.00000000000023, -195.10000000000025, -248.8000000000003, -227.80000000000047, -190.30000000000038, -99.99999999999997, -237.10000000000025, -234.4000000000003, -249.10000000000025, 63.80000000000007, 145.0999999999999, -174.40000000000003, -148.30000000000018, 81.50000000000003, 138.79999999999987, -196.9, -277.9000000000001, -206.50000000000028, -158.5000000000004, -199.30000000000015, -254.5000000000002, 115.09999999999982, 56.30000000000004, -104.50000000000034, -136.60000000000025, -216.10000000000028, -253.90000000000015, 152.29999999999987, 30.80000000000002, -98.80000000000018, -104.8000000000003, -154.30000000000024, -192.7000000000002, -293.49999999999966, -257.2000000000001, 77.6, 98.89999999999993, -278.20000000000005, -263.20000000000016, 117.19999999999968, 88.69999999999979, 67.40000000000006, 80.89999999999995, 124.99999999999986, 97.39999999999992, -213.10000000000042, -229.90000000000043, -68.49999999999997, -72.09999999999997, 69.20000000000002, 61.70000000000004, -216.40000000000032, -82.30000000000007, -281.4999999999998, -225.70000000000027, 69.19999999999999, 84.79999999999991, 91.09999999999998, 74.30000000000004, 81.19999999999997, 60.20000000000005, -207.10000000000014, -160.60000000000002, -189.40000000000026, -219.70000000000041, -182.50000000000034, -172.00000000000009, -132.10000000000008, -189.70000000000044, -202.0000000000003, -196.3000000000002, 50.300000000000104, 107.29999999999995, 74.90000000000006, 7.400000000000038], "policy_predator_policy_reward": [3.0, 4.0, 118.0, 3.0, 13.0, 140.0, 22.0, 26.0, 26.0, 19.0, 182.0, 73.0, 26.0, 21.0, 166.0, 144.0, 168.0, 96.0, 147.0, 3.0, 33.0, 83.0, 5.0, 165.0, 6.0, 7.0, 25.0, 154.0, 164.0, 122.0, 14.0, 14.0, 154.0, 63.0, 35.0, 25.0, 178.0, 191.0, 7.0, 26.0, 112.0, 5.0, 173.0, 163.0, 66.0, 139.0, 163.0, 30.0, 41.0, 46.0, 98.0, 22.0, 123.0, 13.0, 53.0, 56.0, 10.0, 127.0, 129.0, 13.0, 33.0, 32.0, 24.0, 20.0, 22.0, 167.0, 16.0, 134.0, 26.0, 23.0, 26.0, 29.0, 15.0, 15.0, 88.0, 4.0, 153.0, 169.0, 53.0, 77.0, 168.0, 173.0, 4.0, 4.0, 17.0, 19.0, 109.0, 82.0, 30.0, 24.0, 118.0, 140.0, 193.0, 7.0, 148.0, 95.0, 79.0, 101.0, 143.0, 89.0, 22.0, 21.0, 24.0, 23.0, 153.0, 9.0, 33.0, 57.0, 12.0, 164.0, 87.0, 133.0, 172.0, 163.0, 26.0, 23.0, 162.0, 21.0, 112.0, 157.0, 21.0, 65.0, 148.0, 155.0, 15.0, 156.0, 154.0, 77.0, 141.0, 160.0, 86.0, 99.0, 162.0, 125.0, 25.0, 28.0, 36.0, 129.0, 26.0, 26.0, 132.0, 50.0, 145.0, 3.0, 94.0, 154.0, 36.0, 47.0, 17.0, 116.0, 163.0, 142.0, 48.0, 32.0, 112.0, 20.0, 131.0, 19.0, 172.0, 166.0, 26.0, 26.0, 71.0, 184.0, 19.0, 15.0, 26.0, 16.0, 13.0, 12.0, 157.0, 149.0, 94.0, 25.0, 35.0, 35.0, 135.0, 2.0, 180.0, 102.0, 16.0, 19.0, 17.0, 15.0, 36.0, 33.0, 4.0, 157.0, 109.0, 150.0, 134.0, 15.0, 12.0, 139.0, 154.0, 144.0, 11.0, 22.0, 47.0, 8.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5904927234062892, "mean_inference_ms": 1.826288974910407, "mean_action_processing_ms": 0.25324347808749986, "mean_env_wait_ms": 0.1983072928279197, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0052220821380615234, "StateBufferConnector_ms": 0.0032024383544921875, "ViewRequirementAgentConnector_ms": 0.09740233421325684}, "num_episodes": 18, "episode_return_max": 321.60000000000025, "episode_return_min": -367.4999999999999, "episode_return_mean": -12.37700000000021, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1552000, "num_agent_steps_trained": 1552000, "num_env_steps_sampled": 388000, "num_env_steps_trained": 388000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 300.31218138557784, "num_env_steps_trained_throughput_per_sec": 300.31218138557784, "timesteps_total": 388000, "num_env_steps_sampled_lifetime": 388000, "num_agent_steps_sampled_lifetime": 1552000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1552000, "timers": {"training_iteration_time_ms": 10884.251, "restore_workers_time_ms": 0.013, "training_step_time_ms": 10884.209, "sample_time_ms": 1284.864, "learn_time_ms": 9580.797, "learn_throughput": 417.502, "synch_weights_time_ms": 16.951}, "counters": {"num_env_steps_sampled": 388000, "num_env_steps_trained": 388000, "num_agent_steps_sampled": 1552000, "num_agent_steps_trained": 1552000}, "done": false, "training_iteration": 97, "trial_id": "3dae5_00000", "date": "2024-08-14_09-24-34", "timestamp": 1723641874, "time_this_iter_s": 13.34202790260315, "time_total_s": 2693.287933588028, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3680e50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2693.287933588028, "iterations_since_restore": 97, "perf": {"cpu_util_percent": 45.46111111111111, "ram_util_percent": 82.51111111111112}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 6.8362809853579005, "cur_kl_coeff": 0.0008789062500000002, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.876871018939548, "policy_loss": -0.0011429637296016884, "vf_loss": 5.878012104639931, "vf_explained_var": 0.15700166903475604, "kl": 0.002124505639597546, "entropy": 0.2333704517947303, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 184275.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.633881338248177, "cur_kl_coeff": 0.25312499999999993, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.272383505200583, "policy_loss": -0.004952802264905244, "vf_loss": 9.275225509663738, "vf_explained_var": 0.016780458966260233, "kl": 0.00833898470735196, "entropy": 1.2553266624924997, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 184275.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 392000, "num_env_steps_trained": 392000, "num_agent_steps_sampled": 1568000, "num_agent_steps_trained": 1568000}, "env_runners": {"episode_reward_max": 321.60000000000025, "episode_reward_min": -367.4999999999999, "episode_reward_mean": -4.759000000000282, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -348.69999999999993, "predator_policy": 2.0}, "policy_reward_max": {"prey_policy": 159.19999999999982, "predator_policy": 193.0}, "policy_reward_mean": {"prey_policy": -77.12950000000012, "predator_policy": 74.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-58.90000000000016, -259.3000000000003, 260.4999999999999, 5.200000000000053, -72.10000000000045, 229.39999999999978, -49.799999999999955, -0.3999999999999746, 186.59999999999954, 272.09999999999974, -337.99999999999966, -101.30000000000028, 297.19999999999993, 268.1, 229.89999999999964, 78.30000000000004, -199.30000000000024, 160.39999999999992, -302.39999999999986, 321.60000000000025, 282.1000000000005, 117.29999999999998, 264.9999999999997, -81.80000000000007, -367.4999999999999, -212.00000000000009, -68.6000000000005, -157.00000000000017, 231.49999999999963, 262.7999999999997, -263.0000000000003, 251.4999999999999, -260.10000000000036, -100.90000000000023, -136.5000000000002, 258.4999999999998, -251.00000000000043, -229.5000000000004, 91.49999999999984, -114.50000000000014, -266.6, -212.9000000000006, -117.10000000000073, -152.10000000000028, -196.50000000000057, 261.9000000000002, -157.70000000000002, 272.29999999999984, -292.8000000000002, -217.0000000000007, -205.80000000000038, 254.39999999999958, -108.10000000000049, -165.0000000000003, 263.0999999999998, -71.60000000000048, -197.00000000000045, -212.70000000000041, 228.49999999999972, -286.40000000000026, 239.89999999999935, 190.29999999999956, 247.39999999999966, -137.00000000000088, -21.599999999999902, 200.8999999999996, -161.70000000000036, -225.2000000000007, 188.9999999999996, 197.39999999999966, 210.39999999999958, -206.70000000000024, -150.10000000000065, -205.50000000000028, -170.80000000000044, -100.30000000000044, 190.59999999999962, 137.29999999999956, -118.10000000000053, -148.90000000000057, -211.90000000000066, 88.8999999999997, -92.20000000000005, 123.19999999999979, -31.19999999999994, 219.69999999999956, 112.19999999999975, 249.89999999999952, 105.09999999999994, -126.50000000000048, 200.69999999999942, -66.09999999999992, -44.299999999999926, 122.7, -80.10000000000053, 150.89999999999938, -181.4000000000007, -73.20000000000043, 160.09999999999954, -126.20000000000087], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-128.50000000000009, -135.40000000000015, -247.00000000000017, -205.30000000000027, 107.0, 66.50000000000003, -24.39999999999999, -90.4000000000001, -89.50000000000031, -118.6000000000002, 58.10000000000006, 62.300000000000026, -111.40000000000009, -75.40000000000006, -90.70000000000013, -51.69999999999999, 114.49999999999989, 7.099999999999986, 123.49999999999991, 104.60000000000002, -264.10000000000014, -262.9000000000002, -141.1000000000001, -110.20000000000017, 136.10000000000002, 112.09999999999994, 120.19999999999982, 92.89999999999998, 118.09999999999982, 81.79999999999998, 5.900000000000045, -19.60000000000001, -217.0000000000002, -304.2999999999997, 10.700000000000006, 19.700000000000024, -294.6999999999998, -348.69999999999993, 159.19999999999982, 154.3999999999998, 130.09999999999988, 115.99999999999997, -58.60000000000029, -15.099999999999978, 61.40000000000007, 149.59999999999974, -158.5000000000001, -181.30000000000007, -278.20000000000016, -289.30000000000007, -257.8000000000002, -197.20000000000005, -134.20000000000022, -114.40000000000026, -190.60000000000008, -198.4000000000001, 68.30000000000007, 120.19999999999996, 94.69999999999992, 121.09999999999997, -252.70000000000016, -172.3000000000003, 144.49999999999994, 17.0, -216.7000000000001, -219.40000000000032, -173.20000000000016, -147.70000000000013, -210.10000000000022, -261.40000000000015, 114.49999999999994, 95.0, -278.8, -155.20000000000024, -259.6000000000002, -238.9000000000002, -2.1999999999999904, 7.699999999999996, -236.50000000000026, -181.0000000000004, -247.60000000000005, -190.00000000000023, -195.10000000000025, -248.8000000000003, -227.80000000000047, -190.30000000000038, -99.99999999999997, -237.10000000000025, -234.4000000000003, -249.10000000000025, 63.80000000000007, 145.0999999999999, -174.40000000000003, -148.30000000000018, 81.50000000000003, 138.79999999999987, -196.9, -277.9000000000001, -206.50000000000028, -158.5000000000004, -199.30000000000015, -254.5000000000002, 115.09999999999982, 56.30000000000004, -104.50000000000034, -136.60000000000025, -216.10000000000028, -253.90000000000015, 152.29999999999987, 30.80000000000002, -98.80000000000018, -104.8000000000003, -154.30000000000024, -192.7000000000002, -293.49999999999966, -257.2000000000001, 77.6, 98.89999999999993, -278.20000000000005, -263.20000000000016, 117.19999999999968, 88.69999999999979, 67.40000000000006, 80.89999999999995, 124.99999999999986, 97.39999999999992, -213.10000000000042, -229.90000000000043, -68.49999999999997, -72.09999999999997, 69.20000000000002, 61.70000000000004, -216.40000000000032, -82.30000000000007, -281.4999999999998, -225.70000000000027, 69.19999999999999, 84.79999999999991, 91.09999999999998, 74.30000000000004, 81.19999999999997, 60.20000000000005, -207.10000000000014, -160.60000000000002, -189.40000000000026, -219.70000000000041, -182.50000000000034, -172.00000000000009, -132.10000000000008, -189.70000000000044, -202.0000000000003, -196.3000000000002, 50.300000000000104, 107.29999999999995, 74.90000000000006, 7.400000000000038, -105.40000000000029, -156.70000000000024, -162.70000000000024, -233.20000000000044, -161.80000000000032, -192.10000000000034, 29.300000000000008, -6.3999999999999915, -88.29999999999998, -175.9000000000004, -48.39999999999989, -9.399999999999935, -128.20000000000024, -94.00000000000003, 65.00000000000004, 112.69999999999979, 44.300000000000054, -6.099999999999962, 74.30000000000004, 122.59999999999982, -19.300000000000296, 67.39999999999995, -160.60000000000045, -82.89999999999986, 32.30000000000007, 100.39999999999985, -135.4000000000001, -234.70000000000041, -109.30000000000021, -196.00000000000023, 31.700000000000045, 50.00000000000009, -152.2000000000004, -187.90000000000032, 25.70000000000004, 60.20000000000008, -202.90000000000032, -200.5000000000004, -143.80000000000035, -198.4000000000005, 68.29999999999997, 15.800000000000074, -130.6000000000006, -124.60000000000039], "policy_predator_policy_reward": [66.0, 139.0, 163.0, 30.0, 41.0, 46.0, 98.0, 22.0, 123.0, 13.0, 53.0, 56.0, 10.0, 127.0, 129.0, 13.0, 33.0, 32.0, 24.0, 20.0, 22.0, 167.0, 16.0, 134.0, 26.0, 23.0, 26.0, 29.0, 15.0, 15.0, 88.0, 4.0, 153.0, 169.0, 53.0, 77.0, 168.0, 173.0, 4.0, 4.0, 17.0, 19.0, 109.0, 82.0, 30.0, 24.0, 118.0, 140.0, 193.0, 7.0, 148.0, 95.0, 79.0, 101.0, 143.0, 89.0, 22.0, 21.0, 24.0, 23.0, 153.0, 9.0, 33.0, 57.0, 12.0, 164.0, 87.0, 133.0, 172.0, 163.0, 26.0, 23.0, 162.0, 21.0, 112.0, 157.0, 21.0, 65.0, 148.0, 155.0, 15.0, 156.0, 154.0, 77.0, 141.0, 160.0, 86.0, 99.0, 162.0, 125.0, 25.0, 28.0, 36.0, 129.0, 26.0, 26.0, 132.0, 50.0, 145.0, 3.0, 94.0, 154.0, 36.0, 47.0, 17.0, 116.0, 163.0, 142.0, 48.0, 32.0, 112.0, 20.0, 131.0, 19.0, 172.0, 166.0, 26.0, 26.0, 71.0, 184.0, 19.0, 15.0, 26.0, 16.0, 13.0, 12.0, 157.0, 149.0, 94.0, 25.0, 35.0, 35.0, 135.0, 2.0, 180.0, 102.0, 16.0, 19.0, 17.0, 15.0, 36.0, 33.0, 4.0, 157.0, 109.0, 150.0, 134.0, 15.0, 12.0, 139.0, 154.0, 144.0, 11.0, 22.0, 47.0, 8.0, 117.0, 27.0, 104.0, 143.0, 135.0, 7.0, 43.0, 23.0, 112.0, 60.0, 90.0, 91.0, 112.0, 79.0, 21.0, 21.0, 55.0, 19.0, 25.0, 28.0, 37.0, 20.0, 111.0, 6.0, 34.0, 34.0, 149.0, 155.0, 122.0, 139.0, 11.0, 30.0, 124.0, 136.0, 25.0, 40.0, 82.0, 140.0, 128.0, 141.0, 53.0, 23.0, 26.0, 103.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5907901310084785, "mean_inference_ms": 1.8270077457138296, "mean_action_processing_ms": 0.25287883847504405, "mean_env_wait_ms": 0.1985583079644652, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004650235176086426, "StateBufferConnector_ms": 0.004575490951538086, "ViewRequirementAgentConnector_ms": 0.10409557819366455}, "num_episodes": 22, "episode_return_max": 321.60000000000025, "episode_return_min": -367.4999999999999, "episode_return_mean": -4.759000000000282, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1568000, "num_agent_steps_trained": 1568000, "num_env_steps_sampled": 392000, "num_env_steps_trained": 392000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 317.72851937045226, "num_env_steps_trained_throughput_per_sec": 317.72851937045226, "timesteps_total": 392000, "num_env_steps_sampled_lifetime": 392000, "num_agent_steps_sampled_lifetime": 1568000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1568000, "timers": {"training_iteration_time_ms": 11116.912, "restore_workers_time_ms": 0.013, "training_step_time_ms": 11116.872, "sample_time_ms": 1366.029, "learn_time_ms": 9732.645, "learn_throughput": 410.988, "synch_weights_time_ms": 16.638}, "counters": {"num_env_steps_sampled": 392000, "num_env_steps_trained": 392000, "num_agent_steps_sampled": 1568000, "num_agent_steps_trained": 1568000}, "done": false, "training_iteration": 98, "trial_id": "3dae5_00000", "date": "2024-08-14_09-24-47", "timestamp": 1723641887, "time_this_iter_s": 12.596420288085938, "time_total_s": 2705.884353876114, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b38958b0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2705.884353876114, "iterations_since_restore": 98, "perf": {"cpu_util_percent": 49.67222222222222, "ram_util_percent": 77.60555555555555}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.711421466094476, "cur_kl_coeff": 0.0004394531250000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.633508293716996, "policy_loss": -0.00471143390904501, "vf_loss": 5.638217628065241, "vf_explained_var": 0.18492626629809222, "kl": 0.004813623037227899, "entropy": 0.2391598704946104, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 186165.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.400798469371897, "cur_kl_coeff": 0.25312499999999993, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.154496396786321, "policy_loss": -0.001312470977643022, "vf_loss": 9.15424798783802, "vf_explained_var": 0.016136661755344856, "kl": 0.00616646532848634, "entropy": 1.2716626700270113, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 186165.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 396000, "num_env_steps_trained": 396000, "num_agent_steps_sampled": 1584000, "num_agent_steps_trained": 1584000}, "env_runners": {"episode_reward_max": 321.60000000000025, "episode_reward_min": -367.4999999999999, "episode_reward_mean": -22.36000000000034, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -348.69999999999993, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 159.19999999999982, "predator_policy": 193.0}, "policy_reward_mean": {"prey_policy": -86.87500000000014, "predator_policy": 75.695}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-302.39999999999986, 321.60000000000025, 282.1000000000005, 117.29999999999998, 264.9999999999997, -81.80000000000007, -367.4999999999999, -212.00000000000009, -68.6000000000005, -157.00000000000017, 231.49999999999963, 262.7999999999997, -263.0000000000003, 251.4999999999999, -260.10000000000036, -100.90000000000023, -136.5000000000002, 258.4999999999998, -251.00000000000043, -229.5000000000004, 91.49999999999984, -114.50000000000014, -266.6, -212.9000000000006, -117.10000000000073, -152.10000000000028, -196.50000000000057, 261.9000000000002, -157.70000000000002, 272.29999999999984, -292.8000000000002, -217.0000000000007, -205.80000000000038, 254.39999999999958, -108.10000000000049, -165.0000000000003, 263.0999999999998, -71.60000000000048, -197.00000000000045, -212.70000000000041, 228.49999999999972, -286.40000000000026, 239.89999999999935, 190.29999999999956, 247.39999999999966, -137.00000000000088, -21.599999999999902, 200.8999999999996, -161.70000000000036, -225.2000000000007, 188.9999999999996, 197.39999999999966, 210.39999999999958, -206.70000000000024, -150.10000000000065, -205.50000000000028, -170.80000000000044, -100.30000000000044, 190.59999999999962, 137.29999999999956, -118.10000000000053, -148.90000000000057, -211.90000000000066, 88.8999999999997, -92.20000000000005, 123.19999999999979, -31.19999999999994, 219.69999999999956, 112.19999999999975, 249.89999999999952, 105.09999999999994, -126.50000000000048, 200.69999999999942, -66.09999999999992, -44.299999999999926, 122.7, -80.10000000000053, 150.89999999999938, -181.4000000000007, -73.20000000000043, 160.09999999999954, -126.20000000000087, -95.00000000000037, -115.90000000000056, -92.2000000000003, -42.19999999999985, 201.8999999999993, -145.70000000000073, 214.09999999999923, -83.80000000000017, -149.70000000000059, -107.5000000000007, 116.69999999999952, -126.70000000000007, -136.00000000000065, -110.40000000000026, -189.5000000000009, 191.8999999999992, -94.29999999999997, -87.20000000000064], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-294.6999999999998, -348.69999999999993, 159.19999999999982, 154.3999999999998, 130.09999999999988, 115.99999999999997, -58.60000000000029, -15.099999999999978, 61.40000000000007, 149.59999999999974, -158.5000000000001, -181.30000000000007, -278.20000000000016, -289.30000000000007, -257.8000000000002, -197.20000000000005, -134.20000000000022, -114.40000000000026, -190.60000000000008, -198.4000000000001, 68.30000000000007, 120.19999999999996, 94.69999999999992, 121.09999999999997, -252.70000000000016, -172.3000000000003, 144.49999999999994, 17.0, -216.7000000000001, -219.40000000000032, -173.20000000000016, -147.70000000000013, -210.10000000000022, -261.40000000000015, 114.49999999999994, 95.0, -278.8, -155.20000000000024, -259.6000000000002, -238.9000000000002, -2.1999999999999904, 7.699999999999996, -236.50000000000026, -181.0000000000004, -247.60000000000005, -190.00000000000023, -195.10000000000025, -248.8000000000003, -227.80000000000047, -190.30000000000038, -99.99999999999997, -237.10000000000025, -234.4000000000003, -249.10000000000025, 63.80000000000007, 145.0999999999999, -174.40000000000003, -148.30000000000018, 81.50000000000003, 138.79999999999987, -196.9, -277.9000000000001, -206.50000000000028, -158.5000000000004, -199.30000000000015, -254.5000000000002, 115.09999999999982, 56.30000000000004, -104.50000000000034, -136.60000000000025, -216.10000000000028, -253.90000000000015, 152.29999999999987, 30.80000000000002, -98.80000000000018, -104.8000000000003, -154.30000000000024, -192.7000000000002, -293.49999999999966, -257.2000000000001, 77.6, 98.89999999999993, -278.20000000000005, -263.20000000000016, 117.19999999999968, 88.69999999999979, 67.40000000000006, 80.89999999999995, 124.99999999999986, 97.39999999999992, -213.10000000000042, -229.90000000000043, -68.49999999999997, -72.09999999999997, 69.20000000000002, 61.70000000000004, -216.40000000000032, -82.30000000000007, -281.4999999999998, -225.70000000000027, 69.19999999999999, 84.79999999999991, 91.09999999999998, 74.30000000000004, 81.19999999999997, 60.20000000000005, -207.10000000000014, -160.60000000000002, -189.40000000000026, -219.70000000000041, -182.50000000000034, -172.00000000000009, -132.10000000000008, -189.70000000000044, -202.0000000000003, -196.3000000000002, 50.300000000000104, 107.29999999999995, 74.90000000000006, 7.400000000000038, -105.40000000000029, -156.70000000000024, -162.70000000000024, -233.20000000000044, -161.80000000000032, -192.10000000000034, 29.300000000000008, -6.3999999999999915, -88.29999999999998, -175.9000000000004, -48.39999999999989, -9.399999999999935, -128.20000000000024, -94.00000000000003, 65.00000000000004, 112.69999999999979, 44.300000000000054, -6.099999999999962, 74.30000000000004, 122.59999999999982, -19.300000000000296, 67.39999999999995, -160.60000000000045, -82.89999999999986, 32.30000000000007, 100.39999999999985, -135.4000000000001, -234.70000000000041, -109.30000000000021, -196.00000000000023, 31.700000000000045, 50.00000000000009, -152.2000000000004, -187.90000000000032, 25.70000000000004, 60.20000000000008, -202.90000000000032, -200.5000000000004, -143.80000000000035, -198.4000000000005, 68.29999999999997, 15.800000000000074, -130.6000000000006, -124.60000000000039, -176.5000000000003, -170.50000000000034, -187.9000000000002, -169.00000000000028, -81.10000000000025, -192.10000000000045, -67.29999999999993, -109.90000000000016, 84.49999999999987, 76.39999999999992, -128.80000000000035, -133.9000000000004, 43.10000000000005, 109.99999999999974, -179.50000000000048, -112.30000000000018, -159.70000000000033, -139.00000000000045, -150.10000000000042, -111.40000000000035, 37.100000000000115, 32.60000000000011, -141.70000000000005, -148.00000000000063, -81.40000000000002, -187.6000000000004, -121.30000000000035, -111.10000000000011, -188.80000000000047, -162.70000000000047, 109.09999999999997, 81.79999999999993, -127.90000000000009, -72.39999999999995, -130.60000000000028, -127.60000000000048], "policy_predator_policy_reward": [168.0, 173.0, 4.0, 4.0, 17.0, 19.0, 109.0, 82.0, 30.0, 24.0, 118.0, 140.0, 193.0, 7.0, 148.0, 95.0, 79.0, 101.0, 143.0, 89.0, 22.0, 21.0, 24.0, 23.0, 153.0, 9.0, 33.0, 57.0, 12.0, 164.0, 87.0, 133.0, 172.0, 163.0, 26.0, 23.0, 162.0, 21.0, 112.0, 157.0, 21.0, 65.0, 148.0, 155.0, 15.0, 156.0, 154.0, 77.0, 141.0, 160.0, 86.0, 99.0, 162.0, 125.0, 25.0, 28.0, 36.0, 129.0, 26.0, 26.0, 132.0, 50.0, 145.0, 3.0, 94.0, 154.0, 36.0, 47.0, 17.0, 116.0, 163.0, 142.0, 48.0, 32.0, 112.0, 20.0, 131.0, 19.0, 172.0, 166.0, 26.0, 26.0, 71.0, 184.0, 19.0, 15.0, 26.0, 16.0, 13.0, 12.0, 157.0, 149.0, 94.0, 25.0, 35.0, 35.0, 135.0, 2.0, 180.0, 102.0, 16.0, 19.0, 17.0, 15.0, 36.0, 33.0, 4.0, 157.0, 109.0, 150.0, 134.0, 15.0, 12.0, 139.0, 154.0, 144.0, 11.0, 22.0, 47.0, 8.0, 117.0, 27.0, 104.0, 143.0, 135.0, 7.0, 43.0, 23.0, 112.0, 60.0, 90.0, 91.0, 112.0, 79.0, 21.0, 21.0, 55.0, 19.0, 25.0, 28.0, 37.0, 20.0, 111.0, 6.0, 34.0, 34.0, 149.0, 155.0, 122.0, 139.0, 11.0, 30.0, 124.0, 136.0, 25.0, 40.0, 82.0, 140.0, 128.0, 141.0, 53.0, 23.0, 26.0, 103.0, 139.0, 113.0, 100.0, 141.0, 110.0, 71.0, 28.0, 107.0, 19.0, 22.0, 5.0, 112.0, 31.0, 30.0, 91.0, 117.0, 114.0, 35.0, 104.0, 50.0, 24.0, 23.0, 29.0, 134.0, 27.0, 106.0, 114.0, 8.0, 147.0, 15.0, 1.0, 0.0, 87.0, 19.0, 124.0, 47.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5909366385097763, "mean_inference_ms": 1.8276979641905973, "mean_action_processing_ms": 0.2533986929026301, "mean_env_wait_ms": 0.19853095662624048, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004230022430419922, "StateBufferConnector_ms": 0.004634857177734375, "ViewRequirementAgentConnector_ms": 0.10675382614135742}, "num_episodes": 18, "episode_return_max": 321.60000000000025, "episode_return_min": -367.4999999999999, "episode_return_mean": -22.36000000000034, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1584000, "num_agent_steps_trained": 1584000, "num_env_steps_sampled": 396000, "num_env_steps_trained": 396000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 336.55001895965637, "num_env_steps_trained_throughput_per_sec": 336.55001895965637, "timesteps_total": 396000, "num_env_steps_sampled_lifetime": 396000, "num_agent_steps_sampled_lifetime": 1584000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1584000, "timers": {"training_iteration_time_ms": 11239.599, "restore_workers_time_ms": 0.013, "training_step_time_ms": 11239.558, "sample_time_ms": 1361.099, "learn_time_ms": 9860.403, "learn_throughput": 405.663, "synch_weights_time_ms": 16.537}, "counters": {"num_env_steps_sampled": 396000, "num_env_steps_trained": 396000, "num_agent_steps_sampled": 1584000, "num_agent_steps_trained": 1584000}, "done": false, "training_iteration": 99, "trial_id": "3dae5_00000", "date": "2024-08-14_09-24-59", "timestamp": 1723641899, "time_this_iter_s": 11.89136791229248, "time_total_s": 2717.7757217884064, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b381b9d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2717.7757217884064, "iterations_since_restore": 99, "perf": {"cpu_util_percent": 40.73529411764706, "ram_util_percent": 80.15294117647058}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.261476040075696, "cur_kl_coeff": 0.00021972656250000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.685133545865457, "policy_loss": -0.0034895249474892224, "vf_loss": 4.688622471390578, "vf_explained_var": 0.20493310302022905, "kl": 0.0027486792305155324, "entropy": 0.241665441846406, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 188055.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.3061149257516105, "cur_kl_coeff": 0.25312499999999993, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.98233135591739, "policy_loss": -0.004933559388986656, "vf_loss": 8.985215053861104, "vf_explained_var": 0.0113247207232884, "kl": 0.008098308950384764, "entropy": 1.2934704205346486, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 188055.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 400000, "num_env_steps_trained": 400000, "num_agent_steps_sampled": 1600000, "num_agent_steps_trained": 1600000}, "env_runners": {"episode_reward_max": 272.29999999999984, "episode_reward_min": -292.8000000000002, "episode_reward_mean": -7.374000000000382, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -293.49999999999966, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 152.29999999999987, "predator_policy": 184.0}, "policy_reward_mean": {"prey_policy": -72.06700000000015, "predator_policy": 68.38}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-212.9000000000006, -117.10000000000073, -152.10000000000028, -196.50000000000057, 261.9000000000002, -157.70000000000002, 272.29999999999984, -292.8000000000002, -217.0000000000007, -205.80000000000038, 254.39999999999958, -108.10000000000049, -165.0000000000003, 263.0999999999998, -71.60000000000048, -197.00000000000045, -212.70000000000041, 228.49999999999972, -286.40000000000026, 239.89999999999935, 190.29999999999956, 247.39999999999966, -137.00000000000088, -21.599999999999902, 200.8999999999996, -161.70000000000036, -225.2000000000007, 188.9999999999996, 197.39999999999966, 210.39999999999958, -206.70000000000024, -150.10000000000065, -205.50000000000028, -170.80000000000044, -100.30000000000044, 190.59999999999962, 137.29999999999956, -118.10000000000053, -148.90000000000057, -211.90000000000066, 88.8999999999997, -92.20000000000005, 123.19999999999979, -31.19999999999994, 219.69999999999956, 112.19999999999975, 249.89999999999952, 105.09999999999994, -126.50000000000048, 200.69999999999942, -66.09999999999992, -44.299999999999926, 122.7, -80.10000000000053, 150.89999999999938, -181.4000000000007, -73.20000000000043, 160.09999999999954, -126.20000000000087, -95.00000000000037, -115.90000000000056, -92.2000000000003, -42.19999999999985, 201.8999999999993, -145.70000000000073, 214.09999999999923, -83.80000000000017, -149.70000000000059, -107.5000000000007, 116.69999999999952, -126.70000000000007, -136.00000000000065, -110.40000000000026, -189.5000000000009, 191.8999999999992, -94.29999999999997, -87.20000000000064, -105.09999999999998, 164.39999999999947, 206.69999999999953, -25.599999999999653, -183.10000000000105, 125.29999999999986, -196.00000000000054, -152.20000000000024, -28.09999999999986, 138.79999999999936, -29.699999999999896, -102.00000000000031, 157.59999999999934, -124.90000000000019, 140.5999999999996, -137.1000000000003, -12.700000000000054, 199.49999999999937, -82.10000000000011, 221.8999999999997, 196.49999999999926, 263.5, 132.79999999999913], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-195.10000000000025, -248.8000000000003, -227.80000000000047, -190.30000000000038, -99.99999999999997, -237.10000000000025, -234.4000000000003, -249.10000000000025, 63.80000000000007, 145.0999999999999, -174.40000000000003, -148.30000000000018, 81.50000000000003, 138.79999999999987, -196.9, -277.9000000000001, -206.50000000000028, -158.5000000000004, -199.30000000000015, -254.5000000000002, 115.09999999999982, 56.30000000000004, -104.50000000000034, -136.60000000000025, -216.10000000000028, -253.90000000000015, 152.29999999999987, 30.80000000000002, -98.80000000000018, -104.8000000000003, -154.30000000000024, -192.7000000000002, -293.49999999999966, -257.2000000000001, 77.6, 98.89999999999993, -278.20000000000005, -263.20000000000016, 117.19999999999968, 88.69999999999979, 67.40000000000006, 80.89999999999995, 124.99999999999986, 97.39999999999992, -213.10000000000042, -229.90000000000043, -68.49999999999997, -72.09999999999997, 69.20000000000002, 61.70000000000004, -216.40000000000032, -82.30000000000007, -281.4999999999998, -225.70000000000027, 69.19999999999999, 84.79999999999991, 91.09999999999998, 74.30000000000004, 81.19999999999997, 60.20000000000005, -207.10000000000014, -160.60000000000002, -189.40000000000026, -219.70000000000041, -182.50000000000034, -172.00000000000009, -132.10000000000008, -189.70000000000044, -202.0000000000003, -196.3000000000002, 50.300000000000104, 107.29999999999995, 74.90000000000006, 7.400000000000038, -105.40000000000029, -156.70000000000024, -162.70000000000024, -233.20000000000044, -161.80000000000032, -192.10000000000034, 29.300000000000008, -6.3999999999999915, -88.29999999999998, -175.9000000000004, -48.39999999999989, -9.399999999999935, -128.20000000000024, -94.00000000000003, 65.00000000000004, 112.69999999999979, 44.300000000000054, -6.099999999999962, 74.30000000000004, 122.59999999999982, -19.300000000000296, 67.39999999999995, -160.60000000000045, -82.89999999999986, 32.30000000000007, 100.39999999999985, -135.4000000000001, -234.70000000000041, -109.30000000000021, -196.00000000000023, 31.700000000000045, 50.00000000000009, -152.2000000000004, -187.90000000000032, 25.70000000000004, 60.20000000000008, -202.90000000000032, -200.5000000000004, -143.80000000000035, -198.4000000000005, 68.29999999999997, 15.800000000000074, -130.6000000000006, -124.60000000000039, -176.5000000000003, -170.50000000000034, -187.9000000000002, -169.00000000000028, -81.10000000000025, -192.10000000000045, -67.29999999999993, -109.90000000000016, 84.49999999999987, 76.39999999999992, -128.80000000000035, -133.9000000000004, 43.10000000000005, 109.99999999999974, -179.50000000000048, -112.30000000000018, -159.70000000000033, -139.00000000000045, -150.10000000000042, -111.40000000000035, 37.100000000000115, 32.60000000000011, -141.70000000000005, -148.00000000000063, -81.40000000000002, -187.6000000000004, -121.30000000000035, -111.10000000000011, -188.80000000000047, -162.70000000000047, 109.09999999999997, 81.79999999999993, -127.90000000000009, -72.39999999999995, -130.60000000000028, -127.60000000000048, -175.60000000000034, -137.5000000000004, 58.400000000000134, 80.0000000000001, 72.79999999999997, 89.89999999999995, -111.10000000000022, -107.50000000000041, -190.00000000000057, -135.1000000000004, 49.7, 59.60000000000005, -182.80000000000038, -164.20000000000013, -168.40000000000006, -98.80000000000018, -95.50000000000009, -97.6000000000002, 54.500000000000114, 44.300000000000026, -114.40000000000012, -172.30000000000047, -74.50000000000004, -146.5000000000003, 74.59999999999997, 53.00000000000009, -160.30000000000015, -130.60000000000034, 34.40000000000009, 57.200000000000095, -117.40000000000023, -153.70000000000016, -106.60000000000016, -117.10000000000025, 75.8, 91.69999999999996, -59.199999999999925, -160.90000000000038, 24.500000000000064, 136.4, 89.29999999999993, 93.19999999999976, 132.5, 104.00000000000003, -18.69999999999984, 75.4999999999998], "policy_predator_policy_reward": [154.0, 77.0, 141.0, 160.0, 86.0, 99.0, 162.0, 125.0, 25.0, 28.0, 36.0, 129.0, 26.0, 26.0, 132.0, 50.0, 145.0, 3.0, 94.0, 154.0, 36.0, 47.0, 17.0, 116.0, 163.0, 142.0, 48.0, 32.0, 112.0, 20.0, 131.0, 19.0, 172.0, 166.0, 26.0, 26.0, 71.0, 184.0, 19.0, 15.0, 26.0, 16.0, 13.0, 12.0, 157.0, 149.0, 94.0, 25.0, 35.0, 35.0, 135.0, 2.0, 180.0, 102.0, 16.0, 19.0, 17.0, 15.0, 36.0, 33.0, 4.0, 157.0, 109.0, 150.0, 134.0, 15.0, 12.0, 139.0, 154.0, 144.0, 11.0, 22.0, 47.0, 8.0, 117.0, 27.0, 104.0, 143.0, 135.0, 7.0, 43.0, 23.0, 112.0, 60.0, 90.0, 91.0, 112.0, 79.0, 21.0, 21.0, 55.0, 19.0, 25.0, 28.0, 37.0, 20.0, 111.0, 6.0, 34.0, 34.0, 149.0, 155.0, 122.0, 139.0, 11.0, 30.0, 124.0, 136.0, 25.0, 40.0, 82.0, 140.0, 128.0, 141.0, 53.0, 23.0, 26.0, 103.0, 139.0, 113.0, 100.0, 141.0, 110.0, 71.0, 28.0, 107.0, 19.0, 22.0, 5.0, 112.0, 31.0, 30.0, 91.0, 117.0, 114.0, 35.0, 104.0, 50.0, 24.0, 23.0, 29.0, 134.0, 27.0, 106.0, 114.0, 8.0, 147.0, 15.0, 1.0, 0.0, 87.0, 19.0, 124.0, 47.0, 143.0, 65.0, 13.0, 13.0, 16.0, 28.0, 101.0, 92.0, 29.0, 113.0, 4.0, 12.0, 151.0, 0.0, 112.0, 3.0, 86.0, 79.0, 20.0, 20.0, 127.0, 130.0, 20.0, 99.0, 15.0, 15.0, 45.0, 121.0, 30.0, 19.0, 128.0, 6.0, 102.0, 109.0, 14.0, 18.0, 18.0, 120.0, 40.0, 21.0, 7.0, 7.0, 13.0, 14.0, 37.0, 39.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5917334814708457, "mean_inference_ms": 1.8282834644278056, "mean_action_processing_ms": 0.2539268893123224, "mean_env_wait_ms": 0.19885034582317496, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0038514137268066406, "StateBufferConnector_ms": 0.004571199417114258, "ViewRequirementAgentConnector_ms": 0.11070799827575684}, "num_episodes": 23, "episode_return_max": 272.29999999999984, "episode_return_min": -292.8000000000002, "episode_return_mean": -7.374000000000382, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1600000, "num_agent_steps_trained": 1600000, "num_env_steps_sampled": 400000, "num_env_steps_trained": 400000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 356.34530738969556, "num_env_steps_trained_throughput_per_sec": 356.34530738969556, "timesteps_total": 400000, "num_env_steps_sampled_lifetime": 400000, "num_agent_steps_sampled_lifetime": 1600000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1600000, "timers": {"training_iteration_time_ms": 11317.647, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11317.606, "sample_time_ms": 1398.364, "learn_time_ms": 9901.053, "learn_throughput": 403.997, "synch_weights_time_ms": 16.623}, "counters": {"num_env_steps_sampled": 400000, "num_env_steps_trained": 400000, "num_agent_steps_sampled": 1600000, "num_agent_steps_trained": 1600000}, "done": false, "training_iteration": 100, "trial_id": "3dae5_00000", "date": "2024-08-14_09-25-10", "timestamp": 1723641910, "time_this_iter_s": 11.269042253494263, "time_total_s": 2729.0447640419006, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b36e0b80>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2729.0447640419006, "iterations_since_restore": 100, "perf": {"cpu_util_percent": 32.14375, "ram_util_percent": 83.4}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.596242767856235, "cur_kl_coeff": 0.00010986328125000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.684518416218026, "policy_loss": -0.0018423298218597968, "vf_loss": 5.686360431095911, "vf_explained_var": 0.19945602227771092, "kl": 0.0026012426651368993, "entropy": 0.24703679370186316, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 189945.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.137165698960976, "cur_kl_coeff": 0.25312499999999993, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.188913705109288, "policy_loss": -0.00464395043334219, "vf_loss": 9.191630848374947, "vf_explained_var": 0.028635939088448015, "kl": 0.007612114205451534, "entropy": 1.288014021689299, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 189945.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 404000, "num_env_steps_trained": 404000, "num_agent_steps_sampled": 1616000, "num_agent_steps_trained": 1616000}, "env_runners": {"episode_reward_max": 263.5, "episode_reward_min": -286.40000000000026, "episode_reward_mean": 1.4229999999996192, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -281.4999999999998, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 136.4, "predator_policy": 184.0}, "policy_reward_mean": {"prey_policy": -63.30850000000015, "predator_policy": 64.02}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-286.40000000000026, 239.89999999999935, 190.29999999999956, 247.39999999999966, -137.00000000000088, -21.599999999999902, 200.8999999999996, -161.70000000000036, -225.2000000000007, 188.9999999999996, 197.39999999999966, 210.39999999999958, -206.70000000000024, -150.10000000000065, -205.50000000000028, -170.80000000000044, -100.30000000000044, 190.59999999999962, 137.29999999999956, -118.10000000000053, -148.90000000000057, -211.90000000000066, 88.8999999999997, -92.20000000000005, 123.19999999999979, -31.19999999999994, 219.69999999999956, 112.19999999999975, 249.89999999999952, 105.09999999999994, -126.50000000000048, 200.69999999999942, -66.09999999999992, -44.299999999999926, 122.7, -80.10000000000053, 150.89999999999938, -181.4000000000007, -73.20000000000043, 160.09999999999954, -126.20000000000087, -95.00000000000037, -115.90000000000056, -92.2000000000003, -42.19999999999985, 201.8999999999993, -145.70000000000073, 214.09999999999923, -83.80000000000017, -149.70000000000059, -107.5000000000007, 116.69999999999952, -126.70000000000007, -136.00000000000065, -110.40000000000026, -189.5000000000009, 191.8999999999992, -94.29999999999997, -87.20000000000064, -105.09999999999998, 164.39999999999947, 206.69999999999953, -25.599999999999653, -183.10000000000105, 125.29999999999986, -196.00000000000054, -152.20000000000024, -28.09999999999986, 138.79999999999936, -29.699999999999896, -102.00000000000031, 157.59999999999934, -124.90000000000019, 140.5999999999996, -137.1000000000003, -12.700000000000054, 199.49999999999937, -82.10000000000011, 221.8999999999997, 196.49999999999926, 263.5, 132.79999999999913, -78.99999999999991, -57.09999999999962, -32.4, -90.90000000000083, 133.89999999999898, -8.599999999999916, -52.99999999999971, -20.39999999999968, -24.400000000000034, -45.299999999999685, 130.09999999999906, -112.40000000000106, 211.59999999999962, -103.70000000000084, -200.0000000000011, 158.69999999999945, 144.99999999999943, -98.50000000000041], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-278.20000000000005, -263.20000000000016, 117.19999999999968, 88.69999999999979, 67.40000000000006, 80.89999999999995, 124.99999999999986, 97.39999999999992, -213.10000000000042, -229.90000000000043, -68.49999999999997, -72.09999999999997, 69.20000000000002, 61.70000000000004, -216.40000000000032, -82.30000000000007, -281.4999999999998, -225.70000000000027, 69.19999999999999, 84.79999999999991, 91.09999999999998, 74.30000000000004, 81.19999999999997, 60.20000000000005, -207.10000000000014, -160.60000000000002, -189.40000000000026, -219.70000000000041, -182.50000000000034, -172.00000000000009, -132.10000000000008, -189.70000000000044, -202.0000000000003, -196.3000000000002, 50.300000000000104, 107.29999999999995, 74.90000000000006, 7.400000000000038, -105.40000000000029, -156.70000000000024, -162.70000000000024, -233.20000000000044, -161.80000000000032, -192.10000000000034, 29.300000000000008, -6.3999999999999915, -88.29999999999998, -175.9000000000004, -48.39999999999989, -9.399999999999935, -128.20000000000024, -94.00000000000003, 65.00000000000004, 112.69999999999979, 44.300000000000054, -6.099999999999962, 74.30000000000004, 122.59999999999982, -19.300000000000296, 67.39999999999995, -160.60000000000045, -82.89999999999986, 32.30000000000007, 100.39999999999985, -135.4000000000001, -234.70000000000041, -109.30000000000021, -196.00000000000023, 31.700000000000045, 50.00000000000009, -152.2000000000004, -187.90000000000032, 25.70000000000004, 60.20000000000008, -202.90000000000032, -200.5000000000004, -143.80000000000035, -198.4000000000005, 68.29999999999997, 15.800000000000074, -130.6000000000006, -124.60000000000039, -176.5000000000003, -170.50000000000034, -187.9000000000002, -169.00000000000028, -81.10000000000025, -192.10000000000045, -67.29999999999993, -109.90000000000016, 84.49999999999987, 76.39999999999992, -128.80000000000035, -133.9000000000004, 43.10000000000005, 109.99999999999974, -179.50000000000048, -112.30000000000018, -159.70000000000033, -139.00000000000045, -150.10000000000042, -111.40000000000035, 37.100000000000115, 32.60000000000011, -141.70000000000005, -148.00000000000063, -81.40000000000002, -187.6000000000004, -121.30000000000035, -111.10000000000011, -188.80000000000047, -162.70000000000047, 109.09999999999997, 81.79999999999993, -127.90000000000009, -72.39999999999995, -130.60000000000028, -127.60000000000048, -175.60000000000034, -137.5000000000004, 58.400000000000134, 80.0000000000001, 72.79999999999997, 89.89999999999995, -111.10000000000022, -107.50000000000041, -190.00000000000057, -135.1000000000004, 49.7, 59.60000000000005, -182.80000000000038, -164.20000000000013, -168.40000000000006, -98.80000000000018, -95.50000000000009, -97.6000000000002, 54.500000000000114, 44.300000000000026, -114.40000000000012, -172.30000000000047, -74.50000000000004, -146.5000000000003, 74.59999999999997, 53.00000000000009, -160.30000000000015, -130.60000000000034, 34.40000000000009, 57.200000000000095, -117.40000000000023, -153.70000000000016, -106.60000000000016, -117.10000000000025, 75.8, 91.69999999999996, -59.199999999999925, -160.90000000000038, 24.500000000000064, 136.4, 89.29999999999993, 93.19999999999976, 132.5, 104.00000000000003, -18.69999999999984, 75.4999999999998, -213.10000000000045, -142.90000000000032, -36.99999999999977, -120.10000000000016, -80.7999999999999, -97.6000000000003, -70.00000000000026, -127.9000000000004, 54.50000000000015, 55.40000000000009, -168.4000000000006, -65.19999999999996, -148.3000000000004, -18.699999999999978, -125.20000000000027, -59.19999999999982, -108.39999999999995, -90.99999999999991, -72.39999999999992, -52.899999999999864, 55.70000000000011, 64.40000000000013, -131.20000000000059, -170.20000000000044, 72.79999999999993, 90.79999999999991, -175.30000000000044, -198.4000000000005, -191.8000000000005, -167.2000000000006, 68.90000000000009, 75.80000000000003, 52.100000000000065, 56.90000000000013, -85.9000000000002, -127.6000000000007], "policy_predator_policy_reward": [71.0, 184.0, 19.0, 15.0, 26.0, 16.0, 13.0, 12.0, 157.0, 149.0, 94.0, 25.0, 35.0, 35.0, 135.0, 2.0, 180.0, 102.0, 16.0, 19.0, 17.0, 15.0, 36.0, 33.0, 4.0, 157.0, 109.0, 150.0, 134.0, 15.0, 12.0, 139.0, 154.0, 144.0, 11.0, 22.0, 47.0, 8.0, 117.0, 27.0, 104.0, 143.0, 135.0, 7.0, 43.0, 23.0, 112.0, 60.0, 90.0, 91.0, 112.0, 79.0, 21.0, 21.0, 55.0, 19.0, 25.0, 28.0, 37.0, 20.0, 111.0, 6.0, 34.0, 34.0, 149.0, 155.0, 122.0, 139.0, 11.0, 30.0, 124.0, 136.0, 25.0, 40.0, 82.0, 140.0, 128.0, 141.0, 53.0, 23.0, 26.0, 103.0, 139.0, 113.0, 100.0, 141.0, 110.0, 71.0, 28.0, 107.0, 19.0, 22.0, 5.0, 112.0, 31.0, 30.0, 91.0, 117.0, 114.0, 35.0, 104.0, 50.0, 24.0, 23.0, 29.0, 134.0, 27.0, 106.0, 114.0, 8.0, 147.0, 15.0, 1.0, 0.0, 87.0, 19.0, 124.0, 47.0, 143.0, 65.0, 13.0, 13.0, 16.0, 28.0, 101.0, 92.0, 29.0, 113.0, 4.0, 12.0, 151.0, 0.0, 112.0, 3.0, 86.0, 79.0, 20.0, 20.0, 127.0, 130.0, 20.0, 99.0, 15.0, 15.0, 45.0, 121.0, 30.0, 19.0, 128.0, 6.0, 102.0, 109.0, 14.0, 18.0, 18.0, 120.0, 40.0, 21.0, 7.0, 7.0, 13.0, 14.0, 37.0, 39.0, 150.0, 127.0, 75.0, 25.0, 73.0, 73.0, 93.0, 14.0, 8.0, 16.0, 124.0, 101.0, 80.0, 34.0, 99.0, 65.0, 94.0, 81.0, 77.0, 3.0, 10.0, 0.0, 114.0, 75.0, 28.0, 20.0, 134.0, 136.0, 136.0, 23.0, 2.0, 12.0, 17.0, 19.0, 88.0, 27.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5919669917790075, "mean_inference_ms": 1.8313029180268519, "mean_action_processing_ms": 0.2537464507204064, "mean_env_wait_ms": 0.19902028093789798, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003827333450317383, "StateBufferConnector_ms": 0.004528641700744629, "ViewRequirementAgentConnector_ms": 0.11050844192504883}, "num_episodes": 18, "episode_return_max": 263.5, "episode_return_min": -286.40000000000026, "episode_return_mean": 1.4229999999996192, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1616000, "num_agent_steps_trained": 1616000, "num_env_steps_sampled": 404000, "num_env_steps_trained": 404000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 367.56932690656527, "num_env_steps_trained_throughput_per_sec": 367.56932690656527, "timesteps_total": 404000, "num_env_steps_sampled_lifetime": 404000, "num_agent_steps_sampled_lifetime": 1616000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1616000, "timers": {"training_iteration_time_ms": 11312.1, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11312.059, "sample_time_ms": 1400.376, "learn_time_ms": 9894.543, "learn_throughput": 404.263, "synch_weights_time_ms": 15.795}, "counters": {"num_env_steps_sampled": 404000, "num_env_steps_trained": 404000, "num_agent_steps_sampled": 1616000, "num_agent_steps_trained": 1616000}, "done": false, "training_iteration": 101, "trial_id": "3dae5_00000", "date": "2024-08-14_09-25-21", "timestamp": 1723641921, "time_this_iter_s": 10.887756109237671, "time_total_s": 2739.9325201511383, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b38d5820>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2739.9325201511383, "iterations_since_restore": 101, "perf": {"cpu_util_percent": 28.681250000000002, "ram_util_percent": 83.55624999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.624590011626955, "cur_kl_coeff": 5.4931640625000015e-05, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.461737708439903, "policy_loss": -0.002875405937807743, "vf_loss": 4.464613042937385, "vf_explained_var": 0.2536470074817617, "kl": 0.003232781475650564, "entropy": 0.21165357918020278, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 191835.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.401961477156038, "cur_kl_coeff": 0.25312499999999993, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.780394710308661, "policy_loss": -0.004086103718037959, "vf_loss": 8.782482519351616, "vf_explained_var": 0.02268212314635988, "kl": 0.007894482280584753, "entropy": 1.2763260430129117, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 191835.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 408000, "num_env_steps_trained": 408000, "num_agent_steps_sampled": 1632000, "num_agent_steps_trained": 1632000}, "env_runners": {"episode_reward_max": 263.5, "episode_reward_min": -211.90000000000066, "episode_reward_mean": 5.471999999999652, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -234.70000000000041, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 136.4, "predator_policy": 155.0}, "policy_reward_mean": {"prey_policy": -56.49400000000014, "predator_policy": 59.23}, "custom_metrics": {}, "hist_stats": {"episode_reward": [137.29999999999956, -118.10000000000053, -148.90000000000057, -211.90000000000066, 88.8999999999997, -92.20000000000005, 123.19999999999979, -31.19999999999994, 219.69999999999956, 112.19999999999975, 249.89999999999952, 105.09999999999994, -126.50000000000048, 200.69999999999942, -66.09999999999992, -44.299999999999926, 122.7, -80.10000000000053, 150.89999999999938, -181.4000000000007, -73.20000000000043, 160.09999999999954, -126.20000000000087, -95.00000000000037, -115.90000000000056, -92.2000000000003, -42.19999999999985, 201.8999999999993, -145.70000000000073, 214.09999999999923, -83.80000000000017, -149.70000000000059, -107.5000000000007, 116.69999999999952, -126.70000000000007, -136.00000000000065, -110.40000000000026, -189.5000000000009, 191.8999999999992, -94.29999999999997, -87.20000000000064, -105.09999999999998, 164.39999999999947, 206.69999999999953, -25.599999999999653, -183.10000000000105, 125.29999999999986, -196.00000000000054, -152.20000000000024, -28.09999999999986, 138.79999999999936, -29.699999999999896, -102.00000000000031, 157.59999999999934, -124.90000000000019, 140.5999999999996, -137.1000000000003, -12.700000000000054, 199.49999999999937, -82.10000000000011, 221.8999999999997, 196.49999999999926, 263.5, 132.79999999999913, -78.99999999999991, -57.09999999999962, -32.4, -90.90000000000083, 133.89999999999898, -8.599999999999916, -52.99999999999971, -20.39999999999968, -24.400000000000034, -45.299999999999685, 130.09999999999906, -112.40000000000106, 211.59999999999962, -103.70000000000084, -200.0000000000011, 158.69999999999945, 144.99999999999943, -98.50000000000041, 109.89999999999952, 168.29999999999941, -122.30000000000044, 90.99999999999994, 75.2999999999996, 130.5999999999993, 36.30000000000038, -58.49999999999979, -56.09999999999984, 138.19999999999888, 97.29999999999959, -75.0, -98.00000000000064, -14.100000000000055, -2.7000000000000517, -53.1999999999998, -60.299999999999805, 98.79999999999963], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [74.90000000000006, 7.400000000000038, -105.40000000000029, -156.70000000000024, -162.70000000000024, -233.20000000000044, -161.80000000000032, -192.10000000000034, 29.300000000000008, -6.3999999999999915, -88.29999999999998, -175.9000000000004, -48.39999999999989, -9.399999999999935, -128.20000000000024, -94.00000000000003, 65.00000000000004, 112.69999999999979, 44.300000000000054, -6.099999999999962, 74.30000000000004, 122.59999999999982, -19.300000000000296, 67.39999999999995, -160.60000000000045, -82.89999999999986, 32.30000000000007, 100.39999999999985, -135.4000000000001, -234.70000000000041, -109.30000000000021, -196.00000000000023, 31.700000000000045, 50.00000000000009, -152.2000000000004, -187.90000000000032, 25.70000000000004, 60.20000000000008, -202.90000000000032, -200.5000000000004, -143.80000000000035, -198.4000000000005, 68.29999999999997, 15.800000000000074, -130.6000000000006, -124.60000000000039, -176.5000000000003, -170.50000000000034, -187.9000000000002, -169.00000000000028, -81.10000000000025, -192.10000000000045, -67.29999999999993, -109.90000000000016, 84.49999999999987, 76.39999999999992, -128.80000000000035, -133.9000000000004, 43.10000000000005, 109.99999999999974, -179.50000000000048, -112.30000000000018, -159.70000000000033, -139.00000000000045, -150.10000000000042, -111.40000000000035, 37.100000000000115, 32.60000000000011, -141.70000000000005, -148.00000000000063, -81.40000000000002, -187.6000000000004, -121.30000000000035, -111.10000000000011, -188.80000000000047, -162.70000000000047, 109.09999999999997, 81.79999999999993, -127.90000000000009, -72.39999999999995, -130.60000000000028, -127.60000000000048, -175.60000000000034, -137.5000000000004, 58.400000000000134, 80.0000000000001, 72.79999999999997, 89.89999999999995, -111.10000000000022, -107.50000000000041, -190.00000000000057, -135.1000000000004, 49.7, 59.60000000000005, -182.80000000000038, -164.20000000000013, -168.40000000000006, -98.80000000000018, -95.50000000000009, -97.6000000000002, 54.500000000000114, 44.300000000000026, -114.40000000000012, -172.30000000000047, -74.50000000000004, -146.5000000000003, 74.59999999999997, 53.00000000000009, -160.30000000000015, -130.60000000000034, 34.40000000000009, 57.200000000000095, -117.40000000000023, -153.70000000000016, -106.60000000000016, -117.10000000000025, 75.8, 91.69999999999996, -59.199999999999925, -160.90000000000038, 24.500000000000064, 136.4, 89.29999999999993, 93.19999999999976, 132.5, 104.00000000000003, -18.69999999999984, 75.4999999999998, -213.10000000000045, -142.90000000000032, -36.99999999999977, -120.10000000000016, -80.7999999999999, -97.6000000000003, -70.00000000000026, -127.9000000000004, 54.50000000000015, 55.40000000000009, -168.4000000000006, -65.19999999999996, -148.3000000000004, -18.699999999999978, -125.20000000000027, -59.19999999999982, -108.39999999999995, -90.99999999999991, -72.39999999999992, -52.899999999999864, 55.70000000000011, 64.40000000000013, -131.20000000000059, -170.20000000000044, 72.79999999999993, 90.79999999999991, -175.30000000000044, -198.4000000000005, -191.8000000000005, -167.2000000000006, 68.90000000000009, 75.80000000000003, 52.100000000000065, 56.90000000000013, -85.9000000000002, -127.6000000000007, 20.30000000000002, 29.600000000000122, 100.09999999999988, 54.20000000000011, -130.00000000000048, -112.30000000000024, 11.90000000000008, 25.10000000000008, -7.599999999999861, 32.90000000000014, 40.100000000000094, 78.49999999999989, -59.799999999999876, -25.899999999999846, -121.00000000000068, -95.50000000000064, -50.799999999999926, -100.30000000000015, 73.10000000000001, -1.8999999999999395, 42.500000000000064, 15.80000000000014, -127.6, -63.3999999999999, -80.8000000000002, -119.20000000000026, -17.200000000000053, -61.89999999999988, -74.49999999999994, -47.199999999999854, -82.29999999999998, -52.89999999999992, -93.40000000000008, -166.9000000000006, 47.30000000000012, 27.500000000000163], "policy_predator_policy_reward": [47.0, 8.0, 117.0, 27.0, 104.0, 143.0, 135.0, 7.0, 43.0, 23.0, 112.0, 60.0, 90.0, 91.0, 112.0, 79.0, 21.0, 21.0, 55.0, 19.0, 25.0, 28.0, 37.0, 20.0, 111.0, 6.0, 34.0, 34.0, 149.0, 155.0, 122.0, 139.0, 11.0, 30.0, 124.0, 136.0, 25.0, 40.0, 82.0, 140.0, 128.0, 141.0, 53.0, 23.0, 26.0, 103.0, 139.0, 113.0, 100.0, 141.0, 110.0, 71.0, 28.0, 107.0, 19.0, 22.0, 5.0, 112.0, 31.0, 30.0, 91.0, 117.0, 114.0, 35.0, 104.0, 50.0, 24.0, 23.0, 29.0, 134.0, 27.0, 106.0, 114.0, 8.0, 147.0, 15.0, 1.0, 0.0, 87.0, 19.0, 124.0, 47.0, 143.0, 65.0, 13.0, 13.0, 16.0, 28.0, 101.0, 92.0, 29.0, 113.0, 4.0, 12.0, 151.0, 0.0, 112.0, 3.0, 86.0, 79.0, 20.0, 20.0, 127.0, 130.0, 20.0, 99.0, 15.0, 15.0, 45.0, 121.0, 30.0, 19.0, 128.0, 6.0, 102.0, 109.0, 14.0, 18.0, 18.0, 120.0, 40.0, 21.0, 7.0, 7.0, 13.0, 14.0, 37.0, 39.0, 150.0, 127.0, 75.0, 25.0, 73.0, 73.0, 93.0, 14.0, 8.0, 16.0, 124.0, 101.0, 80.0, 34.0, 99.0, 65.0, 94.0, 81.0, 77.0, 3.0, 10.0, 0.0, 114.0, 75.0, 28.0, 20.0, 134.0, 136.0, 136.0, 23.0, 2.0, 12.0, 17.0, 19.0, 88.0, 27.0, 29.0, 31.0, 9.0, 5.0, 15.0, 105.0, 27.0, 27.0, 24.0, 26.0, 8.0, 4.0, 62.0, 60.0, 63.0, 95.0, 22.0, 73.0, 34.0, 33.0, 18.0, 21.0, 22.0, 94.0, 14.0, 88.0, 12.0, 53.0, 60.0, 59.0, 82.0, 0.0, 95.0, 105.0, 14.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5924598629100761, "mean_inference_ms": 1.8329038182346307, "mean_action_processing_ms": 0.25391858049774446, "mean_env_wait_ms": 0.19923314346970128, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0038971900939941406, "StateBufferConnector_ms": 0.00454258918762207, "ViewRequirementAgentConnector_ms": 0.10885739326477051}, "num_episodes": 18, "episode_return_max": 263.5, "episode_return_min": -211.90000000000066, "episode_return_mean": 5.471999999999652, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1632000, "num_agent_steps_trained": 1632000, "num_env_steps_sampled": 408000, "num_env_steps_trained": 408000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 356.4639562255914, "num_env_steps_trained_throughput_per_sec": 356.4639562255914, "timesteps_total": 408000, "num_env_steps_sampled_lifetime": 408000, "num_agent_steps_sampled_lifetime": 1632000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1632000, "timers": {"training_iteration_time_ms": 11359.538, "restore_workers_time_ms": 0.013, "training_step_time_ms": 11359.496, "sample_time_ms": 1388.314, "learn_time_ms": 9952.83, "learn_throughput": 401.896, "synch_weights_time_ms": 16.499}, "counters": {"num_env_steps_sampled": 408000, "num_env_steps_trained": 408000, "num_agent_steps_sampled": 1632000, "num_agent_steps_trained": 1632000}, "done": false, "training_iteration": 102, "trial_id": "3dae5_00000", "date": "2024-08-14_09-25-32", "timestamp": 1723641932, "time_this_iter_s": 11.245136260986328, "time_total_s": 2751.1776564121246, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b364e280>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2751.1776564121246, "iterations_since_restore": 102, "perf": {"cpu_util_percent": 31.65, "ram_util_percent": 83.51875}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 8.302195474584266, "cur_kl_coeff": 2.7465820312500007e-05, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.5284629415582724, "policy_loss": -0.002113246208638268, "vf_loss": 6.530576189737471, "vf_explained_var": 0.2437295050217361, "kl": 0.0018988644067316513, "entropy": 0.22773838283681364, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 193725.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.363601484563616, "cur_kl_coeff": 0.25312499999999993, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.162440453887616, "policy_loss": -0.006177213761176934, "vf_loss": 9.166223438706979, "vf_explained_var": 0.007593701598505495, "kl": 0.009458644502877924, "entropy": 1.2282867699703843, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 193725.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 412000, "num_env_steps_trained": 412000, "num_agent_steps_sampled": 1648000, "num_agent_steps_trained": 1648000}, "env_runners": {"episode_reward_max": 263.5, "episode_reward_min": -200.0000000000011, "episode_reward_mean": 0.13799999999969026, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -213.10000000000045, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 136.4, "predator_policy": 151.0}, "policy_reward_mean": {"prey_policy": -53.82100000000012, "predator_policy": 53.89}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-126.20000000000087, -95.00000000000037, -115.90000000000056, -92.2000000000003, -42.19999999999985, 201.8999999999993, -145.70000000000073, 214.09999999999923, -83.80000000000017, -149.70000000000059, -107.5000000000007, 116.69999999999952, -126.70000000000007, -136.00000000000065, -110.40000000000026, -189.5000000000009, 191.8999999999992, -94.29999999999997, -87.20000000000064, -105.09999999999998, 164.39999999999947, 206.69999999999953, -25.599999999999653, -183.10000000000105, 125.29999999999986, -196.00000000000054, -152.20000000000024, -28.09999999999986, 138.79999999999936, -29.699999999999896, -102.00000000000031, 157.59999999999934, -124.90000000000019, 140.5999999999996, -137.1000000000003, -12.700000000000054, 199.49999999999937, -82.10000000000011, 221.8999999999997, 196.49999999999926, 263.5, 132.79999999999913, -78.99999999999991, -57.09999999999962, -32.4, -90.90000000000083, 133.89999999999898, -8.599999999999916, -52.99999999999971, -20.39999999999968, -24.400000000000034, -45.299999999999685, 130.09999999999906, -112.40000000000106, 211.59999999999962, -103.70000000000084, -200.0000000000011, 158.69999999999945, 144.99999999999943, -98.50000000000041, 109.89999999999952, 168.29999999999941, -122.30000000000044, 90.99999999999994, 75.2999999999996, 130.5999999999993, 36.30000000000038, -58.49999999999979, -56.09999999999984, 138.19999999999888, 97.29999999999959, -75.0, -98.00000000000064, -14.100000000000055, -2.7000000000000517, -53.1999999999998, -60.299999999999805, 98.79999999999963, -83.30000000000035, -9.899999999999995, 73.19999999999956, -120.20000000000093, -55.899999999999736, 62.2999999999996, 109.49999999999892, 10.800000000000031, 66.89999999999917, -41.69999999999981, -11.900000000000055, -49.999999999999794, -42.09999999999965, 52.60000000000041, -110.4000000000014, 88.69999999999992, 73.69999999999968, -2.1999999999999904, -6.699999999999786, -22.69999999999999, -2.099999999999739, -15.199999999999854], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-130.6000000000006, -124.60000000000039, -176.5000000000003, -170.50000000000034, -187.9000000000002, -169.00000000000028, -81.10000000000025, -192.10000000000045, -67.29999999999993, -109.90000000000016, 84.49999999999987, 76.39999999999992, -128.80000000000035, -133.9000000000004, 43.10000000000005, 109.99999999999974, -179.50000000000048, -112.30000000000018, -159.70000000000033, -139.00000000000045, -150.10000000000042, -111.40000000000035, 37.100000000000115, 32.60000000000011, -141.70000000000005, -148.00000000000063, -81.40000000000002, -187.6000000000004, -121.30000000000035, -111.10000000000011, -188.80000000000047, -162.70000000000047, 109.09999999999997, 81.79999999999993, -127.90000000000009, -72.39999999999995, -130.60000000000028, -127.60000000000048, -175.60000000000034, -137.5000000000004, 58.400000000000134, 80.0000000000001, 72.79999999999997, 89.89999999999995, -111.10000000000022, -107.50000000000041, -190.00000000000057, -135.1000000000004, 49.7, 59.60000000000005, -182.80000000000038, -164.20000000000013, -168.40000000000006, -98.80000000000018, -95.50000000000009, -97.6000000000002, 54.500000000000114, 44.300000000000026, -114.40000000000012, -172.30000000000047, -74.50000000000004, -146.5000000000003, 74.59999999999997, 53.00000000000009, -160.30000000000015, -130.60000000000034, 34.40000000000009, 57.200000000000095, -117.40000000000023, -153.70000000000016, -106.60000000000016, -117.10000000000025, 75.8, 91.69999999999996, -59.199999999999925, -160.90000000000038, 24.500000000000064, 136.4, 89.29999999999993, 93.19999999999976, 132.5, 104.00000000000003, -18.69999999999984, 75.4999999999998, -213.10000000000045, -142.90000000000032, -36.99999999999977, -120.10000000000016, -80.7999999999999, -97.6000000000003, -70.00000000000026, -127.9000000000004, 54.50000000000015, 55.40000000000009, -168.4000000000006, -65.19999999999996, -148.3000000000004, -18.699999999999978, -125.20000000000027, -59.19999999999982, -108.39999999999995, -90.99999999999991, -72.39999999999992, -52.899999999999864, 55.70000000000011, 64.40000000000013, -131.20000000000059, -170.20000000000044, 72.79999999999993, 90.79999999999991, -175.30000000000044, -198.4000000000005, -191.8000000000005, -167.2000000000006, 68.90000000000009, 75.80000000000003, 52.100000000000065, 56.90000000000013, -85.9000000000002, -127.6000000000007, 20.30000000000002, 29.600000000000122, 100.09999999999988, 54.20000000000011, -130.00000000000048, -112.30000000000024, 11.90000000000008, 25.10000000000008, -7.599999999999861, 32.90000000000014, 40.100000000000094, 78.49999999999989, -59.799999999999876, -25.899999999999846, -121.00000000000068, -95.50000000000064, -50.799999999999926, -100.30000000000015, 73.10000000000001, -1.8999999999999395, 42.500000000000064, 15.80000000000014, -127.6, -63.3999999999999, -80.8000000000002, -119.20000000000026, -17.200000000000053, -61.89999999999988, -74.49999999999994, -47.199999999999854, -82.29999999999998, -52.89999999999992, -93.40000000000008, -166.9000000000006, 47.30000000000012, 27.500000000000163, -80.80000000000024, -89.50000000000016, -1.0000000000000298, -55.89999999999977, 35.30000000000009, -0.10000000000001208, -93.10000000000012, -135.10000000000062, -70.89999999999988, -63.99999999999988, -45.6999999999998, 44.000000000000185, 9.199999999999998, 53.3000000000002, -79.60000000000016, -52.59999999999994, -91.90000000000067, 66.8, -149.5000000000003, 0.7999999999999815, -37.89999999999987, -100.00000000000004, -49.29999999999984, -117.70000000000076, -64.89999999999986, -53.199999999999775, 13.40000000000018, -71.79999999999987, -78.7000000000003, -135.70000000000064, -3.9999999999998734, 16.699999999999974, -0.6999999999999065, 13.400000000000002, -54.399999999999885, -80.79999999999991, -61.89999999999985, -98.80000000000034, -51.39999999999991, -94.30000000000067, -28.599999999999902, -59.49999999999994, -52.9, -22.2999999999999], "policy_predator_policy_reward": [26.0, 103.0, 139.0, 113.0, 100.0, 141.0, 110.0, 71.0, 28.0, 107.0, 19.0, 22.0, 5.0, 112.0, 31.0, 30.0, 91.0, 117.0, 114.0, 35.0, 104.0, 50.0, 24.0, 23.0, 29.0, 134.0, 27.0, 106.0, 114.0, 8.0, 147.0, 15.0, 1.0, 0.0, 87.0, 19.0, 124.0, 47.0, 143.0, 65.0, 13.0, 13.0, 16.0, 28.0, 101.0, 92.0, 29.0, 113.0, 4.0, 12.0, 151.0, 0.0, 112.0, 3.0, 86.0, 79.0, 20.0, 20.0, 127.0, 130.0, 20.0, 99.0, 15.0, 15.0, 45.0, 121.0, 30.0, 19.0, 128.0, 6.0, 102.0, 109.0, 14.0, 18.0, 18.0, 120.0, 40.0, 21.0, 7.0, 7.0, 13.0, 14.0, 37.0, 39.0, 150.0, 127.0, 75.0, 25.0, 73.0, 73.0, 93.0, 14.0, 8.0, 16.0, 124.0, 101.0, 80.0, 34.0, 99.0, 65.0, 94.0, 81.0, 77.0, 3.0, 10.0, 0.0, 114.0, 75.0, 28.0, 20.0, 134.0, 136.0, 136.0, 23.0, 2.0, 12.0, 17.0, 19.0, 88.0, 27.0, 29.0, 31.0, 9.0, 5.0, 15.0, 105.0, 27.0, 27.0, 24.0, 26.0, 8.0, 4.0, 62.0, 60.0, 63.0, 95.0, 22.0, 73.0, 34.0, 33.0, 18.0, 21.0, 22.0, 94.0, 14.0, 88.0, 12.0, 53.0, 60.0, 59.0, 82.0, 0.0, 95.0, 105.0, 14.0, 10.0, 78.0, 9.0, 7.0, 40.0, 13.0, 25.0, 5.0, 103.0, 6.0, 73.0, 25.0, 39.0, 23.0, 24.0, 67.0, 76.0, 61.0, 31.0, 22.0, 85.0, 66.0, 60.0, 76.0, 41.0, 15.0, 61.0, 55.0, 56.0, 17.0, 87.0, 39.0, 37.0, 31.0, 30.0, 60.0, 73.0, 67.0, 87.0, 81.0, 42.0, 82.0, 4.0, 53.0, 7.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5923204117933065, "mean_inference_ms": 1.8327428636829135, "mean_action_processing_ms": 0.25382806486732024, "mean_env_wait_ms": 0.19927164962173635, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0053577423095703125, "StateBufferConnector_ms": 0.004457235336303711, "ViewRequirementAgentConnector_ms": 0.11782026290893555}, "num_episodes": 22, "episode_return_max": 263.5, "episode_return_min": -200.0000000000011, "episode_return_mean": 0.13799999999969026, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1648000, "num_agent_steps_trained": 1648000, "num_env_steps_sampled": 412000, "num_env_steps_trained": 412000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 324.37073429071705, "num_env_steps_trained_throughput_per_sec": 324.37073429071705, "timesteps_total": 412000, "num_env_steps_sampled_lifetime": 412000, "num_agent_steps_sampled_lifetime": 1648000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1648000, "timers": {"training_iteration_time_ms": 11521.246, "restore_workers_time_ms": 0.013, "training_step_time_ms": 11521.203, "sample_time_ms": 1393.513, "learn_time_ms": 10108.967, "learn_throughput": 395.688, "synch_weights_time_ms": 16.589}, "counters": {"num_env_steps_sampled": 412000, "num_env_steps_trained": 412000, "num_agent_steps_sampled": 1648000, "num_agent_steps_trained": 1648000}, "done": false, "training_iteration": 103, "trial_id": "3dae5_00000", "date": "2024-08-14_09-25-45", "timestamp": 1723641945, "time_this_iter_s": 12.388958930969238, "time_total_s": 2763.566615343094, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b38d53a0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2763.566615343094, "iterations_since_restore": 103, "perf": {"cpu_util_percent": 41.650000000000006, "ram_util_percent": 83.7}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 11.58535458726227, "cur_kl_coeff": 1.3732910156250004e-05, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.23437680769219, "policy_loss": -0.004366383804304022, "vf_loss": 6.238743186123156, "vf_explained_var": 0.23979546620101524, "kl": 0.006063120251600349, "entropy": 0.2843987452526572, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 195615.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.490919713967692, "cur_kl_coeff": 0.25312499999999993, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.061929377803096, "policy_loss": -0.008702139080891376, "vf_loss": 9.067802814705662, "vf_explained_var": 0.12007962818498964, "kl": 0.011175030234686072, "entropy": 1.2359939772615989, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 195615.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 416000, "num_env_steps_trained": 416000, "num_agent_steps_sampled": 1664000, "num_agent_steps_trained": 1664000}, "env_runners": {"episode_reward_max": 263.5, "episode_reward_min": -200.0000000000011, "episode_reward_mean": 7.6039999999997585, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -213.10000000000045, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 136.4, "predator_policy": 151.0}, "policy_reward_mean": {"prey_policy": -45.67300000000009, "predator_policy": 49.475}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-87.20000000000064, -105.09999999999998, 164.39999999999947, 206.69999999999953, -25.599999999999653, -183.10000000000105, 125.29999999999986, -196.00000000000054, -152.20000000000024, -28.09999999999986, 138.79999999999936, -29.699999999999896, -102.00000000000031, 157.59999999999934, -124.90000000000019, 140.5999999999996, -137.1000000000003, -12.700000000000054, 199.49999999999937, -82.10000000000011, 221.8999999999997, 196.49999999999926, 263.5, 132.79999999999913, -78.99999999999991, -57.09999999999962, -32.4, -90.90000000000083, 133.89999999999898, -8.599999999999916, -52.99999999999971, -20.39999999999968, -24.400000000000034, -45.299999999999685, 130.09999999999906, -112.40000000000106, 211.59999999999962, -103.70000000000084, -200.0000000000011, 158.69999999999945, 144.99999999999943, -98.50000000000041, 109.89999999999952, 168.29999999999941, -122.30000000000044, 90.99999999999994, 75.2999999999996, 130.5999999999993, 36.30000000000038, -58.49999999999979, -56.09999999999984, 138.19999999999888, 97.29999999999959, -75.0, -98.00000000000064, -14.100000000000055, -2.7000000000000517, -53.1999999999998, -60.299999999999805, 98.79999999999963, -83.30000000000035, -9.899999999999995, 73.19999999999956, -120.20000000000093, -55.899999999999736, 62.2999999999996, 109.49999999999892, 10.800000000000031, 66.89999999999917, -41.69999999999981, -11.900000000000055, -49.999999999999794, -42.09999999999965, 52.60000000000041, -110.4000000000014, 88.69999999999992, 73.69999999999968, -2.1999999999999904, -6.699999999999786, -22.69999999999999, -2.099999999999739, -15.199999999999854, 2.1000000000000356, 55.100000000000335, -15.599999999999612, 77.59999999999927, -30.599999999999802, 66.10000000000016, 14.399999999999919, -55.70000000000119, 4.899999999999949, 21.200000000000344, -30.099999999999582, -52.60000000000086, -38.4999999999997, -16.599999999999675, -58.60000000000079, -10.599999999999902, -11.099999999999989, -65.30000000000032], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-130.60000000000028, -127.60000000000048, -175.60000000000034, -137.5000000000004, 58.400000000000134, 80.0000000000001, 72.79999999999997, 89.89999999999995, -111.10000000000022, -107.50000000000041, -190.00000000000057, -135.1000000000004, 49.7, 59.60000000000005, -182.80000000000038, -164.20000000000013, -168.40000000000006, -98.80000000000018, -95.50000000000009, -97.6000000000002, 54.500000000000114, 44.300000000000026, -114.40000000000012, -172.30000000000047, -74.50000000000004, -146.5000000000003, 74.59999999999997, 53.00000000000009, -160.30000000000015, -130.60000000000034, 34.40000000000009, 57.200000000000095, -117.40000000000023, -153.70000000000016, -106.60000000000016, -117.10000000000025, 75.8, 91.69999999999996, -59.199999999999925, -160.90000000000038, 24.500000000000064, 136.4, 89.29999999999993, 93.19999999999976, 132.5, 104.00000000000003, -18.69999999999984, 75.4999999999998, -213.10000000000045, -142.90000000000032, -36.99999999999977, -120.10000000000016, -80.7999999999999, -97.6000000000003, -70.00000000000026, -127.9000000000004, 54.50000000000015, 55.40000000000009, -168.4000000000006, -65.19999999999996, -148.3000000000004, -18.699999999999978, -125.20000000000027, -59.19999999999982, -108.39999999999995, -90.99999999999991, -72.39999999999992, -52.899999999999864, 55.70000000000011, 64.40000000000013, -131.20000000000059, -170.20000000000044, 72.79999999999993, 90.79999999999991, -175.30000000000044, -198.4000000000005, -191.8000000000005, -167.2000000000006, 68.90000000000009, 75.80000000000003, 52.100000000000065, 56.90000000000013, -85.9000000000002, -127.6000000000007, 20.30000000000002, 29.600000000000122, 100.09999999999988, 54.20000000000011, -130.00000000000048, -112.30000000000024, 11.90000000000008, 25.10000000000008, -7.599999999999861, 32.90000000000014, 40.100000000000094, 78.49999999999989, -59.799999999999876, -25.899999999999846, -121.00000000000068, -95.50000000000064, -50.799999999999926, -100.30000000000015, 73.10000000000001, -1.8999999999999395, 42.500000000000064, 15.80000000000014, -127.6, -63.3999999999999, -80.8000000000002, -119.20000000000026, -17.200000000000053, -61.89999999999988, -74.49999999999994, -47.199999999999854, -82.29999999999998, -52.89999999999992, -93.40000000000008, -166.9000000000006, 47.30000000000012, 27.500000000000163, -80.80000000000024, -89.50000000000016, -1.0000000000000298, -55.89999999999977, 35.30000000000009, -0.10000000000001208, -93.10000000000012, -135.10000000000062, -70.89999999999988, -63.99999999999988, -45.6999999999998, 44.000000000000185, 9.199999999999998, 53.3000000000002, -79.60000000000016, -52.59999999999994, -91.90000000000067, 66.8, -149.5000000000003, 0.7999999999999815, -37.89999999999987, -100.00000000000004, -49.29999999999984, -117.70000000000076, -64.89999999999986, -53.199999999999775, 13.40000000000018, -71.79999999999987, -78.7000000000003, -135.70000000000064, -3.9999999999998734, 16.699999999999974, -0.6999999999999065, 13.400000000000002, -54.399999999999885, -80.79999999999991, -61.89999999999985, -98.80000000000034, -51.39999999999991, -94.30000000000067, -28.599999999999902, -59.49999999999994, -52.9, -22.2999999999999, -55.59999999999977, -22.299999999999812, 7.999999999999959, 1.100000000000016, -70.30000000000052, -4.300000000000033, 17.6000000000001, 23.000000000000075, -51.399999999999764, -68.19999999999997, 27.800000000000196, -9.699999999999932, -14.799999999999807, -8.799999999999978, -56.49999999999978, -65.20000000000027, -82.90000000000023, -59.19999999999983, 17.600000000000186, -57.39999999999992, -66.10000000000005, -106.00000000000071, -93.40000000000083, -89.20000000000061, -54.69999999999985, -68.80000000000013, -26.199999999999932, -66.40000000000023, -99.70000000000054, -103.9000000000008, -62.19999999999981, -51.399999999999764, -22.59999999999985, -89.50000000000031, -89.80000000000013, -41.4999999999998], "policy_predator_policy_reward": [124.0, 47.0, 143.0, 65.0, 13.0, 13.0, 16.0, 28.0, 101.0, 92.0, 29.0, 113.0, 4.0, 12.0, 151.0, 0.0, 112.0, 3.0, 86.0, 79.0, 20.0, 20.0, 127.0, 130.0, 20.0, 99.0, 15.0, 15.0, 45.0, 121.0, 30.0, 19.0, 128.0, 6.0, 102.0, 109.0, 14.0, 18.0, 18.0, 120.0, 40.0, 21.0, 7.0, 7.0, 13.0, 14.0, 37.0, 39.0, 150.0, 127.0, 75.0, 25.0, 73.0, 73.0, 93.0, 14.0, 8.0, 16.0, 124.0, 101.0, 80.0, 34.0, 99.0, 65.0, 94.0, 81.0, 77.0, 3.0, 10.0, 0.0, 114.0, 75.0, 28.0, 20.0, 134.0, 136.0, 136.0, 23.0, 2.0, 12.0, 17.0, 19.0, 88.0, 27.0, 29.0, 31.0, 9.0, 5.0, 15.0, 105.0, 27.0, 27.0, 24.0, 26.0, 8.0, 4.0, 62.0, 60.0, 63.0, 95.0, 22.0, 73.0, 34.0, 33.0, 18.0, 21.0, 22.0, 94.0, 14.0, 88.0, 12.0, 53.0, 60.0, 59.0, 82.0, 0.0, 95.0, 105.0, 14.0, 10.0, 78.0, 9.0, 7.0, 40.0, 13.0, 25.0, 5.0, 103.0, 6.0, 73.0, 25.0, 39.0, 23.0, 24.0, 67.0, 76.0, 61.0, 31.0, 22.0, 85.0, 66.0, 60.0, 76.0, 41.0, 15.0, 61.0, 55.0, 56.0, 17.0, 87.0, 39.0, 37.0, 31.0, 30.0, 60.0, 73.0, 67.0, 87.0, 81.0, 42.0, 82.0, 4.0, 53.0, 7.0, 26.0, 54.0, 25.0, 21.0, 27.0, 32.0, 16.0, 21.0, 59.0, 30.0, 39.0, 9.0, 4.0, 34.0, 15.0, 51.0, 71.0, 76.0, 50.0, 11.0, 78.0, 64.0, 59.0, 71.0, 74.0, 11.0, 47.0, 29.0, 73.0, 72.0, 50.0, 53.0, 69.0, 32.0, 2.0, 64.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5927140781364076, "mean_inference_ms": 1.8339142294017745, "mean_action_processing_ms": 0.2538953313448485, "mean_env_wait_ms": 0.1994670818588001, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005747079849243164, "StateBufferConnector_ms": 0.00481867790222168, "ViewRequirementAgentConnector_ms": 0.12631380558013916}, "num_episodes": 18, "episode_return_max": 263.5, "episode_return_min": -200.0000000000011, "episode_return_mean": 7.6039999999997585, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1664000, "num_agent_steps_trained": 1664000, "num_env_steps_sampled": 416000, "num_env_steps_trained": 416000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 320.125439778038, "num_env_steps_trained_throughput_per_sec": 320.125439778038, "timesteps_total": 416000, "num_env_steps_sampled_lifetime": 416000, "num_agent_steps_sampled_lifetime": 1664000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1664000, "timers": {"training_iteration_time_ms": 11727.345, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11727.301, "sample_time_ms": 1447.308, "learn_time_ms": 10261.074, "learn_throughput": 389.823, "synch_weights_time_ms": 16.63}, "counters": {"num_env_steps_sampled": 416000, "num_env_steps_trained": 416000, "num_agent_steps_sampled": 1664000, "num_agent_steps_trained": 1664000}, "done": false, "training_iteration": 104, "trial_id": "3dae5_00000", "date": "2024-08-14_09-25-57", "timestamp": 1723641957, "time_this_iter_s": 12.535789012908936, "time_total_s": 2776.102404356003, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b36e0e50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2776.102404356003, "iterations_since_restore": 104, "perf": {"cpu_util_percent": 40.464705882352945, "ram_util_percent": 83.8529411764706}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 12.579535594377568, "cur_kl_coeff": 1.3732910156250004e-05, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.301342611464243, "policy_loss": -0.0034215436994576107, "vf_loss": 6.304764147410317, "vf_explained_var": 0.1349911003201096, "kl": 0.00785955451995328, "entropy": 0.41124684037985626, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 197505.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.386726579338155, "cur_kl_coeff": 0.25312499999999993, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.563139197939918, "policy_loss": -0.006236838862033827, "vf_loss": 8.566993289523655, "vf_explained_var": -0.03657032481577031, "kl": 0.009413295131176188, "entropy": 1.2342321119611226, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 197505.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 420000, "num_env_steps_trained": 420000, "num_agent_steps_sampled": 1680000, "num_agent_steps_trained": 1680000}, "env_runners": {"episode_reward_max": 211.59999999999962, "episode_reward_min": -200.0000000000011, "episode_reward_mean": 2.683999999999865, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -213.10000000000045, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 100.09999999999988, "predator_policy": 150.0}, "policy_reward_mean": {"prey_policy": -44.11300000000006, "predator_policy": 45.455}, "custom_metrics": {}, "hist_stats": {"episode_reward": [132.79999999999913, -78.99999999999991, -57.09999999999962, -32.4, -90.90000000000083, 133.89999999999898, -8.599999999999916, -52.99999999999971, -20.39999999999968, -24.400000000000034, -45.299999999999685, 130.09999999999906, -112.40000000000106, 211.59999999999962, -103.70000000000084, -200.0000000000011, 158.69999999999945, 144.99999999999943, -98.50000000000041, 109.89999999999952, 168.29999999999941, -122.30000000000044, 90.99999999999994, 75.2999999999996, 130.5999999999993, 36.30000000000038, -58.49999999999979, -56.09999999999984, 138.19999999999888, 97.29999999999959, -75.0, -98.00000000000064, -14.100000000000055, -2.7000000000000517, -53.1999999999998, -60.299999999999805, 98.79999999999963, -83.30000000000035, -9.899999999999995, 73.19999999999956, -120.20000000000093, -55.899999999999736, 62.2999999999996, 109.49999999999892, 10.800000000000031, 66.89999999999917, -41.69999999999981, -11.900000000000055, -49.999999999999794, -42.09999999999965, 52.60000000000041, -110.4000000000014, 88.69999999999992, 73.69999999999968, -2.1999999999999904, -6.699999999999786, -22.69999999999999, -2.099999999999739, -15.199999999999854, 2.1000000000000356, 55.100000000000335, -15.599999999999612, 77.59999999999927, -30.599999999999802, 66.10000000000016, 14.399999999999919, -55.70000000000119, 4.899999999999949, 21.200000000000344, -30.099999999999582, -52.60000000000086, -38.4999999999997, -16.599999999999675, -58.60000000000079, -10.599999999999902, -11.099999999999989, -65.30000000000032, 5.800000000000388, 69.29999999999947, 3.099999999999984, 39.10000000000026, -12.299999999999624, 59.5000000000001, -21.59999999999961, -47.0999999999996, 24.300000000000033, 36.80000000000043, -39.399999999999864, -5.799999999999956, 15.899999999999952, -6.399999999999718, -22.399999999999892, -72.00000000000068, 32.90000000000043, -61.299999999999926, 9.599999999999971, -49.89999999999957, 26.200000000000156, 14.700000000000097, 58.00000000000027], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-18.69999999999984, 75.4999999999998, -213.10000000000045, -142.90000000000032, -36.99999999999977, -120.10000000000016, -80.7999999999999, -97.6000000000003, -70.00000000000026, -127.9000000000004, 54.50000000000015, 55.40000000000009, -168.4000000000006, -65.19999999999996, -148.3000000000004, -18.699999999999978, -125.20000000000027, -59.19999999999982, -108.39999999999995, -90.99999999999991, -72.39999999999992, -52.899999999999864, 55.70000000000011, 64.40000000000013, -131.20000000000059, -170.20000000000044, 72.79999999999993, 90.79999999999991, -175.30000000000044, -198.4000000000005, -191.8000000000005, -167.2000000000006, 68.90000000000009, 75.80000000000003, 52.100000000000065, 56.90000000000013, -85.9000000000002, -127.6000000000007, 20.30000000000002, 29.600000000000122, 100.09999999999988, 54.20000000000011, -130.00000000000048, -112.30000000000024, 11.90000000000008, 25.10000000000008, -7.599999999999861, 32.90000000000014, 40.100000000000094, 78.49999999999989, -59.799999999999876, -25.899999999999846, -121.00000000000068, -95.50000000000064, -50.799999999999926, -100.30000000000015, 73.10000000000001, -1.8999999999999395, 42.500000000000064, 15.80000000000014, -127.6, -63.3999999999999, -80.8000000000002, -119.20000000000026, -17.200000000000053, -61.89999999999988, -74.49999999999994, -47.199999999999854, -82.29999999999998, -52.89999999999992, -93.40000000000008, -166.9000000000006, 47.30000000000012, 27.500000000000163, -80.80000000000024, -89.50000000000016, -1.0000000000000298, -55.89999999999977, 35.30000000000009, -0.10000000000001208, -93.10000000000012, -135.10000000000062, -70.89999999999988, -63.99999999999988, -45.6999999999998, 44.000000000000185, 9.199999999999998, 53.3000000000002, -79.60000000000016, -52.59999999999994, -91.90000000000067, 66.8, -149.5000000000003, 0.7999999999999815, -37.89999999999987, -100.00000000000004, -49.29999999999984, -117.70000000000076, -64.89999999999986, -53.199999999999775, 13.40000000000018, -71.79999999999987, -78.7000000000003, -135.70000000000064, -3.9999999999998734, 16.699999999999974, -0.6999999999999065, 13.400000000000002, -54.399999999999885, -80.79999999999991, -61.89999999999985, -98.80000000000034, -51.39999999999991, -94.30000000000067, -28.599999999999902, -59.49999999999994, -52.9, -22.2999999999999, -55.59999999999977, -22.299999999999812, 7.999999999999959, 1.100000000000016, -70.30000000000052, -4.300000000000033, 17.6000000000001, 23.000000000000075, -51.399999999999764, -68.19999999999997, 27.800000000000196, -9.699999999999932, -14.799999999999807, -8.799999999999978, -56.49999999999978, -65.20000000000027, -82.90000000000023, -59.19999999999983, 17.600000000000186, -57.39999999999992, -66.10000000000005, -106.00000000000071, -93.40000000000083, -89.20000000000061, -54.69999999999985, -68.80000000000013, -26.199999999999932, -66.40000000000023, -99.70000000000054, -103.9000000000008, -62.19999999999981, -51.399999999999764, -22.59999999999985, -89.50000000000031, -89.80000000000013, -41.4999999999998, -38.20000000000001, -36.99999999999998, 32.00000000000023, 23.300000000000203, -10.599999999999982, -121.30000000000044, 20.90000000000002, -29.799999999999848, 8.899999999999967, -92.20000000000076, 42.49999999999999, -15.999999999999746, -48.9999999999998, -37.59999999999981, -56.79999999999978, -109.30000000000072, -20.199999999999996, -11.499999999999961, 19.100000000000215, -40.299999999999855, -100.00000000000023, -33.39999999999993, -61.00000000000036, -20.799999999999862, -22.29999999999975, -32.799999999999855, -57.69999999999978, -15.699999999999921, -58.59999999999991, -32.799999999999876, -105.10000000000065, -52.89999999999986, 3.199999999999975, -34.29999999999978, -113.20000000000044, -129.10000000000073, -19.599999999999753, 0.19999999999996046, -24.09999999999979, -89.80000000000052, 17.599999999999966, -57.39999999999979, -61.899999999999864, -24.399999999999963, 46.09999999999997, -45.09999999999995], "policy_predator_policy_reward": [37.0, 39.0, 150.0, 127.0, 75.0, 25.0, 73.0, 73.0, 93.0, 14.0, 8.0, 16.0, 124.0, 101.0, 80.0, 34.0, 99.0, 65.0, 94.0, 81.0, 77.0, 3.0, 10.0, 0.0, 114.0, 75.0, 28.0, 20.0, 134.0, 136.0, 136.0, 23.0, 2.0, 12.0, 17.0, 19.0, 88.0, 27.0, 29.0, 31.0, 9.0, 5.0, 15.0, 105.0, 27.0, 27.0, 24.0, 26.0, 8.0, 4.0, 62.0, 60.0, 63.0, 95.0, 22.0, 73.0, 34.0, 33.0, 18.0, 21.0, 22.0, 94.0, 14.0, 88.0, 12.0, 53.0, 60.0, 59.0, 82.0, 0.0, 95.0, 105.0, 14.0, 10.0, 78.0, 9.0, 7.0, 40.0, 13.0, 25.0, 5.0, 103.0, 6.0, 73.0, 25.0, 39.0, 23.0, 24.0, 67.0, 76.0, 61.0, 31.0, 22.0, 85.0, 66.0, 60.0, 76.0, 41.0, 15.0, 61.0, 55.0, 56.0, 17.0, 87.0, 39.0, 37.0, 31.0, 30.0, 60.0, 73.0, 67.0, 87.0, 81.0, 42.0, 82.0, 4.0, 53.0, 7.0, 26.0, 54.0, 25.0, 21.0, 27.0, 32.0, 16.0, 21.0, 59.0, 30.0, 39.0, 9.0, 4.0, 34.0, 15.0, 51.0, 71.0, 76.0, 50.0, 11.0, 78.0, 64.0, 59.0, 71.0, 74.0, 11.0, 47.0, 29.0, 73.0, 72.0, 50.0, 53.0, 69.0, 32.0, 2.0, 64.0, 38.0, 43.0, 0.0, 14.0, 71.0, 64.0, 24.0, 24.0, 21.0, 50.0, 18.0, 15.0, 26.0, 39.0, 52.0, 67.0, 19.0, 37.0, 15.0, 43.0, 44.0, 50.0, 59.0, 17.0, 27.0, 44.0, 38.0, 29.0, 55.0, 14.0, 23.0, 63.0, 37.0, 27.0, 83.0, 98.0, 8.0, 21.0, 31.0, 33.0, 22.0, 44.0, 46.0, 55.0, 27.0, 30.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.593022181129977, "mean_inference_ms": 1.8346896478964891, "mean_action_processing_ms": 0.25387597755465086, "mean_env_wait_ms": 0.19964217467746598, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005730152130126953, "StateBufferConnector_ms": 0.004803061485290527, "ViewRequirementAgentConnector_ms": 0.12031793594360352}, "num_episodes": 23, "episode_return_max": 211.59999999999962, "episode_return_min": -200.0000000000011, "episode_return_mean": 2.683999999999865, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1680000, "num_agent_steps_trained": 1680000, "num_env_steps_sampled": 420000, "num_env_steps_trained": 420000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 347.43270273566856, "num_env_steps_trained_throughput_per_sec": 347.43270273566856, "timesteps_total": 420000, "num_env_steps_sampled_lifetime": 420000, "num_agent_steps_sampled_lifetime": 1680000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1680000, "timers": {"training_iteration_time_ms": 11796.381, "restore_workers_time_ms": 0.015, "training_step_time_ms": 11796.334, "sample_time_ms": 1458.877, "learn_time_ms": 10318.109, "learn_throughput": 387.668, "synch_weights_time_ms": 16.904}, "counters": {"num_env_steps_sampled": 420000, "num_env_steps_trained": 420000, "num_agent_steps_sampled": 1680000, "num_agent_steps_trained": 1680000}, "done": false, "training_iteration": 105, "trial_id": "3dae5_00000", "date": "2024-08-14_09-26-09", "timestamp": 1723641969, "time_this_iter_s": 11.54520583152771, "time_total_s": 2787.6476101875305, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b364eca0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2787.6476101875305, "iterations_since_restore": 105, "perf": {"cpu_util_percent": 34.04705882352941, "ram_util_percent": 83.41764705882353}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 14.014521372381342, "cur_kl_coeff": 1.3732910156250004e-05, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.365331148722815, "policy_loss": -0.010373073114604546, "vf_loss": 5.375704180752789, "vf_explained_var": 0.19193120589331975, "kl": 0.012016820965823276, "entropy": 0.526984317671685, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 199395.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.441376562408669, "cur_kl_coeff": 0.25312499999999993, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.52536571820577, "policy_loss": -0.004093939541080208, "vf_loss": 8.527400677292436, "vf_explained_var": -0.03666456348050839, "kl": 0.008134333093368803, "entropy": 1.2625998413121258, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 199395.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 424000, "num_env_steps_trained": 424000, "num_agent_steps_sampled": 1696000, "num_agent_steps_trained": 1696000}, "env_runners": {"episode_reward_max": 168.29999999999941, "episode_reward_min": -122.30000000000044, "episode_reward_mean": 3.3129999999999553, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -166.9000000000006, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 100.09999999999988, "predator_policy": 105.0}, "policy_reward_mean": {"prey_policy": -37.80850000000002, "predator_policy": 39.465}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-98.50000000000041, 109.89999999999952, 168.29999999999941, -122.30000000000044, 90.99999999999994, 75.2999999999996, 130.5999999999993, 36.30000000000038, -58.49999999999979, -56.09999999999984, 138.19999999999888, 97.29999999999959, -75.0, -98.00000000000064, -14.100000000000055, -2.7000000000000517, -53.1999999999998, -60.299999999999805, 98.79999999999963, -83.30000000000035, -9.899999999999995, 73.19999999999956, -120.20000000000093, -55.899999999999736, 62.2999999999996, 109.49999999999892, 10.800000000000031, 66.89999999999917, -41.69999999999981, -11.900000000000055, -49.999999999999794, -42.09999999999965, 52.60000000000041, -110.4000000000014, 88.69999999999992, 73.69999999999968, -2.1999999999999904, -6.699999999999786, -22.69999999999999, -2.099999999999739, -15.199999999999854, 2.1000000000000356, 55.100000000000335, -15.599999999999612, 77.59999999999927, -30.599999999999802, 66.10000000000016, 14.399999999999919, -55.70000000000119, 4.899999999999949, 21.200000000000344, -30.099999999999582, -52.60000000000086, -38.4999999999997, -16.599999999999675, -58.60000000000079, -10.599999999999902, -11.099999999999989, -65.30000000000032, 5.800000000000388, 69.29999999999947, 3.099999999999984, 39.10000000000026, -12.299999999999624, 59.5000000000001, -21.59999999999961, -47.0999999999996, 24.300000000000033, 36.80000000000043, -39.399999999999864, -5.799999999999956, 15.899999999999952, -6.399999999999718, -22.399999999999892, -72.00000000000068, 32.90000000000043, -61.299999999999926, 9.599999999999971, -49.89999999999957, 26.200000000000156, 14.700000000000097, 58.00000000000027, 72.6999999999997, 12.499999999999925, 71.00000000000003, 20.900000000000027, 9.200000000000008, 24.300000000000402, -46.99999999999956, -15.500000000000053, 12.500000000000009, -62.90000000000028, -28.299999999999535, 22.800000000000225, -6.199999999999964, -0.7000000000000489, 22.19999999999995, 38.600000000000485, -40.59999999999958, 42.300000000000324], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-85.9000000000002, -127.6000000000007, 20.30000000000002, 29.600000000000122, 100.09999999999988, 54.20000000000011, -130.00000000000048, -112.30000000000024, 11.90000000000008, 25.10000000000008, -7.599999999999861, 32.90000000000014, 40.100000000000094, 78.49999999999989, -59.799999999999876, -25.899999999999846, -121.00000000000068, -95.50000000000064, -50.799999999999926, -100.30000000000015, 73.10000000000001, -1.8999999999999395, 42.500000000000064, 15.80000000000014, -127.6, -63.3999999999999, -80.8000000000002, -119.20000000000026, -17.200000000000053, -61.89999999999988, -74.49999999999994, -47.199999999999854, -82.29999999999998, -52.89999999999992, -93.40000000000008, -166.9000000000006, 47.30000000000012, 27.500000000000163, -80.80000000000024, -89.50000000000016, -1.0000000000000298, -55.89999999999977, 35.30000000000009, -0.10000000000001208, -93.10000000000012, -135.10000000000062, -70.89999999999988, -63.99999999999988, -45.6999999999998, 44.000000000000185, 9.199999999999998, 53.3000000000002, -79.60000000000016, -52.59999999999994, -91.90000000000067, 66.8, -149.5000000000003, 0.7999999999999815, -37.89999999999987, -100.00000000000004, -49.29999999999984, -117.70000000000076, -64.89999999999986, -53.199999999999775, 13.40000000000018, -71.79999999999987, -78.7000000000003, -135.70000000000064, -3.9999999999998734, 16.699999999999974, -0.6999999999999065, 13.400000000000002, -54.399999999999885, -80.79999999999991, -61.89999999999985, -98.80000000000034, -51.39999999999991, -94.30000000000067, -28.599999999999902, -59.49999999999994, -52.9, -22.2999999999999, -55.59999999999977, -22.299999999999812, 7.999999999999959, 1.100000000000016, -70.30000000000052, -4.300000000000033, 17.6000000000001, 23.000000000000075, -51.399999999999764, -68.19999999999997, 27.800000000000196, -9.699999999999932, -14.799999999999807, -8.799999999999978, -56.49999999999978, -65.20000000000027, -82.90000000000023, -59.19999999999983, 17.600000000000186, -57.39999999999992, -66.10000000000005, -106.00000000000071, -93.40000000000083, -89.20000000000061, -54.69999999999985, -68.80000000000013, -26.199999999999932, -66.40000000000023, -99.70000000000054, -103.9000000000008, -62.19999999999981, -51.399999999999764, -22.59999999999985, -89.50000000000031, -89.80000000000013, -41.4999999999998, -38.20000000000001, -36.99999999999998, 32.00000000000023, 23.300000000000203, -10.599999999999982, -121.30000000000044, 20.90000000000002, -29.799999999999848, 8.899999999999967, -92.20000000000076, 42.49999999999999, -15.999999999999746, -48.9999999999998, -37.59999999999981, -56.79999999999978, -109.30000000000072, -20.199999999999996, -11.499999999999961, 19.100000000000215, -40.299999999999855, -100.00000000000023, -33.39999999999993, -61.00000000000036, -20.799999999999862, -22.29999999999975, -32.799999999999855, -57.69999999999978, -15.699999999999921, -58.59999999999991, -32.799999999999876, -105.10000000000065, -52.89999999999986, 3.199999999999975, -34.29999999999978, -113.20000000000044, -129.10000000000073, -19.599999999999753, 0.19999999999996046, -24.09999999999979, -89.80000000000052, 17.599999999999966, -57.39999999999979, -61.899999999999864, -24.399999999999963, 46.09999999999997, -45.09999999999995, 39.200000000000195, 18.499999999999986, -30.699999999999783, -14.799999999999814, 4.100000000000046, 20.900000000000013, -15.099999999999778, 4.999999999999979, -5.199999999999948, -40.59999999999977, -88.0000000000004, 11.300000000000017, -89.20000000000041, -59.799999999999876, -48.099999999999774, -30.399999999999856, -9.400000000000023, -18.099999999999852, -54.99999999999981, -112.9000000000004, -59.79999999999979, -32.49999999999975, -25.299999999999763, -7.900000000000013, -27.69999999999977, -29.499999999999936, -31.899999999999757, -17.800000000000022, -16.29999999999975, 0.49999999999998346, -6.400000000000039, 17.000000000000213, -50.49999999999978, -87.10000000000039, 3.4999999999999925, 21.80000000000001], "policy_predator_policy_reward": [88.0, 27.0, 29.0, 31.0, 9.0, 5.0, 15.0, 105.0, 27.0, 27.0, 24.0, 26.0, 8.0, 4.0, 62.0, 60.0, 63.0, 95.0, 22.0, 73.0, 34.0, 33.0, 18.0, 21.0, 22.0, 94.0, 14.0, 88.0, 12.0, 53.0, 60.0, 59.0, 82.0, 0.0, 95.0, 105.0, 14.0, 10.0, 78.0, 9.0, 7.0, 40.0, 13.0, 25.0, 5.0, 103.0, 6.0, 73.0, 25.0, 39.0, 23.0, 24.0, 67.0, 76.0, 61.0, 31.0, 22.0, 85.0, 66.0, 60.0, 76.0, 41.0, 15.0, 61.0, 55.0, 56.0, 17.0, 87.0, 39.0, 37.0, 31.0, 30.0, 60.0, 73.0, 67.0, 87.0, 81.0, 42.0, 82.0, 4.0, 53.0, 7.0, 26.0, 54.0, 25.0, 21.0, 27.0, 32.0, 16.0, 21.0, 59.0, 30.0, 39.0, 9.0, 4.0, 34.0, 15.0, 51.0, 71.0, 76.0, 50.0, 11.0, 78.0, 64.0, 59.0, 71.0, 74.0, 11.0, 47.0, 29.0, 73.0, 72.0, 50.0, 53.0, 69.0, 32.0, 2.0, 64.0, 38.0, 43.0, 0.0, 14.0, 71.0, 64.0, 24.0, 24.0, 21.0, 50.0, 18.0, 15.0, 26.0, 39.0, 52.0, 67.0, 19.0, 37.0, 15.0, 43.0, 44.0, 50.0, 59.0, 17.0, 27.0, 44.0, 38.0, 29.0, 55.0, 14.0, 23.0, 63.0, 37.0, 27.0, 83.0, 98.0, 8.0, 21.0, 31.0, 33.0, 22.0, 44.0, 46.0, 55.0, 27.0, 30.0, 10.0, 5.0, 38.0, 20.0, 20.0, 26.0, 16.0, 15.0, 33.0, 22.0, 52.0, 49.0, 55.0, 47.0, 49.0, 14.0, 19.0, 21.0, 40.0, 65.0, 20.0, 44.0, 30.0, 26.0, 21.0, 30.0, 19.0, 30.0, 13.0, 25.0, 24.0, 4.0, 43.0, 54.0, 2.0, 15.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5935839809526934, "mean_inference_ms": 1.836181695122918, "mean_action_processing_ms": 0.25398037976254806, "mean_env_wait_ms": 0.19990232578954356, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005882978439331055, "StateBufferConnector_ms": 0.004879474639892578, "ViewRequirementAgentConnector_ms": 0.1265401840209961}, "num_episodes": 18, "episode_return_max": 168.29999999999941, "episode_return_min": -122.30000000000044, "episode_return_mean": 3.3129999999999553, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1696000, "num_agent_steps_trained": 1696000, "num_env_steps_sampled": 424000, "num_env_steps_trained": 424000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 321.3217147767456, "num_env_steps_trained_throughput_per_sec": 321.3217147767456, "timesteps_total": 424000, "num_env_steps_sampled_lifetime": 424000, "num_agent_steps_sampled_lifetime": 1696000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1696000, "timers": {"training_iteration_time_ms": 11991.12, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11991.072, "sample_time_ms": 1501.28, "learn_time_ms": 10468.223, "learn_throughput": 382.109, "synch_weights_time_ms": 17.221}, "counters": {"num_env_steps_sampled": 424000, "num_env_steps_trained": 424000, "num_agent_steps_sampled": 1696000, "num_agent_steps_trained": 1696000}, "done": false, "training_iteration": 106, "trial_id": "3dae5_00000", "date": "2024-08-14_09-26-21", "timestamp": 1723641981, "time_this_iter_s": 12.491744995117188, "time_total_s": 2800.1393551826477, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b364ec10>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2800.1393551826477, "iterations_since_restore": 106, "perf": {"cpu_util_percent": 38.855555555555554, "ram_util_percent": 83.69444444444443}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 10.055043226701242, "cur_kl_coeff": 1.3732910156250004e-05, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.497534712786397, "policy_loss": -0.010130359201135222, "vf_loss": 6.507664985505361, "vf_explained_var": 0.228969742066015, "kl": 0.013575748781998798, "entropy": 0.5811593763096623, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 201285.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.652878631611981, "cur_kl_coeff": 0.25312499999999993, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.225722454464625, "policy_loss": -0.010811092171118294, "vf_loss": 8.233086739141473, "vf_explained_var": 0.12197716122581845, "kl": 0.01361699715331491, "entropy": 1.269663185985, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 201285.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 428000, "num_env_steps_trained": 428000, "num_agent_steps_sampled": 1712000, "num_agent_steps_trained": 1712000}, "env_runners": {"episode_reward_max": 109.49999999999892, "episode_reward_min": -120.20000000000093, "episode_reward_mean": -1.1399999999999684, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -149.5000000000003, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 66.8, "predator_policy": 103.0}, "policy_reward_mean": {"prey_policy": -39.265000000000015, "predator_policy": 38.695}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-120.20000000000093, -55.899999999999736, 62.2999999999996, 109.49999999999892, 10.800000000000031, 66.89999999999917, -41.69999999999981, -11.900000000000055, -49.999999999999794, -42.09999999999965, 52.60000000000041, -110.4000000000014, 88.69999999999992, 73.69999999999968, -2.1999999999999904, -6.699999999999786, -22.69999999999999, -2.099999999999739, -15.199999999999854, 2.1000000000000356, 55.100000000000335, -15.599999999999612, 77.59999999999927, -30.599999999999802, 66.10000000000016, 14.399999999999919, -55.70000000000119, 4.899999999999949, 21.200000000000344, -30.099999999999582, -52.60000000000086, -38.4999999999997, -16.599999999999675, -58.60000000000079, -10.599999999999902, -11.099999999999989, -65.30000000000032, 5.800000000000388, 69.29999999999947, 3.099999999999984, 39.10000000000026, -12.299999999999624, 59.5000000000001, -21.59999999999961, -47.0999999999996, 24.300000000000033, 36.80000000000043, -39.399999999999864, -5.799999999999956, 15.899999999999952, -6.399999999999718, -22.399999999999892, -72.00000000000068, 32.90000000000043, -61.299999999999926, 9.599999999999971, -49.89999999999957, 26.200000000000156, 14.700000000000097, 58.00000000000027, 72.6999999999997, 12.499999999999925, 71.00000000000003, 20.900000000000027, 9.200000000000008, 24.300000000000402, -46.99999999999956, -15.500000000000053, 12.500000000000009, -62.90000000000028, -28.299999999999535, 22.800000000000225, -6.199999999999964, -0.7000000000000489, 22.19999999999995, 38.600000000000485, -40.59999999999958, 42.300000000000324, -21.29999999999981, -36.8999999999996, 17.69999999999995, -5.600000000000107, -35.399999999999544, -20.699999999999527, 26.200000000000117, -81.40000000000103, 1.3999999999999948, 17.799999999999958, -23.29999999999955, 8.399999999999968, -54.19999999999967, 62.90000000000046, -26.199999999999847, 11.799999999999946, -11.800000000000056, -59.799999999999585, -1.9000000000000772, 46.400000000000404, 2.799999999999971, 24.800000000000086], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-93.10000000000012, -135.10000000000062, -70.89999999999988, -63.99999999999988, -45.6999999999998, 44.000000000000185, 9.199999999999998, 53.3000000000002, -79.60000000000016, -52.59999999999994, -91.90000000000067, 66.8, -149.5000000000003, 0.7999999999999815, -37.89999999999987, -100.00000000000004, -49.29999999999984, -117.70000000000076, -64.89999999999986, -53.199999999999775, 13.40000000000018, -71.79999999999987, -78.7000000000003, -135.70000000000064, -3.9999999999998734, 16.699999999999974, -0.6999999999999065, 13.400000000000002, -54.399999999999885, -80.79999999999991, -61.89999999999985, -98.80000000000034, -51.39999999999991, -94.30000000000067, -28.599999999999902, -59.49999999999994, -52.9, -22.2999999999999, -55.59999999999977, -22.299999999999812, 7.999999999999959, 1.100000000000016, -70.30000000000052, -4.300000000000033, 17.6000000000001, 23.000000000000075, -51.399999999999764, -68.19999999999997, 27.800000000000196, -9.699999999999932, -14.799999999999807, -8.799999999999978, -56.49999999999978, -65.20000000000027, -82.90000000000023, -59.19999999999983, 17.600000000000186, -57.39999999999992, -66.10000000000005, -106.00000000000071, -93.40000000000083, -89.20000000000061, -54.69999999999985, -68.80000000000013, -26.199999999999932, -66.40000000000023, -99.70000000000054, -103.9000000000008, -62.19999999999981, -51.399999999999764, -22.59999999999985, -89.50000000000031, -89.80000000000013, -41.4999999999998, -38.20000000000001, -36.99999999999998, 32.00000000000023, 23.300000000000203, -10.599999999999982, -121.30000000000044, 20.90000000000002, -29.799999999999848, 8.899999999999967, -92.20000000000076, 42.49999999999999, -15.999999999999746, -48.9999999999998, -37.59999999999981, -56.79999999999978, -109.30000000000072, -20.199999999999996, -11.499999999999961, 19.100000000000215, -40.299999999999855, -100.00000000000023, -33.39999999999993, -61.00000000000036, -20.799999999999862, -22.29999999999975, -32.799999999999855, -57.69999999999978, -15.699999999999921, -58.59999999999991, -32.799999999999876, -105.10000000000065, -52.89999999999986, 3.199999999999975, -34.29999999999978, -113.20000000000044, -129.10000000000073, -19.599999999999753, 0.19999999999996046, -24.09999999999979, -89.80000000000052, 17.599999999999966, -57.39999999999979, -61.899999999999864, -24.399999999999963, 46.09999999999997, -45.09999999999995, 39.200000000000195, 18.499999999999986, -30.699999999999783, -14.799999999999814, 4.100000000000046, 20.900000000000013, -15.099999999999778, 4.999999999999979, -5.199999999999948, -40.59999999999977, -88.0000000000004, 11.300000000000017, -89.20000000000041, -59.799999999999876, -48.099999999999774, -30.399999999999856, -9.400000000000023, -18.099999999999852, -54.99999999999981, -112.9000000000004, -59.79999999999979, -32.49999999999975, -25.299999999999763, -7.900000000000013, -27.69999999999977, -29.499999999999936, -31.899999999999757, -17.800000000000022, -16.29999999999975, 0.49999999999998346, -6.400000000000039, 17.000000000000213, -50.49999999999978, -87.10000000000039, 3.4999999999999925, 21.80000000000001, -45.399999999999785, -58.89999999999986, -74.5000000000006, -102.40000000000036, -55.89999999999977, 17.599999999999966, -14.800000000000047, -38.799999999999756, -51.099999999999774, -46.29999999999977, -59.79999999999977, -40.89999999999976, -21.999999999999893, 24.200000000000053, -110.20000000000078, -89.20000000000044, -36.699999999999754, -16.899999999999984, -45.69999999999977, 12.499999999999963, -50.7999999999998, -74.50000000000026, -51.69999999999978, -13.899999999999817, -27.999999999999822, -131.20000000000073, -36.099999999999774, 32.000000000000234, -73.90000000000019, -28.299999999999997, 1.0999999999999812, -52.29999999999978, -47.19999999999976, -13.600000000000032, -59.79999999999977, -106.00000000000017, -43.89999999999988, -16.000000000000046, -9.10000000000001, 9.49999999999996, -82.89999999999995, -28.30000000000001, 2.299999999999981, -32.49999999999975], "policy_predator_policy_reward": [5.0, 103.0, 6.0, 73.0, 25.0, 39.0, 23.0, 24.0, 67.0, 76.0, 61.0, 31.0, 22.0, 85.0, 66.0, 60.0, 76.0, 41.0, 15.0, 61.0, 55.0, 56.0, 17.0, 87.0, 39.0, 37.0, 31.0, 30.0, 60.0, 73.0, 67.0, 87.0, 81.0, 42.0, 82.0, 4.0, 53.0, 7.0, 26.0, 54.0, 25.0, 21.0, 27.0, 32.0, 16.0, 21.0, 59.0, 30.0, 39.0, 9.0, 4.0, 34.0, 15.0, 51.0, 71.0, 76.0, 50.0, 11.0, 78.0, 64.0, 59.0, 71.0, 74.0, 11.0, 47.0, 29.0, 73.0, 72.0, 50.0, 53.0, 69.0, 32.0, 2.0, 64.0, 38.0, 43.0, 0.0, 14.0, 71.0, 64.0, 24.0, 24.0, 21.0, 50.0, 18.0, 15.0, 26.0, 39.0, 52.0, 67.0, 19.0, 37.0, 15.0, 43.0, 44.0, 50.0, 59.0, 17.0, 27.0, 44.0, 38.0, 29.0, 55.0, 14.0, 23.0, 63.0, 37.0, 27.0, 83.0, 98.0, 8.0, 21.0, 31.0, 33.0, 22.0, 44.0, 46.0, 55.0, 27.0, 30.0, 10.0, 5.0, 38.0, 20.0, 20.0, 26.0, 16.0, 15.0, 33.0, 22.0, 52.0, 49.0, 55.0, 47.0, 49.0, 14.0, 19.0, 21.0, 40.0, 65.0, 20.0, 44.0, 30.0, 26.0, 21.0, 30.0, 19.0, 30.0, 13.0, 25.0, 24.0, 4.0, 43.0, 54.0, 2.0, 15.0, 47.0, 36.0, 72.0, 68.0, 39.0, 17.0, 27.0, 21.0, 45.0, 17.0, 33.0, 47.0, 5.0, 19.0, 77.0, 41.0, 33.0, 22.0, 31.0, 20.0, 51.0, 51.0, 38.0, 36.0, 83.0, 22.0, 36.0, 31.0, 59.0, 17.0, 32.0, 31.0, 10.0, 39.0, 57.0, 49.0, 16.0, 42.0, 22.0, 24.0, 48.0, 66.0, 35.0, 20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.594410010632669, "mean_inference_ms": 1.8381516557203617, "mean_action_processing_ms": 0.253693908549699, "mean_env_wait_ms": 0.20038755119042737, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005562782287597656, "StateBufferConnector_ms": 0.004393339157104492, "ViewRequirementAgentConnector_ms": 0.12314772605895996}, "num_episodes": 22, "episode_return_max": 109.49999999999892, "episode_return_min": -120.20000000000093, "episode_return_mean": -1.1399999999999684, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1712000, "num_agent_steps_trained": 1712000, "num_env_steps_sampled": 428000, "num_env_steps_trained": 428000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 354.6732905319475, "num_env_steps_trained_throughput_per_sec": 354.6732905319475, "timesteps_total": 428000, "num_env_steps_sampled_lifetime": 428000, "num_agent_steps_sampled_lifetime": 1712000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1712000, "timers": {"training_iteration_time_ms": 11786.971, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11786.921, "sample_time_ms": 1513.175, "learn_time_ms": 10253.951, "learn_throughput": 390.094, "synch_weights_time_ms": 15.435}, "counters": {"num_env_steps_sampled": 428000, "num_env_steps_trained": 428000, "num_agent_steps_sampled": 1712000, "num_agent_steps_trained": 1712000}, "done": false, "training_iteration": 107, "trial_id": "3dae5_00000", "date": "2024-08-14_09-26-33", "timestamp": 1723641993, "time_this_iter_s": 11.333108901977539, "time_total_s": 2811.4724640846252, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3662280>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2811.4724640846252, "iterations_since_restore": 107, "perf": {"cpu_util_percent": 32.59375, "ram_util_percent": 83.79375}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 10.850623912407608, "cur_kl_coeff": 1.3732910156250004e-05, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.917676287857944, "policy_loss": -0.0042905998042976805, "vf_loss": 4.921966906703969, "vf_explained_var": 0.19618370293309448, "kl": 0.00822908784541866, "entropy": 0.6102436938298442, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 203175.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 6.971131306855136, "cur_kl_coeff": 0.25312499999999993, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.848727513368798, "policy_loss": -0.009151743486198405, "vf_loss": 6.854790664602209, "vf_explained_var": 0.26503877179332513, "kl": 0.01220178017021546, "entropy": 1.2860131997910758, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 203175.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 432000, "num_env_steps_trained": 432000, "num_agent_steps_sampled": 1728000, "num_agent_steps_trained": 1728000}, "env_runners": {"episode_reward_max": 77.59999999999927, "episode_reward_min": -81.40000000000103, "episode_reward_mean": 1.1930000000001013, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -131.20000000000073, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 46.09999999999997, "predator_policy": 98.0}, "policy_reward_mean": {"prey_policy": -33.9085, "predator_policy": 34.505}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-15.199999999999854, 2.1000000000000356, 55.100000000000335, -15.599999999999612, 77.59999999999927, -30.599999999999802, 66.10000000000016, 14.399999999999919, -55.70000000000119, 4.899999999999949, 21.200000000000344, -30.099999999999582, -52.60000000000086, -38.4999999999997, -16.599999999999675, -58.60000000000079, -10.599999999999902, -11.099999999999989, -65.30000000000032, 5.800000000000388, 69.29999999999947, 3.099999999999984, 39.10000000000026, -12.299999999999624, 59.5000000000001, -21.59999999999961, -47.0999999999996, 24.300000000000033, 36.80000000000043, -39.399999999999864, -5.799999999999956, 15.899999999999952, -6.399999999999718, -22.399999999999892, -72.00000000000068, 32.90000000000043, -61.299999999999926, 9.599999999999971, -49.89999999999957, 26.200000000000156, 14.700000000000097, 58.00000000000027, 72.6999999999997, 12.499999999999925, 71.00000000000003, 20.900000000000027, 9.200000000000008, 24.300000000000402, -46.99999999999956, -15.500000000000053, 12.500000000000009, -62.90000000000028, -28.299999999999535, 22.800000000000225, -6.199999999999964, -0.7000000000000489, 22.19999999999995, 38.600000000000485, -40.59999999999958, 42.300000000000324, -21.29999999999981, -36.8999999999996, 17.69999999999995, -5.600000000000107, -35.399999999999544, -20.699999999999527, 26.200000000000117, -81.40000000000103, 1.3999999999999948, 17.799999999999958, -23.29999999999955, 8.399999999999968, -54.19999999999967, 62.90000000000046, -26.199999999999847, 11.799999999999946, -11.800000000000056, -59.799999999999585, -1.9000000000000772, 46.400000000000404, 2.799999999999971, 24.800000000000086, 39.00000000000044, 6.899999999999958, -3.2999999999997662, 16.599999999999962, 2.5000000000001728, 45.300000000000466, 33.800000000000196, 14.499999999999973, 37.400000000000276, 14.499999999999913, -34.59999999999957, 14.299999999999928, 39.600000000000456, 20.700000000000053, 34.000000000000256, -33.69999999999954, -22.09999999999952, 6.500000000000137], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-52.9, -22.2999999999999, -55.59999999999977, -22.299999999999812, 7.999999999999959, 1.100000000000016, -70.30000000000052, -4.300000000000033, 17.6000000000001, 23.000000000000075, -51.399999999999764, -68.19999999999997, 27.800000000000196, -9.699999999999932, -14.799999999999807, -8.799999999999978, -56.49999999999978, -65.20000000000027, -82.90000000000023, -59.19999999999983, 17.600000000000186, -57.39999999999992, -66.10000000000005, -106.00000000000071, -93.40000000000083, -89.20000000000061, -54.69999999999985, -68.80000000000013, -26.199999999999932, -66.40000000000023, -99.70000000000054, -103.9000000000008, -62.19999999999981, -51.399999999999764, -22.59999999999985, -89.50000000000031, -89.80000000000013, -41.4999999999998, -38.20000000000001, -36.99999999999998, 32.00000000000023, 23.300000000000203, -10.599999999999982, -121.30000000000044, 20.90000000000002, -29.799999999999848, 8.899999999999967, -92.20000000000076, 42.49999999999999, -15.999999999999746, -48.9999999999998, -37.59999999999981, -56.79999999999978, -109.30000000000072, -20.199999999999996, -11.499999999999961, 19.100000000000215, -40.299999999999855, -100.00000000000023, -33.39999999999993, -61.00000000000036, -20.799999999999862, -22.29999999999975, -32.799999999999855, -57.69999999999978, -15.699999999999921, -58.59999999999991, -32.799999999999876, -105.10000000000065, -52.89999999999986, 3.199999999999975, -34.29999999999978, -113.20000000000044, -129.10000000000073, -19.599999999999753, 0.19999999999996046, -24.09999999999979, -89.80000000000052, 17.599999999999966, -57.39999999999979, -61.899999999999864, -24.399999999999963, 46.09999999999997, -45.09999999999995, 39.200000000000195, 18.499999999999986, -30.699999999999783, -14.799999999999814, 4.100000000000046, 20.900000000000013, -15.099999999999778, 4.999999999999979, -5.199999999999948, -40.59999999999977, -88.0000000000004, 11.300000000000017, -89.20000000000041, -59.799999999999876, -48.099999999999774, -30.399999999999856, -9.400000000000023, -18.099999999999852, -54.99999999999981, -112.9000000000004, -59.79999999999979, -32.49999999999975, -25.299999999999763, -7.900000000000013, -27.69999999999977, -29.499999999999936, -31.899999999999757, -17.800000000000022, -16.29999999999975, 0.49999999999998346, -6.400000000000039, 17.000000000000213, -50.49999999999978, -87.10000000000039, 3.4999999999999925, 21.80000000000001, -45.399999999999785, -58.89999999999986, -74.5000000000006, -102.40000000000036, -55.89999999999977, 17.599999999999966, -14.800000000000047, -38.799999999999756, -51.099999999999774, -46.29999999999977, -59.79999999999977, -40.89999999999976, -21.999999999999893, 24.200000000000053, -110.20000000000078, -89.20000000000044, -36.699999999999754, -16.899999999999984, -45.69999999999977, 12.499999999999963, -50.7999999999998, -74.50000000000026, -51.69999999999978, -13.899999999999817, -27.999999999999822, -131.20000000000073, -36.099999999999774, 32.000000000000234, -73.90000000000019, -28.299999999999997, 1.0999999999999812, -52.29999999999978, -47.19999999999976, -13.600000000000032, -59.79999999999977, -106.00000000000017, -43.89999999999988, -16.000000000000046, -9.10000000000001, 9.49999999999996, -82.89999999999995, -28.30000000000001, 2.299999999999981, -32.49999999999975, 10.700000000000003, -15.699999999999974, -30.999999999999794, -3.100000000000042, -42.399999999999764, -19.899999999999917, 17.899999999999988, -28.29999999999975, -38.799999999999756, -15.699999999999775, 25.70000000000025, -27.399999999999785, 7.399999999999977, -40.59999999999977, -24.6999999999998, -17.80000000000002, -9.99999999999996, 4.399999999999983, -6.100000000000058, -30.39999999999975, -105.10000000000079, -20.499999999999904, -6.100000000000049, -55.59999999999991, -36.99999999999977, 23.600000000000172, -25.899999999999757, -9.400000000000016, 9.799999999999967, 3.1999999999999873, -32.79999999999977, -61.90000000000068, -69.40000000000089, -9.69999999999986, -36.699999999999754, -17.799999999999798], "policy_predator_policy_reward": [53.0, 7.0, 26.0, 54.0, 25.0, 21.0, 27.0, 32.0, 16.0, 21.0, 59.0, 30.0, 39.0, 9.0, 4.0, 34.0, 15.0, 51.0, 71.0, 76.0, 50.0, 11.0, 78.0, 64.0, 59.0, 71.0, 74.0, 11.0, 47.0, 29.0, 73.0, 72.0, 50.0, 53.0, 69.0, 32.0, 2.0, 64.0, 38.0, 43.0, 0.0, 14.0, 71.0, 64.0, 24.0, 24.0, 21.0, 50.0, 18.0, 15.0, 26.0, 39.0, 52.0, 67.0, 19.0, 37.0, 15.0, 43.0, 44.0, 50.0, 59.0, 17.0, 27.0, 44.0, 38.0, 29.0, 55.0, 14.0, 23.0, 63.0, 37.0, 27.0, 83.0, 98.0, 8.0, 21.0, 31.0, 33.0, 22.0, 44.0, 46.0, 55.0, 27.0, 30.0, 10.0, 5.0, 38.0, 20.0, 20.0, 26.0, 16.0, 15.0, 33.0, 22.0, 52.0, 49.0, 55.0, 47.0, 49.0, 14.0, 19.0, 21.0, 40.0, 65.0, 20.0, 44.0, 30.0, 26.0, 21.0, 30.0, 19.0, 30.0, 13.0, 25.0, 24.0, 4.0, 43.0, 54.0, 2.0, 15.0, 47.0, 36.0, 72.0, 68.0, 39.0, 17.0, 27.0, 21.0, 45.0, 17.0, 33.0, 47.0, 5.0, 19.0, 77.0, 41.0, 33.0, 22.0, 31.0, 20.0, 51.0, 51.0, 38.0, 36.0, 83.0, 22.0, 36.0, 31.0, 59.0, 17.0, 32.0, 31.0, 10.0, 39.0, 57.0, 49.0, 16.0, 42.0, 22.0, 24.0, 48.0, 66.0, 35.0, 20.0, 19.0, 25.0, 26.0, 15.0, 38.0, 21.0, 24.0, 3.0, 36.0, 21.0, 28.0, 19.0, 35.0, 32.0, 28.0, 29.0, 20.0, 23.0, 17.0, 34.0, 42.0, 49.0, 43.0, 33.0, 37.0, 16.0, 24.0, 32.0, 9.0, 12.0, 17.0, 44.0, 17.0, 40.0, 28.0, 33.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5949409173954875, "mean_inference_ms": 1.839925031076046, "mean_action_processing_ms": 0.25423439848823426, "mean_env_wait_ms": 0.20050375045119176, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004206657409667969, "StateBufferConnector_ms": 0.003648519515991211, "ViewRequirementAgentConnector_ms": 0.10904371738433838}, "num_episodes": 18, "episode_return_max": 77.59999999999927, "episode_return_min": -81.40000000000103, "episode_return_mean": 1.1930000000001013, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1728000, "num_agent_steps_trained": 1728000, "num_env_steps_sampled": 432000, "num_env_steps_trained": 432000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 363.88421191647865, "num_env_steps_trained_throughput_per_sec": 363.88421191647865, "timesteps_total": 432000, "num_env_steps_sampled_lifetime": 432000, "num_agent_steps_sampled_lifetime": 1728000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1728000, "timers": {"training_iteration_time_ms": 11627.286, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11627.235, "sample_time_ms": 1431.684, "learn_time_ms": 10175.712, "learn_throughput": 393.093, "synch_weights_time_ms": 15.432}, "counters": {"num_env_steps_sampled": 432000, "num_env_steps_trained": 432000, "num_agent_steps_sampled": 1728000, "num_agent_steps_trained": 1728000}, "done": false, "training_iteration": 108, "trial_id": "3dae5_00000", "date": "2024-08-14_09-26-44", "timestamp": 1723642004, "time_this_iter_s": 11.06206488609314, "time_total_s": 2822.5345289707184, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3662e50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2822.5345289707184, "iterations_since_restore": 108, "perf": {"cpu_util_percent": 32.20666666666666, "ram_util_percent": 83.43333333333334}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 9.721715152515936, "cur_kl_coeff": 1.3732910156250004e-05, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.5700245425814674, "policy_loss": -0.0029953248859210697, "vf_loss": 3.5730198591474505, "vf_explained_var": 0.23633219694334362, "kl": 0.004457368221276924, "entropy": 0.5576330385195515, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 205065.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 7.281772085535463, "cur_kl_coeff": 0.25312499999999993, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.7826443315183043, "policy_loss": -0.009454332365748034, "vf_loss": 3.788791342387124, "vf_explained_var": 0.2645839981931858, "kl": 0.013066011703417193, "entropy": 1.250060546776605, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 205065.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 436000, "num_env_steps_trained": 436000, "num_agent_steps_sampled": 1744000, "num_agent_steps_trained": 1744000}, "env_runners": {"episode_reward_max": 72.6999999999997, "episode_reward_min": -98.30000000000129, "episode_reward_mean": 3.3250000000001108, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -131.20000000000073, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 46.09999999999997, "predator_policy": 98.0}, "policy_reward_mean": {"prey_policy": -29.717499999999976, "predator_policy": 31.38}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-65.30000000000032, 5.800000000000388, 69.29999999999947, 3.099999999999984, 39.10000000000026, -12.299999999999624, 59.5000000000001, -21.59999999999961, -47.0999999999996, 24.300000000000033, 36.80000000000043, -39.399999999999864, -5.799999999999956, 15.899999999999952, -6.399999999999718, -22.399999999999892, -72.00000000000068, 32.90000000000043, -61.299999999999926, 9.599999999999971, -49.89999999999957, 26.200000000000156, 14.700000000000097, 58.00000000000027, 72.6999999999997, 12.499999999999925, 71.00000000000003, 20.900000000000027, 9.200000000000008, 24.300000000000402, -46.99999999999956, -15.500000000000053, 12.500000000000009, -62.90000000000028, -28.299999999999535, 22.800000000000225, -6.199999999999964, -0.7000000000000489, 22.19999999999995, 38.600000000000485, -40.59999999999958, 42.300000000000324, -21.29999999999981, -36.8999999999996, 17.69999999999995, -5.600000000000107, -35.399999999999544, -20.699999999999527, 26.200000000000117, -81.40000000000103, 1.3999999999999948, 17.799999999999958, -23.29999999999955, 8.399999999999968, -54.19999999999967, 62.90000000000046, -26.199999999999847, 11.799999999999946, -11.800000000000056, -59.799999999999585, -1.9000000000000772, 46.400000000000404, 2.799999999999971, 24.800000000000086, 39.00000000000044, 6.899999999999958, -3.2999999999997662, 16.599999999999962, 2.5000000000001728, 45.300000000000466, 33.800000000000196, 14.499999999999973, 37.400000000000276, 14.499999999999913, -34.59999999999957, 14.299999999999928, 39.600000000000456, 20.700000000000053, 34.000000000000256, -33.69999999999954, -22.09999999999952, 6.500000000000137, 7.500000000000098, 5.8000000000001535, 22.30000000000002, 43.30000000000036, 27.80000000000012, 32.80000000000019, -18.999999999999517, 24.400000000000063, -93.8000000000014, 31.100000000000147, 24.70000000000007, -98.30000000000129, 30.700000000000166, 26.000000000000078, 7.900000000000061, -13.099999999999557, 23.600000000000037, 35.70000000000022], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-89.80000000000013, -41.4999999999998, -38.20000000000001, -36.99999999999998, 32.00000000000023, 23.300000000000203, -10.599999999999982, -121.30000000000044, 20.90000000000002, -29.799999999999848, 8.899999999999967, -92.20000000000076, 42.49999999999999, -15.999999999999746, -48.9999999999998, -37.59999999999981, -56.79999999999978, -109.30000000000072, -20.199999999999996, -11.499999999999961, 19.100000000000215, -40.299999999999855, -100.00000000000023, -33.39999999999993, -61.00000000000036, -20.799999999999862, -22.29999999999975, -32.799999999999855, -57.69999999999978, -15.699999999999921, -58.59999999999991, -32.799999999999876, -105.10000000000065, -52.89999999999986, 3.199999999999975, -34.29999999999978, -113.20000000000044, -129.10000000000073, -19.599999999999753, 0.19999999999996046, -24.09999999999979, -89.80000000000052, 17.599999999999966, -57.39999999999979, -61.899999999999864, -24.399999999999963, 46.09999999999997, -45.09999999999995, 39.200000000000195, 18.499999999999986, -30.699999999999783, -14.799999999999814, 4.100000000000046, 20.900000000000013, -15.099999999999778, 4.999999999999979, -5.199999999999948, -40.59999999999977, -88.0000000000004, 11.300000000000017, -89.20000000000041, -59.799999999999876, -48.099999999999774, -30.399999999999856, -9.400000000000023, -18.099999999999852, -54.99999999999981, -112.9000000000004, -59.79999999999979, -32.49999999999975, -25.299999999999763, -7.900000000000013, -27.69999999999977, -29.499999999999936, -31.899999999999757, -17.800000000000022, -16.29999999999975, 0.49999999999998346, -6.400000000000039, 17.000000000000213, -50.49999999999978, -87.10000000000039, 3.4999999999999925, 21.80000000000001, -45.399999999999785, -58.89999999999986, -74.5000000000006, -102.40000000000036, -55.89999999999977, 17.599999999999966, -14.800000000000047, -38.799999999999756, -51.099999999999774, -46.29999999999977, -59.79999999999977, -40.89999999999976, -21.999999999999893, 24.200000000000053, -110.20000000000078, -89.20000000000044, -36.699999999999754, -16.899999999999984, -45.69999999999977, 12.499999999999963, -50.7999999999998, -74.50000000000026, -51.69999999999978, -13.899999999999817, -27.999999999999822, -131.20000000000073, -36.099999999999774, 32.000000000000234, -73.90000000000019, -28.299999999999997, 1.0999999999999812, -52.29999999999978, -47.19999999999976, -13.600000000000032, -59.79999999999977, -106.00000000000017, -43.89999999999988, -16.000000000000046, -9.10000000000001, 9.49999999999996, -82.89999999999995, -28.30000000000001, 2.299999999999981, -32.49999999999975, 10.700000000000003, -15.699999999999974, -30.999999999999794, -3.100000000000042, -42.399999999999764, -19.899999999999917, 17.899999999999988, -28.29999999999975, -38.799999999999756, -15.699999999999775, 25.70000000000025, -27.399999999999785, 7.399999999999977, -40.59999999999977, -24.6999999999998, -17.80000000000002, -9.99999999999996, 4.399999999999983, -6.100000000000058, -30.39999999999975, -105.10000000000079, -20.499999999999904, -6.100000000000049, -55.59999999999991, -36.99999999999977, 23.600000000000172, -25.899999999999757, -9.400000000000016, 9.799999999999967, 3.1999999999999873, -32.79999999999977, -61.90000000000068, -69.40000000000089, -9.69999999999986, -36.699999999999754, -17.799999999999798, -17.799999999999915, -9.699999999999875, -0.09999999999999937, -39.09999999999976, -20.499999999999766, 6.799999999999967, 33.50000000000024, -26.19999999999976, -15.999999999999767, 15.799999999999962, -15.699999999999772, 9.499999999999964, -31.899999999999757, -33.09999999999976, -28.899999999999757, -6.699999999999932, -68.20000000000064, -118.60000000000073, 1.699999999999964, -40.599999999999774, 16.099999999999998, -33.399999999999764, -51.399999999999814, -124.9000000000006, 17.899999999999977, -23.199999999999847, 5.2999999999999705, -7.299999999999891, -43.59999999999977, -50.49999999999978, -59.800000000000566, -7.299999999999891, -27.999999999999865, 5.599999999999971, 16.39999999999994, 5.299999999999967], "policy_predator_policy_reward": [2.0, 64.0, 38.0, 43.0, 0.0, 14.0, 71.0, 64.0, 24.0, 24.0, 21.0, 50.0, 18.0, 15.0, 26.0, 39.0, 52.0, 67.0, 19.0, 37.0, 15.0, 43.0, 44.0, 50.0, 59.0, 17.0, 27.0, 44.0, 38.0, 29.0, 55.0, 14.0, 23.0, 63.0, 37.0, 27.0, 83.0, 98.0, 8.0, 21.0, 31.0, 33.0, 22.0, 44.0, 46.0, 55.0, 27.0, 30.0, 10.0, 5.0, 38.0, 20.0, 20.0, 26.0, 16.0, 15.0, 33.0, 22.0, 52.0, 49.0, 55.0, 47.0, 49.0, 14.0, 19.0, 21.0, 40.0, 65.0, 20.0, 44.0, 30.0, 26.0, 21.0, 30.0, 19.0, 30.0, 13.0, 25.0, 24.0, 4.0, 43.0, 54.0, 2.0, 15.0, 47.0, 36.0, 72.0, 68.0, 39.0, 17.0, 27.0, 21.0, 45.0, 17.0, 33.0, 47.0, 5.0, 19.0, 77.0, 41.0, 33.0, 22.0, 31.0, 20.0, 51.0, 51.0, 38.0, 36.0, 83.0, 22.0, 36.0, 31.0, 59.0, 17.0, 32.0, 31.0, 10.0, 39.0, 57.0, 49.0, 16.0, 42.0, 22.0, 24.0, 48.0, 66.0, 35.0, 20.0, 19.0, 25.0, 26.0, 15.0, 38.0, 21.0, 24.0, 3.0, 36.0, 21.0, 28.0, 19.0, 35.0, 32.0, 28.0, 29.0, 20.0, 23.0, 17.0, 34.0, 42.0, 49.0, 43.0, 33.0, 37.0, 16.0, 24.0, 32.0, 9.0, 12.0, 17.0, 44.0, 17.0, 40.0, 28.0, 33.0, 16.0, 19.0, 16.0, 29.0, 21.0, 15.0, 14.0, 22.0, 17.0, 11.0, 18.0, 21.0, 12.0, 34.0, 31.0, 29.0, 72.0, 21.0, 31.0, 39.0, 33.0, 9.0, 8.0, 70.0, 22.0, 14.0, 12.0, 16.0, 51.0, 51.0, 36.0, 18.0, 22.0, 24.0, 8.0, 6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5951905804358876, "mean_inference_ms": 1.8406427014240199, "mean_action_processing_ms": 0.2556411361685844, "mean_env_wait_ms": 0.20065811262330727, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0038846731185913086, "StateBufferConnector_ms": 0.00328981876373291, "ViewRequirementAgentConnector_ms": 0.10038816928863525}, "num_episodes": 18, "episode_return_max": 72.6999999999997, "episode_return_min": -98.30000000000129, "episode_return_mean": 3.3250000000001108, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1744000, "num_agent_steps_trained": 1744000, "num_env_steps_sampled": 436000, "num_env_steps_trained": 436000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 345.77853476042515, "num_env_steps_trained_throughput_per_sec": 345.77853476042515, "timesteps_total": 436000, "num_env_steps_sampled_lifetime": 436000, "num_agent_steps_sampled_lifetime": 1744000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1744000, "timers": {"training_iteration_time_ms": 11595.565, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11595.513, "sample_time_ms": 1483.477, "learn_time_ms": 10092.039, "learn_throughput": 396.352, "synch_weights_time_ms": 15.482}, "counters": {"num_env_steps_sampled": 436000, "num_env_steps_trained": 436000, "num_agent_steps_sampled": 1744000, "num_agent_steps_trained": 1744000}, "done": false, "training_iteration": 109, "trial_id": "3dae5_00000", "date": "2024-08-14_09-26-55", "timestamp": 1723642015, "time_this_iter_s": 11.573666095733643, "time_total_s": 2834.108195066452, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3662d30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2834.108195066452, "iterations_since_restore": 109, "perf": {"cpu_util_percent": 31.017647058823528, "ram_util_percent": 83.67058823529412}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 6.620111141318366, "cur_kl_coeff": 6.866455078125002e-06, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.839300302790586, "policy_loss": -0.005594408196131034, "vf_loss": 2.8448947053107005, "vf_explained_var": 0.28074367093661473, "kl": 0.010082578077454883, "entropy": 0.5550119965637802, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 206955.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.383101553134817, "cur_kl_coeff": 0.25312499999999993, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.7622748274021047, "policy_loss": -0.008966598092583279, "vf_loss": 2.769656392253896, "vf_explained_var": 0.11207113694892358, "kl": 0.006261890144952083, "entropy": 1.1416938757139539, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 206955.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 440000, "num_env_steps_trained": 440000, "num_agent_steps_sampled": 1760000, "num_agent_steps_trained": 1760000}, "env_runners": {"episode_reward_max": 72.6999999999997, "episode_reward_min": -159.7000000000015, "episode_reward_mean": 3.746000000000065, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -177.70000000000059, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 46.09999999999997, "predator_policy": 95.0}, "policy_reward_mean": {"prey_policy": -26.48199999999997, "predator_policy": 28.355}, "custom_metrics": {}, "hist_stats": {"episode_reward": [58.00000000000027, 72.6999999999997, 12.499999999999925, 71.00000000000003, 20.900000000000027, 9.200000000000008, 24.300000000000402, -46.99999999999956, -15.500000000000053, 12.500000000000009, -62.90000000000028, -28.299999999999535, 22.800000000000225, -6.199999999999964, -0.7000000000000489, 22.19999999999995, 38.600000000000485, -40.59999999999958, 42.300000000000324, -21.29999999999981, -36.8999999999996, 17.69999999999995, -5.600000000000107, -35.399999999999544, -20.699999999999527, 26.200000000000117, -81.40000000000103, 1.3999999999999948, 17.799999999999958, -23.29999999999955, 8.399999999999968, -54.19999999999967, 62.90000000000046, -26.199999999999847, 11.799999999999946, -11.800000000000056, -59.799999999999585, -1.9000000000000772, 46.400000000000404, 2.799999999999971, 24.800000000000086, 39.00000000000044, 6.899999999999958, -3.2999999999997662, 16.599999999999962, 2.5000000000001728, 45.300000000000466, 33.800000000000196, 14.499999999999973, 37.400000000000276, 14.499999999999913, -34.59999999999957, 14.299999999999928, 39.600000000000456, 20.700000000000053, 34.000000000000256, -33.69999999999954, -22.09999999999952, 6.500000000000137, 7.500000000000098, 5.8000000000001535, 22.30000000000002, 43.30000000000036, 27.80000000000012, 32.80000000000019, -18.999999999999517, 24.400000000000063, -93.8000000000014, 31.100000000000147, 24.70000000000007, -98.30000000000129, 30.700000000000166, 26.000000000000078, 7.900000000000061, -13.099999999999557, 23.600000000000037, 35.70000000000022, 30.10000000000015, 36.70000000000025, -5.199999999999671, 12.199999999999932, 13.299999999999935, 50.100000000000485, 4.400000000000137, 14.699999999999921, 1.6999999999999897, 10.900000000000064, -71.10000000000116, 47.500000000000426, -78.90000000000124, -50.40000000000073, 13.699999999999926, 9.600000000000097, 20.29999999999998, 37.80000000000027, -1.9999999999997935, 4.4000000000001585, 28.400000000000123, 7.30000000000013, -159.7000000000015], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [46.09999999999997, -45.09999999999995, 39.200000000000195, 18.499999999999986, -30.699999999999783, -14.799999999999814, 4.100000000000046, 20.900000000000013, -15.099999999999778, 4.999999999999979, -5.199999999999948, -40.59999999999977, -88.0000000000004, 11.300000000000017, -89.20000000000041, -59.799999999999876, -48.099999999999774, -30.399999999999856, -9.400000000000023, -18.099999999999852, -54.99999999999981, -112.9000000000004, -59.79999999999979, -32.49999999999975, -25.299999999999763, -7.900000000000013, -27.69999999999977, -29.499999999999936, -31.899999999999757, -17.800000000000022, -16.29999999999975, 0.49999999999998346, -6.400000000000039, 17.000000000000213, -50.49999999999978, -87.10000000000039, 3.4999999999999925, 21.80000000000001, -45.399999999999785, -58.89999999999986, -74.5000000000006, -102.40000000000036, -55.89999999999977, 17.599999999999966, -14.800000000000047, -38.799999999999756, -51.099999999999774, -46.29999999999977, -59.79999999999977, -40.89999999999976, -21.999999999999893, 24.200000000000053, -110.20000000000078, -89.20000000000044, -36.699999999999754, -16.899999999999984, -45.69999999999977, 12.499999999999963, -50.7999999999998, -74.50000000000026, -51.69999999999978, -13.899999999999817, -27.999999999999822, -131.20000000000073, -36.099999999999774, 32.000000000000234, -73.90000000000019, -28.299999999999997, 1.0999999999999812, -52.29999999999978, -47.19999999999976, -13.600000000000032, -59.79999999999977, -106.00000000000017, -43.89999999999988, -16.000000000000046, -9.10000000000001, 9.49999999999996, -82.89999999999995, -28.30000000000001, 2.299999999999981, -32.49999999999975, 10.700000000000003, -15.699999999999974, -30.999999999999794, -3.100000000000042, -42.399999999999764, -19.899999999999917, 17.899999999999988, -28.29999999999975, -38.799999999999756, -15.699999999999775, 25.70000000000025, -27.399999999999785, 7.399999999999977, -40.59999999999977, -24.6999999999998, -17.80000000000002, -9.99999999999996, 4.399999999999983, -6.100000000000058, -30.39999999999975, -105.10000000000079, -20.499999999999904, -6.100000000000049, -55.59999999999991, -36.99999999999977, 23.600000000000172, -25.899999999999757, -9.400000000000016, 9.799999999999967, 3.1999999999999873, -32.79999999999977, -61.90000000000068, -69.40000000000089, -9.69999999999986, -36.699999999999754, -17.799999999999798, -17.799999999999915, -9.699999999999875, -0.09999999999999937, -39.09999999999976, -20.499999999999766, 6.799999999999967, 33.50000000000024, -26.19999999999976, -15.999999999999767, 15.799999999999962, -15.699999999999772, 9.499999999999964, -31.899999999999757, -33.09999999999976, -28.899999999999757, -6.699999999999932, -68.20000000000064, -118.60000000000073, 1.699999999999964, -40.599999999999774, 16.099999999999998, -33.399999999999764, -51.399999999999814, -124.9000000000006, 17.899999999999977, -23.199999999999847, 5.2999999999999705, -7.299999999999891, -43.59999999999977, -50.49999999999978, -59.800000000000566, -7.299999999999891, -27.999999999999865, 5.599999999999971, 16.39999999999994, 5.299999999999967, -6.399999999999908, 9.499999999999966, 13.699999999999964, 20.000000000000014, -15.699999999999747, -11.499999999999819, -44.19999999999983, -52.60000000000004, -17.199999999999747, -11.499999999999819, 10.999999999999973, 19.1, -13.599999999999783, -30.999999999999794, -30.099999999999824, -32.19999999999976, -2.500000000000034, -59.79999999999976, -8.799999999999871, -13.299999999999798, -177.70000000000059, 11.599999999999964, 30.800000000000196, -7.299999999999997, -124.90000000000066, -42.99999999999976, -48.09999999999979, -70.30000000000086, -27.99999999999978, 4.699999999999995, -7.299999999999891, -0.10000000000001347, -11.499999999999819, 12.799999999999974, -7.300000000000059, 7.0999999999999766, 1.0999999999999688, -66.1000000000009, -49.29999999999989, 13.699999999999964, -0.6999999999999993, -13.899999999999913, -33.699999999999754, -0.9999999999999881, -122.80000000000075, -124.90000000000074], "policy_predator_policy_reward": [27.0, 30.0, 10.0, 5.0, 38.0, 20.0, 20.0, 26.0, 16.0, 15.0, 33.0, 22.0, 52.0, 49.0, 55.0, 47.0, 49.0, 14.0, 19.0, 21.0, 40.0, 65.0, 20.0, 44.0, 30.0, 26.0, 21.0, 30.0, 19.0, 30.0, 13.0, 25.0, 24.0, 4.0, 43.0, 54.0, 2.0, 15.0, 47.0, 36.0, 72.0, 68.0, 39.0, 17.0, 27.0, 21.0, 45.0, 17.0, 33.0, 47.0, 5.0, 19.0, 77.0, 41.0, 33.0, 22.0, 31.0, 20.0, 51.0, 51.0, 38.0, 36.0, 83.0, 22.0, 36.0, 31.0, 59.0, 17.0, 32.0, 31.0, 10.0, 39.0, 57.0, 49.0, 16.0, 42.0, 22.0, 24.0, 48.0, 66.0, 35.0, 20.0, 19.0, 25.0, 26.0, 15.0, 38.0, 21.0, 24.0, 3.0, 36.0, 21.0, 28.0, 19.0, 35.0, 32.0, 28.0, 29.0, 20.0, 23.0, 17.0, 34.0, 42.0, 49.0, 43.0, 33.0, 37.0, 16.0, 24.0, 32.0, 9.0, 12.0, 17.0, 44.0, 17.0, 40.0, 28.0, 33.0, 16.0, 19.0, 16.0, 29.0, 21.0, 15.0, 14.0, 22.0, 17.0, 11.0, 18.0, 21.0, 12.0, 34.0, 31.0, 29.0, 72.0, 21.0, 31.0, 39.0, 33.0, 9.0, 8.0, 70.0, 22.0, 14.0, 12.0, 16.0, 51.0, 51.0, 36.0, 18.0, 22.0, 24.0, 8.0, 6.0, 15.0, 12.0, 3.0, 0.0, 5.0, 17.0, 54.0, 55.0, 20.0, 22.0, 10.0, 10.0, 21.0, 28.0, 41.0, 36.0, 39.0, 25.0, 18.0, 15.0, 0.0, 95.0, 13.0, 11.0, 16.0, 73.0, 12.0, 56.0, 12.0, 25.0, 12.0, 5.0, 16.0, 3.0, 17.0, 21.0, 49.0, 14.0, 33.0, 7.0, 25.0, 18.0, 17.0, 25.0, 75.0, 13.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5953857006843187, "mean_inference_ms": 1.8412307448221328, "mean_action_processing_ms": 0.2574125592057113, "mean_env_wait_ms": 0.20079806376949072, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004053592681884766, "StateBufferConnector_ms": 0.0034066438674926758, "ViewRequirementAgentConnector_ms": 0.10448861122131348}, "num_episodes": 23, "episode_return_max": 72.6999999999997, "episode_return_min": -159.7000000000015, "episode_return_mean": 3.746000000000065, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1760000, "num_agent_steps_trained": 1760000, "num_env_steps_sampled": 440000, "num_env_steps_trained": 440000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 370.66868436979195, "num_env_steps_trained_throughput_per_sec": 370.66868436979195, "timesteps_total": 440000, "num_env_steps_sampled_lifetime": 440000, "num_agent_steps_sampled_lifetime": 1760000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1760000, "timers": {"training_iteration_time_ms": 11552.189, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11552.138, "sample_time_ms": 1454.904, "learn_time_ms": 10077.261, "learn_throughput": 396.933, "synch_weights_time_ms": 15.522}, "counters": {"num_env_steps_sampled": 440000, "num_env_steps_trained": 440000, "num_agent_steps_sampled": 1760000, "num_agent_steps_trained": 1760000}, "done": false, "training_iteration": 110, "trial_id": "3dae5_00000", "date": "2024-08-14_09-27-06", "timestamp": 1723642026, "time_this_iter_s": 10.825407981872559, "time_total_s": 2844.9336030483246, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b364ef70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2844.9336030483246, "iterations_since_restore": 110, "perf": {"cpu_util_percent": 29.280000000000005, "ram_util_percent": 83.79333333333332}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.279268827955558, "cur_kl_coeff": 6.866455078125002e-06, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.1045033680068124, "policy_loss": -0.0054973658261741835, "vf_loss": 2.110000726028725, "vf_explained_var": 0.31321898200524545, "kl": 0.00667809692923029, "entropy": 0.5684734999345094, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 208845.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.5669160157915147, "cur_kl_coeff": 0.25312499999999993, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.7507624211134734, "policy_loss": -0.007740533096154058, "vf_loss": 2.7560637358004456, "vf_explained_var": 0.07601378897510508, "kl": 0.009636414592244897, "entropy": 1.1209201968536175, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 208845.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 444000, "num_env_steps_trained": 444000, "num_agent_steps_sampled": 1776000, "num_agent_steps_trained": 1776000}, "env_runners": {"episode_reward_max": 62.90000000000046, "episode_reward_min": -159.7000000000015, "episode_reward_mean": 0.9080000000000524, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -187.90000000000057, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 33.50000000000024, "predator_policy": 127.0}, "policy_reward_mean": {"prey_policy": -27.855999999999984, "predator_policy": 28.31}, "custom_metrics": {}, "hist_stats": {"episode_reward": [42.300000000000324, -21.29999999999981, -36.8999999999996, 17.69999999999995, -5.600000000000107, -35.399999999999544, -20.699999999999527, 26.200000000000117, -81.40000000000103, 1.3999999999999948, 17.799999999999958, -23.29999999999955, 8.399999999999968, -54.19999999999967, 62.90000000000046, -26.199999999999847, 11.799999999999946, -11.800000000000056, -59.799999999999585, -1.9000000000000772, 46.400000000000404, 2.799999999999971, 24.800000000000086, 39.00000000000044, 6.899999999999958, -3.2999999999997662, 16.599999999999962, 2.5000000000001728, 45.300000000000466, 33.800000000000196, 14.499999999999973, 37.400000000000276, 14.499999999999913, -34.59999999999957, 14.299999999999928, 39.600000000000456, 20.700000000000053, 34.000000000000256, -33.69999999999954, -22.09999999999952, 6.500000000000137, 7.500000000000098, 5.8000000000001535, 22.30000000000002, 43.30000000000036, 27.80000000000012, 32.80000000000019, -18.999999999999517, 24.400000000000063, -93.8000000000014, 31.100000000000147, 24.70000000000007, -98.30000000000129, 30.700000000000166, 26.000000000000078, 7.900000000000061, -13.099999999999557, 23.600000000000037, 35.70000000000022, 30.10000000000015, 36.70000000000025, -5.199999999999671, 12.199999999999932, 13.299999999999935, 50.100000000000485, 4.400000000000137, 14.699999999999921, 1.6999999999999897, 10.900000000000064, -71.10000000000116, 47.500000000000426, -78.90000000000124, -50.40000000000073, 13.699999999999926, 9.600000000000097, 20.29999999999998, 37.80000000000027, -1.9999999999997935, 4.4000000000001585, 28.400000000000123, 7.30000000000013, -159.7000000000015, 22.400000000000013, 21.60000000000001, 13.199999999999985, -8.599999999999673, 30.000000000000153, -38.09999999999955, -36.89999999999967, 38.80000000000028, 6.100000000000145, -16.59999999999954, 51.90000000000047, -144.00000000000077, -1.8999999999997437, 33.400000000000205, 23.800000000000082, -63.6000000000013, 23.60000000000005, -75.40000000000032], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [3.4999999999999925, 21.80000000000001, -45.399999999999785, -58.89999999999986, -74.5000000000006, -102.40000000000036, -55.89999999999977, 17.599999999999966, -14.800000000000047, -38.799999999999756, -51.099999999999774, -46.29999999999977, -59.79999999999977, -40.89999999999976, -21.999999999999893, 24.200000000000053, -110.20000000000078, -89.20000000000044, -36.699999999999754, -16.899999999999984, -45.69999999999977, 12.499999999999963, -50.7999999999998, -74.50000000000026, -51.69999999999978, -13.899999999999817, -27.999999999999822, -131.20000000000073, -36.099999999999774, 32.000000000000234, -73.90000000000019, -28.299999999999997, 1.0999999999999812, -52.29999999999978, -47.19999999999976, -13.600000000000032, -59.79999999999977, -106.00000000000017, -43.89999999999988, -16.000000000000046, -9.10000000000001, 9.49999999999996, -82.89999999999995, -28.30000000000001, 2.299999999999981, -32.49999999999975, 10.700000000000003, -15.699999999999974, -30.999999999999794, -3.100000000000042, -42.399999999999764, -19.899999999999917, 17.899999999999988, -28.29999999999975, -38.799999999999756, -15.699999999999775, 25.70000000000025, -27.399999999999785, 7.399999999999977, -40.59999999999977, -24.6999999999998, -17.80000000000002, -9.99999999999996, 4.399999999999983, -6.100000000000058, -30.39999999999975, -105.10000000000079, -20.499999999999904, -6.100000000000049, -55.59999999999991, -36.99999999999977, 23.600000000000172, -25.899999999999757, -9.400000000000016, 9.799999999999967, 3.1999999999999873, -32.79999999999977, -61.90000000000068, -69.40000000000089, -9.69999999999986, -36.699999999999754, -17.799999999999798, -17.799999999999915, -9.699999999999875, -0.09999999999999937, -39.09999999999976, -20.499999999999766, 6.799999999999967, 33.50000000000024, -26.19999999999976, -15.999999999999767, 15.799999999999962, -15.699999999999772, 9.499999999999964, -31.899999999999757, -33.09999999999976, -28.899999999999757, -6.699999999999932, -68.20000000000064, -118.60000000000073, 1.699999999999964, -40.599999999999774, 16.099999999999998, -33.399999999999764, -51.399999999999814, -124.9000000000006, 17.899999999999977, -23.199999999999847, 5.2999999999999705, -7.299999999999891, -43.59999999999977, -50.49999999999978, -59.800000000000566, -7.299999999999891, -27.999999999999865, 5.599999999999971, 16.39999999999994, 5.299999999999967, -6.399999999999908, 9.499999999999966, 13.699999999999964, 20.000000000000014, -15.699999999999747, -11.499999999999819, -44.19999999999983, -52.60000000000004, -17.199999999999747, -11.499999999999819, 10.999999999999973, 19.1, -13.599999999999783, -30.999999999999794, -30.099999999999824, -32.19999999999976, -2.500000000000034, -59.79999999999976, -8.799999999999871, -13.299999999999798, -177.70000000000059, 11.599999999999964, 30.800000000000196, -7.299999999999997, -124.90000000000066, -42.99999999999976, -48.09999999999979, -70.30000000000086, -27.99999999999978, 4.699999999999995, -7.299999999999891, -0.10000000000001347, -11.499999999999819, 12.799999999999974, -7.300000000000059, 7.0999999999999766, 1.0999999999999688, -66.1000000000009, -49.29999999999989, 13.699999999999964, -0.6999999999999993, -13.899999999999913, -33.699999999999754, -0.9999999999999881, -122.80000000000075, -124.90000000000074, -9.399999999999855, 15.799999999999963, 11.89999999999997, -34.29999999999976, 8.299999999999976, -45.09999999999976, -27.69999999999984, -40.89999999999976, -28.29999999999979, -15.699999999999747, 9.499999999999964, -118.6000000000007, -14.199999999999823, -99.70000000000081, 19.1, 13.699999999999964, -42.399999999999764, 9.499999999999964, -41.499999999999766, -42.099999999999774, 3.1999999999999704, -19.29999999999975, -187.90000000000057, -87.1000000000001, 3.2000000000000033, -45.09999999999976, 17.899999999999988, 9.499999999999964, 5.299999999999974, -11.49999999999984, -111.40000000000066, -44.19999999999979, -47.19999999999976, -23.19999999999984, -74.50000000000017, -82.90000000000026], "policy_predator_policy_reward": [2.0, 15.0, 47.0, 36.0, 72.0, 68.0, 39.0, 17.0, 27.0, 21.0, 45.0, 17.0, 33.0, 47.0, 5.0, 19.0, 77.0, 41.0, 33.0, 22.0, 31.0, 20.0, 51.0, 51.0, 38.0, 36.0, 83.0, 22.0, 36.0, 31.0, 59.0, 17.0, 32.0, 31.0, 10.0, 39.0, 57.0, 49.0, 16.0, 42.0, 22.0, 24.0, 48.0, 66.0, 35.0, 20.0, 19.0, 25.0, 26.0, 15.0, 38.0, 21.0, 24.0, 3.0, 36.0, 21.0, 28.0, 19.0, 35.0, 32.0, 28.0, 29.0, 20.0, 23.0, 17.0, 34.0, 42.0, 49.0, 43.0, 33.0, 37.0, 16.0, 24.0, 32.0, 9.0, 12.0, 17.0, 44.0, 17.0, 40.0, 28.0, 33.0, 16.0, 19.0, 16.0, 29.0, 21.0, 15.0, 14.0, 22.0, 17.0, 11.0, 18.0, 21.0, 12.0, 34.0, 31.0, 29.0, 72.0, 21.0, 31.0, 39.0, 33.0, 9.0, 8.0, 70.0, 22.0, 14.0, 12.0, 16.0, 51.0, 51.0, 36.0, 18.0, 22.0, 24.0, 8.0, 6.0, 15.0, 12.0, 3.0, 0.0, 5.0, 17.0, 54.0, 55.0, 20.0, 22.0, 10.0, 10.0, 21.0, 28.0, 41.0, 36.0, 39.0, 25.0, 18.0, 15.0, 0.0, 95.0, 13.0, 11.0, 16.0, 73.0, 12.0, 56.0, 12.0, 25.0, 12.0, 5.0, 16.0, 3.0, 17.0, 21.0, 49.0, 14.0, 33.0, 7.0, 25.0, 18.0, 17.0, 25.0, 75.0, 13.0, 14.0, 2.0, 16.0, 28.0, 35.0, 15.0, 21.0, 39.0, 41.0, 33.0, 5.0, 66.0, 18.0, 59.0, 3.0, 3.0, 13.0, 26.0, 33.0, 34.0, 34.0, 34.0, 4.0, 127.0, 4.0, 36.0, 5.0, 1.0, 13.0, 17.0, 23.0, 69.0, 47.0, 47.0, 0.0, 82.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5951613918342892, "mean_inference_ms": 1.840616751790488, "mean_action_processing_ms": 0.25862389237926875, "mean_env_wait_ms": 0.20074790046519034, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00393986701965332, "StateBufferConnector_ms": 0.003369569778442383, "ViewRequirementAgentConnector_ms": 0.09794032573699951}, "num_episodes": 18, "episode_return_max": 62.90000000000046, "episode_return_min": -159.7000000000015, "episode_return_mean": 0.9080000000000524, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1776000, "num_agent_steps_trained": 1776000, "num_env_steps_sampled": 444000, "num_env_steps_trained": 444000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 362.66142894934336, "num_env_steps_trained_throughput_per_sec": 362.66142894934336, "timesteps_total": 444000, "num_env_steps_sampled_lifetime": 444000, "num_agent_steps_sampled_lifetime": 1776000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1776000, "timers": {"training_iteration_time_ms": 11566.916, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11566.864, "sample_time_ms": 1449.744, "learn_time_ms": 10096.89, "learn_throughput": 396.162, "synch_weights_time_ms": 15.725}, "counters": {"num_env_steps_sampled": 444000, "num_env_steps_trained": 444000, "num_agent_steps_sampled": 1776000, "num_agent_steps_trained": 1776000}, "done": false, "training_iteration": 111, "trial_id": "3dae5_00000", "date": "2024-08-14_09-27-17", "timestamp": 1723642037, "time_this_iter_s": 11.034862995147705, "time_total_s": 2855.9684660434723, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b364ed30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2855.9684660434723, "iterations_since_restore": 111, "perf": {"cpu_util_percent": 28.5625, "ram_util_percent": 83.80625}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.584353305675365, "cur_kl_coeff": 6.866455078125002e-06, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.9788233240445454, "policy_loss": -0.004014077098429124, "vf_loss": 1.9828373973331754, "vf_explained_var": 0.35345613164876505, "kl": 0.006184934062075446, "entropy": 0.6856573913147841, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 210735.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.6620771670783006, "cur_kl_coeff": 0.25312499999999993, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.2727959260423347, "policy_loss": -0.0049187647059274016, "vf_loss": 2.276947343097162, "vf_explained_var": 0.20559865791330892, "kl": 0.0030314738835531315, "entropy": 1.0882669412269794, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 210735.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 448000, "num_env_steps_trained": 448000, "num_agent_steps_sampled": 1792000, "num_agent_steps_trained": 1792000}, "env_runners": {"episode_reward_max": 62.900000000000524, "episode_reward_min": -159.7000000000015, "episode_reward_mean": 5.067000000000076, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -187.90000000000057, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 33.50000000000024, "predator_policy": 127.0}, "policy_reward_mean": {"prey_policy": -22.25649999999998, "predator_policy": 24.79}, "custom_metrics": {}, "hist_stats": {"episode_reward": [24.800000000000086, 39.00000000000044, 6.899999999999958, -3.2999999999997662, 16.599999999999962, 2.5000000000001728, 45.300000000000466, 33.800000000000196, 14.499999999999973, 37.400000000000276, 14.499999999999913, -34.59999999999957, 14.299999999999928, 39.600000000000456, 20.700000000000053, 34.000000000000256, -33.69999999999954, -22.09999999999952, 6.500000000000137, 7.500000000000098, 5.8000000000001535, 22.30000000000002, 43.30000000000036, 27.80000000000012, 32.80000000000019, -18.999999999999517, 24.400000000000063, -93.8000000000014, 31.100000000000147, 24.70000000000007, -98.30000000000129, 30.700000000000166, 26.000000000000078, 7.900000000000061, -13.099999999999557, 23.600000000000037, 35.70000000000022, 30.10000000000015, 36.70000000000025, -5.199999999999671, 12.199999999999932, 13.299999999999935, 50.100000000000485, 4.400000000000137, 14.699999999999921, 1.6999999999999897, 10.900000000000064, -71.10000000000116, 47.500000000000426, -78.90000000000124, -50.40000000000073, 13.699999999999926, 9.600000000000097, 20.29999999999998, 37.80000000000027, -1.9999999999997935, 4.4000000000001585, 28.400000000000123, 7.30000000000013, -159.7000000000015, 22.400000000000013, 21.60000000000001, 13.199999999999985, -8.599999999999673, 30.000000000000153, -38.09999999999955, -36.89999999999967, 38.80000000000028, 6.100000000000145, -16.59999999999954, 51.90000000000047, -144.00000000000077, -1.8999999999997437, 33.400000000000205, 23.800000000000082, -63.6000000000013, 23.60000000000005, -75.40000000000032, 4.8000000000001855, -31.59999999999951, 28.100000000000115, 62.900000000000524, 25.10000000000007, -4.699999999999687, -37.79999999999994, -11.69999999999962, -1.8999999999997437, 21.600000000000005, -22.499999999999567, 38.60000000000028, 42.40000000000033, 20.499999999999993, 11.20000000000006, -23.49999999999958, 38.60000000000028, 40.90000000000031, 23.500000000000036, 31.100000000000165, 19.999999999999982, -0.49999999999979283], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [2.299999999999981, -32.49999999999975, 10.700000000000003, -15.699999999999974, -30.999999999999794, -3.100000000000042, -42.399999999999764, -19.899999999999917, 17.899999999999988, -28.29999999999975, -38.799999999999756, -15.699999999999775, 25.70000000000025, -27.399999999999785, 7.399999999999977, -40.59999999999977, -24.6999999999998, -17.80000000000002, -9.99999999999996, 4.399999999999983, -6.100000000000058, -30.39999999999975, -105.10000000000079, -20.499999999999904, -6.100000000000049, -55.59999999999991, -36.99999999999977, 23.600000000000172, -25.899999999999757, -9.400000000000016, 9.799999999999967, 3.1999999999999873, -32.79999999999977, -61.90000000000068, -69.40000000000089, -9.69999999999986, -36.699999999999754, -17.799999999999798, -17.799999999999915, -9.699999999999875, -0.09999999999999937, -39.09999999999976, -20.499999999999766, 6.799999999999967, 33.50000000000024, -26.19999999999976, -15.999999999999767, 15.799999999999962, -15.699999999999772, 9.499999999999964, -31.899999999999757, -33.09999999999976, -28.899999999999757, -6.699999999999932, -68.20000000000064, -118.60000000000073, 1.699999999999964, -40.599999999999774, 16.099999999999998, -33.399999999999764, -51.399999999999814, -124.9000000000006, 17.899999999999977, -23.199999999999847, 5.2999999999999705, -7.299999999999891, -43.59999999999977, -50.49999999999978, -59.800000000000566, -7.299999999999891, -27.999999999999865, 5.599999999999971, 16.39999999999994, 5.299999999999967, -6.399999999999908, 9.499999999999966, 13.699999999999964, 20.000000000000014, -15.699999999999747, -11.499999999999819, -44.19999999999983, -52.60000000000004, -17.199999999999747, -11.499999999999819, 10.999999999999973, 19.1, -13.599999999999783, -30.999999999999794, -30.099999999999824, -32.19999999999976, -2.500000000000034, -59.79999999999976, -8.799999999999871, -13.299999999999798, -177.70000000000059, 11.599999999999964, 30.800000000000196, -7.299999999999997, -124.90000000000066, -42.99999999999976, -48.09999999999979, -70.30000000000086, -27.99999999999978, 4.699999999999995, -7.299999999999891, -0.10000000000001347, -11.499999999999819, 12.799999999999974, -7.300000000000059, 7.0999999999999766, 1.0999999999999688, -66.1000000000009, -49.29999999999989, 13.699999999999964, -0.6999999999999993, -13.899999999999913, -33.699999999999754, -0.9999999999999881, -122.80000000000075, -124.90000000000074, -9.399999999999855, 15.799999999999963, 11.89999999999997, -34.29999999999976, 8.299999999999976, -45.09999999999976, -27.69999999999984, -40.89999999999976, -28.29999999999979, -15.699999999999747, 9.499999999999964, -118.6000000000007, -14.199999999999823, -99.70000000000081, 19.1, 13.699999999999964, -42.399999999999764, 9.499999999999964, -41.499999999999766, -42.099999999999774, 3.1999999999999704, -19.29999999999975, -187.90000000000057, -87.1000000000001, 3.2000000000000033, -45.09999999999976, 17.899999999999988, 9.499999999999964, 5.299999999999974, -11.49999999999984, -111.40000000000066, -44.19999999999979, -47.19999999999976, -23.19999999999984, -74.50000000000017, -82.90000000000026, -15.699999999999747, -11.499999999999819, -55.599999999999994, -21.999999999999744, 13.699999999999966, 1.3999999999999726, 33.50000000000024, 19.40000000000001, -40.89999999999976, 20.000000000000014, -15.699999999999747, -21.999999999999744, -45.399999999999764, -51.39999999999999, -11.499999999999854, -110.20000000000076, -61.900000000000766, -0.9999999999999846, -43.29999999999976, 17.899999999999984, -68.2000000000009, -19.29999999999982, 20.000000000000014, -12.399999999999816, 22.700000000000053, 13.699999999999964, 9.499999999999964, -21.999999999999773, -32.49999999999976, -4.299999999999944, -59.800000000000594, -30.699999999999804, 11.599999999999964, 20.000000000000014, -0.40000000000002056, 5.299999999999965, 20.000000000000014, -26.49999999999975, 1.0999999999999865, 20.000000000000014, 5.899999999999967, -16.899999999999743, -30.699999999999775, -38.799999999999756], "policy_predator_policy_reward": [35.0, 20.0, 19.0, 25.0, 26.0, 15.0, 38.0, 21.0, 24.0, 3.0, 36.0, 21.0, 28.0, 19.0, 35.0, 32.0, 28.0, 29.0, 20.0, 23.0, 17.0, 34.0, 42.0, 49.0, 43.0, 33.0, 37.0, 16.0, 24.0, 32.0, 9.0, 12.0, 17.0, 44.0, 17.0, 40.0, 28.0, 33.0, 16.0, 19.0, 16.0, 29.0, 21.0, 15.0, 14.0, 22.0, 17.0, 11.0, 18.0, 21.0, 12.0, 34.0, 31.0, 29.0, 72.0, 21.0, 31.0, 39.0, 33.0, 9.0, 8.0, 70.0, 22.0, 14.0, 12.0, 16.0, 51.0, 51.0, 36.0, 18.0, 22.0, 24.0, 8.0, 6.0, 15.0, 12.0, 3.0, 0.0, 5.0, 17.0, 54.0, 55.0, 20.0, 22.0, 10.0, 10.0, 21.0, 28.0, 41.0, 36.0, 39.0, 25.0, 18.0, 15.0, 0.0, 95.0, 13.0, 11.0, 16.0, 73.0, 12.0, 56.0, 12.0, 25.0, 12.0, 5.0, 16.0, 3.0, 17.0, 21.0, 49.0, 14.0, 33.0, 7.0, 25.0, 18.0, 17.0, 25.0, 75.0, 13.0, 14.0, 2.0, 16.0, 28.0, 35.0, 15.0, 21.0, 39.0, 41.0, 33.0, 5.0, 66.0, 18.0, 59.0, 3.0, 3.0, 13.0, 26.0, 33.0, 34.0, 34.0, 34.0, 4.0, 127.0, 4.0, 36.0, 5.0, 1.0, 13.0, 17.0, 23.0, 69.0, 47.0, 47.0, 0.0, 82.0, 17.0, 15.0, 38.0, 8.0, 0.0, 13.0, 5.0, 5.0, 23.0, 23.0, 22.0, 11.0, 42.0, 17.0, 54.0, 56.0, 39.0, 22.0, 19.0, 28.0, 19.0, 46.0, 14.0, 17.0, 3.0, 3.0, 20.0, 13.0, 28.0, 20.0, 61.0, 6.0, 3.0, 4.0, 19.0, 17.0, 9.0, 21.0, 9.0, 1.0, 13.0, 18.0, 27.0, 42.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5948151051513382, "mean_inference_ms": 1.8396003578133064, "mean_action_processing_ms": 0.26004693507016396, "mean_env_wait_ms": 0.20065202003908753, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003994584083557129, "StateBufferConnector_ms": 0.0034521818161010742, "ViewRequirementAgentConnector_ms": 0.10030496120452881}, "num_episodes": 22, "episode_return_max": 62.900000000000524, "episode_return_min": -159.7000000000015, "episode_return_mean": 5.067000000000076, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1792000, "num_agent_steps_trained": 1792000, "num_env_steps_sampled": 448000, "num_env_steps_trained": 448000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 371.47382562520863, "num_env_steps_trained_throughput_per_sec": 371.47382562520863, "timesteps_total": 448000, "num_env_steps_sampled_lifetime": 448000, "num_agent_steps_sampled_lifetime": 1792000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1792000, "timers": {"training_iteration_time_ms": 11521.575, "restore_workers_time_ms": 0.015, "training_step_time_ms": 11521.524, "sample_time_ms": 1454.283, "learn_time_ms": 10048.241, "learn_throughput": 398.08, "synch_weights_time_ms": 14.996}, "counters": {"num_env_steps_sampled": 448000, "num_env_steps_trained": 448000, "num_agent_steps_sampled": 1792000, "num_agent_steps_trained": 1792000}, "done": false, "training_iteration": 112, "trial_id": "3dae5_00000", "date": "2024-08-14_09-27-28", "timestamp": 1723642048, "time_this_iter_s": 10.780985116958618, "time_total_s": 2866.749451160431, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b36e0670>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2866.749451160431, "iterations_since_restore": 112, "perf": {"cpu_util_percent": 28.83333333333333, "ram_util_percent": 83.43333333333334}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.748702449867965, "cur_kl_coeff": 6.866455078125002e-06, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.7236506411953578, "policy_loss": -0.005401615474974274, "vf_loss": 1.7290522440716072, "vf_explained_var": 0.37861786415337256, "kl": 0.006820726411713732, "entropy": 0.6608939667227407, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 212625.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.275429873680942, "cur_kl_coeff": 0.12656249999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.6888116981932726, "policy_loss": -0.009301922167528164, "vf_loss": 1.697083316593574, "vf_explained_var": 0.20981580359595162, "kl": 0.008140674835634333, "entropy": 1.0824438326573245, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 212625.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 452000, "num_env_steps_trained": 452000, "num_agent_steps_sampled": 1808000, "num_agent_steps_trained": 1808000}, "env_runners": {"episode_reward_max": 62.900000000000524, "episode_reward_min": -159.7000000000015, "episode_reward_mean": 4.061000000000045, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -187.90000000000057, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 33.50000000000024, "predator_policy": 127.0}, "policy_reward_mean": {"prey_policy": -21.719499999999986, "predator_policy": 23.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [6.500000000000137, 7.500000000000098, 5.8000000000001535, 22.30000000000002, 43.30000000000036, 27.80000000000012, 32.80000000000019, -18.999999999999517, 24.400000000000063, -93.8000000000014, 31.100000000000147, 24.70000000000007, -98.30000000000129, 30.700000000000166, 26.000000000000078, 7.900000000000061, -13.099999999999557, 23.600000000000037, 35.70000000000022, 30.10000000000015, 36.70000000000025, -5.199999999999671, 12.199999999999932, 13.299999999999935, 50.100000000000485, 4.400000000000137, 14.699999999999921, 1.6999999999999897, 10.900000000000064, -71.10000000000116, 47.500000000000426, -78.90000000000124, -50.40000000000073, 13.699999999999926, 9.600000000000097, 20.29999999999998, 37.80000000000027, -1.9999999999997935, 4.4000000000001585, 28.400000000000123, 7.30000000000013, -159.7000000000015, 22.400000000000013, 21.60000000000001, 13.199999999999985, -8.599999999999673, 30.000000000000153, -38.09999999999955, -36.89999999999967, 38.80000000000028, 6.100000000000145, -16.59999999999954, 51.90000000000047, -144.00000000000077, -1.8999999999997437, 33.400000000000205, 23.800000000000082, -63.6000000000013, 23.60000000000005, -75.40000000000032, 4.8000000000001855, -31.59999999999951, 28.100000000000115, 62.900000000000524, 25.10000000000007, -4.699999999999687, -37.79999999999994, -11.69999999999962, -1.8999999999997437, 21.600000000000005, -22.499999999999567, 38.60000000000028, 42.40000000000033, 20.499999999999993, 11.20000000000006, -23.49999999999958, 38.60000000000028, 40.90000000000031, 23.500000000000036, 31.100000000000165, 19.999999999999982, -0.49999999999979283, 20.200000000000006, 9.200000000000088, -3.0999999999997447, 30.100000000000154, 12.599999999999987, 26.80000000000009, 30.400000000000155, 9.200000000000113, -73.60000000000164, 30.60000000000016, -1.3999999999998356, 1.800000000000215, 42.20000000000034, 0.19999999999995813, 15.499999999999918, 27.100000000000115, -28.19999999999952, 2.0003443346183758e-13], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-36.699999999999754, -17.799999999999798, -17.799999999999915, -9.699999999999875, -0.09999999999999937, -39.09999999999976, -20.499999999999766, 6.799999999999967, 33.50000000000024, -26.19999999999976, -15.999999999999767, 15.799999999999962, -15.699999999999772, 9.499999999999964, -31.899999999999757, -33.09999999999976, -28.899999999999757, -6.699999999999932, -68.20000000000064, -118.60000000000073, 1.699999999999964, -40.599999999999774, 16.099999999999998, -33.399999999999764, -51.399999999999814, -124.9000000000006, 17.899999999999977, -23.199999999999847, 5.2999999999999705, -7.299999999999891, -43.59999999999977, -50.49999999999978, -59.800000000000566, -7.299999999999891, -27.999999999999865, 5.599999999999971, 16.39999999999994, 5.299999999999967, -6.399999999999908, 9.499999999999966, 13.699999999999964, 20.000000000000014, -15.699999999999747, -11.499999999999819, -44.19999999999983, -52.60000000000004, -17.199999999999747, -11.499999999999819, 10.999999999999973, 19.1, -13.599999999999783, -30.999999999999794, -30.099999999999824, -32.19999999999976, -2.500000000000034, -59.79999999999976, -8.799999999999871, -13.299999999999798, -177.70000000000059, 11.599999999999964, 30.800000000000196, -7.299999999999997, -124.90000000000066, -42.99999999999976, -48.09999999999979, -70.30000000000086, -27.99999999999978, 4.699999999999995, -7.299999999999891, -0.10000000000001347, -11.499999999999819, 12.799999999999974, -7.300000000000059, 7.0999999999999766, 1.0999999999999688, -66.1000000000009, -49.29999999999989, 13.699999999999964, -0.6999999999999993, -13.899999999999913, -33.699999999999754, -0.9999999999999881, -122.80000000000075, -124.90000000000074, -9.399999999999855, 15.799999999999963, 11.89999999999997, -34.29999999999976, 8.299999999999976, -45.09999999999976, -27.69999999999984, -40.89999999999976, -28.29999999999979, -15.699999999999747, 9.499999999999964, -118.6000000000007, -14.199999999999823, -99.70000000000081, 19.1, 13.699999999999964, -42.399999999999764, 9.499999999999964, -41.499999999999766, -42.099999999999774, 3.1999999999999704, -19.29999999999975, -187.90000000000057, -87.1000000000001, 3.2000000000000033, -45.09999999999976, 17.899999999999988, 9.499999999999964, 5.299999999999974, -11.49999999999984, -111.40000000000066, -44.19999999999979, -47.19999999999976, -23.19999999999984, -74.50000000000017, -82.90000000000026, -15.699999999999747, -11.499999999999819, -55.599999999999994, -21.999999999999744, 13.699999999999966, 1.3999999999999726, 33.50000000000024, 19.40000000000001, -40.89999999999976, 20.000000000000014, -15.699999999999747, -21.999999999999744, -45.399999999999764, -51.39999999999999, -11.499999999999854, -110.20000000000076, -61.900000000000766, -0.9999999999999846, -43.29999999999976, 17.899999999999984, -68.2000000000009, -19.29999999999982, 20.000000000000014, -12.399999999999816, 22.700000000000053, 13.699999999999964, 9.499999999999964, -21.999999999999773, -32.49999999999976, -4.299999999999944, -59.800000000000594, -30.699999999999804, 11.599999999999964, 20.000000000000014, -0.40000000000002056, 5.299999999999965, 20.000000000000014, -26.49999999999975, 1.0999999999999865, 20.000000000000014, 5.899999999999967, -16.899999999999743, -30.699999999999775, -38.799999999999756, 3.1999999999999615, -0.9999999999999846, -36.699999999999754, 17.899999999999988, -50.79999999999998, -16.29999999999975, 20.000000000000014, -19.899999999999743, -26.499999999999773, 1.0999999999999723, 17.899999999999984, -3.099999999999958, 9.199999999999966, -8.799999999999871, -7.299999999999891, -11.499999999999819, -60.700000000000166, -88.9000000000008, 0.19999999999997944, 7.399999999999965, -30.39999999999975, -30.999999999999787, -43.29999999999976, 1.0999999999999865, 6.199999999999969, 23.000000000000057, -48.9999999999998, 3.1999999999999864, -74.50000000000085, 20.000000000000014, -52.900000000000055, 20.000000000000014, -27.99999999999976, -47.19999999999976, -30.99999999999976, -36.99999999999977], "policy_predator_policy_reward": [28.0, 33.0, 16.0, 19.0, 16.0, 29.0, 21.0, 15.0, 14.0, 22.0, 17.0, 11.0, 18.0, 21.0, 12.0, 34.0, 31.0, 29.0, 72.0, 21.0, 31.0, 39.0, 33.0, 9.0, 8.0, 70.0, 22.0, 14.0, 12.0, 16.0, 51.0, 51.0, 36.0, 18.0, 22.0, 24.0, 8.0, 6.0, 15.0, 12.0, 3.0, 0.0, 5.0, 17.0, 54.0, 55.0, 20.0, 22.0, 10.0, 10.0, 21.0, 28.0, 41.0, 36.0, 39.0, 25.0, 18.0, 15.0, 0.0, 95.0, 13.0, 11.0, 16.0, 73.0, 12.0, 56.0, 12.0, 25.0, 12.0, 5.0, 16.0, 3.0, 17.0, 21.0, 49.0, 14.0, 33.0, 7.0, 25.0, 18.0, 17.0, 25.0, 75.0, 13.0, 14.0, 2.0, 16.0, 28.0, 35.0, 15.0, 21.0, 39.0, 41.0, 33.0, 5.0, 66.0, 18.0, 59.0, 3.0, 3.0, 13.0, 26.0, 33.0, 34.0, 34.0, 34.0, 4.0, 127.0, 4.0, 36.0, 5.0, 1.0, 13.0, 17.0, 23.0, 69.0, 47.0, 47.0, 0.0, 82.0, 17.0, 15.0, 38.0, 8.0, 0.0, 13.0, 5.0, 5.0, 23.0, 23.0, 22.0, 11.0, 42.0, 17.0, 54.0, 56.0, 39.0, 22.0, 19.0, 28.0, 19.0, 46.0, 14.0, 17.0, 3.0, 3.0, 20.0, 13.0, 28.0, 20.0, 61.0, 6.0, 3.0, 4.0, 19.0, 17.0, 9.0, 21.0, 9.0, 1.0, 13.0, 18.0, 27.0, 42.0, 8.0, 10.0, 1.0, 27.0, 29.0, 35.0, 19.0, 11.0, 13.0, 25.0, 11.0, 1.0, 14.0, 16.0, 13.0, 15.0, 16.0, 60.0, 7.0, 16.0, 17.0, 43.0, 15.0, 29.0, 3.0, 10.0, 17.0, 29.0, 39.0, 31.0, 39.0, 21.0, 1.0, 46.0, 42.0, 26.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5945842572526349, "mean_inference_ms": 1.8389969373033934, "mean_action_processing_ms": 0.2612463144760724, "mean_env_wait_ms": 0.20057019744944107, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0041397809982299805, "StateBufferConnector_ms": 0.0036334991455078125, "ViewRequirementAgentConnector_ms": 0.10205233097076416}, "num_episodes": 18, "episode_return_max": 62.900000000000524, "episode_return_min": -159.7000000000015, "episode_return_mean": 4.061000000000045, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1808000, "num_agent_steps_trained": 1808000, "num_env_steps_sampled": 452000, "num_env_steps_trained": 452000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 353.2297940031714, "num_env_steps_trained_throughput_per_sec": 353.2297940031714, "timesteps_total": 452000, "num_env_steps_sampled_lifetime": 452000, "num_agent_steps_sampled_lifetime": 1808000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1808000, "timers": {"training_iteration_time_ms": 11420.826, "restore_workers_time_ms": 0.015, "training_step_time_ms": 11420.775, "sample_time_ms": 1454.057, "learn_time_ms": 9947.381, "learn_throughput": 402.116, "synch_weights_time_ms": 15.44}, "counters": {"num_env_steps_sampled": 452000, "num_env_steps_trained": 452000, "num_agent_steps_sampled": 1808000, "num_agent_steps_trained": 1808000}, "done": false, "training_iteration": 113, "trial_id": "3dae5_00000", "date": "2024-08-14_09-27-39", "timestamp": 1723642059, "time_this_iter_s": 11.363007068634033, "time_total_s": 2878.112458229065, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3831160>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2878.112458229065, "iterations_since_restore": 113, "perf": {"cpu_util_percent": 33.476470588235294, "ram_util_percent": 83.68235294117648}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.0577848544511848, "cur_kl_coeff": 6.866455078125002e-06, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.2607280309868867, "policy_loss": -0.005861297624786852, "vf_loss": 2.2665893132093724, "vf_explained_var": 0.3807459180317228, "kl": 0.00974775085913823, "entropy": 0.6677606920401256, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 214515.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.474720341692526, "cur_kl_coeff": 0.12656249999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.7174786418834063, "policy_loss": -0.00858459392409752, "vf_loss": 2.7249179780798616, "vf_explained_var": 0.20992890284174964, "kl": 0.00904898889907258, "entropy": 1.1125671458622766, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 214515.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 456000, "num_env_steps_trained": 456000, "num_agent_steps_sampled": 1824000, "num_agent_steps_trained": 1824000}, "env_runners": {"episode_reward_max": 62.900000000000524, "episode_reward_min": -159.7000000000015, "episode_reward_mean": 2.4100000000000814, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -187.90000000000057, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 33.50000000000024, "predator_policy": 127.0}, "policy_reward_mean": {"prey_policy": -23.019999999999992, "predator_policy": 24.225}, "custom_metrics": {}, "hist_stats": {"episode_reward": [13.299999999999935, 50.100000000000485, 4.400000000000137, 14.699999999999921, 1.6999999999999897, 10.900000000000064, -71.10000000000116, 47.500000000000426, -78.90000000000124, -50.40000000000073, 13.699999999999926, 9.600000000000097, 20.29999999999998, 37.80000000000027, -1.9999999999997935, 4.4000000000001585, 28.400000000000123, 7.30000000000013, -159.7000000000015, 22.400000000000013, 21.60000000000001, 13.199999999999985, -8.599999999999673, 30.000000000000153, -38.09999999999955, -36.89999999999967, 38.80000000000028, 6.100000000000145, -16.59999999999954, 51.90000000000047, -144.00000000000077, -1.8999999999997437, 33.400000000000205, 23.800000000000082, -63.6000000000013, 23.60000000000005, -75.40000000000032, 4.8000000000001855, -31.59999999999951, 28.100000000000115, 62.900000000000524, 25.10000000000007, -4.699999999999687, -37.79999999999994, -11.69999999999962, -1.8999999999997437, 21.600000000000005, -22.499999999999567, 38.60000000000028, 42.40000000000033, 20.499999999999993, 11.20000000000006, -23.49999999999958, 38.60000000000028, 40.90000000000031, 23.500000000000036, 31.100000000000165, 19.999999999999982, -0.49999999999979283, 20.200000000000006, 9.200000000000088, -3.0999999999997447, 30.100000000000154, 12.599999999999987, 26.80000000000009, 30.400000000000155, 9.200000000000113, -73.60000000000164, 30.60000000000016, -1.3999999999998356, 1.800000000000215, 42.20000000000034, 0.19999999999995813, 15.499999999999918, 27.100000000000115, -28.19999999999952, 2.0003443346183758e-13, 36.300000000000246, -5.199999999999699, 12.599999999999966, 27.900000000000105, 9.59999999999999, 43.600000000000364, 32.20000000000018, -20.999999999999545, -15.099999999999522, -35.79999999999953, -31.499999999999652, 4.799999999999926, 23.000000000000043, 23.700000000000042, 32.000000000000185, 18.600000000000016, -33.89999999999957, -23.599999999999696, -5.000000000000096, 21.199999999999992, 35.70000000000024, -20.499999999999552, -94.99999999999996], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-17.199999999999747, -11.499999999999819, 10.999999999999973, 19.1, -13.599999999999783, -30.999999999999794, -30.099999999999824, -32.19999999999976, -2.500000000000034, -59.79999999999976, -8.799999999999871, -13.299999999999798, -177.70000000000059, 11.599999999999964, 30.800000000000196, -7.299999999999997, -124.90000000000066, -42.99999999999976, -48.09999999999979, -70.30000000000086, -27.99999999999978, 4.699999999999995, -7.299999999999891, -0.10000000000001347, -11.499999999999819, 12.799999999999974, -7.300000000000059, 7.0999999999999766, 1.0999999999999688, -66.1000000000009, -49.29999999999989, 13.699999999999964, -0.6999999999999993, -13.899999999999913, -33.699999999999754, -0.9999999999999881, -122.80000000000075, -124.90000000000074, -9.399999999999855, 15.799999999999963, 11.89999999999997, -34.29999999999976, 8.299999999999976, -45.09999999999976, -27.69999999999984, -40.89999999999976, -28.29999999999979, -15.699999999999747, 9.499999999999964, -118.6000000000007, -14.199999999999823, -99.70000000000081, 19.1, 13.699999999999964, -42.399999999999764, 9.499999999999964, -41.499999999999766, -42.099999999999774, 3.1999999999999704, -19.29999999999975, -187.90000000000057, -87.1000000000001, 3.2000000000000033, -45.09999999999976, 17.899999999999988, 9.499999999999964, 5.299999999999974, -11.49999999999984, -111.40000000000066, -44.19999999999979, -47.19999999999976, -23.19999999999984, -74.50000000000017, -82.90000000000026, -15.699999999999747, -11.499999999999819, -55.599999999999994, -21.999999999999744, 13.699999999999966, 1.3999999999999726, 33.50000000000024, 19.40000000000001, -40.89999999999976, 20.000000000000014, -15.699999999999747, -21.999999999999744, -45.399999999999764, -51.39999999999999, -11.499999999999854, -110.20000000000076, -61.900000000000766, -0.9999999999999846, -43.29999999999976, 17.899999999999984, -68.2000000000009, -19.29999999999982, 20.000000000000014, -12.399999999999816, 22.700000000000053, 13.699999999999964, 9.499999999999964, -21.999999999999773, -32.49999999999976, -4.299999999999944, -59.800000000000594, -30.699999999999804, 11.599999999999964, 20.000000000000014, -0.40000000000002056, 5.299999999999965, 20.000000000000014, -26.49999999999975, 1.0999999999999865, 20.000000000000014, 5.899999999999967, -16.899999999999743, -30.699999999999775, -38.799999999999756, 3.1999999999999615, -0.9999999999999846, -36.699999999999754, 17.899999999999988, -50.79999999999998, -16.29999999999975, 20.000000000000014, -19.899999999999743, -26.499999999999773, 1.0999999999999723, 17.899999999999984, -3.099999999999958, 9.199999999999966, -8.799999999999871, -7.299999999999891, -11.499999999999819, -60.700000000000166, -88.9000000000008, 0.19999999999997944, 7.399999999999965, -30.39999999999975, -30.999999999999787, -43.29999999999976, 1.0999999999999865, 6.199999999999969, 23.000000000000057, -48.9999999999998, 3.1999999999999864, -74.50000000000085, 20.000000000000014, -52.900000000000055, 20.000000000000014, -27.99999999999976, -47.19999999999976, -30.99999999999976, -36.99999999999977, 11.299999999999965, 20.000000000000014, -15.699999999999747, -41.499999999999766, 5.299999999999965, -36.69999999999977, 3.1999999999999615, 13.699999999999964, 20.000000000000014, -93.40000000000083, -0.9999999999999846, 8.599999999999973, -20.799999999999756, 20.000000000000014, 20.000000000000014, -106.0000000000008, -45.09999999999976, -18.999999999999744, -66.1000000000009, -36.699999999999754, -38.799999999999756, -36.699999999999754, -24.099999999999852, -3.099999999999958, 9.499999999999964, -26.499999999999808, 20.000000000000014, -43.29999999999976, 20.000000000000014, -42.99999999999976, 20.000000000000014, -51.399999999999764, -24.099999999999746, -38.799999999999756, -26.199999999999875, -120.40000000000057, -27.999999999999883, -91.00000000000057, 20.000000000000014, -17.79999999999974, 20.000000000000014, -22.29999999999975, -45.099999999999774, -48.39999999999978, -66.09999999999985, -124.90000000000066], "policy_predator_policy_reward": [20.0, 22.0, 10.0, 10.0, 21.0, 28.0, 41.0, 36.0, 39.0, 25.0, 18.0, 15.0, 0.0, 95.0, 13.0, 11.0, 16.0, 73.0, 12.0, 56.0, 12.0, 25.0, 12.0, 5.0, 16.0, 3.0, 17.0, 21.0, 49.0, 14.0, 33.0, 7.0, 25.0, 18.0, 17.0, 25.0, 75.0, 13.0, 14.0, 2.0, 16.0, 28.0, 35.0, 15.0, 21.0, 39.0, 41.0, 33.0, 5.0, 66.0, 18.0, 59.0, 3.0, 3.0, 13.0, 26.0, 33.0, 34.0, 34.0, 34.0, 4.0, 127.0, 4.0, 36.0, 5.0, 1.0, 13.0, 17.0, 23.0, 69.0, 47.0, 47.0, 0.0, 82.0, 17.0, 15.0, 38.0, 8.0, 0.0, 13.0, 5.0, 5.0, 23.0, 23.0, 22.0, 11.0, 42.0, 17.0, 54.0, 56.0, 39.0, 22.0, 19.0, 28.0, 19.0, 46.0, 14.0, 17.0, 3.0, 3.0, 20.0, 13.0, 28.0, 20.0, 61.0, 6.0, 3.0, 4.0, 19.0, 17.0, 9.0, 21.0, 9.0, 1.0, 13.0, 18.0, 27.0, 42.0, 8.0, 10.0, 1.0, 27.0, 29.0, 35.0, 19.0, 11.0, 13.0, 25.0, 11.0, 1.0, 14.0, 16.0, 13.0, 15.0, 16.0, 60.0, 7.0, 16.0, 17.0, 43.0, 15.0, 29.0, 3.0, 10.0, 17.0, 29.0, 39.0, 31.0, 39.0, 21.0, 1.0, 46.0, 42.0, 26.0, 0.0, 5.0, 16.0, 36.0, 30.0, 14.0, 8.0, 3.0, 42.0, 41.0, 17.0, 19.0, 22.0, 11.0, 27.0, 38.0, 31.0, 18.0, 46.0, 21.0, 28.0, 16.0, 21.0, 11.0, 20.0, 20.0, 27.0, 20.0, 25.0, 30.0, 29.0, 21.0, 29.0, 0.0, 45.0, 78.0, 50.0, 64.0, 1.0, 18.0, 20.0, 18.0, 33.0, 40.0, 5.0, 91.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5946500315465486, "mean_inference_ms": 1.8370774408969865, "mean_action_processing_ms": 0.2614544602340618, "mean_env_wait_ms": 0.2004750792344689, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004868745803833008, "StateBufferConnector_ms": 0.003690004348754883, "ViewRequirementAgentConnector_ms": 0.10498607158660889}, "num_episodes": 23, "episode_return_max": 62.900000000000524, "episode_return_min": -159.7000000000015, "episode_return_mean": 2.4100000000000814, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1824000, "num_agent_steps_trained": 1824000, "num_env_steps_sampled": 456000, "num_env_steps_trained": 456000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 358.47003446391705, "num_env_steps_trained_throughput_per_sec": 358.47003446391705, "timesteps_total": 456000, "num_env_steps_sampled_lifetime": 456000, "num_agent_steps_sampled_lifetime": 1824000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1824000, "timers": {"training_iteration_time_ms": 11287.169, "restore_workers_time_ms": 0.015, "training_step_time_ms": 11287.117, "sample_time_ms": 1410.855, "learn_time_ms": 9856.515, "learn_throughput": 405.823, "synch_weights_time_ms": 15.912}, "counters": {"num_env_steps_sampled": 456000, "num_env_steps_trained": 456000, "num_agent_steps_sampled": 1824000, "num_agent_steps_trained": 1824000}, "done": false, "training_iteration": 114, "trial_id": "3dae5_00000", "date": "2024-08-14_09-27-51", "timestamp": 1723642071, "time_this_iter_s": 11.18413519859314, "time_total_s": 2889.296593427658, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3831d30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2889.296593427658, "iterations_since_restore": 114, "perf": {"cpu_util_percent": 30.2875, "ram_util_percent": 83.42500000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.1833582142358106, "cur_kl_coeff": 6.866455078125002e-06, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.9896936252003625, "policy_loss": -0.005069169417398159, "vf_loss": 1.994762730125397, "vf_explained_var": 0.21908512720986018, "kl": 0.01227816091054453, "entropy": 0.6757449096472806, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 216405.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.4226881533703475, "cur_kl_coeff": 0.12656249999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.9889438409023183, "policy_loss": -0.005833879488682936, "vf_loss": 1.993989522274209, "vf_explained_var": 0.08933575910235209, "kl": 0.0062277172750872115, "entropy": 1.0915882055721586, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 216405.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 460000, "num_env_steps_trained": 460000, "num_agent_steps_sampled": 1840000, "num_agent_steps_trained": 1840000}, "env_runners": {"episode_reward_max": 62.900000000000524, "episode_reward_min": -276.29999999999643, "episode_reward_mean": -0.9629999999998704, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -236.20000000000044, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 33.50000000000024, "predator_policy": 127.0}, "policy_reward_mean": {"prey_policy": -24.83650000000001, "predator_policy": 24.355}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-159.7000000000015, 22.400000000000013, 21.60000000000001, 13.199999999999985, -8.599999999999673, 30.000000000000153, -38.09999999999955, -36.89999999999967, 38.80000000000028, 6.100000000000145, -16.59999999999954, 51.90000000000047, -144.00000000000077, -1.8999999999997437, 33.400000000000205, 23.800000000000082, -63.6000000000013, 23.60000000000005, -75.40000000000032, 4.8000000000001855, -31.59999999999951, 28.100000000000115, 62.900000000000524, 25.10000000000007, -4.699999999999687, -37.79999999999994, -11.69999999999962, -1.8999999999997437, 21.600000000000005, -22.499999999999567, 38.60000000000028, 42.40000000000033, 20.499999999999993, 11.20000000000006, -23.49999999999958, 38.60000000000028, 40.90000000000031, 23.500000000000036, 31.100000000000165, 19.999999999999982, -0.49999999999979283, 20.200000000000006, 9.200000000000088, -3.0999999999997447, 30.100000000000154, 12.599999999999987, 26.80000000000009, 30.400000000000155, 9.200000000000113, -73.60000000000164, 30.60000000000016, -1.3999999999998356, 1.800000000000215, 42.20000000000034, 0.19999999999995813, 15.499999999999918, 27.100000000000115, -28.19999999999952, 2.0003443346183758e-13, 36.300000000000246, -5.199999999999699, 12.599999999999966, 27.900000000000105, 9.59999999999999, 43.600000000000364, 32.20000000000018, -20.999999999999545, -15.099999999999522, -35.79999999999953, -31.499999999999652, 4.799999999999926, 23.000000000000043, 23.700000000000042, 32.000000000000185, 18.600000000000016, -33.89999999999957, -23.599999999999696, -5.000000000000096, 21.199999999999992, 35.70000000000024, -20.499999999999552, -94.99999999999996, 26.800000000000086, -9.89999999999964, 27.900000000000123, 28.800000000000125, 40.60000000000034, 8.100000000000131, -100.8000000000016, -15.299999999999535, 24.60000000000005, -276.29999999999643, 20.200000000000006, 30.600000000000158, 12.299999999999919, 2.500000000000185, -52.90000000000094, -43.59999999999992, 25.700000000000067, -24.899999999999537], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-122.80000000000075, -124.90000000000074, -9.399999999999855, 15.799999999999963, 11.89999999999997, -34.29999999999976, 8.299999999999976, -45.09999999999976, -27.69999999999984, -40.89999999999976, -28.29999999999979, -15.699999999999747, 9.499999999999964, -118.6000000000007, -14.199999999999823, -99.70000000000081, 19.1, 13.699999999999964, -42.399999999999764, 9.499999999999964, -41.499999999999766, -42.099999999999774, 3.1999999999999704, -19.29999999999975, -187.90000000000057, -87.1000000000001, 3.2000000000000033, -45.09999999999976, 17.899999999999988, 9.499999999999964, 5.299999999999974, -11.49999999999984, -111.40000000000066, -44.19999999999979, -47.19999999999976, -23.19999999999984, -74.50000000000017, -82.90000000000026, -15.699999999999747, -11.499999999999819, -55.599999999999994, -21.999999999999744, 13.699999999999966, 1.3999999999999726, 33.50000000000024, 19.40000000000001, -40.89999999999976, 20.000000000000014, -15.699999999999747, -21.999999999999744, -45.399999999999764, -51.39999999999999, -11.499999999999854, -110.20000000000076, -61.900000000000766, -0.9999999999999846, -43.29999999999976, 17.899999999999984, -68.2000000000009, -19.29999999999982, 20.000000000000014, -12.399999999999816, 22.700000000000053, 13.699999999999964, 9.499999999999964, -21.999999999999773, -32.49999999999976, -4.299999999999944, -59.800000000000594, -30.699999999999804, 11.599999999999964, 20.000000000000014, -0.40000000000002056, 5.299999999999965, 20.000000000000014, -26.49999999999975, 1.0999999999999865, 20.000000000000014, 5.899999999999967, -16.899999999999743, -30.699999999999775, -38.799999999999756, 3.1999999999999615, -0.9999999999999846, -36.699999999999754, 17.899999999999988, -50.79999999999998, -16.29999999999975, 20.000000000000014, -19.899999999999743, -26.499999999999773, 1.0999999999999723, 17.899999999999984, -3.099999999999958, 9.199999999999966, -8.799999999999871, -7.299999999999891, -11.499999999999819, -60.700000000000166, -88.9000000000008, 0.19999999999997944, 7.399999999999965, -30.39999999999975, -30.999999999999787, -43.29999999999976, 1.0999999999999865, 6.199999999999969, 23.000000000000057, -48.9999999999998, 3.1999999999999864, -74.50000000000085, 20.000000000000014, -52.900000000000055, 20.000000000000014, -27.99999999999976, -47.19999999999976, -30.99999999999976, -36.99999999999977, 11.299999999999965, 20.000000000000014, -15.699999999999747, -41.499999999999766, 5.299999999999965, -36.69999999999977, 3.1999999999999615, 13.699999999999964, 20.000000000000014, -93.40000000000083, -0.9999999999999846, 8.599999999999973, -20.799999999999756, 20.000000000000014, 20.000000000000014, -106.0000000000008, -45.09999999999976, -18.999999999999744, -66.1000000000009, -36.699999999999754, -38.799999999999756, -36.699999999999754, -24.099999999999852, -3.099999999999958, 9.499999999999964, -26.499999999999808, 20.000000000000014, -43.29999999999976, 20.000000000000014, -42.99999999999976, 20.000000000000014, -51.399999999999764, -24.099999999999746, -38.799999999999756, -26.199999999999875, -120.40000000000057, -27.999999999999883, -91.00000000000057, 20.000000000000014, -17.79999999999974, 20.000000000000014, -22.29999999999975, -45.099999999999774, -48.39999999999978, -66.09999999999985, -124.90000000000066, -0.9999999999999846, 15.799999999999963, -82.90000000000086, 20.000000000000014, -27.099999999999767, 20.000000000000014, -24.099999999999746, 17.899999999999988, -13.299999999999834, -12.099999999999817, -7.299999999999891, -13.599999999999783, -70.30000000000055, -137.5000000000007, -44.499999999999766, -23.799999999999763, -7.299999999999894, 17.899999999999988, -192.10000000000056, -236.20000000000044, 3.1999999999999615, -0.9999999999999846, 20.000000000000014, -9.399999999999855, -38.49999999999978, 15.799999999999963, -9.399999999999855, -27.09999999999976, -55.59999999999988, -70.30000000000089, -25.299999999999777, -91.30000000000082, 9.499999999999964, 3.1999999999999615, 15.799999999999963, -99.70000000000081], "policy_predator_policy_reward": [75.0, 13.0, 14.0, 2.0, 16.0, 28.0, 35.0, 15.0, 21.0, 39.0, 41.0, 33.0, 5.0, 66.0, 18.0, 59.0, 3.0, 3.0, 13.0, 26.0, 33.0, 34.0, 34.0, 34.0, 4.0, 127.0, 4.0, 36.0, 5.0, 1.0, 13.0, 17.0, 23.0, 69.0, 47.0, 47.0, 0.0, 82.0, 17.0, 15.0, 38.0, 8.0, 0.0, 13.0, 5.0, 5.0, 23.0, 23.0, 22.0, 11.0, 42.0, 17.0, 54.0, 56.0, 39.0, 22.0, 19.0, 28.0, 19.0, 46.0, 14.0, 17.0, 3.0, 3.0, 20.0, 13.0, 28.0, 20.0, 61.0, 6.0, 3.0, 4.0, 19.0, 17.0, 9.0, 21.0, 9.0, 1.0, 13.0, 18.0, 27.0, 42.0, 8.0, 10.0, 1.0, 27.0, 29.0, 35.0, 19.0, 11.0, 13.0, 25.0, 11.0, 1.0, 14.0, 16.0, 13.0, 15.0, 16.0, 60.0, 7.0, 16.0, 17.0, 43.0, 15.0, 29.0, 3.0, 10.0, 17.0, 29.0, 39.0, 31.0, 39.0, 21.0, 1.0, 46.0, 42.0, 26.0, 0.0, 5.0, 16.0, 36.0, 30.0, 14.0, 8.0, 3.0, 42.0, 41.0, 17.0, 19.0, 22.0, 11.0, 27.0, 38.0, 31.0, 18.0, 46.0, 21.0, 28.0, 16.0, 21.0, 11.0, 20.0, 20.0, 27.0, 20.0, 25.0, 30.0, 29.0, 21.0, 29.0, 0.0, 45.0, 78.0, 50.0, 64.0, 1.0, 18.0, 20.0, 18.0, 33.0, 40.0, 5.0, 91.0, 10.0, 2.0, 25.0, 28.0, 22.0, 13.0, 15.0, 20.0, 37.0, 29.0, 13.0, 16.0, 82.0, 25.0, 29.0, 24.0, 13.0, 1.0, 29.0, 123.0, 10.0, 8.0, 14.0, 6.0, 27.0, 8.0, 24.0, 15.0, 29.0, 44.0, 58.0, 15.0, 5.0, 8.0, 2.0, 57.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5942697266782144, "mean_inference_ms": 1.8375813437155086, "mean_action_processing_ms": 0.2608490664296346, "mean_env_wait_ms": 0.20031181907524165, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005019783973693848, "StateBufferConnector_ms": 0.0035238265991210938, "ViewRequirementAgentConnector_ms": 0.09954583644866943}, "num_episodes": 18, "episode_return_max": 62.900000000000524, "episode_return_min": -276.29999999999643, "episode_return_mean": -0.9629999999998704, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1840000, "num_agent_steps_trained": 1840000, "num_env_steps_sampled": 460000, "num_env_steps_trained": 460000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 364.7806501108928, "num_env_steps_trained_throughput_per_sec": 364.7806501108928, "timesteps_total": 460000, "num_env_steps_sampled_lifetime": 460000, "num_agent_steps_sampled_lifetime": 1840000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1840000, "timers": {"training_iteration_time_ms": 11232.416, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11232.368, "sample_time_ms": 1396.338, "learn_time_ms": 9816.633, "learn_throughput": 407.472, "synch_weights_time_ms": 15.721}, "counters": {"num_env_steps_sampled": 460000, "num_env_steps_trained": 460000, "num_agent_steps_sampled": 1840000, "num_agent_steps_trained": 1840000}, "done": false, "training_iteration": 115, "trial_id": "3dae5_00000", "date": "2024-08-14_09-28-02", "timestamp": 1723642082, "time_this_iter_s": 10.96963095664978, "time_total_s": 2900.266224384308, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3831dc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2900.266224384308, "iterations_since_restore": 115, "perf": {"cpu_util_percent": 27.7, "ram_util_percent": 83.26}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.6245301658198947, "cur_kl_coeff": 6.866455078125002e-06, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.8957789295564884, "policy_loss": -0.0036216848267478837, "vf_loss": 1.89940057904632, "vf_explained_var": 0.16147826159441914, "kl": 0.008127753909747888, "entropy": 0.6301101362894452, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 218295.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.6973755889153352, "cur_kl_coeff": 0.12656249999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.078436870328964, "policy_loss": -0.00570826711448491, "vf_loss": 2.0832624719256447, "vf_explained_var": 0.07382872060493187, "kl": 0.006974152325181687, "entropy": 1.0781807898213625, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 218295.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 464000, "num_env_steps_trained": 464000, "num_agent_steps_sampled": 1856000, "num_agent_steps_trained": 1856000}, "env_runners": {"episode_reward_max": 62.900000000000524, "episode_reward_min": -342.39999999999753, "episode_reward_mean": -1.8399999999997811, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -294.9999999999989, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 36.20000000000025, "predator_policy": 150.0}, "policy_reward_mean": {"prey_policy": -24.639999999999983, "predator_policy": 23.72}, "custom_metrics": {}, "hist_stats": {"episode_reward": [62.900000000000524, 25.10000000000007, -4.699999999999687, -37.79999999999994, -11.69999999999962, -1.8999999999997437, 21.600000000000005, -22.499999999999567, 38.60000000000028, 42.40000000000033, 20.499999999999993, 11.20000000000006, -23.49999999999958, 38.60000000000028, 40.90000000000031, 23.500000000000036, 31.100000000000165, 19.999999999999982, -0.49999999999979283, 20.200000000000006, 9.200000000000088, -3.0999999999997447, 30.100000000000154, 12.599999999999987, 26.80000000000009, 30.400000000000155, 9.200000000000113, -73.60000000000164, 30.60000000000016, -1.3999999999998356, 1.800000000000215, 42.20000000000034, 0.19999999999995813, 15.499999999999918, 27.100000000000115, -28.19999999999952, 2.0003443346183758e-13, 36.300000000000246, -5.199999999999699, 12.599999999999966, 27.900000000000105, 9.59999999999999, 43.600000000000364, 32.20000000000018, -20.999999999999545, -15.099999999999522, -35.79999999999953, -31.499999999999652, 4.799999999999926, 23.000000000000043, 23.700000000000042, 32.000000000000185, 18.600000000000016, -33.89999999999957, -23.599999999999696, -5.000000000000096, 21.199999999999992, 35.70000000000024, -20.499999999999552, -94.99999999999996, 26.800000000000086, -9.89999999999964, 27.900000000000123, 28.800000000000125, 40.60000000000034, 8.100000000000131, -100.8000000000016, -15.299999999999535, 24.60000000000005, -276.29999999999643, 20.200000000000006, 30.600000000000158, 12.299999999999919, 2.500000000000185, -52.90000000000094, -43.59999999999992, 25.700000000000067, -24.899999999999537, -4.399999999999688, -0.29999999999991367, 24.60000000000005, -14.999999999999536, 42.700000000000344, -3.999999999999717, -9.599999999999598, 36.40000000000024, 56.10000000000036, 43.40000000000035, 13.500000000000027, 14.500000000000016, 29.100000000000144, 40.0000000000003, -1.4999999999997433, 12.200000000000045, -68.9000000000004, -294.99999999999727, 1.500000000000229, 37.80000000000026, -342.39999999999753, 22.90000000000002], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [33.50000000000024, 19.40000000000001, -40.89999999999976, 20.000000000000014, -15.699999999999747, -21.999999999999744, -45.399999999999764, -51.39999999999999, -11.499999999999854, -110.20000000000076, -61.900000000000766, -0.9999999999999846, -43.29999999999976, 17.899999999999984, -68.2000000000009, -19.29999999999982, 20.000000000000014, -12.399999999999816, 22.700000000000053, 13.699999999999964, 9.499999999999964, -21.999999999999773, -32.49999999999976, -4.299999999999944, -59.800000000000594, -30.699999999999804, 11.599999999999964, 20.000000000000014, -0.40000000000002056, 5.299999999999965, 20.000000000000014, -26.49999999999975, 1.0999999999999865, 20.000000000000014, 5.899999999999967, -16.899999999999743, -30.699999999999775, -38.799999999999756, 3.1999999999999615, -0.9999999999999846, -36.699999999999754, 17.899999999999988, -50.79999999999998, -16.29999999999975, 20.000000000000014, -19.899999999999743, -26.499999999999773, 1.0999999999999723, 17.899999999999984, -3.099999999999958, 9.199999999999966, -8.799999999999871, -7.299999999999891, -11.499999999999819, -60.700000000000166, -88.9000000000008, 0.19999999999997944, 7.399999999999965, -30.39999999999975, -30.999999999999787, -43.29999999999976, 1.0999999999999865, 6.199999999999969, 23.000000000000057, -48.9999999999998, 3.1999999999999864, -74.50000000000085, 20.000000000000014, -52.900000000000055, 20.000000000000014, -27.99999999999976, -47.19999999999976, -30.99999999999976, -36.99999999999977, 11.299999999999965, 20.000000000000014, -15.699999999999747, -41.499999999999766, 5.299999999999965, -36.69999999999977, 3.1999999999999615, 13.699999999999964, 20.000000000000014, -93.40000000000083, -0.9999999999999846, 8.599999999999973, -20.799999999999756, 20.000000000000014, 20.000000000000014, -106.0000000000008, -45.09999999999976, -18.999999999999744, -66.1000000000009, -36.699999999999754, -38.799999999999756, -36.699999999999754, -24.099999999999852, -3.099999999999958, 9.499999999999964, -26.499999999999808, 20.000000000000014, -43.29999999999976, 20.000000000000014, -42.99999999999976, 20.000000000000014, -51.399999999999764, -24.099999999999746, -38.799999999999756, -26.199999999999875, -120.40000000000057, -27.999999999999883, -91.00000000000057, 20.000000000000014, -17.79999999999974, 20.000000000000014, -22.29999999999975, -45.099999999999774, -48.39999999999978, -66.09999999999985, -124.90000000000066, -0.9999999999999846, 15.799999999999963, -82.90000000000086, 20.000000000000014, -27.099999999999767, 20.000000000000014, -24.099999999999746, 17.899999999999988, -13.299999999999834, -12.099999999999817, -7.299999999999891, -13.599999999999783, -70.30000000000055, -137.5000000000007, -44.499999999999766, -23.799999999999763, -7.299999999999894, 17.899999999999988, -192.10000000000056, -236.20000000000044, 3.1999999999999615, -0.9999999999999846, 20.000000000000014, -9.399999999999855, -38.49999999999978, 15.799999999999963, -9.399999999999855, -27.09999999999976, -55.59999999999988, -70.30000000000089, -25.299999999999777, -91.30000000000082, 9.499999999999964, 3.1999999999999615, 15.799999999999963, -99.70000000000081, -11.499999999999819, -19.899999999999743, -24.099999999999746, -44.199999999999775, 5.299999999999965, 5.299999999999967, -76.60000000000085, 11.599999999999964, 20.000000000000014, 13.699999999999964, -27.99999999999976, -21.999999999999744, -17.79999999999974, -17.79999999999974, 36.20000000000025, -53.800000000000196, -13.899999999999896, 20.000000000000014, 27.20000000000013, 3.1999999999999615, 0.19999999999998655, -15.699999999999747, -18.999999999999744, 9.499999999999966, 20.000000000000014, -34.899999999999764, 20.000000000000014, 20.000000000000014, -11.499999999999819, -36.99999999999976, 5.299999999999965, -45.09999999999976, -61.89999999999989, -106.0000000000008, -267.6999999999997, -208.30000000000032, -15.699999999999747, -17.79999999999974, 24.50000000000008, -30.699999999999754, -294.9999999999989, -216.40000000000032, -11.499999999999819, 16.399999999999967], "policy_predator_policy_reward": [5.0, 5.0, 23.0, 23.0, 22.0, 11.0, 42.0, 17.0, 54.0, 56.0, 39.0, 22.0, 19.0, 28.0, 19.0, 46.0, 14.0, 17.0, 3.0, 3.0, 20.0, 13.0, 28.0, 20.0, 61.0, 6.0, 3.0, 4.0, 19.0, 17.0, 9.0, 21.0, 9.0, 1.0, 13.0, 18.0, 27.0, 42.0, 8.0, 10.0, 1.0, 27.0, 29.0, 35.0, 19.0, 11.0, 13.0, 25.0, 11.0, 1.0, 14.0, 16.0, 13.0, 15.0, 16.0, 60.0, 7.0, 16.0, 17.0, 43.0, 15.0, 29.0, 3.0, 10.0, 17.0, 29.0, 39.0, 31.0, 39.0, 21.0, 1.0, 46.0, 42.0, 26.0, 0.0, 5.0, 16.0, 36.0, 30.0, 14.0, 8.0, 3.0, 42.0, 41.0, 17.0, 19.0, 22.0, 11.0, 27.0, 38.0, 31.0, 18.0, 46.0, 21.0, 28.0, 16.0, 21.0, 11.0, 20.0, 20.0, 27.0, 20.0, 25.0, 30.0, 29.0, 21.0, 29.0, 0.0, 45.0, 78.0, 50.0, 64.0, 1.0, 18.0, 20.0, 18.0, 33.0, 40.0, 5.0, 91.0, 10.0, 2.0, 25.0, 28.0, 22.0, 13.0, 15.0, 20.0, 37.0, 29.0, 13.0, 16.0, 82.0, 25.0, 29.0, 24.0, 13.0, 1.0, 29.0, 123.0, 10.0, 8.0, 14.0, 6.0, 27.0, 8.0, 24.0, 15.0, 29.0, 44.0, 58.0, 15.0, 5.0, 8.0, 2.0, 57.0, 19.0, 8.0, 43.0, 25.0, 10.0, 4.0, 4.0, 46.0, 3.0, 6.0, 26.0, 20.0, 18.0, 8.0, 21.0, 33.0, 26.0, 24.0, 6.0, 7.0, 17.0, 12.0, 19.0, 5.0, 23.0, 21.0, 0.0, 0.0, 19.0, 28.0, 31.0, 21.0, 46.0, 53.0, 148.0, 33.0, 17.0, 18.0, 20.0, 24.0, 150.0, 19.0, 3.0, 15.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.594184878469996, "mean_inference_ms": 1.8365893598383107, "mean_action_processing_ms": 0.2601542452149386, "mean_env_wait_ms": 0.20029737593486246, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005630970001220703, "StateBufferConnector_ms": 0.003562450408935547, "ViewRequirementAgentConnector_ms": 0.10085117816925049}, "num_episodes": 22, "episode_return_max": 62.900000000000524, "episode_return_min": -342.39999999999753, "episode_return_mean": -1.8399999999997811, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1856000, "num_agent_steps_trained": 1856000, "num_env_steps_sampled": 464000, "num_env_steps_trained": 464000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 369.52904936247205, "num_env_steps_trained_throughput_per_sec": 369.52904936247205, "timesteps_total": 464000, "num_env_steps_sampled_lifetime": 464000, "num_agent_steps_sampled_lifetime": 1856000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1856000, "timers": {"training_iteration_time_ms": 11070.016, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11069.97, "sample_time_ms": 1349.975, "learn_time_ms": 9702.537, "learn_throughput": 412.263, "synch_weights_time_ms": 15.624}, "counters": {"num_env_steps_sampled": 464000, "num_env_steps_trained": 464000, "num_agent_steps_sampled": 1856000, "num_agent_steps_trained": 1856000}, "done": false, "training_iteration": 116, "trial_id": "3dae5_00000", "date": "2024-08-14_09-28-12", "timestamp": 1723642092, "time_this_iter_s": 10.86768889427185, "time_total_s": 2911.1339132785797, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b36b4ee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2911.1339132785797, "iterations_since_restore": 116, "perf": {"cpu_util_percent": 27.66875, "ram_util_percent": 83.06875}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.3833238705125437, "cur_kl_coeff": 6.866455078125002e-06, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.9664362345423017, "policy_loss": -0.0034699450827218475, "vf_loss": 1.9699061469741599, "vf_explained_var": 0.14370823215555262, "kl": 0.008454373803419492, "entropy": 0.6126304384261843, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 220185.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.4074363660244713, "cur_kl_coeff": 0.12656249999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.5796711678227418, "policy_loss": -0.006506343519995137, "vf_loss": 2.5852275174130837, "vf_explained_var": 0.02513316658438829, "kl": 0.0075061003452096976, "entropy": 1.0821430568026487, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 220185.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 468000, "num_env_steps_trained": 468000, "num_agent_steps_sampled": 1872000, "num_agent_steps_trained": 1872000}, "env_runners": {"episode_reward_max": 56.10000000000036, "episode_reward_min": -342.39999999999753, "episode_reward_mean": -9.18599999999983, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -393.70000000000005, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 36.20000000000025, "predator_policy": 197.0}, "policy_reward_mean": {"prey_policy": -30.463, "predator_policy": 25.87}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.49999999999979283, 20.200000000000006, 9.200000000000088, -3.0999999999997447, 30.100000000000154, 12.599999999999987, 26.80000000000009, 30.400000000000155, 9.200000000000113, -73.60000000000164, 30.60000000000016, -1.3999999999998356, 1.800000000000215, 42.20000000000034, 0.19999999999995813, 15.499999999999918, 27.100000000000115, -28.19999999999952, 2.0003443346183758e-13, 36.300000000000246, -5.199999999999699, 12.599999999999966, 27.900000000000105, 9.59999999999999, 43.600000000000364, 32.20000000000018, -20.999999999999545, -15.099999999999522, -35.79999999999953, -31.499999999999652, 4.799999999999926, 23.000000000000043, 23.700000000000042, 32.000000000000185, 18.600000000000016, -33.89999999999957, -23.599999999999696, -5.000000000000096, 21.199999999999992, 35.70000000000024, -20.499999999999552, -94.99999999999996, 26.800000000000086, -9.89999999999964, 27.900000000000123, 28.800000000000125, 40.60000000000034, 8.100000000000131, -100.8000000000016, -15.299999999999535, 24.60000000000005, -276.29999999999643, 20.200000000000006, 30.600000000000158, 12.299999999999919, 2.500000000000185, -52.90000000000094, -43.59999999999992, 25.700000000000067, -24.899999999999537, -4.399999999999688, -0.29999999999991367, 24.60000000000005, -14.999999999999536, 42.700000000000344, -3.999999999999717, -9.599999999999598, 36.40000000000024, 56.10000000000036, 43.40000000000035, 13.500000000000027, 14.500000000000016, 29.100000000000144, 40.0000000000003, -1.4999999999997433, 12.200000000000045, -68.9000000000004, -294.99999999999727, 1.500000000000229, 37.80000000000026, -342.39999999999753, 22.90000000000002, 30.00000000000015, -23.399999999999523, 31.700000000000177, 37.80000000000027, 35.600000000000236, -3.799999999999745, -336.6, 38.10000000000027, -138.30000000000157, 33.1000000000002, 25.00000000000006, 8.200000000000117, -8.299999999999702, -109.60000000000167, 30.700000000000163, 33.90000000000022, 8.40000000000008, -152.80000000000047], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-30.699999999999775, -38.799999999999756, 3.1999999999999615, -0.9999999999999846, -36.699999999999754, 17.899999999999988, -50.79999999999998, -16.29999999999975, 20.000000000000014, -19.899999999999743, -26.499999999999773, 1.0999999999999723, 17.899999999999984, -3.099999999999958, 9.199999999999966, -8.799999999999871, -7.299999999999891, -11.499999999999819, -60.700000000000166, -88.9000000000008, 0.19999999999997944, 7.399999999999965, -30.39999999999975, -30.999999999999787, -43.29999999999976, 1.0999999999999865, 6.199999999999969, 23.000000000000057, -48.9999999999998, 3.1999999999999864, -74.50000000000085, 20.000000000000014, -52.900000000000055, 20.000000000000014, -27.99999999999976, -47.19999999999976, -30.99999999999976, -36.99999999999977, 11.299999999999965, 20.000000000000014, -15.699999999999747, -41.499999999999766, 5.299999999999965, -36.69999999999977, 3.1999999999999615, 13.699999999999964, 20.000000000000014, -93.40000000000083, -0.9999999999999846, 8.599999999999973, -20.799999999999756, 20.000000000000014, 20.000000000000014, -106.0000000000008, -45.09999999999976, -18.999999999999744, -66.1000000000009, -36.699999999999754, -38.799999999999756, -36.699999999999754, -24.099999999999852, -3.099999999999958, 9.499999999999964, -26.499999999999808, 20.000000000000014, -43.29999999999976, 20.000000000000014, -42.99999999999976, 20.000000000000014, -51.399999999999764, -24.099999999999746, -38.799999999999756, -26.199999999999875, -120.40000000000057, -27.999999999999883, -91.00000000000057, 20.000000000000014, -17.79999999999974, 20.000000000000014, -22.29999999999975, -45.099999999999774, -48.39999999999978, -66.09999999999985, -124.90000000000066, -0.9999999999999846, 15.799999999999963, -82.90000000000086, 20.000000000000014, -27.099999999999767, 20.000000000000014, -24.099999999999746, 17.899999999999988, -13.299999999999834, -12.099999999999817, -7.299999999999891, -13.599999999999783, -70.30000000000055, -137.5000000000007, -44.499999999999766, -23.799999999999763, -7.299999999999894, 17.899999999999988, -192.10000000000056, -236.20000000000044, 3.1999999999999615, -0.9999999999999846, 20.000000000000014, -9.399999999999855, -38.49999999999978, 15.799999999999963, -9.399999999999855, -27.09999999999976, -55.59999999999988, -70.30000000000089, -25.299999999999777, -91.30000000000082, 9.499999999999964, 3.1999999999999615, 15.799999999999963, -99.70000000000081, -11.499999999999819, -19.899999999999743, -24.099999999999746, -44.199999999999775, 5.299999999999965, 5.299999999999967, -76.60000000000085, 11.599999999999964, 20.000000000000014, 13.699999999999964, -27.99999999999976, -21.999999999999744, -17.79999999999974, -17.79999999999974, 36.20000000000025, -53.800000000000196, -13.899999999999896, 20.000000000000014, 27.20000000000013, 3.1999999999999615, 0.19999999999998655, -15.699999999999747, -18.999999999999744, 9.499999999999966, 20.000000000000014, -34.899999999999764, 20.000000000000014, 20.000000000000014, -11.499999999999819, -36.99999999999976, 5.299999999999965, -45.09999999999976, -61.89999999999989, -106.0000000000008, -267.6999999999997, -208.30000000000032, -15.699999999999747, -17.79999999999974, 24.50000000000008, -30.699999999999754, -294.9999999999989, -216.40000000000032, -11.499999999999819, 16.399999999999967, 17.899999999999988, -19.899999999999743, -38.79999999999976, -34.59999999999976, 22.700000000000053, -0.9999999999999846, 17.899999999999988, 17.899999999999988, 13.699999999999964, 17.899999999999988, -87.10000000000085, 5.299999999999965, -316.9, -393.70000000000005, -15.699999999999747, 27.800000000000143, -103.9000000000008, -108.40000000000077, 8.599999999999968, 9.499999999999964, -30.39999999999975, 7.399999999999965, -13.599999999999783, -11.199999999999834, -11.49999999999989, -38.799999999999756, -85.00000000000085, -97.60000000000082, -43.29999999999978, 20.000000000000014, 21.80000000000004, 1.099999999999983, -72.40000000000089, 12.799999999999967, -208.0000000000004, -110.80000000000024], "policy_predator_policy_reward": [27.0, 42.0, 8.0, 10.0, 1.0, 27.0, 29.0, 35.0, 19.0, 11.0, 13.0, 25.0, 11.0, 1.0, 14.0, 16.0, 13.0, 15.0, 16.0, 60.0, 7.0, 16.0, 17.0, 43.0, 15.0, 29.0, 3.0, 10.0, 17.0, 29.0, 39.0, 31.0, 39.0, 21.0, 1.0, 46.0, 42.0, 26.0, 0.0, 5.0, 16.0, 36.0, 30.0, 14.0, 8.0, 3.0, 42.0, 41.0, 17.0, 19.0, 22.0, 11.0, 27.0, 38.0, 31.0, 18.0, 46.0, 21.0, 28.0, 16.0, 21.0, 11.0, 20.0, 20.0, 27.0, 20.0, 25.0, 30.0, 29.0, 21.0, 29.0, 0.0, 45.0, 78.0, 50.0, 64.0, 1.0, 18.0, 20.0, 18.0, 33.0, 40.0, 5.0, 91.0, 10.0, 2.0, 25.0, 28.0, 22.0, 13.0, 15.0, 20.0, 37.0, 29.0, 13.0, 16.0, 82.0, 25.0, 29.0, 24.0, 13.0, 1.0, 29.0, 123.0, 10.0, 8.0, 14.0, 6.0, 27.0, 8.0, 24.0, 15.0, 29.0, 44.0, 58.0, 15.0, 5.0, 8.0, 2.0, 57.0, 19.0, 8.0, 43.0, 25.0, 10.0, 4.0, 4.0, 46.0, 3.0, 6.0, 26.0, 20.0, 18.0, 8.0, 21.0, 33.0, 26.0, 24.0, 6.0, 7.0, 17.0, 12.0, 19.0, 5.0, 23.0, 21.0, 0.0, 0.0, 19.0, 28.0, 31.0, 21.0, 46.0, 53.0, 148.0, 33.0, 17.0, 18.0, 20.0, 24.0, 150.0, 19.0, 3.0, 15.0, 19.0, 13.0, 39.0, 11.0, 0.0, 10.0, 2.0, 0.0, 3.0, 1.0, 36.0, 42.0, 177.0, 197.0, 9.0, 17.0, 68.0, 6.0, 7.0, 8.0, 24.0, 24.0, 16.0, 17.0, 13.0, 29.0, 12.0, 61.0, 24.0, 30.0, 9.0, 2.0, 31.0, 37.0, 95.0, 71.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5939910482854398, "mean_inference_ms": 1.8361311316267188, "mean_action_processing_ms": 0.2604111449857816, "mean_env_wait_ms": 0.2000388379158435, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0059670209884643555, "StateBufferConnector_ms": 0.0033947229385375977, "ViewRequirementAgentConnector_ms": 0.09793519973754883}, "num_episodes": 18, "episode_return_max": 56.10000000000036, "episode_return_min": -342.39999999999753, "episode_return_mean": -9.18599999999983, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1872000, "num_agent_steps_trained": 1872000, "num_env_steps_sampled": 468000, "num_env_steps_trained": 468000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 364.4743236499884, "num_env_steps_trained_throughput_per_sec": 364.4743236499884, "timesteps_total": 468000, "num_env_steps_sampled_lifetime": 468000, "num_agent_steps_sampled_lifetime": 1872000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1872000, "timers": {"training_iteration_time_ms": 11039.689, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11039.646, "sample_time_ms": 1351.463, "learn_time_ms": 9671.625, "learn_throughput": 413.581, "synch_weights_time_ms": 15.205}, "counters": {"num_env_steps_sampled": 468000, "num_env_steps_trained": 468000, "num_agent_steps_sampled": 1872000, "num_agent_steps_trained": 1872000}, "done": false, "training_iteration": 117, "trial_id": "3dae5_00000", "date": "2024-08-14_09-28-23", "timestamp": 1723642103, "time_this_iter_s": 10.980311870574951, "time_total_s": 2922.1142251491547, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b38955e0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2922.1142251491547, "iterations_since_restore": 117, "perf": {"cpu_util_percent": 30.06666666666667, "ram_util_percent": 83.23333333333333}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.4710417955010024, "cur_kl_coeff": 6.866455078125002e-06, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.010503365280767, "policy_loss": -0.010365188669009262, "vf_loss": 1.0208684539038038, "vf_explained_var": 0.20107341632641182, "kl": 0.012639383180019672, "entropy": 0.5195600331775726, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 222075.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.6370742941659593, "cur_kl_coeff": 0.12656249999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.2992046841789806, "policy_loss": -0.004692474554820115, "vf_loss": 1.3032989691016534, "vf_explained_var": 0.018263597999300274, "kl": 0.004726439214366331, "entropy": 1.0818919590856664, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 222075.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 472000, "num_env_steps_trained": 472000, "num_agent_steps_sampled": 1888000, "num_agent_steps_trained": 1888000}, "env_runners": {"episode_reward_max": 56.10000000000036, "episode_reward_min": -480.0, "episode_reward_mean": -11.133999999999812, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -393.70000000000005, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 36.20000000000025, "predator_policy": 197.0}, "policy_reward_mean": {"prey_policy": -31.416999999999998, "predator_policy": 25.85}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.0003443346183758e-13, 36.300000000000246, -5.199999999999699, 12.599999999999966, 27.900000000000105, 9.59999999999999, 43.600000000000364, 32.20000000000018, -20.999999999999545, -15.099999999999522, -35.79999999999953, -31.499999999999652, 4.799999999999926, 23.000000000000043, 23.700000000000042, 32.000000000000185, 18.600000000000016, -33.89999999999957, -23.599999999999696, -5.000000000000096, 21.199999999999992, 35.70000000000024, -20.499999999999552, -94.99999999999996, 26.800000000000086, -9.89999999999964, 27.900000000000123, 28.800000000000125, 40.60000000000034, 8.100000000000131, -100.8000000000016, -15.299999999999535, 24.60000000000005, -276.29999999999643, 20.200000000000006, 30.600000000000158, 12.299999999999919, 2.500000000000185, -52.90000000000094, -43.59999999999992, 25.700000000000067, -24.899999999999537, -4.399999999999688, -0.29999999999991367, 24.60000000000005, -14.999999999999536, 42.700000000000344, -3.999999999999717, -9.599999999999598, 36.40000000000024, 56.10000000000036, 43.40000000000035, 13.500000000000027, 14.500000000000016, 29.100000000000144, 40.0000000000003, -1.4999999999997433, 12.200000000000045, -68.9000000000004, -294.99999999999727, 1.500000000000229, 37.80000000000026, -342.39999999999753, 22.90000000000002, 30.00000000000015, -23.399999999999523, 31.700000000000177, 37.80000000000027, 35.600000000000236, -3.799999999999745, -336.6, 38.10000000000027, -138.30000000000157, 33.1000000000002, 25.00000000000006, 8.200000000000117, -8.299999999999702, -109.60000000000167, 30.700000000000163, 33.90000000000022, 8.40000000000008, -152.80000000000047, 24.700000000000053, 35.500000000000234, 27.90000000000011, 41.400000000000325, -480.0, 18.39999999999996, 22.900000000000098, -30.399999999999665, 26.200000000000294, 35.70000000000022, 27.300000000000104, 34.200000000000216, 18.099999999999948, 35.30000000000023, 21.600000000000055, 43.700000000000365, 35.600000000000236, 16.199999999999978], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-30.99999999999976, -36.99999999999977, 11.299999999999965, 20.000000000000014, -15.699999999999747, -41.499999999999766, 5.299999999999965, -36.69999999999977, 3.1999999999999615, 13.699999999999964, 20.000000000000014, -93.40000000000083, -0.9999999999999846, 8.599999999999973, -20.799999999999756, 20.000000000000014, 20.000000000000014, -106.0000000000008, -45.09999999999976, -18.999999999999744, -66.1000000000009, -36.699999999999754, -38.799999999999756, -36.699999999999754, -24.099999999999852, -3.099999999999958, 9.499999999999964, -26.499999999999808, 20.000000000000014, -43.29999999999976, 20.000000000000014, -42.99999999999976, 20.000000000000014, -51.399999999999764, -24.099999999999746, -38.799999999999756, -26.199999999999875, -120.40000000000057, -27.999999999999883, -91.00000000000057, 20.000000000000014, -17.79999999999974, 20.000000000000014, -22.29999999999975, -45.099999999999774, -48.39999999999978, -66.09999999999985, -124.90000000000066, -0.9999999999999846, 15.799999999999963, -82.90000000000086, 20.000000000000014, -27.099999999999767, 20.000000000000014, -24.099999999999746, 17.899999999999988, -13.299999999999834, -12.099999999999817, -7.299999999999891, -13.599999999999783, -70.30000000000055, -137.5000000000007, -44.499999999999766, -23.799999999999763, -7.299999999999894, 17.899999999999988, -192.10000000000056, -236.20000000000044, 3.1999999999999615, -0.9999999999999846, 20.000000000000014, -9.399999999999855, -38.49999999999978, 15.799999999999963, -9.399999999999855, -27.09999999999976, -55.59999999999988, -70.30000000000089, -25.299999999999777, -91.30000000000082, 9.499999999999964, 3.1999999999999615, 15.799999999999963, -99.70000000000081, -11.499999999999819, -19.899999999999743, -24.099999999999746, -44.199999999999775, 5.299999999999965, 5.299999999999967, -76.60000000000085, 11.599999999999964, 20.000000000000014, 13.699999999999964, -27.99999999999976, -21.999999999999744, -17.79999999999974, -17.79999999999974, 36.20000000000025, -53.800000000000196, -13.899999999999896, 20.000000000000014, 27.20000000000013, 3.1999999999999615, 0.19999999999998655, -15.699999999999747, -18.999999999999744, 9.499999999999966, 20.000000000000014, -34.899999999999764, 20.000000000000014, 20.000000000000014, -11.499999999999819, -36.99999999999976, 5.299999999999965, -45.09999999999976, -61.89999999999989, -106.0000000000008, -267.6999999999997, -208.30000000000032, -15.699999999999747, -17.79999999999974, 24.50000000000008, -30.699999999999754, -294.9999999999989, -216.40000000000032, -11.499999999999819, 16.399999999999967, 17.899999999999988, -19.899999999999743, -38.79999999999976, -34.59999999999976, 22.700000000000053, -0.9999999999999846, 17.899999999999988, 17.899999999999988, 13.699999999999964, 17.899999999999988, -87.10000000000085, 5.299999999999965, -316.9, -393.70000000000005, -15.699999999999747, 27.800000000000143, -103.9000000000008, -108.40000000000077, 8.599999999999968, 9.499999999999964, -30.39999999999975, 7.399999999999965, -13.599999999999783, -11.199999999999834, -11.49999999999989, -38.799999999999756, -85.00000000000085, -97.60000000000082, -43.29999999999978, 20.000000000000014, 21.80000000000004, 1.099999999999983, -72.40000000000089, 12.799999999999967, -208.0000000000004, -110.80000000000024, 20.300000000000022, -13.599999999999783, 20.000000000000014, -11.499999999999819, 9.499999999999966, 7.399999999999965, 18.799999999999997, -18.39999999999975, -329.8, -341.19999999999993, 13.699999999999964, -28.29999999999975, -33.099999999999774, -18.99999999999983, -54.39999999999985, -73.00000000000072, 15.799999999999963, -19.59999999999995, 20.300000000000022, 7.399999999999965, -10.59999999999985, 17.899999999999988, -14.799999999999764, 20.000000000000014, 15.799999999999963, -36.699999999999754, -8.199999999999887, 12.499999999999968, 11.599999999999964, -21.999999999999794, -1.3000000000000136, 20.000000000000014, 11.599999999999964, 20.000000000000014, -25.899999999999757, 1.0999999999999865], "policy_predator_policy_reward": [42.0, 26.0, 0.0, 5.0, 16.0, 36.0, 30.0, 14.0, 8.0, 3.0, 42.0, 41.0, 17.0, 19.0, 22.0, 11.0, 27.0, 38.0, 31.0, 18.0, 46.0, 21.0, 28.0, 16.0, 21.0, 11.0, 20.0, 20.0, 27.0, 20.0, 25.0, 30.0, 29.0, 21.0, 29.0, 0.0, 45.0, 78.0, 50.0, 64.0, 1.0, 18.0, 20.0, 18.0, 33.0, 40.0, 5.0, 91.0, 10.0, 2.0, 25.0, 28.0, 22.0, 13.0, 15.0, 20.0, 37.0, 29.0, 13.0, 16.0, 82.0, 25.0, 29.0, 24.0, 13.0, 1.0, 29.0, 123.0, 10.0, 8.0, 14.0, 6.0, 27.0, 8.0, 24.0, 15.0, 29.0, 44.0, 58.0, 15.0, 5.0, 8.0, 2.0, 57.0, 19.0, 8.0, 43.0, 25.0, 10.0, 4.0, 4.0, 46.0, 3.0, 6.0, 26.0, 20.0, 18.0, 8.0, 21.0, 33.0, 26.0, 24.0, 6.0, 7.0, 17.0, 12.0, 19.0, 5.0, 23.0, 21.0, 0.0, 0.0, 19.0, 28.0, 31.0, 21.0, 46.0, 53.0, 148.0, 33.0, 17.0, 18.0, 20.0, 24.0, 150.0, 19.0, 3.0, 15.0, 19.0, 13.0, 39.0, 11.0, 0.0, 10.0, 2.0, 0.0, 3.0, 1.0, 36.0, 42.0, 177.0, 197.0, 9.0, 17.0, 68.0, 6.0, 7.0, 8.0, 24.0, 24.0, 16.0, 17.0, 13.0, 29.0, 12.0, 61.0, 24.0, 30.0, 9.0, 2.0, 31.0, 37.0, 95.0, 71.0, 2.0, 16.0, 13.0, 14.0, 4.0, 7.0, 20.0, 21.0, 3.0, 188.0, 13.0, 20.0, 34.0, 41.0, 23.0, 74.0, 21.0, 9.0, 5.0, 3.0, 3.0, 17.0, 16.0, 13.0, 20.0, 19.0, 15.0, 16.0, 24.0, 8.0, 9.0, 16.0, 4.0, 0.0, 22.0, 19.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5937835222945069, "mean_inference_ms": 1.8353716548351893, "mean_action_processing_ms": 0.2602146433091172, "mean_env_wait_ms": 0.1998934868443446, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006046652793884277, "StateBufferConnector_ms": 0.003198385238647461, "ViewRequirementAgentConnector_ms": 0.09797310829162598}, "num_episodes": 18, "episode_return_max": 56.10000000000036, "episode_return_min": -480.0, "episode_return_mean": -11.133999999999812, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1888000, "num_agent_steps_trained": 1888000, "num_env_steps_sampled": 472000, "num_env_steps_trained": 472000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 351.6950057667218, "num_env_steps_trained_throughput_per_sec": 351.6950057667218, "timesteps_total": 472000, "num_env_steps_sampled_lifetime": 472000, "num_agent_steps_sampled_lifetime": 1888000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1888000, "timers": {"training_iteration_time_ms": 11077.787, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11077.745, "sample_time_ms": 1351.106, "learn_time_ms": 9709.688, "learn_throughput": 411.96, "synch_weights_time_ms": 15.596}, "counters": {"num_env_steps_sampled": 472000, "num_env_steps_trained": 472000, "num_agent_steps_sampled": 1888000, "num_agent_steps_trained": 1888000}, "done": false, "training_iteration": 118, "trial_id": "3dae5_00000", "date": "2024-08-14_09-28-35", "timestamp": 1723642115, "time_this_iter_s": 11.416253089904785, "time_total_s": 2933.5304782390594, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b364ed30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2933.5304782390594, "iterations_since_restore": 118, "perf": {"cpu_util_percent": 31.506249999999998, "ram_util_percent": 83.3375}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.156445410453453, "cur_kl_coeff": 6.866455078125002e-06, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.313177222770358, "policy_loss": -0.00453962027058301, "vf_loss": 1.3177168082623254, "vf_explained_var": 0.06271761327824264, "kl": 0.007520363461963475, "entropy": 0.5334236092668362, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 223965.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.6603746582591343, "cur_kl_coeff": 0.06328124999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.5653298835905771, "policy_loss": -0.00663428694384281, "vf_loss": 1.5713916028302812, "vf_explained_var": 0.010993441702827575, "kl": 0.009047991403219687, "entropy": 1.073041375005056, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 223965.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 476000, "num_env_steps_trained": 476000, "num_agent_steps_sampled": 1904000, "num_agent_steps_trained": 1904000}, "env_runners": {"episode_reward_max": 56.10000000000036, "episode_reward_min": -480.0, "episode_reward_mean": -11.010999999999818, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 36.20000000000025, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -29.765500000000003, "predator_policy": 24.26}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-94.99999999999996, 26.800000000000086, -9.89999999999964, 27.900000000000123, 28.800000000000125, 40.60000000000034, 8.100000000000131, -100.8000000000016, -15.299999999999535, 24.60000000000005, -276.29999999999643, 20.200000000000006, 30.600000000000158, 12.299999999999919, 2.500000000000185, -52.90000000000094, -43.59999999999992, 25.700000000000067, -24.899999999999537, -4.399999999999688, -0.29999999999991367, 24.60000000000005, -14.999999999999536, 42.700000000000344, -3.999999999999717, -9.599999999999598, 36.40000000000024, 56.10000000000036, 43.40000000000035, 13.500000000000027, 14.500000000000016, 29.100000000000144, 40.0000000000003, -1.4999999999997433, 12.200000000000045, -68.9000000000004, -294.99999999999727, 1.500000000000229, 37.80000000000026, -342.39999999999753, 22.90000000000002, 30.00000000000015, -23.399999999999523, 31.700000000000177, 37.80000000000027, 35.600000000000236, -3.799999999999745, -336.6, 38.10000000000027, -138.30000000000157, 33.1000000000002, 25.00000000000006, 8.200000000000117, -8.299999999999702, -109.60000000000167, 30.700000000000163, 33.90000000000022, 8.40000000000008, -152.80000000000047, 24.700000000000053, 35.500000000000234, 27.90000000000011, 41.400000000000325, -480.0, 18.39999999999996, 22.900000000000098, -30.399999999999665, 26.200000000000294, 35.70000000000022, 27.300000000000104, 34.200000000000216, 18.099999999999948, 35.30000000000023, 21.600000000000055, 43.700000000000365, 35.600000000000236, 16.199999999999978, 30.600000000000158, -5.099999999999724, 39.700000000000294, 35.90000000000024, -3.8999999999997312, 24.60000000000007, 37.50000000000026, 34.30000000000022, 35.40000000000023, 36.70000000000025, -2.3999999999997335, 23.50000000000003, 14.600000000000009, 39.800000000000296, 17.09999999999997, 34.50000000000022, 21.3, 19.699999999999985, -378.0, 34.00000000000021, 21.80000000000001, 23.90000000000004, 6.400000000000109], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-66.09999999999985, -124.90000000000066, -0.9999999999999846, 15.799999999999963, -82.90000000000086, 20.000000000000014, -27.099999999999767, 20.000000000000014, -24.099999999999746, 17.899999999999988, -13.299999999999834, -12.099999999999817, -7.299999999999891, -13.599999999999783, -70.30000000000055, -137.5000000000007, -44.499999999999766, -23.799999999999763, -7.299999999999894, 17.899999999999988, -192.10000000000056, -236.20000000000044, 3.1999999999999615, -0.9999999999999846, 20.000000000000014, -9.399999999999855, -38.49999999999978, 15.799999999999963, -9.399999999999855, -27.09999999999976, -55.59999999999988, -70.30000000000089, -25.299999999999777, -91.30000000000082, 9.499999999999964, 3.1999999999999615, 15.799999999999963, -99.70000000000081, -11.499999999999819, -19.899999999999743, -24.099999999999746, -44.199999999999775, 5.299999999999965, 5.299999999999967, -76.60000000000085, 11.599999999999964, 20.000000000000014, 13.699999999999964, -27.99999999999976, -21.999999999999744, -17.79999999999974, -17.79999999999974, 36.20000000000025, -53.800000000000196, -13.899999999999896, 20.000000000000014, 27.20000000000013, 3.1999999999999615, 0.19999999999998655, -15.699999999999747, -18.999999999999744, 9.499999999999966, 20.000000000000014, -34.899999999999764, 20.000000000000014, 20.000000000000014, -11.499999999999819, -36.99999999999976, 5.299999999999965, -45.09999999999976, -61.89999999999989, -106.0000000000008, -267.6999999999997, -208.30000000000032, -15.699999999999747, -17.79999999999974, 24.50000000000008, -30.699999999999754, -294.9999999999989, -216.40000000000032, -11.499999999999819, 16.399999999999967, 17.899999999999988, -19.899999999999743, -38.79999999999976, -34.59999999999976, 22.700000000000053, -0.9999999999999846, 17.899999999999988, 17.899999999999988, 13.699999999999964, 17.899999999999988, -87.10000000000085, 5.299999999999965, -316.9, -393.70000000000005, -15.699999999999747, 27.800000000000143, -103.9000000000008, -108.40000000000077, 8.599999999999968, 9.499999999999964, -30.39999999999975, 7.399999999999965, -13.599999999999783, -11.199999999999834, -11.49999999999989, -38.799999999999756, -85.00000000000085, -97.60000000000082, -43.29999999999978, 20.000000000000014, 21.80000000000004, 1.099999999999983, -72.40000000000089, 12.799999999999967, -208.0000000000004, -110.80000000000024, 20.300000000000022, -13.599999999999783, 20.000000000000014, -11.499999999999819, 9.499999999999966, 7.399999999999965, 18.799999999999997, -18.39999999999975, -329.8, -341.19999999999993, 13.699999999999964, -28.29999999999975, -33.099999999999774, -18.99999999999983, -54.39999999999985, -73.00000000000072, 15.799999999999963, -19.59999999999995, 20.300000000000022, 7.399999999999965, -10.59999999999985, 17.899999999999988, -14.799999999999764, 20.000000000000014, 15.799999999999963, -36.699999999999754, -8.199999999999887, 12.499999999999968, 11.599999999999964, -21.999999999999794, -1.3000000000000136, 20.000000000000014, 11.599999999999964, 20.000000000000014, -25.899999999999757, 1.0999999999999865, -9.399999999999855, 20.000000000000014, 13.699999999999964, -59.800000000000196, 17.899999999999988, 3.7999999999999656, 15.199999999999966, 13.699999999999964, -24.699999999999754, -32.19999999999976, -9.39999999999989, 20.000000000000014, 17.899999999999984, 11.599999999999964, -32.49999999999975, 30.8000000000002, 20.000000000000014, 7.399999999999965, 13.699999999999964, 20.000000000000014, -5.1999999999999265, -26.199999999999747, -5.1999999999999265, 13.699999999999964, -0.9999999999999846, -24.39999999999975, 15.799999999999963, 20.000000000000014, 1.09999999999996, -0.9999999999999881, -11.499999999999819, 20.000000000000014, -5.1999999999999265, 9.499999999999964, -4.899999999999942, -0.39999999999999936, -355.0, -400.0, -0.9999999999999846, 20.000000000000014, -9.399999999999855, 3.1999999999999615, 2.599999999999961, -3.6999999999999584, 20.000000000000014, -46.59999999999977], "policy_predator_policy_reward": [5.0, 91.0, 10.0, 2.0, 25.0, 28.0, 22.0, 13.0, 15.0, 20.0, 37.0, 29.0, 13.0, 16.0, 82.0, 25.0, 29.0, 24.0, 13.0, 1.0, 29.0, 123.0, 10.0, 8.0, 14.0, 6.0, 27.0, 8.0, 24.0, 15.0, 29.0, 44.0, 58.0, 15.0, 5.0, 8.0, 2.0, 57.0, 19.0, 8.0, 43.0, 25.0, 10.0, 4.0, 4.0, 46.0, 3.0, 6.0, 26.0, 20.0, 18.0, 8.0, 21.0, 33.0, 26.0, 24.0, 6.0, 7.0, 17.0, 12.0, 19.0, 5.0, 23.0, 21.0, 0.0, 0.0, 19.0, 28.0, 31.0, 21.0, 46.0, 53.0, 148.0, 33.0, 17.0, 18.0, 20.0, 24.0, 150.0, 19.0, 3.0, 15.0, 19.0, 13.0, 39.0, 11.0, 0.0, 10.0, 2.0, 0.0, 3.0, 1.0, 36.0, 42.0, 177.0, 197.0, 9.0, 17.0, 68.0, 6.0, 7.0, 8.0, 24.0, 24.0, 16.0, 17.0, 13.0, 29.0, 12.0, 61.0, 24.0, 30.0, 9.0, 2.0, 31.0, 37.0, 95.0, 71.0, 2.0, 16.0, 13.0, 14.0, 4.0, 7.0, 20.0, 21.0, 3.0, 188.0, 13.0, 20.0, 34.0, 41.0, 23.0, 74.0, 21.0, 9.0, 5.0, 3.0, 3.0, 17.0, 16.0, 13.0, 20.0, 19.0, 15.0, 16.0, 24.0, 8.0, 9.0, 16.0, 4.0, 0.0, 22.0, 19.0, 6.0, 14.0, 38.0, 3.0, 9.0, 9.0, 4.0, 3.0, 27.0, 26.0, 13.0, 1.0, 4.0, 4.0, 20.0, 16.0, 2.0, 6.0, 3.0, 0.0, 7.0, 22.0, 12.0, 3.0, 18.0, 22.0, 2.0, 2.0, 12.0, 5.0, 11.0, 15.0, 5.0, 12.0, 15.0, 10.0, 200.0, 177.0, 10.0, 5.0, 14.0, 14.0, 13.0, 12.0, 25.0, 8.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5932636645528061, "mean_inference_ms": 1.8339433640403175, "mean_action_processing_ms": 0.2598840911533759, "mean_env_wait_ms": 0.1996619912981333, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005834341049194336, "StateBufferConnector_ms": 0.0036771297454833984, "ViewRequirementAgentConnector_ms": 0.09762251377105713}, "num_episodes": 23, "episode_return_max": 56.10000000000036, "episode_return_min": -480.0, "episode_return_mean": -11.010999999999818, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1904000, "num_agent_steps_trained": 1904000, "num_env_steps_sampled": 476000, "num_env_steps_trained": 476000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 367.71681264794535, "num_env_steps_trained_throughput_per_sec": 367.71681264794535, "timesteps_total": 476000, "num_env_steps_sampled_lifetime": 476000, "num_agent_steps_sampled_lifetime": 1904000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1904000, "timers": {"training_iteration_time_ms": 11008.771, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11008.73, "sample_time_ms": 1297.329, "learn_time_ms": 9694.7, "learn_throughput": 412.597, "synch_weights_time_ms": 15.474}, "counters": {"num_env_steps_sampled": 476000, "num_env_steps_trained": 476000, "num_agent_steps_sampled": 1904000, "num_agent_steps_trained": 1904000}, "done": false, "training_iteration": 119, "trial_id": "3dae5_00000", "date": "2024-08-14_09-28-46", "timestamp": 1723642126, "time_this_iter_s": 10.8839590549469, "time_total_s": 2944.4144372940063, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b36b4ee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2944.4144372940063, "iterations_since_restore": 119, "perf": {"cpu_util_percent": 27.74375, "ram_util_percent": 83.475}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.105122152333537, "cur_kl_coeff": 6.866455078125002e-06, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.525984972463083, "policy_loss": -0.0032110509271708826, "vf_loss": 1.5291960010452876, "vf_explained_var": 0.08731963956166827, "kl": 0.006804085058718695, "entropy": 0.5996060627320456, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 225855.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.0007841822016177, "cur_kl_coeff": 0.06328124999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.561710248043928, "policy_loss": -0.006522050056921899, "vf_loss": 2.567586137062658, "vf_explained_var": 0.007064763641862011, "kl": 0.010210994275382803, "entropy": 1.0453653158649565, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 225855.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 480000, "num_env_steps_trained": 480000, "num_agent_steps_sampled": 1920000, "num_agent_steps_trained": 1920000}, "env_runners": {"episode_reward_max": 56.10000000000036, "episode_reward_min": -579.4, "episode_reward_mean": -16.129999999999864, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 36.20000000000025, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -31.734999999999992, "predator_policy": 23.67}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-14.999999999999536, 42.700000000000344, -3.999999999999717, -9.599999999999598, 36.40000000000024, 56.10000000000036, 43.40000000000035, 13.500000000000027, 14.500000000000016, 29.100000000000144, 40.0000000000003, -1.4999999999997433, 12.200000000000045, -68.9000000000004, -294.99999999999727, 1.500000000000229, 37.80000000000026, -342.39999999999753, 22.90000000000002, 30.00000000000015, -23.399999999999523, 31.700000000000177, 37.80000000000027, 35.600000000000236, -3.799999999999745, -336.6, 38.10000000000027, -138.30000000000157, 33.1000000000002, 25.00000000000006, 8.200000000000117, -8.299999999999702, -109.60000000000167, 30.700000000000163, 33.90000000000022, 8.40000000000008, -152.80000000000047, 24.700000000000053, 35.500000000000234, 27.90000000000011, 41.400000000000325, -480.0, 18.39999999999996, 22.900000000000098, -30.399999999999665, 26.200000000000294, 35.70000000000022, 27.300000000000104, 34.200000000000216, 18.099999999999948, 35.30000000000023, 21.600000000000055, 43.700000000000365, 35.600000000000236, 16.199999999999978, 30.600000000000158, -5.099999999999724, 39.700000000000294, 35.90000000000024, -3.8999999999997312, 24.60000000000007, 37.50000000000026, 34.30000000000022, 35.40000000000023, 36.70000000000025, -2.3999999999997335, 23.50000000000003, 14.600000000000009, 39.800000000000296, 17.09999999999997, 34.50000000000022, 21.3, 19.699999999999985, -378.0, 34.00000000000021, 21.80000000000001, 23.90000000000004, 6.400000000000109, 26.000000000000128, 36.30000000000024, 33.400000000000205, 39.800000000000296, 38.70000000000028, -49.2000000000007, -6.79999999999975, -485.3000000000002, -63.10000000000172, 14.699999999999994, 35.10000000000023, 39.00000000000028, 39.90000000000029, 11.899999999999967, -21.89999999999951, -114.00000000000102, 31.200000000000163, 31.200000000000163, 29.200000000000127, 35.70000000000024, -579.4, 15.000000000000014], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-76.60000000000085, 11.599999999999964, 20.000000000000014, 13.699999999999964, -27.99999999999976, -21.999999999999744, -17.79999999999974, -17.79999999999974, 36.20000000000025, -53.800000000000196, -13.899999999999896, 20.000000000000014, 27.20000000000013, 3.1999999999999615, 0.19999999999998655, -15.699999999999747, -18.999999999999744, 9.499999999999966, 20.000000000000014, -34.899999999999764, 20.000000000000014, 20.000000000000014, -11.499999999999819, -36.99999999999976, 5.299999999999965, -45.09999999999976, -61.89999999999989, -106.0000000000008, -267.6999999999997, -208.30000000000032, -15.699999999999747, -17.79999999999974, 24.50000000000008, -30.699999999999754, -294.9999999999989, -216.40000000000032, -11.499999999999819, 16.399999999999967, 17.899999999999988, -19.899999999999743, -38.79999999999976, -34.59999999999976, 22.700000000000053, -0.9999999999999846, 17.899999999999988, 17.899999999999988, 13.699999999999964, 17.899999999999988, -87.10000000000085, 5.299999999999965, -316.9, -393.70000000000005, -15.699999999999747, 27.800000000000143, -103.9000000000008, -108.40000000000077, 8.599999999999968, 9.499999999999964, -30.39999999999975, 7.399999999999965, -13.599999999999783, -11.199999999999834, -11.49999999999989, -38.799999999999756, -85.00000000000085, -97.60000000000082, -43.29999999999978, 20.000000000000014, 21.80000000000004, 1.099999999999983, -72.40000000000089, 12.799999999999967, -208.0000000000004, -110.80000000000024, 20.300000000000022, -13.599999999999783, 20.000000000000014, -11.499999999999819, 9.499999999999966, 7.399999999999965, 18.799999999999997, -18.39999999999975, -329.8, -341.19999999999993, 13.699999999999964, -28.29999999999975, -33.099999999999774, -18.99999999999983, -54.39999999999985, -73.00000000000072, 15.799999999999963, -19.59999999999995, 20.300000000000022, 7.399999999999965, -10.59999999999985, 17.899999999999988, -14.799999999999764, 20.000000000000014, 15.799999999999963, -36.699999999999754, -8.199999999999887, 12.499999999999968, 11.599999999999964, -21.999999999999794, -1.3000000000000136, 20.000000000000014, 11.599999999999964, 20.000000000000014, -25.899999999999757, 1.0999999999999865, -9.399999999999855, 20.000000000000014, 13.699999999999964, -59.800000000000196, 17.899999999999988, 3.7999999999999656, 15.199999999999966, 13.699999999999964, -24.699999999999754, -32.19999999999976, -9.39999999999989, 20.000000000000014, 17.899999999999984, 11.599999999999964, -32.49999999999975, 30.8000000000002, 20.000000000000014, 7.399999999999965, 13.699999999999964, 20.000000000000014, -5.1999999999999265, -26.199999999999747, -5.1999999999999265, 13.699999999999964, -0.9999999999999846, -24.39999999999975, 15.799999999999963, 20.000000000000014, 1.09999999999996, -0.9999999999999881, -11.499999999999819, 20.000000000000014, -5.1999999999999265, 9.499999999999964, -4.899999999999942, -0.39999999999999936, -355.0, -400.0, -0.9999999999999846, 20.000000000000014, -9.399999999999855, 3.1999999999999615, 2.599999999999961, -3.6999999999999584, 20.000000000000014, -46.59999999999977, -18.999999999999883, 20.000000000000014, 11.599999999999964, -10.299999999999851, 15.799999999999963, 11.599999999999964, 6.799999999999967, 20.000000000000014, 20.000000000000014, 13.699999999999966, -38.19999999999976, -64.00000000000085, -28.29999999999975, -11.499999999999996, -316.00000000000017, -385.3, -47.19999999999977, -76.90000000000086, 17.899999999999988, -26.199999999999747, 20.000000000000014, 7.099999999999966, 7.999999999999972, 20.000000000000014, 20.000000000000014, -6.099999999999923, 13.699999999999964, -29.799999999999756, -11.499999999999819, -51.39999999999977, -261.4000000000003, 7.399999999999965, 15.799999999999963, 7.399999999999965, 11.599999999999964, 11.599999999999964, 11.599999999999964, 11.599999999999964, 15.799999999999963, 17.899999999999988, -400.0, -387.4, -11.499999999999819, 9.499999999999964], "policy_predator_policy_reward": [4.0, 46.0, 3.0, 6.0, 26.0, 20.0, 18.0, 8.0, 21.0, 33.0, 26.0, 24.0, 6.0, 7.0, 17.0, 12.0, 19.0, 5.0, 23.0, 21.0, 0.0, 0.0, 19.0, 28.0, 31.0, 21.0, 46.0, 53.0, 148.0, 33.0, 17.0, 18.0, 20.0, 24.0, 150.0, 19.0, 3.0, 15.0, 19.0, 13.0, 39.0, 11.0, 0.0, 10.0, 2.0, 0.0, 3.0, 1.0, 36.0, 42.0, 177.0, 197.0, 9.0, 17.0, 68.0, 6.0, 7.0, 8.0, 24.0, 24.0, 16.0, 17.0, 13.0, 29.0, 12.0, 61.0, 24.0, 30.0, 9.0, 2.0, 31.0, 37.0, 95.0, 71.0, 2.0, 16.0, 13.0, 14.0, 4.0, 7.0, 20.0, 21.0, 3.0, 188.0, 13.0, 20.0, 34.0, 41.0, 23.0, 74.0, 21.0, 9.0, 5.0, 3.0, 3.0, 17.0, 16.0, 13.0, 20.0, 19.0, 15.0, 16.0, 24.0, 8.0, 9.0, 16.0, 4.0, 0.0, 22.0, 19.0, 6.0, 14.0, 38.0, 3.0, 9.0, 9.0, 4.0, 3.0, 27.0, 26.0, 13.0, 1.0, 4.0, 4.0, 20.0, 16.0, 2.0, 6.0, 3.0, 0.0, 7.0, 22.0, 12.0, 3.0, 18.0, 22.0, 2.0, 2.0, 12.0, 5.0, 11.0, 15.0, 5.0, 12.0, 15.0, 10.0, 200.0, 177.0, 10.0, 5.0, 14.0, 14.0, 13.0, 12.0, 25.0, 8.0, 1.0, 24.0, 17.0, 18.0, 4.0, 2.0, 5.0, 8.0, 3.0, 2.0, 7.0, 46.0, 6.0, 27.0, 27.0, 189.0, 48.0, 13.0, 1.0, 22.0, 7.0, 1.0, 6.0, 5.0, 11.0, 15.0, 20.0, 8.0, 1.0, 40.0, 6.0, 134.0, 6.0, 2.0, 4.0, 4.0, 2.0, 4.0, 2.0, 0.0, 200.0, 8.0, 16.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5928565784437481, "mean_inference_ms": 1.8327316587504148, "mean_action_processing_ms": 0.2591841544401144, "mean_env_wait_ms": 0.19959631285520282, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005234718322753906, "StateBufferConnector_ms": 0.00370633602142334, "ViewRequirementAgentConnector_ms": 0.0987401008605957}, "num_episodes": 22, "episode_return_max": 56.10000000000036, "episode_return_min": -579.4, "episode_return_mean": -16.129999999999864, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1920000, "num_agent_steps_trained": 1920000, "num_env_steps_sampled": 480000, "num_env_steps_trained": 480000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 362.32577455666575, "num_env_steps_trained_throughput_per_sec": 362.32577455666575, "timesteps_total": 480000, "num_env_steps_sampled_lifetime": 480000, "num_agent_steps_sampled_lifetime": 1920000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1920000, "timers": {"training_iteration_time_ms": 11033.619, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11033.577, "sample_time_ms": 1289.049, "learn_time_ms": 9727.673, "learn_throughput": 411.198, "synch_weights_time_ms": 15.622}, "counters": {"num_env_steps_sampled": 480000, "num_env_steps_trained": 480000, "num_agent_steps_sampled": 1920000, "num_agent_steps_trained": 1920000}, "done": false, "training_iteration": 120, "trial_id": "3dae5_00000", "date": "2024-08-14_09-28-57", "timestamp": 1723642137, "time_this_iter_s": 11.1008620262146, "time_total_s": 2955.515299320221, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3662b80>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2955.515299320221, "iterations_since_restore": 120, "perf": {"cpu_util_percent": 28.006249999999998, "ram_util_percent": 83.61875}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8005202140757646, "cur_kl_coeff": 6.866455078125002e-06, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.4523668478090297, "policy_loss": -0.008823757529229162, "vf_loss": 1.4611901568988013, "vf_explained_var": 0.10140183965365092, "kl": 0.06466443929741754, "entropy": 0.6800189866275383, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 227745.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.5559215535562507, "cur_kl_coeff": 0.06328124999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.4123104197007637, "policy_loss": -0.005541905310749022, "vf_loss": 2.4173816935095207, "vf_explained_var": 0.005840472222635985, "kl": 0.007437266854445605, "entropy": 1.073122112050889, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 227745.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 484000, "num_env_steps_trained": 484000, "num_agent_steps_sampled": 1936000, "num_agent_steps_trained": 1936000}, "env_runners": {"episode_reward_max": 45.4000000000004, "episode_reward_min": -583.9, "episode_reward_mean": -22.16699999999995, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 30.8000000000002, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -34.4485, "predator_policy": 23.365}, "custom_metrics": {}, "hist_stats": {"episode_reward": [22.90000000000002, 30.00000000000015, -23.399999999999523, 31.700000000000177, 37.80000000000027, 35.600000000000236, -3.799999999999745, -336.6, 38.10000000000027, -138.30000000000157, 33.1000000000002, 25.00000000000006, 8.200000000000117, -8.299999999999702, -109.60000000000167, 30.700000000000163, 33.90000000000022, 8.40000000000008, -152.80000000000047, 24.700000000000053, 35.500000000000234, 27.90000000000011, 41.400000000000325, -480.0, 18.39999999999996, 22.900000000000098, -30.399999999999665, 26.200000000000294, 35.70000000000022, 27.300000000000104, 34.200000000000216, 18.099999999999948, 35.30000000000023, 21.600000000000055, 43.700000000000365, 35.600000000000236, 16.199999999999978, 30.600000000000158, -5.099999999999724, 39.700000000000294, 35.90000000000024, -3.8999999999997312, 24.60000000000007, 37.50000000000026, 34.30000000000022, 35.40000000000023, 36.70000000000025, -2.3999999999997335, 23.50000000000003, 14.600000000000009, 39.800000000000296, 17.09999999999997, 34.50000000000022, 21.3, 19.699999999999985, -378.0, 34.00000000000021, 21.80000000000001, 23.90000000000004, 6.400000000000109, 26.000000000000128, 36.30000000000024, 33.400000000000205, 39.800000000000296, 38.70000000000028, -49.2000000000007, -6.79999999999975, -485.3000000000002, -63.10000000000172, 14.699999999999994, 35.10000000000023, 39.00000000000028, 39.90000000000029, 11.899999999999967, -21.89999999999951, -114.00000000000102, 31.200000000000163, 31.200000000000163, 29.200000000000127, 35.70000000000024, -579.4, 15.000000000000014, -583.9, 45.4000000000004, 39.50000000000029, -32.599999999999525, -56.200000000000884, 36.60000000000025, -524.0, 30.500000000000167, 13.200000000000014, 25.700000000000067, 24.600000000000048, 38.300000000000274, -104.40000000000114, 2.6000000000002013, -26.099999999999525, 11.100000000000092, 15.799999999999923, 31.000000000000163], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-11.499999999999819, 16.399999999999967, 17.899999999999988, -19.899999999999743, -38.79999999999976, -34.59999999999976, 22.700000000000053, -0.9999999999999846, 17.899999999999988, 17.899999999999988, 13.699999999999964, 17.899999999999988, -87.10000000000085, 5.299999999999965, -316.9, -393.70000000000005, -15.699999999999747, 27.800000000000143, -103.9000000000008, -108.40000000000077, 8.599999999999968, 9.499999999999964, -30.39999999999975, 7.399999999999965, -13.599999999999783, -11.199999999999834, -11.49999999999989, -38.799999999999756, -85.00000000000085, -97.60000000000082, -43.29999999999978, 20.000000000000014, 21.80000000000004, 1.099999999999983, -72.40000000000089, 12.799999999999967, -208.0000000000004, -110.80000000000024, 20.300000000000022, -13.599999999999783, 20.000000000000014, -11.499999999999819, 9.499999999999966, 7.399999999999965, 18.799999999999997, -18.39999999999975, -329.8, -341.19999999999993, 13.699999999999964, -28.29999999999975, -33.099999999999774, -18.99999999999983, -54.39999999999985, -73.00000000000072, 15.799999999999963, -19.59999999999995, 20.300000000000022, 7.399999999999965, -10.59999999999985, 17.899999999999988, -14.799999999999764, 20.000000000000014, 15.799999999999963, -36.699999999999754, -8.199999999999887, 12.499999999999968, 11.599999999999964, -21.999999999999794, -1.3000000000000136, 20.000000000000014, 11.599999999999964, 20.000000000000014, -25.899999999999757, 1.0999999999999865, -9.399999999999855, 20.000000000000014, 13.699999999999964, -59.800000000000196, 17.899999999999988, 3.7999999999999656, 15.199999999999966, 13.699999999999964, -24.699999999999754, -32.19999999999976, -9.39999999999989, 20.000000000000014, 17.899999999999984, 11.599999999999964, -32.49999999999975, 30.8000000000002, 20.000000000000014, 7.399999999999965, 13.699999999999964, 20.000000000000014, -5.1999999999999265, -26.199999999999747, -5.1999999999999265, 13.699999999999964, -0.9999999999999846, -24.39999999999975, 15.799999999999963, 20.000000000000014, 1.09999999999996, -0.9999999999999881, -11.499999999999819, 20.000000000000014, -5.1999999999999265, 9.499999999999964, -4.899999999999942, -0.39999999999999936, -355.0, -400.0, -0.9999999999999846, 20.000000000000014, -9.399999999999855, 3.1999999999999615, 2.599999999999961, -3.6999999999999584, 20.000000000000014, -46.59999999999977, -18.999999999999883, 20.000000000000014, 11.599999999999964, -10.299999999999851, 15.799999999999963, 11.599999999999964, 6.799999999999967, 20.000000000000014, 20.000000000000014, 13.699999999999966, -38.19999999999976, -64.00000000000085, -28.29999999999975, -11.499999999999996, -316.00000000000017, -385.3, -47.19999999999977, -76.90000000000086, 17.899999999999988, -26.199999999999747, 20.000000000000014, 7.099999999999966, 7.999999999999972, 20.000000000000014, 20.000000000000014, -6.099999999999923, 13.699999999999964, -29.799999999999756, -11.499999999999819, -51.39999999999977, -261.4000000000003, 7.399999999999965, 15.799999999999963, 7.399999999999965, 11.599999999999964, 11.599999999999964, 11.599999999999964, 11.599999999999964, 15.799999999999963, 17.899999999999988, -400.0, -387.4, -11.499999999999819, 9.499999999999964, -400.0, -385.9, 29.900000000000187, 9.499999999999964, 17.899999999999988, 14.599999999999968, 3.1999999999999615, -101.80000000000081, -47.19999999999976, -70.00000000000077, 20.000000000000014, 11.599999999999964, -385.30000000000007, -339.7, -36.69999999999977, 3.1999999999999615, 11.599999999999964, -27.39999999999975, 11.599999999999964, 1.0999999999999865, -7.299999999999891, 17.899999999999988, 11.299999999999965, 20.000000000000014, -198.40000000000055, -21.999999999999975, -40.89999999999976, 9.499999999999964, -38.79999999999976, -28.299999999999763, 3.1999999999999615, -3.099999999999958, -24.099999999999746, 17.899999999999988, 15.799999999999963, 3.1999999999999615], "policy_predator_policy_reward": [3.0, 15.0, 19.0, 13.0, 39.0, 11.0, 0.0, 10.0, 2.0, 0.0, 3.0, 1.0, 36.0, 42.0, 177.0, 197.0, 9.0, 17.0, 68.0, 6.0, 7.0, 8.0, 24.0, 24.0, 16.0, 17.0, 13.0, 29.0, 12.0, 61.0, 24.0, 30.0, 9.0, 2.0, 31.0, 37.0, 95.0, 71.0, 2.0, 16.0, 13.0, 14.0, 4.0, 7.0, 20.0, 21.0, 3.0, 188.0, 13.0, 20.0, 34.0, 41.0, 23.0, 74.0, 21.0, 9.0, 5.0, 3.0, 3.0, 17.0, 16.0, 13.0, 20.0, 19.0, 15.0, 16.0, 24.0, 8.0, 9.0, 16.0, 4.0, 0.0, 22.0, 19.0, 6.0, 14.0, 38.0, 3.0, 9.0, 9.0, 4.0, 3.0, 27.0, 26.0, 13.0, 1.0, 4.0, 4.0, 20.0, 16.0, 2.0, 6.0, 3.0, 0.0, 7.0, 22.0, 12.0, 3.0, 18.0, 22.0, 2.0, 2.0, 12.0, 5.0, 11.0, 15.0, 5.0, 12.0, 15.0, 10.0, 200.0, 177.0, 10.0, 5.0, 14.0, 14.0, 13.0, 12.0, 25.0, 8.0, 1.0, 24.0, 17.0, 18.0, 4.0, 2.0, 5.0, 8.0, 3.0, 2.0, 7.0, 46.0, 6.0, 27.0, 27.0, 189.0, 48.0, 13.0, 1.0, 22.0, 7.0, 1.0, 6.0, 5.0, 11.0, 15.0, 20.0, 8.0, 1.0, 40.0, 6.0, 134.0, 6.0, 2.0, 4.0, 4.0, 2.0, 4.0, 2.0, 0.0, 200.0, 8.0, 16.0, 1.0, 200.0, 2.0, 5.0, 1.0, 1.0, 6.0, 58.0, 8.0, 52.0, 9.0, 1.0, 4.0, 1.0, 200.0, 31.0, 33.0, 17.0, 12.0, 4.0, 9.0, 2.0, 12.0, 2.0, 5.0, 68.0, 48.0, 4.0, 30.0, 5.0, 36.0, 0.0, 11.0, 21.0, 1.0, 4.0, 8.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5924265939384616, "mean_inference_ms": 1.8317972746879048, "mean_action_processing_ms": 0.2593712506943308, "mean_env_wait_ms": 0.1992998309398034, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004697322845458984, "StateBufferConnector_ms": 0.0036695003509521484, "ViewRequirementAgentConnector_ms": 0.09756338596343994}, "num_episodes": 18, "episode_return_max": 45.4000000000004, "episode_return_min": -583.9, "episode_return_mean": -22.16699999999995, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1936000, "num_agent_steps_trained": 1936000, "num_env_steps_sampled": 484000, "num_env_steps_trained": 484000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 348.31135939852965, "num_env_steps_trained_throughput_per_sec": 348.31135939852965, "timesteps_total": 484000, "num_env_steps_sampled_lifetime": 484000, "num_agent_steps_sampled_lifetime": 1936000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1936000, "timers": {"training_iteration_time_ms": 11079.059, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11079.018, "sample_time_ms": 1286.225, "learn_time_ms": 9775.998, "learn_throughput": 409.165, "synch_weights_time_ms": 15.439}, "counters": {"num_env_steps_sampled": 484000, "num_env_steps_trained": 484000, "num_agent_steps_sampled": 1936000, "num_agent_steps_trained": 1936000}, "done": false, "training_iteration": 121, "trial_id": "3dae5_00000", "date": "2024-08-14_09-29-09", "timestamp": 1723642149, "time_this_iter_s": 11.52943205833435, "time_total_s": 2967.0447313785553, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b394f5e0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2967.0447313785553, "iterations_since_restore": 121, "perf": {"cpu_util_percent": 32.681250000000006, "ram_util_percent": 83.51875}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.6045432611748023, "cur_kl_coeff": 1.02996826171875e-05, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.6676109297565684, "policy_loss": -0.004322988491273785, "vf_loss": 3.67193385053564, "vf_explained_var": 0.1283271280546037, "kl": 0.009753445436322991, "entropy": 0.8829336177104364, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 229635.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.131098400411152, "cur_kl_coeff": 0.06328124999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.555334379685619, "policy_loss": -0.007180079389807015, "vf_loss": 4.561875136188729, "vf_explained_var": 0.030064821874023116, "kl": 0.010102421006666073, "entropy": 1.1126700104229035, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 229635.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 488000, "num_env_steps_trained": 488000, "num_agent_steps_sampled": 1952000, "num_agent_steps_trained": 1952000}, "env_runners": {"episode_reward_max": 63.900000000000524, "episode_reward_min": -583.9, "episode_reward_mean": -31.56799999999993, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 38.000000000000256, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -43.20399999999999, "predator_policy": 27.42}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-152.80000000000047, 24.700000000000053, 35.500000000000234, 27.90000000000011, 41.400000000000325, -480.0, 18.39999999999996, 22.900000000000098, -30.399999999999665, 26.200000000000294, 35.70000000000022, 27.300000000000104, 34.200000000000216, 18.099999999999948, 35.30000000000023, 21.600000000000055, 43.700000000000365, 35.600000000000236, 16.199999999999978, 30.600000000000158, -5.099999999999724, 39.700000000000294, 35.90000000000024, -3.8999999999997312, 24.60000000000007, 37.50000000000026, 34.30000000000022, 35.40000000000023, 36.70000000000025, -2.3999999999997335, 23.50000000000003, 14.600000000000009, 39.800000000000296, 17.09999999999997, 34.50000000000022, 21.3, 19.699999999999985, -378.0, 34.00000000000021, 21.80000000000001, 23.90000000000004, 6.400000000000109, 26.000000000000128, 36.30000000000024, 33.400000000000205, 39.800000000000296, 38.70000000000028, -49.2000000000007, -6.79999999999975, -485.3000000000002, -63.10000000000172, 14.699999999999994, 35.10000000000023, 39.00000000000028, 39.90000000000029, 11.899999999999967, -21.89999999999951, -114.00000000000102, 31.200000000000163, 31.200000000000163, 29.200000000000127, 35.70000000000024, -579.4, 15.000000000000014, -583.9, 45.4000000000004, 39.50000000000029, -32.599999999999525, -56.200000000000884, 36.60000000000025, -524.0, 30.500000000000167, 13.200000000000014, 25.700000000000067, 24.600000000000048, 38.300000000000274, -104.40000000000114, 2.6000000000002013, -26.099999999999525, 11.100000000000092, 15.799999999999923, 31.000000000000163, -236.0000000000006, 44.60000000000037, -358.9, 3.4000000000001807, 44.00000000000037, -140.50000000000045, 53.40000000000045, 21.900000000000098, 25.70000000000007, -409.9000000000002, 29.000000000000124, 28.900000000000222, 35.80000000000024, 56.30000000000041, 17.599999999999998, -421.19999999999925, 63.900000000000524, -82.70000000000148], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-208.0000000000004, -110.80000000000024, 20.300000000000022, -13.599999999999783, 20.000000000000014, -11.499999999999819, 9.499999999999966, 7.399999999999965, 18.799999999999997, -18.39999999999975, -329.8, -341.19999999999993, 13.699999999999964, -28.29999999999975, -33.099999999999774, -18.99999999999983, -54.39999999999985, -73.00000000000072, 15.799999999999963, -19.59999999999995, 20.300000000000022, 7.399999999999965, -10.59999999999985, 17.899999999999988, -14.799999999999764, 20.000000000000014, 15.799999999999963, -36.699999999999754, -8.199999999999887, 12.499999999999968, 11.599999999999964, -21.999999999999794, -1.3000000000000136, 20.000000000000014, 11.599999999999964, 20.000000000000014, -25.899999999999757, 1.0999999999999865, -9.399999999999855, 20.000000000000014, 13.699999999999964, -59.800000000000196, 17.899999999999988, 3.7999999999999656, 15.199999999999966, 13.699999999999964, -24.699999999999754, -32.19999999999976, -9.39999999999989, 20.000000000000014, 17.899999999999984, 11.599999999999964, -32.49999999999975, 30.8000000000002, 20.000000000000014, 7.399999999999965, 13.699999999999964, 20.000000000000014, -5.1999999999999265, -26.199999999999747, -5.1999999999999265, 13.699999999999964, -0.9999999999999846, -24.39999999999975, 15.799999999999963, 20.000000000000014, 1.09999999999996, -0.9999999999999881, -11.499999999999819, 20.000000000000014, -5.1999999999999265, 9.499999999999964, -4.899999999999942, -0.39999999999999936, -355.0, -400.0, -0.9999999999999846, 20.000000000000014, -9.399999999999855, 3.1999999999999615, 2.599999999999961, -3.6999999999999584, 20.000000000000014, -46.59999999999977, -18.999999999999883, 20.000000000000014, 11.599999999999964, -10.299999999999851, 15.799999999999963, 11.599999999999964, 6.799999999999967, 20.000000000000014, 20.000000000000014, 13.699999999999966, -38.19999999999976, -64.00000000000085, -28.29999999999975, -11.499999999999996, -316.00000000000017, -385.3, -47.19999999999977, -76.90000000000086, 17.899999999999988, -26.199999999999747, 20.000000000000014, 7.099999999999966, 7.999999999999972, 20.000000000000014, 20.000000000000014, -6.099999999999923, 13.699999999999964, -29.799999999999756, -11.499999999999819, -51.39999999999977, -261.4000000000003, 7.399999999999965, 15.799999999999963, 7.399999999999965, 11.599999999999964, 11.599999999999964, 11.599999999999964, 11.599999999999964, 15.799999999999963, 17.899999999999988, -400.0, -387.4, -11.499999999999819, 9.499999999999964, -400.0, -385.9, 29.900000000000187, 9.499999999999964, 17.899999999999988, 14.599999999999968, 3.1999999999999615, -101.80000000000081, -47.19999999999976, -70.00000000000077, 20.000000000000014, 11.599999999999964, -385.30000000000007, -339.7, -36.69999999999977, 3.1999999999999615, 11.599999999999964, -27.39999999999975, 11.599999999999964, 1.0999999999999865, -7.299999999999891, 17.899999999999988, 11.299999999999965, 20.000000000000014, -198.40000000000055, -21.999999999999975, -40.89999999999976, 9.499999999999964, -38.79999999999976, -28.299999999999763, 3.1999999999999615, -3.099999999999958, -24.099999999999746, 17.899999999999988, 15.799999999999963, 3.1999999999999615, -194.8000000000002, -236.20000000000044, 5.299999999999965, 26.300000000000114, -346.9, -400.0, -51.399999999999814, 15.799999999999963, 20.000000000000014, 1.9999999999999607, 13.699999999999964, -383.1999999999998, 10.699999999999944, 25.700000000000184, -60.9999999999998, -3.099999999999958, -7.299999999999891, 20.000000000000014, -381.1, -332.8000000000002, 1.0999999999999865, 17.899999999999988, 3.4999999999999796, 7.399999999999947, 20.000000000000014, -5.1999999999999265, 3.4999999999999707, -26.199999999999747, -9.399999999999855, -0.9999999999999846, -288.6999999999997, -347.49999999999966, 23.900000000000073, 38.000000000000256, -141.7000000000007, -85.00000000000034], "policy_predator_policy_reward": [95.0, 71.0, 2.0, 16.0, 13.0, 14.0, 4.0, 7.0, 20.0, 21.0, 3.0, 188.0, 13.0, 20.0, 34.0, 41.0, 23.0, 74.0, 21.0, 9.0, 5.0, 3.0, 3.0, 17.0, 16.0, 13.0, 20.0, 19.0, 15.0, 16.0, 24.0, 8.0, 9.0, 16.0, 4.0, 0.0, 22.0, 19.0, 6.0, 14.0, 38.0, 3.0, 9.0, 9.0, 4.0, 3.0, 27.0, 26.0, 13.0, 1.0, 4.0, 4.0, 20.0, 16.0, 2.0, 6.0, 3.0, 0.0, 7.0, 22.0, 12.0, 3.0, 18.0, 22.0, 2.0, 2.0, 12.0, 5.0, 11.0, 15.0, 5.0, 12.0, 15.0, 10.0, 200.0, 177.0, 10.0, 5.0, 14.0, 14.0, 13.0, 12.0, 25.0, 8.0, 1.0, 24.0, 17.0, 18.0, 4.0, 2.0, 5.0, 8.0, 3.0, 2.0, 7.0, 46.0, 6.0, 27.0, 27.0, 189.0, 48.0, 13.0, 1.0, 22.0, 7.0, 1.0, 6.0, 5.0, 11.0, 15.0, 20.0, 8.0, 1.0, 40.0, 6.0, 134.0, 6.0, 2.0, 4.0, 4.0, 2.0, 4.0, 2.0, 0.0, 200.0, 8.0, 16.0, 1.0, 200.0, 2.0, 5.0, 1.0, 1.0, 6.0, 58.0, 8.0, 52.0, 9.0, 1.0, 4.0, 1.0, 200.0, 31.0, 33.0, 17.0, 12.0, 4.0, 9.0, 2.0, 12.0, 2.0, 5.0, 68.0, 48.0, 4.0, 30.0, 5.0, 36.0, 0.0, 11.0, 21.0, 1.0, 4.0, 8.0, 166.0, 29.0, 7.0, 6.0, 188.0, 200.0, 34.0, 5.0, 11.0, 11.0, 37.0, 192.0, 12.0, 5.0, 43.0, 43.0, 0.0, 13.0, 113.0, 191.0, 1.0, 9.0, 2.0, 16.0, 12.0, 9.0, 43.0, 36.0, 14.0, 14.0, 23.0, 192.0, 2.0, 0.0, 55.0, 89.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5920900458904069, "mean_inference_ms": 1.8306913585398796, "mean_action_processing_ms": 0.2591136729808843, "mean_env_wait_ms": 0.19915912247615136, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004362225532531738, "StateBufferConnector_ms": 0.003716111183166504, "ViewRequirementAgentConnector_ms": 0.10127055644989014}, "num_episodes": 18, "episode_return_max": 63.900000000000524, "episode_return_min": -583.9, "episode_return_mean": -31.56799999999993, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1952000, "num_agent_steps_trained": 1952000, "num_env_steps_sampled": 488000, "num_env_steps_trained": 488000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 355.22874545904534, "num_env_steps_trained_throughput_per_sec": 355.22874545904534, "timesteps_total": 488000, "num_env_steps_sampled_lifetime": 488000, "num_agent_steps_sampled_lifetime": 1952000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1952000, "timers": {"training_iteration_time_ms": 11128.303, "restore_workers_time_ms": 0.013, "training_step_time_ms": 11128.261, "sample_time_ms": 1289.46, "learn_time_ms": 9822.048, "learn_throughput": 407.247, "synch_weights_time_ms": 15.409}, "counters": {"num_env_steps_sampled": 488000, "num_env_steps_trained": 488000, "num_agent_steps_sampled": 1952000, "num_agent_steps_trained": 1952000}, "done": false, "training_iteration": 122, "trial_id": "3dae5_00000", "date": "2024-08-14_09-29-20", "timestamp": 1723642160, "time_this_iter_s": 11.286303043365479, "time_total_s": 2978.331034421921, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b36e0670>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2978.331034421921, "iterations_since_restore": 122, "perf": {"cpu_util_percent": 32.1875, "ram_util_percent": 83.58125}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.5311330488119177, "cur_kl_coeff": 1.02996826171875e-05, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.6567438200037317, "policy_loss": -0.0032619404659493183, "vf_loss": 3.6600056865227915, "vf_explained_var": 0.10774455527779918, "kl": 0.010951396639714757, "entropy": 0.8533043745648924, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 231525.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.6817850300243924, "cur_kl_coeff": 0.06328124999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.785737263714826, "policy_loss": -0.008246649596987973, "vf_loss": 4.793160651474403, "vf_explained_var": 0.026081151810903397, "kl": 0.013009728889905085, "entropy": 1.0446110782484528, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 231525.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 492000, "num_env_steps_trained": 492000, "num_agent_steps_sampled": 1968000, "num_agent_steps_trained": 1968000}, "env_runners": {"episode_reward_max": 63.900000000000524, "episode_reward_min": -583.9, "episode_reward_mean": -40.46799999999994, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 38.000000000000256, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -49.624, "predator_policy": 29.39}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-3.8999999999997312, 24.60000000000007, 37.50000000000026, 34.30000000000022, 35.40000000000023, 36.70000000000025, -2.3999999999997335, 23.50000000000003, 14.600000000000009, 39.800000000000296, 17.09999999999997, 34.50000000000022, 21.3, 19.699999999999985, -378.0, 34.00000000000021, 21.80000000000001, 23.90000000000004, 6.400000000000109, 26.000000000000128, 36.30000000000024, 33.400000000000205, 39.800000000000296, 38.70000000000028, -49.2000000000007, -6.79999999999975, -485.3000000000002, -63.10000000000172, 14.699999999999994, 35.10000000000023, 39.00000000000028, 39.90000000000029, 11.899999999999967, -21.89999999999951, -114.00000000000102, 31.200000000000163, 31.200000000000163, 29.200000000000127, 35.70000000000024, -579.4, 15.000000000000014, -583.9, 45.4000000000004, 39.50000000000029, -32.599999999999525, -56.200000000000884, 36.60000000000025, -524.0, 30.500000000000167, 13.200000000000014, 25.700000000000067, 24.600000000000048, 38.300000000000274, -104.40000000000114, 2.6000000000002013, -26.099999999999525, 11.100000000000092, 15.799999999999923, 31.000000000000163, -236.0000000000006, 44.60000000000037, -358.9, 3.4000000000001807, 44.00000000000037, -140.50000000000045, 53.40000000000045, 21.900000000000098, 25.70000000000007, -409.9000000000002, 29.000000000000124, 28.900000000000222, 35.80000000000024, 56.30000000000041, 17.599999999999998, -421.19999999999925, 63.900000000000524, -82.70000000000148, 30.100000000000218, -37.49999999999958, -536.6, 10.699999999999958, 32.00000000000018, -79.69999999999976, 32.00000000000029, 3.399999999999933, 16.799999999999923, 24.400000000000045, -324.99999999999994, 34.50000000000029, -30.499999999999538, -10.899999999999846, 14.199999999999939, -276.3000000000004, -28.80000000000004, 24.60000000000014, 31.300000000000175, 37.30000000000026, 2.900000000000014, 13.899999999999919, 29.8000000000002], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-24.699999999999754, -32.19999999999976, -9.39999999999989, 20.000000000000014, 17.899999999999984, 11.599999999999964, -32.49999999999975, 30.8000000000002, 20.000000000000014, 7.399999999999965, 13.699999999999964, 20.000000000000014, -5.1999999999999265, -26.199999999999747, -5.1999999999999265, 13.699999999999964, -0.9999999999999846, -24.39999999999975, 15.799999999999963, 20.000000000000014, 1.09999999999996, -0.9999999999999881, -11.499999999999819, 20.000000000000014, -5.1999999999999265, 9.499999999999964, -4.899999999999942, -0.39999999999999936, -355.0, -400.0, -0.9999999999999846, 20.000000000000014, -9.399999999999855, 3.1999999999999615, 2.599999999999961, -3.6999999999999584, 20.000000000000014, -46.59999999999977, -18.999999999999883, 20.000000000000014, 11.599999999999964, -10.299999999999851, 15.799999999999963, 11.599999999999964, 6.799999999999967, 20.000000000000014, 20.000000000000014, 13.699999999999966, -38.19999999999976, -64.00000000000085, -28.29999999999975, -11.499999999999996, -316.00000000000017, -385.3, -47.19999999999977, -76.90000000000086, 17.899999999999988, -26.199999999999747, 20.000000000000014, 7.099999999999966, 7.999999999999972, 20.000000000000014, 20.000000000000014, -6.099999999999923, 13.699999999999964, -29.799999999999756, -11.499999999999819, -51.39999999999977, -261.4000000000003, 7.399999999999965, 15.799999999999963, 7.399999999999965, 11.599999999999964, 11.599999999999964, 11.599999999999964, 11.599999999999964, 15.799999999999963, 17.899999999999988, -400.0, -387.4, -11.499999999999819, 9.499999999999964, -400.0, -385.9, 29.900000000000187, 9.499999999999964, 17.899999999999988, 14.599999999999968, 3.1999999999999615, -101.80000000000081, -47.19999999999976, -70.00000000000077, 20.000000000000014, 11.599999999999964, -385.30000000000007, -339.7, -36.69999999999977, 3.1999999999999615, 11.599999999999964, -27.39999999999975, 11.599999999999964, 1.0999999999999865, -7.299999999999891, 17.899999999999988, 11.299999999999965, 20.000000000000014, -198.40000000000055, -21.999999999999975, -40.89999999999976, 9.499999999999964, -38.79999999999976, -28.299999999999763, 3.1999999999999615, -3.099999999999958, -24.099999999999746, 17.899999999999988, 15.799999999999963, 3.1999999999999615, -194.8000000000002, -236.20000000000044, 5.299999999999965, 26.300000000000114, -346.9, -400.0, -51.399999999999814, 15.799999999999963, 20.000000000000014, 1.9999999999999607, 13.699999999999964, -383.1999999999998, 10.699999999999944, 25.700000000000184, -60.9999999999998, -3.099999999999958, -7.299999999999891, 20.000000000000014, -381.1, -332.8000000000002, 1.0999999999999865, 17.899999999999988, 3.4999999999999796, 7.399999999999947, 20.000000000000014, -5.1999999999999265, 3.4999999999999707, -26.199999999999747, -9.399999999999855, -0.9999999999999846, -288.6999999999997, -347.49999999999966, 23.900000000000073, 38.000000000000256, -141.7000000000007, -85.00000000000034, 11.599999999999946, 9.499999999999964, -47.199999999999804, -70.30000000000086, -340.6, -400.0, -47.799999999999784, -32.49999999999975, 17.899999999999977, 1.0999999999999865, -80.7999999999999, -82.89999999999988, 17.299999999999955, -13.300000000000042, 17.899999999999988, -53.499999999999915, -19.599999999999753, 10.399999999999965, -6.3999999999999435, 15.799999999999963, -246.6999999999999, -229.3, 11.599999999999964, 11.900000000000034, 9.499999999999964, -106.00000000000028, -9.400000000000034, -95.50000000000082, -9.399999999999961, -3.400000000000051, -271.3000000000002, -253.0000000000004, -108.39999999999986, 11.599999999999964, 1.0999999999999865, 9.49999999999996, -15.699999999999747, 20.000000000000014, 7.399999999999965, 20.90000000000003, -7.30000000000001, -17.79999999999994, 5.299999999999965, -18.400000000000023, -29.19999999999976, 20.000000000000014], "policy_predator_policy_reward": [27.0, 26.0, 13.0, 1.0, 4.0, 4.0, 20.0, 16.0, 2.0, 6.0, 3.0, 0.0, 7.0, 22.0, 12.0, 3.0, 18.0, 22.0, 2.0, 2.0, 12.0, 5.0, 11.0, 15.0, 5.0, 12.0, 15.0, 10.0, 200.0, 177.0, 10.0, 5.0, 14.0, 14.0, 13.0, 12.0, 25.0, 8.0, 1.0, 24.0, 17.0, 18.0, 4.0, 2.0, 5.0, 8.0, 3.0, 2.0, 7.0, 46.0, 6.0, 27.0, 27.0, 189.0, 48.0, 13.0, 1.0, 22.0, 7.0, 1.0, 6.0, 5.0, 11.0, 15.0, 20.0, 8.0, 1.0, 40.0, 6.0, 134.0, 6.0, 2.0, 4.0, 4.0, 2.0, 4.0, 2.0, 0.0, 200.0, 8.0, 16.0, 1.0, 200.0, 2.0, 5.0, 1.0, 1.0, 6.0, 58.0, 8.0, 52.0, 9.0, 1.0, 4.0, 1.0, 200.0, 31.0, 33.0, 17.0, 12.0, 4.0, 9.0, 2.0, 12.0, 2.0, 5.0, 68.0, 48.0, 4.0, 30.0, 5.0, 36.0, 0.0, 11.0, 21.0, 1.0, 4.0, 8.0, 166.0, 29.0, 7.0, 6.0, 188.0, 200.0, 34.0, 5.0, 11.0, 11.0, 37.0, 192.0, 12.0, 5.0, 43.0, 43.0, 0.0, 13.0, 113.0, 191.0, 1.0, 9.0, 2.0, 16.0, 12.0, 9.0, 43.0, 36.0, 14.0, 14.0, 23.0, 192.0, 2.0, 0.0, 55.0, 89.0, 7.0, 2.0, 18.0, 62.0, 200.0, 4.0, 40.0, 51.0, 9.0, 4.0, 23.0, 61.0, 15.0, 13.0, 33.0, 6.0, 18.0, 8.0, 13.0, 2.0, 133.0, 18.0, 8.0, 3.0, 44.0, 22.0, 55.0, 39.0, 14.0, 13.0, 139.0, 109.0, 16.0, 52.0, 11.0, 3.0, 11.0, 16.0, 3.0, 6.0, 10.0, 18.0, 10.0, 17.0, 17.0, 22.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5919033032214922, "mean_inference_ms": 1.8282967056498414, "mean_action_processing_ms": 0.2591711779471243, "mean_env_wait_ms": 0.19906033450472624, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004111051559448242, "StateBufferConnector_ms": 0.0036813020706176758, "ViewRequirementAgentConnector_ms": 0.10054326057434082}, "num_episodes": 23, "episode_return_max": 63.900000000000524, "episode_return_min": -583.9, "episode_return_mean": -40.46799999999994, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1968000, "num_agent_steps_trained": 1968000, "num_env_steps_sampled": 492000, "num_env_steps_trained": 492000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 357.6126617253505, "num_env_steps_trained_throughput_per_sec": 357.6126617253505, "timesteps_total": 492000, "num_env_steps_sampled_lifetime": 492000, "num_agent_steps_sampled_lifetime": 1968000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1968000, "timers": {"training_iteration_time_ms": 11114.424, "restore_workers_time_ms": 0.013, "training_step_time_ms": 11114.382, "sample_time_ms": 1289.671, "learn_time_ms": 9808.248, "learn_throughput": 407.82, "synch_weights_time_ms": 15.158}, "counters": {"num_env_steps_sampled": 492000, "num_env_steps_trained": 492000, "num_agent_steps_sampled": 1968000, "num_agent_steps_trained": 1968000}, "done": false, "training_iteration": 123, "trial_id": "3dae5_00000", "date": "2024-08-14_09-29-31", "timestamp": 1723642171, "time_this_iter_s": 11.217265844345093, "time_total_s": 2989.548300266266, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b38d5820>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2989.548300266266, "iterations_since_restore": 123, "perf": {"cpu_util_percent": 30.656249999999996, "ram_util_percent": 83.70625}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.265003351496641, "cur_kl_coeff": 1.02996826171875e-05, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.87427742998436, "policy_loss": -0.0036831084716444215, "vf_loss": 1.8779604045171587, "vf_explained_var": 0.17833941364414477, "kl": 0.013089388650942353, "entropy": 1.1626925230656981, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 233415.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.2312314647215383, "cur_kl_coeff": 0.06328124999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.387575847068161, "policy_loss": -0.003872007011958255, "vf_loss": 2.3911034198034375, "vf_explained_var": 0.025909819678654748, "kl": 0.00544293227366421, "entropy": 1.0462577051901945, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 233415.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 496000, "num_env_steps_trained": 496000, "num_agent_steps_sampled": 1984000, "num_agent_steps_trained": 1984000}, "env_runners": {"episode_reward_max": 63.900000000000524, "episode_reward_min": -583.9, "episode_reward_mean": -47.056999999999924, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 40.70000000000025, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -54.23349999999999, "predator_policy": 30.705}, "custom_metrics": {}, "hist_stats": {"episode_reward": [6.400000000000109, 26.000000000000128, 36.30000000000024, 33.400000000000205, 39.800000000000296, 38.70000000000028, -49.2000000000007, -6.79999999999975, -485.3000000000002, -63.10000000000172, 14.699999999999994, 35.10000000000023, 39.00000000000028, 39.90000000000029, 11.899999999999967, -21.89999999999951, -114.00000000000102, 31.200000000000163, 31.200000000000163, 29.200000000000127, 35.70000000000024, -579.4, 15.000000000000014, -583.9, 45.4000000000004, 39.50000000000029, -32.599999999999525, -56.200000000000884, 36.60000000000025, -524.0, 30.500000000000167, 13.200000000000014, 25.700000000000067, 24.600000000000048, 38.300000000000274, -104.40000000000114, 2.6000000000002013, -26.099999999999525, 11.100000000000092, 15.799999999999923, 31.000000000000163, -236.0000000000006, 44.60000000000037, -358.9, 3.4000000000001807, 44.00000000000037, -140.50000000000045, 53.40000000000045, 21.900000000000098, 25.70000000000007, -409.9000000000002, 29.000000000000124, 28.900000000000222, 35.80000000000024, 56.30000000000041, 17.599999999999998, -421.19999999999925, 63.900000000000524, -82.70000000000148, 30.100000000000218, -37.49999999999958, -536.6, 10.699999999999958, 32.00000000000018, -79.69999999999976, 32.00000000000029, 3.399999999999933, 16.799999999999923, 24.400000000000045, -324.99999999999994, 34.50000000000029, -30.499999999999538, -10.899999999999846, 14.199999999999939, -276.3000000000004, -28.80000000000004, 24.60000000000014, 31.300000000000175, 37.30000000000026, 2.900000000000014, 13.899999999999919, 29.8000000000002, -46.899999999999544, 24.600000000000048, 34.40000000000034, 34.30000000000034, -10.29999999999961, 17.79999999999998, 55.600000000000506, 33.2000000000002, -66.69999999999996, 10.400000000000082, -446.1000000000001, -62.00000000000165, 21.19999999999999, 17.89999999999994, 37.80000000000027, 38.90000000000028, -358.0999999999975, 39.500000000000284], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, -46.59999999999977, -18.999999999999883, 20.000000000000014, 11.599999999999964, -10.299999999999851, 15.799999999999963, 11.599999999999964, 6.799999999999967, 20.000000000000014, 20.000000000000014, 13.699999999999966, -38.19999999999976, -64.00000000000085, -28.29999999999975, -11.499999999999996, -316.00000000000017, -385.3, -47.19999999999977, -76.90000000000086, 17.899999999999988, -26.199999999999747, 20.000000000000014, 7.099999999999966, 7.999999999999972, 20.000000000000014, 20.000000000000014, -6.099999999999923, 13.699999999999964, -29.799999999999756, -11.499999999999819, -51.39999999999977, -261.4000000000003, 7.399999999999965, 15.799999999999963, 7.399999999999965, 11.599999999999964, 11.599999999999964, 11.599999999999964, 11.599999999999964, 15.799999999999963, 17.899999999999988, -400.0, -387.4, -11.499999999999819, 9.499999999999964, -400.0, -385.9, 29.900000000000187, 9.499999999999964, 17.899999999999988, 14.599999999999968, 3.1999999999999615, -101.80000000000081, -47.19999999999976, -70.00000000000077, 20.000000000000014, 11.599999999999964, -385.30000000000007, -339.7, -36.69999999999977, 3.1999999999999615, 11.599999999999964, -27.39999999999975, 11.599999999999964, 1.0999999999999865, -7.299999999999891, 17.899999999999988, 11.299999999999965, 20.000000000000014, -198.40000000000055, -21.999999999999975, -40.89999999999976, 9.499999999999964, -38.79999999999976, -28.299999999999763, 3.1999999999999615, -3.099999999999958, -24.099999999999746, 17.899999999999988, 15.799999999999963, 3.1999999999999615, -194.8000000000002, -236.20000000000044, 5.299999999999965, 26.300000000000114, -346.9, -400.0, -51.399999999999814, 15.799999999999963, 20.000000000000014, 1.9999999999999607, 13.699999999999964, -383.1999999999998, 10.699999999999944, 25.700000000000184, -60.9999999999998, -3.099999999999958, -7.299999999999891, 20.000000000000014, -381.1, -332.8000000000002, 1.0999999999999865, 17.899999999999988, 3.4999999999999796, 7.399999999999947, 20.000000000000014, -5.1999999999999265, 3.4999999999999707, -26.199999999999747, -9.399999999999855, -0.9999999999999846, -288.6999999999997, -347.49999999999966, 23.900000000000073, 38.000000000000256, -141.7000000000007, -85.00000000000034, 11.599999999999946, 9.499999999999964, -47.199999999999804, -70.30000000000086, -340.6, -400.0, -47.799999999999784, -32.49999999999975, 17.899999999999977, 1.0999999999999865, -80.7999999999999, -82.89999999999988, 17.299999999999955, -13.300000000000042, 17.899999999999988, -53.499999999999915, -19.599999999999753, 10.399999999999965, -6.3999999999999435, 15.799999999999963, -246.6999999999999, -229.3, 11.599999999999964, 11.900000000000034, 9.499999999999964, -106.00000000000028, -9.400000000000034, -95.50000000000082, -9.399999999999961, -3.400000000000051, -271.3000000000002, -253.0000000000004, -108.39999999999986, 11.599999999999964, 1.0999999999999865, 9.49999999999996, -15.699999999999747, 20.000000000000014, 7.399999999999965, 20.90000000000003, -7.30000000000001, -17.79999999999994, 5.299999999999965, -18.400000000000023, -29.19999999999976, 20.000000000000014, -69.40000000000019, -53.499999999999766, 3.1999999999999615, 7.399999999999965, 35.900000000000254, -32.49999999999975, 10.100000000000023, -29.799999999999756, -48.399999999999764, -19.899999999999743, 5.299999999999965, -29.49999999999975, 40.70000000000025, -24.099999999999746, 20.000000000000014, 3.1999999999999615, 15.799999999999963, -179.5, -13.599999999999783, -0.9999999999999917, -322.30000000000007, -350.80000000000007, -64.00000000000088, -64.00000000000091, 9.499999999999977, -7.299999999999891, 9.499999999999964, -16.59999999999976, 20.000000000000014, 15.799999999999963, 20.000000000000014, 17.899999999999988, -271.89999999999895, -257.19999999999936, -34.59999999999975, 28.100000000000147], "policy_predator_policy_reward": [25.0, 8.0, 1.0, 24.0, 17.0, 18.0, 4.0, 2.0, 5.0, 8.0, 3.0, 2.0, 7.0, 46.0, 6.0, 27.0, 27.0, 189.0, 48.0, 13.0, 1.0, 22.0, 7.0, 1.0, 6.0, 5.0, 11.0, 15.0, 20.0, 8.0, 1.0, 40.0, 6.0, 134.0, 6.0, 2.0, 4.0, 4.0, 2.0, 4.0, 2.0, 0.0, 200.0, 8.0, 16.0, 1.0, 200.0, 2.0, 5.0, 1.0, 1.0, 6.0, 58.0, 8.0, 52.0, 9.0, 1.0, 4.0, 1.0, 200.0, 31.0, 33.0, 17.0, 12.0, 4.0, 9.0, 2.0, 12.0, 2.0, 5.0, 68.0, 48.0, 4.0, 30.0, 5.0, 36.0, 0.0, 11.0, 21.0, 1.0, 4.0, 8.0, 166.0, 29.0, 7.0, 6.0, 188.0, 200.0, 34.0, 5.0, 11.0, 11.0, 37.0, 192.0, 12.0, 5.0, 43.0, 43.0, 0.0, 13.0, 113.0, 191.0, 1.0, 9.0, 2.0, 16.0, 12.0, 9.0, 43.0, 36.0, 14.0, 14.0, 23.0, 192.0, 2.0, 0.0, 55.0, 89.0, 7.0, 2.0, 18.0, 62.0, 200.0, 4.0, 40.0, 51.0, 9.0, 4.0, 23.0, 61.0, 15.0, 13.0, 33.0, 6.0, 18.0, 8.0, 13.0, 2.0, 133.0, 18.0, 8.0, 3.0, 44.0, 22.0, 55.0, 39.0, 14.0, 13.0, 139.0, 109.0, 16.0, 52.0, 11.0, 3.0, 11.0, 16.0, 3.0, 6.0, 10.0, 18.0, 10.0, 17.0, 17.0, 22.0, 53.0, 23.0, 6.0, 8.0, 20.0, 11.0, 29.0, 25.0, 24.0, 34.0, 24.0, 18.0, 21.0, 18.0, 2.0, 8.0, 95.0, 2.0, 9.0, 16.0, 189.0, 38.0, 44.0, 22.0, 4.0, 15.0, 5.0, 20.0, 2.0, 0.0, 0.0, 1.0, 154.0, 17.0, 22.0, 24.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5915079102609848, "mean_inference_ms": 1.8288524934704378, "mean_action_processing_ms": 0.2586060750007908, "mean_env_wait_ms": 0.19895177912633152, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0036488771438598633, "StateBufferConnector_ms": 0.003179788589477539, "ViewRequirementAgentConnector_ms": 0.0982292890548706}, "num_episodes": 18, "episode_return_max": 63.900000000000524, "episode_return_min": -583.9, "episode_return_mean": -47.056999999999924, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1984000, "num_agent_steps_trained": 1984000, "num_env_steps_sampled": 496000, "num_env_steps_trained": 496000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 365.61152441851254, "num_env_steps_trained_throughput_per_sec": 365.61152441851254, "timesteps_total": 496000, "num_env_steps_sampled_lifetime": 496000, "num_agent_steps_sampled_lifetime": 1984000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1984000, "timers": {"training_iteration_time_ms": 11092.628, "restore_workers_time_ms": 0.013, "training_step_time_ms": 11092.586, "sample_time_ms": 1282.152, "learn_time_ms": 9793.56, "learn_throughput": 408.432, "synch_weights_time_ms": 14.983}, "counters": {"num_env_steps_sampled": 496000, "num_env_steps_trained": 496000, "num_agent_steps_sampled": 1984000, "num_agent_steps_trained": 1984000}, "done": false, "training_iteration": 124, "trial_id": "3dae5_00000", "date": "2024-08-14_09-29-42", "timestamp": 1723642182, "time_this_iter_s": 10.97586703300476, "time_total_s": 3000.5241672992706, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3831160>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3000.5241672992706, "iterations_since_restore": 124, "perf": {"cpu_util_percent": 30.431250000000002, "ram_util_percent": 83.69999999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.2392501275690777, "cur_kl_coeff": 1.02996826171875e-05, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.8046965168897438, "policy_loss": -0.00840018909133813, "vf_loss": 1.8130964782818284, "vf_explained_var": 0.2235166654384956, "kl": 0.022572690936169933, "entropy": 1.0714093332883543, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 235305.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.993924379348755, "cur_kl_coeff": 0.06328124999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.2586281977475635, "policy_loss": -0.0062511558979552575, "vf_loss": 2.264371832905623, "vf_explained_var": 0.02016895157950265, "kl": 0.008019991529846473, "entropy": 1.05476765446562, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 235305.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 500000, "num_env_steps_trained": 500000, "num_agent_steps_sampled": 2000000, "num_agent_steps_trained": 2000000}, "env_runners": {"episode_reward_max": 63.900000000000524, "episode_reward_min": -583.9, "episode_reward_mean": -45.612999999999886, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 40.70000000000025, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -54.7915, "predator_policy": 31.985}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.000000000000014, -583.9, 45.4000000000004, 39.50000000000029, -32.599999999999525, -56.200000000000884, 36.60000000000025, -524.0, 30.500000000000167, 13.200000000000014, 25.700000000000067, 24.600000000000048, 38.300000000000274, -104.40000000000114, 2.6000000000002013, -26.099999999999525, 11.100000000000092, 15.799999999999923, 31.000000000000163, -236.0000000000006, 44.60000000000037, -358.9, 3.4000000000001807, 44.00000000000037, -140.50000000000045, 53.40000000000045, 21.900000000000098, 25.70000000000007, -409.9000000000002, 29.000000000000124, 28.900000000000222, 35.80000000000024, 56.30000000000041, 17.599999999999998, -421.19999999999925, 63.900000000000524, -82.70000000000148, 30.100000000000218, -37.49999999999958, -536.6, 10.699999999999958, 32.00000000000018, -79.69999999999976, 32.00000000000029, 3.399999999999933, 16.799999999999923, 24.400000000000045, -324.99999999999994, 34.50000000000029, -30.499999999999538, -10.899999999999846, 14.199999999999939, -276.3000000000004, -28.80000000000004, 24.60000000000014, 31.300000000000175, 37.30000000000026, 2.900000000000014, 13.899999999999919, 29.8000000000002, -46.899999999999544, 24.600000000000048, 34.40000000000034, 34.30000000000034, -10.29999999999961, 17.79999999999998, 55.600000000000506, 33.2000000000002, -66.69999999999996, 10.400000000000082, -446.1000000000001, -62.00000000000165, 21.19999999999999, 17.89999999999994, 37.80000000000027, 38.90000000000028, -358.0999999999975, 39.500000000000284, 16.89999999999997, 29.000000000000128, 38.300000000000274, 1.6000000000002148, 15.800000000000004, -582.0, 56.200000000000514, 23.50000000000003, 32.900000000000226, 56.10000000000044, 25.900000000000105, 24.1000000000001, 34.50000000000022, 15.700000000000005, 3.7000000000002022, 10.599999999999968, -59.79999999999972, 39.30000000000028, -566.2, -12.799999999999566, 34.50000000000022, 35.40000000000023], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-11.499999999999819, 9.499999999999964, -400.0, -385.9, 29.900000000000187, 9.499999999999964, 17.899999999999988, 14.599999999999968, 3.1999999999999615, -101.80000000000081, -47.19999999999976, -70.00000000000077, 20.000000000000014, 11.599999999999964, -385.30000000000007, -339.7, -36.69999999999977, 3.1999999999999615, 11.599999999999964, -27.39999999999975, 11.599999999999964, 1.0999999999999865, -7.299999999999891, 17.899999999999988, 11.299999999999965, 20.000000000000014, -198.40000000000055, -21.999999999999975, -40.89999999999976, 9.499999999999964, -38.79999999999976, -28.299999999999763, 3.1999999999999615, -3.099999999999958, -24.099999999999746, 17.899999999999988, 15.799999999999963, 3.1999999999999615, -194.8000000000002, -236.20000000000044, 5.299999999999965, 26.300000000000114, -346.9, -400.0, -51.399999999999814, 15.799999999999963, 20.000000000000014, 1.9999999999999607, 13.699999999999964, -383.1999999999998, 10.699999999999944, 25.700000000000184, -60.9999999999998, -3.099999999999958, -7.299999999999891, 20.000000000000014, -381.1, -332.8000000000002, 1.0999999999999865, 17.899999999999988, 3.4999999999999796, 7.399999999999947, 20.000000000000014, -5.1999999999999265, 3.4999999999999707, -26.199999999999747, -9.399999999999855, -0.9999999999999846, -288.6999999999997, -347.49999999999966, 23.900000000000073, 38.000000000000256, -141.7000000000007, -85.00000000000034, 11.599999999999946, 9.499999999999964, -47.199999999999804, -70.30000000000086, -340.6, -400.0, -47.799999999999784, -32.49999999999975, 17.899999999999977, 1.0999999999999865, -80.7999999999999, -82.89999999999988, 17.299999999999955, -13.300000000000042, 17.899999999999988, -53.499999999999915, -19.599999999999753, 10.399999999999965, -6.3999999999999435, 15.799999999999963, -246.6999999999999, -229.3, 11.599999999999964, 11.900000000000034, 9.499999999999964, -106.00000000000028, -9.400000000000034, -95.50000000000082, -9.399999999999961, -3.400000000000051, -271.3000000000002, -253.0000000000004, -108.39999999999986, 11.599999999999964, 1.0999999999999865, 9.49999999999996, -15.699999999999747, 20.000000000000014, 7.399999999999965, 20.90000000000003, -7.30000000000001, -17.79999999999994, 5.299999999999965, -18.400000000000023, -29.19999999999976, 20.000000000000014, -69.40000000000019, -53.499999999999766, 3.1999999999999615, 7.399999999999965, 35.900000000000254, -32.49999999999975, 10.100000000000023, -29.799999999999756, -48.399999999999764, -19.899999999999743, 5.299999999999965, -29.49999999999975, 40.70000000000025, -24.099999999999746, 20.000000000000014, 3.1999999999999615, 15.799999999999963, -179.5, -13.599999999999783, -0.9999999999999917, -322.30000000000007, -350.80000000000007, -64.00000000000088, -64.00000000000091, 9.499999999999977, -7.299999999999891, 9.499999999999964, -16.59999999999976, 20.000000000000014, 15.799999999999963, 20.000000000000014, 17.899999999999988, -271.89999999999895, -257.19999999999936, -34.59999999999975, 28.100000000000147, -7.299999999999891, 3.1999999999999615, 17.899999999999988, 1.099999999999983, 5.299999999999965, 20.000000000000014, -57.70000000000048, 5.299999999999965, -0.9999999999999846, -5.1999999999999265, -400.0, -400.0, 38.000000000000256, 3.1999999999999615, -5.1999999999999265, 13.699999999999964, 17.899999999999977, -21.999999999999744, -0.9999999999999846, 7.099999999999987, -13.899999999999807, -26.199999999999747, -5.200000000000021, -21.699999999999754, 11.599999999999964, 17.899999999999988, 1.0999999999999865, -9.399999999999855, -11.499999999999819, -17.79999999999974, -103.30000000000078, 17.899999999999988, -248.8000000000004, 20.000000000000014, -25.599999999999767, 17.899999999999988, -383.2, -400.0, -70.30000000000089, 9.499999999999964, 11.599999999999966, 17.899999999999988, 20.000000000000014, -13.599999999999783], "policy_predator_policy_reward": [16.0, 1.0, 200.0, 2.0, 5.0, 1.0, 1.0, 6.0, 58.0, 8.0, 52.0, 9.0, 1.0, 4.0, 1.0, 200.0, 31.0, 33.0, 17.0, 12.0, 4.0, 9.0, 2.0, 12.0, 2.0, 5.0, 68.0, 48.0, 4.0, 30.0, 5.0, 36.0, 0.0, 11.0, 21.0, 1.0, 4.0, 8.0, 166.0, 29.0, 7.0, 6.0, 188.0, 200.0, 34.0, 5.0, 11.0, 11.0, 37.0, 192.0, 12.0, 5.0, 43.0, 43.0, 0.0, 13.0, 113.0, 191.0, 1.0, 9.0, 2.0, 16.0, 12.0, 9.0, 43.0, 36.0, 14.0, 14.0, 23.0, 192.0, 2.0, 0.0, 55.0, 89.0, 7.0, 2.0, 18.0, 62.0, 200.0, 4.0, 40.0, 51.0, 9.0, 4.0, 23.0, 61.0, 15.0, 13.0, 33.0, 6.0, 18.0, 8.0, 13.0, 2.0, 133.0, 18.0, 8.0, 3.0, 44.0, 22.0, 55.0, 39.0, 14.0, 13.0, 139.0, 109.0, 16.0, 52.0, 11.0, 3.0, 11.0, 16.0, 3.0, 6.0, 10.0, 18.0, 10.0, 17.0, 17.0, 22.0, 53.0, 23.0, 6.0, 8.0, 20.0, 11.0, 29.0, 25.0, 24.0, 34.0, 24.0, 18.0, 21.0, 18.0, 2.0, 8.0, 95.0, 2.0, 9.0, 16.0, 189.0, 38.0, 44.0, 22.0, 4.0, 15.0, 5.0, 20.0, 2.0, 0.0, 0.0, 1.0, 154.0, 17.0, 22.0, 24.0, 13.0, 8.0, 8.0, 2.0, 7.0, 6.0, 35.0, 19.0, 10.0, 12.0, 200.0, 18.0, 7.0, 8.0, 12.0, 3.0, 18.0, 19.0, 32.0, 18.0, 35.0, 31.0, 25.0, 26.0, 4.0, 1.0, 11.0, 13.0, 18.0, 15.0, 52.0, 44.0, 126.0, 43.0, 23.0, 24.0, 200.0, 17.0, 43.0, 5.0, 5.0, 0.0, 13.0, 16.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5912903013131572, "mean_inference_ms": 1.8281683702343172, "mean_action_processing_ms": 0.25837754180013783, "mean_env_wait_ms": 0.19887420759852895, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003783106803894043, "StateBufferConnector_ms": 0.00337374210357666, "ViewRequirementAgentConnector_ms": 0.1009054183959961}, "num_episodes": 22, "episode_return_max": 63.900000000000524, "episode_return_min": -583.9, "episode_return_mean": -45.612999999999886, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2000000, "num_agent_steps_trained": 2000000, "num_env_steps_sampled": 500000, "num_env_steps_trained": 500000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 370.27565019706105, "num_env_steps_trained_throughput_per_sec": 370.27565019706105, "timesteps_total": 500000, "num_env_steps_sampled_lifetime": 500000, "num_agent_steps_sampled_lifetime": 2000000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2000000, "timers": {"training_iteration_time_ms": 11076.355, "restore_workers_time_ms": 0.013, "training_step_time_ms": 11076.313, "sample_time_ms": 1293.525, "learn_time_ms": 9766.192, "learn_throughput": 409.576, "synch_weights_time_ms": 14.639}, "counters": {"num_env_steps_sampled": 500000, "num_env_steps_trained": 500000, "num_agent_steps_sampled": 2000000, "num_agent_steps_trained": 2000000}, "done": false, "training_iteration": 125, "trial_id": "3dae5_00000", "date": "2024-08-14_09-29-53", "timestamp": 1723642193, "time_this_iter_s": 10.80678677558899, "time_total_s": 3011.3309540748596, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3962430>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3011.3309540748596, "iterations_since_restore": 125, "perf": {"cpu_util_percent": 29.380000000000003, "ram_util_percent": 83.67333333333333}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.3780028406274383, "cur_kl_coeff": 1.5449523925781246e-05, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.9975190730637343, "policy_loss": -0.005769750710438799, "vf_loss": 1.003288576148805, "vf_explained_var": 0.12908881048046092, "kl": 0.015948594065380538, "entropy": 1.0174134876992968, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 237195.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.3372122055954403, "cur_kl_coeff": 0.06328124999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.9503505733140089, "policy_loss": -0.010769831007543616, "vf_loss": 0.9605175903234532, "vf_explained_var": 0.1760304332410217, "kl": 0.009525961821645737, "entropy": 1.0737893429382768, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 237195.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 504000, "num_env_steps_trained": 504000, "num_agent_steps_sampled": 2016000, "num_agent_steps_trained": 2016000}, "env_runners": {"episode_reward_max": 63.900000000000524, "episode_reward_min": -582.0, "episode_reward_mean": -32.66999999999985, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 40.70000000000025, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -46.34499999999999, "predator_policy": 30.01}, "custom_metrics": {}, "hist_stats": {"episode_reward": [31.000000000000163, -236.0000000000006, 44.60000000000037, -358.9, 3.4000000000001807, 44.00000000000037, -140.50000000000045, 53.40000000000045, 21.900000000000098, 25.70000000000007, -409.9000000000002, 29.000000000000124, 28.900000000000222, 35.80000000000024, 56.30000000000041, 17.599999999999998, -421.19999999999925, 63.900000000000524, -82.70000000000148, 30.100000000000218, -37.49999999999958, -536.6, 10.699999999999958, 32.00000000000018, -79.69999999999976, 32.00000000000029, 3.399999999999933, 16.799999999999923, 24.400000000000045, -324.99999999999994, 34.50000000000029, -30.499999999999538, -10.899999999999846, 14.199999999999939, -276.3000000000004, -28.80000000000004, 24.60000000000014, 31.300000000000175, 37.30000000000026, 2.900000000000014, 13.899999999999919, 29.8000000000002, -46.899999999999544, 24.600000000000048, 34.40000000000034, 34.30000000000034, -10.29999999999961, 17.79999999999998, 55.600000000000506, 33.2000000000002, -66.69999999999996, 10.400000000000082, -446.1000000000001, -62.00000000000165, 21.19999999999999, 17.89999999999994, 37.80000000000027, 38.90000000000028, -358.0999999999975, 39.500000000000284, 16.89999999999997, 29.000000000000128, 38.300000000000274, 1.6000000000002148, 15.800000000000004, -582.0, 56.200000000000514, 23.50000000000003, 32.900000000000226, 56.10000000000044, 25.900000000000105, 24.1000000000001, 34.50000000000022, 15.700000000000005, 3.7000000000002022, 10.599999999999968, -59.79999999999972, 39.30000000000028, -566.2, -12.799999999999566, 34.50000000000022, 35.40000000000023, 16.899999999999988, 29.10000000000014, 4.600000000000151, 38.90000000000028, 34.60000000000022, -29.599999999999547, 30.10000000000018, 31.200000000000166, 24.200000000000045, -28.49999999999951, 13.199999999999926, 24.80000000000005, -8.599999999999644, -9.099999999999628, 25.300000000000075, 22.400000000000013, 24.600000000000083, 21.299999999999994], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [15.799999999999963, 3.1999999999999615, -194.8000000000002, -236.20000000000044, 5.299999999999965, 26.300000000000114, -346.9, -400.0, -51.399999999999814, 15.799999999999963, 20.000000000000014, 1.9999999999999607, 13.699999999999964, -383.1999999999998, 10.699999999999944, 25.700000000000184, -60.9999999999998, -3.099999999999958, -7.299999999999891, 20.000000000000014, -381.1, -332.8000000000002, 1.0999999999999865, 17.899999999999988, 3.4999999999999796, 7.399999999999947, 20.000000000000014, -5.1999999999999265, 3.4999999999999707, -26.199999999999747, -9.399999999999855, -0.9999999999999846, -288.6999999999997, -347.49999999999966, 23.900000000000073, 38.000000000000256, -141.7000000000007, -85.00000000000034, 11.599999999999946, 9.499999999999964, -47.199999999999804, -70.30000000000086, -340.6, -400.0, -47.799999999999784, -32.49999999999975, 17.899999999999977, 1.0999999999999865, -80.7999999999999, -82.89999999999988, 17.299999999999955, -13.300000000000042, 17.899999999999988, -53.499999999999915, -19.599999999999753, 10.399999999999965, -6.3999999999999435, 15.799999999999963, -246.6999999999999, -229.3, 11.599999999999964, 11.900000000000034, 9.499999999999964, -106.00000000000028, -9.400000000000034, -95.50000000000082, -9.399999999999961, -3.400000000000051, -271.3000000000002, -253.0000000000004, -108.39999999999986, 11.599999999999964, 1.0999999999999865, 9.49999999999996, -15.699999999999747, 20.000000000000014, 7.399999999999965, 20.90000000000003, -7.30000000000001, -17.79999999999994, 5.299999999999965, -18.400000000000023, -29.19999999999976, 20.000000000000014, -69.40000000000019, -53.499999999999766, 3.1999999999999615, 7.399999999999965, 35.900000000000254, -32.49999999999975, 10.100000000000023, -29.799999999999756, -48.399999999999764, -19.899999999999743, 5.299999999999965, -29.49999999999975, 40.70000000000025, -24.099999999999746, 20.000000000000014, 3.1999999999999615, 15.799999999999963, -179.5, -13.599999999999783, -0.9999999999999917, -322.30000000000007, -350.80000000000007, -64.00000000000088, -64.00000000000091, 9.499999999999977, -7.299999999999891, 9.499999999999964, -16.59999999999976, 20.000000000000014, 15.799999999999963, 20.000000000000014, 17.899999999999988, -271.89999999999895, -257.19999999999936, -34.59999999999975, 28.100000000000147, -7.299999999999891, 3.1999999999999615, 17.899999999999988, 1.099999999999983, 5.299999999999965, 20.000000000000014, -57.70000000000048, 5.299999999999965, -0.9999999999999846, -5.1999999999999265, -400.0, -400.0, 38.000000000000256, 3.1999999999999615, -5.1999999999999265, 13.699999999999964, 17.899999999999977, -21.999999999999744, -0.9999999999999846, 7.099999999999987, -13.899999999999807, -26.199999999999747, -5.200000000000021, -21.699999999999754, 11.599999999999964, 17.899999999999988, 1.0999999999999865, -9.399999999999855, -11.499999999999819, -17.79999999999974, -103.30000000000078, 17.899999999999988, -248.8000000000004, 20.000000000000014, -25.599999999999767, 17.899999999999988, -383.2, -400.0, -70.30000000000089, 9.499999999999964, 11.599999999999966, 17.899999999999988, 20.000000000000014, -13.599999999999783, -17.79999999999974, 13.699999999999964, -2.499999999999986, 11.599999999999964, 20.000000000000014, -48.399999999999835, 20.000000000000014, 17.899999999999988, 20.000000000000014, -9.399999999999855, -110.20000000000077, 11.599999999999964, 9.499999999999964, 11.599999999999964, 3.1999999999999615, 20.000000000000014, 0.7999999999999527, 7.399999999999972, -30.39999999999975, -45.09999999999976, -9.699999999999868, -6.099999999999945, 3.1999999999999615, 11.599999999999964, -53.500000000000135, -21.099999999999746, -17.79999999999974, -31.299999999999763, 20.000000000000014, -36.699999999999754, -13.599999999999783, 20.000000000000014, 5.299999999999965, -33.69999999999978, -15.699999999999747, 20.000000000000014], "policy_predator_policy_reward": [4.0, 8.0, 166.0, 29.0, 7.0, 6.0, 188.0, 200.0, 34.0, 5.0, 11.0, 11.0, 37.0, 192.0, 12.0, 5.0, 43.0, 43.0, 0.0, 13.0, 113.0, 191.0, 1.0, 9.0, 2.0, 16.0, 12.0, 9.0, 43.0, 36.0, 14.0, 14.0, 23.0, 192.0, 2.0, 0.0, 55.0, 89.0, 7.0, 2.0, 18.0, 62.0, 200.0, 4.0, 40.0, 51.0, 9.0, 4.0, 23.0, 61.0, 15.0, 13.0, 33.0, 6.0, 18.0, 8.0, 13.0, 2.0, 133.0, 18.0, 8.0, 3.0, 44.0, 22.0, 55.0, 39.0, 14.0, 13.0, 139.0, 109.0, 16.0, 52.0, 11.0, 3.0, 11.0, 16.0, 3.0, 6.0, 10.0, 18.0, 10.0, 17.0, 17.0, 22.0, 53.0, 23.0, 6.0, 8.0, 20.0, 11.0, 29.0, 25.0, 24.0, 34.0, 24.0, 18.0, 21.0, 18.0, 2.0, 8.0, 95.0, 2.0, 9.0, 16.0, 189.0, 38.0, 44.0, 22.0, 4.0, 15.0, 5.0, 20.0, 2.0, 0.0, 0.0, 1.0, 154.0, 17.0, 22.0, 24.0, 13.0, 8.0, 8.0, 2.0, 7.0, 6.0, 35.0, 19.0, 10.0, 12.0, 200.0, 18.0, 7.0, 8.0, 12.0, 3.0, 18.0, 19.0, 32.0, 18.0, 35.0, 31.0, 25.0, 26.0, 4.0, 1.0, 11.0, 13.0, 18.0, 15.0, 52.0, 44.0, 126.0, 43.0, 23.0, 24.0, 200.0, 17.0, 43.0, 5.0, 5.0, 0.0, 13.0, 16.0, 18.0, 3.0, 14.0, 6.0, 20.0, 13.0, 1.0, 0.0, 13.0, 11.0, 54.0, 15.0, 5.0, 4.0, 8.0, 0.0, 9.0, 7.0, 28.0, 19.0, 22.0, 7.0, 2.0, 8.0, 33.0, 33.0, 33.0, 7.0, 26.0, 16.0, 16.0, 0.0, 19.0, 34.0, 0.0, 17.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5911173338049729, "mean_inference_ms": 1.8277225857238988, "mean_action_processing_ms": 0.25819237799399386, "mean_env_wait_ms": 0.19879302013105163, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003763556480407715, "StateBufferConnector_ms": 0.0032601356506347656, "ViewRequirementAgentConnector_ms": 0.09868729114532471}, "num_episodes": 18, "episode_return_max": 63.900000000000524, "episode_return_min": -582.0, "episode_return_mean": -32.66999999999985, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2016000, "num_agent_steps_trained": 2016000, "num_env_steps_sampled": 504000, "num_env_steps_trained": 504000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 374.4670046297427, "num_env_steps_trained_throughput_per_sec": 374.4670046297427, "timesteps_total": 504000, "num_env_steps_sampled_lifetime": 504000, "num_agent_steps_sampled_lifetime": 2016000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2016000, "timers": {"training_iteration_time_ms": 11062.081, "restore_workers_time_ms": 0.013, "training_step_time_ms": 11062.039, "sample_time_ms": 1294.481, "learn_time_ms": 9751.248, "learn_throughput": 410.204, "synch_weights_time_ms": 14.336}, "counters": {"num_env_steps_sampled": 504000, "num_env_steps_trained": 504000, "num_agent_steps_sampled": 2016000, "num_agent_steps_trained": 2016000}, "done": false, "training_iteration": 126, "trial_id": "3dae5_00000", "date": "2024-08-14_09-30-04", "timestamp": 1723642204, "time_this_iter_s": 10.686594724655151, "time_total_s": 3022.0175487995148, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3962ee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3022.0175487995148, "iterations_since_restore": 126, "perf": {"cpu_util_percent": 28.966666666666665, "ram_util_percent": 83.64}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.709637113664516, "cur_kl_coeff": 1.5449523925781246e-05, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.6478054535767389, "policy_loss": -0.0046619519073930055, "vf_loss": 0.6524671583815858, "vf_explained_var": 0.15710937737157105, "kl": 0.015886719096298144, "entropy": 1.0525245950335549, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 239085.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.534875959567923, "cur_kl_coeff": 0.06328124999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.7541279877442374, "policy_loss": -0.010525827043783412, "vf_loss": 0.7641035911543345, "vf_explained_var": 0.1161501787957691, "kl": 0.008694885464595974, "entropy": 1.0842298906316201, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 239085.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 508000, "num_env_steps_trained": 508000, "num_agent_steps_sampled": 2032000, "num_agent_steps_trained": 2032000}, "env_runners": {"episode_reward_max": 56.200000000000514, "episode_reward_min": -582.0, "episode_reward_mean": -16.94699999999985, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 40.70000000000025, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -32.15349999999998, "predator_policy": 23.68}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-82.70000000000148, 30.100000000000218, -37.49999999999958, -536.6, 10.699999999999958, 32.00000000000018, -79.69999999999976, 32.00000000000029, 3.399999999999933, 16.799999999999923, 24.400000000000045, -324.99999999999994, 34.50000000000029, -30.499999999999538, -10.899999999999846, 14.199999999999939, -276.3000000000004, -28.80000000000004, 24.60000000000014, 31.300000000000175, 37.30000000000026, 2.900000000000014, 13.899999999999919, 29.8000000000002, -46.899999999999544, 24.600000000000048, 34.40000000000034, 34.30000000000034, -10.29999999999961, 17.79999999999998, 55.600000000000506, 33.2000000000002, -66.69999999999996, 10.400000000000082, -446.1000000000001, -62.00000000000165, 21.19999999999999, 17.89999999999994, 37.80000000000027, 38.90000000000028, -358.0999999999975, 39.500000000000284, 16.89999999999997, 29.000000000000128, 38.300000000000274, 1.6000000000002148, 15.800000000000004, -582.0, 56.200000000000514, 23.50000000000003, 32.900000000000226, 56.10000000000044, 25.900000000000105, 24.1000000000001, 34.50000000000022, 15.700000000000005, 3.7000000000002022, 10.599999999999968, -59.79999999999972, 39.30000000000028, -566.2, -12.799999999999566, 34.50000000000022, 35.40000000000023, 16.899999999999988, 29.10000000000014, 4.600000000000151, 38.90000000000028, 34.60000000000022, -29.599999999999547, 30.10000000000018, 31.200000000000166, 24.200000000000045, -28.49999999999951, 13.199999999999926, 24.80000000000005, -8.599999999999644, -9.099999999999628, 25.300000000000075, 22.400000000000013, 24.600000000000083, 21.299999999999994, 15.700000000000005, 31.200000000000163, 35.30000000000023, 26.600000000000108, 33.00000000000019, 24.900000000000052, 40.100000000000314, 32.000000000000185, 32.50000000000019, 17.99999999999999, -14.699999999999537, 16.79999999999998, 25.700000000000067, 7.600000000000115, 44.100000000000385, 31.200000000000163, 32.30000000000018, 29.000000000000124], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-141.7000000000007, -85.00000000000034, 11.599999999999946, 9.499999999999964, -47.199999999999804, -70.30000000000086, -340.6, -400.0, -47.799999999999784, -32.49999999999975, 17.899999999999977, 1.0999999999999865, -80.7999999999999, -82.89999999999988, 17.299999999999955, -13.300000000000042, 17.899999999999988, -53.499999999999915, -19.599999999999753, 10.399999999999965, -6.3999999999999435, 15.799999999999963, -246.6999999999999, -229.3, 11.599999999999964, 11.900000000000034, 9.499999999999964, -106.00000000000028, -9.400000000000034, -95.50000000000082, -9.399999999999961, -3.400000000000051, -271.3000000000002, -253.0000000000004, -108.39999999999986, 11.599999999999964, 1.0999999999999865, 9.49999999999996, -15.699999999999747, 20.000000000000014, 7.399999999999965, 20.90000000000003, -7.30000000000001, -17.79999999999994, 5.299999999999965, -18.400000000000023, -29.19999999999976, 20.000000000000014, -69.40000000000019, -53.499999999999766, 3.1999999999999615, 7.399999999999965, 35.900000000000254, -32.49999999999975, 10.100000000000023, -29.799999999999756, -48.399999999999764, -19.899999999999743, 5.299999999999965, -29.49999999999975, 40.70000000000025, -24.099999999999746, 20.000000000000014, 3.1999999999999615, 15.799999999999963, -179.5, -13.599999999999783, -0.9999999999999917, -322.30000000000007, -350.80000000000007, -64.00000000000088, -64.00000000000091, 9.499999999999977, -7.299999999999891, 9.499999999999964, -16.59999999999976, 20.000000000000014, 15.799999999999963, 20.000000000000014, 17.899999999999988, -271.89999999999895, -257.19999999999936, -34.59999999999975, 28.100000000000147, -7.299999999999891, 3.1999999999999615, 17.899999999999988, 1.099999999999983, 5.299999999999965, 20.000000000000014, -57.70000000000048, 5.299999999999965, -0.9999999999999846, -5.1999999999999265, -400.0, -400.0, 38.000000000000256, 3.1999999999999615, -5.1999999999999265, 13.699999999999964, 17.899999999999977, -21.999999999999744, -0.9999999999999846, 7.099999999999987, -13.899999999999807, -26.199999999999747, -5.200000000000021, -21.699999999999754, 11.599999999999964, 17.899999999999988, 1.0999999999999865, -9.399999999999855, -11.499999999999819, -17.79999999999974, -103.30000000000078, 17.899999999999988, -248.8000000000004, 20.000000000000014, -25.599999999999767, 17.899999999999988, -383.2, -400.0, -70.30000000000089, 9.499999999999964, 11.599999999999966, 17.899999999999988, 20.000000000000014, -13.599999999999783, -17.79999999999974, 13.699999999999964, -2.499999999999986, 11.599999999999964, 20.000000000000014, -48.399999999999835, 20.000000000000014, 17.899999999999988, 20.000000000000014, -9.399999999999855, -110.20000000000077, 11.599999999999964, 9.499999999999964, 11.599999999999964, 3.1999999999999615, 20.000000000000014, 0.7999999999999527, 7.399999999999972, -30.39999999999975, -45.09999999999976, -9.699999999999868, -6.099999999999945, 3.1999999999999615, 11.599999999999964, -53.500000000000135, -21.099999999999746, -17.79999999999974, -31.299999999999763, 20.000000000000014, -36.699999999999754, -13.599999999999783, 20.000000000000014, 5.299999999999965, -33.69999999999978, -15.699999999999747, 20.000000000000014, -5.1999999999999265, -3.099999999999958, 15.799999999999963, 7.399999999999965, -15.699999999999747, 20.000000000000014, 20.000000000000014, -9.39999999999989, 15.499999999999964, 9.499999999999964, 9.499999999999964, 7.399999999999965, 20.90000000000003, -56.80000000000027, -19.899999999999743, 17.899999999999988, -9.399999999999855, 17.899999999999988, 11.599999999999964, -13.599999999999783, -33.699999999999754, -42.99999999999976, -19.899999999999743, 13.699999999999964, 5.299999999999965, 7.399999999999965, -4.299999999999962, -24.099999999999746, -7.299999999999891, 34.40000000000026, 5.299999999999965, 17.899999999999988, 7.399999999999965, 17.899999999999988, 3.1999999999999615, 15.799999999999963], "policy_predator_policy_reward": [55.0, 89.0, 7.0, 2.0, 18.0, 62.0, 200.0, 4.0, 40.0, 51.0, 9.0, 4.0, 23.0, 61.0, 15.0, 13.0, 33.0, 6.0, 18.0, 8.0, 13.0, 2.0, 133.0, 18.0, 8.0, 3.0, 44.0, 22.0, 55.0, 39.0, 14.0, 13.0, 139.0, 109.0, 16.0, 52.0, 11.0, 3.0, 11.0, 16.0, 3.0, 6.0, 10.0, 18.0, 10.0, 17.0, 17.0, 22.0, 53.0, 23.0, 6.0, 8.0, 20.0, 11.0, 29.0, 25.0, 24.0, 34.0, 24.0, 18.0, 21.0, 18.0, 2.0, 8.0, 95.0, 2.0, 9.0, 16.0, 189.0, 38.0, 44.0, 22.0, 4.0, 15.0, 5.0, 20.0, 2.0, 0.0, 0.0, 1.0, 154.0, 17.0, 22.0, 24.0, 13.0, 8.0, 8.0, 2.0, 7.0, 6.0, 35.0, 19.0, 10.0, 12.0, 200.0, 18.0, 7.0, 8.0, 12.0, 3.0, 18.0, 19.0, 32.0, 18.0, 35.0, 31.0, 25.0, 26.0, 4.0, 1.0, 11.0, 13.0, 18.0, 15.0, 52.0, 44.0, 126.0, 43.0, 23.0, 24.0, 200.0, 17.0, 43.0, 5.0, 5.0, 0.0, 13.0, 16.0, 18.0, 3.0, 14.0, 6.0, 20.0, 13.0, 1.0, 0.0, 13.0, 11.0, 54.0, 15.0, 5.0, 4.0, 8.0, 0.0, 9.0, 7.0, 28.0, 19.0, 22.0, 7.0, 2.0, 8.0, 33.0, 33.0, 33.0, 7.0, 26.0, 16.0, 16.0, 0.0, 19.0, 34.0, 0.0, 17.0, 12.0, 12.0, 6.0, 2.0, 14.0, 17.0, 14.0, 2.0, 3.0, 5.0, 2.0, 6.0, 38.0, 38.0, 15.0, 19.0, 11.0, 13.0, 4.0, 16.0, 31.0, 31.0, 4.0, 19.0, 6.0, 7.0, 19.0, 17.0, 12.0, 5.0, 1.0, 7.0, 6.0, 1.0, 8.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5909034967081581, "mean_inference_ms": 1.8272581585649559, "mean_action_processing_ms": 0.25801250047135565, "mean_env_wait_ms": 0.1986947317607108, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0038448572158813477, "StateBufferConnector_ms": 0.00331723690032959, "ViewRequirementAgentConnector_ms": 0.09997379779815674}, "num_episodes": 18, "episode_return_max": 56.200000000000514, "episode_return_min": -582.0, "episode_return_mean": -16.94699999999985, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2032000, "num_agent_steps_trained": 2032000, "num_env_steps_sampled": 508000, "num_env_steps_trained": 508000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 357.7806980768783, "num_env_steps_trained_throughput_per_sec": 357.7806980768783, "timesteps_total": 508000, "num_env_steps_sampled_lifetime": 508000, "num_agent_steps_sampled_lifetime": 2032000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2032000, "timers": {"training_iteration_time_ms": 11082.613, "restore_workers_time_ms": 0.013, "training_step_time_ms": 11082.571, "sample_time_ms": 1288.882, "learn_time_ms": 9776.898, "learn_throughput": 409.128, "synch_weights_time_ms": 14.723}, "counters": {"num_env_steps_sampled": 508000, "num_env_steps_trained": 508000, "num_agent_steps_sampled": 2032000, "num_agent_steps_trained": 2032000}, "done": false, "training_iteration": 127, "trial_id": "3dae5_00000", "date": "2024-08-14_09-30-15", "timestamp": 1723642215, "time_this_iter_s": 11.223136186599731, "time_total_s": 3033.2406849861145, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3831040>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3033.2406849861145, "iterations_since_restore": 127, "perf": {"cpu_util_percent": 29.631249999999998, "ram_util_percent": 83.54999999999998}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.099308270089841, "cur_kl_coeff": 1.5449523925781246e-05, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.0336532776633267, "policy_loss": -0.0016441181590337128, "vf_loss": 1.035297213061146, "vf_explained_var": 0.19443294815916232, "kl": 0.011753337020428424, "entropy": 0.9675946500881639, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 240975.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.4871513984190723, "cur_kl_coeff": 0.06328124999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.374763566791696, "policy_loss": -0.007096337719460722, "vf_loss": 1.3812667391129902, "vf_explained_var": 0.028912117683067524, "kl": 0.00937348397008625, "entropy": 1.0803210486810675, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 240975.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 512000, "num_env_steps_trained": 512000, "num_agent_steps_sampled": 2048000, "num_agent_steps_trained": 2048000}, "env_runners": {"episode_reward_max": 56.200000000000514, "episode_reward_min": -582.0, "episode_reward_mean": -2.4849999999998422, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 40.70000000000025, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -21.212499999999967, "predator_policy": 19.97}, "custom_metrics": {}, "hist_stats": {"episode_reward": [29.8000000000002, -46.899999999999544, 24.600000000000048, 34.40000000000034, 34.30000000000034, -10.29999999999961, 17.79999999999998, 55.600000000000506, 33.2000000000002, -66.69999999999996, 10.400000000000082, -446.1000000000001, -62.00000000000165, 21.19999999999999, 17.89999999999994, 37.80000000000027, 38.90000000000028, -358.0999999999975, 39.500000000000284, 16.89999999999997, 29.000000000000128, 38.300000000000274, 1.6000000000002148, 15.800000000000004, -582.0, 56.200000000000514, 23.50000000000003, 32.900000000000226, 56.10000000000044, 25.900000000000105, 24.1000000000001, 34.50000000000022, 15.700000000000005, 3.7000000000002022, 10.599999999999968, -59.79999999999972, 39.30000000000028, -566.2, -12.799999999999566, 34.50000000000022, 35.40000000000023, 16.899999999999988, 29.10000000000014, 4.600000000000151, 38.90000000000028, 34.60000000000022, -29.599999999999547, 30.10000000000018, 31.200000000000166, 24.200000000000045, -28.49999999999951, 13.199999999999926, 24.80000000000005, -8.599999999999644, -9.099999999999628, 25.300000000000075, 22.400000000000013, 24.600000000000083, 21.299999999999994, 15.700000000000005, 31.200000000000163, 35.30000000000023, 26.600000000000108, 33.00000000000019, 24.900000000000052, 40.100000000000314, 32.000000000000185, 32.50000000000019, 17.99999999999999, -14.699999999999537, 16.79999999999998, 25.700000000000067, 7.600000000000115, 44.100000000000385, 31.200000000000163, 32.30000000000018, 29.000000000000124, -34.89999999999958, 35.600000000000236, 45.60000000000039, 21.200000000000006, 26.900000000000098, -3.400000000000051, 23.30000000000003, 26.20000000000008, 15.899999999999912, 38.10000000000027, 24.600000000000048, 33.400000000000205, -136.00000000000094, 37.40000000000026, 9.200000000000113, 36.700000000000266, 16.29999999999991, 50.80000000000049, 11.400000000000077, 37.80000000000027, 2.1000000000001458, 15.799999999999978, 12.300000000000031], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-29.19999999999976, 20.000000000000014, -69.40000000000019, -53.499999999999766, 3.1999999999999615, 7.399999999999965, 35.900000000000254, -32.49999999999975, 10.100000000000023, -29.799999999999756, -48.399999999999764, -19.899999999999743, 5.299999999999965, -29.49999999999975, 40.70000000000025, -24.099999999999746, 20.000000000000014, 3.1999999999999615, 15.799999999999963, -179.5, -13.599999999999783, -0.9999999999999917, -322.30000000000007, -350.80000000000007, -64.00000000000088, -64.00000000000091, 9.499999999999977, -7.299999999999891, 9.499999999999964, -16.59999999999976, 20.000000000000014, 15.799999999999963, 20.000000000000014, 17.899999999999988, -271.89999999999895, -257.19999999999936, -34.59999999999975, 28.100000000000147, -7.299999999999891, 3.1999999999999615, 17.899999999999988, 1.099999999999983, 5.299999999999965, 20.000000000000014, -57.70000000000048, 5.299999999999965, -0.9999999999999846, -5.1999999999999265, -400.0, -400.0, 38.000000000000256, 3.1999999999999615, -5.1999999999999265, 13.699999999999964, 17.899999999999977, -21.999999999999744, -0.9999999999999846, 7.099999999999987, -13.899999999999807, -26.199999999999747, -5.200000000000021, -21.699999999999754, 11.599999999999964, 17.899999999999988, 1.0999999999999865, -9.399999999999855, -11.499999999999819, -17.79999999999974, -103.30000000000078, 17.899999999999988, -248.8000000000004, 20.000000000000014, -25.599999999999767, 17.899999999999988, -383.2, -400.0, -70.30000000000089, 9.499999999999964, 11.599999999999966, 17.899999999999988, 20.000000000000014, -13.599999999999783, -17.79999999999974, 13.699999999999964, -2.499999999999986, 11.599999999999964, 20.000000000000014, -48.399999999999835, 20.000000000000014, 17.899999999999988, 20.000000000000014, -9.399999999999855, -110.20000000000077, 11.599999999999964, 9.499999999999964, 11.599999999999964, 3.1999999999999615, 20.000000000000014, 0.7999999999999527, 7.399999999999972, -30.39999999999975, -45.09999999999976, -9.699999999999868, -6.099999999999945, 3.1999999999999615, 11.599999999999964, -53.500000000000135, -21.099999999999746, -17.79999999999974, -31.299999999999763, 20.000000000000014, -36.699999999999754, -13.599999999999783, 20.000000000000014, 5.299999999999965, -33.69999999999978, -15.699999999999747, 20.000000000000014, -5.1999999999999265, -3.099999999999958, 15.799999999999963, 7.399999999999965, -15.699999999999747, 20.000000000000014, 20.000000000000014, -9.39999999999989, 15.499999999999964, 9.499999999999964, 9.499999999999964, 7.399999999999965, 20.90000000000003, -56.80000000000027, -19.899999999999743, 17.899999999999988, -9.399999999999855, 17.899999999999988, 11.599999999999964, -13.599999999999783, -33.699999999999754, -42.99999999999976, -19.899999999999743, 13.699999999999964, 5.299999999999965, 7.399999999999965, -4.299999999999962, -24.099999999999746, -7.299999999999891, 34.40000000000026, 5.299999999999965, 17.899999999999988, 7.399999999999965, 17.899999999999988, 3.1999999999999615, 15.799999999999963, 13.699999999999964, -118.6000000000007, -9.399999999999855, 20.000000000000014, 20.000000000000014, -12.39999999999983, -3.099999999999958, 5.299999999999965, -24.099999999999746, 20.000000000000014, -17.799999999999976, -13.600000000000023, -7.299999999999891, 11.59999999999997, 17.899999999999988, -6.699999999999907, 6.199999999999968, -70.30000000000089, 13.099999999999971, 20.000000000000014, 1.0999999999999865, 9.499999999999964, 20.000000000000014, 7.399999999999965, 7.399999999999965, -303.399999999999, 7.399999999999965, 20.000000000000014, 3.1999999999999615, -21.999999999999744, -7.299999999999926, 20.000000000000014, -33.99999999999976, 8.299999999999965, 24.800000000000093, 20.000000000000014, 1.0999999999999865, -15.699999999999747, 20.000000000000014, 15.799999999999963, -47.19999999999976, 5.2999999999999785, 1.0999999999999865, -7.299999999999962, -29.799999999999756, -4.899999999999942], "policy_predator_policy_reward": [17.0, 22.0, 53.0, 23.0, 6.0, 8.0, 20.0, 11.0, 29.0, 25.0, 24.0, 34.0, 24.0, 18.0, 21.0, 18.0, 2.0, 8.0, 95.0, 2.0, 9.0, 16.0, 189.0, 38.0, 44.0, 22.0, 4.0, 15.0, 5.0, 20.0, 2.0, 0.0, 0.0, 1.0, 154.0, 17.0, 22.0, 24.0, 13.0, 8.0, 8.0, 2.0, 7.0, 6.0, 35.0, 19.0, 10.0, 12.0, 200.0, 18.0, 7.0, 8.0, 12.0, 3.0, 18.0, 19.0, 32.0, 18.0, 35.0, 31.0, 25.0, 26.0, 4.0, 1.0, 11.0, 13.0, 18.0, 15.0, 52.0, 44.0, 126.0, 43.0, 23.0, 24.0, 200.0, 17.0, 43.0, 5.0, 5.0, 0.0, 13.0, 16.0, 18.0, 3.0, 14.0, 6.0, 20.0, 13.0, 1.0, 0.0, 13.0, 11.0, 54.0, 15.0, 5.0, 4.0, 8.0, 0.0, 9.0, 7.0, 28.0, 19.0, 22.0, 7.0, 2.0, 8.0, 33.0, 33.0, 33.0, 7.0, 26.0, 16.0, 16.0, 0.0, 19.0, 34.0, 0.0, 17.0, 12.0, 12.0, 6.0, 2.0, 14.0, 17.0, 14.0, 2.0, 3.0, 5.0, 2.0, 6.0, 38.0, 38.0, 15.0, 19.0, 11.0, 13.0, 4.0, 16.0, 31.0, 31.0, 4.0, 19.0, 6.0, 7.0, 19.0, 17.0, 12.0, 5.0, 1.0, 7.0, 6.0, 1.0, 8.0, 2.0, 66.0, 4.0, 11.0, 14.0, 20.0, 18.0, 11.0, 8.0, 21.0, 10.0, 14.0, 14.0, 16.0, 3.0, 14.0, 1.0, 39.0, 41.0, 1.0, 4.0, 5.0, 9.0, 0.0, 6.0, 154.0, 6.0, 4.0, 6.0, 8.0, 20.0, 12.0, 12.0, 22.0, 20.0, 1.0, 5.0, 9.0, 17.0, 2.0, 0.0, 17.0, 27.0, 9.0, 13.0, 22.0, 25.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5906337607718679, "mean_inference_ms": 1.8267753454971551, "mean_action_processing_ms": 0.25776996669883073, "mean_env_wait_ms": 0.19856995895969937, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004134058952331543, "StateBufferConnector_ms": 0.003758549690246582, "ViewRequirementAgentConnector_ms": 0.09894967079162598}, "num_episodes": 23, "episode_return_max": 56.200000000000514, "episode_return_min": -582.0, "episode_return_mean": -2.4849999999998422, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2048000, "num_agent_steps_trained": 2048000, "num_env_steps_sampled": 512000, "num_env_steps_trained": 512000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 360.75348492367874, "num_env_steps_trained_throughput_per_sec": 360.75348492367874, "timesteps_total": 512000, "num_env_steps_sampled_lifetime": 512000, "num_agent_steps_sampled_lifetime": 2048000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2048000, "timers": {"training_iteration_time_ms": 11054.054, "restore_workers_time_ms": 0.013, "training_step_time_ms": 11054.012, "sample_time_ms": 1297.14, "learn_time_ms": 9740.54, "learn_throughput": 410.655, "synch_weights_time_ms": 14.241}, "counters": {"num_env_steps_sampled": 512000, "num_env_steps_trained": 512000, "num_agent_steps_sampled": 2048000, "num_agent_steps_trained": 2048000}, "done": false, "training_iteration": 128, "trial_id": "3dae5_00000", "date": "2024-08-14_09-30-26", "timestamp": 1723642226, "time_this_iter_s": 11.138772964477539, "time_total_s": 3044.379457950592, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3962ca0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3044.379457950592, "iterations_since_restore": 128, "perf": {"cpu_util_percent": 30.88125, "ram_util_percent": 83.5625}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8232424986110163, "cur_kl_coeff": 1.5449523925781246e-05, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.8369509844868271, "policy_loss": -0.00517795245118794, "vf_loss": 0.8421286865753471, "vf_explained_var": 0.12931931864016902, "kl": 0.01608532303922268, "entropy": 0.8935602693646042, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 242865.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.2965498996947806, "cur_kl_coeff": 0.06328124999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.7783555116566027, "policy_loss": -0.008279996556870482, "vf_loss": 0.7861236586693734, "vf_explained_var": 0.07417944436350828, "kl": 0.008088512049636856, "entropy": 1.1318240522076843, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 242865.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 516000, "num_env_steps_trained": 516000, "num_agent_steps_sampled": 2064000, "num_agent_steps_trained": 2064000}, "env_runners": {"episode_reward_max": 56.200000000000514, "episode_reward_min": -582.0, "episode_reward_mean": 8.321000000000158, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 38.000000000000256, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -13.379499999999965, "predator_policy": 17.54}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.6000000000002148, 15.800000000000004, -582.0, 56.200000000000514, 23.50000000000003, 32.900000000000226, 56.10000000000044, 25.900000000000105, 24.1000000000001, 34.50000000000022, 15.700000000000005, 3.7000000000002022, 10.599999999999968, -59.79999999999972, 39.30000000000028, -566.2, -12.799999999999566, 34.50000000000022, 35.40000000000023, 16.899999999999988, 29.10000000000014, 4.600000000000151, 38.90000000000028, 34.60000000000022, -29.599999999999547, 30.10000000000018, 31.200000000000166, 24.200000000000045, -28.49999999999951, 13.199999999999926, 24.80000000000005, -8.599999999999644, -9.099999999999628, 25.300000000000075, 22.400000000000013, 24.600000000000083, 21.299999999999994, 15.700000000000005, 31.200000000000163, 35.30000000000023, 26.600000000000108, 33.00000000000019, 24.900000000000052, 40.100000000000314, 32.000000000000185, 32.50000000000019, 17.99999999999999, -14.699999999999537, 16.79999999999998, 25.700000000000067, 7.600000000000115, 44.100000000000385, 31.200000000000163, 32.30000000000018, 29.000000000000124, -34.89999999999958, 35.600000000000236, 45.60000000000039, 21.200000000000006, 26.900000000000098, -3.400000000000051, 23.30000000000003, 26.20000000000008, 15.899999999999912, 38.10000000000027, 24.600000000000048, 33.400000000000205, -136.00000000000094, 37.40000000000026, 9.200000000000113, 36.700000000000266, 16.29999999999991, 50.80000000000049, 11.400000000000077, 37.80000000000027, 2.1000000000001458, 15.799999999999978, 12.300000000000031, 37.40000000000026, 38.80000000000028, 33.70000000000021, 26.50000000000008, 4.800000000000164, 14.700000000000008, 31.500000000000178, 37.50000000000026, 41.60000000000032, 43.00000000000035, 30.80000000000016, 32.100000000000186, 11.300000000000063, -11.199999999999578, 29.900000000000162, -1.8000000000001046, 41.20000000000034, 34.40000000000023, -2.499999999999744, 27.5000000000001, 39.40000000000029, 29.50000000000014], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-57.70000000000048, 5.299999999999965, -0.9999999999999846, -5.1999999999999265, -400.0, -400.0, 38.000000000000256, 3.1999999999999615, -5.1999999999999265, 13.699999999999964, 17.899999999999977, -21.999999999999744, -0.9999999999999846, 7.099999999999987, -13.899999999999807, -26.199999999999747, -5.200000000000021, -21.699999999999754, 11.599999999999964, 17.899999999999988, 1.0999999999999865, -9.399999999999855, -11.499999999999819, -17.79999999999974, -103.30000000000078, 17.899999999999988, -248.8000000000004, 20.000000000000014, -25.599999999999767, 17.899999999999988, -383.2, -400.0, -70.30000000000089, 9.499999999999964, 11.599999999999966, 17.899999999999988, 20.000000000000014, -13.599999999999783, -17.79999999999974, 13.699999999999964, -2.499999999999986, 11.599999999999964, 20.000000000000014, -48.399999999999835, 20.000000000000014, 17.899999999999988, 20.000000000000014, -9.399999999999855, -110.20000000000077, 11.599999999999964, 9.499999999999964, 11.599999999999964, 3.1999999999999615, 20.000000000000014, 0.7999999999999527, 7.399999999999972, -30.39999999999975, -45.09999999999976, -9.699999999999868, -6.099999999999945, 3.1999999999999615, 11.599999999999964, -53.500000000000135, -21.099999999999746, -17.79999999999974, -31.299999999999763, 20.000000000000014, -36.699999999999754, -13.599999999999783, 20.000000000000014, 5.299999999999965, -33.69999999999978, -15.699999999999747, 20.000000000000014, -5.1999999999999265, -3.099999999999958, 15.799999999999963, 7.399999999999965, -15.699999999999747, 20.000000000000014, 20.000000000000014, -9.39999999999989, 15.499999999999964, 9.499999999999964, 9.499999999999964, 7.399999999999965, 20.90000000000003, -56.80000000000027, -19.899999999999743, 17.899999999999988, -9.399999999999855, 17.899999999999988, 11.599999999999964, -13.599999999999783, -33.699999999999754, -42.99999999999976, -19.899999999999743, 13.699999999999964, 5.299999999999965, 7.399999999999965, -4.299999999999962, -24.099999999999746, -7.299999999999891, 34.40000000000026, 5.299999999999965, 17.899999999999988, 7.399999999999965, 17.899999999999988, 3.1999999999999615, 15.799999999999963, 13.699999999999964, -118.6000000000007, -9.399999999999855, 20.000000000000014, 20.000000000000014, -12.39999999999983, -3.099999999999958, 5.299999999999965, -24.099999999999746, 20.000000000000014, -17.799999999999976, -13.600000000000023, -7.299999999999891, 11.59999999999997, 17.899999999999988, -6.699999999999907, 6.199999999999968, -70.30000000000089, 13.099999999999971, 20.000000000000014, 1.0999999999999865, 9.499999999999964, 20.000000000000014, 7.399999999999965, 7.399999999999965, -303.399999999999, 7.399999999999965, 20.000000000000014, 3.1999999999999615, -21.999999999999744, -7.299999999999926, 20.000000000000014, -33.99999999999976, 8.299999999999965, 24.800000000000093, 20.000000000000014, 1.0999999999999865, -15.699999999999747, 20.000000000000014, 15.799999999999963, -47.19999999999976, 5.2999999999999785, 1.0999999999999865, -7.299999999999962, -29.799999999999756, -4.899999999999942, 20.000000000000014, 7.399999999999965, 20.000000000000014, 15.799999999999963, 7.399999999999965, 11.29999999999997, -0.9999999999999846, 9.499999999999964, -42.99999999999976, 15.799999999999963, 9.499999999999964, -17.79999999999974, 20.000000000000014, -11.499999999999819, 9.499999999999964, 20.000000000000014, 25.400000000000098, -17.79999999999974, 0.4999999999999688, -11.499999999999819, 20.000000000000014, 0.7999999999999865, -19.899999999999743, 20.000000000000014, -6.699999999999907, -12.9999999999998, 1.0999999999999865, -49.299999999999905, 20.000000000000014, -45.09999999999976, -24.099999999999746, -57.699999999999804, 11.299999999999972, 17.899999999999988, 7.39999999999998, 20.000000000000014, -7.599999999999904, -40.89999999999976, 13.699999999999964, -5.1999999999999265, 20.000000000000014, 7.399999999999965, 14.599999999999964, -24.099999999999746], "policy_predator_policy_reward": [35.0, 19.0, 10.0, 12.0, 200.0, 18.0, 7.0, 8.0, 12.0, 3.0, 18.0, 19.0, 32.0, 18.0, 35.0, 31.0, 25.0, 26.0, 4.0, 1.0, 11.0, 13.0, 18.0, 15.0, 52.0, 44.0, 126.0, 43.0, 23.0, 24.0, 200.0, 17.0, 43.0, 5.0, 5.0, 0.0, 13.0, 16.0, 18.0, 3.0, 14.0, 6.0, 20.0, 13.0, 1.0, 0.0, 13.0, 11.0, 54.0, 15.0, 5.0, 4.0, 8.0, 0.0, 9.0, 7.0, 28.0, 19.0, 22.0, 7.0, 2.0, 8.0, 33.0, 33.0, 33.0, 7.0, 26.0, 16.0, 16.0, 0.0, 19.0, 34.0, 0.0, 17.0, 12.0, 12.0, 6.0, 2.0, 14.0, 17.0, 14.0, 2.0, 3.0, 5.0, 2.0, 6.0, 38.0, 38.0, 15.0, 19.0, 11.0, 13.0, 4.0, 16.0, 31.0, 31.0, 4.0, 19.0, 6.0, 7.0, 19.0, 17.0, 12.0, 5.0, 1.0, 7.0, 6.0, 1.0, 8.0, 2.0, 66.0, 4.0, 11.0, 14.0, 20.0, 18.0, 11.0, 8.0, 21.0, 10.0, 14.0, 14.0, 16.0, 3.0, 14.0, 1.0, 39.0, 41.0, 1.0, 4.0, 5.0, 9.0, 0.0, 6.0, 154.0, 6.0, 4.0, 6.0, 8.0, 20.0, 12.0, 12.0, 22.0, 20.0, 1.0, 5.0, 9.0, 17.0, 2.0, 0.0, 17.0, 27.0, 9.0, 13.0, 22.0, 25.0, 6.0, 4.0, 1.0, 2.0, 14.0, 1.0, 10.0, 8.0, 12.0, 20.0, 18.0, 5.0, 9.0, 14.0, 3.0, 5.0, 16.0, 18.0, 26.0, 28.0, 0.0, 10.0, 13.0, 19.0, 17.0, 14.0, 4.0, 33.0, 28.0, 27.0, 58.0, 22.0, 1.0, 11.0, 4.0, 3.0, 18.0, 28.0, 7.0, 12.0, 6.0, 6.0, 20.0, 19.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.590491180987901, "mean_inference_ms": 1.8262433241343479, "mean_action_processing_ms": 0.2571568788525842, "mean_env_wait_ms": 0.1985905571122526, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00411832332611084, "StateBufferConnector_ms": 0.003726482391357422, "ViewRequirementAgentConnector_ms": 0.09724009037017822}, "num_episodes": 22, "episode_return_max": 56.200000000000514, "episode_return_min": -582.0, "episode_return_mean": 8.321000000000158, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2064000, "num_agent_steps_trained": 2064000, "num_env_steps_sampled": 516000, "num_env_steps_trained": 516000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 354.5972935594298, "num_env_steps_trained_throughput_per_sec": 354.5972935594298, "timesteps_total": 516000, "num_env_steps_sampled_lifetime": 516000, "num_agent_steps_sampled_lifetime": 2064000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2064000, "timers": {"training_iteration_time_ms": 11094.301, "restore_workers_time_ms": 0.013, "training_step_time_ms": 11094.241, "sample_time_ms": 1307.022, "learn_time_ms": 9770.323, "learn_throughput": 409.403, "synch_weights_time_ms": 14.611}, "counters": {"num_env_steps_sampled": 516000, "num_env_steps_trained": 516000, "num_agent_steps_sampled": 2064000, "num_agent_steps_trained": 2064000}, "done": false, "training_iteration": 129, "trial_id": "3dae5_00000", "date": "2024-08-14_09-30-37", "timestamp": 1723642237, "time_this_iter_s": 11.330228090286255, "time_total_s": 3055.7096860408783, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3831ca0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3055.7096860408783, "iterations_since_restore": 129, "perf": {"cpu_util_percent": 32.45, "ram_util_percent": 83.69375000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.0174413662108166, "cur_kl_coeff": 1.5449523925781246e-05, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.6736659092562539, "policy_loss": -0.007593101809274346, "vf_loss": 0.6812588318275712, "vf_explained_var": 0.3437501524806653, "kl": 0.011643256540309612, "entropy": 0.9147298243941453, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 244755.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.216115941446294, "cur_kl_coeff": 0.06328124999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.7472071079665391, "policy_loss": -0.011330071543392642, "vf_loss": 0.7579178952626766, "vf_explained_var": 0.14537204273794063, "kl": 0.009786197872089692, "entropy": 1.04376456800592, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 244755.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 520000, "num_env_steps_trained": 520000, "num_agent_steps_sampled": 2080000, "num_agent_steps_trained": 2080000}, "env_runners": {"episode_reward_max": 50.80000000000049, "episode_reward_min": -136.00000000000094, "episode_reward_mean": 21.531000000000162, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -303.399999999999, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 34.40000000000026, "predator_policy": 154.0}, "policy_reward_mean": {"prey_policy": -3.0294999999999583, "predator_policy": 13.795}, "custom_metrics": {}, "hist_stats": {"episode_reward": [35.40000000000023, 16.899999999999988, 29.10000000000014, 4.600000000000151, 38.90000000000028, 34.60000000000022, -29.599999999999547, 30.10000000000018, 31.200000000000166, 24.200000000000045, -28.49999999999951, 13.199999999999926, 24.80000000000005, -8.599999999999644, -9.099999999999628, 25.300000000000075, 22.400000000000013, 24.600000000000083, 21.299999999999994, 15.700000000000005, 31.200000000000163, 35.30000000000023, 26.600000000000108, 33.00000000000019, 24.900000000000052, 40.100000000000314, 32.000000000000185, 32.50000000000019, 17.99999999999999, -14.699999999999537, 16.79999999999998, 25.700000000000067, 7.600000000000115, 44.100000000000385, 31.200000000000163, 32.30000000000018, 29.000000000000124, -34.89999999999958, 35.600000000000236, 45.60000000000039, 21.200000000000006, 26.900000000000098, -3.400000000000051, 23.30000000000003, 26.20000000000008, 15.899999999999912, 38.10000000000027, 24.600000000000048, 33.400000000000205, -136.00000000000094, 37.40000000000026, 9.200000000000113, 36.700000000000266, 16.29999999999991, 50.80000000000049, 11.400000000000077, 37.80000000000027, 2.1000000000001458, 15.799999999999978, 12.300000000000031, 37.40000000000026, 38.80000000000028, 33.70000000000021, 26.50000000000008, 4.800000000000164, 14.700000000000008, 31.500000000000178, 37.50000000000026, 41.60000000000032, 43.00000000000035, 30.80000000000016, 32.100000000000186, 11.300000000000063, -11.199999999999578, 29.900000000000162, -1.8000000000001046, 41.20000000000034, 34.40000000000023, -2.499999999999744, 27.5000000000001, 39.40000000000029, 29.50000000000014, 23.800000000000043, 37.10000000000026, 35.40000000000023, 37.000000000000256, 31.000000000000163, 37.40000000000026, 36.40000000000025, 12.29999999999997, 35.40000000000023, 34.200000000000216, 32.80000000000019, 8.800000000000043, 12.500000000000059, 28.900000000000126, 27.900000000000105, 40.0000000000003, -32.89999999999965, 36.60000000000025], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, -13.599999999999783, -17.79999999999974, 13.699999999999964, -2.499999999999986, 11.599999999999964, 20.000000000000014, -48.399999999999835, 20.000000000000014, 17.899999999999988, 20.000000000000014, -9.399999999999855, -110.20000000000077, 11.599999999999964, 9.499999999999964, 11.599999999999964, 3.1999999999999615, 20.000000000000014, 0.7999999999999527, 7.399999999999972, -30.39999999999975, -45.09999999999976, -9.699999999999868, -6.099999999999945, 3.1999999999999615, 11.599999999999964, -53.500000000000135, -21.099999999999746, -17.79999999999974, -31.299999999999763, 20.000000000000014, -36.699999999999754, -13.599999999999783, 20.000000000000014, 5.299999999999965, -33.69999999999978, -15.699999999999747, 20.000000000000014, -5.1999999999999265, -3.099999999999958, 15.799999999999963, 7.399999999999965, -15.699999999999747, 20.000000000000014, 20.000000000000014, -9.39999999999989, 15.499999999999964, 9.499999999999964, 9.499999999999964, 7.399999999999965, 20.90000000000003, -56.80000000000027, -19.899999999999743, 17.899999999999988, -9.399999999999855, 17.899999999999988, 11.599999999999964, -13.599999999999783, -33.699999999999754, -42.99999999999976, -19.899999999999743, 13.699999999999964, 5.299999999999965, 7.399999999999965, -4.299999999999962, -24.099999999999746, -7.299999999999891, 34.40000000000026, 5.299999999999965, 17.899999999999988, 7.399999999999965, 17.899999999999988, 3.1999999999999615, 15.799999999999963, 13.699999999999964, -118.6000000000007, -9.399999999999855, 20.000000000000014, 20.000000000000014, -12.39999999999983, -3.099999999999958, 5.299999999999965, -24.099999999999746, 20.000000000000014, -17.799999999999976, -13.600000000000023, -7.299999999999891, 11.59999999999997, 17.899999999999988, -6.699999999999907, 6.199999999999968, -70.30000000000089, 13.099999999999971, 20.000000000000014, 1.0999999999999865, 9.499999999999964, 20.000000000000014, 7.399999999999965, 7.399999999999965, -303.399999999999, 7.399999999999965, 20.000000000000014, 3.1999999999999615, -21.999999999999744, -7.299999999999926, 20.000000000000014, -33.99999999999976, 8.299999999999965, 24.800000000000093, 20.000000000000014, 1.0999999999999865, -15.699999999999747, 20.000000000000014, 15.799999999999963, -47.19999999999976, 5.2999999999999785, 1.0999999999999865, -7.299999999999962, -29.799999999999756, -4.899999999999942, 20.000000000000014, 7.399999999999965, 20.000000000000014, 15.799999999999963, 7.399999999999965, 11.29999999999997, -0.9999999999999846, 9.499999999999964, -42.99999999999976, 15.799999999999963, 9.499999999999964, -17.79999999999974, 20.000000000000014, -11.499999999999819, 9.499999999999964, 20.000000000000014, 25.400000000000098, -17.79999999999974, 0.4999999999999688, -11.499999999999819, 20.000000000000014, 0.7999999999999865, -19.899999999999743, 20.000000000000014, -6.699999999999907, -12.9999999999998, 1.0999999999999865, -49.299999999999905, 20.000000000000014, -45.09999999999976, -24.099999999999746, -57.699999999999804, 11.299999999999972, 17.899999999999988, 7.39999999999998, 20.000000000000014, -7.599999999999904, -40.89999999999976, 13.699999999999964, -5.1999999999999265, 20.000000000000014, 7.399999999999965, 14.599999999999964, -24.099999999999746, -9.999999999999853, 15.799999999999956, 31.700000000000216, -13.599999999999783, -5.499999999999925, 17.899999999999988, 20.000000000000014, -21.999999999999744, 8.299999999999965, 13.699999999999966, 20.000000000000014, 13.399999999999965, 7.399999999999965, 20.000000000000014, 3.1999999999999615, -16.899999999999856, -13.599999999999804, 20.000000000000014, 3.1999999999999615, 20.000000000000014, 5.899999999999967, 17.899999999999988, 13.699999999999964, -40.89999999999976, -11.499999999999819, -0.9999999999999846, 8.599999999999968, 5.299999999999965, 3.1999999999999615, 13.699999999999964, 20.000000000000014, 20.000000000000014, -187.90000000000057, 20.000000000000014, 15.799999999999962, 15.799999999999963], "policy_predator_policy_reward": [13.0, 16.0, 18.0, 3.0, 14.0, 6.0, 20.0, 13.0, 1.0, 0.0, 13.0, 11.0, 54.0, 15.0, 5.0, 4.0, 8.0, 0.0, 9.0, 7.0, 28.0, 19.0, 22.0, 7.0, 2.0, 8.0, 33.0, 33.0, 33.0, 7.0, 26.0, 16.0, 16.0, 0.0, 19.0, 34.0, 0.0, 17.0, 12.0, 12.0, 6.0, 2.0, 14.0, 17.0, 14.0, 2.0, 3.0, 5.0, 2.0, 6.0, 38.0, 38.0, 15.0, 19.0, 11.0, 13.0, 4.0, 16.0, 31.0, 31.0, 4.0, 19.0, 6.0, 7.0, 19.0, 17.0, 12.0, 5.0, 1.0, 7.0, 6.0, 1.0, 8.0, 2.0, 66.0, 4.0, 11.0, 14.0, 20.0, 18.0, 11.0, 8.0, 21.0, 10.0, 14.0, 14.0, 16.0, 3.0, 14.0, 1.0, 39.0, 41.0, 1.0, 4.0, 5.0, 9.0, 0.0, 6.0, 154.0, 6.0, 4.0, 6.0, 8.0, 20.0, 12.0, 12.0, 22.0, 20.0, 1.0, 5.0, 9.0, 17.0, 2.0, 0.0, 17.0, 27.0, 9.0, 13.0, 22.0, 25.0, 6.0, 4.0, 1.0, 2.0, 14.0, 1.0, 10.0, 8.0, 12.0, 20.0, 18.0, 5.0, 9.0, 14.0, 3.0, 5.0, 16.0, 18.0, 26.0, 28.0, 0.0, 10.0, 13.0, 19.0, 17.0, 14.0, 4.0, 33.0, 28.0, 27.0, 58.0, 22.0, 1.0, 11.0, 4.0, 3.0, 18.0, 28.0, 7.0, 12.0, 6.0, 6.0, 20.0, 19.0, 2.0, 16.0, 3.0, 16.0, 10.0, 13.0, 19.0, 20.0, 6.0, 3.0, 4.0, 0.0, 6.0, 3.0, 13.0, 13.0, 15.0, 14.0, 8.0, 3.0, 1.0, 8.0, 8.0, 28.0, 10.0, 15.0, 8.0, 7.0, 8.0, 3.0, 0.0, 0.0, 87.0, 48.0, 3.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5902652469338844, "mean_inference_ms": 1.8259086221888103, "mean_action_processing_ms": 0.25735755038299374, "mean_env_wait_ms": 0.1983849167173674, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0040667057037353516, "StateBufferConnector_ms": 0.003876805305480957, "ViewRequirementAgentConnector_ms": 0.09538495540618896}, "num_episodes": 18, "episode_return_max": 50.80000000000049, "episode_return_min": -136.00000000000094, "episode_return_mean": 21.531000000000162, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2080000, "num_agent_steps_trained": 2080000, "num_env_steps_sampled": 520000, "num_env_steps_trained": 520000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 380.9562908409541, "num_env_steps_trained_throughput_per_sec": 380.9562908409541, "timesteps_total": 520000, "num_env_steps_sampled_lifetime": 520000, "num_agent_steps_sampled_lifetime": 2080000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2080000, "timers": {"training_iteration_time_ms": 11040.311, "restore_workers_time_ms": 0.013, "training_step_time_ms": 11040.251, "sample_time_ms": 1309.316, "learn_time_ms": 9714.084, "learn_throughput": 411.773, "synch_weights_time_ms": 14.538}, "counters": {"num_env_steps_sampled": 520000, "num_env_steps_trained": 520000, "num_agent_steps_sampled": 2080000, "num_agent_steps_trained": 2080000}, "done": false, "training_iteration": 130, "trial_id": "3dae5_00000", "date": "2024-08-14_09-30-48", "timestamp": 1723642248, "time_this_iter_s": 10.504828929901123, "time_total_s": 3066.2145149707794, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b36e0700>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3066.2145149707794, "iterations_since_restore": 130, "perf": {"cpu_util_percent": 28.919999999999998, "ram_util_percent": 83.74}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8500473547234106, "cur_kl_coeff": 1.5449523925781246e-05, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.5047750085355743, "policy_loss": -0.007254797081886815, "vf_loss": 0.5120296600555617, "vf_explained_var": 0.21457408165174818, "kl": 0.009392851458611205, "entropy": 0.8816492296715893, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 246645.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8575849919249772, "cur_kl_coeff": 0.06328124999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.5952800401243771, "policy_loss": -0.009091182480807657, "vf_loss": 0.6036020614758686, "vf_explained_var": 0.08413031467054256, "kl": 0.012154660921727574, "entropy": 1.0750479960567736, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 246645.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 524000, "num_env_steps_trained": 524000, "num_agent_steps_sampled": 2096000, "num_agent_steps_trained": 2096000}, "env_runners": {"episode_reward_max": 50.80000000000049, "episode_reward_min": -136.00000000000094, "episode_reward_mean": 23.372000000000163, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -303.399999999999, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 36.200000000000244, "predator_policy": 154.0}, "policy_reward_mean": {"prey_policy": -1.0839999999999625, "predator_policy": 12.77}, "custom_metrics": {}, "hist_stats": {"episode_reward": [21.299999999999994, 15.700000000000005, 31.200000000000163, 35.30000000000023, 26.600000000000108, 33.00000000000019, 24.900000000000052, 40.100000000000314, 32.000000000000185, 32.50000000000019, 17.99999999999999, -14.699999999999537, 16.79999999999998, 25.700000000000067, 7.600000000000115, 44.100000000000385, 31.200000000000163, 32.30000000000018, 29.000000000000124, -34.89999999999958, 35.600000000000236, 45.60000000000039, 21.200000000000006, 26.900000000000098, -3.400000000000051, 23.30000000000003, 26.20000000000008, 15.899999999999912, 38.10000000000027, 24.600000000000048, 33.400000000000205, -136.00000000000094, 37.40000000000026, 9.200000000000113, 36.700000000000266, 16.29999999999991, 50.80000000000049, 11.400000000000077, 37.80000000000027, 2.1000000000001458, 15.799999999999978, 12.300000000000031, 37.40000000000026, 38.80000000000028, 33.70000000000021, 26.50000000000008, 4.800000000000164, 14.700000000000008, 31.500000000000178, 37.50000000000026, 41.60000000000032, 43.00000000000035, 30.80000000000016, 32.100000000000186, 11.300000000000063, -11.199999999999578, 29.900000000000162, -1.8000000000001046, 41.20000000000034, 34.40000000000023, -2.499999999999744, 27.5000000000001, 39.40000000000029, 29.50000000000014, 23.800000000000043, 37.10000000000026, 35.40000000000023, 37.000000000000256, 31.000000000000163, 37.40000000000026, 36.40000000000025, 12.29999999999997, 35.40000000000023, 34.200000000000216, 32.80000000000019, 8.800000000000043, 12.500000000000059, 28.900000000000126, 27.900000000000105, 40.0000000000003, -32.89999999999965, 36.60000000000025, 20.199999999999974, -4.699999999999687, 40.60000000000031, 33.6000000000002, 40.30000000000031, 29.70000000000014, 33.800000000000196, 35.600000000000236, 39.40000000000029, 19.100000000000005, 37.50000000000026, -5.299999999999727, 38.60000000000028, -2.8999999999997446, 20.600000000000005, 32.00000000000018, 26.800000000000086, 28.700000000000127], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-15.699999999999747, 20.000000000000014, -5.1999999999999265, -3.099999999999958, 15.799999999999963, 7.399999999999965, -15.699999999999747, 20.000000000000014, 20.000000000000014, -9.39999999999989, 15.499999999999964, 9.499999999999964, 9.499999999999964, 7.399999999999965, 20.90000000000003, -56.80000000000027, -19.899999999999743, 17.899999999999988, -9.399999999999855, 17.899999999999988, 11.599999999999964, -13.599999999999783, -33.699999999999754, -42.99999999999976, -19.899999999999743, 13.699999999999964, 5.299999999999965, 7.399999999999965, -4.299999999999962, -24.099999999999746, -7.299999999999891, 34.40000000000026, 5.299999999999965, 17.899999999999988, 7.399999999999965, 17.899999999999988, 3.1999999999999615, 15.799999999999963, 13.699999999999964, -118.6000000000007, -9.399999999999855, 20.000000000000014, 20.000000000000014, -12.39999999999983, -3.099999999999958, 5.299999999999965, -24.099999999999746, 20.000000000000014, -17.799999999999976, -13.600000000000023, -7.299999999999891, 11.59999999999997, 17.899999999999988, -6.699999999999907, 6.199999999999968, -70.30000000000089, 13.099999999999971, 20.000000000000014, 1.0999999999999865, 9.499999999999964, 20.000000000000014, 7.399999999999965, 7.399999999999965, -303.399999999999, 7.399999999999965, 20.000000000000014, 3.1999999999999615, -21.999999999999744, -7.299999999999926, 20.000000000000014, -33.99999999999976, 8.299999999999965, 24.800000000000093, 20.000000000000014, 1.0999999999999865, -15.699999999999747, 20.000000000000014, 15.799999999999963, -47.19999999999976, 5.2999999999999785, 1.0999999999999865, -7.299999999999962, -29.799999999999756, -4.899999999999942, 20.000000000000014, 7.399999999999965, 20.000000000000014, 15.799999999999963, 7.399999999999965, 11.29999999999997, -0.9999999999999846, 9.499999999999964, -42.99999999999976, 15.799999999999963, 9.499999999999964, -17.79999999999974, 20.000000000000014, -11.499999999999819, 9.499999999999964, 20.000000000000014, 25.400000000000098, -17.79999999999974, 0.4999999999999688, -11.499999999999819, 20.000000000000014, 0.7999999999999865, -19.899999999999743, 20.000000000000014, -6.699999999999907, -12.9999999999998, 1.0999999999999865, -49.299999999999905, 20.000000000000014, -45.09999999999976, -24.099999999999746, -57.699999999999804, 11.299999999999972, 17.899999999999988, 7.39999999999998, 20.000000000000014, -7.599999999999904, -40.89999999999976, 13.699999999999964, -5.1999999999999265, 20.000000000000014, 7.399999999999965, 14.599999999999964, -24.099999999999746, -9.999999999999853, 15.799999999999956, 31.700000000000216, -13.599999999999783, -5.499999999999925, 17.899999999999988, 20.000000000000014, -21.999999999999744, 8.299999999999965, 13.699999999999966, 20.000000000000014, 13.399999999999965, 7.399999999999965, 20.000000000000014, 3.1999999999999615, -16.899999999999856, -13.599999999999804, 20.000000000000014, 3.1999999999999615, 20.000000000000014, 5.899999999999967, 17.899999999999988, 13.699999999999964, -40.89999999999976, -11.499999999999819, -0.9999999999999846, 8.599999999999968, 5.299999999999965, 3.1999999999999615, 13.699999999999964, 20.000000000000014, 20.000000000000014, -187.90000000000057, 20.000000000000014, 15.799999999999962, 15.799999999999963, 9.499999999999964, -7.299999999999905, -21.999999999999744, -15.699999999999747, 5.299999999999965, 26.300000000000114, 15.799999999999963, 3.799999999999969, -16.899999999999743, 36.200000000000244, -5.1999999999999265, 20.90000000000003, 20.000000000000014, -2.200000000000059, -6.399999999999908, 20.000000000000014, 7.399999999999965, 20.000000000000014, -5.1999999999999265, 5.299999999999965, 9.499999999999964, 20.000000000000014, -7.299999999999944, -42.99999999999976, 20.000000000000014, 11.599999999999964, -61.900000000000766, 20.000000000000014, 9.499999999999964, 1.099999999999983, 3.1999999999999615, 15.799999999999962, -3.099999999999958, 17.899999999999988, 5.299999999999979, 7.399999999999965], "policy_predator_policy_reward": [0.0, 17.0, 12.0, 12.0, 6.0, 2.0, 14.0, 17.0, 14.0, 2.0, 3.0, 5.0, 2.0, 6.0, 38.0, 38.0, 15.0, 19.0, 11.0, 13.0, 4.0, 16.0, 31.0, 31.0, 4.0, 19.0, 6.0, 7.0, 19.0, 17.0, 12.0, 5.0, 1.0, 7.0, 6.0, 1.0, 8.0, 2.0, 66.0, 4.0, 11.0, 14.0, 20.0, 18.0, 11.0, 8.0, 21.0, 10.0, 14.0, 14.0, 16.0, 3.0, 14.0, 1.0, 39.0, 41.0, 1.0, 4.0, 5.0, 9.0, 0.0, 6.0, 154.0, 6.0, 4.0, 6.0, 8.0, 20.0, 12.0, 12.0, 22.0, 20.0, 1.0, 5.0, 9.0, 17.0, 2.0, 0.0, 17.0, 27.0, 9.0, 13.0, 22.0, 25.0, 6.0, 4.0, 1.0, 2.0, 14.0, 1.0, 10.0, 8.0, 12.0, 20.0, 18.0, 5.0, 9.0, 14.0, 3.0, 5.0, 16.0, 18.0, 26.0, 28.0, 0.0, 10.0, 13.0, 19.0, 17.0, 14.0, 4.0, 33.0, 28.0, 27.0, 58.0, 22.0, 1.0, 11.0, 4.0, 3.0, 18.0, 28.0, 7.0, 12.0, 6.0, 6.0, 20.0, 19.0, 2.0, 16.0, 3.0, 16.0, 10.0, 13.0, 19.0, 20.0, 6.0, 3.0, 4.0, 0.0, 6.0, 3.0, 13.0, 13.0, 15.0, 14.0, 8.0, 3.0, 1.0, 8.0, 8.0, 28.0, 10.0, 15.0, 8.0, 7.0, 8.0, 3.0, 0.0, 0.0, 87.0, 48.0, 3.0, 2.0, 13.0, 5.0, 20.0, 13.0, 7.0, 2.0, 12.0, 2.0, 18.0, 3.0, 12.0, 2.0, 6.0, 10.0, 13.0, 9.0, 6.0, 6.0, 12.0, 7.0, 5.0, 3.0, 30.0, 15.0, 4.0, 3.0, 4.0, 35.0, 10.0, 0.0, 5.0, 8.0, 1.0, 11.0, 6.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5900913514483069, "mean_inference_ms": 1.8254757610355796, "mean_action_processing_ms": 0.2571651037420261, "mean_env_wait_ms": 0.19830507192879998, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004124760627746582, "StateBufferConnector_ms": 0.0039261579513549805, "ViewRequirementAgentConnector_ms": 0.09646689891815186}, "num_episodes": 18, "episode_return_max": 50.80000000000049, "episode_return_min": -136.00000000000094, "episode_return_mean": 23.372000000000163, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2096000, "num_agent_steps_trained": 2096000, "num_env_steps_sampled": 524000, "num_env_steps_trained": 524000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 350.11029469612583, "num_env_steps_trained_throughput_per_sec": 350.11029469612583, "timesteps_total": 524000, "num_env_steps_sampled_lifetime": 524000, "num_agent_steps_sampled_lifetime": 2096000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2096000, "timers": {"training_iteration_time_ms": 11034.411, "restore_workers_time_ms": 0.013, "training_step_time_ms": 11034.351, "sample_time_ms": 1311.923, "learn_time_ms": 9705.314, "learn_throughput": 412.145, "synch_weights_time_ms": 14.844}, "counters": {"num_env_steps_sampled": 524000, "num_env_steps_trained": 524000, "num_agent_steps_sampled": 2096000, "num_agent_steps_trained": 2096000}, "done": false, "training_iteration": 131, "trial_id": "3dae5_00000", "date": "2024-08-14_09-30-59", "timestamp": 1723642259, "time_this_iter_s": 11.468868017196655, "time_total_s": 3077.683382987976, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b394fdc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3077.683382987976, "iterations_since_restore": 131, "perf": {"cpu_util_percent": 33.85, "ram_util_percent": 83.575}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9598994410227215, "cur_kl_coeff": 1.5449523925781246e-05, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.43185535464337266, "policy_loss": -0.004479326654124571, "vf_loss": 0.43633449679565806, "vf_explained_var": 0.38995240450536134, "kl": 0.0120066390400184, "entropy": 0.762303009834239, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 248535.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6535937675329113, "cur_kl_coeff": 0.06328124999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.5229922820453313, "policy_loss": -0.007872253155370277, "vf_loss": 0.5302700558214118, "vf_explained_var": 0.03594214764852372, "kl": 0.009394237558118983, "entropy": 1.0479110161463419, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 248535.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 528000, "num_env_steps_trained": 528000, "num_agent_steps_sampled": 2112000, "num_agent_steps_trained": 2112000}, "env_runners": {"episode_reward_max": 57.300000000000495, "episode_reward_min": -136.00000000000094, "episode_reward_mean": 24.154000000000153, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -303.399999999999, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 42.50000000000025, "predator_policy": 154.0}, "policy_reward_mean": {"prey_policy": 0.407000000000028, "predator_policy": 11.67}, "custom_metrics": {}, "hist_stats": {"episode_reward": [26.900000000000098, -3.400000000000051, 23.30000000000003, 26.20000000000008, 15.899999999999912, 38.10000000000027, 24.600000000000048, 33.400000000000205, -136.00000000000094, 37.40000000000026, 9.200000000000113, 36.700000000000266, 16.29999999999991, 50.80000000000049, 11.400000000000077, 37.80000000000027, 2.1000000000001458, 15.799999999999978, 12.300000000000031, 37.40000000000026, 38.80000000000028, 33.70000000000021, 26.50000000000008, 4.800000000000164, 14.700000000000008, 31.500000000000178, 37.50000000000026, 41.60000000000032, 43.00000000000035, 30.80000000000016, 32.100000000000186, 11.300000000000063, -11.199999999999578, 29.900000000000162, -1.8000000000001046, 41.20000000000034, 34.40000000000023, -2.499999999999744, 27.5000000000001, 39.40000000000029, 29.50000000000014, 23.800000000000043, 37.10000000000026, 35.40000000000023, 37.000000000000256, 31.000000000000163, 37.40000000000026, 36.40000000000025, 12.29999999999997, 35.40000000000023, 34.200000000000216, 32.80000000000019, 8.800000000000043, 12.500000000000059, 28.900000000000126, 27.900000000000105, 40.0000000000003, -32.89999999999965, 36.60000000000025, 20.199999999999974, -4.699999999999687, 40.60000000000031, 33.6000000000002, 40.30000000000031, 29.70000000000014, 33.800000000000196, 35.600000000000236, 39.40000000000029, 19.100000000000005, 37.50000000000026, -5.299999999999727, 38.60000000000028, -2.8999999999997446, 20.600000000000005, 32.00000000000018, 26.800000000000086, 28.700000000000127, 29.000000000000124, 32.20000000000019, 29.000000000000124, 44.70000000000037, 22.40000000000001, 33.1000000000002, 34.50000000000022, 57.300000000000495, 27.900000000000116, -2.4999999999997584, 24.500000000000046, 38.90000000000028, 35.70000000000024, 18.000000000000004, 31.200000000000163, 22.90000000000002, 29.40000000000014, 21.900000000000002, -47.30000000000073, 39.9000000000003, 38.20000000000027, 45.000000000000384, 22.40000000000001], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-24.099999999999746, 20.000000000000014, -17.799999999999976, -13.600000000000023, -7.299999999999891, 11.59999999999997, 17.899999999999988, -6.699999999999907, 6.199999999999968, -70.30000000000089, 13.099999999999971, 20.000000000000014, 1.0999999999999865, 9.499999999999964, 20.000000000000014, 7.399999999999965, 7.399999999999965, -303.399999999999, 7.399999999999965, 20.000000000000014, 3.1999999999999615, -21.999999999999744, -7.299999999999926, 20.000000000000014, -33.99999999999976, 8.299999999999965, 24.800000000000093, 20.000000000000014, 1.0999999999999865, -15.699999999999747, 20.000000000000014, 15.799999999999963, -47.19999999999976, 5.2999999999999785, 1.0999999999999865, -7.299999999999962, -29.799999999999756, -4.899999999999942, 20.000000000000014, 7.399999999999965, 20.000000000000014, 15.799999999999963, 7.399999999999965, 11.29999999999997, -0.9999999999999846, 9.499999999999964, -42.99999999999976, 15.799999999999963, 9.499999999999964, -17.79999999999974, 20.000000000000014, -11.499999999999819, 9.499999999999964, 20.000000000000014, 25.400000000000098, -17.79999999999974, 0.4999999999999688, -11.499999999999819, 20.000000000000014, 0.7999999999999865, -19.899999999999743, 20.000000000000014, -6.699999999999907, -12.9999999999998, 1.0999999999999865, -49.299999999999905, 20.000000000000014, -45.09999999999976, -24.099999999999746, -57.699999999999804, 11.299999999999972, 17.899999999999988, 7.39999999999998, 20.000000000000014, -7.599999999999904, -40.89999999999976, 13.699999999999964, -5.1999999999999265, 20.000000000000014, 7.399999999999965, 14.599999999999964, -24.099999999999746, -9.999999999999853, 15.799999999999956, 31.700000000000216, -13.599999999999783, -5.499999999999925, 17.899999999999988, 20.000000000000014, -21.999999999999744, 8.299999999999965, 13.699999999999966, 20.000000000000014, 13.399999999999965, 7.399999999999965, 20.000000000000014, 3.1999999999999615, -16.899999999999856, -13.599999999999804, 20.000000000000014, 3.1999999999999615, 20.000000000000014, 5.899999999999967, 17.899999999999988, 13.699999999999964, -40.89999999999976, -11.499999999999819, -0.9999999999999846, 8.599999999999968, 5.299999999999965, 3.1999999999999615, 13.699999999999964, 20.000000000000014, 20.000000000000014, -187.90000000000057, 20.000000000000014, 15.799999999999962, 15.799999999999963, 9.499999999999964, -7.299999999999905, -21.999999999999744, -15.699999999999747, 5.299999999999965, 26.300000000000114, 15.799999999999963, 3.799999999999969, -16.899999999999743, 36.200000000000244, -5.1999999999999265, 20.90000000000003, 20.000000000000014, -2.200000000000059, -6.399999999999908, 20.000000000000014, 7.399999999999965, 20.000000000000014, -5.1999999999999265, 5.299999999999965, 9.499999999999964, 20.000000000000014, -7.299999999999944, -42.99999999999976, 20.000000000000014, 11.599999999999964, -61.900000000000766, 20.000000000000014, 9.499999999999964, 1.099999999999983, 3.1999999999999615, 15.799999999999962, -3.099999999999958, 17.899999999999988, 5.299999999999979, 7.399999999999965, 9.499999999999964, 9.499999999999964, -0.6999999999999993, 17.899999999999988, 3.1999999999999615, 15.799999999999963, 27.20000000000013, 9.499999999999964, -5.19999999999998, 11.599999999999964, -2.4999999999999716, 20.600000000000026, 9.499999999999964, 20.000000000000014, 42.50000000000025, -11.199999999999841, -3.100000000000001, 20.000000000000014, -70.30000000000089, 21.80000000000004, 7.099999999999966, 7.399999999999965, 20.000000000000014, 17.899999999999988, 16.399999999999963, 5.299999999999965, -0.9999999999999846, -0.9999999999999846, 13.699999999999964, 9.499999999999964, 5.299999999999965, -0.39999999999999936, 0.19999999999998655, 9.199999999999969, -5.499999999999925, 7.399999999999965, -47.19999999999976, -45.09999999999976, 5.899999999999967, 20.000000000000014, 20.000000000000014, 3.1999999999999615, 13.999999999999968, 20.000000000000014, 15.799999999999963, -9.399999999999855], "policy_predator_policy_reward": [21.0, 10.0, 14.0, 14.0, 16.0, 3.0, 14.0, 1.0, 39.0, 41.0, 1.0, 4.0, 5.0, 9.0, 0.0, 6.0, 154.0, 6.0, 4.0, 6.0, 8.0, 20.0, 12.0, 12.0, 22.0, 20.0, 1.0, 5.0, 9.0, 17.0, 2.0, 0.0, 17.0, 27.0, 9.0, 13.0, 22.0, 25.0, 6.0, 4.0, 1.0, 2.0, 14.0, 1.0, 10.0, 8.0, 12.0, 20.0, 18.0, 5.0, 9.0, 14.0, 3.0, 5.0, 16.0, 18.0, 26.0, 28.0, 0.0, 10.0, 13.0, 19.0, 17.0, 14.0, 4.0, 33.0, 28.0, 27.0, 58.0, 22.0, 1.0, 11.0, 4.0, 3.0, 18.0, 28.0, 7.0, 12.0, 6.0, 6.0, 20.0, 19.0, 2.0, 16.0, 3.0, 16.0, 10.0, 13.0, 19.0, 20.0, 6.0, 3.0, 4.0, 0.0, 6.0, 3.0, 13.0, 13.0, 15.0, 14.0, 8.0, 3.0, 1.0, 8.0, 8.0, 28.0, 10.0, 15.0, 8.0, 7.0, 8.0, 3.0, 0.0, 0.0, 87.0, 48.0, 3.0, 2.0, 13.0, 5.0, 20.0, 13.0, 7.0, 2.0, 12.0, 2.0, 18.0, 3.0, 12.0, 2.0, 6.0, 10.0, 13.0, 9.0, 6.0, 6.0, 12.0, 7.0, 5.0, 3.0, 30.0, 15.0, 4.0, 3.0, 4.0, 35.0, 10.0, 0.0, 5.0, 8.0, 1.0, 11.0, 6.0, 10.0, 5.0, 5.0, 13.0, 2.0, 8.0, 2.0, 5.0, 3.0, 4.0, 12.0, 3.0, 12.0, 3.0, 2.0, 9.0, 17.0, 9.0, 2.0, 3.0, 43.0, 9.0, 1.0, 0.0, 1.0, 5.0, 9.0, 10.0, 10.0, 3.0, 5.0, 11.0, 7.0, 8.0, 12.0, 5.0, 15.0, 32.0, 13.0, 7.0, 7.0, 8.0, 7.0, 8.0, 3.0, 2.0, 14.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5901760229435143, "mean_inference_ms": 1.8240214683051081, "mean_action_processing_ms": 0.25727474718746624, "mean_env_wait_ms": 0.198292218270878, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004058957099914551, "StateBufferConnector_ms": 0.00449061393737793, "ViewRequirementAgentConnector_ms": 0.09808492660522461}, "num_episodes": 23, "episode_return_max": 57.300000000000495, "episode_return_min": -136.00000000000094, "episode_return_mean": 24.154000000000153, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2112000, "num_agent_steps_trained": 2112000, "num_env_steps_sampled": 528000, "num_env_steps_trained": 528000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 344.3537427364812, "num_env_steps_trained_throughput_per_sec": 344.3537427364812, "timesteps_total": 528000, "num_env_steps_sampled_lifetime": 528000, "num_agent_steps_sampled_lifetime": 2112000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2112000, "timers": {"training_iteration_time_ms": 11069.972, "restore_workers_time_ms": 0.013, "training_step_time_ms": 11069.912, "sample_time_ms": 1318.122, "learn_time_ms": 9733.996, "learn_throughput": 410.931, "synch_weights_time_ms": 15.28}, "counters": {"num_env_steps_sampled": 528000, "num_env_steps_trained": 528000, "num_agent_steps_sampled": 2112000, "num_agent_steps_trained": 2112000}, "done": false, "training_iteration": 132, "trial_id": "3dae5_00000", "date": "2024-08-14_09-31-11", "timestamp": 1723642271, "time_this_iter_s": 11.683025121688843, "time_total_s": 3089.366408109665, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3981f70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3089.366408109665, "iterations_since_restore": 132, "perf": {"cpu_util_percent": 36.55882352941177, "ram_util_percent": 83.68235294117646}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5226362866857064, "cur_kl_coeff": 1.5449523925781246e-05, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.41915997757955836, "policy_loss": -0.00373453740018208, "vf_loss": 0.42289438992541617, "vf_explained_var": 0.17456912789395246, "kl": 0.008149928664784574, "entropy": 0.6764944130466097, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 250425.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6791021089389842, "cur_kl_coeff": 0.06328124999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.4530529479402864, "policy_loss": -0.009556019629928327, "vf_loss": 0.4623036009057489, "vf_explained_var": 0.1331005944461419, "kl": 0.004825561854621324, "entropy": 1.0484991364693514, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 250425.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 532000, "num_env_steps_trained": 532000, "num_agent_steps_sampled": 2128000, "num_agent_steps_trained": 2128000}, "env_runners": {"episode_reward_max": 58.90000000000049, "episode_reward_min": -47.30000000000073, "episode_reward_mean": 27.461000000000187, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -187.90000000000057, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 42.50000000000025, "predator_policy": 87.0}, "policy_reward_mean": {"prey_policy": 3.6755000000000253, "predator_policy": 10.055}, "custom_metrics": {}, "hist_stats": {"episode_reward": [12.300000000000031, 37.40000000000026, 38.80000000000028, 33.70000000000021, 26.50000000000008, 4.800000000000164, 14.700000000000008, 31.500000000000178, 37.50000000000026, 41.60000000000032, 43.00000000000035, 30.80000000000016, 32.100000000000186, 11.300000000000063, -11.199999999999578, 29.900000000000162, -1.8000000000001046, 41.20000000000034, 34.40000000000023, -2.499999999999744, 27.5000000000001, 39.40000000000029, 29.50000000000014, 23.800000000000043, 37.10000000000026, 35.40000000000023, 37.000000000000256, 31.000000000000163, 37.40000000000026, 36.40000000000025, 12.29999999999997, 35.40000000000023, 34.200000000000216, 32.80000000000019, 8.800000000000043, 12.500000000000059, 28.900000000000126, 27.900000000000105, 40.0000000000003, -32.89999999999965, 36.60000000000025, 20.199999999999974, -4.699999999999687, 40.60000000000031, 33.6000000000002, 40.30000000000031, 29.70000000000014, 33.800000000000196, 35.600000000000236, 39.40000000000029, 19.100000000000005, 37.50000000000026, -5.299999999999727, 38.60000000000028, -2.8999999999997446, 20.600000000000005, 32.00000000000018, 26.800000000000086, 28.700000000000127, 29.000000000000124, 32.20000000000019, 29.000000000000124, 44.70000000000037, 22.40000000000001, 33.1000000000002, 34.50000000000022, 57.300000000000495, 27.900000000000116, -2.4999999999997584, 24.500000000000046, 38.90000000000028, 35.70000000000024, 18.000000000000004, 31.200000000000163, 22.90000000000002, 29.40000000000014, 21.900000000000002, -47.30000000000073, 39.9000000000003, 38.20000000000027, 45.000000000000384, 22.40000000000001, 33.4000000000002, 39.9000000000003, 41.40000000000032, 30.100000000000147, 23.50000000000003, 22.40000000000001, 26.800000000000086, 52.500000000000455, 58.90000000000049, 39.100000000000286, -14.199999999999525, 30.600000000000158, 43.500000000000355, 33.4000000000002, 44.70000000000037, 33.0000000000002, 24.80000000000005, 33.400000000000205], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-29.799999999999756, -4.899999999999942, 20.000000000000014, 7.399999999999965, 20.000000000000014, 15.799999999999963, 7.399999999999965, 11.29999999999997, -0.9999999999999846, 9.499999999999964, -42.99999999999976, 15.799999999999963, 9.499999999999964, -17.79999999999974, 20.000000000000014, -11.499999999999819, 9.499999999999964, 20.000000000000014, 25.400000000000098, -17.79999999999974, 0.4999999999999688, -11.499999999999819, 20.000000000000014, 0.7999999999999865, -19.899999999999743, 20.000000000000014, -6.699999999999907, -12.9999999999998, 1.0999999999999865, -49.299999999999905, 20.000000000000014, -45.09999999999976, -24.099999999999746, -57.699999999999804, 11.299999999999972, 17.899999999999988, 7.39999999999998, 20.000000000000014, -7.599999999999904, -40.89999999999976, 13.699999999999964, -5.1999999999999265, 20.000000000000014, 7.399999999999965, 14.599999999999964, -24.099999999999746, -9.999999999999853, 15.799999999999956, 31.700000000000216, -13.599999999999783, -5.499999999999925, 17.899999999999988, 20.000000000000014, -21.999999999999744, 8.299999999999965, 13.699999999999966, 20.000000000000014, 13.399999999999965, 7.399999999999965, 20.000000000000014, 3.1999999999999615, -16.899999999999856, -13.599999999999804, 20.000000000000014, 3.1999999999999615, 20.000000000000014, 5.899999999999967, 17.899999999999988, 13.699999999999964, -40.89999999999976, -11.499999999999819, -0.9999999999999846, 8.599999999999968, 5.299999999999965, 3.1999999999999615, 13.699999999999964, 20.000000000000014, 20.000000000000014, -187.90000000000057, 20.000000000000014, 15.799999999999962, 15.799999999999963, 9.499999999999964, -7.299999999999905, -21.999999999999744, -15.699999999999747, 5.299999999999965, 26.300000000000114, 15.799999999999963, 3.799999999999969, -16.899999999999743, 36.200000000000244, -5.1999999999999265, 20.90000000000003, 20.000000000000014, -2.200000000000059, -6.399999999999908, 20.000000000000014, 7.399999999999965, 20.000000000000014, -5.1999999999999265, 5.299999999999965, 9.499999999999964, 20.000000000000014, -7.299999999999944, -42.99999999999976, 20.000000000000014, 11.599999999999964, -61.900000000000766, 20.000000000000014, 9.499999999999964, 1.099999999999983, 3.1999999999999615, 15.799999999999962, -3.099999999999958, 17.899999999999988, 5.299999999999979, 7.399999999999965, 9.499999999999964, 9.499999999999964, -0.6999999999999993, 17.899999999999988, 3.1999999999999615, 15.799999999999963, 27.20000000000013, 9.499999999999964, -5.19999999999998, 11.599999999999964, -2.4999999999999716, 20.600000000000026, 9.499999999999964, 20.000000000000014, 42.50000000000025, -11.199999999999841, -3.100000000000001, 20.000000000000014, -70.30000000000089, 21.80000000000004, 7.099999999999966, 7.399999999999965, 20.000000000000014, 17.899999999999988, 16.399999999999963, 5.299999999999965, -0.9999999999999846, -0.9999999999999846, 13.699999999999964, 9.499999999999964, 5.299999999999965, -0.39999999999999936, 0.19999999999998655, 9.199999999999969, -5.499999999999925, 7.399999999999965, -47.19999999999976, -45.09999999999976, 5.899999999999967, 20.000000000000014, 20.000000000000014, 3.1999999999999615, 13.999999999999968, 20.000000000000014, 15.799999999999963, -9.399999999999855, 9.499999999999964, 17.899999999999988, 17.599999999999984, 17.29999999999998, 20.000000000000014, 1.3999999999999726, 20.000000000000014, 1.0999999999999865, 9.499999999999964, -0.9999999999999881, -5.199999999999934, 11.599999999999964, 9.499999999999964, 5.299999999999965, 41.00000000000023, -8.499999999999872, 20.900000000000027, 26.000000000000117, 1.0999999999999865, 20.000000000000014, -38.799999999999756, -9.399999999999855, 20.600000000000026, -0.9999999999999846, -4.899999999999942, 25.400000000000098, 15.799999999999963, 11.599999999999964, 27.20000000000013, 9.499999999999964, 4.999999999999966, 20.000000000000014, 7.399999999999965, 7.399999999999965, 7.399999999999965, 20.000000000000014], "policy_predator_policy_reward": [22.0, 25.0, 6.0, 4.0, 1.0, 2.0, 14.0, 1.0, 10.0, 8.0, 12.0, 20.0, 18.0, 5.0, 9.0, 14.0, 3.0, 5.0, 16.0, 18.0, 26.0, 28.0, 0.0, 10.0, 13.0, 19.0, 17.0, 14.0, 4.0, 33.0, 28.0, 27.0, 58.0, 22.0, 1.0, 11.0, 4.0, 3.0, 18.0, 28.0, 7.0, 12.0, 6.0, 6.0, 20.0, 19.0, 2.0, 16.0, 3.0, 16.0, 10.0, 13.0, 19.0, 20.0, 6.0, 3.0, 4.0, 0.0, 6.0, 3.0, 13.0, 13.0, 15.0, 14.0, 8.0, 3.0, 1.0, 8.0, 8.0, 28.0, 10.0, 15.0, 8.0, 7.0, 8.0, 3.0, 0.0, 0.0, 87.0, 48.0, 3.0, 2.0, 13.0, 5.0, 20.0, 13.0, 7.0, 2.0, 12.0, 2.0, 18.0, 3.0, 12.0, 2.0, 6.0, 10.0, 13.0, 9.0, 6.0, 6.0, 12.0, 7.0, 5.0, 3.0, 30.0, 15.0, 4.0, 3.0, 4.0, 35.0, 10.0, 0.0, 5.0, 8.0, 1.0, 11.0, 6.0, 10.0, 5.0, 5.0, 13.0, 2.0, 8.0, 2.0, 5.0, 3.0, 4.0, 12.0, 3.0, 12.0, 3.0, 2.0, 9.0, 17.0, 9.0, 2.0, 3.0, 43.0, 9.0, 1.0, 0.0, 1.0, 5.0, 9.0, 10.0, 10.0, 3.0, 5.0, 11.0, 7.0, 8.0, 12.0, 5.0, 15.0, 32.0, 13.0, 7.0, 7.0, 8.0, 7.0, 8.0, 3.0, 2.0, 14.0, 5.0, 1.0, 3.0, 2.0, 9.0, 11.0, 0.0, 9.0, 5.0, 10.0, 4.0, 12.0, 5.0, 7.0, 14.0, 6.0, 5.0, 7.0, 9.0, 9.0, 6.0, 28.0, 1.0, 10.0, 9.0, 14.0, 2.0, 4.0, 5.0, 3.0, 8.0, 0.0, 6.0, 4.0, 6.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5899099092578848, "mean_inference_ms": 1.825055753936335, "mean_action_processing_ms": 0.2567837909743179, "mean_env_wait_ms": 0.19822938504402626, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004130125045776367, "StateBufferConnector_ms": 0.004066109657287598, "ViewRequirementAgentConnector_ms": 0.10157859325408936}, "num_episodes": 18, "episode_return_max": 58.90000000000049, "episode_return_min": -47.30000000000073, "episode_return_mean": 27.461000000000187, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2128000, "num_agent_steps_trained": 2128000, "num_env_steps_sampled": 532000, "num_env_steps_trained": 532000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 371.1767210302921, "num_env_steps_trained_throughput_per_sec": 371.1767210302921, "timesteps_total": 532000, "num_env_steps_sampled_lifetime": 532000, "num_agent_steps_sampled_lifetime": 2128000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2128000, "timers": {"training_iteration_time_ms": 11029.097, "restore_workers_time_ms": 0.013, "training_step_time_ms": 11029.038, "sample_time_ms": 1327.038, "learn_time_ms": 9684.67, "learn_throughput": 413.024, "synch_weights_time_ms": 14.955}, "counters": {"num_env_steps_sampled": 532000, "num_env_steps_trained": 532000, "num_agent_steps_sampled": 2128000, "num_agent_steps_trained": 2128000}, "done": false, "training_iteration": 133, "trial_id": "3dae5_00000", "date": "2024-08-14_09-31-22", "timestamp": 1723642282, "time_this_iter_s": 10.780671119689941, "time_total_s": 3100.147079229355, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b38960d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3100.147079229355, "iterations_since_restore": 133, "perf": {"cpu_util_percent": 29.653333333333332, "ram_util_percent": 83.68}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4638253812752073, "cur_kl_coeff": 1.5449523925781246e-05, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.6704669172170932, "policy_loss": -0.0029927460121966544, "vf_loss": 0.673459506590688, "vf_explained_var": 0.09289525472928607, "kl": 0.010233569472848597, "entropy": 0.7277869349434263, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 252315.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.039404996157323, "cur_kl_coeff": 0.03164062499999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.985045976710146, "policy_loss": -0.003063570039603051, "vf_loss": 0.9878017732311809, "vf_explained_var": 0.004099166267132633, "kl": 0.009727110889830205, "entropy": 1.0654872544858822, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 252315.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 536000, "num_env_steps_trained": 536000, "num_agent_steps_sampled": 2144000, "num_agent_steps_trained": 2144000}, "env_runners": {"episode_reward_max": 58.90000000000049, "episode_reward_min": -573.8, "episode_reward_mean": 21.419000000000178, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 42.50000000000025, "predator_policy": 197.0}, "policy_reward_mean": {"prey_policy": 0.489500000000005, "predator_policy": 10.22}, "custom_metrics": {}, "hist_stats": {"episode_reward": [29.50000000000014, 23.800000000000043, 37.10000000000026, 35.40000000000023, 37.000000000000256, 31.000000000000163, 37.40000000000026, 36.40000000000025, 12.29999999999997, 35.40000000000023, 34.200000000000216, 32.80000000000019, 8.800000000000043, 12.500000000000059, 28.900000000000126, 27.900000000000105, 40.0000000000003, -32.89999999999965, 36.60000000000025, 20.199999999999974, -4.699999999999687, 40.60000000000031, 33.6000000000002, 40.30000000000031, 29.70000000000014, 33.800000000000196, 35.600000000000236, 39.40000000000029, 19.100000000000005, 37.50000000000026, -5.299999999999727, 38.60000000000028, -2.8999999999997446, 20.600000000000005, 32.00000000000018, 26.800000000000086, 28.700000000000127, 29.000000000000124, 32.20000000000019, 29.000000000000124, 44.70000000000037, 22.40000000000001, 33.1000000000002, 34.50000000000022, 57.300000000000495, 27.900000000000116, -2.4999999999997584, 24.500000000000046, 38.90000000000028, 35.70000000000024, 18.000000000000004, 31.200000000000163, 22.90000000000002, 29.40000000000014, 21.900000000000002, -47.30000000000073, 39.9000000000003, 38.20000000000027, 45.000000000000384, 22.40000000000001, 33.4000000000002, 39.9000000000003, 41.40000000000032, 30.100000000000147, 23.50000000000003, 22.40000000000001, 26.800000000000086, 52.500000000000455, 58.90000000000049, 39.100000000000286, -14.199999999999525, 30.600000000000158, 43.500000000000355, 33.4000000000002, 44.70000000000037, 33.0000000000002, 24.80000000000005, 33.400000000000205, 26.50000000000008, 41.70000000000032, 41.900000000000325, 41.00000000000031, 39.100000000000286, 22.200000000000006, 37.600000000000264, 18.000000000000004, -3.899999999999724, 6.000000000000153, 22.40000000000001, 13.60000000000004, 25.100000000000065, 45.1000000000004, 23.500000000000032, 25.700000000000067, 25.700000000000067, -573.8, 25.700000000000067, 34.00000000000021, -8.399999999999638, 20.000000000000004], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [14.599999999999964, -24.099999999999746, -9.999999999999853, 15.799999999999956, 31.700000000000216, -13.599999999999783, -5.499999999999925, 17.899999999999988, 20.000000000000014, -21.999999999999744, 8.299999999999965, 13.699999999999966, 20.000000000000014, 13.399999999999965, 7.399999999999965, 20.000000000000014, 3.1999999999999615, -16.899999999999856, -13.599999999999804, 20.000000000000014, 3.1999999999999615, 20.000000000000014, 5.899999999999967, 17.899999999999988, 13.699999999999964, -40.89999999999976, -11.499999999999819, -0.9999999999999846, 8.599999999999968, 5.299999999999965, 3.1999999999999615, 13.699999999999964, 20.000000000000014, 20.000000000000014, -187.90000000000057, 20.000000000000014, 15.799999999999962, 15.799999999999963, 9.499999999999964, -7.299999999999905, -21.999999999999744, -15.699999999999747, 5.299999999999965, 26.300000000000114, 15.799999999999963, 3.799999999999969, -16.899999999999743, 36.200000000000244, -5.1999999999999265, 20.90000000000003, 20.000000000000014, -2.200000000000059, -6.399999999999908, 20.000000000000014, 7.399999999999965, 20.000000000000014, -5.1999999999999265, 5.299999999999965, 9.499999999999964, 20.000000000000014, -7.299999999999944, -42.99999999999976, 20.000000000000014, 11.599999999999964, -61.900000000000766, 20.000000000000014, 9.499999999999964, 1.099999999999983, 3.1999999999999615, 15.799999999999962, -3.099999999999958, 17.899999999999988, 5.299999999999979, 7.399999999999965, 9.499999999999964, 9.499999999999964, -0.6999999999999993, 17.899999999999988, 3.1999999999999615, 15.799999999999963, 27.20000000000013, 9.499999999999964, -5.19999999999998, 11.599999999999964, -2.4999999999999716, 20.600000000000026, 9.499999999999964, 20.000000000000014, 42.50000000000025, -11.199999999999841, -3.100000000000001, 20.000000000000014, -70.30000000000089, 21.80000000000004, 7.099999999999966, 7.399999999999965, 20.000000000000014, 17.899999999999988, 16.399999999999963, 5.299999999999965, -0.9999999999999846, -0.9999999999999846, 13.699999999999964, 9.499999999999964, 5.299999999999965, -0.39999999999999936, 0.19999999999998655, 9.199999999999969, -5.499999999999925, 7.399999999999965, -47.19999999999976, -45.09999999999976, 5.899999999999967, 20.000000000000014, 20.000000000000014, 3.1999999999999615, 13.999999999999968, 20.000000000000014, 15.799999999999963, -9.399999999999855, 9.499999999999964, 17.899999999999988, 17.599999999999984, 17.29999999999998, 20.000000000000014, 1.3999999999999726, 20.000000000000014, 1.0999999999999865, 9.499999999999964, -0.9999999999999881, -5.199999999999934, 11.599999999999964, 9.499999999999964, 5.299999999999965, 41.00000000000023, -8.499999999999872, 20.900000000000027, 26.000000000000117, 1.0999999999999865, 20.000000000000014, -38.799999999999756, -9.399999999999855, 20.600000000000026, -0.9999999999999846, -4.899999999999942, 25.400000000000098, 15.799999999999963, 11.599999999999964, 27.20000000000013, 9.499999999999964, 4.999999999999966, 20.000000000000014, 7.399999999999965, 7.399999999999965, 7.399999999999965, 20.000000000000014, -0.9999999999999881, 9.499999999999964, 9.499999999999964, 27.20000000000013, 5.299999999999965, 23.600000000000065, 17.29999999999998, 10.699999999999967, 1.0999999999999865, 20.000000000000014, 5.299999999999965, -0.09999999999999937, 20.000000000000014, 11.599999999999964, -7.299999999999891, 5.299999999999965, -61.90000000000071, 13.999999999999966, -5.1999999999999265, -38.799999999999756, 15.799999999999963, -9.399999999999855, -5.1999999999999265, -5.1999999999999265, -53.50000000000019, 11.599999999999964, 20.000000000000014, 19.099999999999994, 20.000000000000014, -11.49999999999983, 5.299999999999965, 7.399999999999965, 5.299999999999965, 7.399999999999965, -400.0, -374.8, 9.499999999999964, 3.1999999999999615, 17.899999999999988, 1.0999999999999865, -61.90000000000068, 9.499999999999964, 3.7999999999999656, 6.1999999999999655], "policy_predator_policy_reward": [20.0, 19.0, 2.0, 16.0, 3.0, 16.0, 10.0, 13.0, 19.0, 20.0, 6.0, 3.0, 4.0, 0.0, 6.0, 3.0, 13.0, 13.0, 15.0, 14.0, 8.0, 3.0, 1.0, 8.0, 8.0, 28.0, 10.0, 15.0, 8.0, 7.0, 8.0, 3.0, 0.0, 0.0, 87.0, 48.0, 3.0, 2.0, 13.0, 5.0, 20.0, 13.0, 7.0, 2.0, 12.0, 2.0, 18.0, 3.0, 12.0, 2.0, 6.0, 10.0, 13.0, 9.0, 6.0, 6.0, 12.0, 7.0, 5.0, 3.0, 30.0, 15.0, 4.0, 3.0, 4.0, 35.0, 10.0, 0.0, 5.0, 8.0, 1.0, 11.0, 6.0, 10.0, 5.0, 5.0, 13.0, 2.0, 8.0, 2.0, 5.0, 3.0, 4.0, 12.0, 3.0, 12.0, 3.0, 2.0, 9.0, 17.0, 9.0, 2.0, 3.0, 43.0, 9.0, 1.0, 0.0, 1.0, 5.0, 9.0, 10.0, 10.0, 3.0, 5.0, 11.0, 7.0, 8.0, 12.0, 5.0, 15.0, 32.0, 13.0, 7.0, 7.0, 8.0, 7.0, 8.0, 3.0, 2.0, 14.0, 5.0, 1.0, 3.0, 2.0, 9.0, 11.0, 0.0, 9.0, 5.0, 10.0, 4.0, 12.0, 5.0, 7.0, 14.0, 6.0, 5.0, 7.0, 9.0, 9.0, 6.0, 28.0, 1.0, 10.0, 9.0, 14.0, 2.0, 4.0, 5.0, 3.0, 8.0, 0.0, 6.0, 4.0, 6.0, 0.0, 12.0, 6.0, 0.0, 5.0, 6.0, 7.0, 7.0, 6.0, 9.0, 9.0, 10.0, 7.0, 4.0, 2.0, 13.0, 7.0, 20.0, 24.0, 24.0, 26.0, 2.0, 14.0, 12.0, 12.0, 32.0, 35.0, 0.0, 6.0, 15.0, 0.0, 6.0, 7.0, 6.0, 7.0, 197.0, 4.0, 5.0, 8.0, 8.0, 7.0, 22.0, 22.0, 9.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5896837887538214, "mean_inference_ms": 1.824485351353477, "mean_action_processing_ms": 0.2565902541367446, "mean_env_wait_ms": 0.1981495034474161, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004084467887878418, "StateBufferConnector_ms": 0.004107832908630371, "ViewRequirementAgentConnector_ms": 0.10235023498535156}, "num_episodes": 22, "episode_return_max": 58.90000000000049, "episode_return_min": -573.8, "episode_return_mean": 21.419000000000178, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2144000, "num_agent_steps_trained": 2144000, "num_env_steps_sampled": 536000, "num_env_steps_trained": 536000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 364.56445245740485, "num_env_steps_trained_throughput_per_sec": 364.56445245740485, "timesteps_total": 536000, "num_env_steps_sampled_lifetime": 536000, "num_agent_steps_sampled_lifetime": 2144000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2144000, "timers": {"training_iteration_time_ms": 11032.239, "restore_workers_time_ms": 0.013, "training_step_time_ms": 11032.178, "sample_time_ms": 1312.406, "learn_time_ms": 9703.436, "learn_throughput": 412.225, "synch_weights_time_ms": 14.484}, "counters": {"num_env_steps_sampled": 536000, "num_env_steps_trained": 536000, "num_agent_steps_sampled": 2144000, "num_agent_steps_trained": 2144000}, "done": false, "training_iteration": 134, "trial_id": "3dae5_00000", "date": "2024-08-14_09-31-33", "timestamp": 1723642293, "time_this_iter_s": 11.015439987182617, "time_total_s": 3111.1625192165375, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3896a60>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3111.1625192165375, "iterations_since_restore": 134, "perf": {"cpu_util_percent": 29.481249999999996, "ram_util_percent": 83.7}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3432889262204448, "cur_kl_coeff": 1.5449523925781246e-05, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.271134685308096, "policy_loss": -0.005126442822009305, "vf_loss": 0.27626102241002537, "vf_explained_var": 0.32205210763310627, "kl": 0.00685173637752734, "entropy": 0.6871373724685144, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 254205.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5164798716388683, "cur_kl_coeff": 0.03164062499999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.4072591201078563, "policy_loss": -0.008663793653372932, "vf_loss": 0.4155565872835242, "vf_explained_var": 0.030644140451673477, "kl": 0.011577732965297459, "entropy": 1.0252201421235605, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 254205.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 540000, "num_env_steps_trained": 540000, "num_agent_steps_sampled": 2160000, "num_agent_steps_trained": 2160000}, "env_runners": {"episode_reward_max": 58.90000000000049, "episode_reward_min": -573.8, "episode_reward_mean": 22.160000000000174, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 42.50000000000025, "predator_policy": 197.0}, "policy_reward_mean": {"prey_policy": 1.7300000000000042, "predator_policy": 9.35}, "custom_metrics": {}, "hist_stats": {"episode_reward": [36.60000000000025, 20.199999999999974, -4.699999999999687, 40.60000000000031, 33.6000000000002, 40.30000000000031, 29.70000000000014, 33.800000000000196, 35.600000000000236, 39.40000000000029, 19.100000000000005, 37.50000000000026, -5.299999999999727, 38.60000000000028, -2.8999999999997446, 20.600000000000005, 32.00000000000018, 26.800000000000086, 28.700000000000127, 29.000000000000124, 32.20000000000019, 29.000000000000124, 44.70000000000037, 22.40000000000001, 33.1000000000002, 34.50000000000022, 57.300000000000495, 27.900000000000116, -2.4999999999997584, 24.500000000000046, 38.90000000000028, 35.70000000000024, 18.000000000000004, 31.200000000000163, 22.90000000000002, 29.40000000000014, 21.900000000000002, -47.30000000000073, 39.9000000000003, 38.20000000000027, 45.000000000000384, 22.40000000000001, 33.4000000000002, 39.9000000000003, 41.40000000000032, 30.100000000000147, 23.50000000000003, 22.40000000000001, 26.800000000000086, 52.500000000000455, 58.90000000000049, 39.100000000000286, -14.199999999999525, 30.600000000000158, 43.500000000000355, 33.4000000000002, 44.70000000000037, 33.0000000000002, 24.80000000000005, 33.400000000000205, 26.50000000000008, 41.70000000000032, 41.900000000000325, 41.00000000000031, 39.100000000000286, 22.200000000000006, 37.600000000000264, 18.000000000000004, -3.899999999999724, 6.000000000000153, 22.40000000000001, 13.60000000000004, 25.100000000000065, 45.1000000000004, 23.500000000000032, 25.700000000000067, 25.700000000000067, -573.8, 25.700000000000067, 34.00000000000021, -8.399999999999638, 20.000000000000004, 13.399999999999999, 21.3, 36.50000000000025, 25.500000000000064, 35.70000000000024, 32.600000000000186, 38.00000000000027, 28.600000000000122, 36.00000000000024, 29.000000000000128, 33.10000000000021, 20.39999999999999, 28.400000000000137, 36.80000000000025, 25.600000000000065, 32.00000000000018, 34.800000000000225, 33.9000000000002], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [15.799999999999962, 15.799999999999963, 9.499999999999964, -7.299999999999905, -21.999999999999744, -15.699999999999747, 5.299999999999965, 26.300000000000114, 15.799999999999963, 3.799999999999969, -16.899999999999743, 36.200000000000244, -5.1999999999999265, 20.90000000000003, 20.000000000000014, -2.200000000000059, -6.399999999999908, 20.000000000000014, 7.399999999999965, 20.000000000000014, -5.1999999999999265, 5.299999999999965, 9.499999999999964, 20.000000000000014, -7.299999999999944, -42.99999999999976, 20.000000000000014, 11.599999999999964, -61.900000000000766, 20.000000000000014, 9.499999999999964, 1.099999999999983, 3.1999999999999615, 15.799999999999962, -3.099999999999958, 17.899999999999988, 5.299999999999979, 7.399999999999965, 9.499999999999964, 9.499999999999964, -0.6999999999999993, 17.899999999999988, 3.1999999999999615, 15.799999999999963, 27.20000000000013, 9.499999999999964, -5.19999999999998, 11.599999999999964, -2.4999999999999716, 20.600000000000026, 9.499999999999964, 20.000000000000014, 42.50000000000025, -11.199999999999841, -3.100000000000001, 20.000000000000014, -70.30000000000089, 21.80000000000004, 7.099999999999966, 7.399999999999965, 20.000000000000014, 17.899999999999988, 16.399999999999963, 5.299999999999965, -0.9999999999999846, -0.9999999999999846, 13.699999999999964, 9.499999999999964, 5.299999999999965, -0.39999999999999936, 0.19999999999998655, 9.199999999999969, -5.499999999999925, 7.399999999999965, -47.19999999999976, -45.09999999999976, 5.899999999999967, 20.000000000000014, 20.000000000000014, 3.1999999999999615, 13.999999999999968, 20.000000000000014, 15.799999999999963, -9.399999999999855, 9.499999999999964, 17.899999999999988, 17.599999999999984, 17.29999999999998, 20.000000000000014, 1.3999999999999726, 20.000000000000014, 1.0999999999999865, 9.499999999999964, -0.9999999999999881, -5.199999999999934, 11.599999999999964, 9.499999999999964, 5.299999999999965, 41.00000000000023, -8.499999999999872, 20.900000000000027, 26.000000000000117, 1.0999999999999865, 20.000000000000014, -38.799999999999756, -9.399999999999855, 20.600000000000026, -0.9999999999999846, -4.899999999999942, 25.400000000000098, 15.799999999999963, 11.599999999999964, 27.20000000000013, 9.499999999999964, 4.999999999999966, 20.000000000000014, 7.399999999999965, 7.399999999999965, 7.399999999999965, 20.000000000000014, -0.9999999999999881, 9.499999999999964, 9.499999999999964, 27.20000000000013, 5.299999999999965, 23.600000000000065, 17.29999999999998, 10.699999999999967, 1.0999999999999865, 20.000000000000014, 5.299999999999965, -0.09999999999999937, 20.000000000000014, 11.599999999999964, -7.299999999999891, 5.299999999999965, -61.90000000000071, 13.999999999999966, -5.1999999999999265, -38.799999999999756, 15.799999999999963, -9.399999999999855, -5.1999999999999265, -5.1999999999999265, -53.50000000000019, 11.599999999999964, 20.000000000000014, 19.099999999999994, 20.000000000000014, -11.49999999999983, 5.299999999999965, 7.399999999999965, 5.299999999999965, 7.399999999999965, -400.0, -374.8, 9.499999999999964, 3.1999999999999615, 17.899999999999988, 1.0999999999999865, -61.90000000000068, 9.499999999999964, 3.7999999999999656, 6.1999999999999655, 15.799999999999963, -36.399999999999764, 7.399999999999965, -3.099999999999958, 9.499999999999964, 20.000000000000014, 13.699999999999964, -2.1999999999999713, -7.299999999999891, 20.000000000000014, 7.399999999999965, 15.199999999999966, -5.1999999999999265, 21.20000000000003, 17.899999999999988, -1.2999999999999847, -0.9999999999999846, 20.000000000000014, 17.899999999999988, 1.0999999999999865, 20.000000000000014, 1.0999999999999528, 1.0999999999999794, 5.299999999999965, -13.599999999999783, 20.000000000000014, 31.700000000000216, -19.899999999999743, 9.499999999999964, 1.0999999999999794, 13.69999999999997, 5.299999999999965, 3.1999999999999615, 23.600000000000065, 9.499999999999964, 16.39999999999996], "policy_predator_policy_reward": [3.0, 2.0, 13.0, 5.0, 20.0, 13.0, 7.0, 2.0, 12.0, 2.0, 18.0, 3.0, 12.0, 2.0, 6.0, 10.0, 13.0, 9.0, 6.0, 6.0, 12.0, 7.0, 5.0, 3.0, 30.0, 15.0, 4.0, 3.0, 4.0, 35.0, 10.0, 0.0, 5.0, 8.0, 1.0, 11.0, 6.0, 10.0, 5.0, 5.0, 13.0, 2.0, 8.0, 2.0, 5.0, 3.0, 4.0, 12.0, 3.0, 12.0, 3.0, 2.0, 9.0, 17.0, 9.0, 2.0, 3.0, 43.0, 9.0, 1.0, 0.0, 1.0, 5.0, 9.0, 10.0, 10.0, 3.0, 5.0, 11.0, 7.0, 8.0, 12.0, 5.0, 15.0, 32.0, 13.0, 7.0, 7.0, 8.0, 7.0, 8.0, 3.0, 2.0, 14.0, 5.0, 1.0, 3.0, 2.0, 9.0, 11.0, 0.0, 9.0, 5.0, 10.0, 4.0, 12.0, 5.0, 7.0, 14.0, 6.0, 5.0, 7.0, 9.0, 9.0, 6.0, 28.0, 1.0, 10.0, 9.0, 14.0, 2.0, 4.0, 5.0, 3.0, 8.0, 0.0, 6.0, 4.0, 6.0, 0.0, 12.0, 6.0, 0.0, 5.0, 6.0, 7.0, 7.0, 6.0, 9.0, 9.0, 10.0, 7.0, 4.0, 2.0, 13.0, 7.0, 20.0, 24.0, 24.0, 26.0, 2.0, 14.0, 12.0, 12.0, 32.0, 35.0, 0.0, 6.0, 15.0, 0.0, 6.0, 7.0, 6.0, 7.0, 197.0, 4.0, 5.0, 8.0, 8.0, 7.0, 22.0, 22.0, 9.0, 1.0, 14.0, 20.0, 6.0, 11.0, 2.0, 5.0, 11.0, 3.0, 11.0, 12.0, 4.0, 6.0, 12.0, 10.0, 9.0, 3.0, 10.0, 7.0, 9.0, 1.0, 3.0, 9.0, 7.0, 7.0, 6.0, 16.0, 19.0, 6.0, 6.0, 9.0, 6.0, 7.0, 0.0, 8.0, 5.0, 3.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5895132210610844, "mean_inference_ms": 1.8240826816692635, "mean_action_processing_ms": 0.2564302775825827, "mean_env_wait_ms": 0.19806711668383017, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004225373268127441, "StateBufferConnector_ms": 0.003834247589111328, "ViewRequirementAgentConnector_ms": 0.10515666007995605}, "num_episodes": 18, "episode_return_max": 58.90000000000049, "episode_return_min": -573.8, "episode_return_mean": 22.160000000000174, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2160000, "num_agent_steps_trained": 2160000, "num_env_steps_sampled": 540000, "num_env_steps_trained": 540000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 373.52816779567854, "num_env_steps_trained_throughput_per_sec": 373.52816779567854, "timesteps_total": 540000, "num_env_steps_sampled_lifetime": 540000, "num_agent_steps_sampled_lifetime": 2160000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2160000, "timers": {"training_iteration_time_ms": 11022.833, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11022.77, "sample_time_ms": 1308.301, "learn_time_ms": 9697.918, "learn_throughput": 412.46, "synch_weights_time_ms": 14.746}, "counters": {"num_env_steps_sampled": 540000, "num_env_steps_trained": 540000, "num_agent_steps_sampled": 2160000, "num_agent_steps_trained": 2160000}, "done": false, "training_iteration": 135, "trial_id": "3dae5_00000", "date": "2024-08-14_09-31-44", "timestamp": 1723642304, "time_this_iter_s": 10.713084936141968, "time_total_s": 3121.8756041526794, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b36b4ee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3121.8756041526794, "iterations_since_restore": 135, "perf": {"cpu_util_percent": 28.5, "ram_util_percent": 83.70666666666668}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0635219077584606, "cur_kl_coeff": 1.5449523925781246e-05, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.9350167312161632, "policy_loss": -0.001946216930817596, "vf_loss": 0.9369627057441643, "vf_explained_var": 0.015583958796092442, "kl": 0.015686062570137493, "entropy": 0.5471456976637008, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 256095.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5905054578390072, "cur_kl_coeff": 0.03164062499999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.0135088074656706, "policy_loss": -0.0029899289498903922, "vf_loss": 1.016173395656404, "vf_explained_var": 0.007121099586840029, "kl": 0.010282381072977142, "entropy": 1.0482762299202106, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 256095.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 544000, "num_env_steps_trained": 544000, "num_agent_steps_sampled": 2176000, "num_agent_steps_trained": 2176000}, "env_runners": {"episode_reward_max": 58.90000000000049, "episode_reward_min": -573.8, "episode_reward_mean": 19.33900000000015, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 42.50000000000025, "predator_policy": 197.0}, "policy_reward_mean": {"prey_policy": -0.755499999999995, "predator_policy": 10.425}, "custom_metrics": {}, "hist_stats": {"episode_reward": [28.700000000000127, 29.000000000000124, 32.20000000000019, 29.000000000000124, 44.70000000000037, 22.40000000000001, 33.1000000000002, 34.50000000000022, 57.300000000000495, 27.900000000000116, -2.4999999999997584, 24.500000000000046, 38.90000000000028, 35.70000000000024, 18.000000000000004, 31.200000000000163, 22.90000000000002, 29.40000000000014, 21.900000000000002, -47.30000000000073, 39.9000000000003, 38.20000000000027, 45.000000000000384, 22.40000000000001, 33.4000000000002, 39.9000000000003, 41.40000000000032, 30.100000000000147, 23.50000000000003, 22.40000000000001, 26.800000000000086, 52.500000000000455, 58.90000000000049, 39.100000000000286, -14.199999999999525, 30.600000000000158, 43.500000000000355, 33.4000000000002, 44.70000000000037, 33.0000000000002, 24.80000000000005, 33.400000000000205, 26.50000000000008, 41.70000000000032, 41.900000000000325, 41.00000000000031, 39.100000000000286, 22.200000000000006, 37.600000000000264, 18.000000000000004, -3.899999999999724, 6.000000000000153, 22.40000000000001, 13.60000000000004, 25.100000000000065, 45.1000000000004, 23.500000000000032, 25.700000000000067, 25.700000000000067, -573.8, 25.700000000000067, 34.00000000000021, -8.399999999999638, 20.000000000000004, 13.399999999999999, 21.3, 36.50000000000025, 25.500000000000064, 35.70000000000024, 32.600000000000186, 38.00000000000027, 28.600000000000122, 36.00000000000024, 29.000000000000128, 33.10000000000021, 20.39999999999999, 28.400000000000137, 36.80000000000025, 25.600000000000065, 32.00000000000018, 34.800000000000225, 33.9000000000002, 23.50000000000003, 22.40000000000001, 30.90000000000016, 15.79999999999999, 44.20000000000037, 20.200000000000006, 8.000000000000082, 34.50000000000022, 43.70000000000036, 27.900000000000105, 41.30000000000032, -90.90000000000074, 43.50000000000035, 1.5000000000002076, 23.200000000000024, -145.90000000000066, 34.40000000000022, 11.200000000000092], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [5.299999999999979, 7.399999999999965, 9.499999999999964, 9.499999999999964, -0.6999999999999993, 17.899999999999988, 3.1999999999999615, 15.799999999999963, 27.20000000000013, 9.499999999999964, -5.19999999999998, 11.599999999999964, -2.4999999999999716, 20.600000000000026, 9.499999999999964, 20.000000000000014, 42.50000000000025, -11.199999999999841, -3.100000000000001, 20.000000000000014, -70.30000000000089, 21.80000000000004, 7.099999999999966, 7.399999999999965, 20.000000000000014, 17.899999999999988, 16.399999999999963, 5.299999999999965, -0.9999999999999846, -0.9999999999999846, 13.699999999999964, 9.499999999999964, 5.299999999999965, -0.39999999999999936, 0.19999999999998655, 9.199999999999969, -5.499999999999925, 7.399999999999965, -47.19999999999976, -45.09999999999976, 5.899999999999967, 20.000000000000014, 20.000000000000014, 3.1999999999999615, 13.999999999999968, 20.000000000000014, 15.799999999999963, -9.399999999999855, 9.499999999999964, 17.899999999999988, 17.599999999999984, 17.29999999999998, 20.000000000000014, 1.3999999999999726, 20.000000000000014, 1.0999999999999865, 9.499999999999964, -0.9999999999999881, -5.199999999999934, 11.599999999999964, 9.499999999999964, 5.299999999999965, 41.00000000000023, -8.499999999999872, 20.900000000000027, 26.000000000000117, 1.0999999999999865, 20.000000000000014, -38.799999999999756, -9.399999999999855, 20.600000000000026, -0.9999999999999846, -4.899999999999942, 25.400000000000098, 15.799999999999963, 11.599999999999964, 27.20000000000013, 9.499999999999964, 4.999999999999966, 20.000000000000014, 7.399999999999965, 7.399999999999965, 7.399999999999965, 20.000000000000014, -0.9999999999999881, 9.499999999999964, 9.499999999999964, 27.20000000000013, 5.299999999999965, 23.600000000000065, 17.29999999999998, 10.699999999999967, 1.0999999999999865, 20.000000000000014, 5.299999999999965, -0.09999999999999937, 20.000000000000014, 11.599999999999964, -7.299999999999891, 5.299999999999965, -61.90000000000071, 13.999999999999966, -5.1999999999999265, -38.799999999999756, 15.799999999999963, -9.399999999999855, -5.1999999999999265, -5.1999999999999265, -53.50000000000019, 11.599999999999964, 20.000000000000014, 19.099999999999994, 20.000000000000014, -11.49999999999983, 5.299999999999965, 7.399999999999965, 5.299999999999965, 7.399999999999965, -400.0, -374.8, 9.499999999999964, 3.1999999999999615, 17.899999999999988, 1.0999999999999865, -61.90000000000068, 9.499999999999964, 3.7999999999999656, 6.1999999999999655, 15.799999999999963, -36.399999999999764, 7.399999999999965, -3.099999999999958, 9.499999999999964, 20.000000000000014, 13.699999999999964, -2.1999999999999713, -7.299999999999891, 20.000000000000014, 7.399999999999965, 15.199999999999966, -5.1999999999999265, 21.20000000000003, 17.899999999999988, -1.2999999999999847, -0.9999999999999846, 20.000000000000014, 17.899999999999988, 1.0999999999999865, 20.000000000000014, 1.0999999999999528, 1.0999999999999794, 5.299999999999965, -13.599999999999783, 20.000000000000014, 31.700000000000216, -19.899999999999743, 9.499999999999964, 1.0999999999999794, 13.69999999999997, 5.299999999999965, 3.1999999999999615, 23.600000000000065, 9.499999999999964, 16.39999999999996, 5.299999999999965, 3.1999999999999615, 7.399999999999965, -0.9999999999999846, 15.799999999999963, 1.0999999999999865, -13.599999999999786, 7.399999999999965, -3.099999999999958, 26.300000000000118, -0.9999999999999846, 3.1999999999999615, 20.000000000000014, -42.99999999999976, 15.799999999999963, 13.699999999999964, 27.200000000000134, 9.499999999999964, 11.599999999999966, 5.299999999999965, 11.599999999999964, 22.700000000000053, 20.000000000000014, -229.90000000000046, 26.900000000000126, 11.599999999999964, -21.99999999999976, -11.499999999999819, -13.599999999999797, 15.799999999999963, -324.39999999999975, 9.499999999999964, 20.000000000000014, 7.399999999999965, 1.0999999999999865, 1.0999999999999865], "policy_predator_policy_reward": [6.0, 10.0, 5.0, 5.0, 13.0, 2.0, 8.0, 2.0, 5.0, 3.0, 4.0, 12.0, 3.0, 12.0, 3.0, 2.0, 9.0, 17.0, 9.0, 2.0, 3.0, 43.0, 9.0, 1.0, 0.0, 1.0, 5.0, 9.0, 10.0, 10.0, 3.0, 5.0, 11.0, 7.0, 8.0, 12.0, 5.0, 15.0, 32.0, 13.0, 7.0, 7.0, 8.0, 7.0, 8.0, 3.0, 2.0, 14.0, 5.0, 1.0, 3.0, 2.0, 9.0, 11.0, 0.0, 9.0, 5.0, 10.0, 4.0, 12.0, 5.0, 7.0, 14.0, 6.0, 5.0, 7.0, 9.0, 9.0, 6.0, 28.0, 1.0, 10.0, 9.0, 14.0, 2.0, 4.0, 5.0, 3.0, 8.0, 0.0, 6.0, 4.0, 6.0, 0.0, 12.0, 6.0, 0.0, 5.0, 6.0, 7.0, 7.0, 6.0, 9.0, 9.0, 10.0, 7.0, 4.0, 2.0, 13.0, 7.0, 20.0, 24.0, 24.0, 26.0, 2.0, 14.0, 12.0, 12.0, 32.0, 35.0, 0.0, 6.0, 15.0, 0.0, 6.0, 7.0, 6.0, 7.0, 197.0, 4.0, 5.0, 8.0, 8.0, 7.0, 22.0, 22.0, 9.0, 1.0, 14.0, 20.0, 6.0, 11.0, 2.0, 5.0, 11.0, 3.0, 11.0, 12.0, 4.0, 6.0, 12.0, 10.0, 9.0, 3.0, 10.0, 7.0, 9.0, 1.0, 3.0, 9.0, 7.0, 7.0, 6.0, 16.0, 19.0, 6.0, 6.0, 9.0, 6.0, 7.0, 0.0, 8.0, 5.0, 3.0, 8.0, 7.0, 10.0, 6.0, 5.0, 9.0, 6.0, 16.0, 10.0, 11.0, 8.0, 10.0, 30.0, 1.0, 3.0, 2.0, 5.0, 2.0, 4.0, 7.0, 4.0, 3.0, 119.0, 0.0, 1.0, 4.0, 20.0, 15.0, 8.0, 13.0, 164.0, 5.0, 1.0, 6.0, 0.0, 9.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5893333077071301, "mean_inference_ms": 1.8236843804710452, "mean_action_processing_ms": 0.25627187195656914, "mean_env_wait_ms": 0.19798274614130776, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0046204328536987305, "StateBufferConnector_ms": 0.0038644075393676758, "ViewRequirementAgentConnector_ms": 0.10831224918365479}, "num_episodes": 18, "episode_return_max": 58.90000000000049, "episode_return_min": -573.8, "episode_return_mean": 19.33900000000015, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2176000, "num_agent_steps_trained": 2176000, "num_env_steps_sampled": 544000, "num_env_steps_trained": 544000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 383.84131462619285, "num_env_steps_trained_throughput_per_sec": 383.84131462619285, "timesteps_total": 544000, "num_env_steps_sampled_lifetime": 544000, "num_agent_steps_sampled_lifetime": 2176000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2176000, "timers": {"training_iteration_time_ms": 10996.747, "restore_workers_time_ms": 0.014, "training_step_time_ms": 10996.68, "sample_time_ms": 1306.024, "learn_time_ms": 9673.518, "learn_throughput": 413.5, "synch_weights_time_ms": 15.253}, "counters": {"num_env_steps_sampled": 544000, "num_env_steps_trained": 544000, "num_agent_steps_sampled": 2176000, "num_agent_steps_trained": 2176000}, "done": false, "training_iteration": 136, "trial_id": "3dae5_00000", "date": "2024-08-14_09-31-54", "timestamp": 1723642314, "time_this_iter_s": 10.470570087432861, "time_total_s": 3132.3461742401123, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b38315e0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3132.3461742401123, "iterations_since_restore": 136, "perf": {"cpu_util_percent": 28.213333333333335, "ram_util_percent": 83.72}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.409341323675302, "cur_kl_coeff": 1.5449523925781246e-05, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.7620550764616204, "policy_loss": -0.001552478499370553, "vf_loss": 0.7636072814622253, "vf_explained_var": 0.09943669905107488, "kl": 0.01764405626415388, "entropy": 0.9600737669165172, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 257985.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8256979747581734, "cur_kl_coeff": 0.03164062499999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.975965792792184, "policy_loss": -0.002339962377119317, "vf_loss": 0.9781177368034761, "vf_explained_var": 0.012512603701737823, "kl": 0.005942392762886407, "entropy": 1.0123463633514587, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 257985.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 548000, "num_env_steps_trained": 548000, "num_agent_steps_sampled": 2192000, "num_agent_steps_trained": 2192000}, "env_runners": {"episode_reward_max": 66.8000000000003, "episode_reward_min": -573.8, "episode_reward_mean": 16.25800000000014, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 47.90000000000024, "predator_policy": 197.0}, "policy_reward_mean": {"prey_policy": -4.080999999999994, "predator_policy": 12.21}, "custom_metrics": {}, "hist_stats": {"episode_reward": [22.40000000000001, 33.4000000000002, 39.9000000000003, 41.40000000000032, 30.100000000000147, 23.50000000000003, 22.40000000000001, 26.800000000000086, 52.500000000000455, 58.90000000000049, 39.100000000000286, -14.199999999999525, 30.600000000000158, 43.500000000000355, 33.4000000000002, 44.70000000000037, 33.0000000000002, 24.80000000000005, 33.400000000000205, 26.50000000000008, 41.70000000000032, 41.900000000000325, 41.00000000000031, 39.100000000000286, 22.200000000000006, 37.600000000000264, 18.000000000000004, -3.899999999999724, 6.000000000000153, 22.40000000000001, 13.60000000000004, 25.100000000000065, 45.1000000000004, 23.500000000000032, 25.700000000000067, 25.700000000000067, -573.8, 25.700000000000067, 34.00000000000021, -8.399999999999638, 20.000000000000004, 13.399999999999999, 21.3, 36.50000000000025, 25.500000000000064, 35.70000000000024, 32.600000000000186, 38.00000000000027, 28.600000000000122, 36.00000000000024, 29.000000000000128, 33.10000000000021, 20.39999999999999, 28.400000000000137, 36.80000000000025, 25.600000000000065, 32.00000000000018, 34.800000000000225, 33.9000000000002, 23.50000000000003, 22.40000000000001, 30.90000000000016, 15.79999999999999, 44.20000000000037, 20.200000000000006, 8.000000000000082, 34.50000000000022, 43.70000000000036, 27.900000000000105, 41.30000000000032, -90.90000000000074, 43.50000000000035, 1.5000000000002076, 23.200000000000024, -145.90000000000066, 34.40000000000022, 11.200000000000092, 20.200000000000006, 35.70000000000024, -7.60000000000006, -17.19999999999952, 24.600000000000048, 15.79999999999999, 24.300000000000043, 47.20000000000042, 36.60000000000025, -155.0000000000006, 20.200000000000006, 32.800000000000196, 23.50000000000003, 17.000000000000004, 66.8000000000003, 59.70000000000042, 27.800000000000104, 48.600000000000456, 38.50000000000028, 30.100000000000144, -127.70000000000041, 37.80000000000027, 26.800000000000086], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [15.799999999999963, -9.399999999999855, 9.499999999999964, 17.899999999999988, 17.599999999999984, 17.29999999999998, 20.000000000000014, 1.3999999999999726, 20.000000000000014, 1.0999999999999865, 9.499999999999964, -0.9999999999999881, -5.199999999999934, 11.599999999999964, 9.499999999999964, 5.299999999999965, 41.00000000000023, -8.499999999999872, 20.900000000000027, 26.000000000000117, 1.0999999999999865, 20.000000000000014, -38.799999999999756, -9.399999999999855, 20.600000000000026, -0.9999999999999846, -4.899999999999942, 25.400000000000098, 15.799999999999963, 11.599999999999964, 27.20000000000013, 9.499999999999964, 4.999999999999966, 20.000000000000014, 7.399999999999965, 7.399999999999965, 7.399999999999965, 20.000000000000014, -0.9999999999999881, 9.499999999999964, 9.499999999999964, 27.20000000000013, 5.299999999999965, 23.600000000000065, 17.29999999999998, 10.699999999999967, 1.0999999999999865, 20.000000000000014, 5.299999999999965, -0.09999999999999937, 20.000000000000014, 11.599999999999964, -7.299999999999891, 5.299999999999965, -61.90000000000071, 13.999999999999966, -5.1999999999999265, -38.799999999999756, 15.799999999999963, -9.399999999999855, -5.1999999999999265, -5.1999999999999265, -53.50000000000019, 11.599999999999964, 20.000000000000014, 19.099999999999994, 20.000000000000014, -11.49999999999983, 5.299999999999965, 7.399999999999965, 5.299999999999965, 7.399999999999965, -400.0, -374.8, 9.499999999999964, 3.1999999999999615, 17.899999999999988, 1.0999999999999865, -61.90000000000068, 9.499999999999964, 3.7999999999999656, 6.1999999999999655, 15.799999999999963, -36.399999999999764, 7.399999999999965, -3.099999999999958, 9.499999999999964, 20.000000000000014, 13.699999999999964, -2.1999999999999713, -7.299999999999891, 20.000000000000014, 7.399999999999965, 15.199999999999966, -5.1999999999999265, 21.20000000000003, 17.899999999999988, -1.2999999999999847, -0.9999999999999846, 20.000000000000014, 17.899999999999988, 1.0999999999999865, 20.000000000000014, 1.0999999999999528, 1.0999999999999794, 5.299999999999965, -13.599999999999783, 20.000000000000014, 31.700000000000216, -19.899999999999743, 9.499999999999964, 1.0999999999999794, 13.69999999999997, 5.299999999999965, 3.1999999999999615, 23.600000000000065, 9.499999999999964, 16.39999999999996, 5.299999999999965, 3.1999999999999615, 7.399999999999965, -0.9999999999999846, 15.799999999999963, 1.0999999999999865, -13.599999999999786, 7.399999999999965, -3.099999999999958, 26.300000000000118, -0.9999999999999846, 3.1999999999999615, 20.000000000000014, -42.99999999999976, 15.799999999999963, 13.699999999999964, 27.200000000000134, 9.499999999999964, 11.599999999999966, 5.299999999999965, 11.599999999999964, 22.700000000000053, 20.000000000000014, -229.90000000000046, 26.900000000000126, 11.599999999999964, -21.99999999999976, -11.499999999999819, -13.599999999999797, 15.799999999999963, -324.39999999999975, 9.499999999999964, 20.000000000000014, 7.399999999999965, 1.0999999999999865, 1.0999999999999865, 1.0999999999999865, 1.0999999999999865, -7.299999999999891, 20.000000000000014, -17.800000000000004, -17.80000000000001, -80.80000000000075, 11.599999999999964, 1.0999999999999865, 9.499999999999964, -17.79999999999974, 11.599999999999964, 3.1999999999999615, 1.0999999999999865, 17.899999999999988, 17.299999999999976, 11.599999999999964, 20.000000000000014, -345.4, 7.399999999999968, 3.1999999999999615, -0.9999999999999846, 20.000000000000014, -5.1999999999999265, -3.099999999999958, 11.599999999999964, -0.9999999999999846, -0.9999999999999846, 17.899999999999988, 47.90000000000024, 33.500000000000206, 3.1999999999999615, 9.499999999999964, 5.299999999999965, 20.000000000000014, 14.599999999999975, 20.000000000000014, 9.499999999999964, 13.699999999999964, 7.399999999999965, -334.9000000000001, 27.20000000000013, -5.1999999999999265, 20.000000000000014, 9.499999999999964, 5.299999999999965], "policy_predator_policy_reward": [2.0, 14.0, 5.0, 1.0, 3.0, 2.0, 9.0, 11.0, 0.0, 9.0, 5.0, 10.0, 4.0, 12.0, 5.0, 7.0, 14.0, 6.0, 5.0, 7.0, 9.0, 9.0, 6.0, 28.0, 1.0, 10.0, 9.0, 14.0, 2.0, 4.0, 5.0, 3.0, 8.0, 0.0, 6.0, 4.0, 6.0, 0.0, 12.0, 6.0, 0.0, 5.0, 6.0, 7.0, 7.0, 6.0, 9.0, 9.0, 10.0, 7.0, 4.0, 2.0, 13.0, 7.0, 20.0, 24.0, 24.0, 26.0, 2.0, 14.0, 12.0, 12.0, 32.0, 35.0, 0.0, 6.0, 15.0, 0.0, 6.0, 7.0, 6.0, 7.0, 197.0, 4.0, 5.0, 8.0, 8.0, 7.0, 22.0, 22.0, 9.0, 1.0, 14.0, 20.0, 6.0, 11.0, 2.0, 5.0, 11.0, 3.0, 11.0, 12.0, 4.0, 6.0, 12.0, 10.0, 9.0, 3.0, 10.0, 7.0, 9.0, 1.0, 3.0, 9.0, 7.0, 7.0, 6.0, 16.0, 19.0, 6.0, 6.0, 9.0, 6.0, 7.0, 0.0, 8.0, 5.0, 3.0, 8.0, 7.0, 10.0, 6.0, 5.0, 9.0, 6.0, 16.0, 10.0, 11.0, 8.0, 10.0, 30.0, 1.0, 3.0, 2.0, 5.0, 2.0, 4.0, 7.0, 4.0, 3.0, 119.0, 0.0, 1.0, 4.0, 20.0, 15.0, 8.0, 13.0, 164.0, 5.0, 1.0, 6.0, 0.0, 9.0, 9.0, 9.0, 13.0, 10.0, 3.0, 25.0, 48.0, 4.0, 5.0, 9.0, 18.0, 4.0, 10.0, 10.0, 6.0, 6.0, 4.0, 1.0, 174.0, 9.0, 10.0, 8.0, 12.0, 6.0, 12.0, 3.0, 10.0, 9.0, 1.0, 0.0, 3.0, 20.0, 6.0, 7.0, 9.0, 5.0, 4.0, 5.0, 6.0, 3.0, 169.0, 11.0, 11.0, 12.0, 5.0, 7.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5890394932041157, "mean_inference_ms": 1.82277529707438, "mean_action_processing_ms": 0.2560343240866967, "mean_env_wait_ms": 0.19783322218035884, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005877494812011719, "StateBufferConnector_ms": 0.00325775146484375, "ViewRequirementAgentConnector_ms": 0.1038672924041748}, "num_episodes": 23, "episode_return_max": 66.8000000000003, "episode_return_min": -573.8, "episode_return_mean": 16.25800000000014, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2192000, "num_agent_steps_trained": 2192000, "num_env_steps_sampled": 548000, "num_env_steps_trained": 548000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 369.2218579518783, "num_env_steps_trained_throughput_per_sec": 369.2218579518783, "timesteps_total": 548000, "num_env_steps_sampled_lifetime": 548000, "num_agent_steps_sampled_lifetime": 2192000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2192000, "timers": {"training_iteration_time_ms": 10962.103, "restore_workers_time_ms": 0.014, "training_step_time_ms": 10962.035, "sample_time_ms": 1302.236, "learn_time_ms": 9642.902, "learn_throughput": 414.813, "synch_weights_time_ms": 15.123}, "counters": {"num_env_steps_sampled": 548000, "num_env_steps_trained": 548000, "num_agent_steps_sampled": 2192000, "num_agent_steps_trained": 2192000}, "done": false, "training_iteration": 137, "trial_id": "3dae5_00000", "date": "2024-08-14_09-32-05", "timestamp": 1723642325, "time_this_iter_s": 10.839179992675781, "time_total_s": 3143.185354232788, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b38b6160>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3143.185354232788, "iterations_since_restore": 137, "perf": {"cpu_util_percent": 28.92, "ram_util_percent": 83.66666666666667}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3855097313406606, "cur_kl_coeff": 1.5449523925781246e-05, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.42231651900937317, "policy_loss": -0.0053000162519445575, "vf_loss": 0.42761638315700035, "vf_explained_var": 0.31323801692200715, "kl": 0.009864724446775785, "entropy": 1.0568256763238755, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 259875.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.877746144788606, "cur_kl_coeff": 0.03164062499999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.5314584873717096, "policy_loss": -0.007907882729969012, "vf_loss": 0.5390971414661084, "vf_explained_var": 0.03476215162605205, "kl": 0.008508979310010767, "entropy": 1.0214516939940277, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 259875.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 552000, "num_env_steps_trained": 552000, "num_agent_steps_sampled": 2208000, "num_agent_steps_trained": 2208000}, "env_runners": {"episode_reward_max": 66.8000000000003, "episode_reward_min": -573.8, "episode_reward_mean": 14.32700000000013, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 47.90000000000024, "predator_policy": 197.0}, "policy_reward_mean": {"prey_policy": -5.771499999999994, "predator_policy": 12.935}, "custom_metrics": {}, "hist_stats": {"episode_reward": [41.00000000000031, 39.100000000000286, 22.200000000000006, 37.600000000000264, 18.000000000000004, -3.899999999999724, 6.000000000000153, 22.40000000000001, 13.60000000000004, 25.100000000000065, 45.1000000000004, 23.500000000000032, 25.700000000000067, 25.700000000000067, -573.8, 25.700000000000067, 34.00000000000021, -8.399999999999638, 20.000000000000004, 13.399999999999999, 21.3, 36.50000000000025, 25.500000000000064, 35.70000000000024, 32.600000000000186, 38.00000000000027, 28.600000000000122, 36.00000000000024, 29.000000000000128, 33.10000000000021, 20.39999999999999, 28.400000000000137, 36.80000000000025, 25.600000000000065, 32.00000000000018, 34.800000000000225, 33.9000000000002, 23.50000000000003, 22.40000000000001, 30.90000000000016, 15.79999999999999, 44.20000000000037, 20.200000000000006, 8.000000000000082, 34.50000000000022, 43.70000000000036, 27.900000000000105, 41.30000000000032, -90.90000000000074, 43.50000000000035, 1.5000000000002076, 23.200000000000024, -145.90000000000066, 34.40000000000022, 11.200000000000092, 20.200000000000006, 35.70000000000024, -7.60000000000006, -17.19999999999952, 24.600000000000048, 15.79999999999999, 24.300000000000043, 47.20000000000042, 36.60000000000025, -155.0000000000006, 20.200000000000006, 32.800000000000196, 23.50000000000003, 17.000000000000004, 66.8000000000003, 59.70000000000042, 27.800000000000104, 48.600000000000456, 38.50000000000028, 30.100000000000144, -127.70000000000041, 37.80000000000027, 26.800000000000086, 30.200000000000145, 21.299999999999994, 26.50000000000008, 29.70000000000014, 6.300000000000166, 45.9000000000004, 36.80000000000025, 35.00000000000023, 34.50000000000022, 45.9000000000004, 3.900000000000188, 17.999999999999982, 20.200000000000006, 30.100000000000144, 30.60000000000016, 31.80000000000018, 27.0000000000001, 10.300000000000066, 23.50000000000003, 36.60000000000025, -22.19999999999952, 14.700000000000001], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [17.29999999999998, 10.699999999999967, 1.0999999999999865, 20.000000000000014, 5.299999999999965, -0.09999999999999937, 20.000000000000014, 11.599999999999964, -7.299999999999891, 5.299999999999965, -61.90000000000071, 13.999999999999966, -5.1999999999999265, -38.799999999999756, 15.799999999999963, -9.399999999999855, -5.1999999999999265, -5.1999999999999265, -53.50000000000019, 11.599999999999964, 20.000000000000014, 19.099999999999994, 20.000000000000014, -11.49999999999983, 5.299999999999965, 7.399999999999965, 5.299999999999965, 7.399999999999965, -400.0, -374.8, 9.499999999999964, 3.1999999999999615, 17.899999999999988, 1.0999999999999865, -61.90000000000068, 9.499999999999964, 3.7999999999999656, 6.1999999999999655, 15.799999999999963, -36.399999999999764, 7.399999999999965, -3.099999999999958, 9.499999999999964, 20.000000000000014, 13.699999999999964, -2.1999999999999713, -7.299999999999891, 20.000000000000014, 7.399999999999965, 15.199999999999966, -5.1999999999999265, 21.20000000000003, 17.899999999999988, -1.2999999999999847, -0.9999999999999846, 20.000000000000014, 17.899999999999988, 1.0999999999999865, 20.000000000000014, 1.0999999999999528, 1.0999999999999794, 5.299999999999965, -13.599999999999783, 20.000000000000014, 31.700000000000216, -19.899999999999743, 9.499999999999964, 1.0999999999999794, 13.69999999999997, 5.299999999999965, 3.1999999999999615, 23.600000000000065, 9.499999999999964, 16.39999999999996, 5.299999999999965, 3.1999999999999615, 7.399999999999965, -0.9999999999999846, 15.799999999999963, 1.0999999999999865, -13.599999999999786, 7.399999999999965, -3.099999999999958, 26.300000000000118, -0.9999999999999846, 3.1999999999999615, 20.000000000000014, -42.99999999999976, 15.799999999999963, 13.699999999999964, 27.200000000000134, 9.499999999999964, 11.599999999999966, 5.299999999999965, 11.599999999999964, 22.700000000000053, 20.000000000000014, -229.90000000000046, 26.900000000000126, 11.599999999999964, -21.99999999999976, -11.499999999999819, -13.599999999999797, 15.799999999999963, -324.39999999999975, 9.499999999999964, 20.000000000000014, 7.399999999999965, 1.0999999999999865, 1.0999999999999865, 1.0999999999999865, 1.0999999999999865, -7.299999999999891, 20.000000000000014, -17.800000000000004, -17.80000000000001, -80.80000000000075, 11.599999999999964, 1.0999999999999865, 9.499999999999964, -17.79999999999974, 11.599999999999964, 3.1999999999999615, 1.0999999999999865, 17.899999999999988, 17.299999999999976, 11.599999999999964, 20.000000000000014, -345.4, 7.399999999999968, 3.1999999999999615, -0.9999999999999846, 20.000000000000014, -5.1999999999999265, -3.099999999999958, 11.599999999999964, -0.9999999999999846, -0.9999999999999846, 17.899999999999988, 47.90000000000024, 33.500000000000206, 3.1999999999999615, 9.499999999999964, 5.299999999999965, 20.000000000000014, 14.599999999999975, 20.000000000000014, 9.499999999999964, 13.699999999999964, 7.399999999999965, -334.9000000000001, 27.20000000000013, -5.1999999999999265, 20.000000000000014, 9.499999999999964, 5.299999999999965, 11.599999999999964, 11.599999999999964, 17.899999999999988, -13.599999999999783, 1.0999999999999865, 7.399999999999965, -7.299999999999891, 20.000000000000014, -9.399999999999855, -7.299999999999891, 20.900000000000027, 20.000000000000014, -5.1999999999999265, 20.000000000000014, 22.40000000000005, -9.399999999999855, 9.499999999999964, 20.000000000000014, 25.100000000000094, 0.7999999999999865, 3.1999999999999615, -28.299999999999756, 15.799999999999963, -17.79999999999974, 1.0999999999999865, 1.0999999999999865, 15.799999999999963, 5.299999999999965, 25.400000000000098, -17.79999999999974, -5.1999999999999265, 20.000000000000014, -17.79999999999974, 15.799999999999962, 20.000000000000014, -36.699999999999754, 15.799999999999963, -7.299999999999891, 5.599999999999968, 20.000000000000014, -2.4999999999999716, -78.70000000000087, -5.199999999999941, -3.099999999999958], "policy_predator_policy_reward": [7.0, 6.0, 9.0, 9.0, 10.0, 7.0, 4.0, 2.0, 13.0, 7.0, 20.0, 24.0, 24.0, 26.0, 2.0, 14.0, 12.0, 12.0, 32.0, 35.0, 0.0, 6.0, 15.0, 0.0, 6.0, 7.0, 6.0, 7.0, 197.0, 4.0, 5.0, 8.0, 8.0, 7.0, 22.0, 22.0, 9.0, 1.0, 14.0, 20.0, 6.0, 11.0, 2.0, 5.0, 11.0, 3.0, 11.0, 12.0, 4.0, 6.0, 12.0, 10.0, 9.0, 3.0, 10.0, 7.0, 9.0, 1.0, 3.0, 9.0, 7.0, 7.0, 6.0, 16.0, 19.0, 6.0, 6.0, 9.0, 6.0, 7.0, 0.0, 8.0, 5.0, 3.0, 8.0, 7.0, 10.0, 6.0, 5.0, 9.0, 6.0, 16.0, 10.0, 11.0, 8.0, 10.0, 30.0, 1.0, 3.0, 2.0, 5.0, 2.0, 4.0, 7.0, 4.0, 3.0, 119.0, 0.0, 1.0, 4.0, 20.0, 15.0, 8.0, 13.0, 164.0, 5.0, 1.0, 6.0, 0.0, 9.0, 9.0, 9.0, 13.0, 10.0, 3.0, 25.0, 48.0, 4.0, 5.0, 9.0, 18.0, 4.0, 10.0, 10.0, 6.0, 6.0, 4.0, 1.0, 174.0, 9.0, 10.0, 8.0, 12.0, 6.0, 12.0, 3.0, 10.0, 9.0, 1.0, 0.0, 3.0, 20.0, 6.0, 7.0, 9.0, 5.0, 4.0, 5.0, 6.0, 3.0, 169.0, 11.0, 11.0, 12.0, 5.0, 7.0, 3.0, 4.0, 1.0, 16.0, 9.0, 9.0, 4.0, 13.0, 9.0, 14.0, 3.0, 2.0, 11.0, 11.0, 12.0, 10.0, 5.0, 0.0, 10.0, 10.0, 21.0, 8.0, 2.0, 18.0, 9.0, 9.0, 2.0, 7.0, 5.0, 18.0, 12.0, 5.0, 11.0, 18.0, 27.0, 0.0, 10.0, 5.0, 9.0, 2.0, 12.0, 47.0, 3.0, 20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5886981416642264, "mean_inference_ms": 1.8216003354885044, "mean_action_processing_ms": 0.2554167349299554, "mean_env_wait_ms": 0.197749211411156, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006150007247924805, "StateBufferConnector_ms": 0.0036939382553100586, "ViewRequirementAgentConnector_ms": 0.09840571880340576}, "num_episodes": 22, "episode_return_max": 66.8000000000003, "episode_return_min": -573.8, "episode_return_mean": 14.32700000000013, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2208000, "num_agent_steps_trained": 2208000, "num_env_steps_sampled": 552000, "num_env_steps_trained": 552000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 377.5960179741223, "num_env_steps_trained_throughput_per_sec": 377.5960179741223, "timesteps_total": 552000, "num_env_steps_sampled_lifetime": 552000, "num_agent_steps_sampled_lifetime": 2208000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2208000, "timers": {"training_iteration_time_ms": 10912.646, "restore_workers_time_ms": 0.014, "training_step_time_ms": 10912.579, "sample_time_ms": 1291.862, "learn_time_ms": 9603.859, "learn_throughput": 416.499, "synch_weights_time_ms": 15.151}, "counters": {"num_env_steps_sampled": 552000, "num_env_steps_trained": 552000, "num_agent_steps_sampled": 2208000, "num_agent_steps_trained": 2208000}, "done": false, "training_iteration": 138, "trial_id": "3dae5_00000", "date": "2024-08-14_09-32-16", "timestamp": 1723642336, "time_this_iter_s": 10.597430944442749, "time_total_s": 3153.782785177231, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b38b6c10>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3153.782785177231, "iterations_since_restore": 138, "perf": {"cpu_util_percent": 27.826666666666668, "ram_util_percent": 83.6}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3445237882947796, "cur_kl_coeff": 1.5449523925781246e-05, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.595120252124847, "policy_loss": -0.0015337016773484056, "vf_loss": 0.5966536999655464, "vf_explained_var": 0.062314430368009696, "kl": 0.01643274765066274, "entropy": 1.014642923944211, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 261765.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.875079591107116, "cur_kl_coeff": 0.03164062499999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.6701598392572825, "policy_loss": -0.0037218223054888387, "vf_loss": 0.6736911576635466, "vf_explained_var": 0.01496367514448822, "kl": 0.0060209267722187475, "entropy": 1.0123609740582724, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 261765.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 556000, "num_env_steps_trained": 556000, "num_agent_steps_sampled": 2224000, "num_agent_steps_trained": 2224000}, "env_runners": {"episode_reward_max": 66.8000000000003, "episode_reward_min": -173.40000000000074, "episode_reward_mean": 19.305000000000124, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -378.9999999999998, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 47.90000000000024, "predator_policy": 190.0}, "policy_reward_mean": {"prey_policy": -2.957499999999978, "predator_policy": 12.61}, "custom_metrics": {}, "hist_stats": {"episode_reward": [20.000000000000004, 13.399999999999999, 21.3, 36.50000000000025, 25.500000000000064, 35.70000000000024, 32.600000000000186, 38.00000000000027, 28.600000000000122, 36.00000000000024, 29.000000000000128, 33.10000000000021, 20.39999999999999, 28.400000000000137, 36.80000000000025, 25.600000000000065, 32.00000000000018, 34.800000000000225, 33.9000000000002, 23.50000000000003, 22.40000000000001, 30.90000000000016, 15.79999999999999, 44.20000000000037, 20.200000000000006, 8.000000000000082, 34.50000000000022, 43.70000000000036, 27.900000000000105, 41.30000000000032, -90.90000000000074, 43.50000000000035, 1.5000000000002076, 23.200000000000024, -145.90000000000066, 34.40000000000022, 11.200000000000092, 20.200000000000006, 35.70000000000024, -7.60000000000006, -17.19999999999952, 24.600000000000048, 15.79999999999999, 24.300000000000043, 47.20000000000042, 36.60000000000025, -155.0000000000006, 20.200000000000006, 32.800000000000196, 23.50000000000003, 17.000000000000004, 66.8000000000003, 59.70000000000042, 27.800000000000104, 48.600000000000456, 38.50000000000028, 30.100000000000144, -127.70000000000041, 37.80000000000027, 26.800000000000086, 30.200000000000145, 21.299999999999994, 26.50000000000008, 29.70000000000014, 6.300000000000166, 45.9000000000004, 36.80000000000025, 35.00000000000023, 34.50000000000022, 45.9000000000004, 3.900000000000188, 17.999999999999982, 20.200000000000006, 30.100000000000144, 30.60000000000016, 31.80000000000018, 27.0000000000001, 10.300000000000066, 23.50000000000003, 36.60000000000025, -22.19999999999952, 14.700000000000001, 37.20000000000026, 25.700000000000067, 31.200000000000163, 12.500000000000059, 15.800000000000004, 23.200000000000024, 36.70000000000025, 31.700000000000177, 48.80000000000045, 31.600000000000172, 27.900000000000105, 38.300000000000274, 30.10000000000015, -173.40000000000074, 0.7000000000001183, 44.50000000000037, 15.400000000000006, 38.50000000000028], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [3.7999999999999656, 6.1999999999999655, 15.799999999999963, -36.399999999999764, 7.399999999999965, -3.099999999999958, 9.499999999999964, 20.000000000000014, 13.699999999999964, -2.1999999999999713, -7.299999999999891, 20.000000000000014, 7.399999999999965, 15.199999999999966, -5.1999999999999265, 21.20000000000003, 17.899999999999988, -1.2999999999999847, -0.9999999999999846, 20.000000000000014, 17.899999999999988, 1.0999999999999865, 20.000000000000014, 1.0999999999999528, 1.0999999999999794, 5.299999999999965, -13.599999999999783, 20.000000000000014, 31.700000000000216, -19.899999999999743, 9.499999999999964, 1.0999999999999794, 13.69999999999997, 5.299999999999965, 3.1999999999999615, 23.600000000000065, 9.499999999999964, 16.39999999999996, 5.299999999999965, 3.1999999999999615, 7.399999999999965, -0.9999999999999846, 15.799999999999963, 1.0999999999999865, -13.599999999999786, 7.399999999999965, -3.099999999999958, 26.300000000000118, -0.9999999999999846, 3.1999999999999615, 20.000000000000014, -42.99999999999976, 15.799999999999963, 13.699999999999964, 27.200000000000134, 9.499999999999964, 11.599999999999966, 5.299999999999965, 11.599999999999964, 22.700000000000053, 20.000000000000014, -229.90000000000046, 26.900000000000126, 11.599999999999964, -21.99999999999976, -11.499999999999819, -13.599999999999797, 15.799999999999963, -324.39999999999975, 9.499999999999964, 20.000000000000014, 7.399999999999965, 1.0999999999999865, 1.0999999999999865, 1.0999999999999865, 1.0999999999999865, -7.299999999999891, 20.000000000000014, -17.800000000000004, -17.80000000000001, -80.80000000000075, 11.599999999999964, 1.0999999999999865, 9.499999999999964, -17.79999999999974, 11.599999999999964, 3.1999999999999615, 1.0999999999999865, 17.899999999999988, 17.299999999999976, 11.599999999999964, 20.000000000000014, -345.4, 7.399999999999968, 3.1999999999999615, -0.9999999999999846, 20.000000000000014, -5.1999999999999265, -3.099999999999958, 11.599999999999964, -0.9999999999999846, -0.9999999999999846, 17.899999999999988, 47.90000000000024, 33.500000000000206, 3.1999999999999615, 9.499999999999964, 5.299999999999965, 20.000000000000014, 14.599999999999975, 20.000000000000014, 9.499999999999964, 13.699999999999964, 7.399999999999965, -334.9000000000001, 27.20000000000013, -5.1999999999999265, 20.000000000000014, 9.499999999999964, 5.299999999999965, 11.599999999999964, 11.599999999999964, 17.899999999999988, -13.599999999999783, 1.0999999999999865, 7.399999999999965, -7.299999999999891, 20.000000000000014, -9.399999999999855, -7.299999999999891, 20.900000000000027, 20.000000000000014, -5.1999999999999265, 20.000000000000014, 22.40000000000005, -9.399999999999855, 9.499999999999964, 20.000000000000014, 25.100000000000094, 0.7999999999999865, 3.1999999999999615, -28.299999999999756, 15.799999999999963, -17.79999999999974, 1.0999999999999865, 1.0999999999999865, 15.799999999999963, 5.299999999999965, 25.400000000000098, -17.79999999999974, -5.1999999999999265, 20.000000000000014, -17.79999999999974, 15.799999999999962, 20.000000000000014, -36.699999999999754, 15.799999999999963, -7.299999999999891, 5.599999999999968, 20.000000000000014, -2.4999999999999716, -78.70000000000087, -5.199999999999941, -3.099999999999958, 3.1999999999999615, 20.000000000000014, 7.399999999999965, 5.299999999999965, 7.399999999999965, 15.799999999999963, 3.1999999999999615, -15.699999999999747, -7.299999999999891, 1.0999999999999865, -5.1999999999999265, 7.399999999999965, 20.000000000000014, -7.299999999999891, 20.000000000000014, -7.299999999999891, -23.49999999999975, 35.30000000000026, -3.099999999999958, 13.699999999999964, 13.699999999999964, 3.1999999999999615, 5.299999999999965, 20.000000000000014, 20.000000000000014, -19.899999999999743, -378.9999999999998, 11.599999999999964, 3.1999999999999615, -32.49999999999975, 28.100000000000147, 7.399999999999965, -19.899999999999743, 5.299999999999965, 11.599999999999964, 17.899999999999988], "policy_predator_policy_reward": [9.0, 1.0, 14.0, 20.0, 6.0, 11.0, 2.0, 5.0, 11.0, 3.0, 11.0, 12.0, 4.0, 6.0, 12.0, 10.0, 9.0, 3.0, 10.0, 7.0, 9.0, 1.0, 3.0, 9.0, 7.0, 7.0, 6.0, 16.0, 19.0, 6.0, 6.0, 9.0, 6.0, 7.0, 0.0, 8.0, 5.0, 3.0, 8.0, 7.0, 10.0, 6.0, 5.0, 9.0, 6.0, 16.0, 10.0, 11.0, 8.0, 10.0, 30.0, 1.0, 3.0, 2.0, 5.0, 2.0, 4.0, 7.0, 4.0, 3.0, 119.0, 0.0, 1.0, 4.0, 20.0, 15.0, 8.0, 13.0, 164.0, 5.0, 1.0, 6.0, 0.0, 9.0, 9.0, 9.0, 13.0, 10.0, 3.0, 25.0, 48.0, 4.0, 5.0, 9.0, 18.0, 4.0, 10.0, 10.0, 6.0, 6.0, 4.0, 1.0, 174.0, 9.0, 10.0, 8.0, 12.0, 6.0, 12.0, 3.0, 10.0, 9.0, 1.0, 0.0, 3.0, 20.0, 6.0, 7.0, 9.0, 5.0, 4.0, 5.0, 6.0, 3.0, 169.0, 11.0, 11.0, 12.0, 5.0, 7.0, 3.0, 4.0, 1.0, 16.0, 9.0, 9.0, 4.0, 13.0, 9.0, 14.0, 3.0, 2.0, 11.0, 11.0, 12.0, 10.0, 5.0, 0.0, 10.0, 10.0, 21.0, 8.0, 2.0, 18.0, 9.0, 9.0, 2.0, 7.0, 5.0, 18.0, 12.0, 5.0, 11.0, 18.0, 27.0, 0.0, 10.0, 5.0, 9.0, 2.0, 12.0, 47.0, 3.0, 20.0, 6.0, 8.0, 10.0, 3.0, 6.0, 2.0, 8.0, 17.0, 13.0, 9.0, 12.0, 9.0, 11.0, 13.0, 8.0, 11.0, 22.0, 15.0, 11.0, 10.0, 8.0, 3.0, 6.0, 7.0, 19.0, 11.0, 4.0, 190.0, 25.0, 5.0, 3.0, 6.0, 14.0, 16.0, 5.0, 4.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5883516123757321, "mean_inference_ms": 1.820881464734004, "mean_action_processing_ms": 0.25558651675728256, "mean_env_wait_ms": 0.19747247347970132, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006524205207824707, "StateBufferConnector_ms": 0.0044661760330200195, "ViewRequirementAgentConnector_ms": 0.09668958187103271}, "num_episodes": 18, "episode_return_max": 66.8000000000003, "episode_return_min": -173.40000000000074, "episode_return_mean": 19.305000000000124, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2224000, "num_agent_steps_trained": 2224000, "num_env_steps_sampled": 556000, "num_env_steps_trained": 556000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 357.6341588855362, "num_env_steps_trained_throughput_per_sec": 357.6341588855362, "timesteps_total": 556000, "num_env_steps_sampled_lifetime": 556000, "num_agent_steps_sampled_lifetime": 2224000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2224000, "timers": {"training_iteration_time_ms": 10903.067, "restore_workers_time_ms": 0.014, "training_step_time_ms": 10903.016, "sample_time_ms": 1285.454, "learn_time_ms": 9600.492, "learn_throughput": 416.645, "synch_weights_time_ms": 15.219}, "counters": {"num_env_steps_sampled": 556000, "num_env_steps_trained": 556000, "num_agent_steps_sampled": 2224000, "num_agent_steps_trained": 2224000}, "done": false, "training_iteration": 139, "trial_id": "3dae5_00000", "date": "2024-08-14_09-32-27", "timestamp": 1723642347, "time_this_iter_s": 11.232980966567993, "time_total_s": 3165.015766143799, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b38b6f70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3165.015766143799, "iterations_since_restore": 139, "perf": {"cpu_util_percent": 30.400000000000002, "ram_util_percent": 83.61250000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1558429390980454, "cur_kl_coeff": 1.5449523925781246e-05, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.529716564880477, "policy_loss": -0.0028399909104875943, "vf_loss": 0.5325562789099951, "vf_explained_var": 0.04630285473096939, "kl": 0.01789286055950975, "entropy": 0.9654036560071209, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 263655.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9534679061205928, "cur_kl_coeff": 0.03164062499999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.6052248560440993, "policy_loss": -0.005767946263834361, "vf_loss": 0.6106146669103986, "vf_explained_var": 0.01677424431477905, "kl": 0.01195096292062104, "entropy": 1.056195072143797, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 263655.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 560000, "num_env_steps_trained": 560000, "num_agent_steps_sampled": 2240000, "num_agent_steps_trained": 2240000}, "env_runners": {"episode_reward_max": 66.8000000000003, "episode_reward_min": -198.7000000000008, "episode_reward_mean": 17.024000000000115, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 47.90000000000024, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -4.9029999999999765, "predator_policy": 13.415}, "custom_metrics": {}, "hist_stats": {"episode_reward": [33.9000000000002, 23.50000000000003, 22.40000000000001, 30.90000000000016, 15.79999999999999, 44.20000000000037, 20.200000000000006, 8.000000000000082, 34.50000000000022, 43.70000000000036, 27.900000000000105, 41.30000000000032, -90.90000000000074, 43.50000000000035, 1.5000000000002076, 23.200000000000024, -145.90000000000066, 34.40000000000022, 11.200000000000092, 20.200000000000006, 35.70000000000024, -7.60000000000006, -17.19999999999952, 24.600000000000048, 15.79999999999999, 24.300000000000043, 47.20000000000042, 36.60000000000025, -155.0000000000006, 20.200000000000006, 32.800000000000196, 23.50000000000003, 17.000000000000004, 66.8000000000003, 59.70000000000042, 27.800000000000104, 48.600000000000456, 38.50000000000028, 30.100000000000144, -127.70000000000041, 37.80000000000027, 26.800000000000086, 30.200000000000145, 21.299999999999994, 26.50000000000008, 29.70000000000014, 6.300000000000166, 45.9000000000004, 36.80000000000025, 35.00000000000023, 34.50000000000022, 45.9000000000004, 3.900000000000188, 17.999999999999982, 20.200000000000006, 30.100000000000144, 30.60000000000016, 31.80000000000018, 27.0000000000001, 10.300000000000066, 23.50000000000003, 36.60000000000025, -22.19999999999952, 14.700000000000001, 37.20000000000026, 25.700000000000067, 31.200000000000163, 12.500000000000059, 15.800000000000004, 23.200000000000024, 36.70000000000025, 31.700000000000177, 48.80000000000045, 31.600000000000172, 27.900000000000105, 38.300000000000274, 30.10000000000015, -173.40000000000074, 0.7000000000001183, 44.50000000000037, 15.400000000000006, 38.50000000000028, 44.30000000000036, 29.000000000000128, 28.900000000000126, 21.299999999999997, 27.5000000000001, 34.50000000000022, 30.000000000000146, 39.20000000000029, 25.700000000000067, 38.90000000000028, 36.70000000000025, 9.200000000000081, 27.90000000000011, 31.200000000000166, 20.199999999999978, -198.7000000000008, 32.50000000000019, 21.3], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [9.499999999999964, 16.39999999999996, 5.299999999999965, 3.1999999999999615, 7.399999999999965, -0.9999999999999846, 15.799999999999963, 1.0999999999999865, -13.599999999999786, 7.399999999999965, -3.099999999999958, 26.300000000000118, -0.9999999999999846, 3.1999999999999615, 20.000000000000014, -42.99999999999976, 15.799999999999963, 13.699999999999964, 27.200000000000134, 9.499999999999964, 11.599999999999966, 5.299999999999965, 11.599999999999964, 22.700000000000053, 20.000000000000014, -229.90000000000046, 26.900000000000126, 11.599999999999964, -21.99999999999976, -11.499999999999819, -13.599999999999797, 15.799999999999963, -324.39999999999975, 9.499999999999964, 20.000000000000014, 7.399999999999965, 1.0999999999999865, 1.0999999999999865, 1.0999999999999865, 1.0999999999999865, -7.299999999999891, 20.000000000000014, -17.800000000000004, -17.80000000000001, -80.80000000000075, 11.599999999999964, 1.0999999999999865, 9.499999999999964, -17.79999999999974, 11.599999999999964, 3.1999999999999615, 1.0999999999999865, 17.899999999999988, 17.299999999999976, 11.599999999999964, 20.000000000000014, -345.4, 7.399999999999968, 3.1999999999999615, -0.9999999999999846, 20.000000000000014, -5.1999999999999265, -3.099999999999958, 11.599999999999964, -0.9999999999999846, -0.9999999999999846, 17.899999999999988, 47.90000000000024, 33.500000000000206, 3.1999999999999615, 9.499999999999964, 5.299999999999965, 20.000000000000014, 14.599999999999975, 20.000000000000014, 9.499999999999964, 13.699999999999964, 7.399999999999965, -334.9000000000001, 27.20000000000013, -5.1999999999999265, 20.000000000000014, 9.499999999999964, 5.299999999999965, 11.599999999999964, 11.599999999999964, 17.899999999999988, -13.599999999999783, 1.0999999999999865, 7.399999999999965, -7.299999999999891, 20.000000000000014, -9.399999999999855, -7.299999999999891, 20.900000000000027, 20.000000000000014, -5.1999999999999265, 20.000000000000014, 22.40000000000005, -9.399999999999855, 9.499999999999964, 20.000000000000014, 25.100000000000094, 0.7999999999999865, 3.1999999999999615, -28.299999999999756, 15.799999999999963, -17.79999999999974, 1.0999999999999865, 1.0999999999999865, 15.799999999999963, 5.299999999999965, 25.400000000000098, -17.79999999999974, -5.1999999999999265, 20.000000000000014, -17.79999999999974, 15.799999999999962, 20.000000000000014, -36.699999999999754, 15.799999999999963, -7.299999999999891, 5.599999999999968, 20.000000000000014, -2.4999999999999716, -78.70000000000087, -5.199999999999941, -3.099999999999958, 3.1999999999999615, 20.000000000000014, 7.399999999999965, 5.299999999999965, 7.399999999999965, 15.799999999999963, 3.1999999999999615, -15.699999999999747, -7.299999999999891, 1.0999999999999865, -5.1999999999999265, 7.399999999999965, 20.000000000000014, -7.299999999999891, 20.000000000000014, -7.299999999999891, -23.49999999999975, 35.30000000000026, -3.099999999999958, 13.699999999999964, 13.699999999999964, 3.1999999999999615, 5.299999999999965, 20.000000000000014, 20.000000000000014, -19.899999999999743, -378.9999999999998, 11.599999999999964, 3.1999999999999615, -32.49999999999975, 28.100000000000147, 7.399999999999965, -19.899999999999743, 5.299999999999965, 11.599999999999964, 17.899999999999988, 17.899999999999988, 25.400000000000098, 20.000000000000014, -0.9999999999999846, -3.099999999999958, 20.000000000000014, -9.399999999999855, 13.699999999999964, -1.2999999999999994, 15.799999999999963, 9.499999999999964, 20.000000000000014, -0.9999999999999846, 20.000000000000014, 3.1999999999999615, 20.000000000000014, 7.399999999999965, 5.299999999999965, 20.000000000000014, 17.899999999999988, 13.699999999999964, 20.000000000000014, -30.39999999999975, 11.599999999999964, 17.899999999999988, -0.9999999999999881, 11.599999999999964, 11.599999999999964, -13.59999999999979, -5.1999999999999265, -15.699999999999747, -400.0, -5.199999999999934, 13.699999999999964, 5.299999999999965, -0.9999999999999846], "policy_predator_policy_reward": [5.0, 3.0, 8.0, 7.0, 10.0, 6.0, 5.0, 9.0, 6.0, 16.0, 10.0, 11.0, 8.0, 10.0, 30.0, 1.0, 3.0, 2.0, 5.0, 2.0, 4.0, 7.0, 4.0, 3.0, 119.0, 0.0, 1.0, 4.0, 20.0, 15.0, 8.0, 13.0, 164.0, 5.0, 1.0, 6.0, 0.0, 9.0, 9.0, 9.0, 13.0, 10.0, 3.0, 25.0, 48.0, 4.0, 5.0, 9.0, 18.0, 4.0, 10.0, 10.0, 6.0, 6.0, 4.0, 1.0, 174.0, 9.0, 10.0, 8.0, 12.0, 6.0, 12.0, 3.0, 10.0, 9.0, 1.0, 0.0, 3.0, 20.0, 6.0, 7.0, 9.0, 5.0, 4.0, 5.0, 6.0, 3.0, 169.0, 11.0, 11.0, 12.0, 5.0, 7.0, 3.0, 4.0, 1.0, 16.0, 9.0, 9.0, 4.0, 13.0, 9.0, 14.0, 3.0, 2.0, 11.0, 11.0, 12.0, 10.0, 5.0, 0.0, 10.0, 10.0, 21.0, 8.0, 2.0, 18.0, 9.0, 9.0, 2.0, 7.0, 5.0, 18.0, 12.0, 5.0, 11.0, 18.0, 27.0, 0.0, 10.0, 5.0, 9.0, 2.0, 12.0, 47.0, 3.0, 20.0, 6.0, 8.0, 10.0, 3.0, 6.0, 2.0, 8.0, 17.0, 13.0, 9.0, 12.0, 9.0, 11.0, 13.0, 8.0, 11.0, 22.0, 15.0, 11.0, 10.0, 8.0, 3.0, 6.0, 7.0, 19.0, 11.0, 4.0, 190.0, 25.0, 5.0, 3.0, 6.0, 14.0, 16.0, 5.0, 4.0, 0.0, 1.0, 10.0, 0.0, 11.0, 1.0, 3.0, 14.0, 2.0, 11.0, 0.0, 5.0, 10.0, 1.0, 8.0, 8.0, 6.0, 7.0, 0.0, 1.0, 3.0, 0.0, 4.0, 24.0, 1.0, 10.0, 4.0, 4.0, 22.0, 17.0, 17.0, 200.0, 14.0, 10.0, 7.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5880749698420934, "mean_inference_ms": 1.8200917038501776, "mean_action_processing_ms": 0.2553907101864267, "mean_env_wait_ms": 0.1973311997453569, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006974697113037109, "StateBufferConnector_ms": 0.004618167877197266, "ViewRequirementAgentConnector_ms": 0.0964205265045166}, "num_episodes": 18, "episode_return_max": 66.8000000000003, "episode_return_min": -198.7000000000008, "episode_return_mean": 17.024000000000115, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2240000, "num_agent_steps_trained": 2240000, "num_env_steps_sampled": 560000, "num_env_steps_trained": 560000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 364.6595636961115, "num_env_steps_trained_throughput_per_sec": 364.6595636961115, "timesteps_total": 560000, "num_env_steps_sampled_lifetime": 560000, "num_agent_steps_sampled_lifetime": 2240000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2240000, "timers": {"training_iteration_time_ms": 10949.992, "restore_workers_time_ms": 0.015, "training_step_time_ms": 10949.939, "sample_time_ms": 1291.535, "learn_time_ms": 9641.044, "learn_throughput": 414.893, "synch_weights_time_ms": 15.386}, "counters": {"num_env_steps_sampled": 560000, "num_env_steps_trained": 560000, "num_agent_steps_sampled": 2240000, "num_agent_steps_trained": 2240000}, "done": false, "training_iteration": 140, "trial_id": "3dae5_00000", "date": "2024-08-14_09-32-38", "timestamp": 1723642358, "time_this_iter_s": 10.99746298789978, "time_total_s": 3176.0132291316986, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b36d6d30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3176.0132291316986, "iterations_since_restore": 140, "perf": {"cpu_util_percent": 31.7125, "ram_util_percent": 83.68125}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5987254422335397, "cur_kl_coeff": 1.5449523925781246e-05, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.5921715007178368, "policy_loss": -0.0019430773398006168, "vf_loss": 0.594114188329568, "vf_explained_var": 0.054698983481321385, "kl": 0.025283309833335172, "entropy": 0.7078478875298979, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 265545.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.050955755370004, "cur_kl_coeff": 0.03164062499999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.0499932472273785, "policy_loss": -0.005750061977881367, "vf_loss": 1.05538130833043, "vf_explained_var": 0.012725734048419528, "kl": 0.011441104527719946, "entropy": 1.025421215522857, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 265545.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 564000, "num_env_steps_trained": 564000, "num_agent_steps_sampled": 2256000, "num_agent_steps_trained": 2256000}, "env_runners": {"episode_reward_max": 66.8000000000003, "episode_reward_min": -484.6999999999997, "episode_reward_mean": 16.152000000000147, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 47.90000000000024, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -4.803999999999973, "predator_policy": 12.88}, "custom_metrics": {}, "hist_stats": {"episode_reward": [24.600000000000048, 15.79999999999999, 24.300000000000043, 47.20000000000042, 36.60000000000025, -155.0000000000006, 20.200000000000006, 32.800000000000196, 23.50000000000003, 17.000000000000004, 66.8000000000003, 59.70000000000042, 27.800000000000104, 48.600000000000456, 38.50000000000028, 30.100000000000144, -127.70000000000041, 37.80000000000027, 26.800000000000086, 30.200000000000145, 21.299999999999994, 26.50000000000008, 29.70000000000014, 6.300000000000166, 45.9000000000004, 36.80000000000025, 35.00000000000023, 34.50000000000022, 45.9000000000004, 3.900000000000188, 17.999999999999982, 20.200000000000006, 30.100000000000144, 30.60000000000016, 31.80000000000018, 27.0000000000001, 10.300000000000066, 23.50000000000003, 36.60000000000025, -22.19999999999952, 14.700000000000001, 37.20000000000026, 25.700000000000067, 31.200000000000163, 12.500000000000059, 15.800000000000004, 23.200000000000024, 36.70000000000025, 31.700000000000177, 48.80000000000045, 31.600000000000172, 27.900000000000105, 38.300000000000274, 30.10000000000015, -173.40000000000074, 0.7000000000001183, 44.50000000000037, 15.400000000000006, 38.50000000000028, 44.30000000000036, 29.000000000000128, 28.900000000000126, 21.299999999999997, 27.5000000000001, 34.50000000000022, 30.000000000000146, 39.20000000000029, 25.700000000000067, 38.90000000000028, 36.70000000000025, 9.200000000000081, 27.90000000000011, 31.200000000000166, 20.199999999999978, -198.7000000000008, 32.50000000000019, 21.3, 37.80000000000027, 36.70000000000025, 41.40000000000032, 34.30000000000022, 48.50000000000045, 37.30000000000026, 30.900000000000162, 27.90000000000011, 21.299999999999994, 35.600000000000236, 27.600000000000225, 31.600000000000186, 43.70000000000035, -484.6999999999997, -9.69999999999964, 8.100000000000113, 17.999999999999982, 51.70000000000049, 5.20000000000017, 31.50000000000018, 28.000000000000107, 34.40000000000022, 30.100000000000147], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [1.0999999999999865, 9.499999999999964, -17.79999999999974, 11.599999999999964, 3.1999999999999615, 1.0999999999999865, 17.899999999999988, 17.299999999999976, 11.599999999999964, 20.000000000000014, -345.4, 7.399999999999968, 3.1999999999999615, -0.9999999999999846, 20.000000000000014, -5.1999999999999265, -3.099999999999958, 11.599999999999964, -0.9999999999999846, -0.9999999999999846, 17.899999999999988, 47.90000000000024, 33.500000000000206, 3.1999999999999615, 9.499999999999964, 5.299999999999965, 20.000000000000014, 14.599999999999975, 20.000000000000014, 9.499999999999964, 13.699999999999964, 7.399999999999965, -334.9000000000001, 27.20000000000013, -5.1999999999999265, 20.000000000000014, 9.499999999999964, 5.299999999999965, 11.599999999999964, 11.599999999999964, 17.899999999999988, -13.599999999999783, 1.0999999999999865, 7.399999999999965, -7.299999999999891, 20.000000000000014, -9.399999999999855, -7.299999999999891, 20.900000000000027, 20.000000000000014, -5.1999999999999265, 20.000000000000014, 22.40000000000005, -9.399999999999855, 9.499999999999964, 20.000000000000014, 25.100000000000094, 0.7999999999999865, 3.1999999999999615, -28.299999999999756, 15.799999999999963, -17.79999999999974, 1.0999999999999865, 1.0999999999999865, 15.799999999999963, 5.299999999999965, 25.400000000000098, -17.79999999999974, -5.1999999999999265, 20.000000000000014, -17.79999999999974, 15.799999999999962, 20.000000000000014, -36.699999999999754, 15.799999999999963, -7.299999999999891, 5.599999999999968, 20.000000000000014, -2.4999999999999716, -78.70000000000087, -5.199999999999941, -3.099999999999958, 3.1999999999999615, 20.000000000000014, 7.399999999999965, 5.299999999999965, 7.399999999999965, 15.799999999999963, 3.1999999999999615, -15.699999999999747, -7.299999999999891, 1.0999999999999865, -5.1999999999999265, 7.399999999999965, 20.000000000000014, -7.299999999999891, 20.000000000000014, -7.299999999999891, -23.49999999999975, 35.30000000000026, -3.099999999999958, 13.699999999999964, 13.699999999999964, 3.1999999999999615, 5.299999999999965, 20.000000000000014, 20.000000000000014, -19.899999999999743, -378.9999999999998, 11.599999999999964, 3.1999999999999615, -32.49999999999975, 28.100000000000147, 7.399999999999965, -19.899999999999743, 5.299999999999965, 11.599999999999964, 17.899999999999988, 17.899999999999988, 25.400000000000098, 20.000000000000014, -0.9999999999999846, -3.099999999999958, 20.000000000000014, -9.399999999999855, 13.699999999999964, -1.2999999999999994, 15.799999999999963, 9.499999999999964, 20.000000000000014, -0.9999999999999846, 20.000000000000014, 3.1999999999999615, 20.000000000000014, 7.399999999999965, 5.299999999999965, 20.000000000000014, 17.899999999999988, 13.699999999999964, 20.000000000000014, -30.39999999999975, 11.599999999999964, 17.899999999999988, -0.9999999999999881, 11.599999999999964, 11.599999999999964, -13.59999999999979, -5.1999999999999265, -15.699999999999747, -400.0, -5.199999999999934, 13.699999999999964, 5.299999999999965, -0.9999999999999846, -5.1999999999999265, 20.000000000000014, 13.699999999999964, 20.000000000000014, 15.799999999999963, 23.600000000000065, 13.69999999999997, 11.599999999999973, 11.599999999999964, 29.900000000000183, 20.000000000000014, 5.299999999999965, 20.000000000000014, -3.099999999999958, 20.000000000000014, -3.099999999999958, -11.499999999999819, 15.799999999999963, 20.000000000000014, 11.599999999999964, -9.400000000000045, 20.000000000000014, 20.000000000000014, -9.399999999999855, 26.300000000000114, 7.399999999999965, -311.80000000000007, -376.89999999999986, -78.70000000000087, 20.000000000000014, -13.59999999999979, -7.299999999999905, 15.799999999999963, -17.79999999999974, 39.80000000000025, -6.0999999999999375, -2.4999999999999716, -28.29999999999975, 17.899999999999984, -9.399999999999855, 13.699999999999964, 5.299999999999965, 9.499999999999964, 17.899999999999988, 1.0999999999999865, 20.000000000000014], "policy_predator_policy_reward": [5.0, 9.0, 18.0, 4.0, 10.0, 10.0, 6.0, 6.0, 4.0, 1.0, 174.0, 9.0, 10.0, 8.0, 12.0, 6.0, 12.0, 3.0, 10.0, 9.0, 1.0, 0.0, 3.0, 20.0, 6.0, 7.0, 9.0, 5.0, 4.0, 5.0, 6.0, 3.0, 169.0, 11.0, 11.0, 12.0, 5.0, 7.0, 3.0, 4.0, 1.0, 16.0, 9.0, 9.0, 4.0, 13.0, 9.0, 14.0, 3.0, 2.0, 11.0, 11.0, 12.0, 10.0, 5.0, 0.0, 10.0, 10.0, 21.0, 8.0, 2.0, 18.0, 9.0, 9.0, 2.0, 7.0, 5.0, 18.0, 12.0, 5.0, 11.0, 18.0, 27.0, 0.0, 10.0, 5.0, 9.0, 2.0, 12.0, 47.0, 3.0, 20.0, 6.0, 8.0, 10.0, 3.0, 6.0, 2.0, 8.0, 17.0, 13.0, 9.0, 12.0, 9.0, 11.0, 13.0, 8.0, 11.0, 22.0, 15.0, 11.0, 10.0, 8.0, 3.0, 6.0, 7.0, 19.0, 11.0, 4.0, 190.0, 25.0, 5.0, 3.0, 6.0, 14.0, 16.0, 5.0, 4.0, 0.0, 1.0, 10.0, 0.0, 11.0, 1.0, 3.0, 14.0, 2.0, 11.0, 0.0, 5.0, 10.0, 1.0, 8.0, 8.0, 6.0, 7.0, 0.0, 1.0, 3.0, 0.0, 4.0, 24.0, 1.0, 10.0, 4.0, 4.0, 22.0, 17.0, 17.0, 200.0, 14.0, 10.0, 7.0, 10.0, 12.0, 11.0, 0.0, 3.0, 0.0, 2.0, 3.0, 6.0, 4.0, 3.0, 5.0, 7.0, 3.0, 11.0, 11.0, 0.0, 5.0, 12.0, 0.0, 4.0, 3.0, 14.0, 13.0, 8.0, 4.0, 6.0, 199.0, 5.0, 47.0, 2.0, 13.0, 16.0, 2.0, 18.0, 17.0, 1.0, 24.0, 12.0, 12.0, 11.0, 2.0, 7.0, 2.0, 5.0, 9.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5879883904808306, "mean_inference_ms": 1.8179760211102747, "mean_action_processing_ms": 0.2554707821437795, "mean_env_wait_ms": 0.19721490722428917, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006413102149963379, "StateBufferConnector_ms": 0.004578232765197754, "ViewRequirementAgentConnector_ms": 0.09150803089141846}, "num_episodes": 23, "episode_return_max": 66.8000000000003, "episode_return_min": -484.6999999999997, "episode_return_mean": 16.152000000000147, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2256000, "num_agent_steps_trained": 2256000, "num_env_steps_sampled": 564000, "num_env_steps_trained": 564000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 383.3292907240487, "num_env_steps_trained_throughput_per_sec": 383.3292907240487, "timesteps_total": 564000, "num_env_steps_sampled_lifetime": 564000, "num_agent_steps_sampled_lifetime": 2256000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2256000, "timers": {"training_iteration_time_ms": 10850.984, "restore_workers_time_ms": 0.015, "training_step_time_ms": 10850.932, "sample_time_ms": 1291.645, "learn_time_ms": 9542.469, "learn_throughput": 419.179, "synch_weights_time_ms": 14.983}, "counters": {"num_env_steps_sampled": 564000, "num_env_steps_trained": 564000, "num_agent_steps_sampled": 2256000, "num_agent_steps_trained": 2256000}, "done": false, "training_iteration": 141, "trial_id": "3dae5_00000", "date": "2024-08-14_09-32-48", "timestamp": 1723642368, "time_this_iter_s": 10.440479040145874, "time_total_s": 3186.4537081718445, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b36e0700>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3186.4537081718445, "iterations_since_restore": 141, "perf": {"cpu_util_percent": 29.39333333333333, "ram_util_percent": 83.31333333333332}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.3571222731045314, "cur_kl_coeff": 2.3174285888671882e-05, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.2320832545795137, "policy_loss": -0.0018238752084986244, "vf_loss": 1.2339068611935964, "vf_explained_var": 0.0930401519177452, "kl": 0.011444857201053864, "entropy": 0.529012980016451, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 267435.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.8858423310612875, "cur_kl_coeff": 0.03164062499999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.7316089572729887, "policy_loss": -0.0052096454931112625, "vf_loss": 1.7365741378731199, "vf_explained_var": 0.002113580136072068, "kl": 0.007726203496449959, "entropy": 1.0028524014054152, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 267435.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 568000, "num_env_steps_trained": 568000, "num_agent_steps_sampled": 2272000, "num_agent_steps_trained": 2272000}, "env_runners": {"episode_reward_max": 51.70000000000049, "episode_reward_min": -484.6999999999997, "episode_reward_mean": 17.70700000000015, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 39.80000000000025, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -2.906499999999971, "predator_policy": 11.76}, "custom_metrics": {}, "hist_stats": {"episode_reward": [26.800000000000086, 30.200000000000145, 21.299999999999994, 26.50000000000008, 29.70000000000014, 6.300000000000166, 45.9000000000004, 36.80000000000025, 35.00000000000023, 34.50000000000022, 45.9000000000004, 3.900000000000188, 17.999999999999982, 20.200000000000006, 30.100000000000144, 30.60000000000016, 31.80000000000018, 27.0000000000001, 10.300000000000066, 23.50000000000003, 36.60000000000025, -22.19999999999952, 14.700000000000001, 37.20000000000026, 25.700000000000067, 31.200000000000163, 12.500000000000059, 15.800000000000004, 23.200000000000024, 36.70000000000025, 31.700000000000177, 48.80000000000045, 31.600000000000172, 27.900000000000105, 38.300000000000274, 30.10000000000015, -173.40000000000074, 0.7000000000001183, 44.50000000000037, 15.400000000000006, 38.50000000000028, 44.30000000000036, 29.000000000000128, 28.900000000000126, 21.299999999999997, 27.5000000000001, 34.50000000000022, 30.000000000000146, 39.20000000000029, 25.700000000000067, 38.90000000000028, 36.70000000000025, 9.200000000000081, 27.90000000000011, 31.200000000000166, 20.199999999999978, -198.7000000000008, 32.50000000000019, 21.3, 37.80000000000027, 36.70000000000025, 41.40000000000032, 34.30000000000022, 48.50000000000045, 37.30000000000026, 30.900000000000162, 27.90000000000011, 21.299999999999994, 35.600000000000236, 27.600000000000225, 31.600000000000186, 43.70000000000035, -484.6999999999997, -9.69999999999964, 8.100000000000113, 17.999999999999982, 51.70000000000049, 5.20000000000017, 31.50000000000018, 28.000000000000107, 34.40000000000022, 30.100000000000147, -6.499999999999659, 38.60000000000028, 36.300000000000246, 24.200000000000085, 27.900000000000105, 30.800000000000157, 38.80000000000028, 34.00000000000021, 4.79999999999998, 13.60000000000004, 39.20000000000029, 18.599999999999984, 15.799999999999997, -5.200000000000035, 18.49999999999997, 23.500000000000053, 33.40000000000019, 37.80000000000027], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [9.499999999999964, 5.299999999999965, 11.599999999999964, 11.599999999999964, 17.899999999999988, -13.599999999999783, 1.0999999999999865, 7.399999999999965, -7.299999999999891, 20.000000000000014, -9.399999999999855, -7.299999999999891, 20.900000000000027, 20.000000000000014, -5.1999999999999265, 20.000000000000014, 22.40000000000005, -9.399999999999855, 9.499999999999964, 20.000000000000014, 25.100000000000094, 0.7999999999999865, 3.1999999999999615, -28.299999999999756, 15.799999999999963, -17.79999999999974, 1.0999999999999865, 1.0999999999999865, 15.799999999999963, 5.299999999999965, 25.400000000000098, -17.79999999999974, -5.1999999999999265, 20.000000000000014, -17.79999999999974, 15.799999999999962, 20.000000000000014, -36.699999999999754, 15.799999999999963, -7.299999999999891, 5.599999999999968, 20.000000000000014, -2.4999999999999716, -78.70000000000087, -5.199999999999941, -3.099999999999958, 3.1999999999999615, 20.000000000000014, 7.399999999999965, 5.299999999999965, 7.399999999999965, 15.799999999999963, 3.1999999999999615, -15.699999999999747, -7.299999999999891, 1.0999999999999865, -5.1999999999999265, 7.399999999999965, 20.000000000000014, -7.299999999999891, 20.000000000000014, -7.299999999999891, -23.49999999999975, 35.30000000000026, -3.099999999999958, 13.699999999999964, 13.699999999999964, 3.1999999999999615, 5.299999999999965, 20.000000000000014, 20.000000000000014, -19.899999999999743, -378.9999999999998, 11.599999999999964, 3.1999999999999615, -32.49999999999975, 28.100000000000147, 7.399999999999965, -19.899999999999743, 5.299999999999965, 11.599999999999964, 17.899999999999988, 17.899999999999988, 25.400000000000098, 20.000000000000014, -0.9999999999999846, -3.099999999999958, 20.000000000000014, -9.399999999999855, 13.699999999999964, -1.2999999999999994, 15.799999999999963, 9.499999999999964, 20.000000000000014, -0.9999999999999846, 20.000000000000014, 3.1999999999999615, 20.000000000000014, 7.399999999999965, 5.299999999999965, 20.000000000000014, 17.899999999999988, 13.699999999999964, 20.000000000000014, -30.39999999999975, 11.599999999999964, 17.899999999999988, -0.9999999999999881, 11.599999999999964, 11.599999999999964, -13.59999999999979, -5.1999999999999265, -15.699999999999747, -400.0, -5.199999999999934, 13.699999999999964, 5.299999999999965, -0.9999999999999846, -5.1999999999999265, 20.000000000000014, 13.699999999999964, 20.000000000000014, 15.799999999999963, 23.600000000000065, 13.69999999999997, 11.599999999999973, 11.599999999999964, 29.900000000000183, 20.000000000000014, 5.299999999999965, 20.000000000000014, -3.099999999999958, 20.000000000000014, -3.099999999999958, -11.499999999999819, 15.799999999999963, 20.000000000000014, 11.599999999999964, -9.400000000000045, 20.000000000000014, 20.000000000000014, -9.399999999999855, 26.300000000000114, 7.399999999999965, -311.80000000000007, -376.89999999999986, -78.70000000000087, 20.000000000000014, -13.59999999999979, -7.299999999999905, 15.799999999999963, -17.79999999999974, 39.80000000000025, -6.0999999999999375, -2.4999999999999716, -28.29999999999975, 17.899999999999984, -9.399999999999855, 13.699999999999964, 5.299999999999965, 9.499999999999964, 17.899999999999988, 1.0999999999999865, 20.000000000000014, -15.699999999999747, -17.79999999999974, 20.000000000000014, 11.599999999999964, 20.000000000000014, 5.299999999999965, 20.000000000000014, -17.79999999999975, 5.299999999999965, 11.599999999999964, 1.0999999999999865, 13.699999999999964, 15.799999999999963, 20.000000000000014, 15.799999999999963, 3.1999999999999615, 7.399999999999965, -34.59999999999975, -13.599999999999783, 3.1999999999999615, 9.199999999999966, 20.000000000000014, -17.79999999999974, 7.399999999999965, -13.599999999999783, 7.399999999999965, 32.60000000000023, -122.8000000000007, -5.200000000000012, -7.299999999999958, 20.000000000000014, -11.49999999999989, 3.199999999999974, 18.19999999999999, 20.000000000000014, 15.799999999999963], "policy_predator_policy_reward": [5.0, 7.0, 3.0, 4.0, 1.0, 16.0, 9.0, 9.0, 4.0, 13.0, 9.0, 14.0, 3.0, 2.0, 11.0, 11.0, 12.0, 10.0, 5.0, 0.0, 10.0, 10.0, 21.0, 8.0, 2.0, 18.0, 9.0, 9.0, 2.0, 7.0, 5.0, 18.0, 12.0, 5.0, 11.0, 18.0, 27.0, 0.0, 10.0, 5.0, 9.0, 2.0, 12.0, 47.0, 3.0, 20.0, 6.0, 8.0, 10.0, 3.0, 6.0, 2.0, 8.0, 17.0, 13.0, 9.0, 12.0, 9.0, 11.0, 13.0, 8.0, 11.0, 22.0, 15.0, 11.0, 10.0, 8.0, 3.0, 6.0, 7.0, 19.0, 11.0, 4.0, 190.0, 25.0, 5.0, 3.0, 6.0, 14.0, 16.0, 5.0, 4.0, 0.0, 1.0, 10.0, 0.0, 11.0, 1.0, 3.0, 14.0, 2.0, 11.0, 0.0, 5.0, 10.0, 1.0, 8.0, 8.0, 6.0, 7.0, 0.0, 1.0, 3.0, 0.0, 4.0, 24.0, 1.0, 10.0, 4.0, 4.0, 22.0, 17.0, 17.0, 200.0, 14.0, 10.0, 7.0, 10.0, 12.0, 11.0, 0.0, 3.0, 0.0, 2.0, 3.0, 6.0, 4.0, 3.0, 5.0, 7.0, 3.0, 11.0, 11.0, 0.0, 5.0, 12.0, 0.0, 4.0, 3.0, 14.0, 13.0, 8.0, 4.0, 6.0, 199.0, 5.0, 47.0, 2.0, 13.0, 16.0, 2.0, 18.0, 17.0, 1.0, 24.0, 12.0, 12.0, 11.0, 2.0, 7.0, 2.0, 5.0, 9.0, 0.0, 7.0, 20.0, 4.0, 3.0, 7.0, 4.0, 10.0, 12.0, 7.0, 4.0, 7.0, 9.0, 1.0, 2.0, 8.0, 7.0, 26.0, 6.0, 11.0, 13.0, 4.0, 6.0, 13.0, 16.0, 16.0, 6.0, 68.0, 17.0, 13.0, 18.0, 0.0, 15.0, 6.0, 6.0, 2.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5874758905665498, "mean_inference_ms": 1.818532264852269, "mean_action_processing_ms": 0.2549653689032868, "mean_env_wait_ms": 0.1970390614691406, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00523984432220459, "StateBufferConnector_ms": 0.004562854766845703, "ViewRequirementAgentConnector_ms": 0.09207665920257568}, "num_episodes": 18, "episode_return_max": 51.70000000000049, "episode_return_min": -484.6999999999997, "episode_return_mean": 17.70700000000015, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2272000, "num_agent_steps_trained": 2272000, "num_env_steps_sampled": 568000, "num_env_steps_trained": 568000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 379.72283961942287, "num_env_steps_trained_throughput_per_sec": 379.72283961942287, "timesteps_total": 568000, "num_env_steps_sampled_lifetime": 568000, "num_agent_steps_sampled_lifetime": 2272000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2272000, "timers": {"training_iteration_time_ms": 10742.788, "restore_workers_time_ms": 0.015, "training_step_time_ms": 10742.736, "sample_time_ms": 1282.672, "learn_time_ms": 9444.18, "learn_throughput": 423.541, "synch_weights_time_ms": 14.31}, "counters": {"num_env_steps_sampled": 568000, "num_env_steps_trained": 568000, "num_agent_steps_sampled": 2272000, "num_agent_steps_trained": 2272000}, "done": false, "training_iteration": 142, "trial_id": "3dae5_00000", "date": "2024-08-14_09-32-59", "timestamp": 1723642379, "time_this_iter_s": 10.539038896560669, "time_total_s": 3196.992747068405, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b36d6ca0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3196.992747068405, "iterations_since_restore": 142, "perf": {"cpu_util_percent": 28.626666666666658, "ram_util_percent": 83.21333333333334}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.370940126060809, "cur_kl_coeff": 2.3174285888671882e-05, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.974026525525189, "policy_loss": -0.008717019142454895, "vf_loss": 1.982743281409854, "vf_explained_var": 0.20147535810394893, "kl": 0.011715977803560648, "entropy": 0.6832299735180285, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 269325.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.0523252066481055, "cur_kl_coeff": 0.03164062499999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.9867867622425948, "policy_loss": -0.007841172286373361, "vf_loss": 3.9942861922834285, "vf_explained_var": 0.06499637176120092, "kl": 0.010800620978172078, "entropy": 0.9448917804887055, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 269325.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 572000, "num_env_steps_trained": 572000, "num_agent_steps_sampled": 2288000, "num_agent_steps_trained": 2288000}, "env_runners": {"episode_reward_max": 51.70000000000049, "episode_reward_min": -484.6999999999997, "episode_reward_mean": 12.676000000000148, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 39.80000000000025, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -6.6819999999999675, "predator_policy": 13.02}, "custom_metrics": {}, "hist_stats": {"episode_reward": [14.700000000000001, 37.20000000000026, 25.700000000000067, 31.200000000000163, 12.500000000000059, 15.800000000000004, 23.200000000000024, 36.70000000000025, 31.700000000000177, 48.80000000000045, 31.600000000000172, 27.900000000000105, 38.300000000000274, 30.10000000000015, -173.40000000000074, 0.7000000000001183, 44.50000000000037, 15.400000000000006, 38.50000000000028, 44.30000000000036, 29.000000000000128, 28.900000000000126, 21.299999999999997, 27.5000000000001, 34.50000000000022, 30.000000000000146, 39.20000000000029, 25.700000000000067, 38.90000000000028, 36.70000000000025, 9.200000000000081, 27.90000000000011, 31.200000000000166, 20.199999999999978, -198.7000000000008, 32.50000000000019, 21.3, 37.80000000000027, 36.70000000000025, 41.40000000000032, 34.30000000000022, 48.50000000000045, 37.30000000000026, 30.900000000000162, 27.90000000000011, 21.299999999999994, 35.600000000000236, 27.600000000000225, 31.600000000000186, 43.70000000000035, -484.6999999999997, -9.69999999999964, 8.100000000000113, 17.999999999999982, 51.70000000000049, 5.20000000000017, 31.50000000000018, 28.000000000000107, 34.40000000000022, 30.100000000000147, -6.499999999999659, 38.60000000000028, 36.300000000000246, 24.200000000000085, 27.900000000000105, 30.800000000000157, 38.80000000000028, 34.00000000000021, 4.79999999999998, 13.60000000000004, 39.20000000000029, 18.599999999999984, 15.799999999999997, -5.200000000000035, 18.49999999999997, 23.500000000000053, 33.40000000000019, 37.80000000000027, 5.5000000000000835, 14.099999999999964, 13.80000000000004, 45.00000000000039, 5.899999999999952, 23.500000000000075, -126.10000000000073, -19.29999999999966, -22.299999999999677, 49.500000000000455, 36.40000000000041, 24.600000000000048, -39.29999999999951, 15.399999999999908, 1.6999999999999444, 35.20000000000023, -41.79999999999957, 5.500000000000045, -2.80000000000007, -7.799999999999722, 40.60000000000031, -11.699999999999797], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-5.199999999999941, -3.099999999999958, 3.1999999999999615, 20.000000000000014, 7.399999999999965, 5.299999999999965, 7.399999999999965, 15.799999999999963, 3.1999999999999615, -15.699999999999747, -7.299999999999891, 1.0999999999999865, -5.1999999999999265, 7.399999999999965, 20.000000000000014, -7.299999999999891, 20.000000000000014, -7.299999999999891, -23.49999999999975, 35.30000000000026, -3.099999999999958, 13.699999999999964, 13.699999999999964, 3.1999999999999615, 5.299999999999965, 20.000000000000014, 20.000000000000014, -19.899999999999743, -378.9999999999998, 11.599999999999964, 3.1999999999999615, -32.49999999999975, 28.100000000000147, 7.399999999999965, -19.899999999999743, 5.299999999999965, 11.599999999999964, 17.899999999999988, 17.899999999999988, 25.400000000000098, 20.000000000000014, -0.9999999999999846, -3.099999999999958, 20.000000000000014, -9.399999999999855, 13.699999999999964, -1.2999999999999994, 15.799999999999963, 9.499999999999964, 20.000000000000014, -0.9999999999999846, 20.000000000000014, 3.1999999999999615, 20.000000000000014, 7.399999999999965, 5.299999999999965, 20.000000000000014, 17.899999999999988, 13.699999999999964, 20.000000000000014, -30.39999999999975, 11.599999999999964, 17.899999999999988, -0.9999999999999881, 11.599999999999964, 11.599999999999964, -13.59999999999979, -5.1999999999999265, -15.699999999999747, -400.0, -5.199999999999934, 13.699999999999964, 5.299999999999965, -0.9999999999999846, -5.1999999999999265, 20.000000000000014, 13.699999999999964, 20.000000000000014, 15.799999999999963, 23.600000000000065, 13.69999999999997, 11.599999999999973, 11.599999999999964, 29.900000000000183, 20.000000000000014, 5.299999999999965, 20.000000000000014, -3.099999999999958, 20.000000000000014, -3.099999999999958, -11.499999999999819, 15.799999999999963, 20.000000000000014, 11.599999999999964, -9.400000000000045, 20.000000000000014, 20.000000000000014, -9.399999999999855, 26.300000000000114, 7.399999999999965, -311.80000000000007, -376.89999999999986, -78.70000000000087, 20.000000000000014, -13.59999999999979, -7.299999999999905, 15.799999999999963, -17.79999999999974, 39.80000000000025, -6.0999999999999375, -2.4999999999999716, -28.29999999999975, 17.899999999999984, -9.399999999999855, 13.699999999999964, 5.299999999999965, 9.499999999999964, 17.899999999999988, 1.0999999999999865, 20.000000000000014, -15.699999999999747, -17.79999999999974, 20.000000000000014, 11.599999999999964, 20.000000000000014, 5.299999999999965, 20.000000000000014, -17.79999999999975, 5.299999999999965, 11.599999999999964, 1.0999999999999865, 13.699999999999964, 15.799999999999963, 20.000000000000014, 15.799999999999963, 3.1999999999999615, 7.399999999999965, -34.59999999999975, -13.599999999999783, 3.1999999999999615, 9.199999999999966, 20.000000000000014, -17.79999999999974, 7.399999999999965, -13.599999999999783, 7.399999999999965, 32.60000000000023, -122.8000000000007, -5.200000000000012, -7.299999999999958, 20.000000000000014, -11.49999999999989, 3.199999999999974, 18.19999999999999, 20.000000000000014, 15.799999999999963, -5.19999999999998, -7.29999999999994, 5.300000000000001, -26.199999999999747, 3.1999999999999615, -9.399999999999855, 26.600000000000126, 7.399999999999965, -28.29999999999977, 3.1999999999999615, -7.300000000000052, 15.799999999999963, -288.7000000000003, 11.599999999999964, -17.799999999999937, -53.499999999999766, -34.59999999999975, -15.700000000000001, 11.599999999999964, 29.90000000000018, 9.799999999999962, 11.599999999999946, 1.099999999999983, 9.499999999999964, -36.699999999999754, -34.59999999999976, -26.199999999999747, 11.599999999999964, -9.399999999999975, -19.899999999999828, 15.799999999999963, 13.399999999999965, -32.499999999999815, -49.29999999999976, -11.499999999999925, -1.0000000000000324, -17.4999999999999, -22.299999999999947, -28.29999999999975, -11.499999999999925, 20.000000000000014, 14.599999999999966, 5.299999999999965, -64.00000000000057], "policy_predator_policy_reward": [3.0, 20.0, 6.0, 8.0, 10.0, 3.0, 6.0, 2.0, 8.0, 17.0, 13.0, 9.0, 12.0, 9.0, 11.0, 13.0, 8.0, 11.0, 22.0, 15.0, 11.0, 10.0, 8.0, 3.0, 6.0, 7.0, 19.0, 11.0, 4.0, 190.0, 25.0, 5.0, 3.0, 6.0, 14.0, 16.0, 5.0, 4.0, 0.0, 1.0, 10.0, 0.0, 11.0, 1.0, 3.0, 14.0, 2.0, 11.0, 0.0, 5.0, 10.0, 1.0, 8.0, 8.0, 6.0, 7.0, 0.0, 1.0, 3.0, 0.0, 4.0, 24.0, 1.0, 10.0, 4.0, 4.0, 22.0, 17.0, 17.0, 200.0, 14.0, 10.0, 7.0, 10.0, 12.0, 11.0, 0.0, 3.0, 0.0, 2.0, 3.0, 6.0, 4.0, 3.0, 5.0, 7.0, 3.0, 11.0, 11.0, 0.0, 5.0, 12.0, 0.0, 4.0, 3.0, 14.0, 13.0, 8.0, 4.0, 6.0, 199.0, 5.0, 47.0, 2.0, 13.0, 16.0, 2.0, 18.0, 17.0, 1.0, 24.0, 12.0, 12.0, 11.0, 2.0, 7.0, 2.0, 5.0, 9.0, 0.0, 7.0, 20.0, 4.0, 3.0, 7.0, 4.0, 10.0, 12.0, 7.0, 4.0, 7.0, 9.0, 1.0, 2.0, 8.0, 7.0, 26.0, 6.0, 11.0, 13.0, 4.0, 6.0, 13.0, 16.0, 16.0, 6.0, 68.0, 17.0, 13.0, 18.0, 0.0, 15.0, 6.0, 6.0, 2.0, 0.0, 5.0, 13.0, 20.0, 15.0, 14.0, 6.0, 6.0, 5.0, 13.0, 18.0, 12.0, 3.0, 147.0, 4.0, 31.0, 21.0, 11.0, 17.0, 4.0, 4.0, 4.0, 11.0, 9.0, 5.0, 3.0, 29.0, 22.0, 8.0, 6.0, 25.0, 4.0, 2.0, 13.0, 27.0, 15.0, 3.0, 2.0, 35.0, 14.0, 18.0, 6.0, 0.0, 7.0, 40.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5871745148025767, "mean_inference_ms": 1.8177554067737045, "mean_action_processing_ms": 0.25475013890842063, "mean_env_wait_ms": 0.19688057735060543, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004932284355163574, "StateBufferConnector_ms": 0.004093647003173828, "ViewRequirementAgentConnector_ms": 0.0936880111694336}, "num_episodes": 22, "episode_return_max": 51.70000000000049, "episode_return_min": -484.6999999999997, "episode_return_mean": 12.676000000000148, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2288000, "num_agent_steps_trained": 2288000, "num_env_steps_sampled": 572000, "num_env_steps_trained": 572000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 374.5061329528541, "num_env_steps_trained_throughput_per_sec": 374.5061329528541, "timesteps_total": 572000, "num_env_steps_sampled_lifetime": 572000, "num_agent_steps_sampled_lifetime": 2288000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2288000, "timers": {"training_iteration_time_ms": 10733.208, "restore_workers_time_ms": 0.014, "training_step_time_ms": 10733.156, "sample_time_ms": 1265.996, "learn_time_ms": 9451.531, "learn_throughput": 423.212, "synch_weights_time_ms": 14.051}, "counters": {"num_env_steps_sampled": 572000, "num_env_steps_trained": 572000, "num_agent_steps_sampled": 2288000, "num_agent_steps_trained": 2288000}, "done": false, "training_iteration": 143, "trial_id": "3dae5_00000", "date": "2024-08-14_09-33-10", "timestamp": 1723642390, "time_this_iter_s": 10.68644404411316, "time_total_s": 3207.6791911125183, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b39818b0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3207.6791911125183, "iterations_since_restore": 143, "perf": {"cpu_util_percent": 28.220000000000002, "ram_util_percent": 82.93333333333334}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.51997220194529, "cur_kl_coeff": 2.3174285888671882e-05, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.307962037268139, "policy_loss": -0.013048663585466486, "vf_loss": 2.3210104496390733, "vf_explained_var": 0.323624408182013, "kl": 0.011445761287834278, "entropy": 0.53921876447226, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 271215.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.051578493282277, "cur_kl_coeff": 0.03164062499999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.527318604787191, "policy_loss": -0.0036025206881166293, "vf_loss": 4.530527528505477, "vf_explained_var": 0.16613596658858043, "kl": 0.012439712287636977, "entropy": 0.9125484556117386, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 271215.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 576000, "num_env_steps_trained": 576000, "num_agent_steps_sampled": 2304000, "num_agent_steps_trained": 2304000}, "env_runners": {"episode_reward_max": 51.70000000000049, "episode_reward_min": -484.6999999999997, "episode_reward_mean": 10.720000000000159, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 40.40000000000023, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -7.5849999999999556, "predator_policy": 12.945}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.50000000000028, 44.30000000000036, 29.000000000000128, 28.900000000000126, 21.299999999999997, 27.5000000000001, 34.50000000000022, 30.000000000000146, 39.20000000000029, 25.700000000000067, 38.90000000000028, 36.70000000000025, 9.200000000000081, 27.90000000000011, 31.200000000000166, 20.199999999999978, -198.7000000000008, 32.50000000000019, 21.3, 37.80000000000027, 36.70000000000025, 41.40000000000032, 34.30000000000022, 48.50000000000045, 37.30000000000026, 30.900000000000162, 27.90000000000011, 21.299999999999994, 35.600000000000236, 27.600000000000225, 31.600000000000186, 43.70000000000035, -484.6999999999997, -9.69999999999964, 8.100000000000113, 17.999999999999982, 51.70000000000049, 5.20000000000017, 31.50000000000018, 28.000000000000107, 34.40000000000022, 30.100000000000147, -6.499999999999659, 38.60000000000028, 36.300000000000246, 24.200000000000085, 27.900000000000105, 30.800000000000157, 38.80000000000028, 34.00000000000021, 4.79999999999998, 13.60000000000004, 39.20000000000029, 18.599999999999984, 15.799999999999997, -5.200000000000035, 18.49999999999997, 23.500000000000053, 33.40000000000019, 37.80000000000027, 5.5000000000000835, 14.099999999999964, 13.80000000000004, 45.00000000000039, 5.899999999999952, 23.500000000000075, -126.10000000000073, -19.29999999999966, -22.299999999999677, 49.500000000000455, 36.40000000000041, 24.600000000000048, -39.29999999999951, 15.399999999999908, 1.6999999999999444, 35.20000000000023, -41.79999999999957, 5.500000000000045, -2.80000000000007, -7.799999999999722, 40.60000000000031, -11.699999999999797, 0.799999999999919, 36.10000000000047, -0.8999999999999704, 28.100000000000122, -77.90000000000063, 19.09999999999999, 50.30000000000047, 37.50000000000037, 8.099999999999959, 48.20000000000048, 22.00000000000018, -43.79999999999953, -11.899999999999611, 42.30000000000033, -23.19999999999998, -19.199999999999704, -6.899999999999682, -11.699999999999768], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [11.599999999999964, 17.899999999999988, 17.899999999999988, 25.400000000000098, 20.000000000000014, -0.9999999999999846, -3.099999999999958, 20.000000000000014, -9.399999999999855, 13.699999999999964, -1.2999999999999994, 15.799999999999963, 9.499999999999964, 20.000000000000014, -0.9999999999999846, 20.000000000000014, 3.1999999999999615, 20.000000000000014, 7.399999999999965, 5.299999999999965, 20.000000000000014, 17.899999999999988, 13.699999999999964, 20.000000000000014, -30.39999999999975, 11.599999999999964, 17.899999999999988, -0.9999999999999881, 11.599999999999964, 11.599999999999964, -13.59999999999979, -5.1999999999999265, -15.699999999999747, -400.0, -5.199999999999934, 13.699999999999964, 5.299999999999965, -0.9999999999999846, -5.1999999999999265, 20.000000000000014, 13.699999999999964, 20.000000000000014, 15.799999999999963, 23.600000000000065, 13.69999999999997, 11.599999999999973, 11.599999999999964, 29.900000000000183, 20.000000000000014, 5.299999999999965, 20.000000000000014, -3.099999999999958, 20.000000000000014, -3.099999999999958, -11.499999999999819, 15.799999999999963, 20.000000000000014, 11.599999999999964, -9.400000000000045, 20.000000000000014, 20.000000000000014, -9.399999999999855, 26.300000000000114, 7.399999999999965, -311.80000000000007, -376.89999999999986, -78.70000000000087, 20.000000000000014, -13.59999999999979, -7.299999999999905, 15.799999999999963, -17.79999999999974, 39.80000000000025, -6.0999999999999375, -2.4999999999999716, -28.29999999999975, 17.899999999999984, -9.399999999999855, 13.699999999999964, 5.299999999999965, 9.499999999999964, 17.899999999999988, 1.0999999999999865, 20.000000000000014, -15.699999999999747, -17.79999999999974, 20.000000000000014, 11.599999999999964, 20.000000000000014, 5.299999999999965, 20.000000000000014, -17.79999999999975, 5.299999999999965, 11.599999999999964, 1.0999999999999865, 13.699999999999964, 15.799999999999963, 20.000000000000014, 15.799999999999963, 3.1999999999999615, 7.399999999999965, -34.59999999999975, -13.599999999999783, 3.1999999999999615, 9.199999999999966, 20.000000000000014, -17.79999999999974, 7.399999999999965, -13.599999999999783, 7.399999999999965, 32.60000000000023, -122.8000000000007, -5.200000000000012, -7.299999999999958, 20.000000000000014, -11.49999999999989, 3.199999999999974, 18.19999999999999, 20.000000000000014, 15.799999999999963, -5.19999999999998, -7.29999999999994, 5.300000000000001, -26.199999999999747, 3.1999999999999615, -9.399999999999855, 26.600000000000126, 7.399999999999965, -28.29999999999977, 3.1999999999999615, -7.300000000000052, 15.799999999999963, -288.7000000000003, 11.599999999999964, -17.799999999999937, -53.499999999999766, -34.59999999999975, -15.700000000000001, 11.599999999999964, 29.90000000000018, 9.799999999999962, 11.599999999999946, 1.099999999999983, 9.499999999999964, -36.699999999999754, -34.59999999999976, -26.199999999999747, 11.599999999999964, -9.399999999999975, -19.899999999999828, 15.799999999999963, 13.399999999999965, -32.499999999999815, -49.29999999999976, -11.499999999999925, -1.0000000000000324, -17.4999999999999, -22.299999999999947, -28.29999999999975, -11.499999999999925, 20.000000000000014, 14.599999999999966, 5.299999999999965, -64.00000000000057, -19.899999999999814, -7.300000000000049, 3.2000000000001583, 17.899999999999988, -19.89999999999983, -1.0000000000000435, 20.000000000000014, -19.899999999999743, -70.3000000000001, -76.60000000000024, -40.89999999999978, 20.000000000000014, 5.299999999999965, 38.000000000000256, 30.800000000000196, -7.3000000000000576, 5.2999999999999785, -26.199999999999747, -26.199999999999747, 40.40000000000023, 20.90000000000003, -40.89999999999976, -45.09999999999976, -51.69999999999977, -24.099999999999746, -17.79999999999977, 23.60000000000007, 13.699999999999964, -26.199999999999946, -21.999999999999964, -17.79999999999989, -30.399999999999764, -21.999999999999744, -19.89999999999977, -5.2000000000000455, -32.49999999999975], "policy_predator_policy_reward": [5.0, 4.0, 0.0, 1.0, 10.0, 0.0, 11.0, 1.0, 3.0, 14.0, 2.0, 11.0, 0.0, 5.0, 10.0, 1.0, 8.0, 8.0, 6.0, 7.0, 0.0, 1.0, 3.0, 0.0, 4.0, 24.0, 1.0, 10.0, 4.0, 4.0, 22.0, 17.0, 17.0, 200.0, 14.0, 10.0, 7.0, 10.0, 12.0, 11.0, 0.0, 3.0, 0.0, 2.0, 3.0, 6.0, 4.0, 3.0, 5.0, 7.0, 3.0, 11.0, 11.0, 0.0, 5.0, 12.0, 0.0, 4.0, 3.0, 14.0, 13.0, 8.0, 4.0, 6.0, 199.0, 5.0, 47.0, 2.0, 13.0, 16.0, 2.0, 18.0, 17.0, 1.0, 24.0, 12.0, 12.0, 11.0, 2.0, 7.0, 2.0, 5.0, 9.0, 0.0, 7.0, 20.0, 4.0, 3.0, 7.0, 4.0, 10.0, 12.0, 7.0, 4.0, 7.0, 9.0, 1.0, 2.0, 8.0, 7.0, 26.0, 6.0, 11.0, 13.0, 4.0, 6.0, 13.0, 16.0, 16.0, 6.0, 68.0, 17.0, 13.0, 18.0, 0.0, 15.0, 6.0, 6.0, 2.0, 0.0, 5.0, 13.0, 20.0, 15.0, 14.0, 6.0, 6.0, 5.0, 13.0, 18.0, 12.0, 3.0, 147.0, 4.0, 31.0, 21.0, 11.0, 17.0, 4.0, 4.0, 4.0, 11.0, 9.0, 5.0, 3.0, 29.0, 22.0, 8.0, 6.0, 25.0, 4.0, 2.0, 13.0, 27.0, 15.0, 3.0, 2.0, 35.0, 14.0, 18.0, 6.0, 0.0, 7.0, 40.0, 11.0, 17.0, 5.0, 10.0, 1.0, 19.0, 17.0, 11.0, 55.0, 14.0, 27.0, 13.0, 7.0, 0.0, 13.0, 1.0, 5.0, 24.0, 12.0, 22.0, 27.0, 15.0, 33.0, 20.0, 19.0, 11.0, 3.0, 2.0, 11.0, 14.0, 3.0, 26.0, 28.0, 7.0, 2.0, 24.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5869251342916451, "mean_inference_ms": 1.8171421165538597, "mean_action_processing_ms": 0.254558103075292, "mean_env_wait_ms": 0.19673654443888108, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0042858123779296875, "StateBufferConnector_ms": 0.0031881332397460938, "ViewRequirementAgentConnector_ms": 0.09176373481750488}, "num_episodes": 18, "episode_return_max": 51.70000000000049, "episode_return_min": -484.6999999999997, "episode_return_mean": 10.720000000000159, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2304000, "num_agent_steps_trained": 2304000, "num_env_steps_sampled": 576000, "num_env_steps_trained": 576000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 371.0532146977999, "num_env_steps_trained_throughput_per_sec": 371.0532146977999, "timesteps_total": 576000, "num_env_steps_sampled_lifetime": 576000, "num_agent_steps_sampled_lifetime": 2304000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2304000, "timers": {"training_iteration_time_ms": 10714.02, "restore_workers_time_ms": 0.014, "training_step_time_ms": 10713.973, "sample_time_ms": 1271.952, "learn_time_ms": 9426.264, "learn_throughput": 424.346, "synch_weights_time_ms": 14.355}, "counters": {"num_env_steps_sampled": 576000, "num_env_steps_trained": 576000, "num_agent_steps_sampled": 2304000, "num_agent_steps_trained": 2304000}, "done": false, "training_iteration": 144, "trial_id": "3dae5_00000", "date": "2024-08-14_09-33-21", "timestamp": 1723642401, "time_this_iter_s": 10.785337924957275, "time_total_s": 3218.4645290374756, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3986700>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3218.4645290374756, "iterations_since_restore": 144, "perf": {"cpu_util_percent": 28.553333333333335, "ram_util_percent": 82.92666666666666}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.855172404788789, "cur_kl_coeff": 2.3174285888671882e-05, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.5088869564116947, "policy_loss": -0.008289436905561064, "vf_loss": 3.5171761734775764, "vf_explained_var": 0.30253121673114713, "kl": 0.009272117657969084, "entropy": 0.5157164875792448, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 273105.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.342755411163209, "cur_kl_coeff": 0.03164062499999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.454853122070353, "policy_loss": -0.005332695482983673, "vf_loss": 5.459702944881702, "vf_explained_var": 0.18990458127052065, "kl": 0.015261657761955252, "entropy": 0.8269315867512315, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 273105.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 580000, "num_env_steps_trained": 580000, "num_agent_steps_sampled": 2320000, "num_agent_steps_trained": 2320000}, "env_runners": {"episode_reward_max": 51.70000000000049, "episode_reward_min": -484.6999999999997, "episode_reward_mean": 2.3850000000001423, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -376.89999999999986, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 40.40000000000023, "predator_policy": 199.0}, "policy_reward_mean": {"prey_policy": -13.42749999999995, "predator_policy": 14.62}, "custom_metrics": {}, "hist_stats": {"episode_reward": [21.3, 37.80000000000027, 36.70000000000025, 41.40000000000032, 34.30000000000022, 48.50000000000045, 37.30000000000026, 30.900000000000162, 27.90000000000011, 21.299999999999994, 35.600000000000236, 27.600000000000225, 31.600000000000186, 43.70000000000035, -484.6999999999997, -9.69999999999964, 8.100000000000113, 17.999999999999982, 51.70000000000049, 5.20000000000017, 31.50000000000018, 28.000000000000107, 34.40000000000022, 30.100000000000147, -6.499999999999659, 38.60000000000028, 36.300000000000246, 24.200000000000085, 27.900000000000105, 30.800000000000157, 38.80000000000028, 34.00000000000021, 4.79999999999998, 13.60000000000004, 39.20000000000029, 18.599999999999984, 15.799999999999997, -5.200000000000035, 18.49999999999997, 23.500000000000053, 33.40000000000019, 37.80000000000027, 5.5000000000000835, 14.099999999999964, 13.80000000000004, 45.00000000000039, 5.899999999999952, 23.500000000000075, -126.10000000000073, -19.29999999999966, -22.299999999999677, 49.500000000000455, 36.40000000000041, 24.600000000000048, -39.29999999999951, 15.399999999999908, 1.6999999999999444, 35.20000000000023, -41.79999999999957, 5.500000000000045, -2.80000000000007, -7.799999999999722, 40.60000000000031, -11.699999999999797, 0.799999999999919, 36.10000000000047, -0.8999999999999704, 28.100000000000122, -77.90000000000063, 19.09999999999999, 50.30000000000047, 37.50000000000037, 8.099999999999959, 48.20000000000048, 22.00000000000018, -43.79999999999953, -11.899999999999611, 42.30000000000033, -23.19999999999998, -19.199999999999704, -6.899999999999682, -11.699999999999768, -8.100000000000074, -12.800000000000123, -29.899999999999636, -0.7000000000000969, -48.799999999999734, -41.69999999999951, -102.8000000000008, 3.9999999999999765, 10.299999999999937, 12.800000000000054, -36.499999999999545, -3.099999999999987, 21.70000000000002, -126.90000000000106, 0.39999999999991875, -56.69999999999964, 8.799999999999963, -106.69999999999956], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [5.299999999999965, -0.9999999999999846, -5.1999999999999265, 20.000000000000014, 13.699999999999964, 20.000000000000014, 15.799999999999963, 23.600000000000065, 13.69999999999997, 11.599999999999973, 11.599999999999964, 29.900000000000183, 20.000000000000014, 5.299999999999965, 20.000000000000014, -3.099999999999958, 20.000000000000014, -3.099999999999958, -11.499999999999819, 15.799999999999963, 20.000000000000014, 11.599999999999964, -9.400000000000045, 20.000000000000014, 20.000000000000014, -9.399999999999855, 26.300000000000114, 7.399999999999965, -311.80000000000007, -376.89999999999986, -78.70000000000087, 20.000000000000014, -13.59999999999979, -7.299999999999905, 15.799999999999963, -17.79999999999974, 39.80000000000025, -6.0999999999999375, -2.4999999999999716, -28.29999999999975, 17.899999999999984, -9.399999999999855, 13.699999999999964, 5.299999999999965, 9.499999999999964, 17.899999999999988, 1.0999999999999865, 20.000000000000014, -15.699999999999747, -17.79999999999974, 20.000000000000014, 11.599999999999964, 20.000000000000014, 5.299999999999965, 20.000000000000014, -17.79999999999975, 5.299999999999965, 11.599999999999964, 1.0999999999999865, 13.699999999999964, 15.799999999999963, 20.000000000000014, 15.799999999999963, 3.1999999999999615, 7.399999999999965, -34.59999999999975, -13.599999999999783, 3.1999999999999615, 9.199999999999966, 20.000000000000014, -17.79999999999974, 7.399999999999965, -13.599999999999783, 7.399999999999965, 32.60000000000023, -122.8000000000007, -5.200000000000012, -7.299999999999958, 20.000000000000014, -11.49999999999989, 3.199999999999974, 18.19999999999999, 20.000000000000014, 15.799999999999963, -5.19999999999998, -7.29999999999994, 5.300000000000001, -26.199999999999747, 3.1999999999999615, -9.399999999999855, 26.600000000000126, 7.399999999999965, -28.29999999999977, 3.1999999999999615, -7.300000000000052, 15.799999999999963, -288.7000000000003, 11.599999999999964, -17.799999999999937, -53.499999999999766, -34.59999999999975, -15.700000000000001, 11.599999999999964, 29.90000000000018, 9.799999999999962, 11.599999999999946, 1.099999999999983, 9.499999999999964, -36.699999999999754, -34.59999999999976, -26.199999999999747, 11.599999999999964, -9.399999999999975, -19.899999999999828, 15.799999999999963, 13.399999999999965, -32.499999999999815, -49.29999999999976, -11.499999999999925, -1.0000000000000324, -17.4999999999999, -22.299999999999947, -28.29999999999975, -11.499999999999925, 20.000000000000014, 14.599999999999966, 5.299999999999965, -64.00000000000057, -19.899999999999814, -7.300000000000049, 3.2000000000001583, 17.899999999999988, -19.89999999999983, -1.0000000000000435, 20.000000000000014, -19.899999999999743, -70.3000000000001, -76.60000000000024, -40.89999999999978, 20.000000000000014, 5.299999999999965, 38.000000000000256, 30.800000000000196, -7.3000000000000576, 5.2999999999999785, -26.199999999999747, -26.199999999999747, 40.40000000000023, 20.90000000000003, -40.89999999999976, -45.09999999999976, -51.69999999999977, -24.099999999999746, -17.79999999999977, 23.60000000000007, 13.699999999999964, -26.199999999999946, -21.999999999999964, -17.79999999999989, -30.399999999999764, -21.999999999999744, -19.89999999999977, -5.2000000000000455, -32.49999999999975, -11.800000000000022, -28.299999999999905, 7.399999999999965, -68.19999999999996, -46.29999999999976, -34.59999999999982, -0.9999999999999846, -36.69999999999981, -57.69999999999977, -45.09999999999986, -28.29999999999985, -51.399999999999764, -80.80000000000024, -85.00000000000026, 20.000000000000014, -63.99999999999985, 20.000000000000014, -36.69999999999993, -15.699999999999747, 9.499999999999964, -21.99999999999984, -53.499999999999766, 17.899999999999988, -60.99999999999986, -28.29999999999975, 20.000000000000014, -103.90000000000049, -97.00000000000037, -45.09999999999977, 9.499999999999964, -40.8999999999999, -59.79999999999977, -21.999999999999744, -5.2000000000000455, -84.99999999999979, -78.69999999999979], "policy_predator_policy_reward": [7.0, 10.0, 12.0, 11.0, 0.0, 3.0, 0.0, 2.0, 3.0, 6.0, 4.0, 3.0, 5.0, 7.0, 3.0, 11.0, 11.0, 0.0, 5.0, 12.0, 0.0, 4.0, 3.0, 14.0, 13.0, 8.0, 4.0, 6.0, 199.0, 5.0, 47.0, 2.0, 13.0, 16.0, 2.0, 18.0, 17.0, 1.0, 24.0, 12.0, 12.0, 11.0, 2.0, 7.0, 2.0, 5.0, 9.0, 0.0, 7.0, 20.0, 4.0, 3.0, 7.0, 4.0, 10.0, 12.0, 7.0, 4.0, 7.0, 9.0, 1.0, 2.0, 8.0, 7.0, 26.0, 6.0, 11.0, 13.0, 4.0, 6.0, 13.0, 16.0, 16.0, 6.0, 68.0, 17.0, 13.0, 18.0, 0.0, 15.0, 6.0, 6.0, 2.0, 0.0, 5.0, 13.0, 20.0, 15.0, 14.0, 6.0, 6.0, 5.0, 13.0, 18.0, 12.0, 3.0, 147.0, 4.0, 31.0, 21.0, 11.0, 17.0, 4.0, 4.0, 4.0, 11.0, 9.0, 5.0, 3.0, 29.0, 22.0, 8.0, 6.0, 25.0, 4.0, 2.0, 13.0, 27.0, 15.0, 3.0, 2.0, 35.0, 14.0, 18.0, 6.0, 0.0, 7.0, 40.0, 11.0, 17.0, 5.0, 10.0, 1.0, 19.0, 17.0, 11.0, 55.0, 14.0, 27.0, 13.0, 7.0, 0.0, 13.0, 1.0, 5.0, 24.0, 12.0, 22.0, 27.0, 15.0, 33.0, 20.0, 19.0, 11.0, 3.0, 2.0, 11.0, 14.0, 3.0, 26.0, 28.0, 7.0, 2.0, 24.0, 8.0, 24.0, 7.0, 41.0, 30.0, 21.0, 27.0, 10.0, 33.0, 21.0, 21.0, 17.0, 36.0, 27.0, 21.0, 27.0, 10.0, 17.0, 3.0, 16.0, 19.0, 20.0, 26.0, 14.0, 9.0, 21.0, 31.0, 43.0, 26.0, 10.0, 29.0, 15.0, 12.0, 24.0, 24.0, 33.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5866459569436588, "mean_inference_ms": 1.8164295571217837, "mean_action_processing_ms": 0.2543716695803805, "mean_env_wait_ms": 0.19657733986255604, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003676176071166992, "StateBufferConnector_ms": 0.0029860734939575195, "ViewRequirementAgentConnector_ms": 0.0926433801651001}, "num_episodes": 18, "episode_return_max": 51.70000000000049, "episode_return_min": -484.6999999999997, "episode_return_mean": 2.3850000000001423, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2320000, "num_agent_steps_trained": 2320000, "num_env_steps_sampled": 580000, "num_env_steps_trained": 580000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 354.27735139774734, "num_env_steps_trained_throughput_per_sec": 354.27735139774734, "timesteps_total": 580000, "num_env_steps_sampled_lifetime": 580000, "num_agent_steps_sampled_lifetime": 2320000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2320000, "timers": {"training_iteration_time_ms": 10772.209, "restore_workers_time_ms": 0.013, "training_step_time_ms": 10772.149, "sample_time_ms": 1267.681, "learn_time_ms": 9487.288, "learn_throughput": 421.617, "synch_weights_time_ms": 15.134}, "counters": {"num_env_steps_sampled": 580000, "num_env_steps_trained": 580000, "num_agent_steps_sampled": 2320000, "num_agent_steps_trained": 2320000}, "done": false, "training_iteration": 145, "trial_id": "3dae5_00000", "date": "2024-08-14_09-33-32", "timestamp": 1723642412, "time_this_iter_s": 11.340392827987671, "time_total_s": 3229.8049218654633, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3986a60>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3229.8049218654633, "iterations_since_restore": 145, "perf": {"cpu_util_percent": 30.78125, "ram_util_percent": 83.08125}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.681254888211608, "cur_kl_coeff": 2.3174285888671882e-05, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.769007379541952, "policy_loss": -0.009878186364140775, "vf_loss": 4.778884555423071, "vf_explained_var": 0.2511694766541637, "kl": 0.043090498703521204, "entropy": 0.612116276918265, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 274995.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.312935915762785, "cur_kl_coeff": 0.03164062499999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.0671617583623005, "policy_loss": -0.005599936370851186, "vf_loss": 6.072518026261102, "vf_explained_var": 0.19882539939628077, "kl": 0.007701312010538508, "entropy": 0.7830405486639215, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 274995.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 584000, "num_env_steps_trained": 584000, "num_agent_steps_sampled": 2336000, "num_agent_steps_trained": 2336000}, "env_runners": {"episode_reward_max": 50.30000000000047, "episode_reward_min": -139.50000000000122, "episode_reward_mean": -6.992999999999901, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -288.7000000000003, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 40.40000000000023, "predator_policy": 147.0}, "policy_reward_mean": {"prey_policy": -22.256499999999974, "predator_policy": 18.76}, "custom_metrics": {}, "hist_stats": {"episode_reward": [30.100000000000147, -6.499999999999659, 38.60000000000028, 36.300000000000246, 24.200000000000085, 27.900000000000105, 30.800000000000157, 38.80000000000028, 34.00000000000021, 4.79999999999998, 13.60000000000004, 39.20000000000029, 18.599999999999984, 15.799999999999997, -5.200000000000035, 18.49999999999997, 23.500000000000053, 33.40000000000019, 37.80000000000027, 5.5000000000000835, 14.099999999999964, 13.80000000000004, 45.00000000000039, 5.899999999999952, 23.500000000000075, -126.10000000000073, -19.29999999999966, -22.299999999999677, 49.500000000000455, 36.40000000000041, 24.600000000000048, -39.29999999999951, 15.399999999999908, 1.6999999999999444, 35.20000000000023, -41.79999999999957, 5.500000000000045, -2.80000000000007, -7.799999999999722, 40.60000000000031, -11.699999999999797, 0.799999999999919, 36.10000000000047, -0.8999999999999704, 28.100000000000122, -77.90000000000063, 19.09999999999999, 50.30000000000047, 37.50000000000037, 8.099999999999959, 48.20000000000048, 22.00000000000018, -43.79999999999953, -11.899999999999611, 42.30000000000033, -23.19999999999998, -19.199999999999704, -6.899999999999682, -11.699999999999768, -8.100000000000074, -12.800000000000123, -29.899999999999636, -0.7000000000000969, -48.799999999999734, -41.69999999999951, -102.8000000000008, 3.9999999999999765, 10.299999999999937, 12.800000000000054, -36.499999999999545, -3.099999999999987, 21.70000000000002, -126.90000000000106, 0.39999999999991875, -56.69999999999964, 8.799999999999963, -106.69999999999956, -70.09999999999978, -11.399999999999642, -37.199999999999626, -4.000000000000062, -57.49999999999962, -139.50000000000122, -14.400000000000059, -12.400000000000084, -33.99999999999957, -23.299999999999763, -4.600000000000049, 44.30000000000037, -39.39999999999961, -31.799999999999528, 38.00000000000027, -15.399999999999789, -76.89999999999978, 48.30000000000044, -32.79999999999985, -117.80000000000119, -73.00000000000028, -34.49999999999963, -80.00000000000115], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [1.0999999999999865, 20.000000000000014, -15.699999999999747, -17.79999999999974, 20.000000000000014, 11.599999999999964, 20.000000000000014, 5.299999999999965, 20.000000000000014, -17.79999999999975, 5.299999999999965, 11.599999999999964, 1.0999999999999865, 13.699999999999964, 15.799999999999963, 20.000000000000014, 15.799999999999963, 3.1999999999999615, 7.399999999999965, -34.59999999999975, -13.599999999999783, 3.1999999999999615, 9.199999999999966, 20.000000000000014, -17.79999999999974, 7.399999999999965, -13.599999999999783, 7.399999999999965, 32.60000000000023, -122.8000000000007, -5.200000000000012, -7.299999999999958, 20.000000000000014, -11.49999999999989, 3.199999999999974, 18.19999999999999, 20.000000000000014, 15.799999999999963, -5.19999999999998, -7.29999999999994, 5.300000000000001, -26.199999999999747, 3.1999999999999615, -9.399999999999855, 26.600000000000126, 7.399999999999965, -28.29999999999977, 3.1999999999999615, -7.300000000000052, 15.799999999999963, -288.7000000000003, 11.599999999999964, -17.799999999999937, -53.499999999999766, -34.59999999999975, -15.700000000000001, 11.599999999999964, 29.90000000000018, 9.799999999999962, 11.599999999999946, 1.099999999999983, 9.499999999999964, -36.699999999999754, -34.59999999999976, -26.199999999999747, 11.599999999999964, -9.399999999999975, -19.899999999999828, 15.799999999999963, 13.399999999999965, -32.499999999999815, -49.29999999999976, -11.499999999999925, -1.0000000000000324, -17.4999999999999, -22.299999999999947, -28.29999999999975, -11.499999999999925, 20.000000000000014, 14.599999999999966, 5.299999999999965, -64.00000000000057, -19.899999999999814, -7.300000000000049, 3.2000000000001583, 17.899999999999988, -19.89999999999983, -1.0000000000000435, 20.000000000000014, -19.899999999999743, -70.3000000000001, -76.60000000000024, -40.89999999999978, 20.000000000000014, 5.299999999999965, 38.000000000000256, 30.800000000000196, -7.3000000000000576, 5.2999999999999785, -26.199999999999747, -26.199999999999747, 40.40000000000023, 20.90000000000003, -40.89999999999976, -45.09999999999976, -51.69999999999977, -24.099999999999746, -17.79999999999977, 23.60000000000007, 13.699999999999964, -26.199999999999946, -21.999999999999964, -17.79999999999989, -30.399999999999764, -21.999999999999744, -19.89999999999977, -5.2000000000000455, -32.49999999999975, -11.800000000000022, -28.299999999999905, 7.399999999999965, -68.19999999999996, -46.29999999999976, -34.59999999999982, -0.9999999999999846, -36.69999999999981, -57.69999999999977, -45.09999999999986, -28.29999999999985, -51.399999999999764, -80.80000000000024, -85.00000000000026, 20.000000000000014, -63.99999999999985, 20.000000000000014, -36.69999999999993, -15.699999999999747, 9.499999999999964, -21.99999999999984, -53.499999999999766, 17.899999999999988, -60.99999999999986, -28.29999999999975, 20.000000000000014, -103.90000000000049, -97.00000000000037, -45.09999999999977, 9.499999999999964, -40.8999999999999, -59.79999999999977, -21.999999999999744, -5.2000000000000455, -84.99999999999979, -78.69999999999979, -72.39999999999993, -57.699999999999775, 5.299999999999965, -78.70000000000049, -51.69999999999979, -53.499999999999766, -87.10000000000029, 16.09999999999996, -66.0999999999998, -42.39999999999982, -103.90000000000045, -118.60000000000056, -11.800000000000043, -58.59999999999983, -80.8000000000001, 7.399999999999965, -36.39999999999978, -34.5999999999998, -130.30000000000058, 20.000000000000014, 11.599999999999964, -68.19999999999993, 25.400000000000098, 17.899999999999988, -124.9000000000005, 9.499999999999964, 3.1999999999999615, -106.00000000000041, -0.9999999999999846, 20.000000000000014, -89.20000000000047, 15.799999999999963, -72.39999999999984, -74.49999999999989, 7.399999999999965, 29.90000000000018, -38.799999999999905, -33.999999999999915, -82.90000000000035, -103.9000000000006, -82.90000000000066, -66.1, 20.000000000000014, -158.50000000000063, -42.999999999999844, -148.00000000000063], "policy_predator_policy_reward": [9.0, 0.0, 7.0, 20.0, 4.0, 3.0, 7.0, 4.0, 10.0, 12.0, 7.0, 4.0, 7.0, 9.0, 1.0, 2.0, 8.0, 7.0, 26.0, 6.0, 11.0, 13.0, 4.0, 6.0, 13.0, 16.0, 16.0, 6.0, 68.0, 17.0, 13.0, 18.0, 0.0, 15.0, 6.0, 6.0, 2.0, 0.0, 5.0, 13.0, 20.0, 15.0, 14.0, 6.0, 6.0, 5.0, 13.0, 18.0, 12.0, 3.0, 147.0, 4.0, 31.0, 21.0, 11.0, 17.0, 4.0, 4.0, 4.0, 11.0, 9.0, 5.0, 3.0, 29.0, 22.0, 8.0, 6.0, 25.0, 4.0, 2.0, 13.0, 27.0, 15.0, 3.0, 2.0, 35.0, 14.0, 18.0, 6.0, 0.0, 7.0, 40.0, 11.0, 17.0, 5.0, 10.0, 1.0, 19.0, 17.0, 11.0, 55.0, 14.0, 27.0, 13.0, 7.0, 0.0, 13.0, 1.0, 5.0, 24.0, 12.0, 22.0, 27.0, 15.0, 33.0, 20.0, 19.0, 11.0, 3.0, 2.0, 11.0, 14.0, 3.0, 26.0, 28.0, 7.0, 2.0, 24.0, 8.0, 24.0, 7.0, 41.0, 30.0, 21.0, 27.0, 10.0, 33.0, 21.0, 21.0, 17.0, 36.0, 27.0, 21.0, 27.0, 10.0, 17.0, 3.0, 16.0, 19.0, 20.0, 26.0, 14.0, 9.0, 21.0, 31.0, 43.0, 26.0, 10.0, 29.0, 15.0, 12.0, 24.0, 24.0, 33.0, 41.0, 19.0, 33.0, 29.0, 41.0, 27.0, 35.0, 32.0, 7.0, 44.0, 35.0, 48.0, 32.0, 24.0, 42.0, 19.0, 12.0, 25.0, 44.0, 43.0, 14.0, 38.0, 0.0, 1.0, 27.0, 49.0, 43.0, 28.0, 10.0, 9.0, 38.0, 20.0, 41.0, 29.0, 6.0, 5.0, 31.0, 9.0, 17.0, 52.0, 44.0, 32.0, 43.0, 61.0, 31.0, 80.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5863533362164508, "mean_inference_ms": 1.815657677700646, "mean_action_processing_ms": 0.25414289700435394, "mean_env_wait_ms": 0.19641785321594504, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0037156343460083008, "StateBufferConnector_ms": 0.0030204057693481445, "ViewRequirementAgentConnector_ms": 0.09474456310272217}, "num_episodes": 23, "episode_return_max": 50.30000000000047, "episode_return_min": -139.50000000000122, "episode_return_mean": -6.992999999999901, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2336000, "num_agent_steps_trained": 2336000, "num_env_steps_sampled": 584000, "num_env_steps_trained": 584000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 349.9198898791652, "num_env_steps_trained_throughput_per_sec": 349.9198898791652, "timesteps_total": 584000, "num_env_steps_sampled_lifetime": 584000, "num_agent_steps_sampled_lifetime": 2336000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2336000, "timers": {"training_iteration_time_ms": 10873.229, "restore_workers_time_ms": 0.014, "training_step_time_ms": 10873.173, "sample_time_ms": 1280.32, "learn_time_ms": 9576.069, "learn_throughput": 417.708, "synch_weights_time_ms": 14.921}, "counters": {"num_env_steps_sampled": 584000, "num_env_steps_trained": 584000, "num_agent_steps_sampled": 2336000, "num_agent_steps_trained": 2336000}, "done": false, "training_iteration": 146, "trial_id": "3dae5_00000", "date": "2024-08-14_09-33-43", "timestamp": 1723642423, "time_this_iter_s": 11.43631625175476, "time_total_s": 3241.241238117218, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3986670>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3241.241238117218, "iterations_since_restore": 146, "perf": {"cpu_util_percent": 32.3, "ram_util_percent": 83.05882352941177}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.103547918418097, "cur_kl_coeff": 3.4761428833007795e-05, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.9680494310994625, "policy_loss": -0.004960318753944227, "vf_loss": 6.973009261126241, "vf_explained_var": 0.0602670774258003, "kl": 0.015314514928459583, "entropy": 0.7875231107391377, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 276885.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.37782379850824, "cur_kl_coeff": 0.03164062499999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.06708950605342, "policy_loss": -0.00547543852072623, "vf_loss": 4.072223890016949, "vf_explained_var": 0.193735973639463, "kl": 0.010779371497350027, "entropy": 0.8993236423484863, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 276885.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 588000, "num_env_steps_trained": 588000, "num_agent_steps_sampled": 2352000, "num_agent_steps_trained": 2352000}, "env_runners": {"episode_reward_max": 50.30000000000047, "episode_reward_min": -196.39999999999992, "episode_reward_mean": -19.81199999999991, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -288.7000000000003, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 40.40000000000023, "predator_policy": 147.0}, "policy_reward_mean": {"prey_policy": -35.206, "predator_policy": 25.3}, "custom_metrics": {}, "hist_stats": {"episode_reward": [45.00000000000039, 5.899999999999952, 23.500000000000075, -126.10000000000073, -19.29999999999966, -22.299999999999677, 49.500000000000455, 36.40000000000041, 24.600000000000048, -39.29999999999951, 15.399999999999908, 1.6999999999999444, 35.20000000000023, -41.79999999999957, 5.500000000000045, -2.80000000000007, -7.799999999999722, 40.60000000000031, -11.699999999999797, 0.799999999999919, 36.10000000000047, -0.8999999999999704, 28.100000000000122, -77.90000000000063, 19.09999999999999, 50.30000000000047, 37.50000000000037, 8.099999999999959, 48.20000000000048, 22.00000000000018, -43.79999999999953, -11.899999999999611, 42.30000000000033, -23.19999999999998, -19.199999999999704, -6.899999999999682, -11.699999999999768, -8.100000000000074, -12.800000000000123, -29.899999999999636, -0.7000000000000969, -48.799999999999734, -41.69999999999951, -102.8000000000008, 3.9999999999999765, 10.299999999999937, 12.800000000000054, -36.499999999999545, -3.099999999999987, 21.70000000000002, -126.90000000000106, 0.39999999999991875, -56.69999999999964, 8.799999999999963, -106.69999999999956, -70.09999999999978, -11.399999999999642, -37.199999999999626, -4.000000000000062, -57.49999999999962, -139.50000000000122, -14.400000000000059, -12.400000000000084, -33.99999999999957, -23.299999999999763, -4.600000000000049, 44.30000000000037, -39.39999999999961, -31.799999999999528, 38.00000000000027, -15.399999999999789, -76.89999999999978, 48.30000000000044, -32.79999999999985, -117.80000000000119, -73.00000000000028, -34.49999999999963, -80.00000000000115, -14.300000000000118, -41.09999999999975, 25.000000000000053, -7.300000000000097, -108.00000000000001, -51.99999999999966, -49.599999999999554, 28.900000000000126, -31.3999999999999, -107.50000000000034, -20.499999999999815, -105.30000000000118, -49.79999999999961, 8.200000000000095, -65.3999999999997, -75.50000000000011, 33.10000000000019, 26.40000000000008, 37.500000000000256, -196.39999999999992, 30.40000000000015, -59.69999999999965], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [26.600000000000126, 7.399999999999965, -28.29999999999977, 3.1999999999999615, -7.300000000000052, 15.799999999999963, -288.7000000000003, 11.599999999999964, -17.799999999999937, -53.499999999999766, -34.59999999999975, -15.700000000000001, 11.599999999999964, 29.90000000000018, 9.799999999999962, 11.599999999999946, 1.099999999999983, 9.499999999999964, -36.699999999999754, -34.59999999999976, -26.199999999999747, 11.599999999999964, -9.399999999999975, -19.899999999999828, 15.799999999999963, 13.399999999999965, -32.499999999999815, -49.29999999999976, -11.499999999999925, -1.0000000000000324, -17.4999999999999, -22.299999999999947, -28.29999999999975, -11.499999999999925, 20.000000000000014, 14.599999999999966, 5.299999999999965, -64.00000000000057, -19.899999999999814, -7.300000000000049, 3.2000000000001583, 17.899999999999988, -19.89999999999983, -1.0000000000000435, 20.000000000000014, -19.899999999999743, -70.3000000000001, -76.60000000000024, -40.89999999999978, 20.000000000000014, 5.299999999999965, 38.000000000000256, 30.800000000000196, -7.3000000000000576, 5.2999999999999785, -26.199999999999747, -26.199999999999747, 40.40000000000023, 20.90000000000003, -40.89999999999976, -45.09999999999976, -51.69999999999977, -24.099999999999746, -17.79999999999977, 23.60000000000007, 13.699999999999964, -26.199999999999946, -21.999999999999964, -17.79999999999989, -30.399999999999764, -21.999999999999744, -19.89999999999977, -5.2000000000000455, -32.49999999999975, -11.800000000000022, -28.299999999999905, 7.399999999999965, -68.19999999999996, -46.29999999999976, -34.59999999999982, -0.9999999999999846, -36.69999999999981, -57.69999999999977, -45.09999999999986, -28.29999999999985, -51.399999999999764, -80.80000000000024, -85.00000000000026, 20.000000000000014, -63.99999999999985, 20.000000000000014, -36.69999999999993, -15.699999999999747, 9.499999999999964, -21.99999999999984, -53.499999999999766, 17.899999999999988, -60.99999999999986, -28.29999999999975, 20.000000000000014, -103.90000000000049, -97.00000000000037, -45.09999999999977, 9.499999999999964, -40.8999999999999, -59.79999999999977, -21.999999999999744, -5.2000000000000455, -84.99999999999979, -78.69999999999979, -72.39999999999993, -57.699999999999775, 5.299999999999965, -78.70000000000049, -51.69999999999979, -53.499999999999766, -87.10000000000029, 16.09999999999996, -66.0999999999998, -42.39999999999982, -103.90000000000045, -118.60000000000056, -11.800000000000043, -58.59999999999983, -80.8000000000001, 7.399999999999965, -36.39999999999978, -34.5999999999998, -130.30000000000058, 20.000000000000014, 11.599999999999964, -68.19999999999993, 25.400000000000098, 17.899999999999988, -124.9000000000005, 9.499999999999964, 3.1999999999999615, -106.00000000000041, -0.9999999999999846, 20.000000000000014, -89.20000000000047, 15.799999999999963, -72.39999999999984, -74.49999999999989, 7.399999999999965, 29.90000000000018, -38.799999999999905, -33.999999999999915, -82.90000000000035, -103.9000000000006, -82.90000000000066, -66.1, 20.000000000000014, -158.50000000000063, -42.999999999999844, -148.00000000000063, 20.90000000000003, -110.20000000000061, -154.30000000000027, 6.1999999999999655, -0.09999999999998116, 7.099999999999966, 17.899999999999988, -68.19999999999999, -38.800000000000026, -194.20000000000033, -211.00000000000037, 20.000000000000014, -143.8000000000005, 3.1999999999999615, 8.599999999999968, 5.299999999999965, -0.9999999999999846, -114.40000000000019, -68.1999999999999, -112.30000000000021, 20.000000000000014, -116.50000000000037, -32.49999999999975, -206.80000000000038, -154.9000000000003, 1.0999999999999865, -9.399999999999926, -9.399999999999855, -0.9999999999999846, -177.4000000000004, -9.399999999999855, -234.10000000000008, 15.799999999999963, 5.299999999999965, 13.699999999999964, -7.299999999999891, 11.599999999999964, 14.899999999999936, -110.20000000000003, -278.2000000000002, 9.499999999999964, 8.899999999999967, 20.000000000000014, -204.70000000000033], "policy_predator_policy_reward": [6.0, 5.0, 13.0, 18.0, 12.0, 3.0, 147.0, 4.0, 31.0, 21.0, 11.0, 17.0, 4.0, 4.0, 4.0, 11.0, 9.0, 5.0, 3.0, 29.0, 22.0, 8.0, 6.0, 25.0, 4.0, 2.0, 13.0, 27.0, 15.0, 3.0, 2.0, 35.0, 14.0, 18.0, 6.0, 0.0, 7.0, 40.0, 11.0, 17.0, 5.0, 10.0, 1.0, 19.0, 17.0, 11.0, 55.0, 14.0, 27.0, 13.0, 7.0, 0.0, 13.0, 1.0, 5.0, 24.0, 12.0, 22.0, 27.0, 15.0, 33.0, 20.0, 19.0, 11.0, 3.0, 2.0, 11.0, 14.0, 3.0, 26.0, 28.0, 7.0, 2.0, 24.0, 8.0, 24.0, 7.0, 41.0, 30.0, 21.0, 27.0, 10.0, 33.0, 21.0, 21.0, 17.0, 36.0, 27.0, 21.0, 27.0, 10.0, 17.0, 3.0, 16.0, 19.0, 20.0, 26.0, 14.0, 9.0, 21.0, 31.0, 43.0, 26.0, 10.0, 29.0, 15.0, 12.0, 24.0, 24.0, 33.0, 41.0, 19.0, 33.0, 29.0, 41.0, 27.0, 35.0, 32.0, 7.0, 44.0, 35.0, 48.0, 32.0, 24.0, 42.0, 19.0, 12.0, 25.0, 44.0, 43.0, 14.0, 38.0, 0.0, 1.0, 27.0, 49.0, 43.0, 28.0, 10.0, 9.0, 38.0, 20.0, 41.0, 29.0, 6.0, 5.0, 31.0, 9.0, 17.0, 52.0, 44.0, 32.0, 43.0, 61.0, 31.0, 80.0, 35.0, 40.0, 55.0, 52.0, 8.0, 10.0, 42.0, 1.0, 59.0, 66.0, 74.0, 65.0, 56.0, 35.0, 6.0, 9.0, 36.0, 48.0, 30.0, 43.0, 30.0, 46.0, 68.0, 66.0, 60.0, 44.0, 12.0, 15.0, 74.0, 39.0, 113.0, 55.0, 5.0, 7.0, 7.0, 13.0, 7.0, 4.0, 77.0, 115.0, 7.0, 5.0, 74.0, 51.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.586131231491298, "mean_inference_ms": 1.8148756895832314, "mean_action_processing_ms": 0.2536144028501367, "mean_env_wait_ms": 0.1964046806155496, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0036410093307495117, "StateBufferConnector_ms": 0.0029821395874023438, "ViewRequirementAgentConnector_ms": 0.0925908088684082}, "num_episodes": 22, "episode_return_max": 50.30000000000047, "episode_return_min": -196.39999999999992, "episode_return_mean": -19.81199999999991, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2352000, "num_agent_steps_trained": 2352000, "num_env_steps_sampled": 588000, "num_env_steps_trained": 588000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 369.6537501404609, "num_env_steps_trained_throughput_per_sec": 369.6537501404609, "timesteps_total": 588000, "num_env_steps_sampled_lifetime": 588000, "num_agent_steps_sampled_lifetime": 2352000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2352000, "timers": {"training_iteration_time_ms": 10871.963, "restore_workers_time_ms": 0.014, "training_step_time_ms": 10871.907, "sample_time_ms": 1280.848, "learn_time_ms": 9574.362, "learn_throughput": 417.782, "synch_weights_time_ms": 14.836}, "counters": {"num_env_steps_sampled": 588000, "num_env_steps_trained": 588000, "num_agent_steps_sampled": 2352000, "num_agent_steps_trained": 2352000}, "done": false, "training_iteration": 147, "trial_id": "3dae5_00000", "date": "2024-08-14_09-33-54", "timestamp": 1723642434, "time_this_iter_s": 10.824298858642578, "time_total_s": 3252.0655369758606, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3896040>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3252.0655369758606, "iterations_since_restore": 147, "perf": {"cpu_util_percent": 30.36, "ram_util_percent": 83.2}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.142065208109598, "cur_kl_coeff": 3.4761428833007795e-05, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.818988009861537, "policy_loss": -0.006895121087433485, "vf_loss": 6.825882584960373, "vf_explained_var": 0.01229608002163115, "kl": 0.016347404689580226, "entropy": 0.7828755341509662, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 278775.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.610000637220958, "cur_kl_coeff": 0.03164062499999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.426587395062522, "policy_loss": -0.010254468713152819, "vf_loss": 4.436277862452956, "vf_explained_var": 0.24405604064779937, "kl": 0.017825191557499117, "entropy": 0.9065618790962078, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 278775.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 592000, "num_env_steps_trained": 592000, "num_agent_steps_sampled": 2368000, "num_agent_steps_trained": 2368000}, "env_runners": {"episode_reward_max": 50.30000000000047, "episode_reward_min": -395.09999999999957, "episode_reward_mean": -31.64299999999993, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -313.9000000000001, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 40.40000000000023, "predator_policy": 126.0}, "policy_reward_mean": {"prey_policy": -47.05150000000003, "predator_policy": 31.23}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-11.699999999999797, 0.799999999999919, 36.10000000000047, -0.8999999999999704, 28.100000000000122, -77.90000000000063, 19.09999999999999, 50.30000000000047, 37.50000000000037, 8.099999999999959, 48.20000000000048, 22.00000000000018, -43.79999999999953, -11.899999999999611, 42.30000000000033, -23.19999999999998, -19.199999999999704, -6.899999999999682, -11.699999999999768, -8.100000000000074, -12.800000000000123, -29.899999999999636, -0.7000000000000969, -48.799999999999734, -41.69999999999951, -102.8000000000008, 3.9999999999999765, 10.299999999999937, 12.800000000000054, -36.499999999999545, -3.099999999999987, 21.70000000000002, -126.90000000000106, 0.39999999999991875, -56.69999999999964, 8.799999999999963, -106.69999999999956, -70.09999999999978, -11.399999999999642, -37.199999999999626, -4.000000000000062, -57.49999999999962, -139.50000000000122, -14.400000000000059, -12.400000000000084, -33.99999999999957, -23.299999999999763, -4.600000000000049, 44.30000000000037, -39.39999999999961, -31.799999999999528, 38.00000000000027, -15.399999999999789, -76.89999999999978, 48.30000000000044, -32.79999999999985, -117.80000000000119, -73.00000000000028, -34.49999999999963, -80.00000000000115, -14.300000000000118, -41.09999999999975, 25.000000000000053, -7.300000000000097, -108.00000000000001, -51.99999999999966, -49.599999999999554, 28.900000000000126, -31.3999999999999, -107.50000000000034, -20.499999999999815, -105.30000000000118, -49.79999999999961, 8.200000000000095, -65.3999999999997, -75.50000000000011, 33.10000000000019, 26.40000000000008, 37.500000000000256, -196.39999999999992, 30.40000000000015, -59.69999999999965, 1.4732659536775827e-13, -83.90000000000012, -35.8999999999999, -395.09999999999957, 35.90000000000032, -11.499999999999869, -57.499999999999865, -71.5999999999999, -136.8, 25.70000000000007, -131.7, 40.60000000000031, -84.50000000000034, 29.000000000000124, 16.900000000000002, -70.5999999999998, -23.09999999999996, -205.10000000000105], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [5.299999999999965, -64.00000000000057, -19.899999999999814, -7.300000000000049, 3.2000000000001583, 17.899999999999988, -19.89999999999983, -1.0000000000000435, 20.000000000000014, -19.899999999999743, -70.3000000000001, -76.60000000000024, -40.89999999999978, 20.000000000000014, 5.299999999999965, 38.000000000000256, 30.800000000000196, -7.3000000000000576, 5.2999999999999785, -26.199999999999747, -26.199999999999747, 40.40000000000023, 20.90000000000003, -40.89999999999976, -45.09999999999976, -51.69999999999977, -24.099999999999746, -17.79999999999977, 23.60000000000007, 13.699999999999964, -26.199999999999946, -21.999999999999964, -17.79999999999989, -30.399999999999764, -21.999999999999744, -19.89999999999977, -5.2000000000000455, -32.49999999999975, -11.800000000000022, -28.299999999999905, 7.399999999999965, -68.19999999999996, -46.29999999999976, -34.59999999999982, -0.9999999999999846, -36.69999999999981, -57.69999999999977, -45.09999999999986, -28.29999999999985, -51.399999999999764, -80.80000000000024, -85.00000000000026, 20.000000000000014, -63.99999999999985, 20.000000000000014, -36.69999999999993, -15.699999999999747, 9.499999999999964, -21.99999999999984, -53.499999999999766, 17.899999999999988, -60.99999999999986, -28.29999999999975, 20.000000000000014, -103.90000000000049, -97.00000000000037, -45.09999999999977, 9.499999999999964, -40.8999999999999, -59.79999999999977, -21.999999999999744, -5.2000000000000455, -84.99999999999979, -78.69999999999979, -72.39999999999993, -57.699999999999775, 5.299999999999965, -78.70000000000049, -51.69999999999979, -53.499999999999766, -87.10000000000029, 16.09999999999996, -66.0999999999998, -42.39999999999982, -103.90000000000045, -118.60000000000056, -11.800000000000043, -58.59999999999983, -80.8000000000001, 7.399999999999965, -36.39999999999978, -34.5999999999998, -130.30000000000058, 20.000000000000014, 11.599999999999964, -68.19999999999993, 25.400000000000098, 17.899999999999988, -124.9000000000005, 9.499999999999964, 3.1999999999999615, -106.00000000000041, -0.9999999999999846, 20.000000000000014, -89.20000000000047, 15.799999999999963, -72.39999999999984, -74.49999999999989, 7.399999999999965, 29.90000000000018, -38.799999999999905, -33.999999999999915, -82.90000000000035, -103.9000000000006, -82.90000000000066, -66.1, 20.000000000000014, -158.50000000000063, -42.999999999999844, -148.00000000000063, 20.90000000000003, -110.20000000000061, -154.30000000000027, 6.1999999999999655, -0.09999999999998116, 7.099999999999966, 17.899999999999988, -68.19999999999999, -38.800000000000026, -194.20000000000033, -211.00000000000037, 20.000000000000014, -143.8000000000005, 3.1999999999999615, 8.599999999999968, 5.299999999999965, -0.9999999999999846, -114.40000000000019, -68.1999999999999, -112.30000000000021, 20.000000000000014, -116.50000000000037, -32.49999999999975, -206.80000000000038, -154.9000000000003, 1.0999999999999865, -9.399999999999926, -9.399999999999855, -0.9999999999999846, -177.4000000000004, -9.399999999999855, -234.10000000000008, 15.799999999999963, 5.299999999999965, 13.699999999999964, -7.299999999999891, 11.599999999999964, 14.899999999999936, -110.20000000000003, -278.2000000000002, 9.499999999999964, 8.899999999999967, 20.000000000000014, -204.70000000000033, -57.69999999999978, 13.699999999999964, 20.000000000000014, -313.9000000000001, -135.4000000000001, 9.499999999999964, -295.0000000000002, -297.10000000000025, -24.099999999999966, 20.000000000000014, -93.4000000000004, 17.899999999999988, -190.00000000000014, 9.499999999999964, -204.70000000000024, 1.0999999999999865, -198.4000000000003, -72.39999999999992, 17.899999999999988, -5.1999999999999265, -158.50000000000034, -89.20000000000002, 13.699999999999964, 20.900000000000027, -234.10000000000016, 11.599999999999964, 7.399999999999965, 11.599999999999964, -3.099999999999958, -0.9999999999999846, -205.30000000000013, -7.299999999999891, -129.10000000000005, 20.000000000000014, -255.10000000000034, -127.00000000000068], "policy_predator_policy_reward": [7.0, 40.0, 11.0, 17.0, 5.0, 10.0, 1.0, 19.0, 17.0, 11.0, 55.0, 14.0, 27.0, 13.0, 7.0, 0.0, 13.0, 1.0, 5.0, 24.0, 12.0, 22.0, 27.0, 15.0, 33.0, 20.0, 19.0, 11.0, 3.0, 2.0, 11.0, 14.0, 3.0, 26.0, 28.0, 7.0, 2.0, 24.0, 8.0, 24.0, 7.0, 41.0, 30.0, 21.0, 27.0, 10.0, 33.0, 21.0, 21.0, 17.0, 36.0, 27.0, 21.0, 27.0, 10.0, 17.0, 3.0, 16.0, 19.0, 20.0, 26.0, 14.0, 9.0, 21.0, 31.0, 43.0, 26.0, 10.0, 29.0, 15.0, 12.0, 24.0, 24.0, 33.0, 41.0, 19.0, 33.0, 29.0, 41.0, 27.0, 35.0, 32.0, 7.0, 44.0, 35.0, 48.0, 32.0, 24.0, 42.0, 19.0, 12.0, 25.0, 44.0, 43.0, 14.0, 38.0, 0.0, 1.0, 27.0, 49.0, 43.0, 28.0, 10.0, 9.0, 38.0, 20.0, 41.0, 29.0, 6.0, 5.0, 31.0, 9.0, 17.0, 52.0, 44.0, 32.0, 43.0, 61.0, 31.0, 80.0, 35.0, 40.0, 55.0, 52.0, 8.0, 10.0, 42.0, 1.0, 59.0, 66.0, 74.0, 65.0, 56.0, 35.0, 6.0, 9.0, 36.0, 48.0, 30.0, 43.0, 30.0, 46.0, 68.0, 66.0, 60.0, 44.0, 12.0, 15.0, 74.0, 39.0, 113.0, 55.0, 5.0, 7.0, 7.0, 13.0, 7.0, 4.0, 77.0, 115.0, 7.0, 5.0, 74.0, 51.0, 26.0, 18.0, 84.0, 126.0, 43.0, 47.0, 72.0, 125.0, 27.0, 13.0, 30.0, 34.0, 57.0, 66.0, 48.0, 84.0, 59.0, 75.0, 12.0, 1.0, 65.0, 51.0, 3.0, 3.0, 83.0, 55.0, 4.0, 6.0, 10.0, 11.0, 105.0, 37.0, 45.0, 41.0, 99.0, 78.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5858838263472355, "mean_inference_ms": 1.81443408945067, "mean_action_processing_ms": 0.25380448261833954, "mean_env_wait_ms": 0.19617080166203515, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0034782886505126953, "StateBufferConnector_ms": 0.0029572248458862305, "ViewRequirementAgentConnector_ms": 0.09139955043792725}, "num_episodes": 18, "episode_return_max": 50.30000000000047, "episode_return_min": -395.09999999999957, "episode_return_mean": -31.64299999999993, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2368000, "num_agent_steps_trained": 2368000, "num_env_steps_sampled": 592000, "num_env_steps_trained": 592000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 364.5003360455601, "num_env_steps_trained_throughput_per_sec": 364.5003360455601, "timesteps_total": 592000, "num_env_steps_sampled_lifetime": 592000, "num_agent_steps_sampled_lifetime": 2368000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2368000, "timers": {"training_iteration_time_ms": 10910.023, "restore_workers_time_ms": 0.014, "training_step_time_ms": 10909.966, "sample_time_ms": 1283.672, "learn_time_ms": 9609.238, "learn_throughput": 416.266, "synch_weights_time_ms": 15.003}, "counters": {"num_env_steps_sampled": 592000, "num_env_steps_trained": 592000, "num_agent_steps_sampled": 2368000, "num_agent_steps_trained": 2368000}, "done": false, "training_iteration": 148, "trial_id": "3dae5_00000", "date": "2024-08-14_09-34-05", "timestamp": 1723642445, "time_this_iter_s": 11.018059015274048, "time_total_s": 3263.0835959911346, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b38b6c10>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3263.0835959911346, "iterations_since_restore": 148, "perf": {"cpu_util_percent": 28.1375, "ram_util_percent": 83.4}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.6852488124181355, "cur_kl_coeff": 3.4761428833007795e-05, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.1446271078296437, "policy_loss": -0.005965207625801365, "vf_loss": 3.1505914769475423, "vf_explained_var": 0.021384945653733754, "kl": 0.0241342206679934, "entropy": 0.8520731632040922, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 280665.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.82829351844611, "cur_kl_coeff": 0.03164062499999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.695939602738335, "policy_loss": -0.020762495944035, "vf_loss": 1.7156441736788977, "vf_explained_var": 0.2903679527618267, "kl": 0.03343555323138988, "entropy": 0.9461442787811238, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 280665.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 596000, "num_env_steps_trained": 596000, "num_agent_steps_sampled": 2384000, "num_agent_steps_trained": 2384000}, "env_runners": {"episode_reward_max": 48.30000000000044, "episode_reward_min": -395.09999999999957, "episode_reward_mean": -34.55099999999995, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -313.9000000000001, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 29.90000000000018, "predator_policy": 126.0}, "policy_reward_mean": {"prey_policy": -51.095500000000065, "predator_policy": 33.82}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-11.699999999999768, -8.100000000000074, -12.800000000000123, -29.899999999999636, -0.7000000000000969, -48.799999999999734, -41.69999999999951, -102.8000000000008, 3.9999999999999765, 10.299999999999937, 12.800000000000054, -36.499999999999545, -3.099999999999987, 21.70000000000002, -126.90000000000106, 0.39999999999991875, -56.69999999999964, 8.799999999999963, -106.69999999999956, -70.09999999999978, -11.399999999999642, -37.199999999999626, -4.000000000000062, -57.49999999999962, -139.50000000000122, -14.400000000000059, -12.400000000000084, -33.99999999999957, -23.299999999999763, -4.600000000000049, 44.30000000000037, -39.39999999999961, -31.799999999999528, 38.00000000000027, -15.399999999999789, -76.89999999999978, 48.30000000000044, -32.79999999999985, -117.80000000000119, -73.00000000000028, -34.49999999999963, -80.00000000000115, -14.300000000000118, -41.09999999999975, 25.000000000000053, -7.300000000000097, -108.00000000000001, -51.99999999999966, -49.599999999999554, 28.900000000000126, -31.3999999999999, -107.50000000000034, -20.499999999999815, -105.30000000000118, -49.79999999999961, 8.200000000000095, -65.3999999999997, -75.50000000000011, 33.10000000000019, 26.40000000000008, 37.500000000000256, -196.39999999999992, 30.40000000000015, -59.69999999999965, 1.4732659536775827e-13, -83.90000000000012, -35.8999999999999, -395.09999999999957, 35.90000000000032, -11.499999999999869, -57.499999999999865, -71.5999999999999, -136.8, 25.70000000000007, -131.7, 40.60000000000031, -84.50000000000034, 29.000000000000124, 16.900000000000002, -70.5999999999998, -23.09999999999996, -205.10000000000105, 38.80000000000028, -54.299999999999606, -45.39999999999983, 37.700000000000266, 33.4000000000002, 27.4000000000001, -26.699999999999555, -60.40000000000151, -40.29999999999979, -16.599999999999845, 20.200000000000006, 31.900000000000183, -272.5999999999998, 22.400000000000013, 42.70000000000034, 36.900000000000226, 9.799999999999935, 21.3], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-5.2000000000000455, -32.49999999999975, -11.800000000000022, -28.299999999999905, 7.399999999999965, -68.19999999999996, -46.29999999999976, -34.59999999999982, -0.9999999999999846, -36.69999999999981, -57.69999999999977, -45.09999999999986, -28.29999999999985, -51.399999999999764, -80.80000000000024, -85.00000000000026, 20.000000000000014, -63.99999999999985, 20.000000000000014, -36.69999999999993, -15.699999999999747, 9.499999999999964, -21.99999999999984, -53.499999999999766, 17.899999999999988, -60.99999999999986, -28.29999999999975, 20.000000000000014, -103.90000000000049, -97.00000000000037, -45.09999999999977, 9.499999999999964, -40.8999999999999, -59.79999999999977, -21.999999999999744, -5.2000000000000455, -84.99999999999979, -78.69999999999979, -72.39999999999993, -57.699999999999775, 5.299999999999965, -78.70000000000049, -51.69999999999979, -53.499999999999766, -87.10000000000029, 16.09999999999996, -66.0999999999998, -42.39999999999982, -103.90000000000045, -118.60000000000056, -11.800000000000043, -58.59999999999983, -80.8000000000001, 7.399999999999965, -36.39999999999978, -34.5999999999998, -130.30000000000058, 20.000000000000014, 11.599999999999964, -68.19999999999993, 25.400000000000098, 17.899999999999988, -124.9000000000005, 9.499999999999964, 3.1999999999999615, -106.00000000000041, -0.9999999999999846, 20.000000000000014, -89.20000000000047, 15.799999999999963, -72.39999999999984, -74.49999999999989, 7.399999999999965, 29.90000000000018, -38.799999999999905, -33.999999999999915, -82.90000000000035, -103.9000000000006, -82.90000000000066, -66.1, 20.000000000000014, -158.50000000000063, -42.999999999999844, -148.00000000000063, 20.90000000000003, -110.20000000000061, -154.30000000000027, 6.1999999999999655, -0.09999999999998116, 7.099999999999966, 17.899999999999988, -68.19999999999999, -38.800000000000026, -194.20000000000033, -211.00000000000037, 20.000000000000014, -143.8000000000005, 3.1999999999999615, 8.599999999999968, 5.299999999999965, -0.9999999999999846, -114.40000000000019, -68.1999999999999, -112.30000000000021, 20.000000000000014, -116.50000000000037, -32.49999999999975, -206.80000000000038, -154.9000000000003, 1.0999999999999865, -9.399999999999926, -9.399999999999855, -0.9999999999999846, -177.4000000000004, -9.399999999999855, -234.10000000000008, 15.799999999999963, 5.299999999999965, 13.699999999999964, -7.299999999999891, 11.599999999999964, 14.899999999999936, -110.20000000000003, -278.2000000000002, 9.499999999999964, 8.899999999999967, 20.000000000000014, -204.70000000000033, -57.69999999999978, 13.699999999999964, 20.000000000000014, -313.9000000000001, -135.4000000000001, 9.499999999999964, -295.0000000000002, -297.10000000000025, -24.099999999999966, 20.000000000000014, -93.4000000000004, 17.899999999999988, -190.00000000000014, 9.499999999999964, -204.70000000000024, 1.0999999999999865, -198.4000000000003, -72.39999999999992, 17.899999999999988, -5.1999999999999265, -158.50000000000034, -89.20000000000002, 13.699999999999964, 20.900000000000027, -234.10000000000016, 11.599999999999964, 7.399999999999965, 11.599999999999964, -3.099999999999958, -0.9999999999999846, -205.30000000000013, -7.299999999999891, -129.10000000000005, 20.000000000000014, -255.10000000000034, -127.00000000000068, 20.000000000000014, 15.799999999999963, 1.0999999999999865, -219.40000000000032, 17.899999999999988, -196.30000000000018, 20.000000000000014, -7.299999999999891, 11.599999999999964, 15.799999999999963, -10.599999999999836, 20.000000000000014, -114.40000000000055, -7.299999999999901, -57.70000000000041, -57.70000000000042, -118.60000000000076, 5.299999999999965, 20.000000000000014, -160.6000000000006, 1.0999999999999865, 1.0999999999999865, 1.0999999999999865, 15.799999999999962, -297.10000000000014, -179.50000000000054, 20.000000000000014, -13.599999999999783, 7.399999999999965, 26.300000000000114, 7.0999999999999615, 21.80000000000004, -99.7000000000007, 24.50000000000008, 7.399999999999965, -3.099999999999958], "policy_predator_policy_reward": [2.0, 24.0, 8.0, 24.0, 7.0, 41.0, 30.0, 21.0, 27.0, 10.0, 33.0, 21.0, 21.0, 17.0, 36.0, 27.0, 21.0, 27.0, 10.0, 17.0, 3.0, 16.0, 19.0, 20.0, 26.0, 14.0, 9.0, 21.0, 31.0, 43.0, 26.0, 10.0, 29.0, 15.0, 12.0, 24.0, 24.0, 33.0, 41.0, 19.0, 33.0, 29.0, 41.0, 27.0, 35.0, 32.0, 7.0, 44.0, 35.0, 48.0, 32.0, 24.0, 42.0, 19.0, 12.0, 25.0, 44.0, 43.0, 14.0, 38.0, 0.0, 1.0, 27.0, 49.0, 43.0, 28.0, 10.0, 9.0, 38.0, 20.0, 41.0, 29.0, 6.0, 5.0, 31.0, 9.0, 17.0, 52.0, 44.0, 32.0, 43.0, 61.0, 31.0, 80.0, 35.0, 40.0, 55.0, 52.0, 8.0, 10.0, 42.0, 1.0, 59.0, 66.0, 74.0, 65.0, 56.0, 35.0, 6.0, 9.0, 36.0, 48.0, 30.0, 43.0, 30.0, 46.0, 68.0, 66.0, 60.0, 44.0, 12.0, 15.0, 74.0, 39.0, 113.0, 55.0, 5.0, 7.0, 7.0, 13.0, 7.0, 4.0, 77.0, 115.0, 7.0, 5.0, 74.0, 51.0, 26.0, 18.0, 84.0, 126.0, 43.0, 47.0, 72.0, 125.0, 27.0, 13.0, 30.0, 34.0, 57.0, 66.0, 48.0, 84.0, 59.0, 75.0, 12.0, 1.0, 65.0, 51.0, 3.0, 3.0, 83.0, 55.0, 4.0, 6.0, 10.0, 11.0, 105.0, 37.0, 45.0, 41.0, 99.0, 78.0, 1.0, 2.0, 76.0, 88.0, 65.0, 68.0, 12.0, 13.0, 2.0, 4.0, 3.0, 15.0, 49.0, 46.0, 30.0, 25.0, 7.0, 66.0, 64.0, 60.0, 9.0, 9.0, 5.0, 10.0, 98.0, 106.0, 0.0, 16.0, 6.0, 3.0, 7.0, 1.0, 45.0, 40.0, 6.0, 11.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5856796431690887, "mean_inference_ms": 1.8139259615611032, "mean_action_processing_ms": 0.25365159783141134, "mean_env_wait_ms": 0.1960839444396859, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0035293102264404297, "StateBufferConnector_ms": 0.0030096769332885742, "ViewRequirementAgentConnector_ms": 0.0929574966430664}, "num_episodes": 18, "episode_return_max": 48.30000000000044, "episode_return_min": -395.09999999999957, "episode_return_mean": -34.55099999999995, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2384000, "num_agent_steps_trained": 2384000, "num_env_steps_sampled": 596000, "num_env_steps_trained": 596000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 370.01711227163145, "num_env_steps_trained_throughput_per_sec": 370.01711227163145, "timesteps_total": 596000, "num_env_steps_sampled_lifetime": 596000, "num_agent_steps_sampled_lifetime": 2384000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2384000, "timers": {"training_iteration_time_ms": 10872.592, "restore_workers_time_ms": 0.014, "training_step_time_ms": 10872.537, "sample_time_ms": 1283.569, "learn_time_ms": 9572.613, "learn_throughput": 417.859, "synch_weights_time_ms": 14.631}, "counters": {"num_env_steps_sampled": 596000, "num_env_steps_trained": 596000, "num_agent_steps_sampled": 2384000, "num_agent_steps_trained": 2384000}, "done": false, "training_iteration": 149, "trial_id": "3dae5_00000", "date": "2024-08-14_09-34-16", "timestamp": 1723642456, "time_this_iter_s": 10.81615161895752, "time_total_s": 3273.899747610092, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b384eee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3273.899747610092, "iterations_since_restore": 149, "perf": {"cpu_util_percent": 29.686666666666667, "ram_util_percent": 83.13333333333331}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9116102748446995, "cur_kl_coeff": 5.21421432495117e-05, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.1981969961098262, "policy_loss": -0.004436722261308835, "vf_loss": 1.202632942890364, "vf_explained_var": -0.004785759266091402, "kl": 0.014876330741243086, "entropy": 0.9643026181945095, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 282555.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.1189155614880657, "cur_kl_coeff": 0.047460937500000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.9055709849116663, "policy_loss": -0.010015570920788579, "vf_loss": 0.9149754374746293, "vf_explained_var": 0.34855573284562935, "kl": 0.012876236169296415, "entropy": 1.0089151232330889, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 282555.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 600000, "num_env_steps_trained": 600000, "num_agent_steps_sampled": 2400000, "num_agent_steps_trained": 2400000}, "env_runners": {"episode_reward_max": 48.30000000000044, "episode_reward_min": -395.09999999999957, "episode_reward_mean": -23.70099999999993, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -313.9000000000001, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 29.90000000000018, "predator_policy": 126.0}, "policy_reward_mean": {"prey_policy": -44.37550000000008, "predator_policy": 32.525}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-57.49999999999962, -139.50000000000122, -14.400000000000059, -12.400000000000084, -33.99999999999957, -23.299999999999763, -4.600000000000049, 44.30000000000037, -39.39999999999961, -31.799999999999528, 38.00000000000027, -15.399999999999789, -76.89999999999978, 48.30000000000044, -32.79999999999985, -117.80000000000119, -73.00000000000028, -34.49999999999963, -80.00000000000115, -14.300000000000118, -41.09999999999975, 25.000000000000053, -7.300000000000097, -108.00000000000001, -51.99999999999966, -49.599999999999554, 28.900000000000126, -31.3999999999999, -107.50000000000034, -20.499999999999815, -105.30000000000118, -49.79999999999961, 8.200000000000095, -65.3999999999997, -75.50000000000011, 33.10000000000019, 26.40000000000008, 37.500000000000256, -196.39999999999992, 30.40000000000015, -59.69999999999965, 1.4732659536775827e-13, -83.90000000000012, -35.8999999999999, -395.09999999999957, 35.90000000000032, -11.499999999999869, -57.499999999999865, -71.5999999999999, -136.8, 25.70000000000007, -131.7, 40.60000000000031, -84.50000000000034, 29.000000000000124, 16.900000000000002, -70.5999999999998, -23.09999999999996, -205.10000000000105, 38.80000000000028, -54.299999999999606, -45.39999999999983, 37.700000000000266, 33.4000000000002, 27.4000000000001, -26.699999999999555, -60.40000000000151, -40.29999999999979, -16.599999999999845, 20.200000000000006, 31.900000000000183, -272.5999999999998, 22.400000000000013, 42.70000000000034, 36.900000000000226, 9.799999999999935, 21.3, -31.299999999999507, 12.900000000000043, 15.399999999999913, 35.40000000000023, 7.1000000000000565, 34.100000000000215, 26.200000000000077, 12.499999999999929, 38.90000000000028, 6.600000000000051, 36.500000000000256, 27.90000000000011, 23.500000000000032, -15.899999999999718, -6.999999999999988, 42.30000000000029, 17.999999999999996, 27.300000000000086, 18.699999999999957, 27.200000000000095, 42.30000000000036, -0.4999999999997715, 35.80000000000023], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-66.0999999999998, -42.39999999999982, -103.90000000000045, -118.60000000000056, -11.800000000000043, -58.59999999999983, -80.8000000000001, 7.399999999999965, -36.39999999999978, -34.5999999999998, -130.30000000000058, 20.000000000000014, 11.599999999999964, -68.19999999999993, 25.400000000000098, 17.899999999999988, -124.9000000000005, 9.499999999999964, 3.1999999999999615, -106.00000000000041, -0.9999999999999846, 20.000000000000014, -89.20000000000047, 15.799999999999963, -72.39999999999984, -74.49999999999989, 7.399999999999965, 29.90000000000018, -38.799999999999905, -33.999999999999915, -82.90000000000035, -103.9000000000006, -82.90000000000066, -66.1, 20.000000000000014, -158.50000000000063, -42.999999999999844, -148.00000000000063, 20.90000000000003, -110.20000000000061, -154.30000000000027, 6.1999999999999655, -0.09999999999998116, 7.099999999999966, 17.899999999999988, -68.19999999999999, -38.800000000000026, -194.20000000000033, -211.00000000000037, 20.000000000000014, -143.8000000000005, 3.1999999999999615, 8.599999999999968, 5.299999999999965, -0.9999999999999846, -114.40000000000019, -68.1999999999999, -112.30000000000021, 20.000000000000014, -116.50000000000037, -32.49999999999975, -206.80000000000038, -154.9000000000003, 1.0999999999999865, -9.399999999999926, -9.399999999999855, -0.9999999999999846, -177.4000000000004, -9.399999999999855, -234.10000000000008, 15.799999999999963, 5.299999999999965, 13.699999999999964, -7.299999999999891, 11.599999999999964, 14.899999999999936, -110.20000000000003, -278.2000000000002, 9.499999999999964, 8.899999999999967, 20.000000000000014, -204.70000000000033, -57.69999999999978, 13.699999999999964, 20.000000000000014, -313.9000000000001, -135.4000000000001, 9.499999999999964, -295.0000000000002, -297.10000000000025, -24.099999999999966, 20.000000000000014, -93.4000000000004, 17.899999999999988, -190.00000000000014, 9.499999999999964, -204.70000000000024, 1.0999999999999865, -198.4000000000003, -72.39999999999992, 17.899999999999988, -5.1999999999999265, -158.50000000000034, -89.20000000000002, 13.699999999999964, 20.900000000000027, -234.10000000000016, 11.599999999999964, 7.399999999999965, 11.599999999999964, -3.099999999999958, -0.9999999999999846, -205.30000000000013, -7.299999999999891, -129.10000000000005, 20.000000000000014, -255.10000000000034, -127.00000000000068, 20.000000000000014, 15.799999999999963, 1.0999999999999865, -219.40000000000032, 17.899999999999988, -196.30000000000018, 20.000000000000014, -7.299999999999891, 11.599999999999964, 15.799999999999963, -10.599999999999836, 20.000000000000014, -114.40000000000055, -7.299999999999901, -57.70000000000041, -57.70000000000042, -118.60000000000076, 5.299999999999965, 20.000000000000014, -160.6000000000006, 1.0999999999999865, 1.0999999999999865, 1.0999999999999865, 15.799999999999962, -297.10000000000014, -179.50000000000054, 20.000000000000014, -13.599999999999783, 7.399999999999965, 26.300000000000114, 7.0999999999999615, 21.80000000000004, -99.7000000000007, 24.50000000000008, 7.399999999999965, -3.099999999999958, -13.599999999999783, -57.70000000000034, 1.3999999999999726, -2.4999999999999716, -34.599999999999774, -0.9999999999999846, 20.000000000000014, 7.399999999999965, 20.000000000000014, -61.900000000000695, 13.699999999999964, 13.399999999999974, 14.299999999999965, -3.099999999999958, 20.000000000000014, -32.499999999999794, 20.000000000000014, 17.899999999999988, 20.000000000000014, -51.399999999999785, 21.800000000000047, -49.299999999999905, -0.7000000000000134, 11.599999999999964, 11.599999999999964, -24.099999999999746, 5.299999999999965, -131.20000000000056, 26.900000000000134, -124.9000000000004, 28.100000000000136, -17.79999999999974, -11.499999999999819, 9.499999999999964, 7.999999999999966, 5.299999999999965, 1.099999999999983, -54.400000000000205, 1.6999999999999729, 9.499999999999964, 20.000000000000014, 20.300000000000008, 5.299999999999965, -59.800000000000594, -3.100000000000001, 17.899999999999988], "policy_predator_policy_reward": [7.0, 44.0, 35.0, 48.0, 32.0, 24.0, 42.0, 19.0, 12.0, 25.0, 44.0, 43.0, 14.0, 38.0, 0.0, 1.0, 27.0, 49.0, 43.0, 28.0, 10.0, 9.0, 38.0, 20.0, 41.0, 29.0, 6.0, 5.0, 31.0, 9.0, 17.0, 52.0, 44.0, 32.0, 43.0, 61.0, 31.0, 80.0, 35.0, 40.0, 55.0, 52.0, 8.0, 10.0, 42.0, 1.0, 59.0, 66.0, 74.0, 65.0, 56.0, 35.0, 6.0, 9.0, 36.0, 48.0, 30.0, 43.0, 30.0, 46.0, 68.0, 66.0, 60.0, 44.0, 12.0, 15.0, 74.0, 39.0, 113.0, 55.0, 5.0, 7.0, 7.0, 13.0, 7.0, 4.0, 77.0, 115.0, 7.0, 5.0, 74.0, 51.0, 26.0, 18.0, 84.0, 126.0, 43.0, 47.0, 72.0, 125.0, 27.0, 13.0, 30.0, 34.0, 57.0, 66.0, 48.0, 84.0, 59.0, 75.0, 12.0, 1.0, 65.0, 51.0, 3.0, 3.0, 83.0, 55.0, 4.0, 6.0, 10.0, 11.0, 105.0, 37.0, 45.0, 41.0, 99.0, 78.0, 1.0, 2.0, 76.0, 88.0, 65.0, 68.0, 12.0, 13.0, 2.0, 4.0, 3.0, 15.0, 49.0, 46.0, 30.0, 25.0, 7.0, 66.0, 64.0, 60.0, 9.0, 9.0, 5.0, 10.0, 98.0, 106.0, 0.0, 16.0, 6.0, 3.0, 7.0, 1.0, 45.0, 40.0, 6.0, 11.0, 3.0, 37.0, 2.0, 12.0, 27.0, 24.0, 2.0, 6.0, 21.0, 28.0, 4.0, 3.0, 4.0, 11.0, 2.0, 23.0, 1.0, 0.0, 16.0, 22.0, 31.0, 33.0, 4.0, 13.0, 15.0, 21.0, 59.0, 51.0, 49.0, 42.0, 14.0, 18.0, 5.0, 15.0, 7.0, 7.0, 37.0, 35.0, 10.0, 6.0, 0.0, 2.0, 27.0, 27.0, 1.0, 20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5856486537900581, "mean_inference_ms": 1.812099946507791, "mean_action_processing_ms": 0.253752430041629, "mean_env_wait_ms": 0.1960328396803968, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0034914016723632812, "StateBufferConnector_ms": 0.002961277961730957, "ViewRequirementAgentConnector_ms": 0.08865189552307129}, "num_episodes": 23, "episode_return_max": 48.30000000000044, "episode_return_min": -395.09999999999957, "episode_return_mean": -23.70099999999993, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2400000, "num_agent_steps_trained": 2400000, "num_env_steps_sampled": 600000, "num_env_steps_trained": 600000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 364.8198824776268, "num_env_steps_trained_throughput_per_sec": 364.8198824776268, "timesteps_total": 600000, "num_env_steps_sampled_lifetime": 600000, "num_agent_steps_sampled_lifetime": 2400000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2400000, "timers": {"training_iteration_time_ms": 10872.11, "restore_workers_time_ms": 0.014, "training_step_time_ms": 10872.056, "sample_time_ms": 1278.825, "learn_time_ms": 9577.184, "learn_throughput": 417.659, "synch_weights_time_ms": 14.483}, "counters": {"num_env_steps_sampled": 600000, "num_env_steps_trained": 600000, "num_agent_steps_sampled": 2400000, "num_agent_steps_trained": 2400000}, "done": false, "training_iteration": 150, "trial_id": "3dae5_00000", "date": "2024-08-14_09-34-27", "timestamp": 1723642467, "time_this_iter_s": 10.975692987442017, "time_total_s": 3284.875440597534, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3896040>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3284.875440597534, "iterations_since_restore": 150, "perf": {"cpu_util_percent": 28.7, "ram_util_percent": 83.30000000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.3922242062432426, "cur_kl_coeff": 5.21421432495117e-05, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.4401142529078892, "policy_loss": -0.004927278564942301, "vf_loss": 1.4450409345525914, "vf_explained_var": 0.05753005664184611, "kl": 0.011417356289509904, "entropy": 0.8735891642709258, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 284445.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.797673979606578, "cur_kl_coeff": 0.047460937500000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.4371425969733131, "policy_loss": -0.013246034124432496, "vf_loss": 1.4496960221144257, "vf_explained_var": 0.2897289096363007, "kl": 0.01459318426856604, "entropy": 0.9686076981365366, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 284445.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 604000, "num_env_steps_trained": 604000, "num_agent_steps_sampled": 2416000, "num_agent_steps_trained": 2416000}, "env_runners": {"episode_reward_max": 42.70000000000034, "episode_reward_min": -395.09999999999957, "episode_reward_mean": -14.657999999999907, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -313.9000000000001, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 29.90000000000018, "predator_policy": 126.0}, "policy_reward_mean": {"prey_policy": -37.804000000000066, "predator_policy": 30.475}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-80.00000000000115, -14.300000000000118, -41.09999999999975, 25.000000000000053, -7.300000000000097, -108.00000000000001, -51.99999999999966, -49.599999999999554, 28.900000000000126, -31.3999999999999, -107.50000000000034, -20.499999999999815, -105.30000000000118, -49.79999999999961, 8.200000000000095, -65.3999999999997, -75.50000000000011, 33.10000000000019, 26.40000000000008, 37.500000000000256, -196.39999999999992, 30.40000000000015, -59.69999999999965, 1.4732659536775827e-13, -83.90000000000012, -35.8999999999999, -395.09999999999957, 35.90000000000032, -11.499999999999869, -57.499999999999865, -71.5999999999999, -136.8, 25.70000000000007, -131.7, 40.60000000000031, -84.50000000000034, 29.000000000000124, 16.900000000000002, -70.5999999999998, -23.09999999999996, -205.10000000000105, 38.80000000000028, -54.299999999999606, -45.39999999999983, 37.700000000000266, 33.4000000000002, 27.4000000000001, -26.699999999999555, -60.40000000000151, -40.29999999999979, -16.599999999999845, 20.200000000000006, 31.900000000000183, -272.5999999999998, 22.400000000000013, 42.70000000000034, 36.900000000000226, 9.799999999999935, 21.3, -31.299999999999507, 12.900000000000043, 15.399999999999913, 35.40000000000023, 7.1000000000000565, 34.100000000000215, 26.200000000000077, 12.499999999999929, 38.90000000000028, 6.600000000000051, 36.500000000000256, 27.90000000000011, 23.500000000000032, -15.899999999999718, -6.999999999999988, 42.30000000000029, 17.999999999999996, 27.300000000000086, 18.699999999999957, 27.200000000000095, 42.30000000000036, -0.4999999999997715, 35.80000000000023, 20.3, 35.10000000000023, 36.70000000000025, 25.100000000000062, 35.500000000000234, 15.100000000000021, 20.800000000000008, -17.499999999999552, 39.40000000000029, 3.3000000000001664, -20.399999999999537, 18.099999999999948, -5.699999999999704, 31.500000000000387, 9.200000000000113, 27.800000000000114, 11.200000000000077, 42.10000000000033], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-42.999999999999844, -148.00000000000063, 20.90000000000003, -110.20000000000061, -154.30000000000027, 6.1999999999999655, -0.09999999999998116, 7.099999999999966, 17.899999999999988, -68.19999999999999, -38.800000000000026, -194.20000000000033, -211.00000000000037, 20.000000000000014, -143.8000000000005, 3.1999999999999615, 8.599999999999968, 5.299999999999965, -0.9999999999999846, -114.40000000000019, -68.1999999999999, -112.30000000000021, 20.000000000000014, -116.50000000000037, -32.49999999999975, -206.80000000000038, -154.9000000000003, 1.0999999999999865, -9.399999999999926, -9.399999999999855, -0.9999999999999846, -177.4000000000004, -9.399999999999855, -234.10000000000008, 15.799999999999963, 5.299999999999965, 13.699999999999964, -7.299999999999891, 11.599999999999964, 14.899999999999936, -110.20000000000003, -278.2000000000002, 9.499999999999964, 8.899999999999967, 20.000000000000014, -204.70000000000033, -57.69999999999978, 13.699999999999964, 20.000000000000014, -313.9000000000001, -135.4000000000001, 9.499999999999964, -295.0000000000002, -297.10000000000025, -24.099999999999966, 20.000000000000014, -93.4000000000004, 17.899999999999988, -190.00000000000014, 9.499999999999964, -204.70000000000024, 1.0999999999999865, -198.4000000000003, -72.39999999999992, 17.899999999999988, -5.1999999999999265, -158.50000000000034, -89.20000000000002, 13.699999999999964, 20.900000000000027, -234.10000000000016, 11.599999999999964, 7.399999999999965, 11.599999999999964, -3.099999999999958, -0.9999999999999846, -205.30000000000013, -7.299999999999891, -129.10000000000005, 20.000000000000014, -255.10000000000034, -127.00000000000068, 20.000000000000014, 15.799999999999963, 1.0999999999999865, -219.40000000000032, 17.899999999999988, -196.30000000000018, 20.000000000000014, -7.299999999999891, 11.599999999999964, 15.799999999999963, -10.599999999999836, 20.000000000000014, -114.40000000000055, -7.299999999999901, -57.70000000000041, -57.70000000000042, -118.60000000000076, 5.299999999999965, 20.000000000000014, -160.6000000000006, 1.0999999999999865, 1.0999999999999865, 1.0999999999999865, 15.799999999999962, -297.10000000000014, -179.50000000000054, 20.000000000000014, -13.599999999999783, 7.399999999999965, 26.300000000000114, 7.0999999999999615, 21.80000000000004, -99.7000000000007, 24.50000000000008, 7.399999999999965, -3.099999999999958, -13.599999999999783, -57.70000000000034, 1.3999999999999726, -2.4999999999999716, -34.599999999999774, -0.9999999999999846, 20.000000000000014, 7.399999999999965, 20.000000000000014, -61.900000000000695, 13.699999999999964, 13.399999999999974, 14.299999999999965, -3.099999999999958, 20.000000000000014, -32.499999999999794, 20.000000000000014, 17.899999999999988, 20.000000000000014, -51.399999999999785, 21.800000000000047, -49.299999999999905, -0.7000000000000134, 11.599999999999964, 11.599999999999964, -24.099999999999746, 5.299999999999965, -131.20000000000056, 26.900000000000134, -124.9000000000004, 28.100000000000136, -17.79999999999974, -11.499999999999819, 9.499999999999964, 7.999999999999966, 5.299999999999965, 1.099999999999983, -54.400000000000205, 1.6999999999999729, 9.499999999999964, 20.000000000000014, 20.300000000000008, 5.299999999999965, -59.800000000000594, -3.100000000000001, 17.899999999999988, 3.1999999999999615, 1.0999999999999865, 20.000000000000014, 1.09999999999996, 13.699999999999964, 20.000000000000014, -19.899999999999743, 20.000000000000014, 20.000000000000014, -29.49999999999975, 3.1999999999999615, -3.099999999999958, -4.299999999999958, 1.0999999999999865, -70.30000000000084, -47.19999999999976, 20.000000000000014, 7.399999999999965, 1.099999999999983, -80.80000000000085, -47.19999999999977, -29.19999999999977, -17.199999999999747, 5.299999999999965, 15.799999999999963, -65.50000000000088, 20.000000000000014, -32.49999999999984, -5.1999999999999265, -13.599999999999783, 9.49999999999997, -15.699999999999747, -3.099999999999958, -15.699999999999747, 29.90000000000018, 3.1999999999999615], "policy_predator_policy_reward": [31.0, 80.0, 35.0, 40.0, 55.0, 52.0, 8.0, 10.0, 42.0, 1.0, 59.0, 66.0, 74.0, 65.0, 56.0, 35.0, 6.0, 9.0, 36.0, 48.0, 30.0, 43.0, 30.0, 46.0, 68.0, 66.0, 60.0, 44.0, 12.0, 15.0, 74.0, 39.0, 113.0, 55.0, 5.0, 7.0, 7.0, 13.0, 7.0, 4.0, 77.0, 115.0, 7.0, 5.0, 74.0, 51.0, 26.0, 18.0, 84.0, 126.0, 43.0, 47.0, 72.0, 125.0, 27.0, 13.0, 30.0, 34.0, 57.0, 66.0, 48.0, 84.0, 59.0, 75.0, 12.0, 1.0, 65.0, 51.0, 3.0, 3.0, 83.0, 55.0, 4.0, 6.0, 10.0, 11.0, 105.0, 37.0, 45.0, 41.0, 99.0, 78.0, 1.0, 2.0, 76.0, 88.0, 65.0, 68.0, 12.0, 13.0, 2.0, 4.0, 3.0, 15.0, 49.0, 46.0, 30.0, 25.0, 7.0, 66.0, 64.0, 60.0, 9.0, 9.0, 5.0, 10.0, 98.0, 106.0, 0.0, 16.0, 6.0, 3.0, 7.0, 1.0, 45.0, 40.0, 6.0, 11.0, 3.0, 37.0, 2.0, 12.0, 27.0, 24.0, 2.0, 6.0, 21.0, 28.0, 4.0, 3.0, 4.0, 11.0, 2.0, 23.0, 1.0, 0.0, 16.0, 22.0, 31.0, 33.0, 4.0, 13.0, 15.0, 21.0, 59.0, 51.0, 49.0, 42.0, 14.0, 18.0, 5.0, 15.0, 7.0, 7.0, 37.0, 35.0, 10.0, 6.0, 0.0, 2.0, 27.0, 27.0, 1.0, 20.0, 7.0, 9.0, 9.0, 5.0, 3.0, 0.0, 16.0, 9.0, 22.0, 23.0, 11.0, 4.0, 9.0, 15.0, 53.0, 47.0, 6.0, 6.0, 43.0, 40.0, 36.0, 20.0, 12.0, 18.0, 42.0, 2.0, 15.0, 29.0, 16.0, 12.0, 15.0, 19.0, 13.0, 17.0, 8.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5854689330596549, "mean_inference_ms": 1.8139610750511013, "mean_action_processing_ms": 0.253406486099926, "mean_env_wait_ms": 0.1960483211705187, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0038268566131591797, "StateBufferConnector_ms": 0.003145575523376465, "ViewRequirementAgentConnector_ms": 0.09967601299285889}, "num_episodes": 18, "episode_return_max": 42.70000000000034, "episode_return_min": -395.09999999999957, "episode_return_mean": -14.657999999999907, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2416000, "num_agent_steps_trained": 2416000, "num_env_steps_sampled": 604000, "num_env_steps_trained": 604000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 341.0965255160175, "num_env_steps_trained_throughput_per_sec": 341.0965255160175, "timesteps_total": 604000, "num_env_steps_sampled_lifetime": 604000, "num_agent_steps_sampled_lifetime": 2416000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2416000, "timers": {"training_iteration_time_ms": 11001.309, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11001.254, "sample_time_ms": 1346.188, "learn_time_ms": 9638.838, "learn_throughput": 414.988, "synch_weights_time_ms": 14.586}, "counters": {"num_env_steps_sampled": 604000, "num_env_steps_trained": 604000, "num_agent_steps_sampled": 2416000, "num_agent_steps_trained": 2416000}, "done": false, "training_iteration": 151, "trial_id": "3dae5_00000", "date": "2024-08-14_09-34-39", "timestamp": 1723642479, "time_this_iter_s": 11.760984182357788, "time_total_s": 3296.636424779892, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b384ef70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3296.636424779892, "iterations_since_restore": 151, "perf": {"cpu_util_percent": 37.2375, "ram_util_percent": 83.50625}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.898562436791324, "cur_kl_coeff": 5.21421432495117e-05, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.4639239658123602, "policy_loss": -0.0042674124566099, "vf_loss": 1.468190892537435, "vf_explained_var": 0.024139202555651388, "kl": 0.0092538767741319, "entropy": 0.8543409083255384, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 286335.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.9284713642622426, "cur_kl_coeff": 0.047460937500000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.7461952468705555, "policy_loss": -0.008335471706509235, "vf_loss": 1.7542452821655878, "vf_explained_var": 0.2050138587674136, "kl": 0.0060140724993103176, "entropy": 0.9594732554501326, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 286335.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 608000, "num_env_steps_trained": 608000, "num_agent_steps_sampled": 2432000, "num_agent_steps_trained": 2432000}, "env_runners": {"episode_reward_max": 52.400000000000276, "episode_reward_min": -395.09999999999957, "episode_reward_mean": -3.0089999999998707, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -313.9000000000001, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 32.00000000000013, "predator_policy": 126.0}, "policy_reward_mean": {"prey_policy": -27.509500000000052, "predator_policy": 26.005}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-59.69999999999965, 1.4732659536775827e-13, -83.90000000000012, -35.8999999999999, -395.09999999999957, 35.90000000000032, -11.499999999999869, -57.499999999999865, -71.5999999999999, -136.8, 25.70000000000007, -131.7, 40.60000000000031, -84.50000000000034, 29.000000000000124, 16.900000000000002, -70.5999999999998, -23.09999999999996, -205.10000000000105, 38.80000000000028, -54.299999999999606, -45.39999999999983, 37.700000000000266, 33.4000000000002, 27.4000000000001, -26.699999999999555, -60.40000000000151, -40.29999999999979, -16.599999999999845, 20.200000000000006, 31.900000000000183, -272.5999999999998, 22.400000000000013, 42.70000000000034, 36.900000000000226, 9.799999999999935, 21.3, -31.299999999999507, 12.900000000000043, 15.399999999999913, 35.40000000000023, 7.1000000000000565, 34.100000000000215, 26.200000000000077, 12.499999999999929, 38.90000000000028, 6.600000000000051, 36.500000000000256, 27.90000000000011, 23.500000000000032, -15.899999999999718, -6.999999999999988, 42.30000000000029, 17.999999999999996, 27.300000000000086, 18.699999999999957, 27.200000000000095, 42.30000000000036, -0.4999999999997715, 35.80000000000023, 20.3, 35.10000000000023, 36.70000000000025, 25.100000000000062, 35.500000000000234, 15.100000000000021, 20.800000000000008, -17.499999999999552, 39.40000000000029, 3.3000000000001664, -20.399999999999537, 18.099999999999948, -5.699999999999704, 31.500000000000387, 9.200000000000113, 27.800000000000114, 11.200000000000077, 42.10000000000033, 52.400000000000276, 10.899999999999979, -5.099999999999806, 30.100000000000147, 28.300000000000132, -3.7999999999997027, 20.799999999999994, 31.500000000000178, 48.800000000000246, -1.8999999999997437, 4.300000000000123, 24.500000000000053, -94.4000000000004, -2.199999999999562, 51.00000000000051, 34.70000000000022, -1.7999999999997294, 37.70000000000027, 32.9000000000002, 38.70000000000027, 10.30000000000008, 2.6000000000000716], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, -204.70000000000033, -57.69999999999978, 13.699999999999964, 20.000000000000014, -313.9000000000001, -135.4000000000001, 9.499999999999964, -295.0000000000002, -297.10000000000025, -24.099999999999966, 20.000000000000014, -93.4000000000004, 17.899999999999988, -190.00000000000014, 9.499999999999964, -204.70000000000024, 1.0999999999999865, -198.4000000000003, -72.39999999999992, 17.899999999999988, -5.1999999999999265, -158.50000000000034, -89.20000000000002, 13.699999999999964, 20.900000000000027, -234.10000000000016, 11.599999999999964, 7.399999999999965, 11.599999999999964, -3.099999999999958, -0.9999999999999846, -205.30000000000013, -7.299999999999891, -129.10000000000005, 20.000000000000014, -255.10000000000034, -127.00000000000068, 20.000000000000014, 15.799999999999963, 1.0999999999999865, -219.40000000000032, 17.899999999999988, -196.30000000000018, 20.000000000000014, -7.299999999999891, 11.599999999999964, 15.799999999999963, -10.599999999999836, 20.000000000000014, -114.40000000000055, -7.299999999999901, -57.70000000000041, -57.70000000000042, -118.60000000000076, 5.299999999999965, 20.000000000000014, -160.6000000000006, 1.0999999999999865, 1.0999999999999865, 1.0999999999999865, 15.799999999999962, -297.10000000000014, -179.50000000000054, 20.000000000000014, -13.599999999999783, 7.399999999999965, 26.300000000000114, 7.0999999999999615, 21.80000000000004, -99.7000000000007, 24.50000000000008, 7.399999999999965, -3.099999999999958, -13.599999999999783, -57.70000000000034, 1.3999999999999726, -2.4999999999999716, -34.599999999999774, -0.9999999999999846, 20.000000000000014, 7.399999999999965, 20.000000000000014, -61.900000000000695, 13.699999999999964, 13.399999999999974, 14.299999999999965, -3.099999999999958, 20.000000000000014, -32.499999999999794, 20.000000000000014, 17.899999999999988, 20.000000000000014, -51.399999999999785, 21.800000000000047, -49.299999999999905, -0.7000000000000134, 11.599999999999964, 11.599999999999964, -24.099999999999746, 5.299999999999965, -131.20000000000056, 26.900000000000134, -124.9000000000004, 28.100000000000136, -17.79999999999974, -11.499999999999819, 9.499999999999964, 7.999999999999966, 5.299999999999965, 1.099999999999983, -54.400000000000205, 1.6999999999999729, 9.499999999999964, 20.000000000000014, 20.300000000000008, 5.299999999999965, -59.800000000000594, -3.100000000000001, 17.899999999999988, 3.1999999999999615, 1.0999999999999865, 20.000000000000014, 1.09999999999996, 13.699999999999964, 20.000000000000014, -19.899999999999743, 20.000000000000014, 20.000000000000014, -29.49999999999975, 3.1999999999999615, -3.099999999999958, -4.299999999999958, 1.0999999999999865, -70.30000000000084, -47.19999999999976, 20.000000000000014, 7.399999999999965, 1.099999999999983, -80.80000000000085, -47.19999999999977, -29.19999999999977, -17.199999999999747, 5.299999999999965, 15.799999999999963, -65.50000000000088, 20.000000000000014, -32.49999999999984, -5.1999999999999265, -13.599999999999783, 9.49999999999997, -15.699999999999747, -3.099999999999958, -15.699999999999747, 29.90000000000018, 3.1999999999999615, 20.000000000000014, 28.40000000000005, 20.000000000000014, -66.10000000000085, 5.299999999999965, -51.39999999999988, 1.0999999999999759, 20.000000000000014, -7.299999999999919, 5.599999999999968, -19.899999999999743, -19.899999999999743, -68.2000000000009, 20.000000000000014, 5.299999999999965, -17.79999999999975, -5.1999999999999265, 32.00000000000013, -53.50000000000009, -9.399999999999855, -78.70000000000087, 20.000000000000014, -19.899999999999743, 7.399999999999968, -4.299999999999944, -213.1000000000004, -87.10000000000083, 23.89999999999997, 17.899999999999988, 28.1000000000002, 20.000000000000014, -28.29999999999975, -40.89999999999976, 1.0999999999999865, 9.49999999999998, 3.1999999999999615, 20.000000000000014, -3.099999999999958, 22.40000000000005, 5.299999999999965, -28.29999999999975, 11.599999999999964, -38.799999999999756, 7.399999999999965], "policy_predator_policy_reward": [74.0, 51.0, 26.0, 18.0, 84.0, 126.0, 43.0, 47.0, 72.0, 125.0, 27.0, 13.0, 30.0, 34.0, 57.0, 66.0, 48.0, 84.0, 59.0, 75.0, 12.0, 1.0, 65.0, 51.0, 3.0, 3.0, 83.0, 55.0, 4.0, 6.0, 10.0, 11.0, 105.0, 37.0, 45.0, 41.0, 99.0, 78.0, 1.0, 2.0, 76.0, 88.0, 65.0, 68.0, 12.0, 13.0, 2.0, 4.0, 3.0, 15.0, 49.0, 46.0, 30.0, 25.0, 7.0, 66.0, 64.0, 60.0, 9.0, 9.0, 5.0, 10.0, 98.0, 106.0, 0.0, 16.0, 6.0, 3.0, 7.0, 1.0, 45.0, 40.0, 6.0, 11.0, 3.0, 37.0, 2.0, 12.0, 27.0, 24.0, 2.0, 6.0, 21.0, 28.0, 4.0, 3.0, 4.0, 11.0, 2.0, 23.0, 1.0, 0.0, 16.0, 22.0, 31.0, 33.0, 4.0, 13.0, 15.0, 21.0, 59.0, 51.0, 49.0, 42.0, 14.0, 18.0, 5.0, 15.0, 7.0, 7.0, 37.0, 35.0, 10.0, 6.0, 0.0, 2.0, 27.0, 27.0, 1.0, 20.0, 7.0, 9.0, 9.0, 5.0, 3.0, 0.0, 16.0, 9.0, 22.0, 23.0, 11.0, 4.0, 9.0, 15.0, 53.0, 47.0, 6.0, 6.0, 43.0, 40.0, 36.0, 20.0, 12.0, 18.0, 42.0, 2.0, 15.0, 29.0, 16.0, 12.0, 15.0, 19.0, 13.0, 17.0, 8.0, 1.0, 2.0, 2.0, 27.0, 30.0, 5.0, 36.0, 9.0, 0.0, 20.0, 10.0, 18.0, 18.0, 41.0, 28.0, 22.0, 22.0, 10.0, 12.0, 31.0, 30.0, 47.0, 16.0, 18.0, 19.0, 111.0, 12.0, 12.0, 49.0, 1.0, 4.0, 21.0, 22.0, 29.0, 9.0, 11.0, 14.0, 5.0, 11.0, 7.0, 4.0, 4.0, 23.0, 28.0, 6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5856234992848001, "mean_inference_ms": 1.814850771907624, "mean_action_processing_ms": 0.25338049548358765, "mean_env_wait_ms": 0.19617377701065009, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004019379615783691, "StateBufferConnector_ms": 0.0032917261123657227, "ViewRequirementAgentConnector_ms": 0.10472679138183594}, "num_episodes": 22, "episode_return_max": 52.400000000000276, "episode_return_min": -395.09999999999957, "episode_return_mean": -3.0089999999998707, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2432000, "num_agent_steps_trained": 2432000, "num_env_steps_sampled": 608000, "num_env_steps_trained": 608000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 368.61277071141745, "num_env_steps_trained_throughput_per_sec": 368.61277071141745, "timesteps_total": 608000, "num_env_steps_sampled_lifetime": 608000, "num_agent_steps_sampled_lifetime": 2432000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2432000, "timers": {"training_iteration_time_ms": 11033.058, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11033.004, "sample_time_ms": 1352.512, "learn_time_ms": 9664.017, "learn_throughput": 413.907, "synch_weights_time_ms": 14.833}, "counters": {"num_env_steps_sampled": 608000, "num_env_steps_trained": 608000, "num_agent_steps_sampled": 2432000, "num_agent_steps_trained": 2432000}, "done": false, "training_iteration": 152, "trial_id": "3dae5_00000", "date": "2024-08-14_09-34-50", "timestamp": 1723642490, "time_this_iter_s": 10.857605695724487, "time_total_s": 3307.4940304756165, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b38b6160>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3307.4940304756165, "iterations_since_restore": 152, "perf": {"cpu_util_percent": 31.656250000000004, "ram_util_percent": 83.575}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6664331181654854, "cur_kl_coeff": 5.21421432495117e-05, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.7461977648671972, "policy_loss": -0.0073898646369497615, "vf_loss": 0.7535870341948732, "vf_explained_var": 0.09769582300589828, "kl": 0.011388266703692121, "entropy": 0.9173663986738396, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 288225.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.3743411792176112, "cur_kl_coeff": 0.047460937500000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.6901254887663064, "policy_loss": -0.009623062878443056, "vf_loss": 0.6996102260928305, "vf_explained_var": 0.42696874734585877, "kl": 0.0029145144005505576, "entropy": 0.9811040650915217, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 288225.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 612000, "num_env_steps_trained": 612000, "num_agent_steps_sampled": 2448000, "num_agent_steps_trained": 2448000}, "env_runners": {"episode_reward_max": 52.400000000000276, "episode_reward_min": -272.5999999999998, "episode_reward_mean": 11.010000000000137, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -297.10000000000014, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 32.00000000000013, "predator_policy": 111.0}, "policy_reward_mean": {"prey_policy": -15.175000000000045, "predator_policy": 20.68}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-205.10000000000105, 38.80000000000028, -54.299999999999606, -45.39999999999983, 37.700000000000266, 33.4000000000002, 27.4000000000001, -26.699999999999555, -60.40000000000151, -40.29999999999979, -16.599999999999845, 20.200000000000006, 31.900000000000183, -272.5999999999998, 22.400000000000013, 42.70000000000034, 36.900000000000226, 9.799999999999935, 21.3, -31.299999999999507, 12.900000000000043, 15.399999999999913, 35.40000000000023, 7.1000000000000565, 34.100000000000215, 26.200000000000077, 12.499999999999929, 38.90000000000028, 6.600000000000051, 36.500000000000256, 27.90000000000011, 23.500000000000032, -15.899999999999718, -6.999999999999988, 42.30000000000029, 17.999999999999996, 27.300000000000086, 18.699999999999957, 27.200000000000095, 42.30000000000036, -0.4999999999997715, 35.80000000000023, 20.3, 35.10000000000023, 36.70000000000025, 25.100000000000062, 35.500000000000234, 15.100000000000021, 20.800000000000008, -17.499999999999552, 39.40000000000029, 3.3000000000001664, -20.399999999999537, 18.099999999999948, -5.699999999999704, 31.500000000000387, 9.200000000000113, 27.800000000000114, 11.200000000000077, 42.10000000000033, 52.400000000000276, 10.899999999999979, -5.099999999999806, 30.100000000000147, 28.300000000000132, -3.7999999999997027, 20.799999999999994, 31.500000000000178, 48.800000000000246, -1.8999999999997437, 4.300000000000123, 24.500000000000053, -94.4000000000004, -2.199999999999562, 51.00000000000051, 34.70000000000022, -1.7999999999997294, 37.70000000000027, 32.9000000000002, 38.70000000000027, 10.30000000000008, 2.6000000000000716, 14.099999999999941, 33.3000000000002, 14.000000000000004, 29.000000000000128, -13.099999999999557, 16.799999999999923, -9.999999999999632, 32.30000000000019, 22.80000000000003, 15.000000000000021, 37.50000000000026, 40.200000000000294, 32.10000000000018, 19.89999999999998, 13.300000000000013, 18.40000000000001, 33.2000000000002, 39.30000000000029], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-255.10000000000034, -127.00000000000068, 20.000000000000014, 15.799999999999963, 1.0999999999999865, -219.40000000000032, 17.899999999999988, -196.30000000000018, 20.000000000000014, -7.299999999999891, 11.599999999999964, 15.799999999999963, -10.599999999999836, 20.000000000000014, -114.40000000000055, -7.299999999999901, -57.70000000000041, -57.70000000000042, -118.60000000000076, 5.299999999999965, 20.000000000000014, -160.6000000000006, 1.0999999999999865, 1.0999999999999865, 1.0999999999999865, 15.799999999999962, -297.10000000000014, -179.50000000000054, 20.000000000000014, -13.599999999999783, 7.399999999999965, 26.300000000000114, 7.0999999999999615, 21.80000000000004, -99.7000000000007, 24.50000000000008, 7.399999999999965, -3.099999999999958, -13.599999999999783, -57.70000000000034, 1.3999999999999726, -2.4999999999999716, -34.599999999999774, -0.9999999999999846, 20.000000000000014, 7.399999999999965, 20.000000000000014, -61.900000000000695, 13.699999999999964, 13.399999999999974, 14.299999999999965, -3.099999999999958, 20.000000000000014, -32.499999999999794, 20.000000000000014, 17.899999999999988, 20.000000000000014, -51.399999999999785, 21.800000000000047, -49.299999999999905, -0.7000000000000134, 11.599999999999964, 11.599999999999964, -24.099999999999746, 5.299999999999965, -131.20000000000056, 26.900000000000134, -124.9000000000004, 28.100000000000136, -17.79999999999974, -11.499999999999819, 9.499999999999964, 7.999999999999966, 5.299999999999965, 1.099999999999983, -54.400000000000205, 1.6999999999999729, 9.499999999999964, 20.000000000000014, 20.300000000000008, 5.299999999999965, -59.800000000000594, -3.100000000000001, 17.899999999999988, 3.1999999999999615, 1.0999999999999865, 20.000000000000014, 1.09999999999996, 13.699999999999964, 20.000000000000014, -19.899999999999743, 20.000000000000014, 20.000000000000014, -29.49999999999975, 3.1999999999999615, -3.099999999999958, -4.299999999999958, 1.0999999999999865, -70.30000000000084, -47.19999999999976, 20.000000000000014, 7.399999999999965, 1.099999999999983, -80.80000000000085, -47.19999999999977, -29.19999999999977, -17.199999999999747, 5.299999999999965, 15.799999999999963, -65.50000000000088, 20.000000000000014, -32.49999999999984, -5.1999999999999265, -13.599999999999783, 9.49999999999997, -15.699999999999747, -3.099999999999958, -15.699999999999747, 29.90000000000018, 3.1999999999999615, 20.000000000000014, 28.40000000000005, 20.000000000000014, -66.10000000000085, 5.299999999999965, -51.39999999999988, 1.0999999999999759, 20.000000000000014, -7.299999999999919, 5.599999999999968, -19.899999999999743, -19.899999999999743, -68.2000000000009, 20.000000000000014, 5.299999999999965, -17.79999999999975, -5.1999999999999265, 32.00000000000013, -53.50000000000009, -9.399999999999855, -78.70000000000087, 20.000000000000014, -19.899999999999743, 7.399999999999968, -4.299999999999944, -213.1000000000004, -87.10000000000083, 23.89999999999997, 17.899999999999988, 28.1000000000002, 20.000000000000014, -28.29999999999975, -40.89999999999976, 1.0999999999999865, 9.49999999999998, 3.1999999999999615, 20.000000000000014, -3.099999999999958, 22.40000000000005, 5.299999999999965, -28.29999999999975, 11.599999999999964, -38.799999999999756, 7.399999999999965, 13.099999999999971, -42.99999999999976, 20.000000000000014, 5.299999999999965, -42.999999999999766, -0.9999999999999846, -0.9999999999999846, 20.000000000000014, -59.80000000000062, -7.299999999999912, -64.30000000000089, 10.099999999999966, -95.50000000000082, 9.499999999999964, 2.2999999999999607, -0.9999999999999846, -45.099999999999824, -3.099999999999958, 1.0999999999999865, -3.099999999999958, 6.499999999999968, 20.000000000000014, 1.9999999999999607, 3.1999999999999615, 3.1999999999999615, 17.899999999999988, -9.399999999999855, 5.299999999999965, -5.1999999999999265, -50.49999999999998, 5.299999999999965, 1.0999999999999865, 5.299999999999965, 11.89999999999997, 21.80000000000004, 9.499999999999964], "policy_predator_policy_reward": [99.0, 78.0, 1.0, 2.0, 76.0, 88.0, 65.0, 68.0, 12.0, 13.0, 2.0, 4.0, 3.0, 15.0, 49.0, 46.0, 30.0, 25.0, 7.0, 66.0, 64.0, 60.0, 9.0, 9.0, 5.0, 10.0, 98.0, 106.0, 0.0, 16.0, 6.0, 3.0, 7.0, 1.0, 45.0, 40.0, 6.0, 11.0, 3.0, 37.0, 2.0, 12.0, 27.0, 24.0, 2.0, 6.0, 21.0, 28.0, 4.0, 3.0, 4.0, 11.0, 2.0, 23.0, 1.0, 0.0, 16.0, 22.0, 31.0, 33.0, 4.0, 13.0, 15.0, 21.0, 59.0, 51.0, 49.0, 42.0, 14.0, 18.0, 5.0, 15.0, 7.0, 7.0, 37.0, 35.0, 10.0, 6.0, 0.0, 2.0, 27.0, 27.0, 1.0, 20.0, 7.0, 9.0, 9.0, 5.0, 3.0, 0.0, 16.0, 9.0, 22.0, 23.0, 11.0, 4.0, 9.0, 15.0, 53.0, 47.0, 6.0, 6.0, 43.0, 40.0, 36.0, 20.0, 12.0, 18.0, 42.0, 2.0, 15.0, 29.0, 16.0, 12.0, 15.0, 19.0, 13.0, 17.0, 8.0, 1.0, 2.0, 2.0, 27.0, 30.0, 5.0, 36.0, 9.0, 0.0, 20.0, 10.0, 18.0, 18.0, 41.0, 28.0, 22.0, 22.0, 10.0, 12.0, 31.0, 30.0, 47.0, 16.0, 18.0, 19.0, 111.0, 12.0, 12.0, 49.0, 1.0, 4.0, 21.0, 22.0, 29.0, 9.0, 11.0, 14.0, 5.0, 11.0, 7.0, 4.0, 4.0, 23.0, 28.0, 6.0, 27.0, 17.0, 1.0, 7.0, 31.0, 27.0, 0.0, 10.0, 38.0, 16.0, 40.0, 31.0, 21.0, 55.0, 14.0, 17.0, 36.0, 35.0, 10.0, 7.0, 4.0, 7.0, 17.0, 18.0, 6.0, 5.0, 11.0, 13.0, 34.0, 35.0, 9.0, 3.0, 7.0, 9.0, 5.0, 3.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5857625566596709, "mean_inference_ms": 1.8155293898016955, "mean_action_processing_ms": 0.2533561327638744, "mean_env_wait_ms": 0.1962830329341314, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004074692726135254, "StateBufferConnector_ms": 0.0033174753189086914, "ViewRequirementAgentConnector_ms": 0.10887789726257324}, "num_episodes": 18, "episode_return_max": 52.400000000000276, "episode_return_min": -272.5999999999998, "episode_return_mean": 11.010000000000137, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2448000, "num_agent_steps_trained": 2448000, "num_env_steps_sampled": 612000, "num_env_steps_trained": 612000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 364.5235167329936, "num_env_steps_trained_throughput_per_sec": 364.5235167329936, "timesteps_total": 612000, "num_env_steps_sampled_lifetime": 612000, "num_agent_steps_sampled_lifetime": 2448000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2448000, "timers": {"training_iteration_time_ms": 11062.308, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11062.252, "sample_time_ms": 1353.345, "learn_time_ms": 9691.749, "learn_throughput": 412.722, "synch_weights_time_ms": 15.339}, "counters": {"num_env_steps_sampled": 612000, "num_env_steps_trained": 612000, "num_agent_steps_sampled": 2448000, "num_agent_steps_trained": 2448000}, "done": false, "training_iteration": 153, "trial_id": "3dae5_00000", "date": "2024-08-14_09-35-01", "timestamp": 1723642501, "time_this_iter_s": 11.021269798278809, "time_total_s": 3318.5153002738953, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b38b63a0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3318.5153002738953, "iterations_since_restore": 153, "perf": {"cpu_util_percent": 30.08125, "ram_util_percent": 83.41874999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8230615961173224, "cur_kl_coeff": 5.21421432495117e-05, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.7133932849559834, "policy_loss": -0.007923694092671943, "vf_loss": 0.721316369370651, "vf_explained_var": 0.08019071028976844, "kl": 0.011704621879464496, "entropy": 0.9526851653737366, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 290115.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.225279079590525, "cur_kl_coeff": 0.023730468750000008, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.559156454087447, "policy_loss": -0.00785124669117587, "vf_loss": 0.56664706689143, "vf_explained_var": 0.38021046465666836, "kl": 0.015197042496934007, "entropy": 0.8997158065674797, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 290115.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 616000, "num_env_steps_trained": 616000, "num_agent_steps_sampled": 2464000, "num_agent_steps_trained": 2464000}, "env_runners": {"episode_reward_max": 52.400000000000276, "episode_reward_min": -94.4000000000004, "episode_reward_mean": 19.12500000000016, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -213.1000000000004, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 32.00000000000013, "predator_policy": 111.0}, "policy_reward_mean": {"prey_policy": -7.41250000000002, "predator_policy": 16.975}, "custom_metrics": {}, "hist_stats": {"episode_reward": [21.3, -31.299999999999507, 12.900000000000043, 15.399999999999913, 35.40000000000023, 7.1000000000000565, 34.100000000000215, 26.200000000000077, 12.499999999999929, 38.90000000000028, 6.600000000000051, 36.500000000000256, 27.90000000000011, 23.500000000000032, -15.899999999999718, -6.999999999999988, 42.30000000000029, 17.999999999999996, 27.300000000000086, 18.699999999999957, 27.200000000000095, 42.30000000000036, -0.4999999999997715, 35.80000000000023, 20.3, 35.10000000000023, 36.70000000000025, 25.100000000000062, 35.500000000000234, 15.100000000000021, 20.800000000000008, -17.499999999999552, 39.40000000000029, 3.3000000000001664, -20.399999999999537, 18.099999999999948, -5.699999999999704, 31.500000000000387, 9.200000000000113, 27.800000000000114, 11.200000000000077, 42.10000000000033, 52.400000000000276, 10.899999999999979, -5.099999999999806, 30.100000000000147, 28.300000000000132, -3.7999999999997027, 20.799999999999994, 31.500000000000178, 48.800000000000246, -1.8999999999997437, 4.300000000000123, 24.500000000000053, -94.4000000000004, -2.199999999999562, 51.00000000000051, 34.70000000000022, -1.7999999999997294, 37.70000000000027, 32.9000000000002, 38.70000000000027, 10.30000000000008, 2.6000000000000716, 14.099999999999941, 33.3000000000002, 14.000000000000004, 29.000000000000128, -13.099999999999557, 16.799999999999923, -9.999999999999632, 32.30000000000019, 22.80000000000003, 15.000000000000021, 37.50000000000026, 40.200000000000294, 32.10000000000018, 19.89999999999998, 13.300000000000013, 18.40000000000001, 33.2000000000002, 39.30000000000029, 14.600000000000023, 32.80000000000019, 28.300000000000114, 37.90000000000027, 33.000000000000206, 31.200000000000166, 29.000000000000124, -17.29999999999952, 21.299999999999994, 24.600000000000048, 17.699999999999953, 33.4000000000002, 29.600000000000154, 32.30000000000018, -15.099999999999579, -5.099999999999685, 51.70000000000041, 11.400000000000077], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [7.399999999999965, -3.099999999999958, -13.599999999999783, -57.70000000000034, 1.3999999999999726, -2.4999999999999716, -34.599999999999774, -0.9999999999999846, 20.000000000000014, 7.399999999999965, 20.000000000000014, -61.900000000000695, 13.699999999999964, 13.399999999999974, 14.299999999999965, -3.099999999999958, 20.000000000000014, -32.499999999999794, 20.000000000000014, 17.899999999999988, 20.000000000000014, -51.399999999999785, 21.800000000000047, -49.299999999999905, -0.7000000000000134, 11.599999999999964, 11.599999999999964, -24.099999999999746, 5.299999999999965, -131.20000000000056, 26.900000000000134, -124.9000000000004, 28.100000000000136, -17.79999999999974, -11.499999999999819, 9.499999999999964, 7.999999999999966, 5.299999999999965, 1.099999999999983, -54.400000000000205, 1.6999999999999729, 9.499999999999964, 20.000000000000014, 20.300000000000008, 5.299999999999965, -59.800000000000594, -3.100000000000001, 17.899999999999988, 3.1999999999999615, 1.0999999999999865, 20.000000000000014, 1.09999999999996, 13.699999999999964, 20.000000000000014, -19.899999999999743, 20.000000000000014, 20.000000000000014, -29.49999999999975, 3.1999999999999615, -3.099999999999958, -4.299999999999958, 1.0999999999999865, -70.30000000000084, -47.19999999999976, 20.000000000000014, 7.399999999999965, 1.099999999999983, -80.80000000000085, -47.19999999999977, -29.19999999999977, -17.199999999999747, 5.299999999999965, 15.799999999999963, -65.50000000000088, 20.000000000000014, -32.49999999999984, -5.1999999999999265, -13.599999999999783, 9.49999999999997, -15.699999999999747, -3.099999999999958, -15.699999999999747, 29.90000000000018, 3.1999999999999615, 20.000000000000014, 28.40000000000005, 20.000000000000014, -66.10000000000085, 5.299999999999965, -51.39999999999988, 1.0999999999999759, 20.000000000000014, -7.299999999999919, 5.599999999999968, -19.899999999999743, -19.899999999999743, -68.2000000000009, 20.000000000000014, 5.299999999999965, -17.79999999999975, -5.1999999999999265, 32.00000000000013, -53.50000000000009, -9.399999999999855, -78.70000000000087, 20.000000000000014, -19.899999999999743, 7.399999999999968, -4.299999999999944, -213.1000000000004, -87.10000000000083, 23.89999999999997, 17.899999999999988, 28.1000000000002, 20.000000000000014, -28.29999999999975, -40.89999999999976, 1.0999999999999865, 9.49999999999998, 3.1999999999999615, 20.000000000000014, -3.099999999999958, 22.40000000000005, 5.299999999999965, -28.29999999999975, 11.599999999999964, -38.799999999999756, 7.399999999999965, 13.099999999999971, -42.99999999999976, 20.000000000000014, 5.299999999999965, -42.999999999999766, -0.9999999999999846, -0.9999999999999846, 20.000000000000014, -59.80000000000062, -7.299999999999912, -64.30000000000089, 10.099999999999966, -95.50000000000082, 9.499999999999964, 2.2999999999999607, -0.9999999999999846, -45.099999999999824, -3.099999999999958, 1.0999999999999865, -3.099999999999958, 6.499999999999968, 20.000000000000014, 1.9999999999999607, 3.1999999999999615, 3.1999999999999615, 17.899999999999988, -9.399999999999855, 5.299999999999965, -5.1999999999999265, -50.49999999999998, 5.299999999999965, 1.0999999999999865, 5.299999999999965, 11.89999999999997, 21.80000000000004, 9.499999999999964, -15.699999999999747, 5.299999999999965, 14.299999999999965, 9.499999999999964, 9.499999999999964, -5.1999999999999265, -3.099999999999958, 20.000000000000014, -36.69999999999977, 13.699999999999964, 17.899999999999988, 5.299999999999965, 1.0999999999999865, 17.899999999999988, -21.999999999999744, -70.30000000000089, -11.499999999999819, 15.799999999999963, 3.1999999999999615, 7.399999999999965, 7.399999999999965, -15.699999999999786, 9.499999999999964, 17.899999999999988, -21.999999999999744, 11.599999999999977, 5.299999999999965, 20.000000000000014, 20.000000000000014, -108.10000000000079, -40.89999999999976, -5.1999999999999265, 11.599999999999964, 31.1000000000002, -15.699999999999747, 1.0999999999999865], "policy_predator_policy_reward": [6.0, 11.0, 3.0, 37.0, 2.0, 12.0, 27.0, 24.0, 2.0, 6.0, 21.0, 28.0, 4.0, 3.0, 4.0, 11.0, 2.0, 23.0, 1.0, 0.0, 16.0, 22.0, 31.0, 33.0, 4.0, 13.0, 15.0, 21.0, 59.0, 51.0, 49.0, 42.0, 14.0, 18.0, 5.0, 15.0, 7.0, 7.0, 37.0, 35.0, 10.0, 6.0, 0.0, 2.0, 27.0, 27.0, 1.0, 20.0, 7.0, 9.0, 9.0, 5.0, 3.0, 0.0, 16.0, 9.0, 22.0, 23.0, 11.0, 4.0, 9.0, 15.0, 53.0, 47.0, 6.0, 6.0, 43.0, 40.0, 36.0, 20.0, 12.0, 18.0, 42.0, 2.0, 15.0, 29.0, 16.0, 12.0, 15.0, 19.0, 13.0, 17.0, 8.0, 1.0, 2.0, 2.0, 27.0, 30.0, 5.0, 36.0, 9.0, 0.0, 20.0, 10.0, 18.0, 18.0, 41.0, 28.0, 22.0, 22.0, 10.0, 12.0, 31.0, 30.0, 47.0, 16.0, 18.0, 19.0, 111.0, 12.0, 12.0, 49.0, 1.0, 4.0, 21.0, 22.0, 29.0, 9.0, 11.0, 14.0, 5.0, 11.0, 7.0, 4.0, 4.0, 23.0, 28.0, 6.0, 27.0, 17.0, 1.0, 7.0, 31.0, 27.0, 0.0, 10.0, 38.0, 16.0, 40.0, 31.0, 21.0, 55.0, 14.0, 17.0, 36.0, 35.0, 10.0, 7.0, 4.0, 7.0, 17.0, 18.0, 6.0, 5.0, 11.0, 13.0, 34.0, 35.0, 9.0, 3.0, 7.0, 9.0, 5.0, 3.0, 15.0, 10.0, 4.0, 5.0, 12.0, 12.0, 10.0, 11.0, 26.0, 30.0, 7.0, 1.0, 9.0, 1.0, 42.0, 33.0, 2.0, 15.0, 8.0, 6.0, 23.0, 3.0, 5.0, 1.0, 23.0, 17.0, 7.0, 0.0, 61.0, 12.0, 25.0, 16.0, 5.0, 4.0, 17.0, 9.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5859594576584805, "mean_inference_ms": 1.8162210897724647, "mean_action_processing_ms": 0.2533386788687029, "mean_env_wait_ms": 0.19639115892600784, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004161357879638672, "StateBufferConnector_ms": 0.0033112764358520508, "ViewRequirementAgentConnector_ms": 0.10858428478240967}, "num_episodes": 18, "episode_return_max": 52.400000000000276, "episode_return_min": -94.4000000000004, "episode_return_mean": 19.12500000000016, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2464000, "num_agent_steps_trained": 2464000, "num_env_steps_sampled": 616000, "num_env_steps_trained": 616000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 354.7164459413134, "num_env_steps_trained_throughput_per_sec": 354.7164459413134, "timesteps_total": 616000, "num_env_steps_sampled_lifetime": 616000, "num_agent_steps_sampled_lifetime": 2464000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2464000, "timers": {"training_iteration_time_ms": 11111.957, "restore_workers_time_ms": 0.02, "training_step_time_ms": 11111.886, "sample_time_ms": 1359.499, "learn_time_ms": 9734.896, "learn_throughput": 410.893, "synch_weights_time_ms": 15.119}, "counters": {"num_env_steps_sampled": 616000, "num_env_steps_trained": 616000, "num_agent_steps_sampled": 2464000, "num_agent_steps_trained": 2464000}, "done": false, "training_iteration": 154, "trial_id": "3dae5_00000", "date": "2024-08-14_09-35-12", "timestamp": 1723642512, "time_this_iter_s": 11.331865072250366, "time_total_s": 3329.8471653461456, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3870160>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3329.8471653461456, "iterations_since_restore": 154, "perf": {"cpu_util_percent": 33.875, "ram_util_percent": 83.475}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7977038771702498, "cur_kl_coeff": 5.21421432495117e-05, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.920259576815146, "policy_loss": -0.007416666165073082, "vf_loss": 1.9276758449102835, "vf_explained_var": 0.014152378884572832, "kl": 0.007774367097834556, "entropy": 0.8796971574346856, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 292005.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.4940300047239927, "cur_kl_coeff": 0.023730468750000008, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.2382980051415937, "policy_loss": -0.00958213136043577, "vf_loss": 1.2476320962899576, "vf_explained_var": 0.36683423446599767, "kl": 0.010452444905510732, "entropy": 0.9372024953996063, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 292005.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 620000, "num_env_steps_trained": 620000, "num_agent_steps_sampled": 2480000, "num_agent_steps_trained": 2480000}, "env_runners": {"episode_reward_max": 52.400000000000276, "episode_reward_min": -94.4000000000004, "episode_reward_mean": 19.55500000000015, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -213.1000000000004, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 32.00000000000013, "predator_policy": 111.0}, "policy_reward_mean": {"prey_policy": -8.012500000000014, "predator_policy": 17.79}, "custom_metrics": {}, "hist_stats": {"episode_reward": [35.80000000000023, 20.3, 35.10000000000023, 36.70000000000025, 25.100000000000062, 35.500000000000234, 15.100000000000021, 20.800000000000008, -17.499999999999552, 39.40000000000029, 3.3000000000001664, -20.399999999999537, 18.099999999999948, -5.699999999999704, 31.500000000000387, 9.200000000000113, 27.800000000000114, 11.200000000000077, 42.10000000000033, 52.400000000000276, 10.899999999999979, -5.099999999999806, 30.100000000000147, 28.300000000000132, -3.7999999999997027, 20.799999999999994, 31.500000000000178, 48.800000000000246, -1.8999999999997437, 4.300000000000123, 24.500000000000053, -94.4000000000004, -2.199999999999562, 51.00000000000051, 34.70000000000022, -1.7999999999997294, 37.70000000000027, 32.9000000000002, 38.70000000000027, 10.30000000000008, 2.6000000000000716, 14.099999999999941, 33.3000000000002, 14.000000000000004, 29.000000000000128, -13.099999999999557, 16.799999999999923, -9.999999999999632, 32.30000000000019, 22.80000000000003, 15.000000000000021, 37.50000000000026, 40.200000000000294, 32.10000000000018, 19.89999999999998, 13.300000000000013, 18.40000000000001, 33.2000000000002, 39.30000000000029, 14.600000000000023, 32.80000000000019, 28.300000000000114, 37.90000000000027, 33.000000000000206, 31.200000000000166, 29.000000000000124, -17.29999999999952, 21.299999999999994, 24.600000000000048, 17.699999999999953, 33.4000000000002, 29.600000000000154, 32.30000000000018, -15.099999999999579, -5.099999999999685, 51.70000000000041, 11.400000000000077, 29.40000000000013, 18.79999999999996, 36.50000000000025, 25.4000000000001, 35.20000000000023, 33.5000000000002, 29.000000000000124, 27.800000000000107, -2.899999999999766, 36.30000000000025, 23.30000000000003, 8.400000000000087, 31.300000000000153, 1.5000000000002147, 32.20000000000018, -75.5000000000014, -5.099999999999859, 23.50000000000003, 38.400000000000276, 27.900000000000105, 31.60000000000018, 14.399999999999912, 41.50000000000032], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-3.100000000000001, 17.899999999999988, 3.1999999999999615, 1.0999999999999865, 20.000000000000014, 1.09999999999996, 13.699999999999964, 20.000000000000014, -19.899999999999743, 20.000000000000014, 20.000000000000014, -29.49999999999975, 3.1999999999999615, -3.099999999999958, -4.299999999999958, 1.0999999999999865, -70.30000000000084, -47.19999999999976, 20.000000000000014, 7.399999999999965, 1.099999999999983, -80.80000000000085, -47.19999999999977, -29.19999999999977, -17.199999999999747, 5.299999999999965, 15.799999999999963, -65.50000000000088, 20.000000000000014, -32.49999999999984, -5.1999999999999265, -13.599999999999783, 9.49999999999997, -15.699999999999747, -3.099999999999958, -15.699999999999747, 29.90000000000018, 3.1999999999999615, 20.000000000000014, 28.40000000000005, 20.000000000000014, -66.10000000000085, 5.299999999999965, -51.39999999999988, 1.0999999999999759, 20.000000000000014, -7.299999999999919, 5.599999999999968, -19.899999999999743, -19.899999999999743, -68.2000000000009, 20.000000000000014, 5.299999999999965, -17.79999999999975, -5.1999999999999265, 32.00000000000013, -53.50000000000009, -9.399999999999855, -78.70000000000087, 20.000000000000014, -19.899999999999743, 7.399999999999968, -4.299999999999944, -213.1000000000004, -87.10000000000083, 23.89999999999997, 17.899999999999988, 28.1000000000002, 20.000000000000014, -28.29999999999975, -40.89999999999976, 1.0999999999999865, 9.49999999999998, 3.1999999999999615, 20.000000000000014, -3.099999999999958, 22.40000000000005, 5.299999999999965, -28.29999999999975, 11.599999999999964, -38.799999999999756, 7.399999999999965, 13.099999999999971, -42.99999999999976, 20.000000000000014, 5.299999999999965, -42.999999999999766, -0.9999999999999846, -0.9999999999999846, 20.000000000000014, -59.80000000000062, -7.299999999999912, -64.30000000000089, 10.099999999999966, -95.50000000000082, 9.499999999999964, 2.2999999999999607, -0.9999999999999846, -45.099999999999824, -3.099999999999958, 1.0999999999999865, -3.099999999999958, 6.499999999999968, 20.000000000000014, 1.9999999999999607, 3.1999999999999615, 3.1999999999999615, 17.899999999999988, -9.399999999999855, 5.299999999999965, -5.1999999999999265, -50.49999999999998, 5.299999999999965, 1.0999999999999865, 5.299999999999965, 11.89999999999997, 21.80000000000004, 9.499999999999964, -15.699999999999747, 5.299999999999965, 14.299999999999965, 9.499999999999964, 9.499999999999964, -5.1999999999999265, -3.099999999999958, 20.000000000000014, -36.69999999999977, 13.699999999999964, 17.899999999999988, 5.299999999999965, 1.0999999999999865, 17.899999999999988, -21.999999999999744, -70.30000000000089, -11.499999999999819, 15.799999999999963, 3.1999999999999615, 7.399999999999965, 7.399999999999965, -15.699999999999786, 9.499999999999964, 17.899999999999988, -21.999999999999744, 11.599999999999977, 5.299999999999965, 20.000000000000014, 20.000000000000014, -108.10000000000079, -40.89999999999976, -5.1999999999999265, 11.599999999999964, 31.1000000000002, -15.699999999999747, 1.0999999999999865, -7.299999999999976, 13.699999999999964, -47.19999999999976, 20.000000000000014, 9.499999999999964, 20.000000000000014, -26.19999999999981, 11.599999999999964, 20.000000000000014, -59.80000000000062, -61.90000000000058, 7.399999999999965, 13.699999999999964, 5.299999999999965, -5.1999999999999265, 20.000000000000014, -99.70000000000078, 15.799999999999963, 6.50000000000008, -26.199999999999747, -17.79999999999975, 1.0999999999999865, -20.19999999999976, -30.39999999999975, -36.69999999999987, 20.000000000000014, -40.89999999999976, -13.599999999999783, 20.000000000000014, 3.1999999999999615, -171.10000000000062, -9.399999999999855, -47.19999999999984, 1.0999999999999546, 7.399999999999965, 1.0999999999999865, 20.000000000000014, 7.399999999999965, 1.0999999999999865, 15.799999999999963, -9.399999999999855, 20.000000000000014, -36.699999999999754, -40.899999999999814, 27.20000000000013, 5.299999999999965], "policy_predator_policy_reward": [1.0, 20.0, 7.0, 9.0, 9.0, 5.0, 3.0, 0.0, 16.0, 9.0, 22.0, 23.0, 11.0, 4.0, 9.0, 15.0, 53.0, 47.0, 6.0, 6.0, 43.0, 40.0, 36.0, 20.0, 12.0, 18.0, 42.0, 2.0, 15.0, 29.0, 16.0, 12.0, 15.0, 19.0, 13.0, 17.0, 8.0, 1.0, 2.0, 2.0, 27.0, 30.0, 5.0, 36.0, 9.0, 0.0, 20.0, 10.0, 18.0, 18.0, 41.0, 28.0, 22.0, 22.0, 10.0, 12.0, 31.0, 30.0, 47.0, 16.0, 18.0, 19.0, 111.0, 12.0, 12.0, 49.0, 1.0, 4.0, 21.0, 22.0, 29.0, 9.0, 11.0, 14.0, 5.0, 11.0, 7.0, 4.0, 4.0, 23.0, 28.0, 6.0, 27.0, 17.0, 1.0, 7.0, 31.0, 27.0, 0.0, 10.0, 38.0, 16.0, 40.0, 31.0, 21.0, 55.0, 14.0, 17.0, 36.0, 35.0, 10.0, 7.0, 4.0, 7.0, 17.0, 18.0, 6.0, 5.0, 11.0, 13.0, 34.0, 35.0, 9.0, 3.0, 7.0, 9.0, 5.0, 3.0, 15.0, 10.0, 4.0, 5.0, 12.0, 12.0, 10.0, 11.0, 26.0, 30.0, 7.0, 1.0, 9.0, 1.0, 42.0, 33.0, 2.0, 15.0, 8.0, 6.0, 23.0, 3.0, 5.0, 1.0, 23.0, 17.0, 7.0, 0.0, 61.0, 12.0, 25.0, 16.0, 5.0, 4.0, 17.0, 9.0, 11.0, 12.0, 32.0, 14.0, 5.0, 2.0, 23.0, 17.0, 37.0, 38.0, 43.0, 45.0, 3.0, 7.0, 1.0, 12.0, 49.0, 32.0, 23.0, 33.0, 21.0, 19.0, 29.0, 30.0, 26.0, 22.0, 29.0, 27.0, 8.0, 1.0, 41.0, 64.0, 33.0, 8.0, 9.0, 6.0, 6.0, 5.0, 9.0, 2.0, 14.0, 7.0, 46.0, 46.0, 7.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5863480622032742, "mean_inference_ms": 1.8173407482676145, "mean_action_processing_ms": 0.25334571285336854, "mean_env_wait_ms": 0.19658736814666625, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004184603691101074, "StateBufferConnector_ms": 0.003336191177368164, "ViewRequirementAgentConnector_ms": 0.1104435920715332}, "num_episodes": 23, "episode_return_max": 52.400000000000276, "episode_return_min": -94.4000000000004, "episode_return_mean": 19.55500000000015, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2480000, "num_agent_steps_trained": 2480000, "num_env_steps_sampled": 620000, "num_env_steps_trained": 620000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 371.01342614778383, "num_env_steps_trained_throughput_per_sec": 371.01342614778383, "timesteps_total": 620000, "num_env_steps_sampled_lifetime": 620000, "num_agent_steps_sampled_lifetime": 2480000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2480000, "timers": {"training_iteration_time_ms": 11061.026, "restore_workers_time_ms": 0.021, "training_step_time_ms": 11060.97, "sample_time_ms": 1374.415, "learn_time_ms": 9670.857, "learn_throughput": 413.614, "synch_weights_time_ms": 13.982}, "counters": {"num_env_steps_sampled": 620000, "num_env_steps_trained": 620000, "num_agent_steps_sampled": 2480000, "num_agent_steps_trained": 2480000}, "done": false, "training_iteration": 155, "trial_id": "3dae5_00000", "date": "2024-08-14_09-35-23", "timestamp": 1723642523, "time_this_iter_s": 10.785922050476074, "time_total_s": 3340.6330873966217, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3870ee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3340.6330873966217, "iterations_since_restore": 155, "perf": {"cpu_util_percent": 30.206666666666667, "ram_util_percent": 83.38666666666664}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6190793227424067, "cur_kl_coeff": 5.21421432495117e-05, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.1147073458742214, "policy_loss": -0.00650980699814797, "vf_loss": 2.1212166811423327, "vf_explained_var": 0.04654792692295458, "kl": 0.00899511276803553, "entropy": 0.8722232775713401, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 293895.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.157448302469556, "cur_kl_coeff": 0.023730468750000008, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.4656103074392945, "policy_loss": -0.012122303903689263, "vf_loss": 1.4774811947156512, "vf_explained_var": 0.38503731504949945, "kl": 0.01059489937270231, "entropy": 0.839178220210252, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 293895.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 624000, "num_env_steps_trained": 624000, "num_agent_steps_sampled": 2496000, "num_agent_steps_trained": 2496000}, "env_runners": {"episode_reward_max": 51.70000000000041, "episode_reward_min": -94.4000000000004, "episode_reward_mean": 19.930000000000142, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -213.1000000000004, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 32.00000000000013, "predator_policy": 111.0}, "policy_reward_mean": {"prey_policy": -8.065000000000015, "predator_policy": 18.03}, "custom_metrics": {}, "hist_stats": {"episode_reward": [30.100000000000147, 28.300000000000132, -3.7999999999997027, 20.799999999999994, 31.500000000000178, 48.800000000000246, -1.8999999999997437, 4.300000000000123, 24.500000000000053, -94.4000000000004, -2.199999999999562, 51.00000000000051, 34.70000000000022, -1.7999999999997294, 37.70000000000027, 32.9000000000002, 38.70000000000027, 10.30000000000008, 2.6000000000000716, 14.099999999999941, 33.3000000000002, 14.000000000000004, 29.000000000000128, -13.099999999999557, 16.799999999999923, -9.999999999999632, 32.30000000000019, 22.80000000000003, 15.000000000000021, 37.50000000000026, 40.200000000000294, 32.10000000000018, 19.89999999999998, 13.300000000000013, 18.40000000000001, 33.2000000000002, 39.30000000000029, 14.600000000000023, 32.80000000000019, 28.300000000000114, 37.90000000000027, 33.000000000000206, 31.200000000000166, 29.000000000000124, -17.29999999999952, 21.299999999999994, 24.600000000000048, 17.699999999999953, 33.4000000000002, 29.600000000000154, 32.30000000000018, -15.099999999999579, -5.099999999999685, 51.70000000000041, 11.400000000000077, 29.40000000000013, 18.79999999999996, 36.50000000000025, 25.4000000000001, 35.20000000000023, 33.5000000000002, 29.000000000000124, 27.800000000000107, -2.899999999999766, 36.30000000000025, 23.30000000000003, 8.400000000000087, 31.300000000000153, 1.5000000000002147, 32.20000000000018, -75.5000000000014, -5.099999999999859, 23.50000000000003, 38.400000000000276, 27.900000000000105, 31.60000000000018, 14.399999999999912, 41.50000000000032, 42.10000000000033, 30.80000000000016, 12.899999999999942, 36.200000000000244, 12.799999999999924, -8.399999999999674, -2.4999999999998685, -61.79999999999996, 29.200000000000152, 5.600000000000122, 30.000000000000142, 27.900000000000105, 32.20000000000019, 30.20000000000016, 33.70000000000021, 38.90000000000028, 33.400000000000205, 34.40000000000022, 12.500000000000059, 23.000000000000036, 46.1000000000004, 19.89999999999998], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [1.0999999999999759, 20.000000000000014, -7.299999999999919, 5.599999999999968, -19.899999999999743, -19.899999999999743, -68.2000000000009, 20.000000000000014, 5.299999999999965, -17.79999999999975, -5.1999999999999265, 32.00000000000013, -53.50000000000009, -9.399999999999855, -78.70000000000087, 20.000000000000014, -19.899999999999743, 7.399999999999968, -4.299999999999944, -213.1000000000004, -87.10000000000083, 23.89999999999997, 17.899999999999988, 28.1000000000002, 20.000000000000014, -28.29999999999975, -40.89999999999976, 1.0999999999999865, 9.49999999999998, 3.1999999999999615, 20.000000000000014, -3.099999999999958, 22.40000000000005, 5.299999999999965, -28.29999999999975, 11.599999999999964, -38.799999999999756, 7.399999999999965, 13.099999999999971, -42.99999999999976, 20.000000000000014, 5.299999999999965, -42.999999999999766, -0.9999999999999846, -0.9999999999999846, 20.000000000000014, -59.80000000000062, -7.299999999999912, -64.30000000000089, 10.099999999999966, -95.50000000000082, 9.499999999999964, 2.2999999999999607, -0.9999999999999846, -45.099999999999824, -3.099999999999958, 1.0999999999999865, -3.099999999999958, 6.499999999999968, 20.000000000000014, 1.9999999999999607, 3.1999999999999615, 3.1999999999999615, 17.899999999999988, -9.399999999999855, 5.299999999999965, -5.1999999999999265, -50.49999999999998, 5.299999999999965, 1.0999999999999865, 5.299999999999965, 11.89999999999997, 21.80000000000004, 9.499999999999964, -15.699999999999747, 5.299999999999965, 14.299999999999965, 9.499999999999964, 9.499999999999964, -5.1999999999999265, -3.099999999999958, 20.000000000000014, -36.69999999999977, 13.699999999999964, 17.899999999999988, 5.299999999999965, 1.0999999999999865, 17.899999999999988, -21.999999999999744, -70.30000000000089, -11.499999999999819, 15.799999999999963, 3.1999999999999615, 7.399999999999965, 7.399999999999965, -15.699999999999786, 9.499999999999964, 17.899999999999988, -21.999999999999744, 11.599999999999977, 5.299999999999965, 20.000000000000014, 20.000000000000014, -108.10000000000079, -40.89999999999976, -5.1999999999999265, 11.599999999999964, 31.1000000000002, -15.699999999999747, 1.0999999999999865, -7.299999999999976, 13.699999999999964, -47.19999999999976, 20.000000000000014, 9.499999999999964, 20.000000000000014, -26.19999999999981, 11.599999999999964, 20.000000000000014, -59.80000000000062, -61.90000000000058, 7.399999999999965, 13.699999999999964, 5.299999999999965, -5.1999999999999265, 20.000000000000014, -99.70000000000078, 15.799999999999963, 6.50000000000008, -26.199999999999747, -17.79999999999975, 1.0999999999999865, -20.19999999999976, -30.39999999999975, -36.69999999999987, 20.000000000000014, -40.89999999999976, -13.599999999999783, 20.000000000000014, 3.1999999999999615, -171.10000000000062, -9.399999999999855, -47.19999999999984, 1.0999999999999546, 7.399999999999965, 1.0999999999999865, 20.000000000000014, 7.399999999999965, 1.0999999999999865, 15.799999999999963, -9.399999999999855, 20.000000000000014, -36.699999999999754, -40.899999999999814, 27.20000000000013, 5.299999999999965, 9.499999999999964, 23.600000000000065, 15.799999999999963, 1.9999999999999731, -24.099999999999746, -64.00000000000065, 3.1999999999999615, 20.000000000000014, 20.000000000000014, -131.19999999999985, -72.40000000000086, 20.000000000000014, -61.90000000000041, 7.399999999999965, -31.599999999999838, -131.20000000000073, 7.399999999999965, -5.199999999999969, -55.60000000000031, 3.199999999999965, 3.1999999999999615, 15.799999999999963, 1.0999999999999865, 15.799999999999963, 20.000000000000014, -17.79999999999974, 22.40000000000005, -5.199999999999941, 4.099999999999966, 11.599999999999964, 20.000000000000014, 17.899999999999988, 20.000000000000014, 7.399999999999965, 25.400000000000098, -0.9999999999999846, -11.499999999999819, -0.9999999999999846, 13.699999999999969, -36.699999999999754, 28.100000000000147, -0.9999999999999846, -13.59999999999979, -17.499999999999787], "policy_predator_policy_reward": [9.0, 0.0, 20.0, 10.0, 18.0, 18.0, 41.0, 28.0, 22.0, 22.0, 10.0, 12.0, 31.0, 30.0, 47.0, 16.0, 18.0, 19.0, 111.0, 12.0, 12.0, 49.0, 1.0, 4.0, 21.0, 22.0, 29.0, 9.0, 11.0, 14.0, 5.0, 11.0, 7.0, 4.0, 4.0, 23.0, 28.0, 6.0, 27.0, 17.0, 1.0, 7.0, 31.0, 27.0, 0.0, 10.0, 38.0, 16.0, 40.0, 31.0, 21.0, 55.0, 14.0, 17.0, 36.0, 35.0, 10.0, 7.0, 4.0, 7.0, 17.0, 18.0, 6.0, 5.0, 11.0, 13.0, 34.0, 35.0, 9.0, 3.0, 7.0, 9.0, 5.0, 3.0, 15.0, 10.0, 4.0, 5.0, 12.0, 12.0, 10.0, 11.0, 26.0, 30.0, 7.0, 1.0, 9.0, 1.0, 42.0, 33.0, 2.0, 15.0, 8.0, 6.0, 23.0, 3.0, 5.0, 1.0, 23.0, 17.0, 7.0, 0.0, 61.0, 12.0, 25.0, 16.0, 5.0, 4.0, 17.0, 9.0, 11.0, 12.0, 32.0, 14.0, 5.0, 2.0, 23.0, 17.0, 37.0, 38.0, 43.0, 45.0, 3.0, 7.0, 1.0, 12.0, 49.0, 32.0, 23.0, 33.0, 21.0, 19.0, 29.0, 30.0, 26.0, 22.0, 29.0, 27.0, 8.0, 1.0, 41.0, 64.0, 33.0, 8.0, 9.0, 6.0, 6.0, 5.0, 9.0, 2.0, 14.0, 7.0, 46.0, 46.0, 7.0, 2.0, 5.0, 4.0, 4.0, 9.0, 55.0, 46.0, 5.0, 8.0, 52.0, 72.0, 4.0, 40.0, 21.0, 31.0, 72.0, 29.0, 17.0, 10.0, 27.0, 31.0, 8.0, 3.0, 9.0, 2.0, 17.0, 13.0, 12.0, 1.0, 9.0, 9.0, 1.0, 0.0, 0.0, 6.0, 0.0, 10.0, 15.0, 10.0, 17.0, 29.0, 9.0, 10.0, 25.0, 26.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5864196923320627, "mean_inference_ms": 1.8171124928123192, "mean_action_processing_ms": 0.2529098139261171, "mean_env_wait_ms": 0.1966861909610789, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003857851028442383, "StateBufferConnector_ms": 0.003288745880126953, "ViewRequirementAgentConnector_ms": 0.0991828441619873}, "num_episodes": 22, "episode_return_max": 51.70000000000041, "episode_return_min": -94.4000000000004, "episode_return_mean": 19.930000000000142, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2496000, "num_agent_steps_trained": 2496000, "num_env_steps_sampled": 624000, "num_env_steps_trained": 624000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 351.60615319821676, "num_env_steps_trained_throughput_per_sec": 351.60615319821676, "timesteps_total": 624000, "num_env_steps_sampled_lifetime": 624000, "num_agent_steps_sampled_lifetime": 2496000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2496000, "timers": {"training_iteration_time_ms": 11055.544, "restore_workers_time_ms": 0.021, "training_step_time_ms": 11055.487, "sample_time_ms": 1365.396, "learn_time_ms": 9673.623, "learn_throughput": 413.496, "synch_weights_time_ms": 14.51}, "counters": {"num_env_steps_sampled": 624000, "num_env_steps_trained": 624000, "num_agent_steps_sampled": 2496000, "num_agent_steps_trained": 2496000}, "done": false, "training_iteration": 156, "trial_id": "3dae5_00000", "date": "2024-08-14_09-35-34", "timestamp": 1723642534, "time_this_iter_s": 11.432929039001465, "time_total_s": 3352.066016435623, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b38679d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3352.066016435623, "iterations_since_restore": 156, "perf": {"cpu_util_percent": 31.99375, "ram_util_percent": 83.36875}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8807054785193589, "cur_kl_coeff": 5.21421432495117e-05, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.4153065889916092, "policy_loss": -0.00853576479016473, "vf_loss": 1.423841844601606, "vf_explained_var": 0.03215981346589548, "kl": 0.009712989731673604, "entropy": 0.8654605215819424, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 295785.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.643895273990732, "cur_kl_coeff": 0.023730468750000008, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.181228451966924, "policy_loss": -0.010519974985376749, "vf_loss": 1.191569943592031, "vf_explained_var": 0.44854601400869865, "kl": 0.007521231341237691, "entropy": 0.8817030434255246, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 295785.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 628000, "num_env_steps_trained": 628000, "num_agent_steps_sampled": 2512000, "num_agent_steps_trained": 2512000}, "env_runners": {"episode_reward_max": 51.70000000000041, "episode_reward_min": -75.5000000000014, "episode_reward_mean": 20.33700000000014, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -171.10000000000062, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 31.1000000000002, "predator_policy": 89.0}, "policy_reward_mean": {"prey_policy": -8.246500000000015, "predator_policy": 18.415}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.6000000000000716, 14.099999999999941, 33.3000000000002, 14.000000000000004, 29.000000000000128, -13.099999999999557, 16.799999999999923, -9.999999999999632, 32.30000000000019, 22.80000000000003, 15.000000000000021, 37.50000000000026, 40.200000000000294, 32.10000000000018, 19.89999999999998, 13.300000000000013, 18.40000000000001, 33.2000000000002, 39.30000000000029, 14.600000000000023, 32.80000000000019, 28.300000000000114, 37.90000000000027, 33.000000000000206, 31.200000000000166, 29.000000000000124, -17.29999999999952, 21.299999999999994, 24.600000000000048, 17.699999999999953, 33.4000000000002, 29.600000000000154, 32.30000000000018, -15.099999999999579, -5.099999999999685, 51.70000000000041, 11.400000000000077, 29.40000000000013, 18.79999999999996, 36.50000000000025, 25.4000000000001, 35.20000000000023, 33.5000000000002, 29.000000000000124, 27.800000000000107, -2.899999999999766, 36.30000000000025, 23.30000000000003, 8.400000000000087, 31.300000000000153, 1.5000000000002147, 32.20000000000018, -75.5000000000014, -5.099999999999859, 23.50000000000003, 38.400000000000276, 27.900000000000105, 31.60000000000018, 14.399999999999912, 41.50000000000032, 42.10000000000033, 30.80000000000016, 12.899999999999942, 36.200000000000244, 12.799999999999924, -8.399999999999674, -2.4999999999998685, -61.79999999999996, 29.200000000000152, 5.600000000000122, 30.000000000000142, 27.900000000000105, 32.20000000000019, 30.20000000000016, 33.70000000000021, 38.90000000000028, 33.400000000000205, 34.40000000000022, 12.500000000000059, 23.000000000000036, 46.1000000000004, 19.89999999999998, -5.999999999999696, 20.900000000000063, 23.50000000000003, 32.800000000000196, -0.09999999999985326, 38.70000000000029, 15.8, -2.9999999999997304, 29.700000000000138, 17.300000000000068, 22.400000000000023, 39.700000000000294, 11.60000000000004, 36.40000000000025, -19.899999999999636, 27.700000000000102, 18.099999999999945, 24.600000000000048], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-38.799999999999756, 7.399999999999965, 13.099999999999971, -42.99999999999976, 20.000000000000014, 5.299999999999965, -42.999999999999766, -0.9999999999999846, -0.9999999999999846, 20.000000000000014, -59.80000000000062, -7.299999999999912, -64.30000000000089, 10.099999999999966, -95.50000000000082, 9.499999999999964, 2.2999999999999607, -0.9999999999999846, -45.099999999999824, -3.099999999999958, 1.0999999999999865, -3.099999999999958, 6.499999999999968, 20.000000000000014, 1.9999999999999607, 3.1999999999999615, 3.1999999999999615, 17.899999999999988, -9.399999999999855, 5.299999999999965, -5.1999999999999265, -50.49999999999998, 5.299999999999965, 1.0999999999999865, 5.299999999999965, 11.89999999999997, 21.80000000000004, 9.499999999999964, -15.699999999999747, 5.299999999999965, 14.299999999999965, 9.499999999999964, 9.499999999999964, -5.1999999999999265, -3.099999999999958, 20.000000000000014, -36.69999999999977, 13.699999999999964, 17.899999999999988, 5.299999999999965, 1.0999999999999865, 17.899999999999988, -21.999999999999744, -70.30000000000089, -11.499999999999819, 15.799999999999963, 3.1999999999999615, 7.399999999999965, 7.399999999999965, -15.699999999999786, 9.499999999999964, 17.899999999999988, -21.999999999999744, 11.599999999999977, 5.299999999999965, 20.000000000000014, 20.000000000000014, -108.10000000000079, -40.89999999999976, -5.1999999999999265, 11.599999999999964, 31.1000000000002, -15.699999999999747, 1.0999999999999865, -7.299999999999976, 13.699999999999964, -47.19999999999976, 20.000000000000014, 9.499999999999964, 20.000000000000014, -26.19999999999981, 11.599999999999964, 20.000000000000014, -59.80000000000062, -61.90000000000058, 7.399999999999965, 13.699999999999964, 5.299999999999965, -5.1999999999999265, 20.000000000000014, -99.70000000000078, 15.799999999999963, 6.50000000000008, -26.199999999999747, -17.79999999999975, 1.0999999999999865, -20.19999999999976, -30.39999999999975, -36.69999999999987, 20.000000000000014, -40.89999999999976, -13.599999999999783, 20.000000000000014, 3.1999999999999615, -171.10000000000062, -9.399999999999855, -47.19999999999984, 1.0999999999999546, 7.399999999999965, 1.0999999999999865, 20.000000000000014, 7.399999999999965, 1.0999999999999865, 15.799999999999963, -9.399999999999855, 20.000000000000014, -36.699999999999754, -40.899999999999814, 27.20000000000013, 5.299999999999965, 9.499999999999964, 23.600000000000065, 15.799999999999963, 1.9999999999999731, -24.099999999999746, -64.00000000000065, 3.1999999999999615, 20.000000000000014, 20.000000000000014, -131.19999999999985, -72.40000000000086, 20.000000000000014, -61.90000000000041, 7.399999999999965, -31.599999999999838, -131.20000000000073, 7.399999999999965, -5.199999999999969, -55.60000000000031, 3.199999999999965, 3.1999999999999615, 15.799999999999963, 1.0999999999999865, 15.799999999999963, 20.000000000000014, -17.79999999999974, 22.40000000000005, -5.199999999999941, 4.099999999999966, 11.599999999999964, 20.000000000000014, 17.899999999999988, 20.000000000000014, 7.399999999999965, 25.400000000000098, -0.9999999999999846, -11.499999999999819, -0.9999999999999846, 13.699999999999969, -36.699999999999754, 28.100000000000147, -0.9999999999999846, -13.59999999999979, -17.499999999999787, -45.09999999999976, -40.89999999999976, -66.1000000000002, 20.000000000000014, 7.399999999999965, 1.099999999999983, -5.1999999999999265, 20.000000000000014, -17.799999999999955, -49.299999999999834, 21.20000000000003, -2.4999999999999716, -3.099999999999958, -3.099999999999965, -53.50000000000019, -11.499999999999819, 13.699999999999964, -0.9999999999999846, -18.09999999999976, 7.399999999999965, -93.40000000000057, 15.799999999999963, 20.000000000000014, 4.699999999999967, -11.499999999999819, -40.899999999999764, 7.399999999999965, 20.000000000000014, 20.000000000000014, -166.90000000000063, 12.499999999999964, 3.1999999999999615, -61.90000000000051, 20.000000000000014, 7.399999999999965, 3.1999999999999615], "policy_predator_policy_reward": [28.0, 6.0, 27.0, 17.0, 1.0, 7.0, 31.0, 27.0, 0.0, 10.0, 38.0, 16.0, 40.0, 31.0, 21.0, 55.0, 14.0, 17.0, 36.0, 35.0, 10.0, 7.0, 4.0, 7.0, 17.0, 18.0, 6.0, 5.0, 11.0, 13.0, 34.0, 35.0, 9.0, 3.0, 7.0, 9.0, 5.0, 3.0, 15.0, 10.0, 4.0, 5.0, 12.0, 12.0, 10.0, 11.0, 26.0, 30.0, 7.0, 1.0, 9.0, 1.0, 42.0, 33.0, 2.0, 15.0, 8.0, 6.0, 23.0, 3.0, 5.0, 1.0, 23.0, 17.0, 7.0, 0.0, 61.0, 12.0, 25.0, 16.0, 5.0, 4.0, 17.0, 9.0, 11.0, 12.0, 32.0, 14.0, 5.0, 2.0, 23.0, 17.0, 37.0, 38.0, 43.0, 45.0, 3.0, 7.0, 1.0, 12.0, 49.0, 32.0, 23.0, 33.0, 21.0, 19.0, 29.0, 30.0, 26.0, 22.0, 29.0, 27.0, 8.0, 1.0, 41.0, 64.0, 33.0, 8.0, 9.0, 6.0, 6.0, 5.0, 9.0, 2.0, 14.0, 7.0, 46.0, 46.0, 7.0, 2.0, 5.0, 4.0, 4.0, 9.0, 55.0, 46.0, 5.0, 8.0, 52.0, 72.0, 4.0, 40.0, 21.0, 31.0, 72.0, 29.0, 17.0, 10.0, 27.0, 31.0, 8.0, 3.0, 9.0, 2.0, 17.0, 13.0, 12.0, 1.0, 9.0, 9.0, 1.0, 0.0, 0.0, 6.0, 0.0, 10.0, 15.0, 10.0, 17.0, 29.0, 9.0, 10.0, 25.0, 26.0, 45.0, 35.0, 30.0, 37.0, 9.0, 6.0, 6.0, 12.0, 26.0, 41.0, 12.0, 8.0, 14.0, 8.0, 32.0, 30.0, 10.0, 7.0, 22.0, 6.0, 53.0, 47.0, 9.0, 6.0, 32.0, 32.0, 3.0, 6.0, 89.0, 38.0, 4.0, 8.0, 24.0, 36.0, 6.0, 8.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5863193383726487, "mean_inference_ms": 1.8166117330088758, "mean_action_processing_ms": 0.25310395795764395, "mean_env_wait_ms": 0.1965275827031673, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0036652088165283203, "StateBufferConnector_ms": 0.003227710723876953, "ViewRequirementAgentConnector_ms": 0.09372973442077637}, "num_episodes": 18, "episode_return_max": 51.70000000000041, "episode_return_min": -75.5000000000014, "episode_return_mean": 20.33700000000014, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2512000, "num_agent_steps_trained": 2512000, "num_env_steps_sampled": 628000, "num_env_steps_trained": 628000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 350.55016674581475, "num_env_steps_trained_throughput_per_sec": 350.55016674581475, "timesteps_total": 628000, "num_env_steps_sampled_lifetime": 628000, "num_agent_steps_sampled_lifetime": 2512000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2512000, "timers": {"training_iteration_time_ms": 11114.514, "restore_workers_time_ms": 0.02, "training_step_time_ms": 11114.455, "sample_time_ms": 1371.421, "learn_time_ms": 9726.027, "learn_throughput": 411.268, "synch_weights_time_ms": 14.741}, "counters": {"num_env_steps_sampled": 628000, "num_env_steps_trained": 628000, "num_agent_steps_sampled": 2512000, "num_agent_steps_trained": 2512000}, "done": false, "training_iteration": 157, "trial_id": "3dae5_00000", "date": "2024-08-14_09-35-46", "timestamp": 1723642546, "time_this_iter_s": 11.44323182106018, "time_total_s": 3363.5092482566833, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3870d30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3363.5092482566833, "iterations_since_restore": 157, "perf": {"cpu_util_percent": 33.088235294117645, "ram_util_percent": 83.45294117647059}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6579330763804219, "cur_kl_coeff": 5.21421432495117e-05, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.37414020631442624, "policy_loss": -0.0053471821421885455, "vf_loss": 0.379486786918074, "vf_explained_var": 0.24106915766599948, "kl": 0.011541660554044214, "entropy": 0.8886177716431795, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 297675.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6374780908621178, "cur_kl_coeff": 0.023730468750000008, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.7656369900528006, "policy_loss": -0.008089393904375986, "vf_loss": 0.7734974281280917, "vf_explained_var": -0.2232803011066699, "kl": 0.009648143699812997, "entropy": 0.8111341338939768, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 297675.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 632000, "num_env_steps_trained": 632000, "num_agent_steps_sampled": 2528000, "num_agent_steps_trained": 2528000}, "env_runners": {"episode_reward_max": 51.70000000000041, "episode_reward_min": -75.5000000000014, "episode_reward_mean": 21.28300000000013, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -171.10000000000062, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 34.99999999999998, "predator_policy": 89.0}, "policy_reward_mean": {"prey_policy": -6.248500000000002, "predator_policy": 16.89}, "custom_metrics": {}, "hist_stats": {"episode_reward": [39.30000000000029, 14.600000000000023, 32.80000000000019, 28.300000000000114, 37.90000000000027, 33.000000000000206, 31.200000000000166, 29.000000000000124, -17.29999999999952, 21.299999999999994, 24.600000000000048, 17.699999999999953, 33.4000000000002, 29.600000000000154, 32.30000000000018, -15.099999999999579, -5.099999999999685, 51.70000000000041, 11.400000000000077, 29.40000000000013, 18.79999999999996, 36.50000000000025, 25.4000000000001, 35.20000000000023, 33.5000000000002, 29.000000000000124, 27.800000000000107, -2.899999999999766, 36.30000000000025, 23.30000000000003, 8.400000000000087, 31.300000000000153, 1.5000000000002147, 32.20000000000018, -75.5000000000014, -5.099999999999859, 23.50000000000003, 38.400000000000276, 27.900000000000105, 31.60000000000018, 14.399999999999912, 41.50000000000032, 42.10000000000033, 30.80000000000016, 12.899999999999942, 36.200000000000244, 12.799999999999924, -8.399999999999674, -2.4999999999998685, -61.79999999999996, 29.200000000000152, 5.600000000000122, 30.000000000000142, 27.900000000000105, 32.20000000000019, 30.20000000000016, 33.70000000000021, 38.90000000000028, 33.400000000000205, 34.40000000000022, 12.500000000000059, 23.000000000000036, 46.1000000000004, 19.89999999999998, -5.999999999999696, 20.900000000000063, 23.50000000000003, 32.800000000000196, -0.09999999999985326, 38.70000000000029, 15.8, -2.9999999999997304, 29.700000000000138, 17.300000000000068, 22.400000000000023, 39.700000000000294, 11.60000000000004, 36.40000000000025, -19.899999999999636, 27.700000000000102, 18.099999999999945, 24.600000000000048, 33.4000000000002, 25.10000000000006, 20.400000000000002, 32.30000000000018, -0.6999999999997644, 42.89999999999997, 28.700000000000124, 16.09999999999999, 32.30000000000018, 16.000000000000004, 29.000000000000124, 26.800000000000086, 36.10000000000023, 37.50000000000026, 16.89999999999998, 12.600000000000058, 20.39999999999999, 20.199999999999992], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [21.80000000000004, 9.499999999999964, -15.699999999999747, 5.299999999999965, 14.299999999999965, 9.499999999999964, 9.499999999999964, -5.1999999999999265, -3.099999999999958, 20.000000000000014, -36.69999999999977, 13.699999999999964, 17.899999999999988, 5.299999999999965, 1.0999999999999865, 17.899999999999988, -21.999999999999744, -70.30000000000089, -11.499999999999819, 15.799999999999963, 3.1999999999999615, 7.399999999999965, 7.399999999999965, -15.699999999999786, 9.499999999999964, 17.899999999999988, -21.999999999999744, 11.599999999999977, 5.299999999999965, 20.000000000000014, 20.000000000000014, -108.10000000000079, -40.89999999999976, -5.1999999999999265, 11.599999999999964, 31.1000000000002, -15.699999999999747, 1.0999999999999865, -7.299999999999976, 13.699999999999964, -47.19999999999976, 20.000000000000014, 9.499999999999964, 20.000000000000014, -26.19999999999981, 11.599999999999964, 20.000000000000014, -59.80000000000062, -61.90000000000058, 7.399999999999965, 13.699999999999964, 5.299999999999965, -5.1999999999999265, 20.000000000000014, -99.70000000000078, 15.799999999999963, 6.50000000000008, -26.199999999999747, -17.79999999999975, 1.0999999999999865, -20.19999999999976, -30.39999999999975, -36.69999999999987, 20.000000000000014, -40.89999999999976, -13.599999999999783, 20.000000000000014, 3.1999999999999615, -171.10000000000062, -9.399999999999855, -47.19999999999984, 1.0999999999999546, 7.399999999999965, 1.0999999999999865, 20.000000000000014, 7.399999999999965, 1.0999999999999865, 15.799999999999963, -9.399999999999855, 20.000000000000014, -36.699999999999754, -40.899999999999814, 27.20000000000013, 5.299999999999965, 9.499999999999964, 23.600000000000065, 15.799999999999963, 1.9999999999999731, -24.099999999999746, -64.00000000000065, 3.1999999999999615, 20.000000000000014, 20.000000000000014, -131.19999999999985, -72.40000000000086, 20.000000000000014, -61.90000000000041, 7.399999999999965, -31.599999999999838, -131.20000000000073, 7.399999999999965, -5.199999999999969, -55.60000000000031, 3.199999999999965, 3.1999999999999615, 15.799999999999963, 1.0999999999999865, 15.799999999999963, 20.000000000000014, -17.79999999999974, 22.40000000000005, -5.199999999999941, 4.099999999999966, 11.599999999999964, 20.000000000000014, 17.899999999999988, 20.000000000000014, 7.399999999999965, 25.400000000000098, -0.9999999999999846, -11.499999999999819, -0.9999999999999846, 13.699999999999969, -36.699999999999754, 28.100000000000147, -0.9999999999999846, -13.59999999999979, -17.499999999999787, -45.09999999999976, -40.89999999999976, -66.1000000000002, 20.000000000000014, 7.399999999999965, 1.099999999999983, -5.1999999999999265, 20.000000000000014, -17.799999999999955, -49.299999999999834, 21.20000000000003, -2.4999999999999716, -3.099999999999958, -3.099999999999965, -53.50000000000019, -11.499999999999819, 13.699999999999964, -0.9999999999999846, -18.09999999999976, 7.399999999999965, -93.40000000000057, 15.799999999999963, 20.000000000000014, 4.699999999999967, -11.499999999999819, -40.899999999999764, 7.399999999999965, 20.000000000000014, 20.000000000000014, -166.90000000000063, 12.499999999999964, 3.1999999999999615, -61.90000000000051, 20.000000000000014, 7.399999999999965, 3.1999999999999615, 9.499999999999964, 17.899999999999988, -2.4999999999999716, 11.599999999999964, 7.399999999999965, -0.9999999999999846, 7.399999999999965, 17.899999999999988, 11.599999999999964, -49.29999999999976, 34.99999999999998, -45.09999999999976, 20.000000000000014, -4.299999999999944, -9.699999999999854, 6.799999999999967, 17.899999999999988, 7.399999999999965, 3.1999999999999615, -5.1999999999999265, 15.799999999999963, 3.1999999999999615, 11.599999999999964, 3.1999999999999615, 28.400000000000155, -7.299999999999919, 9.499999999999964, 20.000000000000014, -19.899999999999743, 15.799999999999963, -3.099999999999958, -7.299999999999891, -34.89999999999976, 5.299999999999965, -9.399999999999855, 11.599999999999964], "policy_predator_policy_reward": [5.0, 3.0, 15.0, 10.0, 4.0, 5.0, 12.0, 12.0, 10.0, 11.0, 26.0, 30.0, 7.0, 1.0, 9.0, 1.0, 42.0, 33.0, 2.0, 15.0, 8.0, 6.0, 23.0, 3.0, 5.0, 1.0, 23.0, 17.0, 7.0, 0.0, 61.0, 12.0, 25.0, 16.0, 5.0, 4.0, 17.0, 9.0, 11.0, 12.0, 32.0, 14.0, 5.0, 2.0, 23.0, 17.0, 37.0, 38.0, 43.0, 45.0, 3.0, 7.0, 1.0, 12.0, 49.0, 32.0, 23.0, 33.0, 21.0, 19.0, 29.0, 30.0, 26.0, 22.0, 29.0, 27.0, 8.0, 1.0, 41.0, 64.0, 33.0, 8.0, 9.0, 6.0, 6.0, 5.0, 9.0, 2.0, 14.0, 7.0, 46.0, 46.0, 7.0, 2.0, 5.0, 4.0, 4.0, 9.0, 55.0, 46.0, 5.0, 8.0, 52.0, 72.0, 4.0, 40.0, 21.0, 31.0, 72.0, 29.0, 17.0, 10.0, 27.0, 31.0, 8.0, 3.0, 9.0, 2.0, 17.0, 13.0, 12.0, 1.0, 9.0, 9.0, 1.0, 0.0, 0.0, 6.0, 0.0, 10.0, 15.0, 10.0, 17.0, 29.0, 9.0, 10.0, 25.0, 26.0, 45.0, 35.0, 30.0, 37.0, 9.0, 6.0, 6.0, 12.0, 26.0, 41.0, 12.0, 8.0, 14.0, 8.0, 32.0, 30.0, 10.0, 7.0, 22.0, 6.0, 53.0, 47.0, 9.0, 6.0, 32.0, 32.0, 3.0, 6.0, 89.0, 38.0, 4.0, 8.0, 24.0, 36.0, 6.0, 8.0, 5.0, 1.0, 13.0, 3.0, 4.0, 10.0, 1.0, 6.0, 7.0, 30.0, 28.0, 25.0, 11.0, 2.0, 4.0, 15.0, 1.0, 6.0, 6.0, 12.0, 8.0, 2.0, 7.0, 5.0, 2.0, 13.0, 3.0, 5.0, 19.0, 2.0, 14.0, 9.0, 27.0, 23.0, 4.0, 14.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5863373340021965, "mean_inference_ms": 1.816300940321738, "mean_action_processing_ms": 0.252991103812551, "mean_env_wait_ms": 0.1964996208404325, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004526495933532715, "StateBufferConnector_ms": 0.003222942352294922, "ViewRequirementAgentConnector_ms": 0.09223413467407227}, "num_episodes": 18, "episode_return_max": 51.70000000000041, "episode_return_min": -75.5000000000014, "episode_return_mean": 21.28300000000013, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2528000, "num_agent_steps_trained": 2528000, "num_env_steps_sampled": 632000, "num_env_steps_trained": 632000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 350.3467870656313, "num_env_steps_trained_throughput_per_sec": 350.3467870656313, "timesteps_total": 632000, "num_env_steps_sampled_lifetime": 632000, "num_agent_steps_sampled_lifetime": 2528000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2528000, "timers": {"training_iteration_time_ms": 11158.847, "restore_workers_time_ms": 0.02, "training_step_time_ms": 11158.789, "sample_time_ms": 1380.348, "learn_time_ms": 9761.55, "learn_throughput": 409.771, "synch_weights_time_ms": 14.754}, "counters": {"num_env_steps_sampled": 632000, "num_env_steps_trained": 632000, "num_agent_steps_sampled": 2528000, "num_agent_steps_trained": 2528000}, "done": false, "training_iteration": 158, "trial_id": "3dae5_00000", "date": "2024-08-14_09-35-57", "timestamp": 1723642557, "time_this_iter_s": 11.423318862915039, "time_total_s": 3374.9325671195984, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3981700>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3374.9325671195984, "iterations_since_restore": 158, "perf": {"cpu_util_percent": 33.13125, "ram_util_percent": 83.73125}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6402392824490866, "cur_kl_coeff": 5.21421432495117e-05, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.030804698744779, "policy_loss": -0.007160941009143633, "vf_loss": 1.0379650696323661, "vf_explained_var": 0.0318313081113119, "kl": 0.01092699745421586, "entropy": 0.8880990200257175, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 299565.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9901918156752512, "cur_kl_coeff": 0.023730468750000008, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.9178204835762107, "policy_loss": -0.012582159997395205, "vf_loss": 0.9302863498923009, "vf_explained_var": 0.24012151953404542, "kl": 0.004900498574318338, "entropy": 0.7521836483920062, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 299565.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 636000, "num_env_steps_trained": 636000, "num_agent_steps_sampled": 2544000, "num_agent_steps_trained": 2544000}, "env_runners": {"episode_reward_max": 78.49999999999945, "episode_reward_min": -75.5000000000014, "episode_reward_mean": 22.316000000000127, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -171.10000000000062, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 61.40000000000022, "predator_policy": 89.0}, "policy_reward_mean": {"prey_policy": -5.047000000000001, "predator_policy": 16.205}, "custom_metrics": {}, "hist_stats": {"episode_reward": [11.400000000000077, 29.40000000000013, 18.79999999999996, 36.50000000000025, 25.4000000000001, 35.20000000000023, 33.5000000000002, 29.000000000000124, 27.800000000000107, -2.899999999999766, 36.30000000000025, 23.30000000000003, 8.400000000000087, 31.300000000000153, 1.5000000000002147, 32.20000000000018, -75.5000000000014, -5.099999999999859, 23.50000000000003, 38.400000000000276, 27.900000000000105, 31.60000000000018, 14.399999999999912, 41.50000000000032, 42.10000000000033, 30.80000000000016, 12.899999999999942, 36.200000000000244, 12.799999999999924, -8.399999999999674, -2.4999999999998685, -61.79999999999996, 29.200000000000152, 5.600000000000122, 30.000000000000142, 27.900000000000105, 32.20000000000019, 30.20000000000016, 33.70000000000021, 38.90000000000028, 33.400000000000205, 34.40000000000022, 12.500000000000059, 23.000000000000036, 46.1000000000004, 19.89999999999998, -5.999999999999696, 20.900000000000063, 23.50000000000003, 32.800000000000196, -0.09999999999985326, 38.70000000000029, 15.8, -2.9999999999997304, 29.700000000000138, 17.300000000000068, 22.400000000000023, 39.700000000000294, 11.60000000000004, 36.40000000000025, -19.899999999999636, 27.700000000000102, 18.099999999999945, 24.600000000000048, 33.4000000000002, 25.10000000000006, 20.400000000000002, 32.30000000000018, -0.6999999999997644, 42.89999999999997, 28.700000000000124, 16.09999999999999, 32.30000000000018, 16.000000000000004, 29.000000000000124, 26.800000000000086, 36.10000000000023, 37.50000000000026, 16.89999999999998, 12.600000000000058, 20.39999999999999, 20.199999999999992, 22.700000000000028, 34.900000000000226, 32.20000000000019, 37.600000000000264, 37.90000000000027, 15.800000000000004, 37.40000000000026, 38.90000000000028, 22.100000000000012, 27.4000000000001, -23.49999999999953, 43.40000000000037, 21.300000000000008, 78.49999999999945, 35.20000000000023, -8.199999999999632, 38.80000000000028, 30.100000000000144], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-15.699999999999747, 1.0999999999999865, -7.299999999999976, 13.699999999999964, -47.19999999999976, 20.000000000000014, 9.499999999999964, 20.000000000000014, -26.19999999999981, 11.599999999999964, 20.000000000000014, -59.80000000000062, -61.90000000000058, 7.399999999999965, 13.699999999999964, 5.299999999999965, -5.1999999999999265, 20.000000000000014, -99.70000000000078, 15.799999999999963, 6.50000000000008, -26.199999999999747, -17.79999999999975, 1.0999999999999865, -20.19999999999976, -30.39999999999975, -36.69999999999987, 20.000000000000014, -40.89999999999976, -13.599999999999783, 20.000000000000014, 3.1999999999999615, -171.10000000000062, -9.399999999999855, -47.19999999999984, 1.0999999999999546, 7.399999999999965, 1.0999999999999865, 20.000000000000014, 7.399999999999965, 1.0999999999999865, 15.799999999999963, -9.399999999999855, 20.000000000000014, -36.699999999999754, -40.899999999999814, 27.20000000000013, 5.299999999999965, 9.499999999999964, 23.600000000000065, 15.799999999999963, 1.9999999999999731, -24.099999999999746, -64.00000000000065, 3.1999999999999615, 20.000000000000014, 20.000000000000014, -131.19999999999985, -72.40000000000086, 20.000000000000014, -61.90000000000041, 7.399999999999965, -31.599999999999838, -131.20000000000073, 7.399999999999965, -5.199999999999969, -55.60000000000031, 3.199999999999965, 3.1999999999999615, 15.799999999999963, 1.0999999999999865, 15.799999999999963, 20.000000000000014, -17.79999999999974, 22.40000000000005, -5.199999999999941, 4.099999999999966, 11.599999999999964, 20.000000000000014, 17.899999999999988, 20.000000000000014, 7.399999999999965, 25.400000000000098, -0.9999999999999846, -11.499999999999819, -0.9999999999999846, 13.699999999999969, -36.699999999999754, 28.100000000000147, -0.9999999999999846, -13.59999999999979, -17.499999999999787, -45.09999999999976, -40.89999999999976, -66.1000000000002, 20.000000000000014, 7.399999999999965, 1.099999999999983, -5.1999999999999265, 20.000000000000014, -17.799999999999955, -49.299999999999834, 21.20000000000003, -2.4999999999999716, -3.099999999999958, -3.099999999999965, -53.50000000000019, -11.499999999999819, 13.699999999999964, -0.9999999999999846, -18.09999999999976, 7.399999999999965, -93.40000000000057, 15.799999999999963, 20.000000000000014, 4.699999999999967, -11.499999999999819, -40.899999999999764, 7.399999999999965, 20.000000000000014, 20.000000000000014, -166.90000000000063, 12.499999999999964, 3.1999999999999615, -61.90000000000051, 20.000000000000014, 7.399999999999965, 3.1999999999999615, 9.499999999999964, 17.899999999999988, -2.4999999999999716, 11.599999999999964, 7.399999999999965, -0.9999999999999846, 7.399999999999965, 17.899999999999988, 11.599999999999964, -49.29999999999976, 34.99999999999998, -45.09999999999976, 20.000000000000014, -4.299999999999944, -9.699999999999854, 6.799999999999967, 17.899999999999988, 7.399999999999965, 3.1999999999999615, -5.1999999999999265, 15.799999999999963, 3.1999999999999615, 11.599999999999964, 3.1999999999999615, 28.400000000000155, -7.299999999999919, 9.499999999999964, 20.000000000000014, -19.899999999999743, 15.799999999999963, -3.099999999999958, -7.299999999999891, -34.89999999999976, 5.299999999999965, -9.399999999999855, 11.599999999999964, -6.399999999999908, 1.0999999999999865, 20.000000000000014, -3.099999999999958, 7.399999999999965, 0.7999999999999723, 11.599999999999964, 20.000000000000014, 20.000000000000014, -3.099999999999958, 3.1999999999999615, -9.399999999999855, 20.000000000000014, 7.399999999999965, 17.899999999999988, 20.000000000000014, 3.1999999999999615, -3.099999999999958, 1.0999999999999865, 8.299999999999969, 1.0999999999999528, -76.60000000000085, -0.9999999999999846, 25.40000000000011, -15.699999999999747, 20.000000000000014, 1.0999999999999865, 61.40000000000022, 7.399999999999965, 21.80000000000004, -7.299999999999891, -40.89999999999976, 20.000000000000014, 15.799999999999963, 9.499999999999964, 11.599999999999964], "policy_predator_policy_reward": [17.0, 9.0, 11.0, 12.0, 32.0, 14.0, 5.0, 2.0, 23.0, 17.0, 37.0, 38.0, 43.0, 45.0, 3.0, 7.0, 1.0, 12.0, 49.0, 32.0, 23.0, 33.0, 21.0, 19.0, 29.0, 30.0, 26.0, 22.0, 29.0, 27.0, 8.0, 1.0, 41.0, 64.0, 33.0, 8.0, 9.0, 6.0, 6.0, 5.0, 9.0, 2.0, 14.0, 7.0, 46.0, 46.0, 7.0, 2.0, 5.0, 4.0, 4.0, 9.0, 55.0, 46.0, 5.0, 8.0, 52.0, 72.0, 4.0, 40.0, 21.0, 31.0, 72.0, 29.0, 17.0, 10.0, 27.0, 31.0, 8.0, 3.0, 9.0, 2.0, 17.0, 13.0, 12.0, 1.0, 9.0, 9.0, 1.0, 0.0, 0.0, 6.0, 0.0, 10.0, 15.0, 10.0, 17.0, 29.0, 9.0, 10.0, 25.0, 26.0, 45.0, 35.0, 30.0, 37.0, 9.0, 6.0, 6.0, 12.0, 26.0, 41.0, 12.0, 8.0, 14.0, 8.0, 32.0, 30.0, 10.0, 7.0, 22.0, 6.0, 53.0, 47.0, 9.0, 6.0, 32.0, 32.0, 3.0, 6.0, 89.0, 38.0, 4.0, 8.0, 24.0, 36.0, 6.0, 8.0, 5.0, 1.0, 13.0, 3.0, 4.0, 10.0, 1.0, 6.0, 7.0, 30.0, 28.0, 25.0, 11.0, 2.0, 4.0, 15.0, 1.0, 6.0, 6.0, 12.0, 8.0, 2.0, 7.0, 5.0, 2.0, 13.0, 3.0, 5.0, 19.0, 2.0, 14.0, 9.0, 27.0, 23.0, 4.0, 14.0, 14.0, 14.0, 9.0, 9.0, 13.0, 11.0, 2.0, 4.0, 10.0, 11.0, 13.0, 9.0, 4.0, 6.0, 0.0, 1.0, 11.0, 11.0, 9.0, 9.0, 3.0, 49.0, 9.0, 10.0, 17.0, 0.0, 9.0, 7.0, 0.0, 6.0, 29.0, 11.0, 1.0, 2.0, 4.0, 5.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5863306064349626, "mean_inference_ms": 1.8160671774202288, "mean_action_processing_ms": 0.25288286047581865, "mean_env_wait_ms": 0.19646447151132457, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004918456077575684, "StateBufferConnector_ms": 0.0032731294631958008, "ViewRequirementAgentConnector_ms": 0.0925973653793335}, "num_episodes": 18, "episode_return_max": 78.49999999999945, "episode_return_min": -75.5000000000014, "episode_return_mean": 22.316000000000127, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2544000, "num_agent_steps_trained": 2544000, "num_env_steps_sampled": 636000, "num_env_steps_trained": 636000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 364.2252520409768, "num_env_steps_trained_throughput_per_sec": 364.2252520409768, "timesteps_total": 636000, "num_env_steps_sampled_lifetime": 636000, "num_agent_steps_sampled_lifetime": 2544000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2544000, "timers": {"training_iteration_time_ms": 11176.045, "restore_workers_time_ms": 0.026, "training_step_time_ms": 11175.972, "sample_time_ms": 1382.595, "learn_time_ms": 9776.707, "learn_throughput": 409.136, "synch_weights_time_ms": 14.422}, "counters": {"num_env_steps_sampled": 636000, "num_env_steps_trained": 636000, "num_agent_steps_sampled": 2544000, "num_agent_steps_trained": 2544000}, "done": false, "training_iteration": 159, "trial_id": "3dae5_00000", "date": "2024-08-14_09-36-08", "timestamp": 1723642568, "time_this_iter_s": 10.99036693572998, "time_total_s": 3385.9229340553284, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3662f70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3385.9229340553284, "iterations_since_restore": 159, "perf": {"cpu_util_percent": 29.7, "ram_util_percent": 83.51875}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.594161883769212, "cur_kl_coeff": 5.21421432495117e-05, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.42679222267929207, "policy_loss": -0.0049822584570695955, "vf_loss": 0.43177398433071124, "vf_explained_var": 0.210272108341651, "kl": 0.009542507724598017, "entropy": 0.7567561950002398, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 301455.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.2054427116951616, "cur_kl_coeff": 0.011865234375000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.6251597745294767, "policy_loss": -0.013716051285586285, "vf_loss": 0.6386641074982151, "vf_explained_var": 0.07934996094653216, "kl": 0.017843752802672353, "entropy": 0.7107243566916733, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 301455.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 640000, "num_env_steps_trained": 640000, "num_agent_steps_sampled": 2560000, "num_agent_steps_trained": 2560000}, "env_runners": {"episode_reward_max": 78.49999999999945, "episode_reward_min": -61.79999999999996, "episode_reward_mean": 25.604000000000145, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -166.90000000000063, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 61.40000000000022, "predator_policy": 89.0}, "policy_reward_mean": {"prey_policy": -0.7779999999999921, "predator_policy": 13.58}, "custom_metrics": {}, "hist_stats": {"episode_reward": [36.200000000000244, 12.799999999999924, -8.399999999999674, -2.4999999999998685, -61.79999999999996, 29.200000000000152, 5.600000000000122, 30.000000000000142, 27.900000000000105, 32.20000000000019, 30.20000000000016, 33.70000000000021, 38.90000000000028, 33.400000000000205, 34.40000000000022, 12.500000000000059, 23.000000000000036, 46.1000000000004, 19.89999999999998, -5.999999999999696, 20.900000000000063, 23.50000000000003, 32.800000000000196, -0.09999999999985326, 38.70000000000029, 15.8, -2.9999999999997304, 29.700000000000138, 17.300000000000068, 22.400000000000023, 39.700000000000294, 11.60000000000004, 36.40000000000025, -19.899999999999636, 27.700000000000102, 18.099999999999945, 24.600000000000048, 33.4000000000002, 25.10000000000006, 20.400000000000002, 32.30000000000018, -0.6999999999997644, 42.89999999999997, 28.700000000000124, 16.09999999999999, 32.30000000000018, 16.000000000000004, 29.000000000000124, 26.800000000000086, 36.10000000000023, 37.50000000000026, 16.89999999999998, 12.600000000000058, 20.39999999999999, 20.199999999999992, 22.700000000000028, 34.900000000000226, 32.20000000000019, 37.600000000000264, 37.90000000000027, 15.800000000000004, 37.40000000000026, 38.90000000000028, 22.100000000000012, 27.4000000000001, -23.49999999999953, 43.40000000000037, 21.300000000000008, 78.49999999999945, 35.20000000000023, -8.199999999999632, 38.80000000000028, 30.100000000000144, 69.79999999999988, 31.200000000000163, 22.50000000000001, 35.90000000000024, 24.80000000000005, 51.60000000000035, 37.80000000000027, 41.70000000000033, 23.50000000000003, 25.700000000000067, 25.700000000000067, 31.200000000000166, 23.300000000000026, 25.80000000000007, 7.000000000000149, 37.70000000000027, 47.00000000000042, 36.40000000000025, 46.30000000000036, 36.60000000000025, 33.400000000000205, 27.900000000000105, 26.100000000000072, 35.00000000000023, 24.90000000000004, 28.700000000000127, 30.90000000000016], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [3.1999999999999615, 20.000000000000014, 20.000000000000014, -131.19999999999985, -72.40000000000086, 20.000000000000014, -61.90000000000041, 7.399999999999965, -31.599999999999838, -131.20000000000073, 7.399999999999965, -5.199999999999969, -55.60000000000031, 3.199999999999965, 3.1999999999999615, 15.799999999999963, 1.0999999999999865, 15.799999999999963, 20.000000000000014, -17.79999999999974, 22.40000000000005, -5.199999999999941, 4.099999999999966, 11.599999999999964, 20.000000000000014, 17.899999999999988, 20.000000000000014, 7.399999999999965, 25.400000000000098, -0.9999999999999846, -11.499999999999819, -0.9999999999999846, 13.699999999999969, -36.699999999999754, 28.100000000000147, -0.9999999999999846, -13.59999999999979, -17.499999999999787, -45.09999999999976, -40.89999999999976, -66.1000000000002, 20.000000000000014, 7.399999999999965, 1.099999999999983, -5.1999999999999265, 20.000000000000014, -17.799999999999955, -49.299999999999834, 21.20000000000003, -2.4999999999999716, -3.099999999999958, -3.099999999999965, -53.50000000000019, -11.499999999999819, 13.699999999999964, -0.9999999999999846, -18.09999999999976, 7.399999999999965, -93.40000000000057, 15.799999999999963, 20.000000000000014, 4.699999999999967, -11.499999999999819, -40.899999999999764, 7.399999999999965, 20.000000000000014, 20.000000000000014, -166.90000000000063, 12.499999999999964, 3.1999999999999615, -61.90000000000051, 20.000000000000014, 7.399999999999965, 3.1999999999999615, 9.499999999999964, 17.899999999999988, -2.4999999999999716, 11.599999999999964, 7.399999999999965, -0.9999999999999846, 7.399999999999965, 17.899999999999988, 11.599999999999964, -49.29999999999976, 34.99999999999998, -45.09999999999976, 20.000000000000014, -4.299999999999944, -9.699999999999854, 6.799999999999967, 17.899999999999988, 7.399999999999965, 3.1999999999999615, -5.1999999999999265, 15.799999999999963, 3.1999999999999615, 11.599999999999964, 3.1999999999999615, 28.400000000000155, -7.299999999999919, 9.499999999999964, 20.000000000000014, -19.899999999999743, 15.799999999999963, -3.099999999999958, -7.299999999999891, -34.89999999999976, 5.299999999999965, -9.399999999999855, 11.599999999999964, -6.399999999999908, 1.0999999999999865, 20.000000000000014, -3.099999999999958, 7.399999999999965, 0.7999999999999723, 11.599999999999964, 20.000000000000014, 20.000000000000014, -3.099999999999958, 3.1999999999999615, -9.399999999999855, 20.000000000000014, 7.399999999999965, 17.899999999999988, 20.000000000000014, 3.1999999999999615, -3.099999999999958, 1.0999999999999865, 8.299999999999969, 1.0999999999999528, -76.60000000000085, -0.9999999999999846, 25.40000000000011, -15.699999999999747, 20.000000000000014, 1.0999999999999865, 61.40000000000022, 7.399999999999965, 21.80000000000004, -7.299999999999891, -40.89999999999976, 20.000000000000014, 15.799999999999963, 9.499999999999964, 11.599999999999964, 18.200000000000045, 11.599999999999964, 9.499999999999964, 13.699999999999964, 7.399999999999965, 1.0999999999999865, 20.000000000000014, -24.099999999999746, 7.399999999999965, 7.399999999999965, 11.599999999999964, 35.00000000000017, -5.1999999999999265, 20.000000000000014, -5.1999999999999265, -0.10000000000002768, 15.799999999999963, -7.299999999999891, -5.1999999999999265, 17.899999999999988, -5.1999999999999265, 17.899999999999988, 17.899999999999988, 5.299999999999965, -0.09999999999999937, 7.399999999999965, -5.499999999999925, 5.299999999999965, -28.29999999999975, 5.299999999999965, 15.799999999999962, -0.10000000000001347, 36.20000000000026, -5.1999999999999265, -34.59999999999975, 20.000000000000014, 5.299999999999965, -9.999999999999952, -9.399999999999855, 20.000000000000014, 15.799999999999963, 11.599999999999966, 1.0999999999999865, 15.799999999999963, 9.499999999999964, 11.599999999999964, -0.9999999999999846, 20.000000000000014, 20.000000000000014, -36.09999999999985, 26.300000000000114, -13.599999999999783, 9.499999999999964, 10.399999999999965], "policy_predator_policy_reward": [5.0, 8.0, 52.0, 72.0, 4.0, 40.0, 21.0, 31.0, 72.0, 29.0, 17.0, 10.0, 27.0, 31.0, 8.0, 3.0, 9.0, 2.0, 17.0, 13.0, 12.0, 1.0, 9.0, 9.0, 1.0, 0.0, 0.0, 6.0, 0.0, 10.0, 15.0, 10.0, 17.0, 29.0, 9.0, 10.0, 25.0, 26.0, 45.0, 35.0, 30.0, 37.0, 9.0, 6.0, 6.0, 12.0, 26.0, 41.0, 12.0, 8.0, 14.0, 8.0, 32.0, 30.0, 10.0, 7.0, 22.0, 6.0, 53.0, 47.0, 9.0, 6.0, 32.0, 32.0, 3.0, 6.0, 89.0, 38.0, 4.0, 8.0, 24.0, 36.0, 6.0, 8.0, 5.0, 1.0, 13.0, 3.0, 4.0, 10.0, 1.0, 6.0, 7.0, 30.0, 28.0, 25.0, 11.0, 2.0, 4.0, 15.0, 1.0, 6.0, 6.0, 12.0, 8.0, 2.0, 7.0, 5.0, 2.0, 13.0, 3.0, 5.0, 19.0, 2.0, 14.0, 9.0, 27.0, 23.0, 4.0, 14.0, 14.0, 14.0, 9.0, 9.0, 13.0, 11.0, 2.0, 4.0, 10.0, 11.0, 13.0, 9.0, 4.0, 6.0, 0.0, 1.0, 11.0, 11.0, 9.0, 9.0, 3.0, 49.0, 9.0, 10.0, 17.0, 0.0, 9.0, 7.0, 0.0, 6.0, 29.0, 11.0, 1.0, 2.0, 4.0, 5.0, 21.0, 19.0, 5.0, 3.0, 9.0, 5.0, 19.0, 21.0, 6.0, 4.0, 1.0, 4.0, 11.0, 12.0, 20.0, 27.0, 2.0, 13.0, 1.0, 12.0, 1.0, 12.0, 7.0, 1.0, 6.0, 10.0, 15.0, 11.0, 23.0, 7.0, 11.0, 11.0, 12.0, 4.0, 25.0, 26.0, 23.0, 28.0, 14.0, 12.0, 2.0, 4.0, 2.0, 9.0, 0.0, 5.0, 10.0, 6.0, 21.0, 20.0, 0.0, 16.0, 6.0, 5.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5862306986153977, "mean_inference_ms": 1.8153524309550073, "mean_action_processing_ms": 0.2523679630736156, "mean_env_wait_ms": 0.1964805471313831, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005817413330078125, "StateBufferConnector_ms": 0.0033614635467529297, "ViewRequirementAgentConnector_ms": 0.09252059459686279}, "num_episodes": 27, "episode_return_max": 78.49999999999945, "episode_return_min": -61.79999999999996, "episode_return_mean": 25.604000000000145, "episodes_this_iter": 27}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2560000, "num_agent_steps_trained": 2560000, "num_env_steps_sampled": 640000, "num_env_steps_trained": 640000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 373.2309493436441, "num_env_steps_trained_throughput_per_sec": 373.2309493436441, "timesteps_total": 640000, "num_env_steps_sampled_lifetime": 640000, "num_agent_steps_sampled_lifetime": 2560000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2560000, "timers": {"training_iteration_time_ms": 11151.337, "restore_workers_time_ms": 0.03, "training_step_time_ms": 11151.259, "sample_time_ms": 1378.52, "learn_time_ms": 9756.232, "learn_throughput": 409.994, "synch_weights_time_ms": 14.271}, "counters": {"num_env_steps_sampled": 640000, "num_env_steps_trained": 640000, "num_agent_steps_sampled": 2560000, "num_agent_steps_trained": 2560000}, "done": false, "training_iteration": 160, "trial_id": "3dae5_00000", "date": "2024-08-14_09-36-19", "timestamp": 1723642579, "time_this_iter_s": 10.721697092056274, "time_total_s": 3396.6446311473846, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3981f70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3396.6446311473846, "iterations_since_restore": 160, "perf": {"cpu_util_percent": 28.446666666666665, "ram_util_percent": 83.52666666666664}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6282057906111713, "cur_kl_coeff": 5.21421432495117e-05, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.6598745459996204, "policy_loss": -0.002842804579010046, "vf_loss": 0.6627162738402606, "vf_explained_var": 0.015828497132296285, "kl": 0.02063852944634852, "entropy": 0.8549696920725404, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 303345.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.0533190875141707, "cur_kl_coeff": 0.011865234375000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.203039326743474, "policy_loss": -0.009259760859249918, "vf_loss": 1.2122036696426453, "vf_explained_var": 0.027668104663727777, "kl": 0.008041724968839026, "entropy": 0.8112736628169105, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 303345.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 644000, "num_env_steps_trained": 644000, "num_agent_steps_sampled": 2576000, "num_agent_steps_trained": 2576000}, "env_runners": {"episode_reward_max": 78.49999999999945, "episode_reward_min": -51.30000000000047, "episode_reward_mean": 26.856000000000144, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -166.90000000000063, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 61.40000000000022, "predator_policy": 89.0}, "policy_reward_mean": {"prey_policy": 0.6530000000000138, "predator_policy": 12.775}, "custom_metrics": {}, "hist_stats": {"episode_reward": [19.89999999999998, -5.999999999999696, 20.900000000000063, 23.50000000000003, 32.800000000000196, -0.09999999999985326, 38.70000000000029, 15.8, -2.9999999999997304, 29.700000000000138, 17.300000000000068, 22.400000000000023, 39.700000000000294, 11.60000000000004, 36.40000000000025, -19.899999999999636, 27.700000000000102, 18.099999999999945, 24.600000000000048, 33.4000000000002, 25.10000000000006, 20.400000000000002, 32.30000000000018, -0.6999999999997644, 42.89999999999997, 28.700000000000124, 16.09999999999999, 32.30000000000018, 16.000000000000004, 29.000000000000124, 26.800000000000086, 36.10000000000023, 37.50000000000026, 16.89999999999998, 12.600000000000058, 20.39999999999999, 20.199999999999992, 22.700000000000028, 34.900000000000226, 32.20000000000019, 37.600000000000264, 37.90000000000027, 15.800000000000004, 37.40000000000026, 38.90000000000028, 22.100000000000012, 27.4000000000001, -23.49999999999953, 43.40000000000037, 21.300000000000008, 78.49999999999945, 35.20000000000023, -8.199999999999632, 38.80000000000028, 30.100000000000144, 69.79999999999988, 31.200000000000163, 22.50000000000001, 35.90000000000024, 24.80000000000005, 51.60000000000035, 37.80000000000027, 41.70000000000033, 23.50000000000003, 25.700000000000067, 25.700000000000067, 31.200000000000166, 23.300000000000026, 25.80000000000007, 7.000000000000149, 37.70000000000027, 47.00000000000042, 36.40000000000025, 46.30000000000036, 36.60000000000025, 33.400000000000205, 27.900000000000105, 26.100000000000072, 35.00000000000023, 24.90000000000004, 28.700000000000127, 30.90000000000016, 34.50000000000022, 32.30000000000018, 19.099999999999977, -51.30000000000047, 37.100000000000236, 19.099999999999977, 25.70000000000007, 36.70000000000025, 30.100000000000144, 48.20000000000045, 35.800000000000246, 57.20000000000051, 23.60000000000003, 12.400000000000125, 36.60000000000025, 33.400000000000205, 32.30000000000018, 15.799999999999997], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-13.59999999999979, -17.499999999999787, -45.09999999999976, -40.89999999999976, -66.1000000000002, 20.000000000000014, 7.399999999999965, 1.099999999999983, -5.1999999999999265, 20.000000000000014, -17.799999999999955, -49.299999999999834, 21.20000000000003, -2.4999999999999716, -3.099999999999958, -3.099999999999965, -53.50000000000019, -11.499999999999819, 13.699999999999964, -0.9999999999999846, -18.09999999999976, 7.399999999999965, -93.40000000000057, 15.799999999999963, 20.000000000000014, 4.699999999999967, -11.499999999999819, -40.899999999999764, 7.399999999999965, 20.000000000000014, 20.000000000000014, -166.90000000000063, 12.499999999999964, 3.1999999999999615, -61.90000000000051, 20.000000000000014, 7.399999999999965, 3.1999999999999615, 9.499999999999964, 17.899999999999988, -2.4999999999999716, 11.599999999999964, 7.399999999999965, -0.9999999999999846, 7.399999999999965, 17.899999999999988, 11.599999999999964, -49.29999999999976, 34.99999999999998, -45.09999999999976, 20.000000000000014, -4.299999999999944, -9.699999999999854, 6.799999999999967, 17.899999999999988, 7.399999999999965, 3.1999999999999615, -5.1999999999999265, 15.799999999999963, 3.1999999999999615, 11.599999999999964, 3.1999999999999615, 28.400000000000155, -7.299999999999919, 9.499999999999964, 20.000000000000014, -19.899999999999743, 15.799999999999963, -3.099999999999958, -7.299999999999891, -34.89999999999976, 5.299999999999965, -9.399999999999855, 11.599999999999964, -6.399999999999908, 1.0999999999999865, 20.000000000000014, -3.099999999999958, 7.399999999999965, 0.7999999999999723, 11.599999999999964, 20.000000000000014, 20.000000000000014, -3.099999999999958, 3.1999999999999615, -9.399999999999855, 20.000000000000014, 7.399999999999965, 17.899999999999988, 20.000000000000014, 3.1999999999999615, -3.099999999999958, 1.0999999999999865, 8.299999999999969, 1.0999999999999528, -76.60000000000085, -0.9999999999999846, 25.40000000000011, -15.699999999999747, 20.000000000000014, 1.0999999999999865, 61.40000000000022, 7.399999999999965, 21.80000000000004, -7.299999999999891, -40.89999999999976, 20.000000000000014, 15.799999999999963, 9.499999999999964, 11.599999999999964, 18.200000000000045, 11.599999999999964, 9.499999999999964, 13.699999999999964, 7.399999999999965, 1.0999999999999865, 20.000000000000014, -24.099999999999746, 7.399999999999965, 7.399999999999965, 11.599999999999964, 35.00000000000017, -5.1999999999999265, 20.000000000000014, -5.1999999999999265, -0.10000000000002768, 15.799999999999963, -7.299999999999891, -5.1999999999999265, 17.899999999999988, -5.1999999999999265, 17.899999999999988, 17.899999999999988, 5.299999999999965, -0.09999999999999937, 7.399999999999965, -5.499999999999925, 5.299999999999965, -28.29999999999975, 5.299999999999965, 15.799999999999962, -0.10000000000001347, 36.20000000000026, -5.1999999999999265, -34.59999999999975, 20.000000000000014, 5.299999999999965, -9.999999999999952, -9.399999999999855, 20.000000000000014, 15.799999999999963, 11.599999999999966, 1.0999999999999865, 15.799999999999963, 9.499999999999964, 11.599999999999964, -0.9999999999999846, 20.000000000000014, 20.000000000000014, -36.09999999999985, 26.300000000000114, -13.599999999999783, 9.499999999999964, 10.399999999999965, 17.899999999999988, 11.599999999999964, 13.699999999999964, 11.599999999999964, 20.000000000000014, -19.899999999999743, -139.60000000000068, 5.299999999999965, -3.099999999999958, 21.20000000000003, 13.699999999999964, -13.599999999999783, 11.599999999999966, 1.0999999999999865, 21.500000000000036, 3.1999999999999615, 15.799999999999963, 5.299999999999965, -23.79999999999977, 20.000000000000014, 20.000000000000014, -20.199999999999747, 7.399999999999965, 39.80000000000025, 5.299999999999965, 5.299999999999965, -114.40000000000077, 51.80000000000014, 17.899999999999988, -1.2999999999999847, 20.000000000000014, -13.599999999999783, 15.799999999999963, 9.499999999999964, -9.399999999999858, 3.1999999999999615], "policy_predator_policy_reward": [25.0, 26.0, 45.0, 35.0, 30.0, 37.0, 9.0, 6.0, 6.0, 12.0, 26.0, 41.0, 12.0, 8.0, 14.0, 8.0, 32.0, 30.0, 10.0, 7.0, 22.0, 6.0, 53.0, 47.0, 9.0, 6.0, 32.0, 32.0, 3.0, 6.0, 89.0, 38.0, 4.0, 8.0, 24.0, 36.0, 6.0, 8.0, 5.0, 1.0, 13.0, 3.0, 4.0, 10.0, 1.0, 6.0, 7.0, 30.0, 28.0, 25.0, 11.0, 2.0, 4.0, 15.0, 1.0, 6.0, 6.0, 12.0, 8.0, 2.0, 7.0, 5.0, 2.0, 13.0, 3.0, 5.0, 19.0, 2.0, 14.0, 9.0, 27.0, 23.0, 4.0, 14.0, 14.0, 14.0, 9.0, 9.0, 13.0, 11.0, 2.0, 4.0, 10.0, 11.0, 13.0, 9.0, 4.0, 6.0, 0.0, 1.0, 11.0, 11.0, 9.0, 9.0, 3.0, 49.0, 9.0, 10.0, 17.0, 0.0, 9.0, 7.0, 0.0, 6.0, 29.0, 11.0, 1.0, 2.0, 4.0, 5.0, 21.0, 19.0, 5.0, 3.0, 9.0, 5.0, 19.0, 21.0, 6.0, 4.0, 1.0, 4.0, 11.0, 12.0, 20.0, 27.0, 2.0, 13.0, 1.0, 12.0, 1.0, 12.0, 7.0, 1.0, 6.0, 10.0, 15.0, 11.0, 23.0, 7.0, 11.0, 11.0, 12.0, 4.0, 25.0, 26.0, 23.0, 28.0, 14.0, 12.0, 2.0, 4.0, 2.0, 9.0, 0.0, 5.0, 10.0, 6.0, 21.0, 20.0, 0.0, 16.0, 6.0, 5.0, 1.0, 4.0, 4.0, 3.0, 19.0, 0.0, 76.0, 7.0, 8.0, 11.0, 9.0, 10.0, 4.0, 9.0, 5.0, 7.0, 7.0, 2.0, 26.0, 26.0, 17.0, 19.0, 4.0, 6.0, 6.0, 7.0, 64.0, 11.0, 11.0, 9.0, 15.0, 12.0, 5.0, 2.0, 9.0, 13.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5860189993383071, "mean_inference_ms": 1.8147415263040525, "mean_action_processing_ms": 0.25254747940916256, "mean_env_wait_ms": 0.19628036985940325, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006182670593261719, "StateBufferConnector_ms": 0.0033534765243530273, "ViewRequirementAgentConnector_ms": 0.09286415576934814}, "num_episodes": 18, "episode_return_max": 78.49999999999945, "episode_return_min": -51.30000000000047, "episode_return_mean": 26.856000000000144, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2576000, "num_agent_steps_trained": 2576000, "num_env_steps_sampled": 644000, "num_env_steps_trained": 644000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 362.27172823954356, "num_env_steps_trained_throughput_per_sec": 362.27172823954356, "timesteps_total": 644000, "num_env_steps_sampled_lifetime": 644000, "num_agent_steps_sampled_lifetime": 2576000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2576000, "timers": {"training_iteration_time_ms": 11082.792, "restore_workers_time_ms": 0.03, "training_step_time_ms": 11082.715, "sample_time_ms": 1307.349, "learn_time_ms": 9758.936, "learn_throughput": 409.881, "synch_weights_time_ms": 14.225}, "counters": {"num_env_steps_sampled": 644000, "num_env_steps_trained": 644000, "num_agent_steps_sampled": 2576000, "num_agent_steps_trained": 2576000}, "done": false, "training_iteration": 161, "trial_id": "3dae5_00000", "date": "2024-08-14_09-36-30", "timestamp": 1723642590, "time_this_iter_s": 11.071407079696655, "time_total_s": 3407.7160382270813, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b39cd430>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3407.7160382270813, "iterations_since_restore": 161, "perf": {"cpu_util_percent": 29.53125, "ram_util_percent": 83.76875}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5317880391759215, "cur_kl_coeff": 7.82132148742676e-05, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.078445898792731, "policy_loss": -0.0024713077774596594, "vf_loss": 1.0809166321954715, "vf_explained_var": -0.017655266340447482, "kl": 0.007315252808517154, "entropy": 0.8605139270346001, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 305235.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.2735692947945267, "cur_kl_coeff": 0.011865234375000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.0857583300461844, "policy_loss": -0.014927240894003598, "vf_loss": 2.1003818135412913, "vf_explained_var": 0.0033062553279614324, "kl": 0.025600500964475522, "entropy": 0.9109757582977336, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 305235.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 648000, "num_env_steps_trained": 648000, "num_agent_steps_sampled": 2592000, "num_agent_steps_trained": 2592000}, "env_runners": {"episode_reward_max": 82.1999999999995, "episode_reward_min": -162.4000000000008, "episode_reward_mean": 26.396000000000118, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -372.6999999999997, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 64.99999999999999, "predator_policy": 187.0}, "policy_reward_mean": {"prey_policy": 0.8180000000000177, "predator_policy": 12.38}, "custom_metrics": {}, "hist_stats": {"episode_reward": [24.600000000000048, 33.4000000000002, 25.10000000000006, 20.400000000000002, 32.30000000000018, -0.6999999999997644, 42.89999999999997, 28.700000000000124, 16.09999999999999, 32.30000000000018, 16.000000000000004, 29.000000000000124, 26.800000000000086, 36.10000000000023, 37.50000000000026, 16.89999999999998, 12.600000000000058, 20.39999999999999, 20.199999999999992, 22.700000000000028, 34.900000000000226, 32.20000000000019, 37.600000000000264, 37.90000000000027, 15.800000000000004, 37.40000000000026, 38.90000000000028, 22.100000000000012, 27.4000000000001, -23.49999999999953, 43.40000000000037, 21.300000000000008, 78.49999999999945, 35.20000000000023, -8.199999999999632, 38.80000000000028, 30.100000000000144, 69.79999999999988, 31.200000000000163, 22.50000000000001, 35.90000000000024, 24.80000000000005, 51.60000000000035, 37.80000000000027, 41.70000000000033, 23.50000000000003, 25.700000000000067, 25.700000000000067, 31.200000000000166, 23.300000000000026, 25.80000000000007, 7.000000000000149, 37.70000000000027, 47.00000000000042, 36.40000000000025, 46.30000000000036, 36.60000000000025, 33.400000000000205, 27.900000000000105, 26.100000000000072, 35.00000000000023, 24.90000000000004, 28.700000000000127, 30.90000000000016, 34.50000000000022, 32.30000000000018, 19.099999999999977, -51.30000000000047, 37.100000000000236, 19.099999999999977, 25.70000000000007, 36.70000000000025, 30.100000000000144, 48.20000000000045, 35.800000000000246, 57.20000000000051, 23.60000000000003, 12.400000000000125, 36.60000000000025, 33.400000000000205, 32.30000000000018, 15.799999999999997, 64.40000000000026, 16.399999999999956, 42.400000000000354, 25.400000000000066, 22.10000000000001, -117.10000000000042, 35.600000000000236, 33.2000000000002, 56.100000000000314, 30.100000000000144, 5.200000000000134, 69.29999999999997, 24.10000000000004, -14.99999999999965, 38.70000000000028, 28.800000000000132, 82.1999999999995, -162.4000000000008], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [7.399999999999965, 3.1999999999999615, 9.499999999999964, 17.899999999999988, -2.4999999999999716, 11.599999999999964, 7.399999999999965, -0.9999999999999846, 7.399999999999965, 17.899999999999988, 11.599999999999964, -49.29999999999976, 34.99999999999998, -45.09999999999976, 20.000000000000014, -4.299999999999944, -9.699999999999854, 6.799999999999967, 17.899999999999988, 7.399999999999965, 3.1999999999999615, -5.1999999999999265, 15.799999999999963, 3.1999999999999615, 11.599999999999964, 3.1999999999999615, 28.400000000000155, -7.299999999999919, 9.499999999999964, 20.000000000000014, -19.899999999999743, 15.799999999999963, -3.099999999999958, -7.299999999999891, -34.89999999999976, 5.299999999999965, -9.399999999999855, 11.599999999999964, -6.399999999999908, 1.0999999999999865, 20.000000000000014, -3.099999999999958, 7.399999999999965, 0.7999999999999723, 11.599999999999964, 20.000000000000014, 20.000000000000014, -3.099999999999958, 3.1999999999999615, -9.399999999999855, 20.000000000000014, 7.399999999999965, 17.899999999999988, 20.000000000000014, 3.1999999999999615, -3.099999999999958, 1.0999999999999865, 8.299999999999969, 1.0999999999999528, -76.60000000000085, -0.9999999999999846, 25.40000000000011, -15.699999999999747, 20.000000000000014, 1.0999999999999865, 61.40000000000022, 7.399999999999965, 21.80000000000004, -7.299999999999891, -40.89999999999976, 20.000000000000014, 15.799999999999963, 9.499999999999964, 11.599999999999964, 18.200000000000045, 11.599999999999964, 9.499999999999964, 13.699999999999964, 7.399999999999965, 1.0999999999999865, 20.000000000000014, -24.099999999999746, 7.399999999999965, 7.399999999999965, 11.599999999999964, 35.00000000000017, -5.1999999999999265, 20.000000000000014, -5.1999999999999265, -0.10000000000002768, 15.799999999999963, -7.299999999999891, -5.1999999999999265, 17.899999999999988, -5.1999999999999265, 17.899999999999988, 17.899999999999988, 5.299999999999965, -0.09999999999999937, 7.399999999999965, -5.499999999999925, 5.299999999999965, -28.29999999999975, 5.299999999999965, 15.799999999999962, -0.10000000000001347, 36.20000000000026, -5.1999999999999265, -34.59999999999975, 20.000000000000014, 5.299999999999965, -9.999999999999952, -9.399999999999855, 20.000000000000014, 15.799999999999963, 11.599999999999966, 1.0999999999999865, 15.799999999999963, 9.499999999999964, 11.599999999999964, -0.9999999999999846, 20.000000000000014, 20.000000000000014, -36.09999999999985, 26.300000000000114, -13.599999999999783, 9.499999999999964, 10.399999999999965, 17.899999999999988, 11.599999999999964, 13.699999999999964, 11.599999999999964, 20.000000000000014, -19.899999999999743, -139.60000000000068, 5.299999999999965, -3.099999999999958, 21.20000000000003, 13.699999999999964, -13.599999999999783, 11.599999999999966, 1.0999999999999865, 21.500000000000036, 3.1999999999999615, 15.799999999999963, 5.299999999999965, -23.79999999999977, 20.000000000000014, 20.000000000000014, -20.199999999999747, 7.399999999999965, 39.80000000000025, 5.299999999999965, 5.299999999999965, -114.40000000000077, 51.80000000000014, 17.899999999999988, -1.2999999999999847, 20.000000000000014, -13.599999999999783, 15.799999999999963, 9.499999999999964, -9.399999999999858, 3.1999999999999615, 48.2000000000001, 3.1999999999999615, -12.699999999999815, 1.0999999999999865, -31.599999999999767, 20.000000000000014, -17.199999999999747, 11.599999999999964, -5.1999999999999265, 5.299999999999965, 59.60000000000015, -372.6999999999997, 20.000000000000014, 11.599999999999964, 20.000000000000014, 3.1999999999999615, -5.1999999999999265, 38.3000000000001, 13.699999999999964, 7.399999999999965, -57.70000000000048, 20.90000000000003, 61.40000000000021, -3.099999999999958, -7.299999999999891, 7.399999999999965, 20.90000000000003, -103.9000000000006, 20.000000000000014, 13.699999999999964, -1.8999999999999853, 13.699999999999964, 3.1999999999999615, 64.99999999999999, -357.99999999999955, 11.599999999999964], "policy_predator_policy_reward": [6.0, 8.0, 5.0, 1.0, 13.0, 3.0, 4.0, 10.0, 1.0, 6.0, 7.0, 30.0, 28.0, 25.0, 11.0, 2.0, 4.0, 15.0, 1.0, 6.0, 6.0, 12.0, 8.0, 2.0, 7.0, 5.0, 2.0, 13.0, 3.0, 5.0, 19.0, 2.0, 14.0, 9.0, 27.0, 23.0, 4.0, 14.0, 14.0, 14.0, 9.0, 9.0, 13.0, 11.0, 2.0, 4.0, 10.0, 11.0, 13.0, 9.0, 4.0, 6.0, 0.0, 1.0, 11.0, 11.0, 9.0, 9.0, 3.0, 49.0, 9.0, 10.0, 17.0, 0.0, 9.0, 7.0, 0.0, 6.0, 29.0, 11.0, 1.0, 2.0, 4.0, 5.0, 21.0, 19.0, 5.0, 3.0, 9.0, 5.0, 19.0, 21.0, 6.0, 4.0, 1.0, 4.0, 11.0, 12.0, 20.0, 27.0, 2.0, 13.0, 1.0, 12.0, 1.0, 12.0, 7.0, 1.0, 6.0, 10.0, 15.0, 11.0, 23.0, 7.0, 11.0, 11.0, 12.0, 4.0, 25.0, 26.0, 23.0, 28.0, 14.0, 12.0, 2.0, 4.0, 2.0, 9.0, 0.0, 5.0, 10.0, 6.0, 21.0, 20.0, 0.0, 16.0, 6.0, 5.0, 1.0, 4.0, 4.0, 3.0, 19.0, 0.0, 76.0, 7.0, 8.0, 11.0, 9.0, 10.0, 4.0, 9.0, 5.0, 7.0, 7.0, 2.0, 26.0, 26.0, 17.0, 19.0, 4.0, 6.0, 6.0, 7.0, 64.0, 11.0, 11.0, 9.0, 15.0, 12.0, 5.0, 2.0, 9.0, 13.0, 5.0, 8.0, 21.0, 7.0, 26.0, 28.0, 12.0, 19.0, 10.0, 12.0, 9.0, 187.0, 0.0, 4.0, 2.0, 8.0, 12.0, 11.0, 3.0, 6.0, 5.0, 37.0, 11.0, 0.0, 12.0, 12.0, 3.0, 65.0, 2.0, 3.0, 16.0, 1.0, 8.0, 6.0, 180.0, 4.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5858821496622443, "mean_inference_ms": 1.814191502155758, "mean_action_processing_ms": 0.2524108947020904, "mean_env_wait_ms": 0.1962045033424394, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006891369819641113, "StateBufferConnector_ms": 0.003387928009033203, "ViewRequirementAgentConnector_ms": 0.09650754928588867}, "num_episodes": 18, "episode_return_max": 82.1999999999995, "episode_return_min": -162.4000000000008, "episode_return_mean": 26.396000000000118, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2592000, "num_agent_steps_trained": 2592000, "num_env_steps_sampled": 648000, "num_env_steps_trained": 648000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 368.1757354312738, "num_env_steps_trained_throughput_per_sec": 368.1757354312738, "timesteps_total": 648000, "num_env_steps_sampled_lifetime": 648000, "num_agent_steps_sampled_lifetime": 2592000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2592000, "timers": {"training_iteration_time_ms": 11084.08, "restore_workers_time_ms": 0.03, "training_step_time_ms": 11084.0, "sample_time_ms": 1301.988, "learn_time_ms": 9765.207, "learn_throughput": 409.618, "synch_weights_time_ms": 14.317}, "counters": {"num_env_steps_sampled": 648000, "num_env_steps_trained": 648000, "num_agent_steps_sampled": 2592000, "num_agent_steps_trained": 2592000}, "done": false, "training_iteration": 162, "trial_id": "3dae5_00000", "date": "2024-08-14_09-36-41", "timestamp": 1723642601, "time_this_iter_s": 10.919106006622314, "time_total_s": 3418.6351442337036, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b36ef040>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3418.6351442337036, "iterations_since_restore": 162, "perf": {"cpu_util_percent": 31.586666666666666, "ram_util_percent": 83.58666666666666}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6324826819713785, "cur_kl_coeff": 7.82132148742676e-05, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.8363247820466915, "policy_loss": -0.0036858668592733837, "vf_loss": 0.8400094440374425, "vf_explained_var": 0.062319101543022844, "kl": 0.015421192452441702, "entropy": 0.9496666795046872, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 307125.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.687579321703583, "cur_kl_coeff": 0.01779785156249999, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.8043144573294927, "policy_loss": -0.016361723619725103, "vf_loss": 1.8203931241123765, "vf_explained_var": 0.030291432583773578, "kl": 0.015904040031997888, "entropy": 0.9736395508523972, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 307125.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 652000, "num_env_steps_trained": 652000, "num_agent_steps_sampled": 2608000, "num_agent_steps_trained": 2608000}, "env_runners": {"episode_reward_max": 82.1999999999995, "episode_reward_min": -162.4000000000008, "episode_reward_mean": 26.82200000000012, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -372.6999999999997, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 64.99999999999999, "predator_policy": 187.0}, "policy_reward_mean": {"prey_policy": -0.06399999999998557, "predator_policy": 13.475}, "custom_metrics": {}, "hist_stats": {"episode_reward": [20.199999999999992, 22.700000000000028, 34.900000000000226, 32.20000000000019, 37.600000000000264, 37.90000000000027, 15.800000000000004, 37.40000000000026, 38.90000000000028, 22.100000000000012, 27.4000000000001, -23.49999999999953, 43.40000000000037, 21.300000000000008, 78.49999999999945, 35.20000000000023, -8.199999999999632, 38.80000000000028, 30.100000000000144, 69.79999999999988, 31.200000000000163, 22.50000000000001, 35.90000000000024, 24.80000000000005, 51.60000000000035, 37.80000000000027, 41.70000000000033, 23.50000000000003, 25.700000000000067, 25.700000000000067, 31.200000000000166, 23.300000000000026, 25.80000000000007, 7.000000000000149, 37.70000000000027, 47.00000000000042, 36.40000000000025, 46.30000000000036, 36.60000000000025, 33.400000000000205, 27.900000000000105, 26.100000000000072, 35.00000000000023, 24.90000000000004, 28.700000000000127, 30.90000000000016, 34.50000000000022, 32.30000000000018, 19.099999999999977, -51.30000000000047, 37.100000000000236, 19.099999999999977, 25.70000000000007, 36.70000000000025, 30.100000000000144, 48.20000000000045, 35.800000000000246, 57.20000000000051, 23.60000000000003, 12.400000000000125, 36.60000000000025, 33.400000000000205, 32.30000000000018, 15.799999999999997, 64.40000000000026, 16.399999999999956, 42.400000000000354, 25.400000000000066, 22.10000000000001, -117.10000000000042, 35.600000000000236, 33.2000000000002, 56.100000000000314, 30.100000000000144, 5.200000000000134, 69.29999999999997, 24.10000000000004, -14.99999999999965, 38.70000000000028, 28.800000000000132, 82.1999999999995, -162.4000000000008, 60.900000000000325, 17.999999999999975, 47.40000000000004, 45.60000000000032, 82.09999999999991, 37.40000000000026, 38.70000000000028, 38.50000000000028, 30.60000000000017, 21.4, 72.60000000000034, 38.300000000000274, 38.300000000000274, 29.000000000000124, 65.80000000000027, -159.10000000000088, -56.400000000000716, 43.900000000000276], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-9.399999999999855, 11.599999999999964, -6.399999999999908, 1.0999999999999865, 20.000000000000014, -3.099999999999958, 7.399999999999965, 0.7999999999999723, 11.599999999999964, 20.000000000000014, 20.000000000000014, -3.099999999999958, 3.1999999999999615, -9.399999999999855, 20.000000000000014, 7.399999999999965, 17.899999999999988, 20.000000000000014, 3.1999999999999615, -3.099999999999958, 1.0999999999999865, 8.299999999999969, 1.0999999999999528, -76.60000000000085, -0.9999999999999846, 25.40000000000011, -15.699999999999747, 20.000000000000014, 1.0999999999999865, 61.40000000000022, 7.399999999999965, 21.80000000000004, -7.299999999999891, -40.89999999999976, 20.000000000000014, 15.799999999999963, 9.499999999999964, 11.599999999999964, 18.200000000000045, 11.599999999999964, 9.499999999999964, 13.699999999999964, 7.399999999999965, 1.0999999999999865, 20.000000000000014, -24.099999999999746, 7.399999999999965, 7.399999999999965, 11.599999999999964, 35.00000000000017, -5.1999999999999265, 20.000000000000014, -5.1999999999999265, -0.10000000000002768, 15.799999999999963, -7.299999999999891, -5.1999999999999265, 17.899999999999988, -5.1999999999999265, 17.899999999999988, 17.899999999999988, 5.299999999999965, -0.09999999999999937, 7.399999999999965, -5.499999999999925, 5.299999999999965, -28.29999999999975, 5.299999999999965, 15.799999999999962, -0.10000000000001347, 36.20000000000026, -5.1999999999999265, -34.59999999999975, 20.000000000000014, 5.299999999999965, -9.999999999999952, -9.399999999999855, 20.000000000000014, 15.799999999999963, 11.599999999999966, 1.0999999999999865, 15.799999999999963, 9.499999999999964, 11.599999999999964, -0.9999999999999846, 20.000000000000014, 20.000000000000014, -36.09999999999985, 26.300000000000114, -13.599999999999783, 9.499999999999964, 10.399999999999965, 17.899999999999988, 11.599999999999964, 13.699999999999964, 11.599999999999964, 20.000000000000014, -19.899999999999743, -139.60000000000068, 5.299999999999965, -3.099999999999958, 21.20000000000003, 13.699999999999964, -13.599999999999783, 11.599999999999966, 1.0999999999999865, 21.500000000000036, 3.1999999999999615, 15.799999999999963, 5.299999999999965, -23.79999999999977, 20.000000000000014, 20.000000000000014, -20.199999999999747, 7.399999999999965, 39.80000000000025, 5.299999999999965, 5.299999999999965, -114.40000000000077, 51.80000000000014, 17.899999999999988, -1.2999999999999847, 20.000000000000014, -13.599999999999783, 15.799999999999963, 9.499999999999964, -9.399999999999858, 3.1999999999999615, 48.2000000000001, 3.1999999999999615, -12.699999999999815, 1.0999999999999865, -31.599999999999767, 20.000000000000014, -17.199999999999747, 11.599999999999964, -5.1999999999999265, 5.299999999999965, 59.60000000000015, -372.6999999999997, 20.000000000000014, 11.599999999999964, 20.000000000000014, 3.1999999999999615, -5.1999999999999265, 38.3000000000001, 13.699999999999964, 7.399999999999965, -57.70000000000048, 20.90000000000003, 61.40000000000021, -3.099999999999958, -7.299999999999891, 7.399999999999965, 20.90000000000003, -103.9000000000006, 20.000000000000014, 13.699999999999964, -1.8999999999999853, 13.699999999999964, 3.1999999999999615, 64.99999999999999, -357.99999999999955, 11.599999999999964, 50.900000000000155, -21.999999999999744, 20.000000000000014, -21.999999999999744, -4.2999999999998, 13.699999999999964, -21.999999999999744, 47.600000000000115, 49.10000000000006, 20.000000000000014, 20.000000000000014, 7.399999999999965, 20.000000000000014, 13.699999999999964, 20.000000000000014, -11.499999999999819, 3.1999999999999615, 7.39999999999997, -4.599999999999943, -0.9999999999999846, 7.399999999999965, 57.20000000000018, 5.299999999999965, 20.000000000000014, 7.399999999999965, 20.90000000000003, 5.299999999999965, 13.699999999999964, 11.599999999999964, 30.200000000000152, -64.00000000000058, -243.10000000000028, 7.099999999999971, -158.50000000000065, 24.800000000000132, -19.899999999999743], "policy_predator_policy_reward": [4.0, 14.0, 14.0, 14.0, 9.0, 9.0, 13.0, 11.0, 2.0, 4.0, 10.0, 11.0, 13.0, 9.0, 4.0, 6.0, 0.0, 1.0, 11.0, 11.0, 9.0, 9.0, 3.0, 49.0, 9.0, 10.0, 17.0, 0.0, 9.0, 7.0, 0.0, 6.0, 29.0, 11.0, 1.0, 2.0, 4.0, 5.0, 21.0, 19.0, 5.0, 3.0, 9.0, 5.0, 19.0, 21.0, 6.0, 4.0, 1.0, 4.0, 11.0, 12.0, 20.0, 27.0, 2.0, 13.0, 1.0, 12.0, 1.0, 12.0, 7.0, 1.0, 6.0, 10.0, 15.0, 11.0, 23.0, 7.0, 11.0, 11.0, 12.0, 4.0, 25.0, 26.0, 23.0, 28.0, 14.0, 12.0, 2.0, 4.0, 2.0, 9.0, 0.0, 5.0, 10.0, 6.0, 21.0, 20.0, 0.0, 16.0, 6.0, 5.0, 1.0, 4.0, 4.0, 3.0, 19.0, 0.0, 76.0, 7.0, 8.0, 11.0, 9.0, 10.0, 4.0, 9.0, 5.0, 7.0, 7.0, 2.0, 26.0, 26.0, 17.0, 19.0, 4.0, 6.0, 6.0, 7.0, 64.0, 11.0, 11.0, 9.0, 15.0, 12.0, 5.0, 2.0, 9.0, 13.0, 5.0, 8.0, 21.0, 7.0, 26.0, 28.0, 12.0, 19.0, 10.0, 12.0, 9.0, 187.0, 0.0, 4.0, 2.0, 8.0, 12.0, 11.0, 3.0, 6.0, 5.0, 37.0, 11.0, 0.0, 12.0, 12.0, 3.0, 65.0, 2.0, 3.0, 16.0, 1.0, 8.0, 6.0, 180.0, 4.0, 18.0, 14.0, 0.0, 20.0, 15.0, 23.0, 0.0, 20.0, 7.0, 6.0, 6.0, 4.0, 2.0, 3.0, 15.0, 15.0, 9.0, 11.0, 11.0, 16.0, 6.0, 2.0, 7.0, 6.0, 6.0, 4.0, 7.0, 3.0, 6.0, 18.0, 141.0, 7.0, 85.0, 10.0, 20.0, 19.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5857916626896231, "mean_inference_ms": 1.8138480702739233, "mean_action_processing_ms": 0.2523119567007523, "mean_env_wait_ms": 0.19616263330017472, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006102085113525391, "StateBufferConnector_ms": 0.0033746957778930664, "ViewRequirementAgentConnector_ms": 0.09865736961364746}, "num_episodes": 18, "episode_return_max": 82.1999999999995, "episode_return_min": -162.4000000000008, "episode_return_mean": 26.82200000000012, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2608000, "num_agent_steps_trained": 2608000, "num_env_steps_sampled": 652000, "num_env_steps_trained": 652000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 333.91270232785325, "num_env_steps_trained_throughput_per_sec": 333.91270232785325, "timesteps_total": 652000, "num_env_steps_sampled_lifetime": 652000, "num_agent_steps_sampled_lifetime": 2608000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2608000, "timers": {"training_iteration_time_ms": 11184.676, "restore_workers_time_ms": 0.03, "training_step_time_ms": 11184.596, "sample_time_ms": 1324.74, "learn_time_ms": 9842.597, "learn_throughput": 406.397, "synch_weights_time_ms": 14.367}, "counters": {"num_env_steps_sampled": 652000, "num_env_steps_trained": 652000, "num_agent_steps_sampled": 2608000, "num_agent_steps_trained": 2608000}, "done": false, "training_iteration": 163, "trial_id": "3dae5_00000", "date": "2024-08-14_09-36-53", "timestamp": 1723642613, "time_this_iter_s": 12.032680749893188, "time_total_s": 3430.667824983597, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b36e0ca0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3430.667824983597, "iterations_since_restore": 163, "perf": {"cpu_util_percent": 43.170588235294126, "ram_util_percent": 83.54705882352941}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9099047185567322, "cur_kl_coeff": 7.82132148742676e-05, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.5034197144092076, "policy_loss": -0.00285845024378172, "vf_loss": 1.5062775131098176, "vf_explained_var": 0.057469369810094276, "kl": 0.008361231651409022, "entropy": 0.849881037770125, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 309015.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.7587041481462107, "cur_kl_coeff": 0.01779785156249999, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.805585388027171, "policy_loss": -0.011991969986434375, "vf_loss": 2.8171593343770063, "vf_explained_var": 0.08579738644695786, "kl": 0.02348733269133422, "entropy": 1.0159829965344183, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 309015.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 656000, "num_env_steps_trained": 656000, "num_agent_steps_sampled": 2624000, "num_agent_steps_trained": 2624000}, "env_runners": {"episode_reward_max": 136.59999999999982, "episode_reward_min": -290.89999999999907, "episode_reward_mean": 24.2510000000001, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -409.29999999999995, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 82.10000000000007, "predator_policy": 220.0}, "policy_reward_mean": {"prey_policy": -3.924499999999975, "predator_policy": 16.05}, "custom_metrics": {}, "hist_stats": {"episode_reward": [24.80000000000005, 51.60000000000035, 37.80000000000027, 41.70000000000033, 23.50000000000003, 25.700000000000067, 25.700000000000067, 31.200000000000166, 23.300000000000026, 25.80000000000007, 7.000000000000149, 37.70000000000027, 47.00000000000042, 36.40000000000025, 46.30000000000036, 36.60000000000025, 33.400000000000205, 27.900000000000105, 26.100000000000072, 35.00000000000023, 24.90000000000004, 28.700000000000127, 30.90000000000016, 34.50000000000022, 32.30000000000018, 19.099999999999977, -51.30000000000047, 37.100000000000236, 19.099999999999977, 25.70000000000007, 36.70000000000025, 30.100000000000144, 48.20000000000045, 35.800000000000246, 57.20000000000051, 23.60000000000003, 12.400000000000125, 36.60000000000025, 33.400000000000205, 32.30000000000018, 15.799999999999997, 64.40000000000026, 16.399999999999956, 42.400000000000354, 25.400000000000066, 22.10000000000001, -117.10000000000042, 35.600000000000236, 33.2000000000002, 56.100000000000314, 30.100000000000144, 5.200000000000134, 69.29999999999997, 24.10000000000004, -14.99999999999965, 38.70000000000028, 28.800000000000132, 82.1999999999995, -162.4000000000008, 60.900000000000325, 17.999999999999975, 47.40000000000004, 45.60000000000032, 82.09999999999991, 37.40000000000026, 38.70000000000028, 38.50000000000028, 30.60000000000017, 21.4, 72.60000000000034, 38.300000000000274, 38.300000000000274, 29.000000000000124, 65.80000000000027, -159.10000000000088, -56.400000000000716, 43.900000000000276, -185.80000000000075, 14.900000000000007, 38.10000000000027, 36.60000000000025, 38.90000000000028, 25.700000000000067, 48.60000000000044, -95.9000000000006, 38.300000000000274, -290.89999999999907, 38.300000000000274, 41.200000000000315, 93.09999999999947, 101.19999999999945, 27.700000000000102, 32.10000000000018, 74.40000000000028, 19.000000000000004, 105.2999999999991, 136.59999999999982, 60.60000000000019, 12.49999999999995, 34.50000000000022], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [7.399999999999965, 7.399999999999965, 11.599999999999964, 35.00000000000017, -5.1999999999999265, 20.000000000000014, -5.1999999999999265, -0.10000000000002768, 15.799999999999963, -7.299999999999891, -5.1999999999999265, 17.899999999999988, -5.1999999999999265, 17.899999999999988, 17.899999999999988, 5.299999999999965, -0.09999999999999937, 7.399999999999965, -5.499999999999925, 5.299999999999965, -28.29999999999975, 5.299999999999965, 15.799999999999962, -0.10000000000001347, 36.20000000000026, -5.1999999999999265, -34.59999999999975, 20.000000000000014, 5.299999999999965, -9.999999999999952, -9.399999999999855, 20.000000000000014, 15.799999999999963, 11.599999999999966, 1.0999999999999865, 15.799999999999963, 9.499999999999964, 11.599999999999964, -0.9999999999999846, 20.000000000000014, 20.000000000000014, -36.09999999999985, 26.300000000000114, -13.599999999999783, 9.499999999999964, 10.399999999999965, 17.899999999999988, 11.599999999999964, 13.699999999999964, 11.599999999999964, 20.000000000000014, -19.899999999999743, -139.60000000000068, 5.299999999999965, -3.099999999999958, 21.20000000000003, 13.699999999999964, -13.599999999999783, 11.599999999999966, 1.0999999999999865, 21.500000000000036, 3.1999999999999615, 15.799999999999963, 5.299999999999965, -23.79999999999977, 20.000000000000014, 20.000000000000014, -20.199999999999747, 7.399999999999965, 39.80000000000025, 5.299999999999965, 5.299999999999965, -114.40000000000077, 51.80000000000014, 17.899999999999988, -1.2999999999999847, 20.000000000000014, -13.599999999999783, 15.799999999999963, 9.499999999999964, -9.399999999999858, 3.1999999999999615, 48.2000000000001, 3.1999999999999615, -12.699999999999815, 1.0999999999999865, -31.599999999999767, 20.000000000000014, -17.199999999999747, 11.599999999999964, -5.1999999999999265, 5.299999999999965, 59.60000000000015, -372.6999999999997, 20.000000000000014, 11.599999999999964, 20.000000000000014, 3.1999999999999615, -5.1999999999999265, 38.3000000000001, 13.699999999999964, 7.399999999999965, -57.70000000000048, 20.90000000000003, 61.40000000000021, -3.099999999999958, -7.299999999999891, 7.399999999999965, 20.90000000000003, -103.9000000000006, 20.000000000000014, 13.699999999999964, -1.8999999999999853, 13.699999999999964, 3.1999999999999615, 64.99999999999999, -357.99999999999955, 11.599999999999964, 50.900000000000155, -21.999999999999744, 20.000000000000014, -21.999999999999744, -4.2999999999998, 13.699999999999964, -21.999999999999744, 47.600000000000115, 49.10000000000006, 20.000000000000014, 20.000000000000014, 7.399999999999965, 20.000000000000014, 13.699999999999964, 20.000000000000014, -11.499999999999819, 3.1999999999999615, 7.39999999999997, -4.599999999999943, -0.9999999999999846, 7.399999999999965, 57.20000000000018, 5.299999999999965, 20.000000000000014, 7.399999999999965, 20.90000000000003, 5.299999999999965, 13.699999999999964, 11.599999999999964, 30.200000000000152, -64.00000000000058, -243.10000000000028, 7.099999999999971, -158.50000000000065, 24.800000000000132, -19.899999999999743, -11.499999999999822, -409.29999999999995, 5.299999999999965, -9.399999999999862, 5.299999999999965, 21.80000000000004, -9.399999999999855, 20.000000000000014, 17.899999999999988, 20.000000000000014, -5.1999999999999265, 17.899999999999988, 11.599999999999964, 29.000000000000163, -247.3000000000001, 7.399999999999965, 11.599999999999964, 7.699999999999967, -225.30000000000038, -286.5999999999992, 20.000000000000014, 5.299999999999965, 25.100000000000104, 4.099999999999966, 80.30000000000001, -5.199999999999934, 69.2000000000001, -7.000000000000027, -0.9999999999999917, 13.699999999999964, 15.799999999999963, -15.699999999999747, 36.800000000000026, 11.599999999999964, -3.099999999999958, 1.0999999999999865, 31.700000000000212, 68.6000000000001, 82.10000000000007, 33.500000000000085, -24.099999999999746, 46.70000000000003, 20.000000000000014, -32.4999999999999, 17.899999999999988, 11.599999999999964], "policy_predator_policy_reward": [6.0, 4.0, 1.0, 4.0, 11.0, 12.0, 20.0, 27.0, 2.0, 13.0, 1.0, 12.0, 1.0, 12.0, 7.0, 1.0, 6.0, 10.0, 15.0, 11.0, 23.0, 7.0, 11.0, 11.0, 12.0, 4.0, 25.0, 26.0, 23.0, 28.0, 14.0, 12.0, 2.0, 4.0, 2.0, 9.0, 0.0, 5.0, 10.0, 6.0, 21.0, 20.0, 0.0, 16.0, 6.0, 5.0, 1.0, 4.0, 4.0, 3.0, 19.0, 0.0, 76.0, 7.0, 8.0, 11.0, 9.0, 10.0, 4.0, 9.0, 5.0, 7.0, 7.0, 2.0, 26.0, 26.0, 17.0, 19.0, 4.0, 6.0, 6.0, 7.0, 64.0, 11.0, 11.0, 9.0, 15.0, 12.0, 5.0, 2.0, 9.0, 13.0, 5.0, 8.0, 21.0, 7.0, 26.0, 28.0, 12.0, 19.0, 10.0, 12.0, 9.0, 187.0, 0.0, 4.0, 2.0, 8.0, 12.0, 11.0, 3.0, 6.0, 5.0, 37.0, 11.0, 0.0, 12.0, 12.0, 3.0, 65.0, 2.0, 3.0, 16.0, 1.0, 8.0, 6.0, 180.0, 4.0, 18.0, 14.0, 0.0, 20.0, 15.0, 23.0, 0.0, 20.0, 7.0, 6.0, 6.0, 4.0, 2.0, 3.0, 15.0, 15.0, 9.0, 11.0, 11.0, 16.0, 6.0, 2.0, 7.0, 6.0, 6.0, 4.0, 7.0, 3.0, 6.0, 18.0, 141.0, 7.0, 85.0, 10.0, 20.0, 19.0, 15.0, 220.0, 15.0, 4.0, 4.0, 7.0, 12.0, 14.0, 0.0, 1.0, 12.0, 1.0, 4.0, 4.0, 132.0, 12.0, 10.0, 9.0, 40.0, 181.0, 6.0, 7.0, 8.0, 4.0, 12.0, 6.0, 15.0, 24.0, 7.0, 8.0, 17.0, 15.0, 4.0, 22.0, 11.0, 10.0, 3.0, 2.0, 9.0, 12.0, 17.0, 21.0, 25.0, 0.0, 4.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5859698979781907, "mean_inference_ms": 1.8124355583616687, "mean_action_processing_ms": 0.252336969279495, "mean_env_wait_ms": 0.19620822059137935, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005486845970153809, "StateBufferConnector_ms": 0.003309965133666992, "ViewRequirementAgentConnector_ms": 0.09810090065002441}, "num_episodes": 23, "episode_return_max": 136.59999999999982, "episode_return_min": -290.89999999999907, "episode_return_mean": 24.2510000000001, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2624000, "num_agent_steps_trained": 2624000, "num_env_steps_sampled": 656000, "num_env_steps_trained": 656000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 358.8686659624287, "num_env_steps_trained_throughput_per_sec": 358.8686659624287, "timesteps_total": 656000, "num_env_steps_sampled_lifetime": 656000, "num_agent_steps_sampled_lifetime": 2624000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2624000, "timers": {"training_iteration_time_ms": 11171.628, "restore_workers_time_ms": 0.024, "training_step_time_ms": 11171.563, "sample_time_ms": 1325.097, "learn_time_ms": 9829.524, "learn_throughput": 406.937, "synch_weights_time_ms": 14.592}, "counters": {"num_env_steps_sampled": 656000, "num_env_steps_trained": 656000, "num_agent_steps_sampled": 2624000, "num_agent_steps_trained": 2624000}, "done": false, "training_iteration": 164, "trial_id": "3dae5_00000", "date": "2024-08-14_09-37-04", "timestamp": 1723642624, "time_this_iter_s": 11.152168989181519, "time_total_s": 3441.8199939727783, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b39cdd30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3441.8199939727783, "iterations_since_restore": 164, "perf": {"cpu_util_percent": 30.543750000000003, "ram_util_percent": 83.05625}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3599552904329604, "cur_kl_coeff": 7.82132148742676e-05, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.0055666019361487, "policy_loss": -0.0023559243728717167, "vf_loss": 1.0079207104665262, "vf_explained_var": 0.0878315352888965, "kl": 0.02318626686939591, "entropy": 0.8447644582501164, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 310905.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.8895583848473887, "cur_kl_coeff": 0.02669677734374999, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.043352000486283, "policy_loss": -0.004896906517795903, "vf_loss": 2.047887134993518, "vf_explained_var": 0.06994949758998932, "kl": 0.013551435163748286, "entropy": 1.0400045169093621, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 310905.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 660000, "num_env_steps_trained": 660000, "num_agent_steps_sampled": 2640000, "num_agent_steps_trained": 2640000}, "env_runners": {"episode_reward_max": 136.59999999999982, "episode_reward_min": -322.19999999999914, "episode_reward_mean": 20.70000000000008, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -409.29999999999995, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 85.69999999999999, "predator_policy": 220.0}, "policy_reward_mean": {"prey_policy": -6.5899999999999785, "predator_policy": 16.94}, "custom_metrics": {}, "hist_stats": {"episode_reward": [30.90000000000016, 34.50000000000022, 32.30000000000018, 19.099999999999977, -51.30000000000047, 37.100000000000236, 19.099999999999977, 25.70000000000007, 36.70000000000025, 30.100000000000144, 48.20000000000045, 35.800000000000246, 57.20000000000051, 23.60000000000003, 12.400000000000125, 36.60000000000025, 33.400000000000205, 32.30000000000018, 15.799999999999997, 64.40000000000026, 16.399999999999956, 42.400000000000354, 25.400000000000066, 22.10000000000001, -117.10000000000042, 35.600000000000236, 33.2000000000002, 56.100000000000314, 30.100000000000144, 5.200000000000134, 69.29999999999997, 24.10000000000004, -14.99999999999965, 38.70000000000028, 28.800000000000132, 82.1999999999995, -162.4000000000008, 60.900000000000325, 17.999999999999975, 47.40000000000004, 45.60000000000032, 82.09999999999991, 37.40000000000026, 38.70000000000028, 38.50000000000028, 30.60000000000017, 21.4, 72.60000000000034, 38.300000000000274, 38.300000000000274, 29.000000000000124, 65.80000000000027, -159.10000000000088, -56.400000000000716, 43.900000000000276, -185.80000000000075, 14.900000000000007, 38.10000000000027, 36.60000000000025, 38.90000000000028, 25.700000000000067, 48.60000000000044, -95.9000000000006, 38.300000000000274, -290.89999999999907, 38.300000000000274, 41.200000000000315, 93.09999999999947, 101.19999999999945, 27.700000000000102, 32.10000000000018, 74.40000000000028, 19.000000000000004, 105.2999999999991, 136.59999999999982, 60.60000000000019, 12.49999999999995, 34.50000000000022, 27.800000000000107, 23.50000000000003, 37.600000000000264, 36.70000000000025, 13.599999999999962, 34.40000000000022, 108.09999999999978, 21.300000000000008, 26.00000000000007, 39.50000000000029, 37.30000000000026, -102.20000000000071, 30.100000000000144, 52.50000000000028, 39.90000000000027, 39.60000000000026, 40.70000000000003, 31.300000000000168, 22.000000000000025, 25.70000000000007, 79.79999999999976, -322.19999999999914], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [9.499999999999964, 10.399999999999965, 17.899999999999988, 11.599999999999964, 13.699999999999964, 11.599999999999964, 20.000000000000014, -19.899999999999743, -139.60000000000068, 5.299999999999965, -3.099999999999958, 21.20000000000003, 13.699999999999964, -13.599999999999783, 11.599999999999966, 1.0999999999999865, 21.500000000000036, 3.1999999999999615, 15.799999999999963, 5.299999999999965, -23.79999999999977, 20.000000000000014, 20.000000000000014, -20.199999999999747, 7.399999999999965, 39.80000000000025, 5.299999999999965, 5.299999999999965, -114.40000000000077, 51.80000000000014, 17.899999999999988, -1.2999999999999847, 20.000000000000014, -13.599999999999783, 15.799999999999963, 9.499999999999964, -9.399999999999858, 3.1999999999999615, 48.2000000000001, 3.1999999999999615, -12.699999999999815, 1.0999999999999865, -31.599999999999767, 20.000000000000014, -17.199999999999747, 11.599999999999964, -5.1999999999999265, 5.299999999999965, 59.60000000000015, -372.6999999999997, 20.000000000000014, 11.599999999999964, 20.000000000000014, 3.1999999999999615, -5.1999999999999265, 38.3000000000001, 13.699999999999964, 7.399999999999965, -57.70000000000048, 20.90000000000003, 61.40000000000021, -3.099999999999958, -7.299999999999891, 7.399999999999965, 20.90000000000003, -103.9000000000006, 20.000000000000014, 13.699999999999964, -1.8999999999999853, 13.699999999999964, 3.1999999999999615, 64.99999999999999, -357.99999999999955, 11.599999999999964, 50.900000000000155, -21.999999999999744, 20.000000000000014, -21.999999999999744, -4.2999999999998, 13.699999999999964, -21.999999999999744, 47.600000000000115, 49.10000000000006, 20.000000000000014, 20.000000000000014, 7.399999999999965, 20.000000000000014, 13.699999999999964, 20.000000000000014, -11.499999999999819, 3.1999999999999615, 7.39999999999997, -4.599999999999943, -0.9999999999999846, 7.399999999999965, 57.20000000000018, 5.299999999999965, 20.000000000000014, 7.399999999999965, 20.90000000000003, 5.299999999999965, 13.699999999999964, 11.599999999999964, 30.200000000000152, -64.00000000000058, -243.10000000000028, 7.099999999999971, -158.50000000000065, 24.800000000000132, -19.899999999999743, -11.499999999999822, -409.29999999999995, 5.299999999999965, -9.399999999999862, 5.299999999999965, 21.80000000000004, -9.399999999999855, 20.000000000000014, 17.899999999999988, 20.000000000000014, -5.1999999999999265, 17.899999999999988, 11.599999999999964, 29.000000000000163, -247.3000000000001, 7.399999999999965, 11.599999999999964, 7.699999999999967, -225.30000000000038, -286.5999999999992, 20.000000000000014, 5.299999999999965, 25.100000000000104, 4.099999999999966, 80.30000000000001, -5.199999999999934, 69.2000000000001, -7.000000000000027, -0.9999999999999917, 13.699999999999964, 15.799999999999963, -15.699999999999747, 36.800000000000026, 11.599999999999964, -3.099999999999958, 1.0999999999999865, 31.700000000000212, 68.6000000000001, 82.10000000000007, 33.500000000000085, -24.099999999999746, 46.70000000000003, 20.000000000000014, -32.4999999999999, 17.899999999999988, 11.599999999999964, 17.899999999999988, -3.099999999999958, 15.799999999999963, -7.299999999999965, 20.90000000000003, 13.699999999999966, 13.699999999999964, 20.000000000000014, -0.9999999999999846, -9.399999999999887, 15.799999999999963, 11.599999999999964, 7.399999999999965, 85.69999999999999, 1.0999999999999865, 3.1999999999999615, 13.699999999999964, 5.299999999999965, 9.499999999999964, 20.000000000000014, 21.80000000000004, 9.499999999999964, -297.7000000000001, 9.499999999999964, 15.799999999999963, 5.299999999999965, 13.699999999999964, 33.800000000000054, 14.899999999999956, 20.000000000000014, -34.59999999999975, 45.200000000000195, -16.899999999999743, 38.60000000000004, 14.299999999999965, -0.9999999999999846, -18.999999999999744, -0.9999999999999846, -7.299999999999891, 20.000000000000014, 7.399999999999965, 61.400000000000084, -265.5999999999997, -244.60000000000002], "policy_predator_policy_reward": [6.0, 5.0, 1.0, 4.0, 4.0, 3.0, 19.0, 0.0, 76.0, 7.0, 8.0, 11.0, 9.0, 10.0, 4.0, 9.0, 5.0, 7.0, 7.0, 2.0, 26.0, 26.0, 17.0, 19.0, 4.0, 6.0, 6.0, 7.0, 64.0, 11.0, 11.0, 9.0, 15.0, 12.0, 5.0, 2.0, 9.0, 13.0, 5.0, 8.0, 21.0, 7.0, 26.0, 28.0, 12.0, 19.0, 10.0, 12.0, 9.0, 187.0, 0.0, 4.0, 2.0, 8.0, 12.0, 11.0, 3.0, 6.0, 5.0, 37.0, 11.0, 0.0, 12.0, 12.0, 3.0, 65.0, 2.0, 3.0, 16.0, 1.0, 8.0, 6.0, 180.0, 4.0, 18.0, 14.0, 0.0, 20.0, 15.0, 23.0, 0.0, 20.0, 7.0, 6.0, 6.0, 4.0, 2.0, 3.0, 15.0, 15.0, 9.0, 11.0, 11.0, 16.0, 6.0, 2.0, 7.0, 6.0, 6.0, 4.0, 7.0, 3.0, 6.0, 18.0, 141.0, 7.0, 85.0, 10.0, 20.0, 19.0, 15.0, 220.0, 15.0, 4.0, 4.0, 7.0, 12.0, 14.0, 0.0, 1.0, 12.0, 1.0, 4.0, 4.0, 132.0, 12.0, 10.0, 9.0, 40.0, 181.0, 6.0, 7.0, 8.0, 4.0, 12.0, 6.0, 15.0, 24.0, 7.0, 8.0, 17.0, 15.0, 4.0, 22.0, 11.0, 10.0, 3.0, 2.0, 9.0, 12.0, 17.0, 21.0, 25.0, 0.0, 4.0, 1.0, 11.0, 2.0, 13.0, 2.0, 1.0, 2.0, 0.0, 3.0, 14.0, 10.0, 3.0, 4.0, 7.0, 8.0, 9.0, 8.0, 0.0, 7.0, 5.0, 5.0, 5.0, 1.0, 120.0, 66.0, 7.0, 2.0, 2.0, 3.0, 0.0, 5.0, 24.0, 5.0, 1.0, 18.0, 8.0, 10.0, 21.0, 21.0, 13.0, 0.0, 5.0, 6.0, 138.0, 50.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5856770183650947, "mean_inference_ms": 1.81303108298925, "mean_action_processing_ms": 0.2521108911888402, "mean_env_wait_ms": 0.19609277855179727, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004682779312133789, "StateBufferConnector_ms": 0.0032186508178710938, "ViewRequirementAgentConnector_ms": 0.09616720676422119}, "num_episodes": 22, "episode_return_max": 136.59999999999982, "episode_return_min": -322.19999999999914, "episode_return_mean": 20.70000000000008, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2640000, "num_agent_steps_trained": 2640000, "num_env_steps_sampled": 660000, "num_env_steps_trained": 660000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 364.00417576430345, "num_env_steps_trained_throughput_per_sec": 364.00417576430345, "timesteps_total": 660000, "num_env_steps_sampled_lifetime": 660000, "num_agent_steps_sampled_lifetime": 2640000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2640000, "timers": {"training_iteration_time_ms": 11192.388, "restore_workers_time_ms": 0.023, "training_step_time_ms": 11192.324, "sample_time_ms": 1311.94, "learn_time_ms": 9863.081, "learn_throughput": 405.553, "synch_weights_time_ms": 14.952}, "counters": {"num_env_steps_sampled": 660000, "num_env_steps_trained": 660000, "num_agent_steps_sampled": 2640000, "num_agent_steps_trained": 2640000}, "done": false, "training_iteration": 165, "trial_id": "3dae5_00000", "date": "2024-08-14_09-37-15", "timestamp": 1723642635, "time_this_iter_s": 10.993983030319214, "time_total_s": 3452.8139770030975, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b38b6430>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3452.8139770030975, "iterations_since_restore": 165, "perf": {"cpu_util_percent": 28.9, "ram_util_percent": 83.2625}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3809306411437257, "cur_kl_coeff": 0.00011731982231140134, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.8991107029574258, "policy_loss": -0.002202898688939592, "vf_loss": 0.9013103167886141, "vf_explained_var": 0.13024218337876456, "kl": 0.02801190739870491, "entropy": 0.9450308800059021, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 312795.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.515055583961426, "cur_kl_coeff": 0.02669677734374999, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.0740033758695793, "policy_loss": -0.005218204394199703, "vf_loss": 2.078912939911797, "vf_explained_var": 0.04642173382971022, "kl": 0.011561024438818868, "entropy": 1.0526658802120774, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 312795.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 664000, "num_env_steps_trained": 664000, "num_agent_steps_sampled": 2656000, "num_agent_steps_trained": 2656000}, "env_runners": {"episode_reward_max": 136.59999999999982, "episode_reward_min": -322.19999999999914, "episode_reward_mean": 19.873000000000054, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -409.29999999999995, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 92.90000000000018, "predator_policy": 220.0}, "policy_reward_mean": {"prey_policy": -6.903499999999973, "predator_policy": 16.84}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.799999999999997, 64.40000000000026, 16.399999999999956, 42.400000000000354, 25.400000000000066, 22.10000000000001, -117.10000000000042, 35.600000000000236, 33.2000000000002, 56.100000000000314, 30.100000000000144, 5.200000000000134, 69.29999999999997, 24.10000000000004, -14.99999999999965, 38.70000000000028, 28.800000000000132, 82.1999999999995, -162.4000000000008, 60.900000000000325, 17.999999999999975, 47.40000000000004, 45.60000000000032, 82.09999999999991, 37.40000000000026, 38.70000000000028, 38.50000000000028, 30.60000000000017, 21.4, 72.60000000000034, 38.300000000000274, 38.300000000000274, 29.000000000000124, 65.80000000000027, -159.10000000000088, -56.400000000000716, 43.900000000000276, -185.80000000000075, 14.900000000000007, 38.10000000000027, 36.60000000000025, 38.90000000000028, 25.700000000000067, 48.60000000000044, -95.9000000000006, 38.300000000000274, -290.89999999999907, 38.300000000000274, 41.200000000000315, 93.09999999999947, 101.19999999999945, 27.700000000000102, 32.10000000000018, 74.40000000000028, 19.000000000000004, 105.2999999999991, 136.59999999999982, 60.60000000000019, 12.49999999999995, 34.50000000000022, 27.800000000000107, 23.50000000000003, 37.600000000000264, 36.70000000000025, 13.599999999999962, 34.40000000000022, 108.09999999999978, 21.300000000000008, 26.00000000000007, 39.50000000000029, 37.30000000000026, -102.20000000000071, 30.100000000000144, 52.50000000000028, 39.90000000000027, 39.60000000000026, 40.70000000000003, 31.300000000000168, 22.000000000000025, 25.70000000000007, 79.79999999999976, -322.19999999999914, 133.99999999999972, 25.40000000000009, 37.30000000000022, 35.40000000000023, -313.4000000000003, 25.70000000000007, 88.1999999999991, 33.3000000000002, 43.90000000000031, 30.600000000000154, 24.60000000000005, 24.600000000000048, 29.900000000000144, 18.000000000000004, 28.80000000000012, 26.80000000000009, 112.29999999999978, 5.600000000000183], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-9.399999999999858, 3.1999999999999615, 48.2000000000001, 3.1999999999999615, -12.699999999999815, 1.0999999999999865, -31.599999999999767, 20.000000000000014, -17.199999999999747, 11.599999999999964, -5.1999999999999265, 5.299999999999965, 59.60000000000015, -372.6999999999997, 20.000000000000014, 11.599999999999964, 20.000000000000014, 3.1999999999999615, -5.1999999999999265, 38.3000000000001, 13.699999999999964, 7.399999999999965, -57.70000000000048, 20.90000000000003, 61.40000000000021, -3.099999999999958, -7.299999999999891, 7.399999999999965, 20.90000000000003, -103.9000000000006, 20.000000000000014, 13.699999999999964, -1.8999999999999853, 13.699999999999964, 3.1999999999999615, 64.99999999999999, -357.99999999999955, 11.599999999999964, 50.900000000000155, -21.999999999999744, 20.000000000000014, -21.999999999999744, -4.2999999999998, 13.699999999999964, -21.999999999999744, 47.600000000000115, 49.10000000000006, 20.000000000000014, 20.000000000000014, 7.399999999999965, 20.000000000000014, 13.699999999999964, 20.000000000000014, -11.499999999999819, 3.1999999999999615, 7.39999999999997, -4.599999999999943, -0.9999999999999846, 7.399999999999965, 57.20000000000018, 5.299999999999965, 20.000000000000014, 7.399999999999965, 20.90000000000003, 5.299999999999965, 13.699999999999964, 11.599999999999964, 30.200000000000152, -64.00000000000058, -243.10000000000028, 7.099999999999971, -158.50000000000065, 24.800000000000132, -19.899999999999743, -11.499999999999822, -409.29999999999995, 5.299999999999965, -9.399999999999862, 5.299999999999965, 21.80000000000004, -9.399999999999855, 20.000000000000014, 17.899999999999988, 20.000000000000014, -5.1999999999999265, 17.899999999999988, 11.599999999999964, 29.000000000000163, -247.3000000000001, 7.399999999999965, 11.599999999999964, 7.699999999999967, -225.30000000000038, -286.5999999999992, 20.000000000000014, 5.299999999999965, 25.100000000000104, 4.099999999999966, 80.30000000000001, -5.199999999999934, 69.2000000000001, -7.000000000000027, -0.9999999999999917, 13.699999999999964, 15.799999999999963, -15.699999999999747, 36.800000000000026, 11.599999999999964, -3.099999999999958, 1.0999999999999865, 31.700000000000212, 68.6000000000001, 82.10000000000007, 33.500000000000085, -24.099999999999746, 46.70000000000003, 20.000000000000014, -32.4999999999999, 17.899999999999988, 11.599999999999964, 17.899999999999988, -3.099999999999958, 15.799999999999963, -7.299999999999965, 20.90000000000003, 13.699999999999966, 13.699999999999964, 20.000000000000014, -0.9999999999999846, -9.399999999999887, 15.799999999999963, 11.599999999999964, 7.399999999999965, 85.69999999999999, 1.0999999999999865, 3.1999999999999615, 13.699999999999964, 5.299999999999965, 9.499999999999964, 20.000000000000014, 21.80000000000004, 9.499999999999964, -297.7000000000001, 9.499999999999964, 15.799999999999963, 5.299999999999965, 13.699999999999964, 33.800000000000054, 14.899999999999956, 20.000000000000014, -34.59999999999975, 45.200000000000195, -16.899999999999743, 38.60000000000004, 14.299999999999965, -0.9999999999999846, -18.999999999999744, -0.9999999999999846, -7.299999999999891, 20.000000000000014, 7.399999999999965, 61.400000000000084, -265.5999999999997, -244.60000000000002, 77.60000000000002, 49.40000000000008, 20.000000000000014, -34.599999999999795, 11.599999999999964, 16.69999999999996, 15.799999999999963, 11.599999999999964, -400.0, -114.40000000000003, 17.899999999999988, -5.1999999999999265, 35.60000000000025, 50.600000000000115, 13.699999999999964, 11.599999999999975, 27.200000000000074, 13.699999999999964, -5.1999999999999265, 21.800000000000047, -7.300000000000038, 17.899999999999988, 13.699999999999964, -3.099999999999965, -3.099999999999958, 20.000000000000014, 1.0999999999999865, -3.099999999999958, 7.399999999999965, 10.399999999999965, 20.000000000000014, -5.1999999999999265, 92.90000000000018, 7.399999999999965, -5.1999999999999265, -5.1999999999999265], "policy_predator_policy_reward": [9.0, 13.0, 5.0, 8.0, 21.0, 7.0, 26.0, 28.0, 12.0, 19.0, 10.0, 12.0, 9.0, 187.0, 0.0, 4.0, 2.0, 8.0, 12.0, 11.0, 3.0, 6.0, 5.0, 37.0, 11.0, 0.0, 12.0, 12.0, 3.0, 65.0, 2.0, 3.0, 16.0, 1.0, 8.0, 6.0, 180.0, 4.0, 18.0, 14.0, 0.0, 20.0, 15.0, 23.0, 0.0, 20.0, 7.0, 6.0, 6.0, 4.0, 2.0, 3.0, 15.0, 15.0, 9.0, 11.0, 11.0, 16.0, 6.0, 2.0, 7.0, 6.0, 6.0, 4.0, 7.0, 3.0, 6.0, 18.0, 141.0, 7.0, 85.0, 10.0, 20.0, 19.0, 15.0, 220.0, 15.0, 4.0, 4.0, 7.0, 12.0, 14.0, 0.0, 1.0, 12.0, 1.0, 4.0, 4.0, 132.0, 12.0, 10.0, 9.0, 40.0, 181.0, 6.0, 7.0, 8.0, 4.0, 12.0, 6.0, 15.0, 24.0, 7.0, 8.0, 17.0, 15.0, 4.0, 22.0, 11.0, 10.0, 3.0, 2.0, 9.0, 12.0, 17.0, 21.0, 25.0, 0.0, 4.0, 1.0, 11.0, 2.0, 13.0, 2.0, 1.0, 2.0, 0.0, 3.0, 14.0, 10.0, 3.0, 4.0, 7.0, 8.0, 9.0, 8.0, 0.0, 7.0, 5.0, 5.0, 5.0, 1.0, 120.0, 66.0, 7.0, 2.0, 2.0, 3.0, 0.0, 5.0, 24.0, 5.0, 1.0, 18.0, 8.0, 10.0, 21.0, 21.0, 13.0, 0.0, 5.0, 6.0, 138.0, 50.0, 0.0, 7.0, 25.0, 15.0, 4.0, 5.0, 4.0, 4.0, 200.0, 1.0, 12.0, 1.0, 2.0, 0.0, 5.0, 3.0, 3.0, 0.0, 12.0, 2.0, 13.0, 1.0, 11.0, 3.0, 11.0, 2.0, 11.0, 9.0, 5.0, 6.0, 12.0, 0.0, 6.0, 6.0, 4.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5856486663273927, "mean_inference_ms": 1.8127690462188217, "mean_action_processing_ms": 0.25204290335673074, "mean_env_wait_ms": 0.19606947557950305, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004312276840209961, "StateBufferConnector_ms": 0.003071904182434082, "ViewRequirementAgentConnector_ms": 0.09624028205871582}, "num_episodes": 18, "episode_return_max": 136.59999999999982, "episode_return_min": -322.19999999999914, "episode_return_mean": 19.873000000000054, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2656000, "num_agent_steps_trained": 2656000, "num_env_steps_sampled": 664000, "num_env_steps_trained": 664000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 359.20471041337044, "num_env_steps_trained_throughput_per_sec": 359.20471041337044, "timesteps_total": 664000, "num_env_steps_sampled_lifetime": 664000, "num_agent_steps_sampled_lifetime": 2656000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2656000, "timers": {"training_iteration_time_ms": 11168.323, "restore_workers_time_ms": 0.023, "training_step_time_ms": 11168.259, "sample_time_ms": 1313.591, "learn_time_ms": 9836.05, "learn_throughput": 406.667, "synch_weights_time_ms": 16.341}, "counters": {"num_env_steps_sampled": 664000, "num_env_steps_trained": 664000, "num_agent_steps_sampled": 2656000, "num_agent_steps_trained": 2656000}, "done": false, "training_iteration": 166, "trial_id": "3dae5_00000", "date": "2024-08-14_09-37-27", "timestamp": 1723642647, "time_this_iter_s": 11.164454936981201, "time_total_s": 3463.9784319400787, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3870310>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3463.9784319400787, "iterations_since_restore": 166, "perf": {"cpu_util_percent": 28.6875, "ram_util_percent": 83.75}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4795440964282505, "cur_kl_coeff": 0.00017597973346710204, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.5097197464534216, "policy_loss": -0.002871673860434423, "vf_loss": 1.5125864293997882, "vf_explained_var": 0.18776055296892843, "kl": 0.028354937491880824, "entropy": 0.8199378995352952, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 314685.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.3113846234543614, "cur_kl_coeff": 0.02669677734374999, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.6989359245098457, "policy_loss": -0.011816509302321171, "vf_loss": 1.710283640137425, "vf_explained_var": -0.033173168210125475, "kl": 0.017559748158463402, "entropy": 1.0657196866772163, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 314685.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 668000, "num_env_steps_trained": 668000, "num_agent_steps_sampled": 2672000, "num_agent_steps_trained": 2672000}, "env_runners": {"episode_reward_max": 136.59999999999982, "episode_reward_min": -322.19999999999914, "episode_reward_mean": 15.29900000000004, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -409.29999999999995, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 92.90000000000018, "predator_policy": 220.0}, "policy_reward_mean": {"prey_policy": -10.935499999999967, "predator_policy": 18.585}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-162.4000000000008, 60.900000000000325, 17.999999999999975, 47.40000000000004, 45.60000000000032, 82.09999999999991, 37.40000000000026, 38.70000000000028, 38.50000000000028, 30.60000000000017, 21.4, 72.60000000000034, 38.300000000000274, 38.300000000000274, 29.000000000000124, 65.80000000000027, -159.10000000000088, -56.400000000000716, 43.900000000000276, -185.80000000000075, 14.900000000000007, 38.10000000000027, 36.60000000000025, 38.90000000000028, 25.700000000000067, 48.60000000000044, -95.9000000000006, 38.300000000000274, -290.89999999999907, 38.300000000000274, 41.200000000000315, 93.09999999999947, 101.19999999999945, 27.700000000000102, 32.10000000000018, 74.40000000000028, 19.000000000000004, 105.2999999999991, 136.59999999999982, 60.60000000000019, 12.49999999999995, 34.50000000000022, 27.800000000000107, 23.50000000000003, 37.600000000000264, 36.70000000000025, 13.599999999999962, 34.40000000000022, 108.09999999999978, 21.300000000000008, 26.00000000000007, 39.50000000000029, 37.30000000000026, -102.20000000000071, 30.100000000000144, 52.50000000000028, 39.90000000000027, 39.60000000000026, 40.70000000000003, 31.300000000000168, 22.000000000000025, 25.70000000000007, 79.79999999999976, -322.19999999999914, 133.99999999999972, 25.40000000000009, 37.30000000000022, 35.40000000000023, -313.4000000000003, 25.70000000000007, 88.1999999999991, 33.3000000000002, 43.90000000000031, 30.600000000000154, 24.60000000000005, 24.600000000000048, 29.900000000000144, 18.000000000000004, 28.80000000000012, 26.80000000000009, 112.29999999999978, 5.600000000000183, 24.700000000000053, -12.70000000000006, 24.90000000000006, 34.50000000000022, 23.200000000000024, 38.00000000000027, 37.700000000000266, 26.800000000000086, 26.800000000000086, 71.39999999999972, 39.700000000000294, 17.699999999999964, -134.5000000000008, -43.59999999999991, -3.4999999999997167, 65.70000000000023, -153.70000000000053, -82.80000000000024], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-357.99999999999955, 11.599999999999964, 50.900000000000155, -21.999999999999744, 20.000000000000014, -21.999999999999744, -4.2999999999998, 13.699999999999964, -21.999999999999744, 47.600000000000115, 49.10000000000006, 20.000000000000014, 20.000000000000014, 7.399999999999965, 20.000000000000014, 13.699999999999964, 20.000000000000014, -11.499999999999819, 3.1999999999999615, 7.39999999999997, -4.599999999999943, -0.9999999999999846, 7.399999999999965, 57.20000000000018, 5.299999999999965, 20.000000000000014, 7.399999999999965, 20.90000000000003, 5.299999999999965, 13.699999999999964, 11.599999999999964, 30.200000000000152, -64.00000000000058, -243.10000000000028, 7.099999999999971, -158.50000000000065, 24.800000000000132, -19.899999999999743, -11.499999999999822, -409.29999999999995, 5.299999999999965, -9.399999999999862, 5.299999999999965, 21.80000000000004, -9.399999999999855, 20.000000000000014, 17.899999999999988, 20.000000000000014, -5.1999999999999265, 17.899999999999988, 11.599999999999964, 29.000000000000163, -247.3000000000001, 7.399999999999965, 11.599999999999964, 7.699999999999967, -225.30000000000038, -286.5999999999992, 20.000000000000014, 5.299999999999965, 25.100000000000104, 4.099999999999966, 80.30000000000001, -5.199999999999934, 69.2000000000001, -7.000000000000027, -0.9999999999999917, 13.699999999999964, 15.799999999999963, -15.699999999999747, 36.800000000000026, 11.599999999999964, -3.099999999999958, 1.0999999999999865, 31.700000000000212, 68.6000000000001, 82.10000000000007, 33.500000000000085, -24.099999999999746, 46.70000000000003, 20.000000000000014, -32.4999999999999, 17.899999999999988, 11.599999999999964, 17.899999999999988, -3.099999999999958, 15.799999999999963, -7.299999999999965, 20.90000000000003, 13.699999999999966, 13.699999999999964, 20.000000000000014, -0.9999999999999846, -9.399999999999887, 15.799999999999963, 11.599999999999964, 7.399999999999965, 85.69999999999999, 1.0999999999999865, 3.1999999999999615, 13.699999999999964, 5.299999999999965, 9.499999999999964, 20.000000000000014, 21.80000000000004, 9.499999999999964, -297.7000000000001, 9.499999999999964, 15.799999999999963, 5.299999999999965, 13.699999999999964, 33.800000000000054, 14.899999999999956, 20.000000000000014, -34.59999999999975, 45.200000000000195, -16.899999999999743, 38.60000000000004, 14.299999999999965, -0.9999999999999846, -18.999999999999744, -0.9999999999999846, -7.299999999999891, 20.000000000000014, 7.399999999999965, 61.400000000000084, -265.5999999999997, -244.60000000000002, 77.60000000000002, 49.40000000000008, 20.000000000000014, -34.599999999999795, 11.599999999999964, 16.69999999999996, 15.799999999999963, 11.599999999999964, -400.0, -114.40000000000003, 17.899999999999988, -5.1999999999999265, 35.60000000000025, 50.600000000000115, 13.699999999999964, 11.599999999999975, 27.200000000000074, 13.699999999999964, -5.1999999999999265, 21.800000000000047, -7.300000000000038, 17.899999999999988, 13.699999999999964, -3.099999999999965, -3.099999999999958, 20.000000000000014, 1.0999999999999865, -3.099999999999958, 7.399999999999965, 10.399999999999965, 20.000000000000014, -5.1999999999999265, 92.90000000000018, 7.399999999999965, -5.1999999999999265, -5.1999999999999265, -11.499999999999819, 6.1999999999999655, -40.59999999999996, -24.099999999999767, 15.799999999999963, -7.8999999999998884, 11.599999999999964, 17.899999999999988, 11.599999999999964, -9.399999999999855, -0.9999999999999846, 20.000000000000014, 20.000000000000014, 13.699999999999964, 11.599999999999964, 3.1999999999999615, 1.0999999999999865, 13.699999999999964, 46.40000000000007, 20.000000000000014, 20.000000000000014, 13.699999999999964, 13.699999999999964, -39.99999999999976, 28.100000000000147, -328.5999999999992, 20.000000000000014, -139.6000000000007, -49.299999999999905, 3.7999999999999656, 15.799999999999963, 47.90000000000016, 20.000000000000014, -351.70000000000005, 20.000000000000014, -353.7999999999996], "policy_predator_policy_reward": [180.0, 4.0, 18.0, 14.0, 0.0, 20.0, 15.0, 23.0, 0.0, 20.0, 7.0, 6.0, 6.0, 4.0, 2.0, 3.0, 15.0, 15.0, 9.0, 11.0, 11.0, 16.0, 6.0, 2.0, 7.0, 6.0, 6.0, 4.0, 7.0, 3.0, 6.0, 18.0, 141.0, 7.0, 85.0, 10.0, 20.0, 19.0, 15.0, 220.0, 15.0, 4.0, 4.0, 7.0, 12.0, 14.0, 0.0, 1.0, 12.0, 1.0, 4.0, 4.0, 132.0, 12.0, 10.0, 9.0, 40.0, 181.0, 6.0, 7.0, 8.0, 4.0, 12.0, 6.0, 15.0, 24.0, 7.0, 8.0, 17.0, 15.0, 4.0, 22.0, 11.0, 10.0, 3.0, 2.0, 9.0, 12.0, 17.0, 21.0, 25.0, 0.0, 4.0, 1.0, 11.0, 2.0, 13.0, 2.0, 1.0, 2.0, 0.0, 3.0, 14.0, 10.0, 3.0, 4.0, 7.0, 8.0, 9.0, 8.0, 0.0, 7.0, 5.0, 5.0, 5.0, 1.0, 120.0, 66.0, 7.0, 2.0, 2.0, 3.0, 0.0, 5.0, 24.0, 5.0, 1.0, 18.0, 8.0, 10.0, 21.0, 21.0, 13.0, 0.0, 5.0, 6.0, 138.0, 50.0, 0.0, 7.0, 25.0, 15.0, 4.0, 5.0, 4.0, 4.0, 200.0, 1.0, 12.0, 1.0, 2.0, 0.0, 5.0, 3.0, 3.0, 0.0, 12.0, 2.0, 13.0, 1.0, 11.0, 3.0, 11.0, 2.0, 11.0, 9.0, 5.0, 6.0, 12.0, 0.0, 6.0, 6.0, 4.0, 12.0, 15.0, 15.0, 15.0, 37.0, 15.0, 2.0, 1.0, 4.0, 10.0, 11.0, 10.0, 9.0, 1.0, 3.0, 8.0, 4.0, 9.0, 3.0, 5.0, 0.0, 3.0, 3.0, 29.0, 15.0, 166.0, 0.0, 76.0, 0.0, 33.0, 9.0, 0.0, 2.0, 1.0, 177.0, 139.0, 112.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5856356910856835, "mean_inference_ms": 1.812561341438331, "mean_action_processing_ms": 0.25198878345472536, "mean_env_wait_ms": 0.1960431102683418, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003665328025817871, "StateBufferConnector_ms": 0.0032047033309936523, "ViewRequirementAgentConnector_ms": 0.09546327590942383}, "num_episodes": 18, "episode_return_max": 136.59999999999982, "episode_return_min": -322.19999999999914, "episode_return_mean": 15.29900000000004, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2672000, "num_agent_steps_trained": 2672000, "num_env_steps_sampled": 668000, "num_env_steps_trained": 668000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 364.50354331033697, "num_env_steps_trained_throughput_per_sec": 364.50354331033697, "timesteps_total": 668000, "num_env_steps_sampled_lifetime": 668000, "num_agent_steps_sampled_lifetime": 2672000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2672000, "timers": {"training_iteration_time_ms": 11124.643, "restore_workers_time_ms": 0.025, "training_step_time_ms": 11124.579, "sample_time_ms": 1312.225, "learn_time_ms": 9794.061, "learn_throughput": 408.411, "synch_weights_time_ms": 16.226}, "counters": {"num_env_steps_sampled": 668000, "num_env_steps_trained": 668000, "num_agent_steps_sampled": 2672000, "num_agent_steps_trained": 2672000}, "done": false, "training_iteration": 167, "trial_id": "3dae5_00000", "date": "2024-08-14_09-37-38", "timestamp": 1723642658, "time_this_iter_s": 11.01091194152832, "time_total_s": 3474.989343881607, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3948dc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3474.989343881607, "iterations_since_restore": 167, "perf": {"cpu_util_percent": 32.25333333333334, "ram_util_percent": 83.54666666666665}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9276700490366214, "cur_kl_coeff": 0.00026396960020065314, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.5745864022976508, "policy_loss": -0.0019832300002533922, "vf_loss": 1.5765654967890845, "vf_explained_var": 0.04209150268287255, "kl": 0.01565009175579658, "entropy": 0.6424933010623568, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 316575.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.340318132140649, "cur_kl_coeff": 0.02669677734374999, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.9318005009933754, "policy_loss": -0.008791847719451186, "vf_loss": 1.9402327408550908, "vf_explained_var": 0.037536004264518696, "kl": 0.013470175897397327, "entropy": 1.0643756622990603, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 316575.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 672000, "num_env_steps_trained": 672000, "num_agent_steps_sampled": 2688000, "num_agent_steps_trained": 2688000}, "env_runners": {"episode_reward_max": 136.59999999999982, "episode_reward_min": -322.19999999999914, "episode_reward_mean": 13.49600000000004, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -409.29999999999995, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 106.69999999999975, "predator_policy": 220.0}, "policy_reward_mean": {"prey_policy": -12.121999999999975, "predator_policy": 18.87}, "custom_metrics": {}, "hist_stats": {"episode_reward": [43.900000000000276, -185.80000000000075, 14.900000000000007, 38.10000000000027, 36.60000000000025, 38.90000000000028, 25.700000000000067, 48.60000000000044, -95.9000000000006, 38.300000000000274, -290.89999999999907, 38.300000000000274, 41.200000000000315, 93.09999999999947, 101.19999999999945, 27.700000000000102, 32.10000000000018, 74.40000000000028, 19.000000000000004, 105.2999999999991, 136.59999999999982, 60.60000000000019, 12.49999999999995, 34.50000000000022, 27.800000000000107, 23.50000000000003, 37.600000000000264, 36.70000000000025, 13.599999999999962, 34.40000000000022, 108.09999999999978, 21.300000000000008, 26.00000000000007, 39.50000000000029, 37.30000000000026, -102.20000000000071, 30.100000000000144, 52.50000000000028, 39.90000000000027, 39.60000000000026, 40.70000000000003, 31.300000000000168, 22.000000000000025, 25.70000000000007, 79.79999999999976, -322.19999999999914, 133.99999999999972, 25.40000000000009, 37.30000000000022, 35.40000000000023, -313.4000000000003, 25.70000000000007, 88.1999999999991, 33.3000000000002, 43.90000000000031, 30.600000000000154, 24.60000000000005, 24.600000000000048, 29.900000000000144, 18.000000000000004, 28.80000000000012, 26.80000000000009, 112.29999999999978, 5.600000000000183, 24.700000000000053, -12.70000000000006, 24.90000000000006, 34.50000000000022, 23.200000000000024, 38.00000000000027, 37.700000000000266, 26.800000000000086, 26.800000000000086, 71.39999999999972, 39.700000000000294, 17.699999999999964, -134.5000000000008, -43.59999999999991, -3.4999999999997167, 65.70000000000023, -153.70000000000053, -82.80000000000024, 19.09999999999999, 27.6000000000001, 28.80000000000012, 122.09999999999928, -37.39999999999958, 27.900000000000105, -35.899999999999714, 52.00000000000025, 24.600000000000048, 35.30000000000023, 38.60000000000028, -173.4000000000007, 35.600000000000236, -166.80000000000075, 32.000000000000185, 35.20000000000023, 28.900000000000123, 12.20000000000006], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [24.800000000000132, -19.899999999999743, -11.499999999999822, -409.29999999999995, 5.299999999999965, -9.399999999999862, 5.299999999999965, 21.80000000000004, -9.399999999999855, 20.000000000000014, 17.899999999999988, 20.000000000000014, -5.1999999999999265, 17.899999999999988, 11.599999999999964, 29.000000000000163, -247.3000000000001, 7.399999999999965, 11.599999999999964, 7.699999999999967, -225.30000000000038, -286.5999999999992, 20.000000000000014, 5.299999999999965, 25.100000000000104, 4.099999999999966, 80.30000000000001, -5.199999999999934, 69.2000000000001, -7.000000000000027, -0.9999999999999917, 13.699999999999964, 15.799999999999963, -15.699999999999747, 36.800000000000026, 11.599999999999964, -3.099999999999958, 1.0999999999999865, 31.700000000000212, 68.6000000000001, 82.10000000000007, 33.500000000000085, -24.099999999999746, 46.70000000000003, 20.000000000000014, -32.4999999999999, 17.899999999999988, 11.599999999999964, 17.899999999999988, -3.099999999999958, 15.799999999999963, -7.299999999999965, 20.90000000000003, 13.699999999999966, 13.699999999999964, 20.000000000000014, -0.9999999999999846, -9.399999999999887, 15.799999999999963, 11.599999999999964, 7.399999999999965, 85.69999999999999, 1.0999999999999865, 3.1999999999999615, 13.699999999999964, 5.299999999999965, 9.499999999999964, 20.000000000000014, 21.80000000000004, 9.499999999999964, -297.7000000000001, 9.499999999999964, 15.799999999999963, 5.299999999999965, 13.699999999999964, 33.800000000000054, 14.899999999999956, 20.000000000000014, -34.59999999999975, 45.200000000000195, -16.899999999999743, 38.60000000000004, 14.299999999999965, -0.9999999999999846, -18.999999999999744, -0.9999999999999846, -7.299999999999891, 20.000000000000014, 7.399999999999965, 61.400000000000084, -265.5999999999997, -244.60000000000002, 77.60000000000002, 49.40000000000008, 20.000000000000014, -34.599999999999795, 11.599999999999964, 16.69999999999996, 15.799999999999963, 11.599999999999964, -400.0, -114.40000000000003, 17.899999999999988, -5.1999999999999265, 35.60000000000025, 50.600000000000115, 13.699999999999964, 11.599999999999975, 27.200000000000074, 13.699999999999964, -5.1999999999999265, 21.800000000000047, -7.300000000000038, 17.899999999999988, 13.699999999999964, -3.099999999999965, -3.099999999999958, 20.000000000000014, 1.0999999999999865, -3.099999999999958, 7.399999999999965, 10.399999999999965, 20.000000000000014, -5.1999999999999265, 92.90000000000018, 7.399999999999965, -5.1999999999999265, -5.1999999999999265, -11.499999999999819, 6.1999999999999655, -40.59999999999996, -24.099999999999767, 15.799999999999963, -7.8999999999998884, 11.599999999999964, 17.899999999999988, 11.599999999999964, -9.399999999999855, -0.9999999999999846, 20.000000000000014, 20.000000000000014, 13.699999999999964, 11.599999999999964, 3.1999999999999615, 1.0999999999999865, 13.699999999999964, 46.40000000000007, 20.000000000000014, 20.000000000000014, 13.699999999999964, 13.699999999999964, -39.99999999999976, 28.100000000000147, -328.5999999999992, 20.000000000000014, -139.6000000000007, -49.299999999999905, 3.7999999999999656, 15.799999999999963, 47.90000000000016, 20.000000000000014, -351.70000000000005, 20.000000000000014, -353.7999999999996, 7.399999999999965, -7.299999999999891, 13.699999999999964, -3.099999999999958, 3.1999999999999615, 11.599999999999964, 7.399999999999965, 106.69999999999975, -47.199999999999854, -89.20000000000084, 15.799999999999963, 1.0999999999999865, 11.599999999999964, -116.50000000000038, 15.199999999999994, 15.799999999999963, 13.699999999999964, -3.099999999999958, 3.1999999999999615, 7.0999999999999694, 20.000000000000014, 11.599999999999964, 20.000000000000014, -387.39999999999986, 20.000000000000014, 11.599999999999964, -3.099999999999958, -351.6999999999997, 17.899999999999988, -4.899999999999942, 20.000000000000014, 3.1999999999999615, 5.299999999999965, 11.599999999999964, -3.099999999999958, -15.699999999999747], "policy_predator_policy_reward": [20.0, 19.0, 15.0, 220.0, 15.0, 4.0, 4.0, 7.0, 12.0, 14.0, 0.0, 1.0, 12.0, 1.0, 4.0, 4.0, 132.0, 12.0, 10.0, 9.0, 40.0, 181.0, 6.0, 7.0, 8.0, 4.0, 12.0, 6.0, 15.0, 24.0, 7.0, 8.0, 17.0, 15.0, 4.0, 22.0, 11.0, 10.0, 3.0, 2.0, 9.0, 12.0, 17.0, 21.0, 25.0, 0.0, 4.0, 1.0, 11.0, 2.0, 13.0, 2.0, 1.0, 2.0, 0.0, 3.0, 14.0, 10.0, 3.0, 4.0, 7.0, 8.0, 9.0, 8.0, 0.0, 7.0, 5.0, 5.0, 5.0, 1.0, 120.0, 66.0, 7.0, 2.0, 2.0, 3.0, 0.0, 5.0, 24.0, 5.0, 1.0, 18.0, 8.0, 10.0, 21.0, 21.0, 13.0, 0.0, 5.0, 6.0, 138.0, 50.0, 0.0, 7.0, 25.0, 15.0, 4.0, 5.0, 4.0, 4.0, 200.0, 1.0, 12.0, 1.0, 2.0, 0.0, 5.0, 3.0, 3.0, 0.0, 12.0, 2.0, 13.0, 1.0, 11.0, 3.0, 11.0, 2.0, 11.0, 9.0, 5.0, 6.0, 12.0, 0.0, 6.0, 6.0, 4.0, 12.0, 15.0, 15.0, 15.0, 37.0, 15.0, 2.0, 1.0, 4.0, 10.0, 11.0, 10.0, 9.0, 1.0, 3.0, 8.0, 4.0, 9.0, 3.0, 5.0, 0.0, 3.0, 3.0, 29.0, 15.0, 166.0, 0.0, 76.0, 0.0, 33.0, 9.0, 0.0, 2.0, 1.0, 177.0, 139.0, 112.0, 6.0, 13.0, 10.0, 7.0, 8.0, 6.0, 2.0, 6.0, 17.0, 82.0, 9.0, 2.0, 65.0, 4.0, 19.0, 2.0, 11.0, 3.0, 15.0, 10.0, 3.0, 4.0, 0.0, 194.0, 0.0, 4.0, 11.0, 177.0, 13.0, 6.0, 7.0, 5.0, 5.0, 7.0, 18.0, 13.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5854964123117172, "mean_inference_ms": 1.8121350915201089, "mean_action_processing_ms": 0.2519001125713975, "mean_env_wait_ms": 0.19598544490387768, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00351107120513916, "StateBufferConnector_ms": 0.003175497055053711, "ViewRequirementAgentConnector_ms": 0.09028923511505127}, "num_episodes": 18, "episode_return_max": 136.59999999999982, "episode_return_min": -322.19999999999914, "episode_return_mean": 13.49600000000004, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2688000, "num_agent_steps_trained": 2688000, "num_env_steps_sampled": 672000, "num_env_steps_trained": 672000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 363.91539727761733, "num_env_steps_trained_throughput_per_sec": 363.91539727761733, "timesteps_total": 672000, "num_env_steps_sampled_lifetime": 672000, "num_agent_steps_sampled_lifetime": 2688000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2688000, "timers": {"training_iteration_time_ms": 11082.073, "restore_workers_time_ms": 0.024, "training_step_time_ms": 11081.984, "sample_time_ms": 1305.572, "learn_time_ms": 9757.239, "learn_throughput": 409.952, "synch_weights_time_ms": 16.589}, "counters": {"num_env_steps_sampled": 672000, "num_env_steps_trained": 672000, "num_agent_steps_sampled": 2688000, "num_agent_steps_trained": 2688000}, "done": false, "training_iteration": 168, "trial_id": "3dae5_00000", "date": "2024-08-14_09-37-49", "timestamp": 1723642669, "time_this_iter_s": 11.028491973876953, "time_total_s": 3486.017835855484, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b38b6430>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3486.017835855484, "iterations_since_restore": 168, "perf": {"cpu_util_percent": 31.268749999999997, "ram_util_percent": 83.38125}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.03244455743719, "cur_kl_coeff": 0.00026396960020065314, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.3503366137623156, "policy_loss": -0.0016414949713550785, "vf_loss": 1.351973107346782, "vf_explained_var": 0.13333231046717003, "kl": 0.0189630804788544, "entropy": 0.5341533172225196, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 318465.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.73739337996831, "cur_kl_coeff": 0.02669677734374999, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.9276160974981924, "policy_loss": -0.008222965668472979, "vf_loss": 1.9355382432067205, "vf_explained_var": -0.0056274880492498, "kl": 0.011268125213955446, "entropy": 1.0336094805803249, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 318465.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 676000, "num_env_steps_trained": 676000, "num_agent_steps_sampled": 2704000, "num_agent_steps_trained": 2704000}, "env_runners": {"episode_reward_max": 133.99999999999972, "episode_reward_min": -322.19999999999914, "episode_reward_mean": 7.449000000000028, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -472.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 106.69999999999975, "predator_policy": 281.0}, "policy_reward_mean": {"prey_policy": -16.600499999999997, "predator_policy": 20.325}, "custom_metrics": {}, "hist_stats": {"episode_reward": [36.70000000000025, 13.599999999999962, 34.40000000000022, 108.09999999999978, 21.300000000000008, 26.00000000000007, 39.50000000000029, 37.30000000000026, -102.20000000000071, 30.100000000000144, 52.50000000000028, 39.90000000000027, 39.60000000000026, 40.70000000000003, 31.300000000000168, 22.000000000000025, 25.70000000000007, 79.79999999999976, -322.19999999999914, 133.99999999999972, 25.40000000000009, 37.30000000000022, 35.40000000000023, -313.4000000000003, 25.70000000000007, 88.1999999999991, 33.3000000000002, 43.90000000000031, 30.600000000000154, 24.60000000000005, 24.600000000000048, 29.900000000000144, 18.000000000000004, 28.80000000000012, 26.80000000000009, 112.29999999999978, 5.600000000000183, 24.700000000000053, -12.70000000000006, 24.90000000000006, 34.50000000000022, 23.200000000000024, 38.00000000000027, 37.700000000000266, 26.800000000000086, 26.800000000000086, 71.39999999999972, 39.700000000000294, 17.699999999999964, -134.5000000000008, -43.59999999999991, -3.4999999999997167, 65.70000000000023, -153.70000000000053, -82.80000000000024, 19.09999999999999, 27.6000000000001, 28.80000000000012, 122.09999999999928, -37.39999999999958, 27.900000000000105, -35.899999999999714, 52.00000000000025, 24.600000000000048, 35.30000000000023, 38.60000000000028, -173.4000000000007, 35.600000000000236, -166.80000000000075, 32.000000000000185, 35.20000000000023, 28.900000000000123, 12.20000000000006, 31.900000000000176, 11.400000000000077, 63.30000000000034, 59.90000000000018, 37.80000000000027, 39.700000000000294, 25.700000000000067, 13.300000000000056, 33.200000000000195, 38.90000000000028, 89.5999999999994, -63.09999999999975, 28.800000000000125, 44.40000000000015, 27.900000000000105, -133.50000000000105, -168.00000000000063, 36.40000000000025, -14.999999999999522, 17.99999999999998, 0.5000000000000155, -184.4000000000008, -178.00000000000065, 31.000000000000163, 22.40000000000001, 35.30000000000023, 25.70000000000007], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [13.699999999999964, 20.000000000000014, -0.9999999999999846, -9.399999999999887, 15.799999999999963, 11.599999999999964, 7.399999999999965, 85.69999999999999, 1.0999999999999865, 3.1999999999999615, 13.699999999999964, 5.299999999999965, 9.499999999999964, 20.000000000000014, 21.80000000000004, 9.499999999999964, -297.7000000000001, 9.499999999999964, 15.799999999999963, 5.299999999999965, 13.699999999999964, 33.800000000000054, 14.899999999999956, 20.000000000000014, -34.59999999999975, 45.200000000000195, -16.899999999999743, 38.60000000000004, 14.299999999999965, -0.9999999999999846, -18.999999999999744, -0.9999999999999846, -7.299999999999891, 20.000000000000014, 7.399999999999965, 61.400000000000084, -265.5999999999997, -244.60000000000002, 77.60000000000002, 49.40000000000008, 20.000000000000014, -34.599999999999795, 11.599999999999964, 16.69999999999996, 15.799999999999963, 11.599999999999964, -400.0, -114.40000000000003, 17.899999999999988, -5.1999999999999265, 35.60000000000025, 50.600000000000115, 13.699999999999964, 11.599999999999975, 27.200000000000074, 13.699999999999964, -5.1999999999999265, 21.800000000000047, -7.300000000000038, 17.899999999999988, 13.699999999999964, -3.099999999999965, -3.099999999999958, 20.000000000000014, 1.0999999999999865, -3.099999999999958, 7.399999999999965, 10.399999999999965, 20.000000000000014, -5.1999999999999265, 92.90000000000018, 7.399999999999965, -5.1999999999999265, -5.1999999999999265, -11.499999999999819, 6.1999999999999655, -40.59999999999996, -24.099999999999767, 15.799999999999963, -7.8999999999998884, 11.599999999999964, 17.899999999999988, 11.599999999999964, -9.399999999999855, -0.9999999999999846, 20.000000000000014, 20.000000000000014, 13.699999999999964, 11.599999999999964, 3.1999999999999615, 1.0999999999999865, 13.699999999999964, 46.40000000000007, 20.000000000000014, 20.000000000000014, 13.699999999999964, 13.699999999999964, -39.99999999999976, 28.100000000000147, -328.5999999999992, 20.000000000000014, -139.6000000000007, -49.299999999999905, 3.7999999999999656, 15.799999999999963, 47.90000000000016, 20.000000000000014, -351.70000000000005, 20.000000000000014, -353.7999999999996, 7.399999999999965, -7.299999999999891, 13.699999999999964, -3.099999999999958, 3.1999999999999615, 11.599999999999964, 7.399999999999965, 106.69999999999975, -47.199999999999854, -89.20000000000084, 15.799999999999963, 1.0999999999999865, 11.599999999999964, -116.50000000000038, 15.199999999999994, 15.799999999999963, 13.699999999999964, -3.099999999999958, 3.1999999999999615, 7.0999999999999694, 20.000000000000014, 11.599999999999964, 20.000000000000014, -387.39999999999986, 20.000000000000014, 11.599999999999964, -3.099999999999958, -351.6999999999997, 17.899999999999988, -4.899999999999942, 20.000000000000014, 3.1999999999999615, 5.299999999999965, 11.599999999999964, -3.099999999999958, -15.699999999999747, 13.699999999999964, 3.1999999999999615, -11.499999999999819, -3.099999999999958, 17.899999999999988, 37.40000000000005, -0.9999999999999846, 29.900000000000045, 20.000000000000014, 15.799999999999963, 20.90000000000003, -5.1999999999999265, 9.499999999999964, 3.1999999999999615, 1.0999999999999865, 3.1999999999999615, 10.399999999999965, 15.799999999999963, 20.000000000000014, 17.899999999999988, 69.79999999999984, 15.799999999999963, -234.10000000000045, 20.000000000000014, 20.000000000000014, -5.1999999999999265, 5.299999999999965, 25.10000000000005, 9.499999999999964, 7.399999999999965, -172.40000000000052, -87.10000000000036, 20.000000000000014, -472.0, 5.299999999999965, 1.0999999999999723, -57.70000000000048, -7.299999999999891, -19.899999999999743, 17.899999999999988, 11.599999999999946, -45.100000000000016, -385.29999999999995, -3.099999999999958, -400.0, 20.000000000000014, 20.000000000000014, -0.9999999999999846, 11.599999999999964, -5.1999999999999265, 7.399999999999965, 20.900000000000027, -7.299999999999891, 20.000000000000014], "policy_predator_policy_reward": [0.0, 3.0, 14.0, 10.0, 3.0, 4.0, 7.0, 8.0, 9.0, 8.0, 0.0, 7.0, 5.0, 5.0, 5.0, 1.0, 120.0, 66.0, 7.0, 2.0, 2.0, 3.0, 0.0, 5.0, 24.0, 5.0, 1.0, 18.0, 8.0, 10.0, 21.0, 21.0, 13.0, 0.0, 5.0, 6.0, 138.0, 50.0, 0.0, 7.0, 25.0, 15.0, 4.0, 5.0, 4.0, 4.0, 200.0, 1.0, 12.0, 1.0, 2.0, 0.0, 5.0, 3.0, 3.0, 0.0, 12.0, 2.0, 13.0, 1.0, 11.0, 3.0, 11.0, 2.0, 11.0, 9.0, 5.0, 6.0, 12.0, 0.0, 6.0, 6.0, 4.0, 12.0, 15.0, 15.0, 15.0, 37.0, 15.0, 2.0, 1.0, 4.0, 10.0, 11.0, 10.0, 9.0, 1.0, 3.0, 8.0, 4.0, 9.0, 3.0, 5.0, 0.0, 3.0, 3.0, 29.0, 15.0, 166.0, 0.0, 76.0, 0.0, 33.0, 9.0, 0.0, 2.0, 1.0, 177.0, 139.0, 112.0, 6.0, 13.0, 10.0, 7.0, 8.0, 6.0, 2.0, 6.0, 17.0, 82.0, 9.0, 2.0, 65.0, 4.0, 19.0, 2.0, 11.0, 3.0, 15.0, 10.0, 3.0, 4.0, 0.0, 194.0, 0.0, 4.0, 11.0, 177.0, 13.0, 6.0, 7.0, 5.0, 5.0, 7.0, 18.0, 13.0, 7.0, 8.0, 15.0, 11.0, 8.0, 0.0, 21.0, 10.0, 0.0, 2.0, 12.0, 12.0, 8.0, 5.0, 0.0, 9.0, 2.0, 5.0, 0.0, 1.0, 0.0, 4.0, 121.0, 30.0, 12.0, 2.0, 7.0, 7.0, 6.0, 5.0, 5.0, 121.0, 281.0, 3.0, 15.0, 15.0, 13.0, 37.0, 19.0, 1.0, 34.0, 0.0, 193.0, 11.0, 200.0, 2.0, 2.0, 10.0, 12.0, 4.0, 1.0, 6.0, 0.0, 13.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5853225186845873, "mean_inference_ms": 1.811497536022141, "mean_action_processing_ms": 0.2514555042185741, "mean_env_wait_ms": 0.1960026866513791, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004021763801574707, "StateBufferConnector_ms": 0.0035189390182495117, "ViewRequirementAgentConnector_ms": 0.09483766555786133}, "num_episodes": 27, "episode_return_max": 133.99999999999972, "episode_return_min": -322.19999999999914, "episode_return_mean": 7.449000000000028, "episodes_this_iter": 27}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2704000, "num_agent_steps_trained": 2704000, "num_env_steps_sampled": 676000, "num_env_steps_trained": 676000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 351.9096162925699, "num_env_steps_trained_throughput_per_sec": 351.9096162925699, "timesteps_total": 676000, "num_env_steps_sampled_lifetime": 676000, "num_agent_steps_sampled_lifetime": 2704000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2704000, "timers": {"training_iteration_time_ms": 11120.5, "restore_workers_time_ms": 0.018, "training_step_time_ms": 11120.423, "sample_time_ms": 1300.485, "learn_time_ms": 9800.7, "learn_throughput": 408.134, "synch_weights_time_ms": 16.606}, "counters": {"num_env_steps_sampled": 676000, "num_env_steps_trained": 676000, "num_agent_steps_sampled": 2704000, "num_agent_steps_trained": 2704000}, "done": false, "training_iteration": 169, "trial_id": "3dae5_00000", "date": "2024-08-14_09-38-00", "timestamp": 1723642680, "time_this_iter_s": 11.409182071685791, "time_total_s": 3497.42701792717, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3948e50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3497.42701792717, "iterations_since_restore": 169, "perf": {"cpu_util_percent": 30.95, "ram_util_percent": 83.7}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.835237509706033, "cur_kl_coeff": 0.00026396960020065314, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.3254068521280138, "policy_loss": -0.0027460669790685334, "vf_loss": 1.3281498595520302, "vf_explained_var": 0.17457874092475448, "kl": 0.011611612726748783, "entropy": 0.7521108857853703, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 320355.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.3117483726884953, "cur_kl_coeff": 0.02669677734374999, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.0910292890652147, "policy_loss": -0.005399616843178159, "vf_loss": 2.096259526916282, "vf_explained_var": 0.09195911111655058, "kl": 0.006344481581338464, "entropy": 1.0329467962973964, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 320355.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 680000, "num_env_steps_trained": 680000, "num_agent_steps_sampled": 2720000, "num_agent_steps_trained": 2720000}, "env_runners": {"episode_reward_max": 133.99999999999972, "episode_reward_min": -322.19999999999914, "episode_reward_mean": 6.593000000000015, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -472.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 106.69999999999975, "predator_policy": 281.0}, "policy_reward_mean": {"prey_policy": -17.8935, "predator_policy": 21.19}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-322.19999999999914, 133.99999999999972, 25.40000000000009, 37.30000000000022, 35.40000000000023, -313.4000000000003, 25.70000000000007, 88.1999999999991, 33.3000000000002, 43.90000000000031, 30.600000000000154, 24.60000000000005, 24.600000000000048, 29.900000000000144, 18.000000000000004, 28.80000000000012, 26.80000000000009, 112.29999999999978, 5.600000000000183, 24.700000000000053, -12.70000000000006, 24.90000000000006, 34.50000000000022, 23.200000000000024, 38.00000000000027, 37.700000000000266, 26.800000000000086, 26.800000000000086, 71.39999999999972, 39.700000000000294, 17.699999999999964, -134.5000000000008, -43.59999999999991, -3.4999999999997167, 65.70000000000023, -153.70000000000053, -82.80000000000024, 19.09999999999999, 27.6000000000001, 28.80000000000012, 122.09999999999928, -37.39999999999958, 27.900000000000105, -35.899999999999714, 52.00000000000025, 24.600000000000048, 35.30000000000023, 38.60000000000028, -173.4000000000007, 35.600000000000236, -166.80000000000075, 32.000000000000185, 35.20000000000023, 28.900000000000123, 12.20000000000006, 31.900000000000176, 11.400000000000077, 63.30000000000034, 59.90000000000018, 37.80000000000027, 39.700000000000294, 25.700000000000067, 13.300000000000056, 33.200000000000195, 38.90000000000028, 89.5999999999994, -63.09999999999975, 28.800000000000125, 44.40000000000015, 27.900000000000105, -133.50000000000105, -168.00000000000063, 36.40000000000025, -14.999999999999522, 17.99999999999998, 0.5000000000000155, -184.4000000000008, -178.00000000000065, 31.000000000000163, 22.40000000000001, 35.30000000000023, 25.70000000000007, -93.80000000000081, 18.000000000000004, 37.00000000000021, 1.2999999999999936, 13.60000000000002, 24.40000000000005, 18.29999999999996, 73.99999999999972, 47.400000000000425, 21.600000000000033, 37.700000000000266, 102.99999999999942, 36.70000000000025, 13.700000000000033, 57.70000000000017, 34.50000000000022, 31.200000000000163, 14.399999999999919], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-265.5999999999997, -244.60000000000002, 77.60000000000002, 49.40000000000008, 20.000000000000014, -34.599999999999795, 11.599999999999964, 16.69999999999996, 15.799999999999963, 11.599999999999964, -400.0, -114.40000000000003, 17.899999999999988, -5.1999999999999265, 35.60000000000025, 50.600000000000115, 13.699999999999964, 11.599999999999975, 27.200000000000074, 13.699999999999964, -5.1999999999999265, 21.800000000000047, -7.300000000000038, 17.899999999999988, 13.699999999999964, -3.099999999999965, -3.099999999999958, 20.000000000000014, 1.0999999999999865, -3.099999999999958, 7.399999999999965, 10.399999999999965, 20.000000000000014, -5.1999999999999265, 92.90000000000018, 7.399999999999965, -5.1999999999999265, -5.1999999999999265, -11.499999999999819, 6.1999999999999655, -40.59999999999996, -24.099999999999767, 15.799999999999963, -7.8999999999998884, 11.599999999999964, 17.899999999999988, 11.599999999999964, -9.399999999999855, -0.9999999999999846, 20.000000000000014, 20.000000000000014, 13.699999999999964, 11.599999999999964, 3.1999999999999615, 1.0999999999999865, 13.699999999999964, 46.40000000000007, 20.000000000000014, 20.000000000000014, 13.699999999999964, 13.699999999999964, -39.99999999999976, 28.100000000000147, -328.5999999999992, 20.000000000000014, -139.6000000000007, -49.299999999999905, 3.7999999999999656, 15.799999999999963, 47.90000000000016, 20.000000000000014, -351.70000000000005, 20.000000000000014, -353.7999999999996, 7.399999999999965, -7.299999999999891, 13.699999999999964, -3.099999999999958, 3.1999999999999615, 11.599999999999964, 7.399999999999965, 106.69999999999975, -47.199999999999854, -89.20000000000084, 15.799999999999963, 1.0999999999999865, 11.599999999999964, -116.50000000000038, 15.199999999999994, 15.799999999999963, 13.699999999999964, -3.099999999999958, 3.1999999999999615, 7.0999999999999694, 20.000000000000014, 11.599999999999964, 20.000000000000014, -387.39999999999986, 20.000000000000014, 11.599999999999964, -3.099999999999958, -351.6999999999997, 17.899999999999988, -4.899999999999942, 20.000000000000014, 3.1999999999999615, 5.299999999999965, 11.599999999999964, -3.099999999999958, -15.699999999999747, 13.699999999999964, 3.1999999999999615, -11.499999999999819, -3.099999999999958, 17.899999999999988, 37.40000000000005, -0.9999999999999846, 29.900000000000045, 20.000000000000014, 15.799999999999963, 20.90000000000003, -5.1999999999999265, 9.499999999999964, 3.1999999999999615, 1.0999999999999865, 3.1999999999999615, 10.399999999999965, 15.799999999999963, 20.000000000000014, 17.899999999999988, 69.79999999999984, 15.799999999999963, -234.10000000000045, 20.000000000000014, 20.000000000000014, -5.1999999999999265, 5.299999999999965, 25.10000000000005, 9.499999999999964, 7.399999999999965, -172.40000000000052, -87.10000000000036, 20.000000000000014, -472.0, 5.299999999999965, 1.0999999999999723, -57.70000000000048, -7.299999999999891, -19.899999999999743, 17.899999999999988, 11.599999999999946, -45.100000000000016, -385.29999999999995, -3.099999999999958, -400.0, 20.000000000000014, 20.000000000000014, -0.9999999999999846, 11.599999999999964, -5.1999999999999265, 7.399999999999965, 20.900000000000027, -7.299999999999891, 20.000000000000014, -262.0000000000002, -20.79999999999977, -3.099999999999958, 1.0999999999999865, -110.20000000000078, 81.19999999999979, 74.00000000000003, -162.7000000000003, 5.299999999999965, -15.699999999999754, 20.000000000000014, -13.599999999999783, -36.69999999999976, 20.000000000000014, 68.59999999999982, -22.59999999999978, 21.500000000000036, 17.899999999999988, 9.499999999999964, -7.8999999999998884, 20.000000000000014, 13.699999999999966, 11.599999999999964, 82.40000000000006, 17.899999999999988, 15.799999999999963, 7.399999999999965, -15.699999999999747, -7.299999999999891, 44.000000000000014, 20.000000000000014, 9.499999999999964, 11.599999999999964, 11.599999999999964, -34.59999999999977, 20.000000000000014], "policy_predator_policy_reward": [138.0, 50.0, 0.0, 7.0, 25.0, 15.0, 4.0, 5.0, 4.0, 4.0, 200.0, 1.0, 12.0, 1.0, 2.0, 0.0, 5.0, 3.0, 3.0, 0.0, 12.0, 2.0, 13.0, 1.0, 11.0, 3.0, 11.0, 2.0, 11.0, 9.0, 5.0, 6.0, 12.0, 0.0, 6.0, 6.0, 4.0, 12.0, 15.0, 15.0, 15.0, 37.0, 15.0, 2.0, 1.0, 4.0, 10.0, 11.0, 10.0, 9.0, 1.0, 3.0, 8.0, 4.0, 9.0, 3.0, 5.0, 0.0, 3.0, 3.0, 29.0, 15.0, 166.0, 0.0, 76.0, 0.0, 33.0, 9.0, 0.0, 2.0, 1.0, 177.0, 139.0, 112.0, 6.0, 13.0, 10.0, 7.0, 8.0, 6.0, 2.0, 6.0, 17.0, 82.0, 9.0, 2.0, 65.0, 4.0, 19.0, 2.0, 11.0, 3.0, 15.0, 10.0, 3.0, 4.0, 0.0, 194.0, 0.0, 4.0, 11.0, 177.0, 13.0, 6.0, 7.0, 5.0, 5.0, 7.0, 18.0, 13.0, 7.0, 8.0, 15.0, 11.0, 8.0, 0.0, 21.0, 10.0, 0.0, 2.0, 12.0, 12.0, 8.0, 5.0, 0.0, 9.0, 2.0, 5.0, 0.0, 1.0, 0.0, 4.0, 121.0, 30.0, 12.0, 2.0, 7.0, 7.0, 6.0, 5.0, 5.0, 121.0, 281.0, 3.0, 15.0, 15.0, 13.0, 37.0, 19.0, 1.0, 34.0, 0.0, 193.0, 11.0, 200.0, 2.0, 2.0, 10.0, 12.0, 4.0, 1.0, 6.0, 0.0, 13.0, 83.0, 106.0, 9.0, 11.0, 62.0, 4.0, 4.0, 86.0, 17.0, 7.0, 16.0, 2.0, 27.0, 8.0, 10.0, 18.0, 4.0, 4.0, 5.0, 15.0, 1.0, 3.0, 5.0, 4.0, 2.0, 1.0, 17.0, 5.0, 13.0, 8.0, 5.0, 0.0, 4.0, 4.0, 23.0, 6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5851684947297031, "mean_inference_ms": 1.8110457128359008, "mean_action_processing_ms": 0.251644596365289, "mean_env_wait_ms": 0.19584947930679533, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0040215253829956055, "StateBufferConnector_ms": 0.0035381317138671875, "ViewRequirementAgentConnector_ms": 0.09556996822357178}, "num_episodes": 18, "episode_return_max": 133.99999999999972, "episode_return_min": -322.19999999999914, "episode_return_mean": 6.593000000000015, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2720000, "num_agent_steps_trained": 2720000, "num_env_steps_sampled": 680000, "num_env_steps_trained": 680000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 365.06483521964054, "num_env_steps_trained_throughput_per_sec": 365.06483521964054, "timesteps_total": 680000, "num_env_steps_sampled_lifetime": 680000, "num_agent_steps_sampled_lifetime": 2720000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2720000, "timers": {"training_iteration_time_ms": 11144.472, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11144.4, "sample_time_ms": 1308.263, "learn_time_ms": 9816.643, "learn_throughput": 407.471, "synch_weights_time_ms": 16.74}, "counters": {"num_env_steps_sampled": 680000, "num_env_steps_trained": 680000, "num_agent_steps_sampled": 2720000, "num_agent_steps_trained": 2720000}, "done": false, "training_iteration": 170, "trial_id": "3dae5_00000", "date": "2024-08-14_09-38-11", "timestamp": 1723642691, "time_this_iter_s": 10.996861934661865, "time_total_s": 3508.4238798618317, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3867b80>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3508.4238798618317, "iterations_since_restore": 170, "perf": {"cpu_util_percent": 29.700000000000003, "ram_util_percent": 83.75}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9808340390838644, "cur_kl_coeff": 0.00026396960020065314, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.8951702040023904, "policy_loss": -0.001941095820502452, "vf_loss": 0.8971079583836611, "vf_explained_var": 0.1362765065892033, "kl": 0.012665679290231512, "entropy": 0.8841072070850897, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 322245.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.2640264860536687, "cur_kl_coeff": 0.02669677734374999, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.2818823632187943, "policy_loss": -0.006970436590915871, "vf_loss": 1.2886640869593493, "vf_explained_var": 0.18298569271173426, "kl": 0.007068786110400143, "entropy": 1.0453275795966859, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 322245.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 684000, "num_env_steps_trained": 684000, "num_agent_steps_sampled": 2736000, "num_agent_steps_trained": 2736000}, "env_runners": {"episode_reward_max": 122.09999999999928, "episode_reward_min": -184.4000000000008, "episode_reward_mean": 9.834000000000024, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -472.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 106.69999999999975, "predator_policy": 281.0}, "policy_reward_mean": {"prey_policy": -15.497999999999998, "predator_policy": 20.415}, "custom_metrics": {}, "hist_stats": {"episode_reward": [5.600000000000183, 24.700000000000053, -12.70000000000006, 24.90000000000006, 34.50000000000022, 23.200000000000024, 38.00000000000027, 37.700000000000266, 26.800000000000086, 26.800000000000086, 71.39999999999972, 39.700000000000294, 17.699999999999964, -134.5000000000008, -43.59999999999991, -3.4999999999997167, 65.70000000000023, -153.70000000000053, -82.80000000000024, 19.09999999999999, 27.6000000000001, 28.80000000000012, 122.09999999999928, -37.39999999999958, 27.900000000000105, -35.899999999999714, 52.00000000000025, 24.600000000000048, 35.30000000000023, 38.60000000000028, -173.4000000000007, 35.600000000000236, -166.80000000000075, 32.000000000000185, 35.20000000000023, 28.900000000000123, 12.20000000000006, 31.900000000000176, 11.400000000000077, 63.30000000000034, 59.90000000000018, 37.80000000000027, 39.700000000000294, 25.700000000000067, 13.300000000000056, 33.200000000000195, 38.90000000000028, 89.5999999999994, -63.09999999999975, 28.800000000000125, 44.40000000000015, 27.900000000000105, -133.50000000000105, -168.00000000000063, 36.40000000000025, -14.999999999999522, 17.99999999999998, 0.5000000000000155, -184.4000000000008, -178.00000000000065, 31.000000000000163, 22.40000000000001, 35.30000000000023, 25.70000000000007, -93.80000000000081, 18.000000000000004, 37.00000000000021, 1.2999999999999936, 13.60000000000002, 24.40000000000005, 18.29999999999996, 73.99999999999972, 47.400000000000425, 21.600000000000033, 37.700000000000266, 102.99999999999942, 36.70000000000025, 13.700000000000033, 57.70000000000017, 34.50000000000022, 31.200000000000163, 14.399999999999919, 35.10000000000023, 41.30000000000034, 37.80000000000027, 27.400000000000098, 39.700000000000294, 6.999999999999922, 69.30000000000003, 23.200000000000028, 26.20000000000008, 19.100000000000005, 19.399999999999963, -76.50000000000077, 36.50000000000025, 33.4000000000002, -3.8999999999996886, 22.10000000000001, 23.20000000000003, 27.000000000000092], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-5.1999999999999265, -5.1999999999999265, -11.499999999999819, 6.1999999999999655, -40.59999999999996, -24.099999999999767, 15.799999999999963, -7.8999999999998884, 11.599999999999964, 17.899999999999988, 11.599999999999964, -9.399999999999855, -0.9999999999999846, 20.000000000000014, 20.000000000000014, 13.699999999999964, 11.599999999999964, 3.1999999999999615, 1.0999999999999865, 13.699999999999964, 46.40000000000007, 20.000000000000014, 20.000000000000014, 13.699999999999964, 13.699999999999964, -39.99999999999976, 28.100000000000147, -328.5999999999992, 20.000000000000014, -139.6000000000007, -49.299999999999905, 3.7999999999999656, 15.799999999999963, 47.90000000000016, 20.000000000000014, -351.70000000000005, 20.000000000000014, -353.7999999999996, 7.399999999999965, -7.299999999999891, 13.699999999999964, -3.099999999999958, 3.1999999999999615, 11.599999999999964, 7.399999999999965, 106.69999999999975, -47.199999999999854, -89.20000000000084, 15.799999999999963, 1.0999999999999865, 11.599999999999964, -116.50000000000038, 15.199999999999994, 15.799999999999963, 13.699999999999964, -3.099999999999958, 3.1999999999999615, 7.0999999999999694, 20.000000000000014, 11.599999999999964, 20.000000000000014, -387.39999999999986, 20.000000000000014, 11.599999999999964, -3.099999999999958, -351.6999999999997, 17.899999999999988, -4.899999999999942, 20.000000000000014, 3.1999999999999615, 5.299999999999965, 11.599999999999964, -3.099999999999958, -15.699999999999747, 13.699999999999964, 3.1999999999999615, -11.499999999999819, -3.099999999999958, 17.899999999999988, 37.40000000000005, -0.9999999999999846, 29.900000000000045, 20.000000000000014, 15.799999999999963, 20.90000000000003, -5.1999999999999265, 9.499999999999964, 3.1999999999999615, 1.0999999999999865, 3.1999999999999615, 10.399999999999965, 15.799999999999963, 20.000000000000014, 17.899999999999988, 69.79999999999984, 15.799999999999963, -234.10000000000045, 20.000000000000014, 20.000000000000014, -5.1999999999999265, 5.299999999999965, 25.10000000000005, 9.499999999999964, 7.399999999999965, -172.40000000000052, -87.10000000000036, 20.000000000000014, -472.0, 5.299999999999965, 1.0999999999999723, -57.70000000000048, -7.299999999999891, -19.899999999999743, 17.899999999999988, 11.599999999999946, -45.100000000000016, -385.29999999999995, -3.099999999999958, -400.0, 20.000000000000014, 20.000000000000014, -0.9999999999999846, 11.599999999999964, -5.1999999999999265, 7.399999999999965, 20.900000000000027, -7.299999999999891, 20.000000000000014, -262.0000000000002, -20.79999999999977, -3.099999999999958, 1.0999999999999865, -110.20000000000078, 81.19999999999979, 74.00000000000003, -162.7000000000003, 5.299999999999965, -15.699999999999754, 20.000000000000014, -13.599999999999783, -36.69999999999976, 20.000000000000014, 68.59999999999982, -22.59999999999978, 21.500000000000036, 17.899999999999988, 9.499999999999964, -7.8999999999998884, 20.000000000000014, 13.699999999999966, 11.599999999999964, 82.40000000000006, 17.899999999999988, 15.799999999999963, 7.399999999999965, -15.699999999999747, -7.299999999999891, 44.000000000000014, 20.000000000000014, 9.499999999999964, 11.599999999999964, 11.599999999999964, -34.59999999999977, 20.000000000000014, 20.000000000000014, 1.0999999999999865, 15.799999999999963, 9.499999999999977, 20.000000000000014, -5.1999999999999265, -9.399999999999855, 15.799999999999963, 20.000000000000014, 13.699999999999964, -30.39999999999977, 7.399999999999965, -7.299999999999891, 59.600000000000065, 20.000000000000014, -14.799999999999764, 7.39999999999997, -5.1999999999999265, -5.1999999999999265, 5.299999999999965, 20.000000000000014, -34.59999999999975, 20.000000000000014, -221.50000000000048, 11.599999999999964, 20.90000000000003, 11.599999999999964, 15.799999999999963, -11.499999999999819, -9.399999999999855, 20.000000000000014, -19.899999999999743, -3.099999999999972, 5.299999999999965, 8.899999999999956, 1.0999999999999528], "policy_predator_policy_reward": [4.0, 12.0, 15.0, 15.0, 15.0, 37.0, 15.0, 2.0, 1.0, 4.0, 10.0, 11.0, 10.0, 9.0, 1.0, 3.0, 8.0, 4.0, 9.0, 3.0, 5.0, 0.0, 3.0, 3.0, 29.0, 15.0, 166.0, 0.0, 76.0, 0.0, 33.0, 9.0, 0.0, 2.0, 1.0, 177.0, 139.0, 112.0, 6.0, 13.0, 10.0, 7.0, 8.0, 6.0, 2.0, 6.0, 17.0, 82.0, 9.0, 2.0, 65.0, 4.0, 19.0, 2.0, 11.0, 3.0, 15.0, 10.0, 3.0, 4.0, 0.0, 194.0, 0.0, 4.0, 11.0, 177.0, 13.0, 6.0, 7.0, 5.0, 5.0, 7.0, 18.0, 13.0, 7.0, 8.0, 15.0, 11.0, 8.0, 0.0, 21.0, 10.0, 0.0, 2.0, 12.0, 12.0, 8.0, 5.0, 0.0, 9.0, 2.0, 5.0, 0.0, 1.0, 0.0, 4.0, 121.0, 30.0, 12.0, 2.0, 7.0, 7.0, 6.0, 5.0, 5.0, 121.0, 281.0, 3.0, 15.0, 15.0, 13.0, 37.0, 19.0, 1.0, 34.0, 0.0, 193.0, 11.0, 200.0, 2.0, 2.0, 10.0, 12.0, 4.0, 1.0, 6.0, 0.0, 13.0, 83.0, 106.0, 9.0, 11.0, 62.0, 4.0, 4.0, 86.0, 17.0, 7.0, 16.0, 2.0, 27.0, 8.0, 10.0, 18.0, 4.0, 4.0, 5.0, 15.0, 1.0, 3.0, 5.0, 4.0, 2.0, 1.0, 17.0, 5.0, 13.0, 8.0, 5.0, 0.0, 4.0, 4.0, 23.0, 6.0, 9.0, 5.0, 2.0, 14.0, 11.0, 12.0, 13.0, 8.0, 3.0, 3.0, 24.0, 6.0, 6.0, 11.0, 2.0, 16.0, 18.0, 6.0, 7.0, 12.0, 8.0, 26.0, 113.0, 12.0, 4.0, 0.0, 4.0, 2.0, 15.0, 2.0, 3.0, 19.0, 9.0, 12.0, 16.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5850590038155922, "mean_inference_ms": 1.8105500905128005, "mean_action_processing_ms": 0.2515308473917197, "mean_env_wait_ms": 0.1958063576173633, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004037380218505859, "StateBufferConnector_ms": 0.0035943984985351562, "ViewRequirementAgentConnector_ms": 0.09735691547393799}, "num_episodes": 18, "episode_return_max": 122.09999999999928, "episode_return_min": -184.4000000000008, "episode_return_mean": 9.834000000000024, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2736000, "num_agent_steps_trained": 2736000, "num_env_steps_sampled": 684000, "num_env_steps_trained": 684000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 353.8620379343573, "num_env_steps_trained_throughput_per_sec": 353.8620379343573, "timesteps_total": 684000, "num_env_steps_sampled_lifetime": 684000, "num_agent_steps_sampled_lifetime": 2736000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2736000, "timers": {"training_iteration_time_ms": 11170.713, "restore_workers_time_ms": 0.015, "training_step_time_ms": 11170.64, "sample_time_ms": 1310.585, "learn_time_ms": 9840.385, "learn_throughput": 406.488, "synch_weights_time_ms": 16.897}, "counters": {"num_env_steps_sampled": 684000, "num_env_steps_trained": 684000, "num_agent_steps_sampled": 2736000, "num_agent_steps_trained": 2736000}, "done": false, "training_iteration": 171, "trial_id": "3dae5_00000", "date": "2024-08-14_09-38-23", "timestamp": 1723642703, "time_this_iter_s": 11.317556142807007, "time_total_s": 3519.7414360046387, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3867af0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3519.7414360046387, "iterations_since_restore": 171, "perf": {"cpu_util_percent": 30.737499999999997, "ram_util_percent": 83.69375}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.569196334733534, "cur_kl_coeff": 0.00026396960020065314, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.9588219987967658, "policy_loss": -0.0016262064885013002, "vf_loss": 0.9604464065618616, "vf_explained_var": 0.11898988507412098, "kl": 0.006819445344908747, "entropy": 0.7373344810236068, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 324135.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.494052523311484, "cur_kl_coeff": 0.02669677734374999, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.5277806362935475, "policy_loss": -0.005938633506201089, "vf_loss": 1.5334993446314777, "vf_explained_var": 0.13236554277637017, "kl": 0.008238023698835382, "entropy": 0.9731066093558357, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 324135.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 688000, "num_env_steps_trained": 688000, "num_agent_steps_sampled": 2752000, "num_agent_steps_trained": 2752000}, "env_runners": {"episode_reward_max": 122.09999999999928, "episode_reward_min": -184.4000000000008, "episode_reward_mean": 14.89900000000004, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -472.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 106.69999999999975, "predator_policy": 281.0}, "policy_reward_mean": {"prey_policy": -11.950500000000016, "predator_policy": 19.4}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-82.80000000000024, 19.09999999999999, 27.6000000000001, 28.80000000000012, 122.09999999999928, -37.39999999999958, 27.900000000000105, -35.899999999999714, 52.00000000000025, 24.600000000000048, 35.30000000000023, 38.60000000000028, -173.4000000000007, 35.600000000000236, -166.80000000000075, 32.000000000000185, 35.20000000000023, 28.900000000000123, 12.20000000000006, 31.900000000000176, 11.400000000000077, 63.30000000000034, 59.90000000000018, 37.80000000000027, 39.700000000000294, 25.700000000000067, 13.300000000000056, 33.200000000000195, 38.90000000000028, 89.5999999999994, -63.09999999999975, 28.800000000000125, 44.40000000000015, 27.900000000000105, -133.50000000000105, -168.00000000000063, 36.40000000000025, -14.999999999999522, 17.99999999999998, 0.5000000000000155, -184.4000000000008, -178.00000000000065, 31.000000000000163, 22.40000000000001, 35.30000000000023, 25.70000000000007, -93.80000000000081, 18.000000000000004, 37.00000000000021, 1.2999999999999936, 13.60000000000002, 24.40000000000005, 18.29999999999996, 73.99999999999972, 47.400000000000425, 21.600000000000033, 37.700000000000266, 102.99999999999942, 36.70000000000025, 13.700000000000033, 57.70000000000017, 34.50000000000022, 31.200000000000163, 14.399999999999919, 35.10000000000023, 41.30000000000034, 37.80000000000027, 27.400000000000098, 39.700000000000294, 6.999999999999922, 69.30000000000003, 23.200000000000028, 26.20000000000008, 19.100000000000005, 19.399999999999963, -76.50000000000077, 36.50000000000025, 33.4000000000002, -3.8999999999996886, 22.10000000000001, 23.20000000000003, 27.000000000000092, 25.700000000000067, -53.599999999999625, 36.60000000000025, 37.50000000000026, 18.099999999999998, 103.39999999999966, -30.699999999999534, 31.90000000000019, 86.39999999999964, 34.200000000000216, 33.1000000000002, 75.79999999999959, -29.399999999999523, 29.300000000000143, 81.90000000000009, 25.700000000000067, 34.50000000000022, 54.80000000000048], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, -353.7999999999996, 7.399999999999965, -7.299999999999891, 13.699999999999964, -3.099999999999958, 3.1999999999999615, 11.599999999999964, 7.399999999999965, 106.69999999999975, -47.199999999999854, -89.20000000000084, 15.799999999999963, 1.0999999999999865, 11.599999999999964, -116.50000000000038, 15.199999999999994, 15.799999999999963, 13.699999999999964, -3.099999999999958, 3.1999999999999615, 7.0999999999999694, 20.000000000000014, 11.599999999999964, 20.000000000000014, -387.39999999999986, 20.000000000000014, 11.599999999999964, -3.099999999999958, -351.6999999999997, 17.899999999999988, -4.899999999999942, 20.000000000000014, 3.1999999999999615, 5.299999999999965, 11.599999999999964, -3.099999999999958, -15.699999999999747, 13.699999999999964, 3.1999999999999615, -11.499999999999819, -3.099999999999958, 17.899999999999988, 37.40000000000005, -0.9999999999999846, 29.900000000000045, 20.000000000000014, 15.799999999999963, 20.90000000000003, -5.1999999999999265, 9.499999999999964, 3.1999999999999615, 1.0999999999999865, 3.1999999999999615, 10.399999999999965, 15.799999999999963, 20.000000000000014, 17.899999999999988, 69.79999999999984, 15.799999999999963, -234.10000000000045, 20.000000000000014, 20.000000000000014, -5.1999999999999265, 5.299999999999965, 25.10000000000005, 9.499999999999964, 7.399999999999965, -172.40000000000052, -87.10000000000036, 20.000000000000014, -472.0, 5.299999999999965, 1.0999999999999723, -57.70000000000048, -7.299999999999891, -19.899999999999743, 17.899999999999988, 11.599999999999946, -45.100000000000016, -385.29999999999995, -3.099999999999958, -400.0, 20.000000000000014, 20.000000000000014, -0.9999999999999846, 11.599999999999964, -5.1999999999999265, 7.399999999999965, 20.900000000000027, -7.299999999999891, 20.000000000000014, -262.0000000000002, -20.79999999999977, -3.099999999999958, 1.0999999999999865, -110.20000000000078, 81.19999999999979, 74.00000000000003, -162.7000000000003, 5.299999999999965, -15.699999999999754, 20.000000000000014, -13.599999999999783, -36.69999999999976, 20.000000000000014, 68.59999999999982, -22.59999999999978, 21.500000000000036, 17.899999999999988, 9.499999999999964, -7.8999999999998884, 20.000000000000014, 13.699999999999966, 11.599999999999964, 82.40000000000006, 17.899999999999988, 15.799999999999963, 7.399999999999965, -15.699999999999747, -7.299999999999891, 44.000000000000014, 20.000000000000014, 9.499999999999964, 11.599999999999964, 11.599999999999964, -34.59999999999977, 20.000000000000014, 20.000000000000014, 1.0999999999999865, 15.799999999999963, 9.499999999999977, 20.000000000000014, -5.1999999999999265, -9.399999999999855, 15.799999999999963, 20.000000000000014, 13.699999999999964, -30.39999999999977, 7.399999999999965, -7.299999999999891, 59.600000000000065, 20.000000000000014, -14.799999999999764, 7.39999999999997, -5.1999999999999265, -5.1999999999999265, 5.299999999999965, 20.000000000000014, -34.59999999999975, 20.000000000000014, -221.50000000000048, 11.599999999999964, 20.90000000000003, 11.599999999999964, 15.799999999999963, -11.499999999999819, -9.399999999999855, 20.000000000000014, -19.899999999999743, -3.099999999999972, 5.299999999999965, 8.899999999999956, 1.0999999999999528, -3.099999999999965, 15.799999999999963, 13.699999999999964, -154.3000000000006, 11.599999999999964, 20.000000000000014, 9.499999999999964, 20.000000000000014, -7.299999999999894, 7.399999999999965, 84.80000000000001, 11.599999999999964, -61.900000000000766, -38.79999999999976, 20.000000000000014, -24.099999999999746, 49.40000000000009, 20.000000000000014, -59.80000000000062, 20.000000000000014, 1.0999999999999865, 20.000000000000014, 59.60000000000019, 3.1999999999999615, -93.40000000000083, -0.9999999999999846, 1.0999999999999865, 6.199999999999973, 13.699999999999964, 63.20000000000005, 13.699999999999964, -0.9999999999999846, 20.000000000000014, 9.499999999999964, 17.59999999999998, 3.1999999999999615], "policy_predator_policy_reward": [139.0, 112.0, 6.0, 13.0, 10.0, 7.0, 8.0, 6.0, 2.0, 6.0, 17.0, 82.0, 9.0, 2.0, 65.0, 4.0, 19.0, 2.0, 11.0, 3.0, 15.0, 10.0, 3.0, 4.0, 0.0, 194.0, 0.0, 4.0, 11.0, 177.0, 13.0, 6.0, 7.0, 5.0, 5.0, 7.0, 18.0, 13.0, 7.0, 8.0, 15.0, 11.0, 8.0, 0.0, 21.0, 10.0, 0.0, 2.0, 12.0, 12.0, 8.0, 5.0, 0.0, 9.0, 2.0, 5.0, 0.0, 1.0, 0.0, 4.0, 121.0, 30.0, 12.0, 2.0, 7.0, 7.0, 6.0, 5.0, 5.0, 121.0, 281.0, 3.0, 15.0, 15.0, 13.0, 37.0, 19.0, 1.0, 34.0, 0.0, 193.0, 11.0, 200.0, 2.0, 2.0, 10.0, 12.0, 4.0, 1.0, 6.0, 0.0, 13.0, 83.0, 106.0, 9.0, 11.0, 62.0, 4.0, 4.0, 86.0, 17.0, 7.0, 16.0, 2.0, 27.0, 8.0, 10.0, 18.0, 4.0, 4.0, 5.0, 15.0, 1.0, 3.0, 5.0, 4.0, 2.0, 1.0, 17.0, 5.0, 13.0, 8.0, 5.0, 0.0, 4.0, 4.0, 23.0, 6.0, 9.0, 5.0, 2.0, 14.0, 11.0, 12.0, 13.0, 8.0, 3.0, 3.0, 24.0, 6.0, 6.0, 11.0, 2.0, 16.0, 18.0, 6.0, 7.0, 12.0, 8.0, 26.0, 113.0, 12.0, 4.0, 0.0, 4.0, 2.0, 15.0, 2.0, 3.0, 19.0, 9.0, 12.0, 16.0, 1.0, 7.0, 6.0, 80.0, 7.0, 4.0, 1.0, 3.0, 5.0, 11.0, 7.0, 4.0, 3.0, 31.0, 39.0, 15.0, 21.0, 13.0, 4.0, 36.0, 38.0, 9.0, 3.0, 8.0, 5.0, 54.0, 11.0, 9.0, 13.0, 3.0, 2.0, 10.0, 3.0, 0.0, 5.0, 12.0, 22.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5849490595488819, "mean_inference_ms": 1.810120378128667, "mean_action_processing_ms": 0.2514190068294829, "mean_env_wait_ms": 0.19577135666875634, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00399017333984375, "StateBufferConnector_ms": 0.0033447742462158203, "ViewRequirementAgentConnector_ms": 0.09585320949554443}, "num_episodes": 18, "episode_return_max": 122.09999999999928, "episode_return_min": -184.4000000000008, "episode_return_mean": 14.89900000000004, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2752000, "num_agent_steps_trained": 2752000, "num_env_steps_sampled": 688000, "num_env_steps_trained": 688000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 355.1504879218424, "num_env_steps_trained_throughput_per_sec": 355.1504879218424, "timesteps_total": 688000, "num_env_steps_sampled_lifetime": 688000, "num_agent_steps_sampled_lifetime": 2752000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2752000, "timers": {"training_iteration_time_ms": 11210.558, "restore_workers_time_ms": 0.015, "training_step_time_ms": 11210.487, "sample_time_ms": 1314.345, "learn_time_ms": 9876.3, "learn_throughput": 405.01, "synch_weights_time_ms": 17.21}, "counters": {"num_env_steps_sampled": 688000, "num_env_steps_trained": 688000, "num_agent_steps_sampled": 2752000, "num_agent_steps_trained": 2752000}, "done": false, "training_iteration": 172, "trial_id": "3dae5_00000", "date": "2024-08-14_09-38-34", "timestamp": 1723642714, "time_this_iter_s": 11.294605731964111, "time_total_s": 3531.036041736603, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b38efd30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3531.036041736603, "iterations_since_restore": 172, "perf": {"cpu_util_percent": 32.36875, "ram_util_percent": 83.6}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5349025094162219, "cur_kl_coeff": 0.00026396960020065314, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.4681042062463584, "policy_loss": -0.004010282448990635, "vf_loss": 0.472111769470943, "vf_explained_var": 0.1785853205534516, "kl": 0.010297583549205859, "entropy": 0.9323415885842036, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 326025.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.1379537729989915, "cur_kl_coeff": 0.02669677734374999, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.074673459848399, "policy_loss": -0.005477319772154457, "vf_loss": 1.0800038341649625, "vf_explained_var": 0.30869511766408486, "kl": 0.0055042472557719005, "entropy": 1.0133607201790684, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 326025.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 692000, "num_env_steps_trained": 692000, "num_agent_steps_sampled": 2768000, "num_agent_steps_trained": 2768000}, "env_runners": {"episode_reward_max": 125.19999999999871, "episode_reward_min": -184.4000000000008, "episode_reward_mean": 20.141000000000034, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -472.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 106.39999999999944, "predator_policy": 281.0}, "policy_reward_mean": {"prey_policy": -6.139500000000013, "predator_policy": 16.21}, "custom_metrics": {}, "hist_stats": {"episode_reward": [37.80000000000027, 39.700000000000294, 25.700000000000067, 13.300000000000056, 33.200000000000195, 38.90000000000028, 89.5999999999994, -63.09999999999975, 28.800000000000125, 44.40000000000015, 27.900000000000105, -133.50000000000105, -168.00000000000063, 36.40000000000025, -14.999999999999522, 17.99999999999998, 0.5000000000000155, -184.4000000000008, -178.00000000000065, 31.000000000000163, 22.40000000000001, 35.30000000000023, 25.70000000000007, -93.80000000000081, 18.000000000000004, 37.00000000000021, 1.2999999999999936, 13.60000000000002, 24.40000000000005, 18.29999999999996, 73.99999999999972, 47.400000000000425, 21.600000000000033, 37.700000000000266, 102.99999999999942, 36.70000000000025, 13.700000000000033, 57.70000000000017, 34.50000000000022, 31.200000000000163, 14.399999999999919, 35.10000000000023, 41.30000000000034, 37.80000000000027, 27.400000000000098, 39.700000000000294, 6.999999999999922, 69.30000000000003, 23.200000000000028, 26.20000000000008, 19.100000000000005, 19.399999999999963, -76.50000000000077, 36.50000000000025, 33.4000000000002, -3.8999999999996886, 22.10000000000001, 23.20000000000003, 27.000000000000092, 25.700000000000067, -53.599999999999625, 36.60000000000025, 37.50000000000026, 18.099999999999998, 103.39999999999966, -30.699999999999534, 31.90000000000019, 86.39999999999964, 34.200000000000216, 33.1000000000002, 75.79999999999959, -29.399999999999523, 29.300000000000143, 81.90000000000009, 25.700000000000067, 34.50000000000022, 54.80000000000048, 69.40000000000008, 37.90000000000027, 38.20000000000027, 27.900000000000105, 21.90000000000004, 31.100000000000165, 17.900000000000002, 17.099999999999998, 87.4999999999993, 15.79999999999999, 33.4000000000002, 16.899999999999995, 125.19999999999871, 31.100000000000176, -5.799999999999711, 38.300000000000274, 19.300000000000008, -44.29999999999978, 38.70000000000028, 19.199999999999992, 37.80000000000027, 14.599999999999945, 25.200000000000063], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 15.799999999999963, 20.90000000000003, -5.1999999999999265, 9.499999999999964, 3.1999999999999615, 1.0999999999999865, 3.1999999999999615, 10.399999999999965, 15.799999999999963, 20.000000000000014, 17.899999999999988, 69.79999999999984, 15.799999999999963, -234.10000000000045, 20.000000000000014, 20.000000000000014, -5.1999999999999265, 5.299999999999965, 25.10000000000005, 9.499999999999964, 7.399999999999965, -172.40000000000052, -87.10000000000036, 20.000000000000014, -472.0, 5.299999999999965, 1.0999999999999723, -57.70000000000048, -7.299999999999891, -19.899999999999743, 17.899999999999988, 11.599999999999946, -45.100000000000016, -385.29999999999995, -3.099999999999958, -400.0, 20.000000000000014, 20.000000000000014, -0.9999999999999846, 11.599999999999964, -5.1999999999999265, 7.399999999999965, 20.900000000000027, -7.299999999999891, 20.000000000000014, -262.0000000000002, -20.79999999999977, -3.099999999999958, 1.0999999999999865, -110.20000000000078, 81.19999999999979, 74.00000000000003, -162.7000000000003, 5.299999999999965, -15.699999999999754, 20.000000000000014, -13.599999999999783, -36.69999999999976, 20.000000000000014, 68.59999999999982, -22.59999999999978, 21.500000000000036, 17.899999999999988, 9.499999999999964, -7.8999999999998884, 20.000000000000014, 13.699999999999966, 11.599999999999964, 82.40000000000006, 17.899999999999988, 15.799999999999963, 7.399999999999965, -15.699999999999747, -7.299999999999891, 44.000000000000014, 20.000000000000014, 9.499999999999964, 11.599999999999964, 11.599999999999964, -34.59999999999977, 20.000000000000014, 20.000000000000014, 1.0999999999999865, 15.799999999999963, 9.499999999999977, 20.000000000000014, -5.1999999999999265, -9.399999999999855, 15.799999999999963, 20.000000000000014, 13.699999999999964, -30.39999999999977, 7.399999999999965, -7.299999999999891, 59.600000000000065, 20.000000000000014, -14.799999999999764, 7.39999999999997, -5.1999999999999265, -5.1999999999999265, 5.299999999999965, 20.000000000000014, -34.59999999999975, 20.000000000000014, -221.50000000000048, 11.599999999999964, 20.90000000000003, 11.599999999999964, 15.799999999999963, -11.499999999999819, -9.399999999999855, 20.000000000000014, -19.899999999999743, -3.099999999999972, 5.299999999999965, 8.899999999999956, 1.0999999999999528, -3.099999999999965, 15.799999999999963, 13.699999999999964, -154.3000000000006, 11.599999999999964, 20.000000000000014, 9.499999999999964, 20.000000000000014, -7.299999999999894, 7.399999999999965, 84.80000000000001, 11.599999999999964, -61.900000000000766, -38.79999999999976, 20.000000000000014, -24.099999999999746, 49.40000000000009, 20.000000000000014, -59.80000000000062, 20.000000000000014, 1.0999999999999865, 20.000000000000014, 59.60000000000019, 3.1999999999999615, -93.40000000000083, -0.9999999999999846, 1.0999999999999865, 6.199999999999973, 13.699999999999964, 63.20000000000005, 13.699999999999964, -0.9999999999999846, 20.000000000000014, 9.499999999999964, 17.59999999999998, 3.1999999999999615, 27.50000000000015, 20.90000000000003, 24.50000000000008, 7.399999999999965, 3.1999999999999615, 20.000000000000014, -0.9999999999999846, 17.899999999999988, -15.699999999999818, 14.599999999999968, 20.000000000000014, 1.0999999999999865, -9.399999999999855, 5.299999999999965, 5.299999999999965, -5.19999999999993, 64.70000000000005, 15.799999999999963, 9.499999999999964, -15.699999999999747, 15.799999999999963, 11.599999999999964, -9.399999999999855, 5.299999999999967, 15.799999999999963, 106.39999999999944, -16.899999999999743, 20.000000000000014, -2.2, -43.59999999999977, 20.000000000000014, 5.299999999999965, 1.0999999999999865, 3.1999999999999615, -146.2000000000006, 17.899999999999988, 15.799999999999963, 17.899999999999988, -0.9999999999999917, 3.1999999999999615, 15.799999999999963, 20.000000000000014, -51.399999999999764, 20.000000000000014, -17.79999999999974, 20.000000000000014], "policy_predator_policy_reward": [0.0, 2.0, 12.0, 12.0, 8.0, 5.0, 0.0, 9.0, 2.0, 5.0, 0.0, 1.0, 0.0, 4.0, 121.0, 30.0, 12.0, 2.0, 7.0, 7.0, 6.0, 5.0, 5.0, 121.0, 281.0, 3.0, 15.0, 15.0, 13.0, 37.0, 19.0, 1.0, 34.0, 0.0, 193.0, 11.0, 200.0, 2.0, 2.0, 10.0, 12.0, 4.0, 1.0, 6.0, 0.0, 13.0, 83.0, 106.0, 9.0, 11.0, 62.0, 4.0, 4.0, 86.0, 17.0, 7.0, 16.0, 2.0, 27.0, 8.0, 10.0, 18.0, 4.0, 4.0, 5.0, 15.0, 1.0, 3.0, 5.0, 4.0, 2.0, 1.0, 17.0, 5.0, 13.0, 8.0, 5.0, 0.0, 4.0, 4.0, 23.0, 6.0, 9.0, 5.0, 2.0, 14.0, 11.0, 12.0, 13.0, 8.0, 3.0, 3.0, 24.0, 6.0, 6.0, 11.0, 2.0, 16.0, 18.0, 6.0, 7.0, 12.0, 8.0, 26.0, 113.0, 12.0, 4.0, 0.0, 4.0, 2.0, 15.0, 2.0, 3.0, 19.0, 9.0, 12.0, 16.0, 1.0, 7.0, 6.0, 80.0, 7.0, 4.0, 1.0, 3.0, 5.0, 11.0, 7.0, 4.0, 3.0, 31.0, 39.0, 15.0, 21.0, 13.0, 4.0, 36.0, 38.0, 9.0, 3.0, 8.0, 5.0, 54.0, 11.0, 9.0, 13.0, 3.0, 2.0, 10.0, 3.0, 0.0, 5.0, 12.0, 22.0, 10.0, 11.0, 0.0, 6.0, 7.0, 8.0, 1.0, 10.0, 6.0, 17.0, 1.0, 9.0, 13.0, 9.0, 5.0, 12.0, 0.0, 7.0, 5.0, 17.0, 4.0, 2.0, 7.0, 14.0, 2.0, 1.0, 18.0, 10.0, 23.0, 17.0, 7.0, 6.0, 9.0, 6.0, 72.0, 12.0, 2.0, 3.0, 6.0, 11.0, 0.0, 2.0, 33.0, 13.0, 5.0, 18.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5851212239518641, "mean_inference_ms": 1.8087811929566917, "mean_action_processing_ms": 0.25141956519370007, "mean_env_wait_ms": 0.1958212727205219, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003996729850769043, "StateBufferConnector_ms": 0.003358125686645508, "ViewRequirementAgentConnector_ms": 0.09738552570343018}, "num_episodes": 23, "episode_return_max": 125.19999999999871, "episode_return_min": -184.4000000000008, "episode_return_mean": 20.141000000000034, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2768000, "num_agent_steps_trained": 2768000, "num_env_steps_sampled": 692000, "num_env_steps_trained": 692000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 372.63078656933067, "num_env_steps_trained_throughput_per_sec": 372.63078656933067, "timesteps_total": 692000, "num_env_steps_sampled_lifetime": 692000, "num_agent_steps_sampled_lifetime": 2768000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2768000, "timers": {"training_iteration_time_ms": 11086.089, "restore_workers_time_ms": 0.015, "training_step_time_ms": 11086.019, "sample_time_ms": 1306.801, "learn_time_ms": 9760.419, "learn_throughput": 409.818, "synch_weights_time_ms": 16.677}, "counters": {"num_env_steps_sampled": 692000, "num_env_steps_trained": 692000, "num_agent_steps_sampled": 2768000, "num_agent_steps_trained": 2768000}, "done": false, "training_iteration": 173, "trial_id": "3dae5_00000", "date": "2024-08-14_09-38-45", "timestamp": 1723642725, "time_this_iter_s": 10.74043583869934, "time_total_s": 3541.776477575302, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b38efdc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3541.776477575302, "iterations_since_restore": 173, "perf": {"cpu_util_percent": 28.612499999999997, "ram_util_percent": 83.46249999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3889736900096217, "cur_kl_coeff": 0.00026396960020065314, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.5669693131295461, "policy_loss": -0.0015905056345872778, "vf_loss": 1.56855709801906, "vf_explained_var": 0.15315126521246775, "kl": 0.010306412976397313, "entropy": 0.7684241724077356, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 327915.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.587981961076222, "cur_kl_coeff": 0.02669677734374999, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.7236509582353015, "policy_loss": -0.006953569676076609, "vf_loss": 2.730286279620317, "vf_explained_var": 0.08315521188513943, "kl": 0.01192081126263686, "entropy": 0.9498697293498529, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 327915.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 696000, "num_env_steps_trained": 696000, "num_agent_steps_sampled": 2784000, "num_agent_steps_trained": 2784000}, "env_runners": {"episode_reward_max": 143.29999999999976, "episode_reward_min": -253.8000000000007, "episode_reward_mean": 27.050000000000022, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -301.29999999999893, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 123.49999999999972, "predator_policy": 161.0}, "policy_reward_mean": {"prey_policy": -1.194999999999999, "predator_policy": 14.72}, "custom_metrics": {}, "hist_stats": {"episode_reward": [25.70000000000007, -93.80000000000081, 18.000000000000004, 37.00000000000021, 1.2999999999999936, 13.60000000000002, 24.40000000000005, 18.29999999999996, 73.99999999999972, 47.400000000000425, 21.600000000000033, 37.700000000000266, 102.99999999999942, 36.70000000000025, 13.700000000000033, 57.70000000000017, 34.50000000000022, 31.200000000000163, 14.399999999999919, 35.10000000000023, 41.30000000000034, 37.80000000000027, 27.400000000000098, 39.700000000000294, 6.999999999999922, 69.30000000000003, 23.200000000000028, 26.20000000000008, 19.100000000000005, 19.399999999999963, -76.50000000000077, 36.50000000000025, 33.4000000000002, -3.8999999999996886, 22.10000000000001, 23.20000000000003, 27.000000000000092, 25.700000000000067, -53.599999999999625, 36.60000000000025, 37.50000000000026, 18.099999999999998, 103.39999999999966, -30.699999999999534, 31.90000000000019, 86.39999999999964, 34.200000000000216, 33.1000000000002, 75.79999999999959, -29.399999999999523, 29.300000000000143, 81.90000000000009, 25.700000000000067, 34.50000000000022, 54.80000000000048, 69.40000000000008, 37.90000000000027, 38.20000000000027, 27.900000000000105, 21.90000000000004, 31.100000000000165, 17.900000000000002, 17.099999999999998, 87.4999999999993, 15.79999999999999, 33.4000000000002, 16.899999999999995, 125.19999999999871, 31.100000000000176, -5.799999999999711, 38.300000000000274, 19.300000000000008, -44.29999999999978, 38.70000000000028, 19.199999999999992, 37.80000000000027, 14.599999999999945, 25.200000000000063, 29.000000000000128, 143.29999999999976, 14.700000000000008, 93.19999999999996, 36.80000000000025, 31.200000000000166, 21.299999999999997, 36.70000000000025, -83.7999999999999, 21.900000000000002, 15.099999999999929, 125.59999999999928, -42.299999999999756, -253.8000000000007, 60.00000000000052, 112.59999999999897, 22.000000000000004, 32.30000000000019, 137.69999999999916, 38.20000000000027, -150.3000000000011, 30.40000000000015], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-7.299999999999891, 20.000000000000014, -262.0000000000002, -20.79999999999977, -3.099999999999958, 1.0999999999999865, -110.20000000000078, 81.19999999999979, 74.00000000000003, -162.7000000000003, 5.299999999999965, -15.699999999999754, 20.000000000000014, -13.599999999999783, -36.69999999999976, 20.000000000000014, 68.59999999999982, -22.59999999999978, 21.500000000000036, 17.899999999999988, 9.499999999999964, -7.8999999999998884, 20.000000000000014, 13.699999999999966, 11.599999999999964, 82.40000000000006, 17.899999999999988, 15.799999999999963, 7.399999999999965, -15.699999999999747, -7.299999999999891, 44.000000000000014, 20.000000000000014, 9.499999999999964, 11.599999999999964, 11.599999999999964, -34.59999999999977, 20.000000000000014, 20.000000000000014, 1.0999999999999865, 15.799999999999963, 9.499999999999977, 20.000000000000014, -5.1999999999999265, -9.399999999999855, 15.799999999999963, 20.000000000000014, 13.699999999999964, -30.39999999999977, 7.399999999999965, -7.299999999999891, 59.600000000000065, 20.000000000000014, -14.799999999999764, 7.39999999999997, -5.1999999999999265, -5.1999999999999265, 5.299999999999965, 20.000000000000014, -34.59999999999975, 20.000000000000014, -221.50000000000048, 11.599999999999964, 20.90000000000003, 11.599999999999964, 15.799999999999963, -11.499999999999819, -9.399999999999855, 20.000000000000014, -19.899999999999743, -3.099999999999972, 5.299999999999965, 8.899999999999956, 1.0999999999999528, -3.099999999999965, 15.799999999999963, 13.699999999999964, -154.3000000000006, 11.599999999999964, 20.000000000000014, 9.499999999999964, 20.000000000000014, -7.299999999999894, 7.399999999999965, 84.80000000000001, 11.599999999999964, -61.900000000000766, -38.79999999999976, 20.000000000000014, -24.099999999999746, 49.40000000000009, 20.000000000000014, -59.80000000000062, 20.000000000000014, 1.0999999999999865, 20.000000000000014, 59.60000000000019, 3.1999999999999615, -93.40000000000083, -0.9999999999999846, 1.0999999999999865, 6.199999999999973, 13.699999999999964, 63.20000000000005, 13.699999999999964, -0.9999999999999846, 20.000000000000014, 9.499999999999964, 17.59999999999998, 3.1999999999999615, 27.50000000000015, 20.90000000000003, 24.50000000000008, 7.399999999999965, 3.1999999999999615, 20.000000000000014, -0.9999999999999846, 17.899999999999988, -15.699999999999818, 14.599999999999968, 20.000000000000014, 1.0999999999999865, -9.399999999999855, 5.299999999999965, 5.299999999999965, -5.19999999999993, 64.70000000000005, 15.799999999999963, 9.499999999999964, -15.699999999999747, 15.799999999999963, 11.599999999999964, -9.399999999999855, 5.299999999999967, 15.799999999999963, 106.39999999999944, -16.899999999999743, 20.000000000000014, -2.2, -43.59999999999977, 20.000000000000014, 5.299999999999965, 1.0999999999999865, 3.1999999999999615, -146.2000000000006, 17.899999999999988, 15.799999999999963, 17.899999999999988, -0.9999999999999917, 3.1999999999999615, 15.799999999999963, 20.000000000000014, -51.399999999999764, 20.000000000000014, -17.79999999999974, 20.000000000000014, 20.000000000000014, -0.9999999999999846, 114.50000000000006, 21.80000000000004, 11.599999999999964, -19.899999999999743, 69.19999999999999, 20.000000000000014, 9.499999999999964, 20.300000000000022, 20.000000000000014, 3.1999999999999615, -9.399999999999855, 13.699999999999964, 13.699999999999964, 20.000000000000014, 20.000000000000014, -218.80000000000044, 5.299999999999965, -9.399999999999855, 20.000000000000014, -40.89999999999976, 108.19999999999976, 13.399999999999965, -280.30000000000024, 20.000000000000014, -240.40000000000023, -177.40000000000043, 28.100000000000147, 17.899999999999984, 31.700000000000173, 71.8999999999998, -3.099999999999972, 1.0999999999999865, 27.20000000000013, -19.899999999999743, 123.49999999999972, 3.1999999999999615, 20.000000000000014, 3.1999999999999615, -301.29999999999893, -21.999999999999744, 13.699999999999964, -7.299999999999891], "policy_predator_policy_reward": [0.0, 13.0, 83.0, 106.0, 9.0, 11.0, 62.0, 4.0, 4.0, 86.0, 17.0, 7.0, 16.0, 2.0, 27.0, 8.0, 10.0, 18.0, 4.0, 4.0, 5.0, 15.0, 1.0, 3.0, 5.0, 4.0, 2.0, 1.0, 17.0, 5.0, 13.0, 8.0, 5.0, 0.0, 4.0, 4.0, 23.0, 6.0, 9.0, 5.0, 2.0, 14.0, 11.0, 12.0, 13.0, 8.0, 3.0, 3.0, 24.0, 6.0, 6.0, 11.0, 2.0, 16.0, 18.0, 6.0, 7.0, 12.0, 8.0, 26.0, 113.0, 12.0, 4.0, 0.0, 4.0, 2.0, 15.0, 2.0, 3.0, 19.0, 9.0, 12.0, 16.0, 1.0, 7.0, 6.0, 80.0, 7.0, 4.0, 1.0, 3.0, 5.0, 11.0, 7.0, 4.0, 3.0, 31.0, 39.0, 15.0, 21.0, 13.0, 4.0, 36.0, 38.0, 9.0, 3.0, 8.0, 5.0, 54.0, 11.0, 9.0, 13.0, 3.0, 2.0, 10.0, 3.0, 0.0, 5.0, 12.0, 22.0, 10.0, 11.0, 0.0, 6.0, 7.0, 8.0, 1.0, 10.0, 6.0, 17.0, 1.0, 9.0, 13.0, 9.0, 5.0, 12.0, 0.0, 7.0, 5.0, 17.0, 4.0, 2.0, 7.0, 14.0, 2.0, 1.0, 18.0, 10.0, 23.0, 17.0, 7.0, 6.0, 9.0, 6.0, 72.0, 12.0, 2.0, 3.0, 6.0, 11.0, 0.0, 2.0, 33.0, 13.0, 5.0, 18.0, 10.0, 0.0, 6.0, 1.0, 19.0, 4.0, 4.0, 0.0, 2.0, 5.0, 0.0, 8.0, 3.0, 14.0, 3.0, 0.0, 0.0, 115.0, 14.0, 12.0, 7.0, 29.0, 0.0, 4.0, 75.0, 143.0, 161.0, 3.0, 7.0, 7.0, 8.0, 1.0, 14.0, 10.0, 19.0, 6.0, 3.0, 8.0, 7.0, 8.0, 20.0, 153.0, 12.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5847722375385541, "mean_inference_ms": 1.8093664088161268, "mean_action_processing_ms": 0.25116249975998983, "mean_env_wait_ms": 0.19569980611519655, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003598809242248535, "StateBufferConnector_ms": 0.003029465675354004, "ViewRequirementAgentConnector_ms": 0.09277546405792236}, "num_episodes": 22, "episode_return_max": 143.29999999999976, "episode_return_min": -253.8000000000007, "episode_return_mean": 27.050000000000022, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2784000, "num_agent_steps_trained": 2784000, "num_env_steps_sampled": 696000, "num_env_steps_trained": 696000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 381.414501926065, "num_env_steps_trained_throughput_per_sec": 381.414501926065, "timesteps_total": 696000, "num_env_steps_sampled_lifetime": 696000, "num_agent_steps_sampled_lifetime": 2784000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2784000, "timers": {"training_iteration_time_ms": 11020.202, "restore_workers_time_ms": 0.015, "training_step_time_ms": 11020.132, "sample_time_ms": 1301.251, "learn_time_ms": 9700.312, "learn_throughput": 412.358, "synch_weights_time_ms": 16.422}, "counters": {"num_env_steps_sampled": 696000, "num_env_steps_trained": 696000, "num_agent_steps_sampled": 2784000, "num_agent_steps_trained": 2784000}, "done": false, "training_iteration": 174, "trial_id": "3dae5_00000", "date": "2024-08-14_09-38-55", "timestamp": 1723642735, "time_this_iter_s": 10.511307716369629, "time_total_s": 3552.2877852916718, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b38f88b0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3552.2877852916718, "iterations_since_restore": 174, "perf": {"cpu_util_percent": 27.600000000000005, "ram_util_percent": 83.68666666666667}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.56219566095443, "cur_kl_coeff": 0.00026396960020065314, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.8258118096009764, "policy_loss": -0.003955971227870101, "vf_loss": 0.8297544605517514, "vf_explained_var": 0.14900371640447585, "kl": 0.05046131484906209, "entropy": 1.0584098544385698, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 329805.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.956789687622792, "cur_kl_coeff": 0.02669677734374999, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.2315119040075433, "policy_loss": -0.006646670837068645, "vf_loss": 2.2379190696610345, "vf_explained_var": 0.1366520051602964, "kl": 0.008971257136132749, "entropy": 0.8798319491129073, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 329805.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 700000, "num_env_steps_trained": 700000, "num_agent_steps_sampled": 2800000, "num_agent_steps_trained": 2800000}, "env_runners": {"episode_reward_max": 207.99999999999932, "episode_reward_min": -502.2, "episode_reward_mean": 26.910000000000032, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 182.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -1.2099999999999966, "predator_policy": 14.665}, "custom_metrics": {}, "hist_stats": {"episode_reward": [14.399999999999919, 35.10000000000023, 41.30000000000034, 37.80000000000027, 27.400000000000098, 39.700000000000294, 6.999999999999922, 69.30000000000003, 23.200000000000028, 26.20000000000008, 19.100000000000005, 19.399999999999963, -76.50000000000077, 36.50000000000025, 33.4000000000002, -3.8999999999996886, 22.10000000000001, 23.20000000000003, 27.000000000000092, 25.700000000000067, -53.599999999999625, 36.60000000000025, 37.50000000000026, 18.099999999999998, 103.39999999999966, -30.699999999999534, 31.90000000000019, 86.39999999999964, 34.200000000000216, 33.1000000000002, 75.79999999999959, -29.399999999999523, 29.300000000000143, 81.90000000000009, 25.700000000000067, 34.50000000000022, 54.80000000000048, 69.40000000000008, 37.90000000000027, 38.20000000000027, 27.900000000000105, 21.90000000000004, 31.100000000000165, 17.900000000000002, 17.099999999999998, 87.4999999999993, 15.79999999999999, 33.4000000000002, 16.899999999999995, 125.19999999999871, 31.100000000000176, -5.799999999999711, 38.300000000000274, 19.300000000000008, -44.29999999999978, 38.70000000000028, 19.199999999999992, 37.80000000000027, 14.599999999999945, 25.200000000000063, 29.000000000000128, 143.29999999999976, 14.700000000000008, 93.19999999999996, 36.80000000000025, 31.200000000000166, 21.299999999999997, 36.70000000000025, -83.7999999999999, 21.900000000000002, 15.099999999999929, 125.59999999999928, -42.299999999999756, -253.8000000000007, 60.00000000000052, 112.59999999999897, 22.000000000000004, 32.30000000000019, 137.69999999999916, 38.20000000000027, -150.3000000000011, 30.40000000000015, 38.90000000000028, 29.800000000000143, 29.000000000000124, 108.29999999999964, 31.000000000000163, -502.2, 207.99999999999932, 25.500000000000068, -23.899999999999572, 174.69999999999948, 127.8999999999997, 14.099999999999989, 37.40000000000026, 40.90000000000031, 26.700000000000085, 35.40000000000023, 49.80000000000048, 36.70000000000025], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-34.59999999999977, 20.000000000000014, 20.000000000000014, 1.0999999999999865, 15.799999999999963, 9.499999999999977, 20.000000000000014, -5.1999999999999265, -9.399999999999855, 15.799999999999963, 20.000000000000014, 13.699999999999964, -30.39999999999977, 7.399999999999965, -7.299999999999891, 59.600000000000065, 20.000000000000014, -14.799999999999764, 7.39999999999997, -5.1999999999999265, -5.1999999999999265, 5.299999999999965, 20.000000000000014, -34.59999999999975, 20.000000000000014, -221.50000000000048, 11.599999999999964, 20.90000000000003, 11.599999999999964, 15.799999999999963, -11.499999999999819, -9.399999999999855, 20.000000000000014, -19.899999999999743, -3.099999999999972, 5.299999999999965, 8.899999999999956, 1.0999999999999528, -3.099999999999965, 15.799999999999963, 13.699999999999964, -154.3000000000006, 11.599999999999964, 20.000000000000014, 9.499999999999964, 20.000000000000014, -7.299999999999894, 7.399999999999965, 84.80000000000001, 11.599999999999964, -61.900000000000766, -38.79999999999976, 20.000000000000014, -24.099999999999746, 49.40000000000009, 20.000000000000014, -59.80000000000062, 20.000000000000014, 1.0999999999999865, 20.000000000000014, 59.60000000000019, 3.1999999999999615, -93.40000000000083, -0.9999999999999846, 1.0999999999999865, 6.199999999999973, 13.699999999999964, 63.20000000000005, 13.699999999999964, -0.9999999999999846, 20.000000000000014, 9.499999999999964, 17.59999999999998, 3.1999999999999615, 27.50000000000015, 20.90000000000003, 24.50000000000008, 7.399999999999965, 3.1999999999999615, 20.000000000000014, -0.9999999999999846, 17.899999999999988, -15.699999999999818, 14.599999999999968, 20.000000000000014, 1.0999999999999865, -9.399999999999855, 5.299999999999965, 5.299999999999965, -5.19999999999993, 64.70000000000005, 15.799999999999963, 9.499999999999964, -15.699999999999747, 15.799999999999963, 11.599999999999964, -9.399999999999855, 5.299999999999967, 15.799999999999963, 106.39999999999944, -16.899999999999743, 20.000000000000014, -2.2, -43.59999999999977, 20.000000000000014, 5.299999999999965, 1.0999999999999865, 3.1999999999999615, -146.2000000000006, 17.899999999999988, 15.799999999999963, 17.899999999999988, -0.9999999999999917, 3.1999999999999615, 15.799999999999963, 20.000000000000014, -51.399999999999764, 20.000000000000014, -17.79999999999974, 20.000000000000014, 20.000000000000014, -0.9999999999999846, 114.50000000000006, 21.80000000000004, 11.599999999999964, -19.899999999999743, 69.19999999999999, 20.000000000000014, 9.499999999999964, 20.300000000000022, 20.000000000000014, 3.1999999999999615, -9.399999999999855, 13.699999999999964, 13.699999999999964, 20.000000000000014, 20.000000000000014, -218.80000000000044, 5.299999999999965, -9.399999999999855, 20.000000000000014, -40.89999999999976, 108.19999999999976, 13.399999999999965, -280.30000000000024, 20.000000000000014, -240.40000000000023, -177.40000000000043, 28.100000000000147, 17.899999999999984, 31.700000000000173, 71.8999999999998, -3.099999999999972, 1.0999999999999865, 27.20000000000013, -19.899999999999743, 123.49999999999972, 3.1999999999999615, 20.000000000000014, 3.1999999999999615, -301.29999999999893, -21.999999999999744, 13.699999999999964, -7.299999999999891, 17.899999999999988, 20.000000000000014, 20.000000000000014, -5.1999999999999265, 3.1999999999999615, 15.799999999999963, 14.599999999999964, 88.6999999999999, -0.9999999999999846, 20.000000000000014, -400.0, -341.2, 182.0, 20.000000000000014, 20.000000000000014, -11.499999999999819, -47.79999999999979, -66.10000000000034, 155.0, 13.699999999999964, -19.899999999999743, 120.79999999999993, 20.000000000000014, -40.89999999999976, -13.599999999999783, 20.000000000000014, 9.499999999999964, 25.400000000000098, 11.599999999999964, 1.0999999999999865, 20.000000000000014, 7.399999999999965, -5.1999999999999265, 7.999999999999973, 15.799999999999963, 17.899999999999988], "policy_predator_policy_reward": [23.0, 6.0, 9.0, 5.0, 2.0, 14.0, 11.0, 12.0, 13.0, 8.0, 3.0, 3.0, 24.0, 6.0, 6.0, 11.0, 2.0, 16.0, 18.0, 6.0, 7.0, 12.0, 8.0, 26.0, 113.0, 12.0, 4.0, 0.0, 4.0, 2.0, 15.0, 2.0, 3.0, 19.0, 9.0, 12.0, 16.0, 1.0, 7.0, 6.0, 80.0, 7.0, 4.0, 1.0, 3.0, 5.0, 11.0, 7.0, 4.0, 3.0, 31.0, 39.0, 15.0, 21.0, 13.0, 4.0, 36.0, 38.0, 9.0, 3.0, 8.0, 5.0, 54.0, 11.0, 9.0, 13.0, 3.0, 2.0, 10.0, 3.0, 0.0, 5.0, 12.0, 22.0, 10.0, 11.0, 0.0, 6.0, 7.0, 8.0, 1.0, 10.0, 6.0, 17.0, 1.0, 9.0, 13.0, 9.0, 5.0, 12.0, 0.0, 7.0, 5.0, 17.0, 4.0, 2.0, 7.0, 14.0, 2.0, 1.0, 18.0, 10.0, 23.0, 17.0, 7.0, 6.0, 9.0, 6.0, 72.0, 12.0, 2.0, 3.0, 6.0, 11.0, 0.0, 2.0, 33.0, 13.0, 5.0, 18.0, 10.0, 0.0, 6.0, 1.0, 19.0, 4.0, 4.0, 0.0, 2.0, 5.0, 0.0, 8.0, 3.0, 14.0, 3.0, 0.0, 0.0, 115.0, 14.0, 12.0, 7.0, 29.0, 0.0, 4.0, 75.0, 143.0, 161.0, 3.0, 7.0, 7.0, 8.0, 1.0, 14.0, 10.0, 19.0, 6.0, 3.0, 8.0, 7.0, 8.0, 20.0, 153.0, 12.0, 12.0, 0.0, 1.0, 12.0, 3.0, 8.0, 2.0, 3.0, 2.0, 4.0, 8.0, 200.0, 39.0, 0.0, 6.0, 2.0, 15.0, 36.0, 54.0, 3.0, 3.0, 19.0, 8.0, 6.0, 29.0, 15.0, 16.0, 5.0, 1.0, 10.0, 4.0, 2.0, 6.0, 22.0, 25.0, 2.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5846431819815918, "mean_inference_ms": 1.8091133053871413, "mean_action_processing_ms": 0.25106112067529296, "mean_env_wait_ms": 0.19564725389811977, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003603339195251465, "StateBufferConnector_ms": 0.003015279769897461, "ViewRequirementAgentConnector_ms": 0.09217166900634766}, "num_episodes": 18, "episode_return_max": 207.99999999999932, "episode_return_min": -502.2, "episode_return_mean": 26.910000000000032, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2800000, "num_agent_steps_trained": 2800000, "num_env_steps_sampled": 700000, "num_env_steps_trained": 700000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 376.84111705257214, "num_env_steps_trained_throughput_per_sec": 376.84111705257214, "timesteps_total": 700000, "num_env_steps_sampled_lifetime": 700000, "num_agent_steps_sampled_lifetime": 2800000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2800000, "timers": {"training_iteration_time_ms": 10982.769, "restore_workers_time_ms": 0.015, "training_step_time_ms": 10982.698, "sample_time_ms": 1303.324, "learn_time_ms": 9660.99, "learn_throughput": 414.036, "synch_weights_time_ms": 16.224}, "counters": {"num_env_steps_sampled": 700000, "num_env_steps_trained": 700000, "num_agent_steps_sampled": 2800000, "num_agent_steps_trained": 2800000}, "done": false, "training_iteration": 175, "trial_id": "3dae5_00000", "date": "2024-08-14_09-39-06", "timestamp": 1723642746, "time_this_iter_s": 10.61948299407959, "time_total_s": 3562.9072682857513, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b38ef5e0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3562.9072682857513, "iterations_since_restore": 175, "perf": {"cpu_util_percent": 29.82, "ram_util_percent": 83.44666666666667}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4006798289755664, "cur_kl_coeff": 0.0003959544003009795, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.7175514967195571, "policy_loss": -0.002558984097448133, "vf_loss": 0.7201029941597313, "vf_explained_var": 0.2278065749892482, "kl": 0.018904637894131004, "entropy": 1.1245198371233764, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 331695.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.3361377615461905, "cur_kl_coeff": 0.02669677734374999, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.9070576675354487, "policy_loss": -0.004448267364647811, "vf_loss": 2.9113712823580182, "vf_explained_var": 0.3189978595763918, "kl": 0.00504365197782459, "entropy": 0.8365445086880335, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 331695.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 704000, "num_env_steps_trained": 704000, "num_agent_steps_sampled": 2816000, "num_agent_steps_trained": 2816000}, "env_runners": {"episode_reward_max": 207.99999999999932, "episode_reward_min": -502.2, "episode_reward_mean": 31.730999999999984, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 182.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -0.26950000000000274, "predator_policy": 16.135}, "custom_metrics": {}, "hist_stats": {"episode_reward": [27.000000000000092, 25.700000000000067, -53.599999999999625, 36.60000000000025, 37.50000000000026, 18.099999999999998, 103.39999999999966, -30.699999999999534, 31.90000000000019, 86.39999999999964, 34.200000000000216, 33.1000000000002, 75.79999999999959, -29.399999999999523, 29.300000000000143, 81.90000000000009, 25.700000000000067, 34.50000000000022, 54.80000000000048, 69.40000000000008, 37.90000000000027, 38.20000000000027, 27.900000000000105, 21.90000000000004, 31.100000000000165, 17.900000000000002, 17.099999999999998, 87.4999999999993, 15.79999999999999, 33.4000000000002, 16.899999999999995, 125.19999999999871, 31.100000000000176, -5.799999999999711, 38.300000000000274, 19.300000000000008, -44.29999999999978, 38.70000000000028, 19.199999999999992, 37.80000000000027, 14.599999999999945, 25.200000000000063, 29.000000000000128, 143.29999999999976, 14.700000000000008, 93.19999999999996, 36.80000000000025, 31.200000000000166, 21.299999999999997, 36.70000000000025, -83.7999999999999, 21.900000000000002, 15.099999999999929, 125.59999999999928, -42.299999999999756, -253.8000000000007, 60.00000000000052, 112.59999999999897, 22.000000000000004, 32.30000000000019, 137.69999999999916, 38.20000000000027, -150.3000000000011, 30.40000000000015, 38.90000000000028, 29.800000000000143, 29.000000000000124, 108.29999999999964, 31.000000000000163, -502.2, 207.99999999999932, 25.500000000000068, -23.899999999999572, 174.69999999999948, 127.8999999999997, 14.099999999999989, 37.40000000000026, 40.90000000000031, 26.700000000000085, 35.40000000000023, 49.80000000000048, 36.70000000000025, -85.09999999999988, 16.900000000000002, -200.9000000000009, 26.800000000000097, 37.80000000000027, 173.3999999999993, 30.400000000000155, 31.400000000000176, 24.60000000000005, 143.09999999999962, 31.90000000000018, 175.79999999999916, 107.999999999999, 24.600000000000048, 125.19999999999919, 45.39999999999999, 37.30000000000026, 130.1999999999997], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [8.899999999999956, 1.0999999999999528, -3.099999999999965, 15.799999999999963, 13.699999999999964, -154.3000000000006, 11.599999999999964, 20.000000000000014, 9.499999999999964, 20.000000000000014, -7.299999999999894, 7.399999999999965, 84.80000000000001, 11.599999999999964, -61.900000000000766, -38.79999999999976, 20.000000000000014, -24.099999999999746, 49.40000000000009, 20.000000000000014, -59.80000000000062, 20.000000000000014, 1.0999999999999865, 20.000000000000014, 59.60000000000019, 3.1999999999999615, -93.40000000000083, -0.9999999999999846, 1.0999999999999865, 6.199999999999973, 13.699999999999964, 63.20000000000005, 13.699999999999964, -0.9999999999999846, 20.000000000000014, 9.499999999999964, 17.59999999999998, 3.1999999999999615, 27.50000000000015, 20.90000000000003, 24.50000000000008, 7.399999999999965, 3.1999999999999615, 20.000000000000014, -0.9999999999999846, 17.899999999999988, -15.699999999999818, 14.599999999999968, 20.000000000000014, 1.0999999999999865, -9.399999999999855, 5.299999999999965, 5.299999999999965, -5.19999999999993, 64.70000000000005, 15.799999999999963, 9.499999999999964, -15.699999999999747, 15.799999999999963, 11.599999999999964, -9.399999999999855, 5.299999999999967, 15.799999999999963, 106.39999999999944, -16.899999999999743, 20.000000000000014, -2.2, -43.59999999999977, 20.000000000000014, 5.299999999999965, 1.0999999999999865, 3.1999999999999615, -146.2000000000006, 17.899999999999988, 15.799999999999963, 17.899999999999988, -0.9999999999999917, 3.1999999999999615, 15.799999999999963, 20.000000000000014, -51.399999999999764, 20.000000000000014, -17.79999999999974, 20.000000000000014, 20.000000000000014, -0.9999999999999846, 114.50000000000006, 21.80000000000004, 11.599999999999964, -19.899999999999743, 69.19999999999999, 20.000000000000014, 9.499999999999964, 20.300000000000022, 20.000000000000014, 3.1999999999999615, -9.399999999999855, 13.699999999999964, 13.699999999999964, 20.000000000000014, 20.000000000000014, -218.80000000000044, 5.299999999999965, -9.399999999999855, 20.000000000000014, -40.89999999999976, 108.19999999999976, 13.399999999999965, -280.30000000000024, 20.000000000000014, -240.40000000000023, -177.40000000000043, 28.100000000000147, 17.899999999999984, 31.700000000000173, 71.8999999999998, -3.099999999999972, 1.0999999999999865, 27.20000000000013, -19.899999999999743, 123.49999999999972, 3.1999999999999615, 20.000000000000014, 3.1999999999999615, -301.29999999999893, -21.999999999999744, 13.699999999999964, -7.299999999999891, 17.899999999999988, 20.000000000000014, 20.000000000000014, -5.1999999999999265, 3.1999999999999615, 15.799999999999963, 14.599999999999964, 88.6999999999999, -0.9999999999999846, 20.000000000000014, -400.0, -341.2, 182.0, 20.000000000000014, 20.000000000000014, -11.499999999999819, -47.79999999999979, -66.10000000000034, 155.0, 13.699999999999964, -19.899999999999743, 120.79999999999993, 20.000000000000014, -40.89999999999976, -13.599999999999783, 20.000000000000014, 9.499999999999964, 25.400000000000098, 11.599999999999964, 1.0999999999999865, 20.000000000000014, 7.399999999999965, -5.1999999999999265, 7.999999999999973, 15.799999999999963, 17.899999999999988, -222.70000000000036, 11.599999999999964, -3.099999999999958, -0.9999999999999846, -28.299999999999756, -391.5999999999999, -26.199999999999747, 20.000000000000014, 20.000000000000014, 15.799999999999963, 154.0999999999999, 5.299999999999965, 1.0999999999999865, 5.299999999999967, 20.000000000000014, -13.599999999999783, -9.399999999999855, 20.000000000000014, 9.499999999999964, 104.60000000000007, 20.000000000000014, -3.099999999999958, -9.399999999999855, 162.19999999999982, 15.799999999999963, 90.19999999999955, -3.099999999999958, 13.699999999999964, -26.199999999999747, 112.3999999999997, -4.599999999999984, -40.0, 18.799999999999997, 9.499999999999964, -24.099999999999746, 113.29999999999998], "policy_predator_policy_reward": [16.0, 1.0, 7.0, 6.0, 80.0, 7.0, 4.0, 1.0, 3.0, 5.0, 11.0, 7.0, 4.0, 3.0, 31.0, 39.0, 15.0, 21.0, 13.0, 4.0, 36.0, 38.0, 9.0, 3.0, 8.0, 5.0, 54.0, 11.0, 9.0, 13.0, 3.0, 2.0, 10.0, 3.0, 0.0, 5.0, 12.0, 22.0, 10.0, 11.0, 0.0, 6.0, 7.0, 8.0, 1.0, 10.0, 6.0, 17.0, 1.0, 9.0, 13.0, 9.0, 5.0, 12.0, 0.0, 7.0, 5.0, 17.0, 4.0, 2.0, 7.0, 14.0, 2.0, 1.0, 18.0, 10.0, 23.0, 17.0, 7.0, 6.0, 9.0, 6.0, 72.0, 12.0, 2.0, 3.0, 6.0, 11.0, 0.0, 2.0, 33.0, 13.0, 5.0, 18.0, 10.0, 0.0, 6.0, 1.0, 19.0, 4.0, 4.0, 0.0, 2.0, 5.0, 0.0, 8.0, 3.0, 14.0, 3.0, 0.0, 0.0, 115.0, 14.0, 12.0, 7.0, 29.0, 0.0, 4.0, 75.0, 143.0, 161.0, 3.0, 7.0, 7.0, 8.0, 1.0, 14.0, 10.0, 19.0, 6.0, 3.0, 8.0, 7.0, 8.0, 20.0, 153.0, 12.0, 12.0, 0.0, 1.0, 12.0, 3.0, 8.0, 2.0, 3.0, 2.0, 4.0, 8.0, 200.0, 39.0, 0.0, 6.0, 2.0, 15.0, 36.0, 54.0, 3.0, 3.0, 19.0, 8.0, 6.0, 29.0, 15.0, 16.0, 5.0, 1.0, 10.0, 4.0, 2.0, 6.0, 22.0, 25.0, 2.0, 1.0, 4.0, 122.0, 10.0, 11.0, 196.0, 23.0, 22.0, 11.0, 2.0, 0.0, 7.0, 7.0, 11.0, 13.0, 9.0, 16.0, 14.0, 0.0, 18.0, 11.0, 5.0, 10.0, 11.0, 12.0, 0.0, 2.0, 4.0, 10.0, 22.0, 17.0, 7.0, 83.0, 4.0, 5.0, 21.0, 20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5845144490102833, "mean_inference_ms": 1.8089627371563444, "mean_action_processing_ms": 0.2509573026392755, "mean_env_wait_ms": 0.19558588097157303, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0035812854766845703, "StateBufferConnector_ms": 0.0029747486114501953, "ViewRequirementAgentConnector_ms": 0.09217321872711182}, "num_episodes": 18, "episode_return_max": 207.99999999999932, "episode_return_min": -502.2, "episode_return_mean": 31.730999999999984, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2816000, "num_agent_steps_trained": 2816000, "num_env_steps_sampled": 704000, "num_env_steps_trained": 704000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 376.96285764949505, "num_env_steps_trained_throughput_per_sec": 376.96285764949505, "timesteps_total": 704000, "num_env_steps_sampled_lifetime": 704000, "num_agent_steps_sampled_lifetime": 2816000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2816000, "timers": {"training_iteration_time_ms": 10930.311, "restore_workers_time_ms": 0.015, "training_step_time_ms": 10930.239, "sample_time_ms": 1303.918, "learn_time_ms": 9610.011, "learn_throughput": 416.233, "synch_weights_time_ms": 14.319}, "counters": {"num_env_steps_sampled": 704000, "num_env_steps_trained": 704000, "num_agent_steps_sampled": 2816000, "num_agent_steps_trained": 2816000}, "done": false, "training_iteration": 176, "trial_id": "3dae5_00000", "date": "2024-08-14_09-39-17", "timestamp": 1723642757, "time_this_iter_s": 10.628642082214355, "time_total_s": 3573.5359103679657, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b38ef040>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3573.5359103679657, "iterations_since_restore": 176, "perf": {"cpu_util_percent": 28.52, "ram_util_percent": 83.50666666666667}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.341155934365338, "cur_kl_coeff": 0.0003959544003009795, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.8343280475606363, "policy_loss": -0.0017752565524821716, "vf_loss": 0.8361006703878205, "vf_explained_var": 0.24205498657529317, "kl": 0.006649067860575452, "entropy": 0.9495578091611308, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 333585.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.186508135237391, "cur_kl_coeff": 0.02669677734374999, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.0430354803012163, "policy_loss": -0.003497182957892104, "vf_loss": 2.0463299152396974, "vf_explained_var": 0.12115547398410777, "kl": 0.007594277513369652, "entropy": 0.8978027210349129, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 333585.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 708000, "num_env_steps_trained": 708000, "num_agent_steps_sampled": 2832000, "num_agent_steps_trained": 2832000}, "env_runners": {"episode_reward_max": 290.5999999999999, "episode_reward_min": -502.2, "episode_reward_mean": 41.200999999999915, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 182.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 4.650500000000006, "predator_policy": 15.95}, "custom_metrics": {}, "hist_stats": {"episode_reward": [54.80000000000048, 69.40000000000008, 37.90000000000027, 38.20000000000027, 27.900000000000105, 21.90000000000004, 31.100000000000165, 17.900000000000002, 17.099999999999998, 87.4999999999993, 15.79999999999999, 33.4000000000002, 16.899999999999995, 125.19999999999871, 31.100000000000176, -5.799999999999711, 38.300000000000274, 19.300000000000008, -44.29999999999978, 38.70000000000028, 19.199999999999992, 37.80000000000027, 14.599999999999945, 25.200000000000063, 29.000000000000128, 143.29999999999976, 14.700000000000008, 93.19999999999996, 36.80000000000025, 31.200000000000166, 21.299999999999997, 36.70000000000025, -83.7999999999999, 21.900000000000002, 15.099999999999929, 125.59999999999928, -42.299999999999756, -253.8000000000007, 60.00000000000052, 112.59999999999897, 22.000000000000004, 32.30000000000019, 137.69999999999916, 38.20000000000027, -150.3000000000011, 30.40000000000015, 38.90000000000028, 29.800000000000143, 29.000000000000124, 108.29999999999964, 31.000000000000163, -502.2, 207.99999999999932, 25.500000000000068, -23.899999999999572, 174.69999999999948, 127.8999999999997, 14.099999999999989, 37.40000000000026, 40.90000000000031, 26.700000000000085, 35.40000000000023, 49.80000000000048, 36.70000000000025, -85.09999999999988, 16.900000000000002, -200.9000000000009, 26.800000000000097, 37.80000000000027, 173.3999999999993, 30.400000000000155, 31.400000000000176, 24.60000000000005, 143.09999999999962, 31.90000000000018, 175.79999999999916, 107.999999999999, 24.600000000000048, 125.19999999999919, 45.39999999999999, 37.30000000000026, 130.1999999999997, 16.900000000000002, 113.29999999999922, 36.70000000000025, 30.100000000000147, 19.099999999999998, 158.29999999999927, 38.00000000000027, 38.00000000000027, 37.40000000000026, 154.0999999999992, 174.79999999999936, 2.6000000000002084, 181.9999999999992, 35.600000000000236, 290.5999999999999, 164.89999999999952, 177.9999999999995, -156.0000000000008], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [17.59999999999998, 3.1999999999999615, 27.50000000000015, 20.90000000000003, 24.50000000000008, 7.399999999999965, 3.1999999999999615, 20.000000000000014, -0.9999999999999846, 17.899999999999988, -15.699999999999818, 14.599999999999968, 20.000000000000014, 1.0999999999999865, -9.399999999999855, 5.299999999999965, 5.299999999999965, -5.19999999999993, 64.70000000000005, 15.799999999999963, 9.499999999999964, -15.699999999999747, 15.799999999999963, 11.599999999999964, -9.399999999999855, 5.299999999999967, 15.799999999999963, 106.39999999999944, -16.899999999999743, 20.000000000000014, -2.2, -43.59999999999977, 20.000000000000014, 5.299999999999965, 1.0999999999999865, 3.1999999999999615, -146.2000000000006, 17.899999999999988, 15.799999999999963, 17.899999999999988, -0.9999999999999917, 3.1999999999999615, 15.799999999999963, 20.000000000000014, -51.399999999999764, 20.000000000000014, -17.79999999999974, 20.000000000000014, 20.000000000000014, -0.9999999999999846, 114.50000000000006, 21.80000000000004, 11.599999999999964, -19.899999999999743, 69.19999999999999, 20.000000000000014, 9.499999999999964, 20.300000000000022, 20.000000000000014, 3.1999999999999615, -9.399999999999855, 13.699999999999964, 13.699999999999964, 20.000000000000014, 20.000000000000014, -218.80000000000044, 5.299999999999965, -9.399999999999855, 20.000000000000014, -40.89999999999976, 108.19999999999976, 13.399999999999965, -280.30000000000024, 20.000000000000014, -240.40000000000023, -177.40000000000043, 28.100000000000147, 17.899999999999984, 31.700000000000173, 71.8999999999998, -3.099999999999972, 1.0999999999999865, 27.20000000000013, -19.899999999999743, 123.49999999999972, 3.1999999999999615, 20.000000000000014, 3.1999999999999615, -301.29999999999893, -21.999999999999744, 13.699999999999964, -7.299999999999891, 17.899999999999988, 20.000000000000014, 20.000000000000014, -5.1999999999999265, 3.1999999999999615, 15.799999999999963, 14.599999999999964, 88.6999999999999, -0.9999999999999846, 20.000000000000014, -400.0, -341.2, 182.0, 20.000000000000014, 20.000000000000014, -11.499999999999819, -47.79999999999979, -66.10000000000034, 155.0, 13.699999999999964, -19.899999999999743, 120.79999999999993, 20.000000000000014, -40.89999999999976, -13.599999999999783, 20.000000000000014, 9.499999999999964, 25.400000000000098, 11.599999999999964, 1.0999999999999865, 20.000000000000014, 7.399999999999965, -5.1999999999999265, 7.999999999999973, 15.799999999999963, 17.899999999999988, -222.70000000000036, 11.599999999999964, -3.099999999999958, -0.9999999999999846, -28.299999999999756, -391.5999999999999, -26.199999999999747, 20.000000000000014, 20.000000000000014, 15.799999999999963, 154.0999999999999, 5.299999999999965, 1.0999999999999865, 5.299999999999967, 20.000000000000014, -13.599999999999783, -9.399999999999855, 20.000000000000014, 9.499999999999964, 104.60000000000007, 20.000000000000014, -3.099999999999958, -9.399999999999855, 162.19999999999982, 15.799999999999963, 90.19999999999955, -3.099999999999958, 13.699999999999964, -26.199999999999747, 112.3999999999997, -4.599999999999984, -40.0, 18.799999999999997, 9.499999999999964, -24.099999999999746, 113.29999999999998, 1.0999999999999865, -5.1999999999999265, 56.90000000000003, 7.399999999999987, 20.000000000000014, 13.699999999999964, 1.0999999999999865, 20.000000000000014, -9.399999999999855, 9.499999999999964, 141.79999999999984, -8.499999999999872, 22.700000000000053, 5.299999999999965, 20.000000000000014, -0.9999999999999846, 20.000000000000014, 13.399999999999965, 7.399999999999965, 139.6999999999998, 1.0999999999999865, 157.69999999999993, -40.89999999999976, 9.499999999999964, 160.39999999999986, 11.599999999999964, 11.599999999999964, 20.000000000000014, 154.99999999999991, 128.6, 137.00000000000003, 17.899999999999988, 161.9, 1.0999999999999865, -345.0999999999998, 1.0999999999999865], "policy_predator_policy_reward": [12.0, 22.0, 10.0, 11.0, 0.0, 6.0, 7.0, 8.0, 1.0, 10.0, 6.0, 17.0, 1.0, 9.0, 13.0, 9.0, 5.0, 12.0, 0.0, 7.0, 5.0, 17.0, 4.0, 2.0, 7.0, 14.0, 2.0, 1.0, 18.0, 10.0, 23.0, 17.0, 7.0, 6.0, 9.0, 6.0, 72.0, 12.0, 2.0, 3.0, 6.0, 11.0, 0.0, 2.0, 33.0, 13.0, 5.0, 18.0, 10.0, 0.0, 6.0, 1.0, 19.0, 4.0, 4.0, 0.0, 2.0, 5.0, 0.0, 8.0, 3.0, 14.0, 3.0, 0.0, 0.0, 115.0, 14.0, 12.0, 7.0, 29.0, 0.0, 4.0, 75.0, 143.0, 161.0, 3.0, 7.0, 7.0, 8.0, 1.0, 14.0, 10.0, 19.0, 6.0, 3.0, 8.0, 7.0, 8.0, 20.0, 153.0, 12.0, 12.0, 0.0, 1.0, 12.0, 3.0, 8.0, 2.0, 3.0, 2.0, 4.0, 8.0, 200.0, 39.0, 0.0, 6.0, 2.0, 15.0, 36.0, 54.0, 3.0, 3.0, 19.0, 8.0, 6.0, 29.0, 15.0, 16.0, 5.0, 1.0, 10.0, 4.0, 2.0, 6.0, 22.0, 25.0, 2.0, 1.0, 4.0, 122.0, 10.0, 11.0, 196.0, 23.0, 22.0, 11.0, 2.0, 0.0, 7.0, 7.0, 11.0, 13.0, 9.0, 16.0, 14.0, 0.0, 18.0, 11.0, 5.0, 10.0, 11.0, 12.0, 0.0, 2.0, 4.0, 10.0, 22.0, 17.0, 7.0, 83.0, 4.0, 5.0, 21.0, 20.0, 9.0, 12.0, 1.0, 48.0, 3.0, 0.0, 0.0, 9.0, 14.0, 5.0, 11.0, 14.0, 3.0, 7.0, 9.0, 10.0, 4.0, 0.0, 6.0, 1.0, 9.0, 7.0, 29.0, 5.0, 4.0, 6.0, 4.0, 0.0, 4.0, 3.0, 9.0, 1.0, 9.0, 6.0, 179.0, 9.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5843345002840465, "mean_inference_ms": 1.8087047176328759, "mean_action_processing_ms": 0.2508391950139854, "mean_env_wait_ms": 0.19551910503859127, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0036046504974365234, "StateBufferConnector_ms": 0.002994060516357422, "ViewRequirementAgentConnector_ms": 0.09070074558258057}, "num_episodes": 18, "episode_return_max": 290.5999999999999, "episode_return_min": -502.2, "episode_return_mean": 41.200999999999915, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2832000, "num_agent_steps_trained": 2832000, "num_env_steps_sampled": 708000, "num_env_steps_trained": 708000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 360.79772927237065, "num_env_steps_trained_throughput_per_sec": 360.79772927237065, "timesteps_total": 708000, "num_env_steps_sampled_lifetime": 708000, "num_agent_steps_sampled_lifetime": 2832000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2832000, "timers": {"training_iteration_time_ms": 10941.582, "restore_workers_time_ms": 0.014, "training_step_time_ms": 10941.498, "sample_time_ms": 1300.925, "learn_time_ms": 9622.327, "learn_throughput": 415.7, "synch_weights_time_ms": 16.075}, "counters": {"num_env_steps_sampled": 708000, "num_env_steps_trained": 708000, "num_agent_steps_sampled": 2832000, "num_agent_steps_trained": 2832000}, "done": false, "training_iteration": 177, "trial_id": "3dae5_00000", "date": "2024-08-14_09-39-28", "timestamp": 1723642768, "time_this_iter_s": 11.123555183410645, "time_total_s": 3584.6594655513763, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b36d6ca0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3584.6594655513763, "iterations_since_restore": 177, "perf": {"cpu_util_percent": 29.912499999999998, "ram_util_percent": 83.3125}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.2111732708713996, "cur_kl_coeff": 0.0003959544003009795, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.127379633572997, "policy_loss": -0.0021197292350094627, "vf_loss": 2.1294877095197244, "vf_explained_var": 0.19211454044574153, "kl": 0.02943394554440741, "entropy": 0.8591638093902951, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 335475.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.549466133559192, "cur_kl_coeff": 0.02669677734374999, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.7894976690332727, "policy_loss": -0.01540306670192097, "vf_loss": 3.8043352588774666, "vf_explained_var": -0.1717866595775362, "kl": 0.0211813835569205, "entropy": 0.8981631197626628, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 335475.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 712000, "num_env_steps_trained": 712000, "num_agent_steps_sampled": 2848000, "num_agent_steps_trained": 2848000}, "env_runners": {"episode_reward_max": 290.5999999999999, "episode_reward_min": -502.2, "episode_reward_mean": 40.12999999999986, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 182.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 0.845000000000008, "predator_policy": 19.22}, "custom_metrics": {}, "hist_stats": {"episode_reward": [93.19999999999996, 36.80000000000025, 31.200000000000166, 21.299999999999997, 36.70000000000025, -83.7999999999999, 21.900000000000002, 15.099999999999929, 125.59999999999928, -42.299999999999756, -253.8000000000007, 60.00000000000052, 112.59999999999897, 22.000000000000004, 32.30000000000019, 137.69999999999916, 38.20000000000027, -150.3000000000011, 30.40000000000015, 38.90000000000028, 29.800000000000143, 29.000000000000124, 108.29999999999964, 31.000000000000163, -502.2, 207.99999999999932, 25.500000000000068, -23.899999999999572, 174.69999999999948, 127.8999999999997, 14.099999999999989, 37.40000000000026, 40.90000000000031, 26.700000000000085, 35.40000000000023, 49.80000000000048, 36.70000000000025, -85.09999999999988, 16.900000000000002, -200.9000000000009, 26.800000000000097, 37.80000000000027, 173.3999999999993, 30.400000000000155, 31.400000000000176, 24.60000000000005, 143.09999999999962, 31.90000000000018, 175.79999999999916, 107.999999999999, 24.600000000000048, 125.19999999999919, 45.39999999999999, 37.30000000000026, 130.1999999999997, 16.900000000000002, 113.29999999999922, 36.70000000000025, 30.100000000000147, 19.099999999999998, 158.29999999999927, 38.00000000000027, 38.00000000000027, 37.40000000000026, 154.0999999999992, 174.79999999999936, 2.6000000000002084, 181.9999999999992, 35.600000000000236, 290.5999999999999, 164.89999999999952, 177.9999999999995, -156.0000000000008, 19.09999999999996, 83.19999999999939, -123.90000000000046, 149.9999999999995, 98.7999999999991, 35.700000000000166, 27.900000000000105, 134.09999999999874, 29.00000000000014, 4.800000000000157, 85.80000000000003, 91.6999999999993, 37.50000000000026, 32.00000000000023, 45.600000000000385, 30.500000000000156, 102.89999999999947, -113.90000000000097, 24.900000000000063, -0.4000000000000601, -174.50000000000063, 6.800000000000114, 38.90000000000028, -41.39999999999988, 32.30000000000019, 43.70000000000035, 147.89999999999912], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [69.19999999999999, 20.000000000000014, 9.499999999999964, 20.300000000000022, 20.000000000000014, 3.1999999999999615, -9.399999999999855, 13.699999999999964, 13.699999999999964, 20.000000000000014, 20.000000000000014, -218.80000000000044, 5.299999999999965, -9.399999999999855, 20.000000000000014, -40.89999999999976, 108.19999999999976, 13.399999999999965, -280.30000000000024, 20.000000000000014, -240.40000000000023, -177.40000000000043, 28.100000000000147, 17.899999999999984, 31.700000000000173, 71.8999999999998, -3.099999999999972, 1.0999999999999865, 27.20000000000013, -19.899999999999743, 123.49999999999972, 3.1999999999999615, 20.000000000000014, 3.1999999999999615, -301.29999999999893, -21.999999999999744, 13.699999999999964, -7.299999999999891, 17.899999999999988, 20.000000000000014, 20.000000000000014, -5.1999999999999265, 3.1999999999999615, 15.799999999999963, 14.599999999999964, 88.6999999999999, -0.9999999999999846, 20.000000000000014, -400.0, -341.2, 182.0, 20.000000000000014, 20.000000000000014, -11.499999999999819, -47.79999999999979, -66.10000000000034, 155.0, 13.699999999999964, -19.899999999999743, 120.79999999999993, 20.000000000000014, -40.89999999999976, -13.599999999999783, 20.000000000000014, 9.499999999999964, 25.400000000000098, 11.599999999999964, 1.0999999999999865, 20.000000000000014, 7.399999999999965, -5.1999999999999265, 7.999999999999973, 15.799999999999963, 17.899999999999988, -222.70000000000036, 11.599999999999964, -3.099999999999958, -0.9999999999999846, -28.299999999999756, -391.5999999999999, -26.199999999999747, 20.000000000000014, 20.000000000000014, 15.799999999999963, 154.0999999999999, 5.299999999999965, 1.0999999999999865, 5.299999999999967, 20.000000000000014, -13.599999999999783, -9.399999999999855, 20.000000000000014, 9.499999999999964, 104.60000000000007, 20.000000000000014, -3.099999999999958, -9.399999999999855, 162.19999999999982, 15.799999999999963, 90.19999999999955, -3.099999999999958, 13.699999999999964, -26.199999999999747, 112.3999999999997, -4.599999999999984, -40.0, 18.799999999999997, 9.499999999999964, -24.099999999999746, 113.29999999999998, 1.0999999999999865, -5.1999999999999265, 56.90000000000003, 7.399999999999987, 20.000000000000014, 13.699999999999964, 1.0999999999999865, 20.000000000000014, -9.399999999999855, 9.499999999999964, 141.79999999999984, -8.499999999999872, 22.700000000000053, 5.299999999999965, 20.000000000000014, -0.9999999999999846, 20.000000000000014, 13.399999999999965, 7.399999999999965, 139.6999999999998, 1.0999999999999865, 157.69999999999993, -40.89999999999976, 9.499999999999964, 160.39999999999986, 11.599999999999964, 11.599999999999964, 20.000000000000014, 154.99999999999991, 128.6, 137.00000000000003, 17.899999999999988, 161.9, 1.0999999999999865, -345.0999999999998, 1.0999999999999865, -9.399999999999883, -11.499999999999819, 58.700000000000074, -11.499999999999822, 5.299999999999969, -278.20000000000016, 140.29999999999993, -7.299999999999891, 85.69999999999958, 4.09999999999999, 8.00000000000002, 16.69999999999997, 3.1999999999999615, 13.699999999999964, 15.799999999999963, 116.29999999999947, 5.299999999999965, 13.699999999999964, 20.000000000000014, -47.19999999999976, 64.40000000000009, 7.399999999999965, 99.19999999999968, -32.49999999999983, 9.499999999999964, 20.000000000000014, 20.000000000000014, -1.0000000000000355, 5.299999999999965, 26.300000000000114, -11.499999999999819, 20.000000000000014, 103.69999999999979, -38.799999999999756, 17.899999999999988, -275.7999999999997, 20.000000000000014, -24.099999999999746, -80.80000000000013, 25.400000000000098, 20.000000000000014, -389.5, 20.000000000000014, -47.19999999999976, 20.000000000000014, 17.899999999999988, 20.000000000000014, -321.39999999999947, 7.399999999999967, 17.899999999999988, 28.100000000000147, 11.599999999999964, 133.39999999999972, 9.499999999999964], "policy_predator_policy_reward": [4.0, 0.0, 2.0, 5.0, 0.0, 8.0, 3.0, 14.0, 3.0, 0.0, 0.0, 115.0, 14.0, 12.0, 7.0, 29.0, 0.0, 4.0, 75.0, 143.0, 161.0, 3.0, 7.0, 7.0, 8.0, 1.0, 14.0, 10.0, 19.0, 6.0, 3.0, 8.0, 7.0, 8.0, 20.0, 153.0, 12.0, 12.0, 0.0, 1.0, 12.0, 3.0, 8.0, 2.0, 3.0, 2.0, 4.0, 8.0, 200.0, 39.0, 0.0, 6.0, 2.0, 15.0, 36.0, 54.0, 3.0, 3.0, 19.0, 8.0, 6.0, 29.0, 15.0, 16.0, 5.0, 1.0, 10.0, 4.0, 2.0, 6.0, 22.0, 25.0, 2.0, 1.0, 4.0, 122.0, 10.0, 11.0, 196.0, 23.0, 22.0, 11.0, 2.0, 0.0, 7.0, 7.0, 11.0, 13.0, 9.0, 16.0, 14.0, 0.0, 18.0, 11.0, 5.0, 10.0, 11.0, 12.0, 0.0, 2.0, 4.0, 10.0, 22.0, 17.0, 7.0, 83.0, 4.0, 5.0, 21.0, 20.0, 9.0, 12.0, 1.0, 48.0, 3.0, 0.0, 0.0, 9.0, 14.0, 5.0, 11.0, 14.0, 3.0, 7.0, 9.0, 10.0, 4.0, 0.0, 6.0, 1.0, 9.0, 7.0, 29.0, 5.0, 4.0, 6.0, 4.0, 0.0, 4.0, 3.0, 9.0, 1.0, 9.0, 6.0, 179.0, 9.0, 21.0, 19.0, 15.0, 21.0, 0.0, 149.0, 13.0, 4.0, 8.0, 1.0, 2.0, 9.0, 3.0, 8.0, 0.0, 2.0, 3.0, 7.0, 0.0, 32.0, 8.0, 6.0, 14.0, 11.0, 3.0, 5.0, 3.0, 10.0, 7.0, 7.0, 7.0, 15.0, 10.0, 28.0, 1.0, 143.0, 8.0, 21.0, 9.0, 46.0, 190.0, 5.0, 2.0, 32.0, 1.0, 0.0, 158.0, 102.0, 1.0, 6.0, 0.0, 4.0, 5.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5847551756713036, "mean_inference_ms": 1.809816530236037, "mean_action_processing_ms": 0.2506333007148854, "mean_env_wait_ms": 0.19576712171436103, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0038014650344848633, "StateBufferConnector_ms": 0.007220149040222168, "ViewRequirementAgentConnector_ms": 0.11719262599945068}, "num_episodes": 27, "episode_return_max": 290.5999999999999, "episode_return_min": -502.2, "episode_return_mean": 40.12999999999986, "episodes_this_iter": 27}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2848000, "num_agent_steps_trained": 2848000, "num_env_steps_sampled": 712000, "num_env_steps_trained": 712000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 268.2781977591503, "num_env_steps_trained_throughput_per_sec": 268.2781977591503, "timesteps_total": 712000, "num_env_steps_sampled_lifetime": 712000, "num_agent_steps_sampled_lifetime": 2848000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2848000, "timers": {"training_iteration_time_ms": 11333.415, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11333.355, "sample_time_ms": 1384.536, "learn_time_ms": 9930.392, "learn_throughput": 402.804, "synch_weights_time_ms": 16.526}, "counters": {"num_env_steps_sampled": 712000, "num_env_steps_trained": 712000, "num_agent_steps_sampled": 2848000, "num_agent_steps_trained": 2848000}, "done": false, "training_iteration": 178, "trial_id": "3dae5_00000", "date": "2024-08-14_09-39-43", "timestamp": 1723642783, "time_this_iter_s": 14.966722249984741, "time_total_s": 3599.626187801361, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b38ef5e0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3599.626187801361, "iterations_since_restore": 178, "perf": {"cpu_util_percent": 60.74761904761906, "ram_util_percent": 80.04285714285713}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1769082673327633, "cur_kl_coeff": 0.0005939316004514694, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.2460845513318581, "policy_loss": -0.002997027708355475, "vf_loss": 1.249066726445521, "vf_explained_var": 0.3098893236861658, "kl": 0.025000990374047752, "entropy": 1.0133282305071594, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 337365.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9086248505683172, "cur_kl_coeff": 0.04004516601562501, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.0382043651172093, "policy_loss": -0.006805074546564981, "vf_loss": 2.04467821669957, "vf_explained_var": -0.21504066700027102, "kl": 0.008271234879852048, "entropy": 0.9260969406397885, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 337365.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 716000, "num_env_steps_trained": 716000, "num_agent_steps_sampled": 2864000, "num_agent_steps_trained": 2864000}, "env_runners": {"episode_reward_max": 290.5999999999999, "episode_reward_min": -502.2, "episode_reward_mean": 38.27299999999988, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 182.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 0.38150000000000317, "predator_policy": 18.755}, "custom_metrics": {}, "hist_stats": {"episode_reward": [30.40000000000015, 38.90000000000028, 29.800000000000143, 29.000000000000124, 108.29999999999964, 31.000000000000163, -502.2, 207.99999999999932, 25.500000000000068, -23.899999999999572, 174.69999999999948, 127.8999999999997, 14.099999999999989, 37.40000000000026, 40.90000000000031, 26.700000000000085, 35.40000000000023, 49.80000000000048, 36.70000000000025, -85.09999999999988, 16.900000000000002, -200.9000000000009, 26.800000000000097, 37.80000000000027, 173.3999999999993, 30.400000000000155, 31.400000000000176, 24.60000000000005, 143.09999999999962, 31.90000000000018, 175.79999999999916, 107.999999999999, 24.600000000000048, 125.19999999999919, 45.39999999999999, 37.30000000000026, 130.1999999999997, 16.900000000000002, 113.29999999999922, 36.70000000000025, 30.100000000000147, 19.099999999999998, 158.29999999999927, 38.00000000000027, 38.00000000000027, 37.40000000000026, 154.0999999999992, 174.79999999999936, 2.6000000000002084, 181.9999999999992, 35.600000000000236, 290.5999999999999, 164.89999999999952, 177.9999999999995, -156.0000000000008, 19.09999999999996, 83.19999999999939, -123.90000000000046, 149.9999999999995, 98.7999999999991, 35.700000000000166, 27.900000000000105, 134.09999999999874, 29.00000000000014, 4.800000000000157, 85.80000000000003, 91.6999999999993, 37.50000000000026, 32.00000000000023, 45.600000000000385, 30.500000000000156, 102.89999999999947, -113.90000000000097, 24.900000000000063, -0.4000000000000601, -174.50000000000063, 6.800000000000114, 38.90000000000028, -41.39999999999988, 32.30000000000019, 43.70000000000035, 147.89999999999912, -14.999999999999522, 37.80000000000027, 134.5999999999996, 35.600000000000236, 5.900000000000096, 170.0999999999995, 33.4000000000002, -179.00000000000065, 35.500000000000234, -233.00000000000057, 13.900000000000036, 29.000000000000128, 37.80000000000027, 30.90000000000016, 23.50000000000003, 17.999999999999968, -130.7000000000003, 20.399999999999995], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [13.699999999999964, -7.299999999999891, 17.899999999999988, 20.000000000000014, 20.000000000000014, -5.1999999999999265, 3.1999999999999615, 15.799999999999963, 14.599999999999964, 88.6999999999999, -0.9999999999999846, 20.000000000000014, -400.0, -341.2, 182.0, 20.000000000000014, 20.000000000000014, -11.499999999999819, -47.79999999999979, -66.10000000000034, 155.0, 13.699999999999964, -19.899999999999743, 120.79999999999993, 20.000000000000014, -40.89999999999976, -13.599999999999783, 20.000000000000014, 9.499999999999964, 25.400000000000098, 11.599999999999964, 1.0999999999999865, 20.000000000000014, 7.399999999999965, -5.1999999999999265, 7.999999999999973, 15.799999999999963, 17.899999999999988, -222.70000000000036, 11.599999999999964, -3.099999999999958, -0.9999999999999846, -28.299999999999756, -391.5999999999999, -26.199999999999747, 20.000000000000014, 20.000000000000014, 15.799999999999963, 154.0999999999999, 5.299999999999965, 1.0999999999999865, 5.299999999999967, 20.000000000000014, -13.599999999999783, -9.399999999999855, 20.000000000000014, 9.499999999999964, 104.60000000000007, 20.000000000000014, -3.099999999999958, -9.399999999999855, 162.19999999999982, 15.799999999999963, 90.19999999999955, -3.099999999999958, 13.699999999999964, -26.199999999999747, 112.3999999999997, -4.599999999999984, -40.0, 18.799999999999997, 9.499999999999964, -24.099999999999746, 113.29999999999998, 1.0999999999999865, -5.1999999999999265, 56.90000000000003, 7.399999999999987, 20.000000000000014, 13.699999999999964, 1.0999999999999865, 20.000000000000014, -9.399999999999855, 9.499999999999964, 141.79999999999984, -8.499999999999872, 22.700000000000053, 5.299999999999965, 20.000000000000014, -0.9999999999999846, 20.000000000000014, 13.399999999999965, 7.399999999999965, 139.6999999999998, 1.0999999999999865, 157.69999999999993, -40.89999999999976, 9.499999999999964, 160.39999999999986, 11.599999999999964, 11.599999999999964, 20.000000000000014, 154.99999999999991, 128.6, 137.00000000000003, 17.899999999999988, 161.9, 1.0999999999999865, -345.0999999999998, 1.0999999999999865, -9.399999999999883, -11.499999999999819, 58.700000000000074, -11.499999999999822, 5.299999999999969, -278.20000000000016, 140.29999999999993, -7.299999999999891, 85.69999999999958, 4.09999999999999, 8.00000000000002, 16.69999999999997, 3.1999999999999615, 13.699999999999964, 15.799999999999963, 116.29999999999947, 5.299999999999965, 13.699999999999964, 20.000000000000014, -47.19999999999976, 64.40000000000009, 7.399999999999965, 99.19999999999968, -32.49999999999983, 9.499999999999964, 20.000000000000014, 20.000000000000014, -1.0000000000000355, 5.299999999999965, 26.300000000000114, -11.499999999999819, 20.000000000000014, 103.69999999999979, -38.799999999999756, 17.899999999999988, -275.7999999999997, 20.000000000000014, -24.099999999999746, -80.80000000000013, 25.400000000000098, 20.000000000000014, -389.5, 20.000000000000014, -47.19999999999976, 20.000000000000014, 17.899999999999988, 20.000000000000014, -321.39999999999947, 7.399999999999967, 17.899999999999988, 28.100000000000147, 11.599999999999964, 133.39999999999972, 9.499999999999964, -11.499999999999819, -53.500000000000135, 15.799999999999963, 20.000000000000014, -3.099999999999958, 124.70000000000006, 11.599999999999964, 20.000000000000014, 20.000000000000014, -45.10000000000002, 20.000000000000014, 145.1, 9.499999999999964, 17.899999999999988, -400.0, 20.000000000000014, 17.899999999999988, 11.599999999999964, -213.40000000000012, -202.6000000000005, -11.499999999999819, 7.399999999999965, 20.000000000000014, -0.9999999999999846, 15.799999999999963, 20.000000000000014, 3.1999999999999615, 13.699999999999964, 9.499999999999964, -0.9999999999999846, -26.199999999999747, 3.199999999999967, 7.399999999999965, -303.10000000000014, -9.399999999999855, 15.799999999999963], "policy_predator_policy_reward": [12.0, 12.0, 0.0, 1.0, 12.0, 3.0, 8.0, 2.0, 3.0, 2.0, 4.0, 8.0, 200.0, 39.0, 0.0, 6.0, 2.0, 15.0, 36.0, 54.0, 3.0, 3.0, 19.0, 8.0, 6.0, 29.0, 15.0, 16.0, 5.0, 1.0, 10.0, 4.0, 2.0, 6.0, 22.0, 25.0, 2.0, 1.0, 4.0, 122.0, 10.0, 11.0, 196.0, 23.0, 22.0, 11.0, 2.0, 0.0, 7.0, 7.0, 11.0, 13.0, 9.0, 16.0, 14.0, 0.0, 18.0, 11.0, 5.0, 10.0, 11.0, 12.0, 0.0, 2.0, 4.0, 10.0, 22.0, 17.0, 7.0, 83.0, 4.0, 5.0, 21.0, 20.0, 9.0, 12.0, 1.0, 48.0, 3.0, 0.0, 0.0, 9.0, 14.0, 5.0, 11.0, 14.0, 3.0, 7.0, 9.0, 10.0, 4.0, 0.0, 6.0, 1.0, 9.0, 7.0, 29.0, 5.0, 4.0, 6.0, 4.0, 0.0, 4.0, 3.0, 9.0, 1.0, 9.0, 6.0, 179.0, 9.0, 21.0, 19.0, 15.0, 21.0, 0.0, 149.0, 13.0, 4.0, 8.0, 1.0, 2.0, 9.0, 3.0, 8.0, 0.0, 2.0, 3.0, 7.0, 0.0, 32.0, 8.0, 6.0, 14.0, 11.0, 3.0, 5.0, 3.0, 10.0, 7.0, 7.0, 7.0, 15.0, 10.0, 28.0, 1.0, 143.0, 8.0, 21.0, 9.0, 46.0, 190.0, 5.0, 2.0, 32.0, 1.0, 0.0, 158.0, 102.0, 1.0, 6.0, 0.0, 4.0, 5.0, 0.0, 15.0, 35.0, 2.0, 0.0, 2.0, 11.0, 4.0, 0.0, 31.0, 0.0, 2.0, 3.0, 1.0, 5.0, 200.0, 1.0, 2.0, 4.0, 176.0, 7.0, 16.0, 2.0, 0.0, 10.0, 2.0, 0.0, 6.0, 8.0, 5.0, 10.0, 19.0, 22.0, 159.0, 6.0, 14.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5850756179031071, "mean_inference_ms": 1.810690310785502, "mean_action_processing_ms": 0.2509855207587542, "mean_env_wait_ms": 0.19577507308080555, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003863692283630371, "StateBufferConnector_ms": 0.007303953170776367, "ViewRequirementAgentConnector_ms": 0.12062442302703857}, "num_episodes": 18, "episode_return_max": 290.5999999999999, "episode_return_min": -502.2, "episode_return_mean": 38.27299999999988, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2864000, "num_agent_steps_trained": 2864000, "num_env_steps_sampled": 716000, "num_env_steps_trained": 716000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 364.60671271064746, "num_env_steps_trained_throughput_per_sec": 364.60671271064746, "timesteps_total": 716000, "num_env_steps_sampled_lifetime": 716000, "num_agent_steps_sampled_lifetime": 2864000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2864000, "timers": {"training_iteration_time_ms": 11293.832, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11293.773, "sample_time_ms": 1406.61, "learn_time_ms": 9868.732, "learn_throughput": 405.321, "synch_weights_time_ms": 16.689}, "counters": {"num_env_steps_sampled": 716000, "num_env_steps_trained": 716000, "num_agent_steps_sampled": 2864000, "num_agent_steps_trained": 2864000}, "done": false, "training_iteration": 179, "trial_id": "3dae5_00000", "date": "2024-08-14_09-39-54", "timestamp": 1723642794, "time_this_iter_s": 10.975517749786377, "time_total_s": 3610.6017055511475, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b38fa0d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3610.6017055511475, "iterations_since_restore": 179, "perf": {"cpu_util_percent": 32.906666666666666, "ram_util_percent": 80.50666666666667}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.0687838851459444, "cur_kl_coeff": 0.0008908974006772044, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.6308408508225094, "policy_loss": -0.010525775702162671, "vf_loss": 2.641347751857112, "vf_explained_var": 0.09956545763545566, "kl": 0.021184352122728487, "entropy": 1.0542687291821475, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 339255.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.8537712668300306, "cur_kl_coeff": 0.04004516601562501, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.6597450281577135, "policy_loss": -0.008846579185346998, "vf_loss": 3.667969372285106, "vf_explained_var": -0.018894875743401745, "kl": 0.015538481727100331, "entropy": 0.9995267735902594, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 339255.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 720000, "num_env_steps_trained": 720000, "num_agent_steps_sampled": 2880000, "num_agent_steps_trained": 2880000}, "env_runners": {"episode_reward_max": 290.5999999999999, "episode_reward_min": -233.00000000000057, "episode_reward_mean": 34.59699999999989, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 162.19999999999982, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -2.9514999999999976, "predator_policy": 20.25}, "custom_metrics": {}, "hist_stats": {"episode_reward": [36.70000000000025, -85.09999999999988, 16.900000000000002, -200.9000000000009, 26.800000000000097, 37.80000000000027, 173.3999999999993, 30.400000000000155, 31.400000000000176, 24.60000000000005, 143.09999999999962, 31.90000000000018, 175.79999999999916, 107.999999999999, 24.600000000000048, 125.19999999999919, 45.39999999999999, 37.30000000000026, 130.1999999999997, 16.900000000000002, 113.29999999999922, 36.70000000000025, 30.100000000000147, 19.099999999999998, 158.29999999999927, 38.00000000000027, 38.00000000000027, 37.40000000000026, 154.0999999999992, 174.79999999999936, 2.6000000000002084, 181.9999999999992, 35.600000000000236, 290.5999999999999, 164.89999999999952, 177.9999999999995, -156.0000000000008, 19.09999999999996, 83.19999999999939, -123.90000000000046, 149.9999999999995, 98.7999999999991, 35.700000000000166, 27.900000000000105, 134.09999999999874, 29.00000000000014, 4.800000000000157, 85.80000000000003, 91.6999999999993, 37.50000000000026, 32.00000000000023, 45.600000000000385, 30.500000000000156, 102.89999999999947, -113.90000000000097, 24.900000000000063, -0.4000000000000601, -174.50000000000063, 6.800000000000114, 38.90000000000028, -41.39999999999988, 32.30000000000019, 43.70000000000035, 147.89999999999912, -14.999999999999522, 37.80000000000027, 134.5999999999996, 35.600000000000236, 5.900000000000096, 170.0999999999995, 33.4000000000002, -179.00000000000065, 35.500000000000234, -233.00000000000057, 13.900000000000036, 29.000000000000128, 37.80000000000027, 30.90000000000016, 23.50000000000003, 17.999999999999968, -130.7000000000003, 20.399999999999995, 73.60000000000028, -27.299999999999777, 24.600000000000048, -69.30000000000027, -50.39999999999988, -8.000000000000053, -16.10000000000008, -20.499999999999865, 25.700000000000067, 38.200000000000095, -67.80000000000042, 22.20000000000001, 52.50000000000037, 27.5000000000001, -38.89999999999968, 35.600000000000236, 34.300000000000246, 78.19999999999987], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [15.799999999999963, 17.899999999999988, -222.70000000000036, 11.599999999999964, -3.099999999999958, -0.9999999999999846, -28.299999999999756, -391.5999999999999, -26.199999999999747, 20.000000000000014, 20.000000000000014, 15.799999999999963, 154.0999999999999, 5.299999999999965, 1.0999999999999865, 5.299999999999967, 20.000000000000014, -13.599999999999783, -9.399999999999855, 20.000000000000014, 9.499999999999964, 104.60000000000007, 20.000000000000014, -3.099999999999958, -9.399999999999855, 162.19999999999982, 15.799999999999963, 90.19999999999955, -3.099999999999958, 13.699999999999964, -26.199999999999747, 112.3999999999997, -4.599999999999984, -40.0, 18.799999999999997, 9.499999999999964, -24.099999999999746, 113.29999999999998, 1.0999999999999865, -5.1999999999999265, 56.90000000000003, 7.399999999999987, 20.000000000000014, 13.699999999999964, 1.0999999999999865, 20.000000000000014, -9.399999999999855, 9.499999999999964, 141.79999999999984, -8.499999999999872, 22.700000000000053, 5.299999999999965, 20.000000000000014, -0.9999999999999846, 20.000000000000014, 13.399999999999965, 7.399999999999965, 139.6999999999998, 1.0999999999999865, 157.69999999999993, -40.89999999999976, 9.499999999999964, 160.39999999999986, 11.599999999999964, 11.599999999999964, 20.000000000000014, 154.99999999999991, 128.6, 137.00000000000003, 17.899999999999988, 161.9, 1.0999999999999865, -345.0999999999998, 1.0999999999999865, -9.399999999999883, -11.499999999999819, 58.700000000000074, -11.499999999999822, 5.299999999999969, -278.20000000000016, 140.29999999999993, -7.299999999999891, 85.69999999999958, 4.09999999999999, 8.00000000000002, 16.69999999999997, 3.1999999999999615, 13.699999999999964, 15.799999999999963, 116.29999999999947, 5.299999999999965, 13.699999999999964, 20.000000000000014, -47.19999999999976, 64.40000000000009, 7.399999999999965, 99.19999999999968, -32.49999999999983, 9.499999999999964, 20.000000000000014, 20.000000000000014, -1.0000000000000355, 5.299999999999965, 26.300000000000114, -11.499999999999819, 20.000000000000014, 103.69999999999979, -38.799999999999756, 17.899999999999988, -275.7999999999997, 20.000000000000014, -24.099999999999746, -80.80000000000013, 25.400000000000098, 20.000000000000014, -389.5, 20.000000000000014, -47.19999999999976, 20.000000000000014, 17.899999999999988, 20.000000000000014, -321.39999999999947, 7.399999999999967, 17.899999999999988, 28.100000000000147, 11.599999999999964, 133.39999999999972, 9.499999999999964, -11.499999999999819, -53.500000000000135, 15.799999999999963, 20.000000000000014, -3.099999999999958, 124.70000000000006, 11.599999999999964, 20.000000000000014, 20.000000000000014, -45.10000000000002, 20.000000000000014, 145.1, 9.499999999999964, 17.899999999999988, -400.0, 20.000000000000014, 17.899999999999988, 11.599999999999964, -213.40000000000012, -202.6000000000005, -11.499999999999819, 7.399999999999965, 20.000000000000014, -0.9999999999999846, 15.799999999999963, 20.000000000000014, 3.1999999999999615, 13.699999999999964, 9.499999999999964, -0.9999999999999846, -26.199999999999747, 3.199999999999967, 7.399999999999965, -303.10000000000014, -9.399999999999855, 15.799999999999963, 13.699999999999964, 56.90000000000017, -51.399999999999764, -27.89999999999992, 9.499999999999964, 1.0999999999999794, -169.30000000000032, -21.999999999999744, 20.000000000000014, -164.40000000000003, -118.19999999999979, 3.1999999999999615, -76.59999999999995, 9.499999999999964, 20.000000000000014, -95.50000000000023, -5.1999999999999265, 17.899999999999988, 38.89999999999999, -36.699999999999754, -51.39999999999996, -80.4000000000002, -9.399999999999855, 11.599999999999968, 3.1999999999999615, 8.29999999999994, 7.399999999999965, 1.099999999999983, 20.000000000000014, -185.90000000000066, 20.000000000000014, 11.599999999999964, -36.69999999999976, 20.00000000000003, 20.000000000000014, 39.20000000000012], "policy_predator_policy_reward": [2.0, 1.0, 4.0, 122.0, 10.0, 11.0, 196.0, 23.0, 22.0, 11.0, 2.0, 0.0, 7.0, 7.0, 11.0, 13.0, 9.0, 16.0, 14.0, 0.0, 18.0, 11.0, 5.0, 10.0, 11.0, 12.0, 0.0, 2.0, 4.0, 10.0, 22.0, 17.0, 7.0, 83.0, 4.0, 5.0, 21.0, 20.0, 9.0, 12.0, 1.0, 48.0, 3.0, 0.0, 0.0, 9.0, 14.0, 5.0, 11.0, 14.0, 3.0, 7.0, 9.0, 10.0, 4.0, 0.0, 6.0, 1.0, 9.0, 7.0, 29.0, 5.0, 4.0, 6.0, 4.0, 0.0, 4.0, 3.0, 9.0, 1.0, 9.0, 6.0, 179.0, 9.0, 21.0, 19.0, 15.0, 21.0, 0.0, 149.0, 13.0, 4.0, 8.0, 1.0, 2.0, 9.0, 3.0, 8.0, 0.0, 2.0, 3.0, 7.0, 0.0, 32.0, 8.0, 6.0, 14.0, 11.0, 3.0, 5.0, 3.0, 10.0, 7.0, 7.0, 7.0, 15.0, 10.0, 28.0, 1.0, 143.0, 8.0, 21.0, 9.0, 46.0, 190.0, 5.0, 2.0, 32.0, 1.0, 0.0, 158.0, 102.0, 1.0, 6.0, 0.0, 4.0, 5.0, 0.0, 15.0, 35.0, 2.0, 0.0, 2.0, 11.0, 4.0, 0.0, 31.0, 0.0, 2.0, 3.0, 1.0, 5.0, 200.0, 1.0, 2.0, 4.0, 176.0, 7.0, 16.0, 2.0, 0.0, 10.0, 2.0, 0.0, 6.0, 8.0, 5.0, 10.0, 19.0, 22.0, 159.0, 6.0, 14.0, 0.0, 0.0, 3.0, 31.0, 21.0, 9.0, 5.0, 46.0, 76.0, 93.0, 1.0, 85.0, 22.0, 5.0, 46.0, 33.0, 22.0, 12.0, 1.0, 20.0, 16.0, 8.0, 56.0, 14.0, 6.0, 33.0, 8.0, 11.0, 8.0, 7.0, 120.0, 0.0, 4.0, 10.0, 41.0, 5.0, 14.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5856834663491215, "mean_inference_ms": 1.8119944871072644, "mean_action_processing_ms": 0.25110735663682404, "mean_env_wait_ms": 0.1959450292551236, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003892660140991211, "StateBufferConnector_ms": 0.007328033447265625, "ViewRequirementAgentConnector_ms": 0.13292384147644043}, "num_episodes": 18, "episode_return_max": 290.5999999999999, "episode_return_min": -233.00000000000057, "episode_return_mean": 34.59699999999989, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2880000, "num_agent_steps_trained": 2880000, "num_env_steps_sampled": 720000, "num_env_steps_trained": 720000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 338.82983089141493, "num_env_steps_trained_throughput_per_sec": 338.82983089141493, "timesteps_total": 720000, "num_env_steps_sampled_lifetime": 720000, "num_agent_steps_sampled_lifetime": 2880000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2880000, "timers": {"training_iteration_time_ms": 11378.67, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11378.604, "sample_time_ms": 1438.431, "learn_time_ms": 9920.862, "learn_throughput": 403.191, "synch_weights_time_ms": 17.144}, "counters": {"num_env_steps_sampled": 720000, "num_env_steps_trained": 720000, "num_agent_steps_sampled": 2880000, "num_agent_steps_trained": 2880000}, "done": false, "training_iteration": 180, "trial_id": "3dae5_00000", "date": "2024-08-14_09-40-06", "timestamp": 1723642806, "time_this_iter_s": 11.834755182266235, "time_total_s": 3622.4364607334137, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b38faca0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3622.4364607334137, "iterations_since_restore": 180, "perf": {"cpu_util_percent": 41.59411764705882, "ram_util_percent": 82.84117647058824}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.7976958540381576, "cur_kl_coeff": 0.001336346101015806, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.426511016220012, "policy_loss": -0.006602066871340549, "vf_loss": 5.4330942635813715, "vf_explained_var": 0.012245652221498034, "kl": 0.014081888643743486, "entropy": 0.9759699006875356, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 341145.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.3233482445989337, "cur_kl_coeff": 0.04004516601562501, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.889566762989791, "policy_loss": -0.008732067238879464, "vf_loss": 4.897408104069019, "vf_explained_var": 0.010716833670934041, "kl": 0.022242743771788726, "entropy": 0.9366867799292166, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 341145.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 724000, "num_env_steps_trained": 724000, "num_agent_steps_sampled": 2896000, "num_agent_steps_trained": 2896000}, "env_runners": {"episode_reward_max": 290.5999999999999, "episode_reward_min": -334.7000000000006, "episode_reward_mean": 12.038999999999906, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 161.9, "predator_policy": 318.0}, "policy_reward_mean": {"prey_policy": -25.685500000000005, "predator_policy": 31.705}, "custom_metrics": {}, "hist_stats": {"episode_reward": [130.1999999999997, 16.900000000000002, 113.29999999999922, 36.70000000000025, 30.100000000000147, 19.099999999999998, 158.29999999999927, 38.00000000000027, 38.00000000000027, 37.40000000000026, 154.0999999999992, 174.79999999999936, 2.6000000000002084, 181.9999999999992, 35.600000000000236, 290.5999999999999, 164.89999999999952, 177.9999999999995, -156.0000000000008, 19.09999999999996, 83.19999999999939, -123.90000000000046, 149.9999999999995, 98.7999999999991, 35.700000000000166, 27.900000000000105, 134.09999999999874, 29.00000000000014, 4.800000000000157, 85.80000000000003, 91.6999999999993, 37.50000000000026, 32.00000000000023, 45.600000000000385, 30.500000000000156, 102.89999999999947, -113.90000000000097, 24.900000000000063, -0.4000000000000601, -174.50000000000063, 6.800000000000114, 38.90000000000028, -41.39999999999988, 32.30000000000019, 43.70000000000035, 147.89999999999912, -14.999999999999522, 37.80000000000027, 134.5999999999996, 35.600000000000236, 5.900000000000096, 170.0999999999995, 33.4000000000002, -179.00000000000065, 35.500000000000234, -233.00000000000057, 13.900000000000036, 29.000000000000128, 37.80000000000027, 30.90000000000016, 23.50000000000003, 17.999999999999968, -130.7000000000003, 20.399999999999995, 73.60000000000028, -27.299999999999777, 24.600000000000048, -69.30000000000027, -50.39999999999988, -8.000000000000053, -16.10000000000008, -20.499999999999865, 25.700000000000067, 38.200000000000095, -67.80000000000042, 22.20000000000001, 52.50000000000037, 27.5000000000001, -38.89999999999968, 35.600000000000236, 34.300000000000246, 78.19999999999987, -179.00000000000065, -13.999999999999964, -179.9999999999999, -254.89999999999998, 13.60000000000004, -150.30000000000072, -334.7000000000006, -140.40000000000043, 57.10000000000017, -235.9000000000007, -24.999999999999964, 54.50000000000041, 31.200000000000163, 21.70000000000004, -72.09999999999974, -57.19999999999997, -43.799999999999635, 36.70000000000025], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-24.099999999999746, 113.29999999999998, 1.0999999999999865, -5.1999999999999265, 56.90000000000003, 7.399999999999987, 20.000000000000014, 13.699999999999964, 1.0999999999999865, 20.000000000000014, -9.399999999999855, 9.499999999999964, 141.79999999999984, -8.499999999999872, 22.700000000000053, 5.299999999999965, 20.000000000000014, -0.9999999999999846, 20.000000000000014, 13.399999999999965, 7.399999999999965, 139.6999999999998, 1.0999999999999865, 157.69999999999993, -40.89999999999976, 9.499999999999964, 160.39999999999986, 11.599999999999964, 11.599999999999964, 20.000000000000014, 154.99999999999991, 128.6, 137.00000000000003, 17.899999999999988, 161.9, 1.0999999999999865, -345.0999999999998, 1.0999999999999865, -9.399999999999883, -11.499999999999819, 58.700000000000074, -11.499999999999822, 5.299999999999969, -278.20000000000016, 140.29999999999993, -7.299999999999891, 85.69999999999958, 4.09999999999999, 8.00000000000002, 16.69999999999997, 3.1999999999999615, 13.699999999999964, 15.799999999999963, 116.29999999999947, 5.299999999999965, 13.699999999999964, 20.000000000000014, -47.19999999999976, 64.40000000000009, 7.399999999999965, 99.19999999999968, -32.49999999999983, 9.499999999999964, 20.000000000000014, 20.000000000000014, -1.0000000000000355, 5.299999999999965, 26.300000000000114, -11.499999999999819, 20.000000000000014, 103.69999999999979, -38.799999999999756, 17.899999999999988, -275.7999999999997, 20.000000000000014, -24.099999999999746, -80.80000000000013, 25.400000000000098, 20.000000000000014, -389.5, 20.000000000000014, -47.19999999999976, 20.000000000000014, 17.899999999999988, 20.000000000000014, -321.39999999999947, 7.399999999999967, 17.899999999999988, 28.100000000000147, 11.599999999999964, 133.39999999999972, 9.499999999999964, -11.499999999999819, -53.500000000000135, 15.799999999999963, 20.000000000000014, -3.099999999999958, 124.70000000000006, 11.599999999999964, 20.000000000000014, 20.000000000000014, -45.10000000000002, 20.000000000000014, 145.1, 9.499999999999964, 17.899999999999988, -400.0, 20.000000000000014, 17.899999999999988, 11.599999999999964, -213.40000000000012, -202.6000000000005, -11.499999999999819, 7.399999999999965, 20.000000000000014, -0.9999999999999846, 15.799999999999963, 20.000000000000014, 3.1999999999999615, 13.699999999999964, 9.499999999999964, -0.9999999999999846, -26.199999999999747, 3.199999999999967, 7.399999999999965, -303.10000000000014, -9.399999999999855, 15.799999999999963, 13.699999999999964, 56.90000000000017, -51.399999999999764, -27.89999999999992, 9.499999999999964, 1.0999999999999794, -169.30000000000032, -21.999999999999744, 20.000000000000014, -164.40000000000003, -118.19999999999979, 3.1999999999999615, -76.59999999999995, 9.499999999999964, 20.000000000000014, -95.50000000000023, -5.1999999999999265, 17.899999999999988, 38.89999999999999, -36.699999999999754, -51.39999999999996, -80.4000000000002, -9.399999999999855, 11.599999999999968, 3.1999999999999615, 8.29999999999994, 7.399999999999965, 1.099999999999983, 20.000000000000014, -185.90000000000066, 20.000000000000014, 11.599999999999964, -36.69999999999976, 20.00000000000003, 20.000000000000014, 39.20000000000012, -400.0, 20.000000000000014, 12.49999999999997, -222.49999999999994, -241.49999999999994, -278.5000000000001, -359.5, -392.4000000000001, 3.1999999999999615, -13.599999999999783, 20.000000000000014, -388.2999999999996, -345.2000000000003, -327.5000000000003, 7.399999999999965, -311.8, 95.59999999999997, -185.50000000000006, -291.3999999999999, -137.5000000000007, 20.000000000000014, -195.9999999999999, 30.500000000000185, 20.000000000000014, 13.699999999999964, 9.499999999999964, -72.29999999999978, 20.000000000000014, 20.000000000000014, -253.10000000000042, 15.799999999999963, -201.00000000000006, -209.80000000000058, 20.000000000000014, 20.000000000000014, 13.699999999999964], "policy_predator_policy_reward": [21.0, 20.0, 9.0, 12.0, 1.0, 48.0, 3.0, 0.0, 0.0, 9.0, 14.0, 5.0, 11.0, 14.0, 3.0, 7.0, 9.0, 10.0, 4.0, 0.0, 6.0, 1.0, 9.0, 7.0, 29.0, 5.0, 4.0, 6.0, 4.0, 0.0, 4.0, 3.0, 9.0, 1.0, 9.0, 6.0, 179.0, 9.0, 21.0, 19.0, 15.0, 21.0, 0.0, 149.0, 13.0, 4.0, 8.0, 1.0, 2.0, 9.0, 3.0, 8.0, 0.0, 2.0, 3.0, 7.0, 0.0, 32.0, 8.0, 6.0, 14.0, 11.0, 3.0, 5.0, 3.0, 10.0, 7.0, 7.0, 7.0, 15.0, 10.0, 28.0, 1.0, 143.0, 8.0, 21.0, 9.0, 46.0, 190.0, 5.0, 2.0, 32.0, 1.0, 0.0, 158.0, 102.0, 1.0, 6.0, 0.0, 4.0, 5.0, 0.0, 15.0, 35.0, 2.0, 0.0, 2.0, 11.0, 4.0, 0.0, 31.0, 0.0, 2.0, 3.0, 1.0, 5.0, 200.0, 1.0, 2.0, 4.0, 176.0, 7.0, 16.0, 2.0, 0.0, 10.0, 2.0, 0.0, 6.0, 8.0, 5.0, 10.0, 19.0, 22.0, 159.0, 6.0, 14.0, 0.0, 0.0, 3.0, 31.0, 21.0, 9.0, 5.0, 46.0, 76.0, 93.0, 1.0, 85.0, 22.0, 5.0, 46.0, 33.0, 22.0, 12.0, 1.0, 20.0, 16.0, 8.0, 56.0, 14.0, 6.0, 33.0, 8.0, 11.0, 8.0, 7.0, 120.0, 0.0, 4.0, 10.0, 41.0, 5.0, 14.0, 1.0, 200.0, 84.0, 112.0, 64.0, 276.0, 292.0, 205.0, 8.0, 16.0, 8.0, 210.0, 20.0, 318.0, 6.0, 158.0, 39.0, 108.0, 0.0, 193.0, 134.0, 17.0, 0.0, 4.0, 3.0, 5.0, 35.0, 39.0, 83.0, 78.0, 120.0, 8.0, 92.0, 54.0, 3.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5863269477644932, "mean_inference_ms": 1.8132806517404254, "mean_action_processing_ms": 0.25123817853890956, "mean_env_wait_ms": 0.19613328753390707, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0042095184326171875, "StateBufferConnector_ms": 0.0073947906494140625, "ViewRequirementAgentConnector_ms": 0.13587212562561035}, "num_episodes": 18, "episode_return_max": 290.5999999999999, "episode_return_min": -334.7000000000006, "episode_return_mean": 12.038999999999906, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2896000, "num_agent_steps_trained": 2896000, "num_env_steps_sampled": 724000, "num_env_steps_trained": 724000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 379.0425107749077, "num_env_steps_trained_throughput_per_sec": 379.0425107749077, "timesteps_total": 724000, "num_env_steps_sampled_lifetime": 724000, "num_agent_steps_sampled_lifetime": 2896000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2896000, "timers": {"training_iteration_time_ms": 11303.576, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11303.512, "sample_time_ms": 1443.191, "learn_time_ms": 9841.223, "learn_throughput": 406.454, "synch_weights_time_ms": 16.981}, "counters": {"num_env_steps_sampled": 724000, "num_env_steps_trained": 724000, "num_agent_steps_sampled": 2896000, "num_agent_steps_trained": 2896000}, "done": false, "training_iteration": 181, "trial_id": "3dae5_00000", "date": "2024-08-14_09-40-16", "timestamp": 1723642816, "time_this_iter_s": 10.559237003326416, "time_total_s": 3632.99569773674, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3867ca0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3632.99569773674, "iterations_since_restore": 181, "perf": {"cpu_util_percent": 29.37333333333333, "ram_util_percent": 83.66666666666667}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.6912150060689006, "cur_kl_coeff": 0.001336346101015806, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.056167525715298, "policy_loss": -0.003703795942581362, "vf_loss": 5.059858401868709, "vf_explained_var": -0.019019674371790002, "kl": 0.009666853585297218, "entropy": 0.7172167356682833, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 343035.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.2372895235737795, "cur_kl_coeff": 0.060067749023437485, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.7210218321078665, "policy_loss": -0.004636334160973549, "vf_loss": 4.72513216879002, "vf_explained_var": 0.04071742324602036, "kl": 0.008756687694108574, "entropy": 0.8870268617042159, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 343035.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 728000, "num_env_steps_trained": 728000, "num_agent_steps_sampled": 2912000, "num_agent_steps_trained": 2912000}, "env_runners": {"episode_reward_max": 170.0999999999995, "episode_reward_min": -386.19999999999993, "episode_reward_mean": -13.987000000000078, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -600.2, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 145.1, "predator_policy": 440.0}, "policy_reward_mean": {"prey_policy": -55.643500000000024, "predator_policy": 48.65}, "custom_metrics": {}, "hist_stats": {"episode_reward": [98.7999999999991, 35.700000000000166, 27.900000000000105, 134.09999999999874, 29.00000000000014, 4.800000000000157, 85.80000000000003, 91.6999999999993, 37.50000000000026, 32.00000000000023, 45.600000000000385, 30.500000000000156, 102.89999999999947, -113.90000000000097, 24.900000000000063, -0.4000000000000601, -174.50000000000063, 6.800000000000114, 38.90000000000028, -41.39999999999988, 32.30000000000019, 43.70000000000035, 147.89999999999912, -14.999999999999522, 37.80000000000027, 134.5999999999996, 35.600000000000236, 5.900000000000096, 170.0999999999995, 33.4000000000002, -179.00000000000065, 35.500000000000234, -233.00000000000057, 13.900000000000036, 29.000000000000128, 37.80000000000027, 30.90000000000016, 23.50000000000003, 17.999999999999968, -130.7000000000003, 20.399999999999995, 73.60000000000028, -27.299999999999777, 24.600000000000048, -69.30000000000027, -50.39999999999988, -8.000000000000053, -16.10000000000008, -20.499999999999865, 25.700000000000067, 38.200000000000095, -67.80000000000042, 22.20000000000001, 52.50000000000037, 27.5000000000001, -38.89999999999968, 35.600000000000236, 34.300000000000246, 78.19999999999987, -179.00000000000065, -13.999999999999964, -179.9999999999999, -254.89999999999998, 13.60000000000004, -150.30000000000072, -334.7000000000006, -140.40000000000043, 57.10000000000017, -235.9000000000007, -24.999999999999964, 54.50000000000041, 31.200000000000163, 21.70000000000004, -72.09999999999974, -57.19999999999997, -43.799999999999635, 36.70000000000025, -37.400000000000006, -152.20000000000073, 37.50000000000026, -92.40000000000114, 124.39999999999932, 29.30000000000014, -103.60000000000022, -23.799999999999542, 33.4000000000002, 14.100000000000035, 24.200000000000223, -168.70000000000073, 57.0000000000004, -386.19999999999993, -207.30000000000075, -124.60000000000068, 36.60000000000025, 10.999999999999943, 88.2999999999995, -9.199999999999864, -79.50000000000071, 14.000000000000165, 85.49999999999906], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [85.69999999999958, 4.09999999999999, 8.00000000000002, 16.69999999999997, 3.1999999999999615, 13.699999999999964, 15.799999999999963, 116.29999999999947, 5.299999999999965, 13.699999999999964, 20.000000000000014, -47.19999999999976, 64.40000000000009, 7.399999999999965, 99.19999999999968, -32.49999999999983, 9.499999999999964, 20.000000000000014, 20.000000000000014, -1.0000000000000355, 5.299999999999965, 26.300000000000114, -11.499999999999819, 20.000000000000014, 103.69999999999979, -38.799999999999756, 17.899999999999988, -275.7999999999997, 20.000000000000014, -24.099999999999746, -80.80000000000013, 25.400000000000098, 20.000000000000014, -389.5, 20.000000000000014, -47.19999999999976, 20.000000000000014, 17.899999999999988, 20.000000000000014, -321.39999999999947, 7.399999999999967, 17.899999999999988, 28.100000000000147, 11.599999999999964, 133.39999999999972, 9.499999999999964, -11.499999999999819, -53.500000000000135, 15.799999999999963, 20.000000000000014, -3.099999999999958, 124.70000000000006, 11.599999999999964, 20.000000000000014, 20.000000000000014, -45.10000000000002, 20.000000000000014, 145.1, 9.499999999999964, 17.899999999999988, -400.0, 20.000000000000014, 17.899999999999988, 11.599999999999964, -213.40000000000012, -202.6000000000005, -11.499999999999819, 7.399999999999965, 20.000000000000014, -0.9999999999999846, 15.799999999999963, 20.000000000000014, 3.1999999999999615, 13.699999999999964, 9.499999999999964, -0.9999999999999846, -26.199999999999747, 3.199999999999967, 7.399999999999965, -303.10000000000014, -9.399999999999855, 15.799999999999963, 13.699999999999964, 56.90000000000017, -51.399999999999764, -27.89999999999992, 9.499999999999964, 1.0999999999999794, -169.30000000000032, -21.999999999999744, 20.000000000000014, -164.40000000000003, -118.19999999999979, 3.1999999999999615, -76.59999999999995, 9.499999999999964, 20.000000000000014, -95.50000000000023, -5.1999999999999265, 17.899999999999988, 38.89999999999999, -36.699999999999754, -51.39999999999996, -80.4000000000002, -9.399999999999855, 11.599999999999968, 3.1999999999999615, 8.29999999999994, 7.399999999999965, 1.099999999999983, 20.000000000000014, -185.90000000000066, 20.000000000000014, 11.599999999999964, -36.69999999999976, 20.00000000000003, 20.000000000000014, 39.20000000000012, -400.0, 20.000000000000014, 12.49999999999997, -222.49999999999994, -241.49999999999994, -278.5000000000001, -359.5, -392.4000000000001, 3.1999999999999615, -13.599999999999783, 20.000000000000014, -388.2999999999996, -345.2000000000003, -327.5000000000003, 7.399999999999965, -311.8, 95.59999999999997, -185.50000000000006, -291.3999999999999, -137.5000000000007, 20.000000000000014, -195.9999999999999, 30.500000000000185, 20.000000000000014, 13.699999999999964, 9.499999999999964, -72.29999999999978, 20.000000000000014, 20.000000000000014, -253.10000000000042, 15.799999999999963, -201.00000000000006, -209.80000000000058, 20.000000000000014, 20.000000000000014, 13.699999999999964, -139.9999999999999, 11.599999999999964, -576.9999999999999, -47.19999999999976, 9.499999999999964, 20.000000000000014, -9.399999999999855, -211.0000000000005, 20.000000000000014, 103.39999999999986, 11.599999999999964, -7.299999999999894, -308.5999999999999, 20.000000000000014, -101.80000000000081, 20.000000000000014, 13.699999999999964, 13.699999999999964, 20.000000000000014, -487.9, 45.20000000000024, -400.0, -375.40000000000003, 13.699999999999964, 15.799999999999963, 36.200000000000166, -280.3, -379.9, -215.2000000000005, -168.10000000000005, -472.59999999999945, 20.000000000000014, 20.000000000000014, 11.599999999999964, -64.00000000000037, 20.000000000000014, 9.499999999999964, 72.79999999999995, -600.2, 29.00000000000003, 17.899999999999988, -219.40000000000032, 20.000000000000014, -520.0, -66.1000000000009, 104.59999999999951], "policy_predator_policy_reward": [8.0, 1.0, 2.0, 9.0, 3.0, 8.0, 0.0, 2.0, 3.0, 7.0, 0.0, 32.0, 8.0, 6.0, 14.0, 11.0, 3.0, 5.0, 3.0, 10.0, 7.0, 7.0, 7.0, 15.0, 10.0, 28.0, 1.0, 143.0, 8.0, 21.0, 9.0, 46.0, 190.0, 5.0, 2.0, 32.0, 1.0, 0.0, 158.0, 102.0, 1.0, 6.0, 0.0, 4.0, 5.0, 0.0, 15.0, 35.0, 2.0, 0.0, 2.0, 11.0, 4.0, 0.0, 31.0, 0.0, 2.0, 3.0, 1.0, 5.0, 200.0, 1.0, 2.0, 4.0, 176.0, 7.0, 16.0, 2.0, 0.0, 10.0, 2.0, 0.0, 6.0, 8.0, 5.0, 10.0, 19.0, 22.0, 159.0, 6.0, 14.0, 0.0, 0.0, 3.0, 31.0, 21.0, 9.0, 5.0, 46.0, 76.0, 93.0, 1.0, 85.0, 22.0, 5.0, 46.0, 33.0, 22.0, 12.0, 1.0, 20.0, 16.0, 8.0, 56.0, 14.0, 6.0, 33.0, 8.0, 11.0, 8.0, 7.0, 120.0, 0.0, 4.0, 10.0, 41.0, 5.0, 14.0, 1.0, 200.0, 84.0, 112.0, 64.0, 276.0, 292.0, 205.0, 8.0, 16.0, 8.0, 210.0, 20.0, 318.0, 6.0, 158.0, 39.0, 108.0, 0.0, 193.0, 134.0, 17.0, 0.0, 4.0, 3.0, 5.0, 35.0, 39.0, 83.0, 78.0, 120.0, 8.0, 92.0, 54.0, 3.0, 0.0, 87.0, 4.0, 32.0, 440.0, 3.0, 5.0, 110.0, 18.0, 1.0, 0.0, 16.0, 9.0, 179.0, 6.0, 58.0, 0.0, 3.0, 3.0, 305.0, 177.0, 184.0, 195.0, 3.0, 190.0, 3.0, 2.0, 136.0, 138.0, 4.0, 172.0, 0.0, 328.0, 1.0, 4.0, 16.0, 39.0, 5.0, 1.0, 203.0, 359.0, 32.0, 90.0, 224.0, 290.0, 6.0, 41.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5873169640394793, "mean_inference_ms": 1.8140462076851278, "mean_action_processing_ms": 0.2515002958695828, "mean_env_wait_ms": 0.19641821156457492, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004899263381958008, "StateBufferConnector_ms": 0.007373690605163574, "ViewRequirementAgentConnector_ms": 0.1344432830810547}, "num_episodes": 23, "episode_return_max": 170.0999999999995, "episode_return_min": -386.19999999999993, "episode_return_mean": -13.987000000000078, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2912000, "num_agent_steps_trained": 2912000, "num_env_steps_sampled": 728000, "num_env_steps_trained": 728000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 368.8055420051618, "num_env_steps_trained_throughput_per_sec": 368.8055420051618, "timesteps_total": 728000, "num_env_steps_sampled_lifetime": 728000, "num_agent_steps_sampled_lifetime": 2912000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2912000, "timers": {"training_iteration_time_ms": 11261.875, "restore_workers_time_ms": 0.013, "training_step_time_ms": 11261.812, "sample_time_ms": 1439.339, "learn_time_ms": 9803.948, "learn_throughput": 407.999, "synch_weights_time_ms": 16.539}, "counters": {"num_env_steps_sampled": 728000, "num_env_steps_trained": 728000, "num_agent_steps_sampled": 2912000, "num_agent_steps_trained": 2912000}, "done": false, "training_iteration": 182, "trial_id": "3dae5_00000", "date": "2024-08-14_09-40-27", "timestamp": 1723642827, "time_this_iter_s": 10.850263118743896, "time_total_s": 3643.845960855484, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3867790>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3643.845960855484, "iterations_since_restore": 182, "perf": {"cpu_util_percent": 29.19375, "ram_util_percent": 83.5375}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.373224991623056, "cur_kl_coeff": 0.001336346101015806, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.107088776492568, "policy_loss": -0.005186582262573576, "vf_loss": 5.112262886920303, "vf_explained_var": -0.00811831963756097, "kl": 0.009335125713374587, "entropy": 0.7037352658138073, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 344925.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.3525931428979945, "cur_kl_coeff": 0.060067749023437485, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.9425718719997103, "policy_loss": -0.006198041560867476, "vf_loss": 3.9482685965835733, "vf_explained_var": 0.017293070233057414, "kl": 0.008345764549655495, "entropy": 0.889046428411726, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 344925.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 732000, "num_env_steps_trained": 732000, "num_agent_steps_sampled": 2928000, "num_agent_steps_trained": 2928000}, "env_runners": {"episode_reward_max": 170.0999999999995, "episode_reward_min": -386.19999999999993, "episode_reward_mean": -25.610000000000056, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -741.9, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 145.1, "predator_policy": 612.0}, "policy_reward_mean": {"prey_policy": -88.42500000000004, "predator_policy": 75.62}, "custom_metrics": {}, "hist_stats": {"episode_reward": [147.89999999999912, -14.999999999999522, 37.80000000000027, 134.5999999999996, 35.600000000000236, 5.900000000000096, 170.0999999999995, 33.4000000000002, -179.00000000000065, 35.500000000000234, -233.00000000000057, 13.900000000000036, 29.000000000000128, 37.80000000000027, 30.90000000000016, 23.50000000000003, 17.999999999999968, -130.7000000000003, 20.399999999999995, 73.60000000000028, -27.299999999999777, 24.600000000000048, -69.30000000000027, -50.39999999999988, -8.000000000000053, -16.10000000000008, -20.499999999999865, 25.700000000000067, 38.200000000000095, -67.80000000000042, 22.20000000000001, 52.50000000000037, 27.5000000000001, -38.89999999999968, 35.600000000000236, 34.300000000000246, 78.19999999999987, -179.00000000000065, -13.999999999999964, -179.9999999999999, -254.89999999999998, 13.60000000000004, -150.30000000000072, -334.7000000000006, -140.40000000000043, 57.10000000000017, -235.9000000000007, -24.999999999999964, 54.50000000000041, 31.200000000000163, 21.70000000000004, -72.09999999999974, -57.19999999999997, -43.799999999999635, 36.70000000000025, -37.400000000000006, -152.20000000000073, 37.50000000000026, -92.40000000000114, 124.39999999999932, 29.30000000000014, -103.60000000000022, -23.799999999999542, 33.4000000000002, 14.100000000000035, 24.200000000000223, -168.70000000000073, 57.0000000000004, -386.19999999999993, -207.30000000000075, -124.60000000000068, 36.60000000000025, 10.999999999999943, 88.2999999999995, -9.199999999999864, -79.50000000000071, 14.000000000000165, 85.49999999999906, 26.80000000000009, 2.8999999999999324, 31.00000000000017, -161.8000000000007, 70.49999999999996, 29.20000000000013, -83.80000000000027, -341.1, 26.80000000000009, -20.29999999999977, 36.10000000000016, 38.90000000000028, 31.200000000000163, -70.29999999999984, 24.40000000000022, 37.80000000000027, -218.89999999999992, 115.59999999999974, 17.79999999999996, -172.40000000000003, -47.40000000000034, 37.40000000000026], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [133.39999999999972, 9.499999999999964, -11.499999999999819, -53.500000000000135, 15.799999999999963, 20.000000000000014, -3.099999999999958, 124.70000000000006, 11.599999999999964, 20.000000000000014, 20.000000000000014, -45.10000000000002, 20.000000000000014, 145.1, 9.499999999999964, 17.899999999999988, -400.0, 20.000000000000014, 17.899999999999988, 11.599999999999964, -213.40000000000012, -202.6000000000005, -11.499999999999819, 7.399999999999965, 20.000000000000014, -0.9999999999999846, 15.799999999999963, 20.000000000000014, 3.1999999999999615, 13.699999999999964, 9.499999999999964, -0.9999999999999846, -26.199999999999747, 3.199999999999967, 7.399999999999965, -303.10000000000014, -9.399999999999855, 15.799999999999963, 13.699999999999964, 56.90000000000017, -51.399999999999764, -27.89999999999992, 9.499999999999964, 1.0999999999999794, -169.30000000000032, -21.999999999999744, 20.000000000000014, -164.40000000000003, -118.19999999999979, 3.1999999999999615, -76.59999999999995, 9.499999999999964, 20.000000000000014, -95.50000000000023, -5.1999999999999265, 17.899999999999988, 38.89999999999999, -36.699999999999754, -51.39999999999996, -80.4000000000002, -9.399999999999855, 11.599999999999968, 3.1999999999999615, 8.29999999999994, 7.399999999999965, 1.099999999999983, 20.000000000000014, -185.90000000000066, 20.000000000000014, 11.599999999999964, -36.69999999999976, 20.00000000000003, 20.000000000000014, 39.20000000000012, -400.0, 20.000000000000014, 12.49999999999997, -222.49999999999994, -241.49999999999994, -278.5000000000001, -359.5, -392.4000000000001, 3.1999999999999615, -13.599999999999783, 20.000000000000014, -388.2999999999996, -345.2000000000003, -327.5000000000003, 7.399999999999965, -311.8, 95.59999999999997, -185.50000000000006, -291.3999999999999, -137.5000000000007, 20.000000000000014, -195.9999999999999, 30.500000000000185, 20.000000000000014, 13.699999999999964, 9.499999999999964, -72.29999999999978, 20.000000000000014, 20.000000000000014, -253.10000000000042, 15.799999999999963, -201.00000000000006, -209.80000000000058, 20.000000000000014, 20.000000000000014, 13.699999999999964, -139.9999999999999, 11.599999999999964, -576.9999999999999, -47.19999999999976, 9.499999999999964, 20.000000000000014, -9.399999999999855, -211.0000000000005, 20.000000000000014, 103.39999999999986, 11.599999999999964, -7.299999999999894, -308.5999999999999, 20.000000000000014, -101.80000000000081, 20.000000000000014, 13.699999999999964, 13.699999999999964, 20.000000000000014, -487.9, 45.20000000000024, -400.0, -375.40000000000003, 13.699999999999964, 15.799999999999963, 36.200000000000166, -280.3, -379.9, -215.2000000000005, -168.10000000000005, -472.59999999999945, 20.000000000000014, 20.000000000000014, 11.599999999999964, -64.00000000000037, 20.000000000000014, 9.499999999999964, 72.79999999999995, -600.2, 29.00000000000003, 17.899999999999988, -219.40000000000032, 20.000000000000014, -520.0, -66.1000000000009, 104.59999999999951, -5.1999999999999265, 20.000000000000014, -260.6, 12.499999999999964, 20.000000000000014, -0.9999999999999992, -523.8, 20.000000000000014, 20.000000000000014, 45.5000000000001, 7.399999999999965, 15.799999999999963, 18.799999999999997, -217.6000000000002, -700.4, -629.7, 20.000000000000014, -5.1999999999999265, 31.700000000000188, -400.0, -138.40000000000035, 33.50000000000008, 20.000000000000014, 17.899999999999988, 13.699999999999966, 9.499999999999964, 20.000000000000014, -322.3000000000002, 20.000000000000014, -559.6, 20.000000000000014, 15.799999999999963, -538.5, -424.39999999999986, 24.500000000000096, -741.9, 20.000000000000014, -215.20000000000044, -486.6, -516.8, -720.0, 11.599999999999964, 20.000000000000014, 7.399999999999965], "policy_predator_policy_reward": [5.0, 0.0, 15.0, 35.0, 2.0, 0.0, 2.0, 11.0, 4.0, 0.0, 31.0, 0.0, 2.0, 3.0, 1.0, 5.0, 200.0, 1.0, 2.0, 4.0, 176.0, 7.0, 16.0, 2.0, 0.0, 10.0, 2.0, 0.0, 6.0, 8.0, 5.0, 10.0, 19.0, 22.0, 159.0, 6.0, 14.0, 0.0, 0.0, 3.0, 31.0, 21.0, 9.0, 5.0, 46.0, 76.0, 93.0, 1.0, 85.0, 22.0, 5.0, 46.0, 33.0, 22.0, 12.0, 1.0, 20.0, 16.0, 8.0, 56.0, 14.0, 6.0, 33.0, 8.0, 11.0, 8.0, 7.0, 120.0, 0.0, 4.0, 10.0, 41.0, 5.0, 14.0, 1.0, 200.0, 84.0, 112.0, 64.0, 276.0, 292.0, 205.0, 8.0, 16.0, 8.0, 210.0, 20.0, 318.0, 6.0, 158.0, 39.0, 108.0, 0.0, 193.0, 134.0, 17.0, 0.0, 4.0, 3.0, 5.0, 35.0, 39.0, 83.0, 78.0, 120.0, 8.0, 92.0, 54.0, 3.0, 0.0, 87.0, 4.0, 32.0, 440.0, 3.0, 5.0, 110.0, 18.0, 1.0, 0.0, 16.0, 9.0, 179.0, 6.0, 58.0, 0.0, 3.0, 3.0, 305.0, 177.0, 184.0, 195.0, 3.0, 190.0, 3.0, 2.0, 136.0, 138.0, 4.0, 172.0, 0.0, 328.0, 1.0, 4.0, 16.0, 39.0, 5.0, 1.0, 203.0, 359.0, 32.0, 90.0, 224.0, 290.0, 6.0, 41.0, 12.0, 0.0, 103.0, 148.0, 4.0, 8.0, 342.0, 0.0, 5.0, 0.0, 0.0, 6.0, 113.0, 2.0, 377.0, 612.0, 0.0, 12.0, 148.0, 200.0, 90.0, 51.0, 1.0, 0.0, 5.0, 3.0, 69.0, 163.0, 340.0, 224.0, 0.0, 2.0, 470.0, 274.0, 406.0, 427.0, 110.0, 103.0, 419.0, 412.0, 515.0, 146.0, 6.0, 4.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5873732438495002, "mean_inference_ms": 1.8155101639641527, "mean_action_processing_ms": 0.25135438015822753, "mean_env_wait_ms": 0.1963694377034475, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005836367607116699, "StateBufferConnector_ms": 0.0033072233200073242, "ViewRequirementAgentConnector_ms": 0.11584651470184326}, "num_episodes": 22, "episode_return_max": 170.0999999999995, "episode_return_min": -386.19999999999993, "episode_return_mean": -25.610000000000056, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2928000, "num_agent_steps_trained": 2928000, "num_env_steps_sampled": 732000, "num_env_steps_trained": 732000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 348.0796931029344, "num_env_steps_trained_throughput_per_sec": 348.0796931029344, "timesteps_total": 732000, "num_env_steps_sampled_lifetime": 732000, "num_agent_steps_sampled_lifetime": 2928000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2928000, "timers": {"training_iteration_time_ms": 11337.589, "restore_workers_time_ms": 0.013, "training_step_time_ms": 11337.525, "sample_time_ms": 1432.863, "learn_time_ms": 9885.78, "learn_throughput": 404.622, "synch_weights_time_ms": 16.827}, "counters": {"num_env_steps_sampled": 732000, "num_env_steps_trained": 732000, "num_agent_steps_sampled": 2928000, "num_agent_steps_trained": 2928000}, "done": false, "training_iteration": 183, "trial_id": "3dae5_00000", "date": "2024-08-14_09-40-39", "timestamp": 1723642839, "time_this_iter_s": 11.56030797958374, "time_total_s": 3655.4062688350677, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b38f89d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3655.4062688350677, "iterations_since_restore": 183, "perf": {"cpu_util_percent": 34.13125, "ram_util_percent": 83.64375}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.1171533248411913, "cur_kl_coeff": 0.001336346101015806, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.932422786036496, "policy_loss": -0.0033767249622436426, "vf_loss": 5.935793144740756, "vf_explained_var": -0.006958086843843813, "kl": 0.00476401436118623, "entropy": 0.6781223608072473, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 346815.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.250624856305501, "cur_kl_coeff": 0.060067749023437485, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.921078709698228, "policy_loss": -0.007427112381811692, "vf_loss": 4.927768893090505, "vf_explained_var": 0.03320523270223506, "kl": 0.012268375158682608, "entropy": 0.8317773083215038, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 346815.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 736000, "num_env_steps_trained": 736000, "num_agent_steps_sampled": 2944000, "num_agent_steps_trained": 2944000}, "env_runners": {"episode_reward_max": 124.39999999999932, "episode_reward_min": -386.19999999999993, "episode_reward_mean": -36.498000000000054, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -741.9, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 104.59999999999951, "predator_policy": 612.0}, "policy_reward_mean": {"prey_policy": -116.82900000000001, "predator_policy": 98.58}, "custom_metrics": {}, "hist_stats": {"episode_reward": [20.399999999999995, 73.60000000000028, -27.299999999999777, 24.600000000000048, -69.30000000000027, -50.39999999999988, -8.000000000000053, -16.10000000000008, -20.499999999999865, 25.700000000000067, 38.200000000000095, -67.80000000000042, 22.20000000000001, 52.50000000000037, 27.5000000000001, -38.89999999999968, 35.600000000000236, 34.300000000000246, 78.19999999999987, -179.00000000000065, -13.999999999999964, -179.9999999999999, -254.89999999999998, 13.60000000000004, -150.30000000000072, -334.7000000000006, -140.40000000000043, 57.10000000000017, -235.9000000000007, -24.999999999999964, 54.50000000000041, 31.200000000000163, 21.70000000000004, -72.09999999999974, -57.19999999999997, -43.799999999999635, 36.70000000000025, -37.400000000000006, -152.20000000000073, 37.50000000000026, -92.40000000000114, 124.39999999999932, 29.30000000000014, -103.60000000000022, -23.799999999999542, 33.4000000000002, 14.100000000000035, 24.200000000000223, -168.70000000000073, 57.0000000000004, -386.19999999999993, -207.30000000000075, -124.60000000000068, 36.60000000000025, 10.999999999999943, 88.2999999999995, -9.199999999999864, -79.50000000000071, 14.000000000000165, 85.49999999999906, 26.80000000000009, 2.8999999999999324, 31.00000000000017, -161.8000000000007, 70.49999999999996, 29.20000000000013, -83.80000000000027, -341.1, 26.80000000000009, -20.29999999999977, 36.10000000000016, 38.90000000000028, 31.200000000000163, -70.29999999999984, 24.40000000000022, 37.80000000000027, -218.89999999999992, 115.59999999999974, 17.79999999999996, -172.40000000000003, -47.40000000000034, 37.40000000000026, -211.70000000000087, -51.799999999999805, 29.000000000000128, -318.80000000000007, 0.6999999999999545, -3.200000000000026, -365.5, 4.400000000000173, -0.6999999999998523, 26.20000000000008, 33.10000000000019, 22.900000000000105, 32.30000000000018, -12.19999999999991, 38.90000000000028, 100.99999999999986, -123.0000000000004, -94.20000000000067], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-9.399999999999855, 15.799999999999963, 13.699999999999964, 56.90000000000017, -51.399999999999764, -27.89999999999992, 9.499999999999964, 1.0999999999999794, -169.30000000000032, -21.999999999999744, 20.000000000000014, -164.40000000000003, -118.19999999999979, 3.1999999999999615, -76.59999999999995, 9.499999999999964, 20.000000000000014, -95.50000000000023, -5.1999999999999265, 17.899999999999988, 38.89999999999999, -36.699999999999754, -51.39999999999996, -80.4000000000002, -9.399999999999855, 11.599999999999968, 3.1999999999999615, 8.29999999999994, 7.399999999999965, 1.099999999999983, 20.000000000000014, -185.90000000000066, 20.000000000000014, 11.599999999999964, -36.69999999999976, 20.00000000000003, 20.000000000000014, 39.20000000000012, -400.0, 20.000000000000014, 12.49999999999997, -222.49999999999994, -241.49999999999994, -278.5000000000001, -359.5, -392.4000000000001, 3.1999999999999615, -13.599999999999783, 20.000000000000014, -388.2999999999996, -345.2000000000003, -327.5000000000003, 7.399999999999965, -311.8, 95.59999999999997, -185.50000000000006, -291.3999999999999, -137.5000000000007, 20.000000000000014, -195.9999999999999, 30.500000000000185, 20.000000000000014, 13.699999999999964, 9.499999999999964, -72.29999999999978, 20.000000000000014, 20.000000000000014, -253.10000000000042, 15.799999999999963, -201.00000000000006, -209.80000000000058, 20.000000000000014, 20.000000000000014, 13.699999999999964, -139.9999999999999, 11.599999999999964, -576.9999999999999, -47.19999999999976, 9.499999999999964, 20.000000000000014, -9.399999999999855, -211.0000000000005, 20.000000000000014, 103.39999999999986, 11.599999999999964, -7.299999999999894, -308.5999999999999, 20.000000000000014, -101.80000000000081, 20.000000000000014, 13.699999999999964, 13.699999999999964, 20.000000000000014, -487.9, 45.20000000000024, -400.0, -375.40000000000003, 13.699999999999964, 15.799999999999963, 36.200000000000166, -280.3, -379.9, -215.2000000000005, -168.10000000000005, -472.59999999999945, 20.000000000000014, 20.000000000000014, 11.599999999999964, -64.00000000000037, 20.000000000000014, 9.499999999999964, 72.79999999999995, -600.2, 29.00000000000003, 17.899999999999988, -219.40000000000032, 20.000000000000014, -520.0, -66.1000000000009, 104.59999999999951, -5.1999999999999265, 20.000000000000014, -260.6, 12.499999999999964, 20.000000000000014, -0.9999999999999992, -523.8, 20.000000000000014, 20.000000000000014, 45.5000000000001, 7.399999999999965, 15.799999999999963, 18.799999999999997, -217.6000000000002, -700.4, -629.7, 20.000000000000014, -5.1999999999999265, 31.700000000000188, -400.0, -138.40000000000035, 33.50000000000008, 20.000000000000014, 17.899999999999988, 13.699999999999966, 9.499999999999964, 20.000000000000014, -322.3000000000002, 20.000000000000014, -559.6, 20.000000000000014, 15.799999999999963, -538.5, -424.39999999999986, 24.500000000000096, -741.9, 20.000000000000014, -215.20000000000044, -486.6, -516.8, -720.0, 11.599999999999964, 20.000000000000014, 7.399999999999965, -82.90000000000086, -365.79999999999995, 20.000000000000014, -355.8, 20.000000000000014, -0.9999999999999846, -528.9, -676.9, -199.3000000000004, 20.000000000000014, 20.000000000000014, -329.20000000000005, -517.5, -736.0, -687.6, 20.000000000000014, 20.000000000000014, -57.70000000000002, 20.000000000000014, -17.79999999999974, -1.9000000000000496, 20.000000000000014, 56.9000000000002, -672.0, 13.699999999999964, 11.599999999999964, -261.0, 15.799999999999963, 20.000000000000014, 17.899999999999988, 20.000000000000014, -592.0, -291.9999999999999, 20.000000000000014, 20.000000000000014, -236.20000000000036], "policy_predator_policy_reward": [14.0, 0.0, 0.0, 3.0, 31.0, 21.0, 9.0, 5.0, 46.0, 76.0, 93.0, 1.0, 85.0, 22.0, 5.0, 46.0, 33.0, 22.0, 12.0, 1.0, 20.0, 16.0, 8.0, 56.0, 14.0, 6.0, 33.0, 8.0, 11.0, 8.0, 7.0, 120.0, 0.0, 4.0, 10.0, 41.0, 5.0, 14.0, 1.0, 200.0, 84.0, 112.0, 64.0, 276.0, 292.0, 205.0, 8.0, 16.0, 8.0, 210.0, 20.0, 318.0, 6.0, 158.0, 39.0, 108.0, 0.0, 193.0, 134.0, 17.0, 0.0, 4.0, 3.0, 5.0, 35.0, 39.0, 83.0, 78.0, 120.0, 8.0, 92.0, 54.0, 3.0, 0.0, 87.0, 4.0, 32.0, 440.0, 3.0, 5.0, 110.0, 18.0, 1.0, 0.0, 16.0, 9.0, 179.0, 6.0, 58.0, 0.0, 3.0, 3.0, 305.0, 177.0, 184.0, 195.0, 3.0, 190.0, 3.0, 2.0, 136.0, 138.0, 4.0, 172.0, 0.0, 328.0, 1.0, 4.0, 16.0, 39.0, 5.0, 1.0, 203.0, 359.0, 32.0, 90.0, 224.0, 290.0, 6.0, 41.0, 12.0, 0.0, 103.0, 148.0, 4.0, 8.0, 342.0, 0.0, 5.0, 0.0, 0.0, 6.0, 113.0, 2.0, 377.0, 612.0, 0.0, 12.0, 148.0, 200.0, 90.0, 51.0, 1.0, 0.0, 5.0, 3.0, 69.0, 163.0, 340.0, 224.0, 0.0, 2.0, 470.0, 274.0, 406.0, 427.0, 110.0, 103.0, 419.0, 412.0, 515.0, 146.0, 6.0, 4.0, 188.0, 49.0, 281.0, 3.0, 0.0, 10.0, 533.0, 354.0, 94.0, 86.0, 140.0, 166.0, 596.0, 292.0, 421.0, 251.0, 37.0, 0.0, 6.0, 18.0, 4.0, 11.0, 377.0, 261.0, 4.0, 3.0, 92.0, 141.0, 0.0, 1.0, 329.0, 344.0, 149.0, 0.0, 0.0, 122.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5875042421997164, "mean_inference_ms": 1.815715639208111, "mean_action_processing_ms": 0.25130117239144867, "mean_env_wait_ms": 0.19637644058728249, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006477713584899902, "StateBufferConnector_ms": 0.003304600715637207, "ViewRequirementAgentConnector_ms": 0.11474621295928955}, "num_episodes": 18, "episode_return_max": 124.39999999999932, "episode_return_min": -386.19999999999993, "episode_return_mean": -36.498000000000054, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2944000, "num_agent_steps_trained": 2944000, "num_env_steps_sampled": 736000, "num_env_steps_trained": 736000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 372.3529755118428, "num_env_steps_trained_throughput_per_sec": 372.3529755118428, "timesteps_total": 736000, "num_env_steps_sampled_lifetime": 736000, "num_agent_steps_sampled_lifetime": 2944000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2944000, "timers": {"training_iteration_time_ms": 11363.11, "restore_workers_time_ms": 0.013, "training_step_time_ms": 11363.048, "sample_time_ms": 1436.48, "learn_time_ms": 9907.58, "learn_throughput": 403.731, "synch_weights_time_ms": 16.944}, "counters": {"num_env_steps_sampled": 736000, "num_env_steps_trained": 736000, "num_agent_steps_sampled": 2944000, "num_agent_steps_trained": 2944000}, "done": false, "training_iteration": 184, "trial_id": "3dae5_00000", "date": "2024-08-14_09-40-49", "timestamp": 1723642849, "time_this_iter_s": 10.748340129852295, "time_total_s": 3666.15460896492, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b38f88b0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3666.15460896492, "iterations_since_restore": 184, "perf": {"cpu_util_percent": 28.753333333333334, "ram_util_percent": 83.74666666666666}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7183932057764164, "cur_kl_coeff": 0.000668173050507903, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.274370435179857, "policy_loss": -0.0045801767962368786, "vf_loss": 3.278946790619502, "vf_explained_var": 0.0010769502826468655, "kl": 0.005712628307205212, "entropy": 0.6537531480587349, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 348705.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.6962774931438385, "cur_kl_coeff": 0.060067749023437485, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.916975864026912, "policy_loss": -0.007460008705251668, "vf_loss": 3.9239208514097506, "vf_explained_var": 0.05577652243079332, "kl": 0.008574072036133138, "entropy": 0.7671051814757958, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 348705.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 740000, "num_env_steps_trained": 740000, "num_agent_steps_sampled": 2960000, "num_agent_steps_trained": 2960000}, "env_runners": {"episode_reward_max": 151.89999999999932, "episode_reward_min": -386.19999999999993, "episode_reward_mean": -37.795000000000066, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -741.9, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 119.59999999999972, "predator_policy": 612.0}, "policy_reward_mean": {"prey_policy": -132.5775, "predator_policy": 113.68}, "custom_metrics": {}, "hist_stats": {"episode_reward": [78.19999999999987, -179.00000000000065, -13.999999999999964, -179.9999999999999, -254.89999999999998, 13.60000000000004, -150.30000000000072, -334.7000000000006, -140.40000000000043, 57.10000000000017, -235.9000000000007, -24.999999999999964, 54.50000000000041, 31.200000000000163, 21.70000000000004, -72.09999999999974, -57.19999999999997, -43.799999999999635, 36.70000000000025, -37.400000000000006, -152.20000000000073, 37.50000000000026, -92.40000000000114, 124.39999999999932, 29.30000000000014, -103.60000000000022, -23.799999999999542, 33.4000000000002, 14.100000000000035, 24.200000000000223, -168.70000000000073, 57.0000000000004, -386.19999999999993, -207.30000000000075, -124.60000000000068, 36.60000000000025, 10.999999999999943, 88.2999999999995, -9.199999999999864, -79.50000000000071, 14.000000000000165, 85.49999999999906, 26.80000000000009, 2.8999999999999324, 31.00000000000017, -161.8000000000007, 70.49999999999996, 29.20000000000013, -83.80000000000027, -341.1, 26.80000000000009, -20.29999999999977, 36.10000000000016, 38.90000000000028, 31.200000000000163, -70.29999999999984, 24.40000000000022, 37.80000000000027, -218.89999999999992, 115.59999999999974, 17.79999999999996, -172.40000000000003, -47.40000000000034, 37.40000000000026, -211.70000000000087, -51.799999999999805, 29.000000000000128, -318.80000000000007, 0.6999999999999545, -3.200000000000026, -365.5, 4.400000000000173, -0.6999999999998523, 26.20000000000008, 33.10000000000019, 22.900000000000105, 32.30000000000018, -12.19999999999991, 38.90000000000028, 100.99999999999986, -123.0000000000004, -94.20000000000067, 146.59999999999914, 13.699999999999923, 47.50000000000016, -5.099999999999877, -74.5000000000006, 103.19999999999985, -251.5999999999988, -39.89999999999984, -21.59999999999964, -38.299999999999585, 106.29999999999944, 151.89999999999932, -281.7999999999988, -235.60000000000082, 92.09999999999974, 44.60000000000026, 38.90000000000028, 130.19999999999976], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 39.20000000000012, -400.0, 20.000000000000014, 12.49999999999997, -222.49999999999994, -241.49999999999994, -278.5000000000001, -359.5, -392.4000000000001, 3.1999999999999615, -13.599999999999783, 20.000000000000014, -388.2999999999996, -345.2000000000003, -327.5000000000003, 7.399999999999965, -311.8, 95.59999999999997, -185.50000000000006, -291.3999999999999, -137.5000000000007, 20.000000000000014, -195.9999999999999, 30.500000000000185, 20.000000000000014, 13.699999999999964, 9.499999999999964, -72.29999999999978, 20.000000000000014, 20.000000000000014, -253.10000000000042, 15.799999999999963, -201.00000000000006, -209.80000000000058, 20.000000000000014, 20.000000000000014, 13.699999999999964, -139.9999999999999, 11.599999999999964, -576.9999999999999, -47.19999999999976, 9.499999999999964, 20.000000000000014, -9.399999999999855, -211.0000000000005, 20.000000000000014, 103.39999999999986, 11.599999999999964, -7.299999999999894, -308.5999999999999, 20.000000000000014, -101.80000000000081, 20.000000000000014, 13.699999999999964, 13.699999999999964, 20.000000000000014, -487.9, 45.20000000000024, -400.0, -375.40000000000003, 13.699999999999964, 15.799999999999963, 36.200000000000166, -280.3, -379.9, -215.2000000000005, -168.10000000000005, -472.59999999999945, 20.000000000000014, 20.000000000000014, 11.599999999999964, -64.00000000000037, 20.000000000000014, 9.499999999999964, 72.79999999999995, -600.2, 29.00000000000003, 17.899999999999988, -219.40000000000032, 20.000000000000014, -520.0, -66.1000000000009, 104.59999999999951, -5.1999999999999265, 20.000000000000014, -260.6, 12.499999999999964, 20.000000000000014, -0.9999999999999992, -523.8, 20.000000000000014, 20.000000000000014, 45.5000000000001, 7.399999999999965, 15.799999999999963, 18.799999999999997, -217.6000000000002, -700.4, -629.7, 20.000000000000014, -5.1999999999999265, 31.700000000000188, -400.0, -138.40000000000035, 33.50000000000008, 20.000000000000014, 17.899999999999988, 13.699999999999966, 9.499999999999964, 20.000000000000014, -322.3000000000002, 20.000000000000014, -559.6, 20.000000000000014, 15.799999999999963, -538.5, -424.39999999999986, 24.500000000000096, -741.9, 20.000000000000014, -215.20000000000044, -486.6, -516.8, -720.0, 11.599999999999964, 20.000000000000014, 7.399999999999965, -82.90000000000086, -365.79999999999995, 20.000000000000014, -355.8, 20.000000000000014, -0.9999999999999846, -528.9, -676.9, -199.3000000000004, 20.000000000000014, 20.000000000000014, -329.20000000000005, -517.5, -736.0, -687.6, 20.000000000000014, 20.000000000000014, -57.70000000000002, 20.000000000000014, -17.79999999999974, -1.9000000000000496, 20.000000000000014, 56.9000000000002, -672.0, 13.699999999999964, 11.599999999999964, -261.0, 15.799999999999963, 20.000000000000014, 17.899999999999988, 20.000000000000014, -592.0, -291.9999999999999, 20.000000000000014, 20.000000000000014, -236.20000000000036, 20.000000000000014, 119.59999999999972, -133.30000000000064, 20.000000000000014, 20.000000000000014, -180.50000000000026, 20.000000000000014, -255.09999999999877, -219.5000000000006, -656.0, 95.60000000000008, -9.39999999999989, -304.7999999999984, -327.7999999999991, -53.50000000000002, -45.39999999999978, -91.30000000000068, 13.699999999999964, -124.90000000000074, 11.599999999999964, 87.49999999999979, 15.799999999999963, 20.000000000000014, 101.89999999999988, -421.89999999999884, -524.8999999999999, -106.0000000000008, -382.6, -586.5999999999997, 85.69999999999996, 38.00000000000003, -386.3999999999987, 20.000000000000014, 17.899999999999988, 102.19999999999999, 20.000000000000014], "policy_predator_policy_reward": [5.0, 14.0, 1.0, 200.0, 84.0, 112.0, 64.0, 276.0, 292.0, 205.0, 8.0, 16.0, 8.0, 210.0, 20.0, 318.0, 6.0, 158.0, 39.0, 108.0, 0.0, 193.0, 134.0, 17.0, 0.0, 4.0, 3.0, 5.0, 35.0, 39.0, 83.0, 78.0, 120.0, 8.0, 92.0, 54.0, 3.0, 0.0, 87.0, 4.0, 32.0, 440.0, 3.0, 5.0, 110.0, 18.0, 1.0, 0.0, 16.0, 9.0, 179.0, 6.0, 58.0, 0.0, 3.0, 3.0, 305.0, 177.0, 184.0, 195.0, 3.0, 190.0, 3.0, 2.0, 136.0, 138.0, 4.0, 172.0, 0.0, 328.0, 1.0, 4.0, 16.0, 39.0, 5.0, 1.0, 203.0, 359.0, 32.0, 90.0, 224.0, 290.0, 6.0, 41.0, 12.0, 0.0, 103.0, 148.0, 4.0, 8.0, 342.0, 0.0, 5.0, 0.0, 0.0, 6.0, 113.0, 2.0, 377.0, 612.0, 0.0, 12.0, 148.0, 200.0, 90.0, 51.0, 1.0, 0.0, 5.0, 3.0, 69.0, 163.0, 340.0, 224.0, 0.0, 2.0, 470.0, 274.0, 406.0, 427.0, 110.0, 103.0, 419.0, 412.0, 515.0, 146.0, 6.0, 4.0, 188.0, 49.0, 281.0, 3.0, 0.0, 10.0, 533.0, 354.0, 94.0, 86.0, 140.0, 166.0, 596.0, 292.0, 421.0, 251.0, 37.0, 0.0, 6.0, 18.0, 4.0, 11.0, 377.0, 261.0, 4.0, 3.0, 92.0, 141.0, 0.0, 1.0, 329.0, 344.0, 149.0, 0.0, 0.0, 122.0, 0.0, 7.0, 63.0, 64.0, 110.0, 98.0, 109.0, 121.0, 395.0, 406.0, 3.0, 14.0, 195.0, 186.0, 19.0, 40.0, 53.0, 3.0, 69.0, 6.0, 1.0, 2.0, 18.0, 12.0, 430.0, 235.0, 60.0, 193.0, 282.0, 311.0, 187.0, 206.0, 0.0, 1.0, 3.0, 5.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.587402763432981, "mean_inference_ms": 1.8156008241058896, "mean_action_processing_ms": 0.25120347725329356, "mean_env_wait_ms": 0.19633655028686492, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006732821464538574, "StateBufferConnector_ms": 0.0033257007598876953, "ViewRequirementAgentConnector_ms": 0.1028364896774292}, "num_episodes": 18, "episode_return_max": 151.89999999999932, "episode_return_min": -386.19999999999993, "episode_return_mean": -37.795000000000066, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2960000, "num_agent_steps_trained": 2960000, "num_env_steps_sampled": 740000, "num_env_steps_trained": 740000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 377.0745067786457, "num_env_steps_trained_throughput_per_sec": 377.0745067786457, "timesteps_total": 740000, "num_env_steps_sampled_lifetime": 740000, "num_agent_steps_sampled_lifetime": 2960000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2960000, "timers": {"training_iteration_time_ms": 11362.453, "restore_workers_time_ms": 0.013, "training_step_time_ms": 11362.391, "sample_time_ms": 1433.374, "learn_time_ms": 9909.818, "learn_throughput": 403.64, "synch_weights_time_ms": 17.116}, "counters": {"num_env_steps_sampled": 740000, "num_env_steps_trained": 740000, "num_agent_steps_sampled": 2960000, "num_agent_steps_trained": 2960000}, "done": false, "training_iteration": 185, "trial_id": "3dae5_00000", "date": "2024-08-14_09-41-00", "timestamp": 1723642860, "time_this_iter_s": 10.648826122283936, "time_total_s": 3676.803435087204, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b38f8040>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3676.803435087204, "iterations_since_restore": 185, "perf": {"cpu_util_percent": 28.225, "ram_util_percent": 83.84375}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.555790102513379, "cur_kl_coeff": 0.000668173050507903, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.9063884545886327, "policy_loss": -0.005350228434024507, "vf_loss": 2.911733172999488, "vf_explained_var": 0.012023201915952894, "kl": 0.008254650847503018, "entropy": 0.5584697911505977, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 350595.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.5490044815515085, "cur_kl_coeff": 0.060067749023437485, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.441524165900296, "policy_loss": -0.00844287964313355, "vf_loss": 4.449265109925043, "vf_explained_var": 0.07672429368609474, "kl": 0.011685778859073494, "entropy": 0.7506608458107742, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 350595.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 744000, "num_env_steps_trained": 744000, "num_agent_steps_sampled": 2976000, "num_agent_steps_trained": 2976000}, "env_runners": {"episode_reward_max": 151.89999999999932, "episode_reward_min": -386.19999999999993, "episode_reward_mean": -22.11400000000005, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -741.9, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 123.49999999999991, "predator_policy": 612.0}, "policy_reward_mean": {"prey_policy": -118.97200000000002, "predator_policy": 107.915}, "custom_metrics": {}, "hist_stats": {"episode_reward": [36.70000000000025, -37.400000000000006, -152.20000000000073, 37.50000000000026, -92.40000000000114, 124.39999999999932, 29.30000000000014, -103.60000000000022, -23.799999999999542, 33.4000000000002, 14.100000000000035, 24.200000000000223, -168.70000000000073, 57.0000000000004, -386.19999999999993, -207.30000000000075, -124.60000000000068, 36.60000000000025, 10.999999999999943, 88.2999999999995, -9.199999999999864, -79.50000000000071, 14.000000000000165, 85.49999999999906, 26.80000000000009, 2.8999999999999324, 31.00000000000017, -161.8000000000007, 70.49999999999996, 29.20000000000013, -83.80000000000027, -341.1, 26.80000000000009, -20.29999999999977, 36.10000000000016, 38.90000000000028, 31.200000000000163, -70.29999999999984, 24.40000000000022, 37.80000000000027, -218.89999999999992, 115.59999999999974, 17.79999999999996, -172.40000000000003, -47.40000000000034, 37.40000000000026, -211.70000000000087, -51.799999999999805, 29.000000000000128, -318.80000000000007, 0.6999999999999545, -3.200000000000026, -365.5, 4.400000000000173, -0.6999999999998523, 26.20000000000008, 33.10000000000019, 22.900000000000105, 32.30000000000018, -12.19999999999991, 38.90000000000028, 100.99999999999986, -123.0000000000004, -94.20000000000067, 146.59999999999914, 13.699999999999923, 47.50000000000016, -5.099999999999877, -74.5000000000006, 103.19999999999985, -251.5999999999988, -39.89999999999984, -21.59999999999964, -38.299999999999585, 106.29999999999944, 151.89999999999932, -281.7999999999988, -235.60000000000082, 92.09999999999974, 44.60000000000026, 38.90000000000028, 130.19999999999976, 38.90000000000028, 136.49999999999977, 102.9999999999995, 134.4999999999998, 34.50000000000022, -34.59999999999955, 20.59999999999999, 71.30000000000003, 141.29999999999956, 21.10000000000027, -35.899999999999714, -124.50000000000111, 33.60000000000021, -21.799999999999862, -348.09999999999945, 35.600000000000236, -6.299999999999752, -62.600000000001316], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 13.699999999999964, -139.9999999999999, 11.599999999999964, -576.9999999999999, -47.19999999999976, 9.499999999999964, 20.000000000000014, -9.399999999999855, -211.0000000000005, 20.000000000000014, 103.39999999999986, 11.599999999999964, -7.299999999999894, -308.5999999999999, 20.000000000000014, -101.80000000000081, 20.000000000000014, 13.699999999999964, 13.699999999999964, 20.000000000000014, -487.9, 45.20000000000024, -400.0, -375.40000000000003, 13.699999999999964, 15.799999999999963, 36.200000000000166, -280.3, -379.9, -215.2000000000005, -168.10000000000005, -472.59999999999945, 20.000000000000014, 20.000000000000014, 11.599999999999964, -64.00000000000037, 20.000000000000014, 9.499999999999964, 72.79999999999995, -600.2, 29.00000000000003, 17.899999999999988, -219.40000000000032, 20.000000000000014, -520.0, -66.1000000000009, 104.59999999999951, -5.1999999999999265, 20.000000000000014, -260.6, 12.499999999999964, 20.000000000000014, -0.9999999999999992, -523.8, 20.000000000000014, 20.000000000000014, 45.5000000000001, 7.399999999999965, 15.799999999999963, 18.799999999999997, -217.6000000000002, -700.4, -629.7, 20.000000000000014, -5.1999999999999265, 31.700000000000188, -400.0, -138.40000000000035, 33.50000000000008, 20.000000000000014, 17.899999999999988, 13.699999999999966, 9.499999999999964, 20.000000000000014, -322.3000000000002, 20.000000000000014, -559.6, 20.000000000000014, 15.799999999999963, -538.5, -424.39999999999986, 24.500000000000096, -741.9, 20.000000000000014, -215.20000000000044, -486.6, -516.8, -720.0, 11.599999999999964, 20.000000000000014, 7.399999999999965, -82.90000000000086, -365.79999999999995, 20.000000000000014, -355.8, 20.000000000000014, -0.9999999999999846, -528.9, -676.9, -199.3000000000004, 20.000000000000014, 20.000000000000014, -329.20000000000005, -517.5, -736.0, -687.6, 20.000000000000014, 20.000000000000014, -57.70000000000002, 20.000000000000014, -17.79999999999974, -1.9000000000000496, 20.000000000000014, 56.9000000000002, -672.0, 13.699999999999964, 11.599999999999964, -261.0, 15.799999999999963, 20.000000000000014, 17.899999999999988, 20.000000000000014, -592.0, -291.9999999999999, 20.000000000000014, 20.000000000000014, -236.20000000000036, 20.000000000000014, 119.59999999999972, -133.30000000000064, 20.000000000000014, 20.000000000000014, -180.50000000000026, 20.000000000000014, -255.09999999999877, -219.5000000000006, -656.0, 95.60000000000008, -9.39999999999989, -304.7999999999984, -327.7999999999991, -53.50000000000002, -45.39999999999978, -91.30000000000068, 13.699999999999964, -124.90000000000074, 11.599999999999964, 87.49999999999979, 15.799999999999963, 20.000000000000014, 101.89999999999988, -421.89999999999884, -524.8999999999999, -106.0000000000008, -382.6, -586.5999999999997, 85.69999999999996, 38.00000000000003, -386.3999999999987, 20.000000000000014, 17.899999999999988, 102.19999999999999, 20.000000000000014, 17.899999999999988, 20.000000000000014, 110.0, -362.499999999999, 74.0000000000001, 20.000000000000014, 20.000000000000014, 102.50000000000004, 13.699999999999964, 15.799999999999963, -201.10000000000056, 9.499999999999964, 17.899999999999977, -28.29999999999975, 49.1000000000001, 3.199999999999967, 15.799999999999963, 123.49999999999991, -222.1, 3.1999999999999615, -124.90000000000049, 20.000000000000014, -154.30000000000064, -152.2000000000005, -9.399999999999855, 20.000000000000014, -335.9999999999992, 45.200000000000095, -224.50000000000009, -361.59999999999997, 11.599999999999964, 20.000000000000014, 20.000000000000014, -112.30000000000078, -108.10000000000072, -74.50000000000071], "policy_predator_policy_reward": [3.0, 0.0, 87.0, 4.0, 32.0, 440.0, 3.0, 5.0, 110.0, 18.0, 1.0, 0.0, 16.0, 9.0, 179.0, 6.0, 58.0, 0.0, 3.0, 3.0, 305.0, 177.0, 184.0, 195.0, 3.0, 190.0, 3.0, 2.0, 136.0, 138.0, 4.0, 172.0, 0.0, 328.0, 1.0, 4.0, 16.0, 39.0, 5.0, 1.0, 203.0, 359.0, 32.0, 90.0, 224.0, 290.0, 6.0, 41.0, 12.0, 0.0, 103.0, 148.0, 4.0, 8.0, 342.0, 0.0, 5.0, 0.0, 0.0, 6.0, 113.0, 2.0, 377.0, 612.0, 0.0, 12.0, 148.0, 200.0, 90.0, 51.0, 1.0, 0.0, 5.0, 3.0, 69.0, 163.0, 340.0, 224.0, 0.0, 2.0, 470.0, 274.0, 406.0, 427.0, 110.0, 103.0, 419.0, 412.0, 515.0, 146.0, 6.0, 4.0, 188.0, 49.0, 281.0, 3.0, 0.0, 10.0, 533.0, 354.0, 94.0, 86.0, 140.0, 166.0, 596.0, 292.0, 421.0, 251.0, 37.0, 0.0, 6.0, 18.0, 4.0, 11.0, 377.0, 261.0, 4.0, 3.0, 92.0, 141.0, 0.0, 1.0, 329.0, 344.0, 149.0, 0.0, 0.0, 122.0, 0.0, 7.0, 63.0, 64.0, 110.0, 98.0, 109.0, 121.0, 395.0, 406.0, 3.0, 14.0, 195.0, 186.0, 19.0, 40.0, 53.0, 3.0, 69.0, 6.0, 1.0, 2.0, 18.0, 12.0, 430.0, 235.0, 60.0, 193.0, 282.0, 311.0, 187.0, 206.0, 0.0, 1.0, 3.0, 5.0, 1.0, 0.0, 260.0, 129.0, 6.0, 3.0, 2.0, 10.0, 2.0, 3.0, 152.0, 5.0, 7.0, 24.0, 11.0, 8.0, 0.0, 2.0, 108.0, 132.0, 69.0, 0.0, 79.0, 103.0, 14.0, 9.0, 228.0, 41.0, 131.0, 107.0, 4.0, 0.0, 63.0, 23.0, 61.0, 59.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5872724580142916, "mean_inference_ms": 1.815501469183701, "mean_action_processing_ms": 0.2511012045896958, "mean_env_wait_ms": 0.19629587349416383, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006892800331115723, "StateBufferConnector_ms": 0.0033020973205566406, "ViewRequirementAgentConnector_ms": 0.10066688060760498}, "num_episodes": 18, "episode_return_max": 151.89999999999932, "episode_return_min": -386.19999999999993, "episode_return_mean": -22.11400000000005, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2976000, "num_agent_steps_trained": 2976000, "num_env_steps_sampled": 744000, "num_env_steps_trained": 744000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 364.8488243340007, "num_env_steps_trained_throughput_per_sec": 364.8488243340007, "timesteps_total": 744000, "num_env_steps_sampled_lifetime": 744000, "num_agent_steps_sampled_lifetime": 2976000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2976000, "timers": {"training_iteration_time_ms": 11397.685, "restore_workers_time_ms": 0.013, "training_step_time_ms": 11397.622, "sample_time_ms": 1432.976, "learn_time_ms": 9945.374, "learn_throughput": 402.197, "synch_weights_time_ms": 17.133}, "counters": {"num_env_steps_sampled": 744000, "num_env_steps_trained": 744000, "num_agent_steps_sampled": 2976000, "num_agent_steps_trained": 2976000}, "done": false, "training_iteration": 186, "trial_id": "3dae5_00000", "date": "2024-08-14_09-41-11", "timestamp": 1723642871, "time_this_iter_s": 11.008355140686035, "time_total_s": 3687.81179022789, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b38fadc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3687.81179022789, "iterations_since_restore": 186, "perf": {"cpu_util_percent": 31.586666666666662, "ram_util_percent": 83.56666666666668}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.607525484492539, "cur_kl_coeff": 0.000668173050507903, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.689608780227641, "policy_loss": -0.007179959065024618, "vf_loss": 1.696781063931329, "vf_explained_var": 0.07047439113495842, "kl": 0.011483641493287742, "entropy": 0.6450346715551205, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 352485.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.39353390272963, "cur_kl_coeff": 0.060067749023437485, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.5764448228336514, "policy_loss": -0.008165194663569016, "vf_loss": 2.58411672184707, "vf_explained_var": 0.05585041090294167, "kl": 0.008212300668078409, "entropy": 0.6976483133104112, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 352485.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 748000, "num_env_steps_trained": 748000, "num_agent_steps_sampled": 2992000, "num_agent_steps_trained": 2992000}, "env_runners": {"episode_reward_max": 151.89999999999932, "episode_reward_min": -388.79999999999995, "episode_reward_mean": -11.384000000000022, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -741.9, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 131.60000000000005, "predator_policy": 612.0}, "policy_reward_mean": {"prey_policy": -98.91200000000002, "predator_policy": 93.22}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-161.8000000000007, 70.49999999999996, 29.20000000000013, -83.80000000000027, -341.1, 26.80000000000009, -20.29999999999977, 36.10000000000016, 38.90000000000028, 31.200000000000163, -70.29999999999984, 24.40000000000022, 37.80000000000027, -218.89999999999992, 115.59999999999974, 17.79999999999996, -172.40000000000003, -47.40000000000034, 37.40000000000026, -211.70000000000087, -51.799999999999805, 29.000000000000128, -318.80000000000007, 0.6999999999999545, -3.200000000000026, -365.5, 4.400000000000173, -0.6999999999998523, 26.20000000000008, 33.10000000000019, 22.900000000000105, 32.30000000000018, -12.19999999999991, 38.90000000000028, 100.99999999999986, -123.0000000000004, -94.20000000000067, 146.59999999999914, 13.699999999999923, 47.50000000000016, -5.099999999999877, -74.5000000000006, 103.19999999999985, -251.5999999999988, -39.89999999999984, -21.59999999999964, -38.299999999999585, 106.29999999999944, 151.89999999999932, -281.7999999999988, -235.60000000000082, 92.09999999999974, 44.60000000000026, 38.90000000000028, 130.19999999999976, 38.90000000000028, 136.49999999999977, 102.9999999999995, 134.4999999999998, 34.50000000000022, -34.59999999999955, 20.59999999999999, 71.30000000000003, 141.29999999999956, 21.10000000000027, -35.899999999999714, -124.50000000000111, 33.60000000000021, -21.799999999999862, -348.09999999999945, 35.600000000000236, -6.299999999999752, -62.600000000001316, 63.70000000000015, 149.0999999999997, 89.5, 50.20000000000021, 16.199999999999925, -44.29999999999995, 77.50000000000001, 28.60000000000013, -101.40000000000016, -388.79999999999995, -85.90000000000134, 3.9000000000000603, 40.0000000000003, 31.800000000000182, 33.2000000000002, 36.60000000000025, -177.80000000000067, 36.70000000000025, -20.200000000000017, 86.60000000000018, 19.09999999999999, 75.40000000000002, 1.5000000000001898, 98.29999999999944, 79.90000000000032, 19.399999999999974, 121.99999999999955], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-523.8, 20.000000000000014, 20.000000000000014, 45.5000000000001, 7.399999999999965, 15.799999999999963, 18.799999999999997, -217.6000000000002, -700.4, -629.7, 20.000000000000014, -5.1999999999999265, 31.700000000000188, -400.0, -138.40000000000035, 33.50000000000008, 20.000000000000014, 17.899999999999988, 13.699999999999966, 9.499999999999964, 20.000000000000014, -322.3000000000002, 20.000000000000014, -559.6, 20.000000000000014, 15.799999999999963, -538.5, -424.39999999999986, 24.500000000000096, -741.9, 20.000000000000014, -215.20000000000044, -486.6, -516.8, -720.0, 11.599999999999964, 20.000000000000014, 7.399999999999965, -82.90000000000086, -365.79999999999995, 20.000000000000014, -355.8, 20.000000000000014, -0.9999999999999846, -528.9, -676.9, -199.3000000000004, 20.000000000000014, 20.000000000000014, -329.20000000000005, -517.5, -736.0, -687.6, 20.000000000000014, 20.000000000000014, -57.70000000000002, 20.000000000000014, -17.79999999999974, -1.9000000000000496, 20.000000000000014, 56.9000000000002, -672.0, 13.699999999999964, 11.599999999999964, -261.0, 15.799999999999963, 20.000000000000014, 17.899999999999988, 20.000000000000014, -592.0, -291.9999999999999, 20.000000000000014, 20.000000000000014, -236.20000000000036, 20.000000000000014, 119.59999999999972, -133.30000000000064, 20.000000000000014, 20.000000000000014, -180.50000000000026, 20.000000000000014, -255.09999999999877, -219.5000000000006, -656.0, 95.60000000000008, -9.39999999999989, -304.7999999999984, -327.7999999999991, -53.50000000000002, -45.39999999999978, -91.30000000000068, 13.699999999999964, -124.90000000000074, 11.599999999999964, 87.49999999999979, 15.799999999999963, 20.000000000000014, 101.89999999999988, -421.89999999999884, -524.8999999999999, -106.0000000000008, -382.6, -586.5999999999997, 85.69999999999996, 38.00000000000003, -386.3999999999987, 20.000000000000014, 17.899999999999988, 102.19999999999999, 20.000000000000014, 17.899999999999988, 20.000000000000014, 110.0, -362.499999999999, 74.0000000000001, 20.000000000000014, 20.000000000000014, 102.50000000000004, 13.699999999999964, 15.799999999999963, -201.10000000000056, 9.499999999999964, 17.899999999999977, -28.29999999999975, 49.1000000000001, 3.199999999999967, 15.799999999999963, 123.49999999999991, -222.1, 3.1999999999999615, -124.90000000000049, 20.000000000000014, -154.30000000000064, -152.2000000000005, -9.399999999999855, 20.000000000000014, -335.9999999999992, 45.200000000000095, -224.50000000000009, -361.59999999999997, 11.599999999999964, 20.000000000000014, 20.000000000000014, -112.30000000000078, -108.10000000000072, -74.50000000000071, -30.3999999999998, 61.100000000000065, 9.499999999999964, 131.60000000000005, 15.799999999999963, 64.69999999999999, -146.20000000000067, 52.40000000000013, 11.599999999999964, -30.399999999999793, 5.299999999999965, -139.60000000000068, 51.50000000000009, 20.000000000000014, 13.699999999999955, -3.0999999999999934, -248.20000000000007, 15.799999999999963, -373.00000000000006, -215.80000000000007, -92.2000000000007, -141.70000000000064, -108.10000000000076, 20.000000000000014, 20.000000000000014, 20.000000000000014, -15.699999999999747, 24.50000000000008, 20.000000000000014, 3.1999999999999615, 11.599999999999964, 20.000000000000014, -395.8, 20.000000000000014, 13.699999999999964, 20.000000000000014, -11.50000000000005, -36.699999999999996, 17.899999999999988, 67.70000000000016, -11.499999999999819, 11.599999999999964, 65.9000000000001, -95.50000000000068, -51.399999999999906, 17.899999999999988, 81.19999999999976, -19.899999999999743, 56.900000000000176, 20.000000000000014, -74.50000000000081, 17.899999999999988, 11.599999999999964, 106.39999999999989], "policy_predator_policy_reward": [342.0, 0.0, 5.0, 0.0, 0.0, 6.0, 113.0, 2.0, 377.0, 612.0, 0.0, 12.0, 148.0, 200.0, 90.0, 51.0, 1.0, 0.0, 5.0, 3.0, 69.0, 163.0, 340.0, 224.0, 0.0, 2.0, 470.0, 274.0, 406.0, 427.0, 110.0, 103.0, 419.0, 412.0, 515.0, 146.0, 6.0, 4.0, 188.0, 49.0, 281.0, 3.0, 0.0, 10.0, 533.0, 354.0, 94.0, 86.0, 140.0, 166.0, 596.0, 292.0, 421.0, 251.0, 37.0, 0.0, 6.0, 18.0, 4.0, 11.0, 377.0, 261.0, 4.0, 3.0, 92.0, 141.0, 0.0, 1.0, 329.0, 344.0, 149.0, 0.0, 0.0, 122.0, 0.0, 7.0, 63.0, 64.0, 110.0, 98.0, 109.0, 121.0, 395.0, 406.0, 3.0, 14.0, 195.0, 186.0, 19.0, 40.0, 53.0, 3.0, 69.0, 6.0, 1.0, 2.0, 18.0, 12.0, 430.0, 235.0, 60.0, 193.0, 282.0, 311.0, 187.0, 206.0, 0.0, 1.0, 3.0, 5.0, 1.0, 0.0, 260.0, 129.0, 6.0, 3.0, 2.0, 10.0, 2.0, 3.0, 152.0, 5.0, 7.0, 24.0, 11.0, 8.0, 0.0, 2.0, 108.0, 132.0, 69.0, 0.0, 79.0, 103.0, 14.0, 9.0, 228.0, 41.0, 131.0, 107.0, 4.0, 0.0, 63.0, 23.0, 61.0, 59.0, 28.0, 5.0, 4.0, 4.0, 2.0, 7.0, 73.0, 71.0, 12.0, 23.0, 37.0, 53.0, 4.0, 2.0, 5.0, 13.0, 122.0, 9.0, 199.0, 1.0, 86.0, 62.0, 55.0, 37.0, 0.0, 0.0, 17.0, 6.0, 8.0, 2.0, 4.0, 1.0, 0.0, 198.0, 3.0, 0.0, 24.0, 4.0, 0.0, 1.0, 4.0, 15.0, 55.0, 50.0, 34.0, 1.0, 18.0, 19.0, 0.0, 3.0, 31.0, 45.0, 4.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5871427524094723, "mean_inference_ms": 1.81538303786973, "mean_action_processing_ms": 0.2507099129373583, "mean_env_wait_ms": 0.19637109346672108, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005945444107055664, "StateBufferConnector_ms": 0.003546476364135742, "ViewRequirementAgentConnector_ms": 0.09802746772766113}, "num_episodes": 27, "episode_return_max": 151.89999999999932, "episode_return_min": -388.79999999999995, "episode_return_mean": -11.384000000000022, "episodes_this_iter": 27}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2992000, "num_agent_steps_trained": 2992000, "num_env_steps_sampled": 748000, "num_env_steps_trained": 748000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 384.21543231786603, "num_env_steps_trained_throughput_per_sec": 384.21543231786603, "timesteps_total": 748000, "num_env_steps_sampled_lifetime": 748000, "num_agent_steps_sampled_lifetime": 2992000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2992000, "timers": {"training_iteration_time_ms": 11330.114, "restore_workers_time_ms": 0.013, "training_step_time_ms": 11330.065, "sample_time_ms": 1439.062, "learn_time_ms": 9874.169, "learn_throughput": 405.097, "synch_weights_time_ms": 14.976}, "counters": {"num_env_steps_sampled": 748000, "num_env_steps_trained": 748000, "num_agent_steps_sampled": 2992000, "num_agent_steps_trained": 2992000}, "done": false, "training_iteration": 187, "trial_id": "3dae5_00000", "date": "2024-08-14_09-41-22", "timestamp": 1723642882, "time_this_iter_s": 10.414589166641235, "time_total_s": 3698.2263793945312, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b44438b0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3698.2263793945312, "iterations_since_restore": 187, "perf": {"cpu_util_percent": 29.55333333333333, "ram_util_percent": 83.17333333333333}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5935856894210534, "cur_kl_coeff": 0.000668173050507903, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.7567296182983136, "policy_loss": -0.007988758312252464, "vf_loss": 1.7647123892786643, "vf_explained_var": 0.044387315568469816, "kl": 0.00896749386090055, "entropy": 0.7295506947885746, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 354375.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.9275142510732013, "cur_kl_coeff": 0.060067749023437485, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.7665576806774848, "policy_loss": -0.016674246215729643, "vf_loss": 2.7826743918751915, "vf_explained_var": 0.32693078366536943, "kl": 0.009281724173726061, "entropy": 0.6877501129788697, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 354375.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 752000, "num_env_steps_trained": 752000, "num_agent_steps_sampled": 3008000, "num_agent_steps_trained": 3008000}, "env_runners": {"episode_reward_max": 173.09999999999974, "episode_reward_min": -388.79999999999995, "episode_reward_mean": 0.2039999999999651, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -736.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 131.60000000000005, "predator_policy": 596.0}, "policy_reward_mean": {"prey_policy": -67.15300000000008, "predator_policy": 67.255}, "custom_metrics": {}, "hist_stats": {"episode_reward": [37.40000000000026, -211.70000000000087, -51.799999999999805, 29.000000000000128, -318.80000000000007, 0.6999999999999545, -3.200000000000026, -365.5, 4.400000000000173, -0.6999999999998523, 26.20000000000008, 33.10000000000019, 22.900000000000105, 32.30000000000018, -12.19999999999991, 38.90000000000028, 100.99999999999986, -123.0000000000004, -94.20000000000067, 146.59999999999914, 13.699999999999923, 47.50000000000016, -5.099999999999877, -74.5000000000006, 103.19999999999985, -251.5999999999988, -39.89999999999984, -21.59999999999964, -38.299999999999585, 106.29999999999944, 151.89999999999932, -281.7999999999988, -235.60000000000082, 92.09999999999974, 44.60000000000026, 38.90000000000028, 130.19999999999976, 38.90000000000028, 136.49999999999977, 102.9999999999995, 134.4999999999998, 34.50000000000022, -34.59999999999955, 20.59999999999999, 71.30000000000003, 141.29999999999956, 21.10000000000027, -35.899999999999714, -124.50000000000111, 33.60000000000021, -21.799999999999862, -348.09999999999945, 35.600000000000236, -6.299999999999752, -62.600000000001316, 63.70000000000015, 149.0999999999997, 89.5, 50.20000000000021, 16.199999999999925, -44.29999999999995, 77.50000000000001, 28.60000000000013, -101.40000000000016, -388.79999999999995, -85.90000000000134, 3.9000000000000603, 40.0000000000003, 31.800000000000182, 33.2000000000002, 36.60000000000025, -177.80000000000067, 36.70000000000025, -20.200000000000017, 86.60000000000018, 19.09999999999999, 75.40000000000002, 1.5000000000001898, 98.29999999999944, 79.90000000000032, 19.399999999999974, 121.99999999999955, 36.40000000000025, -10.099999999999682, 92.59999999999977, 73.89999999999978, -15.799999999999704, -44.89999999999958, -5.09999999999982, -83.30000000000135, 25.90000000000007, 25.70000000000009, -51.400000000000645, 132.69999999999933, 29.10000000000015, 37.700000000000266, 37.80000000000027, -1.1999999999998354, 17.999999999999954, 173.09999999999974], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 7.399999999999965, -82.90000000000086, -365.79999999999995, 20.000000000000014, -355.8, 20.000000000000014, -0.9999999999999846, -528.9, -676.9, -199.3000000000004, 20.000000000000014, 20.000000000000014, -329.20000000000005, -517.5, -736.0, -687.6, 20.000000000000014, 20.000000000000014, -57.70000000000002, 20.000000000000014, -17.79999999999974, -1.9000000000000496, 20.000000000000014, 56.9000000000002, -672.0, 13.699999999999964, 11.599999999999964, -261.0, 15.799999999999963, 20.000000000000014, 17.899999999999988, 20.000000000000014, -592.0, -291.9999999999999, 20.000000000000014, 20.000000000000014, -236.20000000000036, 20.000000000000014, 119.59999999999972, -133.30000000000064, 20.000000000000014, 20.000000000000014, -180.50000000000026, 20.000000000000014, -255.09999999999877, -219.5000000000006, -656.0, 95.60000000000008, -9.39999999999989, -304.7999999999984, -327.7999999999991, -53.50000000000002, -45.39999999999978, -91.30000000000068, 13.699999999999964, -124.90000000000074, 11.599999999999964, 87.49999999999979, 15.799999999999963, 20.000000000000014, 101.89999999999988, -421.89999999999884, -524.8999999999999, -106.0000000000008, -382.6, -586.5999999999997, 85.69999999999996, 38.00000000000003, -386.3999999999987, 20.000000000000014, 17.899999999999988, 102.19999999999999, 20.000000000000014, 17.899999999999988, 20.000000000000014, 110.0, -362.499999999999, 74.0000000000001, 20.000000000000014, 20.000000000000014, 102.50000000000004, 13.699999999999964, 15.799999999999963, -201.10000000000056, 9.499999999999964, 17.899999999999977, -28.29999999999975, 49.1000000000001, 3.199999999999967, 15.799999999999963, 123.49999999999991, -222.1, 3.1999999999999615, -124.90000000000049, 20.000000000000014, -154.30000000000064, -152.2000000000005, -9.399999999999855, 20.000000000000014, -335.9999999999992, 45.200000000000095, -224.50000000000009, -361.59999999999997, 11.599999999999964, 20.000000000000014, 20.000000000000014, -112.30000000000078, -108.10000000000072, -74.50000000000071, -30.3999999999998, 61.100000000000065, 9.499999999999964, 131.60000000000005, 15.799999999999963, 64.69999999999999, -146.20000000000067, 52.40000000000013, 11.599999999999964, -30.399999999999793, 5.299999999999965, -139.60000000000068, 51.50000000000009, 20.000000000000014, 13.699999999999955, -3.0999999999999934, -248.20000000000007, 15.799999999999963, -373.00000000000006, -215.80000000000007, -92.2000000000007, -141.70000000000064, -108.10000000000076, 20.000000000000014, 20.000000000000014, 20.000000000000014, -15.699999999999747, 24.50000000000008, 20.000000000000014, 3.1999999999999615, 11.599999999999964, 20.000000000000014, -395.8, 20.000000000000014, 13.699999999999964, 20.000000000000014, -11.50000000000005, -36.699999999999996, 17.899999999999988, 67.70000000000016, -11.499999999999819, 11.599999999999964, 65.9000000000001, -95.50000000000068, -51.399999999999906, 17.899999999999988, 81.19999999999976, -19.899999999999743, 56.900000000000176, 20.000000000000014, -74.50000000000081, 17.899999999999988, 11.599999999999964, 106.39999999999989, 17.899999999999988, 9.499999999999964, -73.90000000000077, 15.799999999999963, 46.10000000000004, 12.499999999999964, -64.00000000000088, 74.89999999999984, 17.899999999999988, -112.70000000000053, -135.10000000000062, 3.1999999999999615, 17.899999999999988, -64.00000000000071, -72.40000000000069, -103.90000000000069, 9.499999999999964, 7.399999999999965, 20.000000000000014, -70.30000000000089, -108.10000000000076, -7.29999999999994, 7.399999999999965, 107.29999999999987, 20.000000000000014, -61.90000000000065, 17.899999999999988, 15.799999999999963, 15.799999999999963, 20.000000000000014, 9.499999999999964, -117.70000000000076, -13.599999999999818, 11.599999999999964, 75.50000000000003, 68.60000000000002], "policy_predator_policy_reward": [6.0, 4.0, 188.0, 49.0, 281.0, 3.0, 0.0, 10.0, 533.0, 354.0, 94.0, 86.0, 140.0, 166.0, 596.0, 292.0, 421.0, 251.0, 37.0, 0.0, 6.0, 18.0, 4.0, 11.0, 377.0, 261.0, 4.0, 3.0, 92.0, 141.0, 0.0, 1.0, 329.0, 344.0, 149.0, 0.0, 0.0, 122.0, 0.0, 7.0, 63.0, 64.0, 110.0, 98.0, 109.0, 121.0, 395.0, 406.0, 3.0, 14.0, 195.0, 186.0, 19.0, 40.0, 53.0, 3.0, 69.0, 6.0, 1.0, 2.0, 18.0, 12.0, 430.0, 235.0, 60.0, 193.0, 282.0, 311.0, 187.0, 206.0, 0.0, 1.0, 3.0, 5.0, 1.0, 0.0, 260.0, 129.0, 6.0, 3.0, 2.0, 10.0, 2.0, 3.0, 152.0, 5.0, 7.0, 24.0, 11.0, 8.0, 0.0, 2.0, 108.0, 132.0, 69.0, 0.0, 79.0, 103.0, 14.0, 9.0, 228.0, 41.0, 131.0, 107.0, 4.0, 0.0, 63.0, 23.0, 61.0, 59.0, 28.0, 5.0, 4.0, 4.0, 2.0, 7.0, 73.0, 71.0, 12.0, 23.0, 37.0, 53.0, 4.0, 2.0, 5.0, 13.0, 122.0, 9.0, 199.0, 1.0, 86.0, 62.0, 55.0, 37.0, 0.0, 0.0, 17.0, 6.0, 8.0, 2.0, 4.0, 1.0, 0.0, 198.0, 3.0, 0.0, 24.0, 4.0, 0.0, 1.0, 4.0, 15.0, 55.0, 50.0, 34.0, 1.0, 18.0, 19.0, 0.0, 3.0, 31.0, 45.0, 4.0, 0.0, 4.0, 5.0, 2.0, 46.0, 3.0, 31.0, 28.0, 35.0, 69.0, 10.0, 48.0, 39.0, 1.0, 40.0, 87.0, 6.0, 6.0, 3.0, 38.0, 38.0, 4.0, 60.0, 12.0, 6.0, 32.0, 39.0, 2.0, 2.0, 0.0, 2.0, 43.0, 64.0, 16.0, 4.0, 18.0, 11.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5869646280523264, "mean_inference_ms": 1.8151273441651816, "mean_action_processing_ms": 0.2508492627338663, "mean_env_wait_ms": 0.19619632149621172, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005049347877502441, "StateBufferConnector_ms": 0.0034437179565429688, "ViewRequirementAgentConnector_ms": 0.09309089183807373}, "num_episodes": 18, "episode_return_max": 173.09999999999974, "episode_return_min": -388.79999999999995, "episode_return_mean": 0.2039999999999651, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 3008000, "num_agent_steps_trained": 3008000, "num_env_steps_sampled": 752000, "num_env_steps_trained": 752000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 374.34771414429537, "num_env_steps_trained_throughput_per_sec": 374.34771414429537, "timesteps_total": 752000, "num_env_steps_sampled_lifetime": 752000, "num_agent_steps_sampled_lifetime": 3008000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 3008000, "timers": {"training_iteration_time_ms": 10907.649, "restore_workers_time_ms": 0.013, "training_step_time_ms": 10907.603, "sample_time_ms": 1357.183, "learn_time_ms": 9534.629, "learn_throughput": 419.523, "synch_weights_time_ms": 14.234}, "counters": {"num_env_steps_sampled": 752000, "num_env_steps_trained": 752000, "num_agent_steps_sampled": 3008000, "num_agent_steps_trained": 3008000}, "done": false, "training_iteration": 188, "trial_id": "3dae5_00000", "date": "2024-08-14_09-41-32", "timestamp": 1723642892, "time_this_iter_s": 10.708412885665894, "time_total_s": 3708.934792280197, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b38faee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3708.934792280197, "iterations_since_restore": 188, "perf": {"cpu_util_percent": 28.866666666666667, "ram_util_percent": 83.35333333333332}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.494850488834911, "cur_kl_coeff": 0.000668173050507903, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.7878124715159178, "policy_loss": -0.003617315032770709, "vf_loss": 1.7914266570535287, "vf_explained_var": 0.06503466910155362, "kl": 0.004681984139613623, "entropy": 0.5678263835175328, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 356265.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.458979121339384, "cur_kl_coeff": 0.060067749023437485, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.127457897499125, "policy_loss": -0.0057042448064460165, "vf_loss": 3.1327679530022636, "vf_explained_var": 0.18857329415265844, "kl": 0.006562449168829657, "entropy": 0.6402096469250936, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 356265.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 756000, "num_env_steps_trained": 756000, "num_agent_steps_sampled": 3024000, "num_agent_steps_trained": 3024000}, "env_runners": {"episode_reward_max": 315.5999999999999, "episode_reward_min": -388.79999999999995, "episode_reward_mean": 15.843999999999943, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -656.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 161.29999999999998, "predator_policy": 430.0}, "policy_reward_mean": {"prey_policy": -38.43800000000007, "predator_policy": 46.36}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-94.20000000000067, 146.59999999999914, 13.699999999999923, 47.50000000000016, -5.099999999999877, -74.5000000000006, 103.19999999999985, -251.5999999999988, -39.89999999999984, -21.59999999999964, -38.299999999999585, 106.29999999999944, 151.89999999999932, -281.7999999999988, -235.60000000000082, 92.09999999999974, 44.60000000000026, 38.90000000000028, 130.19999999999976, 38.90000000000028, 136.49999999999977, 102.9999999999995, 134.4999999999998, 34.50000000000022, -34.59999999999955, 20.59999999999999, 71.30000000000003, 141.29999999999956, 21.10000000000027, -35.899999999999714, -124.50000000000111, 33.60000000000021, -21.799999999999862, -348.09999999999945, 35.600000000000236, -6.299999999999752, -62.600000000001316, 63.70000000000015, 149.0999999999997, 89.5, 50.20000000000021, 16.199999999999925, -44.29999999999995, 77.50000000000001, 28.60000000000013, -101.40000000000016, -388.79999999999995, -85.90000000000134, 3.9000000000000603, 40.0000000000003, 31.800000000000182, 33.2000000000002, 36.60000000000025, -177.80000000000067, 36.70000000000025, -20.200000000000017, 86.60000000000018, 19.09999999999999, 75.40000000000002, 1.5000000000001898, 98.29999999999944, 79.90000000000032, 19.399999999999974, 121.99999999999955, 36.40000000000025, -10.099999999999682, 92.59999999999977, 73.89999999999978, -15.799999999999704, -44.89999999999958, -5.09999999999982, -83.30000000000135, 25.90000000000007, 25.70000000000009, -51.400000000000645, 132.69999999999933, 29.10000000000015, 37.700000000000266, 37.80000000000027, -1.1999999999998354, 17.999999999999954, 173.09999999999974, 16.59999999999993, -86.1, 129.1999999999997, 30.000000000000153, 44.000000000000355, -67.80000000000103, 69.60000000000014, 176.5999999999992, 11.199999999999944, 40.0000000000003, 2.6000000000002013, 36.60000000000025, 204.19999999999928, -71.60000000000018, -52.80000000000081, 24.00000000000004, 315.5999999999999, -18.89999999999955], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, -236.20000000000036, 20.000000000000014, 119.59999999999972, -133.30000000000064, 20.000000000000014, 20.000000000000014, -180.50000000000026, 20.000000000000014, -255.09999999999877, -219.5000000000006, -656.0, 95.60000000000008, -9.39999999999989, -304.7999999999984, -327.7999999999991, -53.50000000000002, -45.39999999999978, -91.30000000000068, 13.699999999999964, -124.90000000000074, 11.599999999999964, 87.49999999999979, 15.799999999999963, 20.000000000000014, 101.89999999999988, -421.89999999999884, -524.8999999999999, -106.0000000000008, -382.6, -586.5999999999997, 85.69999999999996, 38.00000000000003, -386.3999999999987, 20.000000000000014, 17.899999999999988, 102.19999999999999, 20.000000000000014, 17.899999999999988, 20.000000000000014, 110.0, -362.499999999999, 74.0000000000001, 20.000000000000014, 20.000000000000014, 102.50000000000004, 13.699999999999964, 15.799999999999963, -201.10000000000056, 9.499999999999964, 17.899999999999977, -28.29999999999975, 49.1000000000001, 3.199999999999967, 15.799999999999963, 123.49999999999991, -222.1, 3.1999999999999615, -124.90000000000049, 20.000000000000014, -154.30000000000064, -152.2000000000005, -9.399999999999855, 20.000000000000014, -335.9999999999992, 45.200000000000095, -224.50000000000009, -361.59999999999997, 11.599999999999964, 20.000000000000014, 20.000000000000014, -112.30000000000078, -108.10000000000072, -74.50000000000071, -30.3999999999998, 61.100000000000065, 9.499999999999964, 131.60000000000005, 15.799999999999963, 64.69999999999999, -146.20000000000067, 52.40000000000013, 11.599999999999964, -30.399999999999793, 5.299999999999965, -139.60000000000068, 51.50000000000009, 20.000000000000014, 13.699999999999955, -3.0999999999999934, -248.20000000000007, 15.799999999999963, -373.00000000000006, -215.80000000000007, -92.2000000000007, -141.70000000000064, -108.10000000000076, 20.000000000000014, 20.000000000000014, 20.000000000000014, -15.699999999999747, 24.50000000000008, 20.000000000000014, 3.1999999999999615, 11.599999999999964, 20.000000000000014, -395.8, 20.000000000000014, 13.699999999999964, 20.000000000000014, -11.50000000000005, -36.699999999999996, 17.899999999999988, 67.70000000000016, -11.499999999999819, 11.599999999999964, 65.9000000000001, -95.50000000000068, -51.399999999999906, 17.899999999999988, 81.19999999999976, -19.899999999999743, 56.900000000000176, 20.000000000000014, -74.50000000000081, 17.899999999999988, 11.599999999999964, 106.39999999999989, 17.899999999999988, 9.499999999999964, -73.90000000000077, 15.799999999999963, 46.10000000000004, 12.499999999999964, -64.00000000000088, 74.89999999999984, 17.899999999999988, -112.70000000000053, -135.10000000000062, 3.1999999999999615, 17.899999999999988, -64.00000000000071, -72.40000000000069, -103.90000000000069, 9.499999999999964, 7.399999999999965, 20.000000000000014, -70.30000000000089, -108.10000000000076, -7.29999999999994, 7.399999999999965, 107.29999999999987, 20.000000000000014, -61.90000000000065, 17.899999999999988, 15.799999999999963, 15.799999999999963, 20.000000000000014, 9.499999999999964, -117.70000000000076, -13.599999999999818, 11.599999999999964, 75.50000000000003, 68.60000000000002, 21.80000000000004, -68.20000000000088, -204.40000000000006, -36.699999999999754, 99.20000000000002, 20.000000000000014, 20.000000000000014, -21.999999999999744, 20.30000000000002, 19.70000000000001, -185.80000000000058, 20.000000000000014, 20.000000000000014, -9.400000000000132, 17.899999999999988, 157.69999999999985, -118.60000000000076, 15.799999999999963, 20.000000000000014, 20.000000000000014, 9.499999999999964, -40.89999999999976, 20.000000000000014, -30.39999999999978, 102.5, 91.70000000000002, 3.8000000000000522, -269.3999999999985, -72.40000000000089, -135.40000000000072, -7.299999999999891, 5.299999999999965, 140.29999999999987, 161.29999999999998, 11.599999999999964, -86.50000000000081], "policy_predator_policy_reward": [0.0, 122.0, 0.0, 7.0, 63.0, 64.0, 110.0, 98.0, 109.0, 121.0, 395.0, 406.0, 3.0, 14.0, 195.0, 186.0, 19.0, 40.0, 53.0, 3.0, 69.0, 6.0, 1.0, 2.0, 18.0, 12.0, 430.0, 235.0, 60.0, 193.0, 282.0, 311.0, 187.0, 206.0, 0.0, 1.0, 3.0, 5.0, 1.0, 0.0, 260.0, 129.0, 6.0, 3.0, 2.0, 10.0, 2.0, 3.0, 152.0, 5.0, 7.0, 24.0, 11.0, 8.0, 0.0, 2.0, 108.0, 132.0, 69.0, 0.0, 79.0, 103.0, 14.0, 9.0, 228.0, 41.0, 131.0, 107.0, 4.0, 0.0, 63.0, 23.0, 61.0, 59.0, 28.0, 5.0, 4.0, 4.0, 2.0, 7.0, 73.0, 71.0, 12.0, 23.0, 37.0, 53.0, 4.0, 2.0, 5.0, 13.0, 122.0, 9.0, 199.0, 1.0, 86.0, 62.0, 55.0, 37.0, 0.0, 0.0, 17.0, 6.0, 8.0, 2.0, 4.0, 1.0, 0.0, 198.0, 3.0, 0.0, 24.0, 4.0, 0.0, 1.0, 4.0, 15.0, 55.0, 50.0, 34.0, 1.0, 18.0, 19.0, 0.0, 3.0, 31.0, 45.0, 4.0, 0.0, 4.0, 5.0, 2.0, 46.0, 3.0, 31.0, 28.0, 35.0, 69.0, 10.0, 48.0, 39.0, 1.0, 40.0, 87.0, 6.0, 6.0, 3.0, 38.0, 38.0, 4.0, 60.0, 12.0, 6.0, 32.0, 39.0, 2.0, 2.0, 0.0, 2.0, 43.0, 64.0, 16.0, 4.0, 18.0, 11.0, 42.0, 21.0, 137.0, 18.0, 6.0, 4.0, 12.0, 20.0, 3.0, 1.0, 96.0, 2.0, 0.0, 59.0, 1.0, 0.0, 62.0, 52.0, 0.0, 0.0, 29.0, 5.0, 24.0, 23.0, 5.0, 5.0, 182.0, 12.0, 76.0, 79.0, 12.0, 14.0, 7.0, 7.0, 4.0, 52.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5868005680954802, "mean_inference_ms": 1.814993634616364, "mean_action_processing_ms": 0.2507455286201181, "mean_env_wait_ms": 0.19615559917483513, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004247307777404785, "StateBufferConnector_ms": 0.0033254623413085938, "ViewRequirementAgentConnector_ms": 0.09009075164794922}, "num_episodes": 18, "episode_return_max": 315.5999999999999, "episode_return_min": -388.79999999999995, "episode_return_mean": 15.843999999999943, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 3024000, "num_agent_steps_trained": 3024000, "num_env_steps_sampled": 756000, "num_env_steps_trained": 756000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 391.5962660631878, "num_env_steps_trained_throughput_per_sec": 391.5962660631878, "timesteps_total": 756000, "num_env_steps_sampled_lifetime": 756000, "num_agent_steps_sampled_lifetime": 3024000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 3024000, "timers": {"training_iteration_time_ms": 10832.037, "restore_workers_time_ms": 0.013, "training_step_time_ms": 10831.992, "sample_time_ms": 1339.72, "learn_time_ms": 9475.943, "learn_throughput": 422.122, "synch_weights_time_ms": 14.746}, "counters": {"num_env_steps_sampled": 756000, "num_env_steps_trained": 756000, "num_agent_steps_sampled": 3024000, "num_agent_steps_trained": 3024000}, "done": false, "training_iteration": 189, "trial_id": "3dae5_00000", "date": "2024-08-14_09-41-43", "timestamp": 1723642903, "time_this_iter_s": 10.220256090164185, "time_total_s": 3719.1550483703613, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b38ef700>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3719.1550483703613, "iterations_since_restore": 189, "perf": {"cpu_util_percent": 28.53333333333334, "ram_util_percent": 83.34666666666665}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4917503066794582, "cur_kl_coeff": 0.0003340865252539515, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.5389314533226073, "policy_loss": -0.002583155928366872, "vf_loss": 1.5415127870897767, "vf_explained_var": 0.06560723551366696, "kl": 0.005451568147128891, "entropy": 0.5653684613565919, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 358155.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9913395993293277, "cur_kl_coeff": 0.060067749023437485, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.2439298754646666, "policy_loss": -0.011758607834646547, "vf_loss": 2.2549055793928723, "vf_explained_var": -0.15645148410368218, "kl": 0.013033676305737986, "entropy": 0.6566551011075419, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 358155.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 760000, "num_env_steps_trained": 760000, "num_agent_steps_sampled": 3040000, "num_agent_steps_trained": 3040000}, "env_runners": {"episode_reward_max": 315.5999999999999, "episode_reward_min": -388.79999999999995, "episode_reward_mean": 21.858999999999938, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -395.8, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 178.39999999999992, "predator_policy": 260.0}, "policy_reward_mean": {"prey_policy": -20.2205000000001, "predator_policy": 31.15}, "custom_metrics": {}, "hist_stats": {"episode_reward": [130.19999999999976, 38.90000000000028, 136.49999999999977, 102.9999999999995, 134.4999999999998, 34.50000000000022, -34.59999999999955, 20.59999999999999, 71.30000000000003, 141.29999999999956, 21.10000000000027, -35.899999999999714, -124.50000000000111, 33.60000000000021, -21.799999999999862, -348.09999999999945, 35.600000000000236, -6.299999999999752, -62.600000000001316, 63.70000000000015, 149.0999999999997, 89.5, 50.20000000000021, 16.199999999999925, -44.29999999999995, 77.50000000000001, 28.60000000000013, -101.40000000000016, -388.79999999999995, -85.90000000000134, 3.9000000000000603, 40.0000000000003, 31.800000000000182, 33.2000000000002, 36.60000000000025, -177.80000000000067, 36.70000000000025, -20.200000000000017, 86.60000000000018, 19.09999999999999, 75.40000000000002, 1.5000000000001898, 98.29999999999944, 79.90000000000032, 19.399999999999974, 121.99999999999955, 36.40000000000025, -10.099999999999682, 92.59999999999977, 73.89999999999978, -15.799999999999704, -44.89999999999958, -5.09999999999982, -83.30000000000135, 25.90000000000007, 25.70000000000009, -51.400000000000645, 132.69999999999933, 29.10000000000015, 37.700000000000266, 37.80000000000027, -1.1999999999998354, 17.999999999999954, 173.09999999999974, 16.59999999999993, -86.1, 129.1999999999997, 30.000000000000153, 44.000000000000355, -67.80000000000103, 69.60000000000014, 176.5999999999992, 11.199999999999944, 40.0000000000003, 2.6000000000002013, 36.60000000000025, 204.19999999999928, -71.60000000000018, -52.80000000000081, 24.00000000000004, 315.5999999999999, -18.89999999999955, 13.60000000000002, -374.6999999999997, 147.49999999999918, 77.99999999999994, -34.09999999999956, 44.30000000000036, 30.400000000000148, 190.39999999999927, -165.80000000000095, 7.300000000000027, -2.8999999999997446, 39.800000000000296, 37.700000000000266, 35.600000000000236, 107.49999999999987, 30.000000000000146, 119.39999999999908, -0.2999999999998568], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [102.19999999999999, 20.000000000000014, 17.899999999999988, 20.000000000000014, 110.0, -362.499999999999, 74.0000000000001, 20.000000000000014, 20.000000000000014, 102.50000000000004, 13.699999999999964, 15.799999999999963, -201.10000000000056, 9.499999999999964, 17.899999999999977, -28.29999999999975, 49.1000000000001, 3.199999999999967, 15.799999999999963, 123.49999999999991, -222.1, 3.1999999999999615, -124.90000000000049, 20.000000000000014, -154.30000000000064, -152.2000000000005, -9.399999999999855, 20.000000000000014, -335.9999999999992, 45.200000000000095, -224.50000000000009, -361.59999999999997, 11.599999999999964, 20.000000000000014, 20.000000000000014, -112.30000000000078, -108.10000000000072, -74.50000000000071, -30.3999999999998, 61.100000000000065, 9.499999999999964, 131.60000000000005, 15.799999999999963, 64.69999999999999, -146.20000000000067, 52.40000000000013, 11.599999999999964, -30.399999999999793, 5.299999999999965, -139.60000000000068, 51.50000000000009, 20.000000000000014, 13.699999999999955, -3.0999999999999934, -248.20000000000007, 15.799999999999963, -373.00000000000006, -215.80000000000007, -92.2000000000007, -141.70000000000064, -108.10000000000076, 20.000000000000014, 20.000000000000014, 20.000000000000014, -15.699999999999747, 24.50000000000008, 20.000000000000014, 3.1999999999999615, 11.599999999999964, 20.000000000000014, -395.8, 20.000000000000014, 13.699999999999964, 20.000000000000014, -11.50000000000005, -36.699999999999996, 17.899999999999988, 67.70000000000016, -11.499999999999819, 11.599999999999964, 65.9000000000001, -95.50000000000068, -51.399999999999906, 17.899999999999988, 81.19999999999976, -19.899999999999743, 56.900000000000176, 20.000000000000014, -74.50000000000081, 17.899999999999988, 11.599999999999964, 106.39999999999989, 17.899999999999988, 9.499999999999964, -73.90000000000077, 15.799999999999963, 46.10000000000004, 12.499999999999964, -64.00000000000088, 74.89999999999984, 17.899999999999988, -112.70000000000053, -135.10000000000062, 3.1999999999999615, 17.899999999999988, -64.00000000000071, -72.40000000000069, -103.90000000000069, 9.499999999999964, 7.399999999999965, 20.000000000000014, -70.30000000000089, -108.10000000000076, -7.29999999999994, 7.399999999999965, 107.29999999999987, 20.000000000000014, -61.90000000000065, 17.899999999999988, 15.799999999999963, 15.799999999999963, 20.000000000000014, 9.499999999999964, -117.70000000000076, -13.599999999999818, 11.599999999999964, 75.50000000000003, 68.60000000000002, 21.80000000000004, -68.20000000000088, -204.40000000000006, -36.699999999999754, 99.20000000000002, 20.000000000000014, 20.000000000000014, -21.999999999999744, 20.30000000000002, 19.70000000000001, -185.80000000000058, 20.000000000000014, 20.000000000000014, -9.400000000000132, 17.899999999999988, 157.69999999999985, -118.60000000000076, 15.799999999999963, 20.000000000000014, 20.000000000000014, 9.499999999999964, -40.89999999999976, 20.000000000000014, -30.39999999999978, 102.5, 91.70000000000002, 3.8000000000000522, -269.3999999999985, -72.40000000000089, -135.40000000000072, -7.299999999999891, 5.299999999999965, 140.29999999999987, 161.29999999999998, 11.599999999999964, -86.50000000000081, -26.199999999999747, 15.799999999999963, -281.79999999999984, -289.9000000000001, 20.000000000000014, 111.49999999999977, 105.79999999999995, -116.80000000000072, -34.899999999999764, -89.20000000000056, 17.899999999999988, 25.400000000000098, 13.699999999999964, 13.699999999999964, -21.999999999999744, 178.39999999999992, -26.199999999999747, -334.5999999999999, -74.50000000000082, 15.799999999999963, -61.90000000000068, 20.000000000000014, 20.000000000000014, 15.799999999999963, 20.000000000000014, 13.699999999999964, 11.599999999999964, 20.000000000000014, 130.4, -82.9000000000006, 20.000000000000014, -0.9999999999999846, 114.49999999999955, -87.1000000000008, 1.0999999999999865, -51.399999999999935], "policy_predator_policy_reward": [3.0, 5.0, 1.0, 0.0, 260.0, 129.0, 6.0, 3.0, 2.0, 10.0, 2.0, 3.0, 152.0, 5.0, 7.0, 24.0, 11.0, 8.0, 0.0, 2.0, 108.0, 132.0, 69.0, 0.0, 79.0, 103.0, 14.0, 9.0, 228.0, 41.0, 131.0, 107.0, 4.0, 0.0, 63.0, 23.0, 61.0, 59.0, 28.0, 5.0, 4.0, 4.0, 2.0, 7.0, 73.0, 71.0, 12.0, 23.0, 37.0, 53.0, 4.0, 2.0, 5.0, 13.0, 122.0, 9.0, 199.0, 1.0, 86.0, 62.0, 55.0, 37.0, 0.0, 0.0, 17.0, 6.0, 8.0, 2.0, 4.0, 1.0, 0.0, 198.0, 3.0, 0.0, 24.0, 4.0, 0.0, 1.0, 4.0, 15.0, 55.0, 50.0, 34.0, 1.0, 18.0, 19.0, 0.0, 3.0, 31.0, 45.0, 4.0, 0.0, 4.0, 5.0, 2.0, 46.0, 3.0, 31.0, 28.0, 35.0, 69.0, 10.0, 48.0, 39.0, 1.0, 40.0, 87.0, 6.0, 6.0, 3.0, 38.0, 38.0, 4.0, 60.0, 12.0, 6.0, 32.0, 39.0, 2.0, 2.0, 0.0, 2.0, 43.0, 64.0, 16.0, 4.0, 18.0, 11.0, 42.0, 21.0, 137.0, 18.0, 6.0, 4.0, 12.0, 20.0, 3.0, 1.0, 96.0, 2.0, 0.0, 59.0, 1.0, 0.0, 62.0, 52.0, 0.0, 0.0, 29.0, 5.0, 24.0, 23.0, 5.0, 5.0, 182.0, 12.0, 76.0, 79.0, 12.0, 14.0, 7.0, 7.0, 4.0, 52.0, 2.0, 22.0, 196.0, 1.0, 6.0, 10.0, 55.0, 34.0, 42.0, 48.0, 0.0, 1.0, 3.0, 0.0, 20.0, 14.0, 174.0, 21.0, 37.0, 29.0, 0.0, 39.0, 2.0, 2.0, 1.0, 3.0, 0.0, 4.0, 32.0, 28.0, 1.0, 10.0, 48.0, 44.0, 31.0, 19.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5870771591628011, "mean_inference_ms": 1.8151104734680918, "mean_action_processing_ms": 0.25095424091137064, "mean_env_wait_ms": 0.196135109139531, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004040718078613281, "StateBufferConnector_ms": 0.006924152374267578, "ViewRequirementAgentConnector_ms": 0.1020050048828125}, "num_episodes": 18, "episode_return_max": 315.5999999999999, "episode_return_min": -388.79999999999995, "episode_return_mean": 21.858999999999938, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 3040000, "num_agent_steps_trained": 3040000, "num_env_steps_sampled": 760000, "num_env_steps_trained": 760000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 364.73166512720593, "num_env_steps_trained_throughput_per_sec": 364.73166512720593, "timesteps_total": 760000, "num_env_steps_sampled_lifetime": 760000, "num_agent_steps_sampled_lifetime": 3040000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 3040000, "timers": {"training_iteration_time_ms": 10748.2, "restore_workers_time_ms": 0.013, "training_step_time_ms": 10748.161, "sample_time_ms": 1360.329, "learn_time_ms": 9372.659, "learn_throughput": 426.773, "synch_weights_time_ms": 14.128}, "counters": {"num_env_steps_sampled": 760000, "num_env_steps_trained": 760000, "num_agent_steps_sampled": 3040000, "num_agent_steps_trained": 3040000}, "done": false, "training_iteration": 190, "trial_id": "3dae5_00000", "date": "2024-08-14_09-41-54", "timestamp": 1723642914, "time_this_iter_s": 10.988379955291748, "time_total_s": 3730.143428325653, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3867940>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3730.143428325653, "iterations_since_restore": 190, "perf": {"cpu_util_percent": 32.64375, "ram_util_percent": 83.11250000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.313179152715143, "cur_kl_coeff": 0.0003340865252539515, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.0573896578695408, "policy_loss": -0.004289699752479989, "vf_loss": 2.0616776857741925, "vf_explained_var": 0.08001309762556086, "kl": 0.005013148005336717, "entropy": 0.644816703613473, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 360045.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.5118060011870016, "cur_kl_coeff": 0.060067749023437485, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.5680252979672145, "policy_loss": -0.008554767697147789, "vf_loss": 2.5758444055047613, "vf_explained_var": 0.0965849518145203, "kl": 0.01224694787249747, "entropy": 0.6390726203325564, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 360045.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 764000, "num_env_steps_trained": 764000, "num_agent_steps_sampled": 3056000, "num_agent_steps_trained": 3056000}, "env_runners": {"episode_reward_max": 315.5999999999999, "episode_reward_min": -563.4, "episode_reward_mean": 14.880999999999974, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 178.39999999999992, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -20.08450000000012, "predator_policy": 27.525}, "custom_metrics": {}, "hist_stats": {"episode_reward": [16.199999999999925, -44.29999999999995, 77.50000000000001, 28.60000000000013, -101.40000000000016, -388.79999999999995, -85.90000000000134, 3.9000000000000603, 40.0000000000003, 31.800000000000182, 33.2000000000002, 36.60000000000025, -177.80000000000067, 36.70000000000025, -20.200000000000017, 86.60000000000018, 19.09999999999999, 75.40000000000002, 1.5000000000001898, 98.29999999999944, 79.90000000000032, 19.399999999999974, 121.99999999999955, 36.40000000000025, -10.099999999999682, 92.59999999999977, 73.89999999999978, -15.799999999999704, -44.89999999999958, -5.09999999999982, -83.30000000000135, 25.90000000000007, 25.70000000000009, -51.400000000000645, 132.69999999999933, 29.10000000000015, 37.700000000000266, 37.80000000000027, -1.1999999999998354, 17.999999999999954, 173.09999999999974, 16.59999999999993, -86.1, 129.1999999999997, 30.000000000000153, 44.000000000000355, -67.80000000000103, 69.60000000000014, 176.5999999999992, 11.199999999999944, 40.0000000000003, 2.6000000000002013, 36.60000000000025, 204.19999999999928, -71.60000000000018, -52.80000000000081, 24.00000000000004, 315.5999999999999, -18.89999999999955, 13.60000000000002, -374.6999999999997, 147.49999999999918, 77.99999999999994, -34.09999999999956, 44.30000000000036, 30.400000000000148, 190.39999999999927, -165.80000000000095, 7.300000000000027, -2.8999999999997446, 39.800000000000296, 37.700000000000266, 35.600000000000236, 107.49999999999987, 30.000000000000146, 119.39999999999908, -0.2999999999998568, 38.60000000000028, 39.800000000000296, 4.700000000000143, 40.3000000000002, 136.79999999999944, -16.099999999999504, 8.999999999999924, 31.700000000000188, 27.700000000000102, 12.700000000000047, -2.199999999999737, -34.19999999999956, 10.400000000000025, -2.9999999999998725, 29.100000000000126, 35.80000000000024, 3.1999999999999384, -9.499999999999627, 23.900000000000066, -563.4, 0.4000000000002427, 10.300000000000074, 95.9999999999996], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [11.599999999999964, -30.399999999999793, 5.299999999999965, -139.60000000000068, 51.50000000000009, 20.000000000000014, 13.699999999999955, -3.0999999999999934, -248.20000000000007, 15.799999999999963, -373.00000000000006, -215.80000000000007, -92.2000000000007, -141.70000000000064, -108.10000000000076, 20.000000000000014, 20.000000000000014, 20.000000000000014, -15.699999999999747, 24.50000000000008, 20.000000000000014, 3.1999999999999615, 11.599999999999964, 20.000000000000014, -395.8, 20.000000000000014, 13.699999999999964, 20.000000000000014, -11.50000000000005, -36.699999999999996, 17.899999999999988, 67.70000000000016, -11.499999999999819, 11.599999999999964, 65.9000000000001, -95.50000000000068, -51.399999999999906, 17.899999999999988, 81.19999999999976, -19.899999999999743, 56.900000000000176, 20.000000000000014, -74.50000000000081, 17.899999999999988, 11.599999999999964, 106.39999999999989, 17.899999999999988, 9.499999999999964, -73.90000000000077, 15.799999999999963, 46.10000000000004, 12.499999999999964, -64.00000000000088, 74.89999999999984, 17.899999999999988, -112.70000000000053, -135.10000000000062, 3.1999999999999615, 17.899999999999988, -64.00000000000071, -72.40000000000069, -103.90000000000069, 9.499999999999964, 7.399999999999965, 20.000000000000014, -70.30000000000089, -108.10000000000076, -7.29999999999994, 7.399999999999965, 107.29999999999987, 20.000000000000014, -61.90000000000065, 17.899999999999988, 15.799999999999963, 15.799999999999963, 20.000000000000014, 9.499999999999964, -117.70000000000076, -13.599999999999818, 11.599999999999964, 75.50000000000003, 68.60000000000002, 21.80000000000004, -68.20000000000088, -204.40000000000006, -36.699999999999754, 99.20000000000002, 20.000000000000014, 20.000000000000014, -21.999999999999744, 20.30000000000002, 19.70000000000001, -185.80000000000058, 20.000000000000014, 20.000000000000014, -9.400000000000132, 17.899999999999988, 157.69999999999985, -118.60000000000076, 15.799999999999963, 20.000000000000014, 20.000000000000014, 9.499999999999964, -40.89999999999976, 20.000000000000014, -30.39999999999978, 102.5, 91.70000000000002, 3.8000000000000522, -269.3999999999985, -72.40000000000089, -135.40000000000072, -7.299999999999891, 5.299999999999965, 140.29999999999987, 161.29999999999998, 11.599999999999964, -86.50000000000081, -26.199999999999747, 15.799999999999963, -281.79999999999984, -289.9000000000001, 20.000000000000014, 111.49999999999977, 105.79999999999995, -116.80000000000072, -34.899999999999764, -89.20000000000056, 17.899999999999988, 25.400000000000098, 13.699999999999964, 13.699999999999964, -21.999999999999744, 178.39999999999992, -26.199999999999747, -334.5999999999999, -74.50000000000082, 15.799999999999963, -61.90000000000068, 20.000000000000014, 20.000000000000014, 15.799999999999963, 20.000000000000014, 13.699999999999964, 11.599999999999964, 20.000000000000014, 130.4, -82.9000000000006, 20.000000000000014, -0.9999999999999846, 114.49999999999955, -87.1000000000008, 1.0999999999999865, -51.399999999999935, 20.000000000000014, 11.599999999999964, 15.799999999999963, 20.000000000000014, -61.90000000000041, -30.399999999999764, 26.000000000000085, -15.699999999999747, 96.79999999999987, 20.000000000000014, -68.20000000000074, 1.0999999999999865, -77.80000000000055, 15.799999999999963, 20.000000000000014, -70.30000000000089, 10.399999999999965, 5.299999999999965, 1.999999999999991, -49.29999999999976, -24.099999999999753, -24.099999999999746, -131.20000000000073, 20.000000000000014, 20.000000000000014, -76.60000000000069, 13.699999999999964, -162.70000000000064, 7.399999999999965, 13.699999999999964, 31.70000000000022, -82.90000000000076, 11.599999999999964, -75.40000000000038, -68.2000000000009, 13.699999999999964, 20.90000000000003, -64.0000000000006, -400.0, -366.4, -9.399999999999855, -26.199999999999747, 3.1999999999999615, -19.899999999999757, 68.59999999999985, 4.399999999999968], "policy_predator_policy_reward": [12.0, 23.0, 37.0, 53.0, 4.0, 2.0, 5.0, 13.0, 122.0, 9.0, 199.0, 1.0, 86.0, 62.0, 55.0, 37.0, 0.0, 0.0, 17.0, 6.0, 8.0, 2.0, 4.0, 1.0, 0.0, 198.0, 3.0, 0.0, 24.0, 4.0, 0.0, 1.0, 4.0, 15.0, 55.0, 50.0, 34.0, 1.0, 18.0, 19.0, 0.0, 3.0, 31.0, 45.0, 4.0, 0.0, 4.0, 5.0, 2.0, 46.0, 3.0, 31.0, 28.0, 35.0, 69.0, 10.0, 48.0, 39.0, 1.0, 40.0, 87.0, 6.0, 6.0, 3.0, 38.0, 38.0, 4.0, 60.0, 12.0, 6.0, 32.0, 39.0, 2.0, 2.0, 0.0, 2.0, 43.0, 64.0, 16.0, 4.0, 18.0, 11.0, 42.0, 21.0, 137.0, 18.0, 6.0, 4.0, 12.0, 20.0, 3.0, 1.0, 96.0, 2.0, 0.0, 59.0, 1.0, 0.0, 62.0, 52.0, 0.0, 0.0, 29.0, 5.0, 24.0, 23.0, 5.0, 5.0, 182.0, 12.0, 76.0, 79.0, 12.0, 14.0, 7.0, 7.0, 4.0, 52.0, 2.0, 22.0, 196.0, 1.0, 6.0, 10.0, 55.0, 34.0, 42.0, 48.0, 0.0, 1.0, 3.0, 0.0, 20.0, 14.0, 174.0, 21.0, 37.0, 29.0, 0.0, 39.0, 2.0, 2.0, 1.0, 3.0, 0.0, 4.0, 32.0, 28.0, 1.0, 10.0, 48.0, 44.0, 31.0, 19.0, 3.0, 4.0, 2.0, 2.0, 47.0, 50.0, 13.0, 17.0, 6.0, 14.0, 42.0, 9.0, 31.0, 40.0, 39.0, 43.0, 7.0, 5.0, 27.0, 33.0, 22.0, 24.0, 72.0, 5.0, 21.0, 46.0, 84.0, 62.0, 6.0, 2.0, 39.0, 48.0, 39.0, 28.0, 42.0, 3.0, 31.0, 36.0, 3.0, 200.0, 22.0, 14.0, 4.0, 23.0, 12.0, 11.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5877790055117691, "mean_inference_ms": 1.814523952452812, "mean_action_processing_ms": 0.25126294451451586, "mean_env_wait_ms": 0.1961853134543903, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0036410093307495117, "StateBufferConnector_ms": 0.0069495439529418945, "ViewRequirementAgentConnector_ms": 0.10670006275177002}, "num_episodes": 23, "episode_return_max": 315.5999999999999, "episode_return_min": -563.4, "episode_return_mean": 14.880999999999974, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 3056000, "num_agent_steps_trained": 3056000, "num_env_steps_sampled": 764000, "num_env_steps_trained": 764000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 392.0659877564909, "num_env_steps_trained_throughput_per_sec": 392.0659877564909, "timesteps_total": 764000, "num_env_steps_sampled_lifetime": 764000, "num_agent_steps_sampled_lifetime": 3056000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 3056000, "timers": {"training_iteration_time_ms": 10713.146, "restore_workers_time_ms": 0.013, "training_step_time_ms": 10713.107, "sample_time_ms": 1358.539, "learn_time_ms": 9339.603, "learn_throughput": 428.284, "synch_weights_time_ms": 13.927}, "counters": {"num_env_steps_sampled": 764000, "num_env_steps_trained": 764000, "num_agent_steps_sampled": 3056000, "num_agent_steps_trained": 3056000}, "done": false, "training_iteration": 191, "trial_id": "3dae5_00000", "date": "2024-08-14_09-42-04", "timestamp": 1723642924, "time_this_iter_s": 10.20801305770874, "time_total_s": 3740.351441383362, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3867280>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3740.351441383362, "iterations_since_restore": 191, "perf": {"cpu_util_percent": 31.907142857142855, "ram_util_percent": 83.66428571428573}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7979518210446392, "cur_kl_coeff": 0.0003340865252539515, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.552539234911954, "policy_loss": -0.005820156461633151, "vf_loss": 1.5583557438598108, "vf_explained_var": 0.05800191678067364, "kl": 0.01091133178977341, "entropy": 0.703518363817659, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 361935.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.145005238749993, "cur_kl_coeff": 0.060067749023437485, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.975544601521164, "policy_loss": -0.006320881062044353, "vf_loss": 2.981340264012574, "vf_explained_var": 0.057954749449220286, "kl": 0.008743804199026182, "entropy": 0.7399561476139795, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 361935.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 768000, "num_env_steps_trained": 768000, "num_agent_steps_sampled": 3072000, "num_agent_steps_trained": 3072000}, "env_runners": {"episode_reward_max": 315.5999999999999, "episode_reward_min": -563.4, "episode_reward_mean": 25.542999999999964, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 178.39999999999992, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -11.963500000000103, "predator_policy": 24.735}, "custom_metrics": {}, "hist_stats": {"episode_reward": [121.99999999999955, 36.40000000000025, -10.099999999999682, 92.59999999999977, 73.89999999999978, -15.799999999999704, -44.89999999999958, -5.09999999999982, -83.30000000000135, 25.90000000000007, 25.70000000000009, -51.400000000000645, 132.69999999999933, 29.10000000000015, 37.700000000000266, 37.80000000000027, -1.1999999999998354, 17.999999999999954, 173.09999999999974, 16.59999999999993, -86.1, 129.1999999999997, 30.000000000000153, 44.000000000000355, -67.80000000000103, 69.60000000000014, 176.5999999999992, 11.199999999999944, 40.0000000000003, 2.6000000000002013, 36.60000000000025, 204.19999999999928, -71.60000000000018, -52.80000000000081, 24.00000000000004, 315.5999999999999, -18.89999999999955, 13.60000000000002, -374.6999999999997, 147.49999999999918, 77.99999999999994, -34.09999999999956, 44.30000000000036, 30.400000000000148, 190.39999999999927, -165.80000000000095, 7.300000000000027, -2.8999999999997446, 39.800000000000296, 37.700000000000266, 35.600000000000236, 107.49999999999987, 30.000000000000146, 119.39999999999908, -0.2999999999998568, 38.60000000000028, 39.800000000000296, 4.700000000000143, 40.3000000000002, 136.79999999999944, -16.099999999999504, 8.999999999999924, 31.700000000000188, 27.700000000000102, 12.700000000000047, -2.199999999999737, -34.19999999999956, 10.400000000000025, -2.9999999999998725, 29.100000000000126, 35.80000000000024, 3.1999999999999384, -9.499999999999627, 23.900000000000066, -563.4, 0.4000000000002427, 10.300000000000074, 95.9999999999996, 145.39999999999912, 61.40000000000017, -125.2000000000003, 4.400000000000066, 33.10000000000023, 68.59999999999997, 21.099999999999994, 21.800000000000015, 37.80000000000026, 37.30000000000026, 26.4000000000001, 183.399999999999, 23.50000000000003, 7.000000000000149, 107.59999999999943, 40.0000000000003, 33.200000000000195, 40.90000000000031, 29.300000000000153, 19.19999999999997, 13.100000000000035, 103.1999999999995], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [11.599999999999964, 106.39999999999989, 17.899999999999988, 9.499999999999964, -73.90000000000077, 15.799999999999963, 46.10000000000004, 12.499999999999964, -64.00000000000088, 74.89999999999984, 17.899999999999988, -112.70000000000053, -135.10000000000062, 3.1999999999999615, 17.899999999999988, -64.00000000000071, -72.40000000000069, -103.90000000000069, 9.499999999999964, 7.399999999999965, 20.000000000000014, -70.30000000000089, -108.10000000000076, -7.29999999999994, 7.399999999999965, 107.29999999999987, 20.000000000000014, -61.90000000000065, 17.899999999999988, 15.799999999999963, 15.799999999999963, 20.000000000000014, 9.499999999999964, -117.70000000000076, -13.599999999999818, 11.599999999999964, 75.50000000000003, 68.60000000000002, 21.80000000000004, -68.20000000000088, -204.40000000000006, -36.699999999999754, 99.20000000000002, 20.000000000000014, 20.000000000000014, -21.999999999999744, 20.30000000000002, 19.70000000000001, -185.80000000000058, 20.000000000000014, 20.000000000000014, -9.400000000000132, 17.899999999999988, 157.69999999999985, -118.60000000000076, 15.799999999999963, 20.000000000000014, 20.000000000000014, 9.499999999999964, -40.89999999999976, 20.000000000000014, -30.39999999999978, 102.5, 91.70000000000002, 3.8000000000000522, -269.3999999999985, -72.40000000000089, -135.40000000000072, -7.299999999999891, 5.299999999999965, 140.29999999999987, 161.29999999999998, 11.599999999999964, -86.50000000000081, -26.199999999999747, 15.799999999999963, -281.79999999999984, -289.9000000000001, 20.000000000000014, 111.49999999999977, 105.79999999999995, -116.80000000000072, -34.899999999999764, -89.20000000000056, 17.899999999999988, 25.400000000000098, 13.699999999999964, 13.699999999999964, -21.999999999999744, 178.39999999999992, -26.199999999999747, -334.5999999999999, -74.50000000000082, 15.799999999999963, -61.90000000000068, 20.000000000000014, 20.000000000000014, 15.799999999999963, 20.000000000000014, 13.699999999999964, 11.599999999999964, 20.000000000000014, 130.4, -82.9000000000006, 20.000000000000014, -0.9999999999999846, 114.49999999999955, -87.1000000000008, 1.0999999999999865, -51.399999999999935, 20.000000000000014, 11.599999999999964, 15.799999999999963, 20.000000000000014, -61.90000000000041, -30.399999999999764, 26.000000000000085, -15.699999999999747, 96.79999999999987, 20.000000000000014, -68.20000000000074, 1.0999999999999865, -77.80000000000055, 15.799999999999963, 20.000000000000014, -70.30000000000089, 10.399999999999965, 5.299999999999965, 1.999999999999991, -49.29999999999976, -24.099999999999753, -24.099999999999746, -131.20000000000073, 20.000000000000014, 20.000000000000014, -76.60000000000069, 13.699999999999964, -162.70000000000064, 7.399999999999965, 13.699999999999964, 31.70000000000022, -82.90000000000076, 11.599999999999964, -75.40000000000038, -68.2000000000009, 13.699999999999964, 20.90000000000003, -64.0000000000006, -400.0, -366.4, -9.399999999999855, -26.199999999999747, 3.1999999999999615, -19.899999999999757, 68.59999999999985, 4.399999999999968, 79.69999999999999, 46.70000000000012, -49.29999999999976, 76.70000000000012, -290.50000000000006, 5.299999999999965, 23.00000000000007, -118.60000000000076, 23.900000000000105, -38.79999999999976, 10.09999999999997, 36.50000000000016, 7.399999999999965, -4.299999999999958, 5.299999999999965, 9.499999999999964, 17.899999999999988, 17.899999999999988, 20.000000000000014, 5.299999999999965, 20.000000000000014, -13.599999999999808, 113.59999999999985, 66.79999999999997, -0.9999999999999846, 9.499999999999964, -28.29999999999975, 5.299999999999965, 89.89999999999986, 13.699999999999964, 20.000000000000014, 20.000000000000014, 16.69999999999997, 9.499999999999964, 20.000000000000014, 20.90000000000003, -38.7999999999998, 1.0999999999999865, -80.80000000000004, 20.000000000000014, -0.9999999999999846, -19.89999999999975, 81.19999999999996, -1.0000000000000098], "policy_predator_policy_reward": [4.0, 0.0, 4.0, 5.0, 2.0, 46.0, 3.0, 31.0, 28.0, 35.0, 69.0, 10.0, 48.0, 39.0, 1.0, 40.0, 87.0, 6.0, 6.0, 3.0, 38.0, 38.0, 4.0, 60.0, 12.0, 6.0, 32.0, 39.0, 2.0, 2.0, 0.0, 2.0, 43.0, 64.0, 16.0, 4.0, 18.0, 11.0, 42.0, 21.0, 137.0, 18.0, 6.0, 4.0, 12.0, 20.0, 3.0, 1.0, 96.0, 2.0, 0.0, 59.0, 1.0, 0.0, 62.0, 52.0, 0.0, 0.0, 29.0, 5.0, 24.0, 23.0, 5.0, 5.0, 182.0, 12.0, 76.0, 79.0, 12.0, 14.0, 7.0, 7.0, 4.0, 52.0, 2.0, 22.0, 196.0, 1.0, 6.0, 10.0, 55.0, 34.0, 42.0, 48.0, 0.0, 1.0, 3.0, 0.0, 20.0, 14.0, 174.0, 21.0, 37.0, 29.0, 0.0, 39.0, 2.0, 2.0, 1.0, 3.0, 0.0, 4.0, 32.0, 28.0, 1.0, 10.0, 48.0, 44.0, 31.0, 19.0, 3.0, 4.0, 2.0, 2.0, 47.0, 50.0, 13.0, 17.0, 6.0, 14.0, 42.0, 9.0, 31.0, 40.0, 39.0, 43.0, 7.0, 5.0, 27.0, 33.0, 22.0, 24.0, 72.0, 5.0, 21.0, 46.0, 84.0, 62.0, 6.0, 2.0, 39.0, 48.0, 39.0, 28.0, 42.0, 3.0, 31.0, 36.0, 3.0, 200.0, 22.0, 14.0, 4.0, 23.0, 12.0, 11.0, 11.0, 8.0, 1.0, 33.0, 155.0, 5.0, 66.0, 34.0, 27.0, 21.0, 17.0, 5.0, 0.0, 18.0, 7.0, 0.0, 0.0, 2.0, 5.0, 7.0, 6.0, 14.0, 1.0, 2.0, 5.0, 10.0, 7.0, 23.0, 3.0, 1.0, 0.0, 0.0, 5.0, 2.0, 0.0, 0.0, 35.0, 32.0, 46.0, 34.0, 19.0, 15.0, 1.0, 22.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.58780588660912, "mean_inference_ms": 1.815387019193051, "mean_action_processing_ms": 0.2514756240010358, "mean_env_wait_ms": 0.19606676437690068, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0036464929580688477, "StateBufferConnector_ms": 0.006722807884216309, "ViewRequirementAgentConnector_ms": 0.10683536529541016}, "num_episodes": 22, "episode_return_max": 315.5999999999999, "episode_return_min": -563.4, "episode_return_mean": 25.542999999999964, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 3072000, "num_agent_steps_trained": 3072000, "num_env_steps_sampled": 768000, "num_env_steps_trained": 768000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 380.08960547492353, "num_env_steps_trained_throughput_per_sec": 380.08960547492353, "timesteps_total": 768000, "num_env_steps_sampled_lifetime": 768000, "num_agent_steps_sampled_lifetime": 3072000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 3072000, "timers": {"training_iteration_time_ms": 10680.947, "restore_workers_time_ms": 0.013, "training_step_time_ms": 10680.907, "sample_time_ms": 1354.242, "learn_time_ms": 9311.575, "learn_throughput": 429.573, "synch_weights_time_ms": 13.948}, "counters": {"num_env_steps_sampled": 768000, "num_env_steps_trained": 768000, "num_agent_steps_sampled": 3072000, "num_agent_steps_trained": 3072000}, "done": false, "training_iteration": 192, "trial_id": "3dae5_00000", "date": "2024-08-14_09-42-14", "timestamp": 1723642934, "time_this_iter_s": 10.554791927337646, "time_total_s": 3750.9062333106995, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b44d0790>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3750.9062333106995, "iterations_since_restore": 192, "perf": {"cpu_util_percent": 29.073333333333338, "ram_util_percent": 83.75333333333334}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.460678014174971, "cur_kl_coeff": 0.0003340865252539515, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.599781513245648, "policy_loss": -0.002589610268031715, "vf_loss": 1.6023689767986378, "vf_explained_var": 0.15968196379444585, "kl": 0.006425410385578619, "entropy": 0.5567319761350672, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 363825.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.5187121487483775, "cur_kl_coeff": 0.060067749023437485, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.667658051233443, "policy_loss": -0.002359152940057573, "vf_loss": 3.6696657222414775, "vf_explained_var": 0.08222385175013669, "kl": 0.005851358096495062, "entropy": 0.7030444155925165, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 363825.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 772000, "num_env_steps_trained": 772000, "num_agent_steps_sampled": 3088000, "num_agent_steps_trained": 3088000}, "env_runners": {"episode_reward_max": 315.5999999999999, "episode_reward_min": -580.1, "episode_reward_mean": 20.66899999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 178.39999999999992, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -15.465500000000059, "predator_policy": 25.8}, "custom_metrics": {}, "hist_stats": {"episode_reward": [173.09999999999974, 16.59999999999993, -86.1, 129.1999999999997, 30.000000000000153, 44.000000000000355, -67.80000000000103, 69.60000000000014, 176.5999999999992, 11.199999999999944, 40.0000000000003, 2.6000000000002013, 36.60000000000025, 204.19999999999928, -71.60000000000018, -52.80000000000081, 24.00000000000004, 315.5999999999999, -18.89999999999955, 13.60000000000002, -374.6999999999997, 147.49999999999918, 77.99999999999994, -34.09999999999956, 44.30000000000036, 30.400000000000148, 190.39999999999927, -165.80000000000095, 7.300000000000027, -2.8999999999997446, 39.800000000000296, 37.700000000000266, 35.600000000000236, 107.49999999999987, 30.000000000000146, 119.39999999999908, -0.2999999999998568, 38.60000000000028, 39.800000000000296, 4.700000000000143, 40.3000000000002, 136.79999999999944, -16.099999999999504, 8.999999999999924, 31.700000000000188, 27.700000000000102, 12.700000000000047, -2.199999999999737, -34.19999999999956, 10.400000000000025, -2.9999999999998725, 29.100000000000126, 35.80000000000024, 3.1999999999999384, -9.499999999999627, 23.900000000000066, -563.4, 0.4000000000002427, 10.300000000000074, 95.9999999999996, 145.39999999999912, 61.40000000000017, -125.2000000000003, 4.400000000000066, 33.10000000000023, 68.59999999999997, 21.099999999999994, 21.800000000000015, 37.80000000000026, 37.30000000000026, 26.4000000000001, 183.399999999999, 23.50000000000003, 7.000000000000149, 107.59999999999943, 40.0000000000003, 33.200000000000195, 40.90000000000031, 29.300000000000153, 19.19999999999997, 13.100000000000035, 103.1999999999995, 43.700000000000195, 109.89999999999965, 105.79999999999981, 89.49999999999962, 15.799999999999983, 17.99999999999996, 21.100000000000012, -83.70000000000005, -185.20000000000013, 134.39999999999978, 33.4000000000002, 31.200000000000166, 29.000000000000124, 31.200000000000166, 17.999999999999975, -580.1, 63.90000000000017, 36.70000000000025], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [75.50000000000003, 68.60000000000002, 21.80000000000004, -68.20000000000088, -204.40000000000006, -36.699999999999754, 99.20000000000002, 20.000000000000014, 20.000000000000014, -21.999999999999744, 20.30000000000002, 19.70000000000001, -185.80000000000058, 20.000000000000014, 20.000000000000014, -9.400000000000132, 17.899999999999988, 157.69999999999985, -118.60000000000076, 15.799999999999963, 20.000000000000014, 20.000000000000014, 9.499999999999964, -40.89999999999976, 20.000000000000014, -30.39999999999978, 102.5, 91.70000000000002, 3.8000000000000522, -269.3999999999985, -72.40000000000089, -135.40000000000072, -7.299999999999891, 5.299999999999965, 140.29999999999987, 161.29999999999998, 11.599999999999964, -86.50000000000081, -26.199999999999747, 15.799999999999963, -281.79999999999984, -289.9000000000001, 20.000000000000014, 111.49999999999977, 105.79999999999995, -116.80000000000072, -34.899999999999764, -89.20000000000056, 17.899999999999988, 25.400000000000098, 13.699999999999964, 13.699999999999964, -21.999999999999744, 178.39999999999992, -26.199999999999747, -334.5999999999999, -74.50000000000082, 15.799999999999963, -61.90000000000068, 20.000000000000014, 20.000000000000014, 15.799999999999963, 20.000000000000014, 13.699999999999964, 11.599999999999964, 20.000000000000014, 130.4, -82.9000000000006, 20.000000000000014, -0.9999999999999846, 114.49999999999955, -87.1000000000008, 1.0999999999999865, -51.399999999999935, 20.000000000000014, 11.599999999999964, 15.799999999999963, 20.000000000000014, -61.90000000000041, -30.399999999999764, 26.000000000000085, -15.699999999999747, 96.79999999999987, 20.000000000000014, -68.20000000000074, 1.0999999999999865, -77.80000000000055, 15.799999999999963, 20.000000000000014, -70.30000000000089, 10.399999999999965, 5.299999999999965, 1.999999999999991, -49.29999999999976, -24.099999999999753, -24.099999999999746, -131.20000000000073, 20.000000000000014, 20.000000000000014, -76.60000000000069, 13.699999999999964, -162.70000000000064, 7.399999999999965, 13.699999999999964, 31.70000000000022, -82.90000000000076, 11.599999999999964, -75.40000000000038, -68.2000000000009, 13.699999999999964, 20.90000000000003, -64.0000000000006, -400.0, -366.4, -9.399999999999855, -26.199999999999747, 3.1999999999999615, -19.899999999999757, 68.59999999999985, 4.399999999999968, 79.69999999999999, 46.70000000000012, -49.29999999999976, 76.70000000000012, -290.50000000000006, 5.299999999999965, 23.00000000000007, -118.60000000000076, 23.900000000000105, -38.79999999999976, 10.09999999999997, 36.50000000000016, 7.399999999999965, -4.299999999999958, 5.299999999999965, 9.499999999999964, 17.899999999999988, 17.899999999999988, 20.000000000000014, 5.299999999999965, 20.000000000000014, -13.599999999999808, 113.59999999999985, 66.79999999999997, -0.9999999999999846, 9.499999999999964, -28.29999999999975, 5.299999999999965, 89.89999999999986, 13.699999999999964, 20.000000000000014, 20.000000000000014, 16.69999999999997, 9.499999999999964, 20.000000000000014, 20.90000000000003, -38.7999999999998, 1.0999999999999865, -80.80000000000004, 20.000000000000014, -0.9999999999999846, -19.89999999999975, 81.19999999999996, -1.0000000000000098, 4.700000000000024, 20.000000000000014, 11.599999999999964, 65.30000000000007, 11.599999999999964, 87.19999999999999, 74.0, 9.499999999999964, -13.59999999999979, 7.399999999999965, -7.299999999999905, 5.299999999999965, 20.000000000000014, -25.899999999999757, 106.3999999999997, -381.1, -279.70000000000005, -275.49999999999983, 1.999999999999991, 118.40000000000005, 11.599999999999964, 15.799999999999963, 3.1999999999999615, 20.000000000000014, 11.599999999999964, 7.399999999999965, 17.899999999999988, 5.299999999999965, -21.999999999999744, 20.000000000000014, -381.1, -400.0, -80.8000000000006, 67.70000000000012, 13.699999999999964, 20.000000000000014], "policy_predator_policy_reward": [18.0, 11.0, 42.0, 21.0, 137.0, 18.0, 6.0, 4.0, 12.0, 20.0, 3.0, 1.0, 96.0, 2.0, 0.0, 59.0, 1.0, 0.0, 62.0, 52.0, 0.0, 0.0, 29.0, 5.0, 24.0, 23.0, 5.0, 5.0, 182.0, 12.0, 76.0, 79.0, 12.0, 14.0, 7.0, 7.0, 4.0, 52.0, 2.0, 22.0, 196.0, 1.0, 6.0, 10.0, 55.0, 34.0, 42.0, 48.0, 0.0, 1.0, 3.0, 0.0, 20.0, 14.0, 174.0, 21.0, 37.0, 29.0, 0.0, 39.0, 2.0, 2.0, 1.0, 3.0, 0.0, 4.0, 32.0, 28.0, 1.0, 10.0, 48.0, 44.0, 31.0, 19.0, 3.0, 4.0, 2.0, 2.0, 47.0, 50.0, 13.0, 17.0, 6.0, 14.0, 42.0, 9.0, 31.0, 40.0, 39.0, 43.0, 7.0, 5.0, 27.0, 33.0, 22.0, 24.0, 72.0, 5.0, 21.0, 46.0, 84.0, 62.0, 6.0, 2.0, 39.0, 48.0, 39.0, 28.0, 42.0, 3.0, 31.0, 36.0, 3.0, 200.0, 22.0, 14.0, 4.0, 23.0, 12.0, 11.0, 11.0, 8.0, 1.0, 33.0, 155.0, 5.0, 66.0, 34.0, 27.0, 21.0, 17.0, 5.0, 0.0, 18.0, 7.0, 0.0, 0.0, 2.0, 5.0, 7.0, 6.0, 14.0, 1.0, 2.0, 5.0, 10.0, 7.0, 23.0, 3.0, 1.0, 0.0, 0.0, 5.0, 2.0, 0.0, 0.0, 35.0, 32.0, 46.0, 34.0, 19.0, 15.0, 1.0, 22.0, 9.0, 10.0, 16.0, 17.0, 4.0, 3.0, 5.0, 1.0, 8.0, 14.0, 13.0, 7.0, 15.0, 12.0, 191.0, 0.0, 188.0, 182.0, 9.0, 5.0, 4.0, 2.0, 0.0, 8.0, 6.0, 4.0, 1.0, 7.0, 0.0, 20.0, 1.0, 200.0, 35.0, 42.0, 0.0, 3.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5880992409263807, "mean_inference_ms": 1.8155765849542087, "mean_action_processing_ms": 0.25168301590917885, "mean_env_wait_ms": 0.1960578186455041, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0036696195602416992, "StateBufferConnector_ms": 0.006873607635498047, "ViewRequirementAgentConnector_ms": 0.10774898529052734}, "num_episodes": 18, "episode_return_max": 315.5999999999999, "episode_return_min": -580.1, "episode_return_mean": 20.66899999999998, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 3088000, "num_agent_steps_trained": 3088000, "num_env_steps_sampled": 772000, "num_env_steps_trained": 772000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 381.84818560719214, "num_env_steps_trained_throughput_per_sec": 381.84818560719214, "timesteps_total": 772000, "num_env_steps_sampled_lifetime": 772000, "num_agent_steps_sampled_lifetime": 3088000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 3088000, "timers": {"training_iteration_time_ms": 10579.322, "restore_workers_time_ms": 0.013, "training_step_time_ms": 10579.282, "sample_time_ms": 1355.85, "learn_time_ms": 9208.817, "learn_throughput": 434.366, "synch_weights_time_ms": 13.625}, "counters": {"num_env_steps_sampled": 772000, "num_env_steps_trained": 772000, "num_agent_steps_sampled": 3088000, "num_agent_steps_trained": 3088000}, "done": false, "training_iteration": 193, "trial_id": "3dae5_00000", "date": "2024-08-14_09-42-25", "timestamp": 1723642945, "time_this_iter_s": 10.479444980621338, "time_total_s": 3761.385678291321, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b4483700>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3761.385678291321, "iterations_since_restore": 193, "perf": {"cpu_util_percent": 28.433333333333334, "ram_util_percent": 83.4}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1461521581209526, "cur_kl_coeff": 0.0003340865252539515, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.0312141480899992, "policy_loss": -0.0025200574710551238, "vf_loss": 2.0337314769704506, "vf_explained_var": 0.13162283493728233, "kl": 0.008172814881227024, "entropy": 0.5403283364400662, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 365715.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.0032130264415944, "cur_kl_coeff": 0.060067749023437485, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.6199685852363626, "policy_loss": -0.005232972634473333, "vf_loss": 3.6248715835904317, "vf_explained_var": -0.13905140946781824, "kl": 0.0054935582693372625, "entropy": 0.6303597385290438, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 365715.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 776000, "num_env_steps_trained": 776000, "num_agent_steps_sampled": 3104000, "num_agent_steps_trained": 3104000}, "env_runners": {"episode_reward_max": 190.39999999999927, "episode_reward_min": -580.1, "episode_reward_mean": 9.46399999999997, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 178.39999999999992, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -23.413000000000057, "predator_policy": 28.145}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-18.89999999999955, 13.60000000000002, -374.6999999999997, 147.49999999999918, 77.99999999999994, -34.09999999999956, 44.30000000000036, 30.400000000000148, 190.39999999999927, -165.80000000000095, 7.300000000000027, -2.8999999999997446, 39.800000000000296, 37.700000000000266, 35.600000000000236, 107.49999999999987, 30.000000000000146, 119.39999999999908, -0.2999999999998568, 38.60000000000028, 39.800000000000296, 4.700000000000143, 40.3000000000002, 136.79999999999944, -16.099999999999504, 8.999999999999924, 31.700000000000188, 27.700000000000102, 12.700000000000047, -2.199999999999737, -34.19999999999956, 10.400000000000025, -2.9999999999998725, 29.100000000000126, 35.80000000000024, 3.1999999999999384, -9.499999999999627, 23.900000000000066, -563.4, 0.4000000000002427, 10.300000000000074, 95.9999999999996, 145.39999999999912, 61.40000000000017, -125.2000000000003, 4.400000000000066, 33.10000000000023, 68.59999999999997, 21.099999999999994, 21.800000000000015, 37.80000000000026, 37.30000000000026, 26.4000000000001, 183.399999999999, 23.50000000000003, 7.000000000000149, 107.59999999999943, 40.0000000000003, 33.200000000000195, 40.90000000000031, 29.300000000000153, 19.19999999999997, 13.100000000000035, 103.1999999999995, 43.700000000000195, 109.89999999999965, 105.79999999999981, 89.49999999999962, 15.799999999999983, 17.99999999999996, 21.100000000000012, -83.70000000000005, -185.20000000000013, 134.39999999999978, 33.4000000000002, 31.200000000000166, 29.000000000000124, 31.200000000000166, 17.999999999999975, -580.1, 63.90000000000017, 36.70000000000025, 29.90000000000014, 36.10000000000024, -18.49999999999951, -129.4000000000006, -156.1000000000005, 52.000000000000256, -155.00000000000054, -278.0000000000003, -89.60000000000122, 79.79999999999998, 98.39999999999982, 73.20000000000005, 137.9999999999997, 40.3000000000003, 126.89999999999922, -102.8000000000012, 92.69999999999996, 36.60000000000025], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [11.599999999999964, -86.50000000000081, -26.199999999999747, 15.799999999999963, -281.79999999999984, -289.9000000000001, 20.000000000000014, 111.49999999999977, 105.79999999999995, -116.80000000000072, -34.899999999999764, -89.20000000000056, 17.899999999999988, 25.400000000000098, 13.699999999999964, 13.699999999999964, -21.999999999999744, 178.39999999999992, -26.199999999999747, -334.5999999999999, -74.50000000000082, 15.799999999999963, -61.90000000000068, 20.000000000000014, 20.000000000000014, 15.799999999999963, 20.000000000000014, 13.699999999999964, 11.599999999999964, 20.000000000000014, 130.4, -82.9000000000006, 20.000000000000014, -0.9999999999999846, 114.49999999999955, -87.1000000000008, 1.0999999999999865, -51.399999999999935, 20.000000000000014, 11.599999999999964, 15.799999999999963, 20.000000000000014, -61.90000000000041, -30.399999999999764, 26.000000000000085, -15.699999999999747, 96.79999999999987, 20.000000000000014, -68.20000000000074, 1.0999999999999865, -77.80000000000055, 15.799999999999963, 20.000000000000014, -70.30000000000089, 10.399999999999965, 5.299999999999965, 1.999999999999991, -49.29999999999976, -24.099999999999753, -24.099999999999746, -131.20000000000073, 20.000000000000014, 20.000000000000014, -76.60000000000069, 13.699999999999964, -162.70000000000064, 7.399999999999965, 13.699999999999964, 31.70000000000022, -82.90000000000076, 11.599999999999964, -75.40000000000038, -68.2000000000009, 13.699999999999964, 20.90000000000003, -64.0000000000006, -400.0, -366.4, -9.399999999999855, -26.199999999999747, 3.1999999999999615, -19.899999999999757, 68.59999999999985, 4.399999999999968, 79.69999999999999, 46.70000000000012, -49.29999999999976, 76.70000000000012, -290.50000000000006, 5.299999999999965, 23.00000000000007, -118.60000000000076, 23.900000000000105, -38.79999999999976, 10.09999999999997, 36.50000000000016, 7.399999999999965, -4.299999999999958, 5.299999999999965, 9.499999999999964, 17.899999999999988, 17.899999999999988, 20.000000000000014, 5.299999999999965, 20.000000000000014, -13.599999999999808, 113.59999999999985, 66.79999999999997, -0.9999999999999846, 9.499999999999964, -28.29999999999975, 5.299999999999965, 89.89999999999986, 13.699999999999964, 20.000000000000014, 20.000000000000014, 16.69999999999997, 9.499999999999964, 20.000000000000014, 20.90000000000003, -38.7999999999998, 1.0999999999999865, -80.80000000000004, 20.000000000000014, -0.9999999999999846, -19.89999999999975, 81.19999999999996, -1.0000000000000098, 4.700000000000024, 20.000000000000014, 11.599999999999964, 65.30000000000007, 11.599999999999964, 87.19999999999999, 74.0, 9.499999999999964, -13.59999999999979, 7.399999999999965, -7.299999999999905, 5.299999999999965, 20.000000000000014, -25.899999999999757, 106.3999999999997, -381.1, -279.70000000000005, -275.49999999999983, 1.999999999999991, 118.40000000000005, 11.599999999999964, 15.799999999999963, 3.1999999999999615, 20.000000000000014, 11.599999999999964, 7.399999999999965, 17.899999999999988, 5.299999999999965, -21.999999999999744, 20.000000000000014, -381.1, -400.0, -80.8000000000006, 67.70000000000012, 13.699999999999964, 20.000000000000014, 3.1999999999999615, 13.699999999999964, -28.900000000000126, -21.999999999999744, -64.00000000000082, -11.499999999999819, -0.9999999999999846, -372.3999999999999, 20.000000000000014, -360.1, 9.499999999999964, 3.5000000000001235, -400.0, 20.000000000000014, -288.70000000000016, -364.30000000000007, -68.20000000000061, -72.4000000000006, -7.299999999999891, 70.10000000000002, 79.09999999999997, 5.299999999999965, 20.000000000000014, 15.200000000000145, 118.10000000000002, 17.899999999999988, -0.9999999999999846, 26.300000000000114, 15.799999999999963, 109.09999999999975, -24.099999999999746, -210.7000000000003, 23.600000000000065, 55.1, 20.000000000000014, 11.599999999999964], "policy_predator_policy_reward": [4.0, 52.0, 2.0, 22.0, 196.0, 1.0, 6.0, 10.0, 55.0, 34.0, 42.0, 48.0, 0.0, 1.0, 3.0, 0.0, 20.0, 14.0, 174.0, 21.0, 37.0, 29.0, 0.0, 39.0, 2.0, 2.0, 1.0, 3.0, 0.0, 4.0, 32.0, 28.0, 1.0, 10.0, 48.0, 44.0, 31.0, 19.0, 3.0, 4.0, 2.0, 2.0, 47.0, 50.0, 13.0, 17.0, 6.0, 14.0, 42.0, 9.0, 31.0, 40.0, 39.0, 43.0, 7.0, 5.0, 27.0, 33.0, 22.0, 24.0, 72.0, 5.0, 21.0, 46.0, 84.0, 62.0, 6.0, 2.0, 39.0, 48.0, 39.0, 28.0, 42.0, 3.0, 31.0, 36.0, 3.0, 200.0, 22.0, 14.0, 4.0, 23.0, 12.0, 11.0, 11.0, 8.0, 1.0, 33.0, 155.0, 5.0, 66.0, 34.0, 27.0, 21.0, 17.0, 5.0, 0.0, 18.0, 7.0, 0.0, 0.0, 2.0, 5.0, 7.0, 6.0, 14.0, 1.0, 2.0, 5.0, 10.0, 7.0, 23.0, 3.0, 1.0, 0.0, 0.0, 5.0, 2.0, 0.0, 0.0, 35.0, 32.0, 46.0, 34.0, 19.0, 15.0, 1.0, 22.0, 9.0, 10.0, 16.0, 17.0, 4.0, 3.0, 5.0, 1.0, 8.0, 14.0, 13.0, 7.0, 15.0, 12.0, 191.0, 0.0, 188.0, 182.0, 9.0, 5.0, 4.0, 2.0, 0.0, 8.0, 6.0, 4.0, 1.0, 7.0, 0.0, 20.0, 1.0, 200.0, 35.0, 42.0, 0.0, 3.0, 5.0, 8.0, 14.0, 73.0, 12.0, 45.0, 58.0, 186.0, 2.0, 182.0, 12.0, 27.0, 25.0, 200.0, 189.0, 186.0, 44.0, 7.0, 13.0, 4.0, 7.0, 7.0, 30.0, 8.0, 1.0, 1.0, 10.0, 5.0, 0.0, 2.0, 123.0, 9.0, 9.0, 5.0, 1.0, 4.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5884603430285992, "mean_inference_ms": 1.816126159009272, "mean_action_processing_ms": 0.25191128295239235, "mean_env_wait_ms": 0.19605739401243802, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0037244558334350586, "StateBufferConnector_ms": 0.006932735443115234, "ViewRequirementAgentConnector_ms": 0.10986793041229248}, "num_episodes": 18, "episode_return_max": 190.39999999999927, "episode_return_min": -580.1, "episode_return_mean": 9.46399999999997, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 3104000, "num_agent_steps_trained": 3104000, "num_env_steps_sampled": 776000, "num_env_steps_trained": 776000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 354.98205837093496, "num_env_steps_trained_throughput_per_sec": 354.98205837093496, "timesteps_total": 776000, "num_env_steps_sampled_lifetime": 776000, "num_agent_steps_sampled_lifetime": 3104000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 3104000, "timers": {"training_iteration_time_ms": 10631.89, "restore_workers_time_ms": 0.013, "training_step_time_ms": 10631.849, "sample_time_ms": 1377.044, "learn_time_ms": 9240.073, "learn_throughput": 432.897, "synch_weights_time_ms": 13.593}, "counters": {"num_env_steps_sampled": 776000, "num_env_steps_trained": 776000, "num_agent_steps_sampled": 3104000, "num_agent_steps_trained": 3104000}, "done": false, "training_iteration": 194, "trial_id": "3dae5_00000", "date": "2024-08-14_09-42-36", "timestamp": 1723642956, "time_this_iter_s": 11.301805019378662, "time_total_s": 3772.6874833106995, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b38efca0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3772.6874833106995, "iterations_since_restore": 194, "perf": {"cpu_util_percent": 36.1, "ram_util_percent": 83.66874999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6932046510239758, "cur_kl_coeff": 0.0003340865252539515, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.9484625598267903, "policy_loss": -0.0031002181132506364, "vf_loss": 0.951547080404544, "vf_explained_var": 0.1064436068925908, "kl": 0.046979699810096316, "entropy": 0.6761820886658613, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 367605.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.257638298187937, "cur_kl_coeff": 0.060067749023437485, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.3568576962859544, "policy_loss": -0.0061700846783067816, "vf_loss": 2.362612063985653, "vf_explained_var": 0.04146379566697216, "kl": 0.00692069139576457, "entropy": 0.5326312649817694, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 367605.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 780000, "num_env_steps_trained": 780000, "num_agent_steps_sampled": 3120000, "num_agent_steps_trained": 3120000}, "env_runners": {"episode_reward_max": 205.6999999999992, "episode_reward_min": -595.0, "episode_reward_mean": 9.920999999999971, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 118.40000000000005, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -22.064500000000045, "predator_policy": 27.025}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.2999999999998568, 38.60000000000028, 39.800000000000296, 4.700000000000143, 40.3000000000002, 136.79999999999944, -16.099999999999504, 8.999999999999924, 31.700000000000188, 27.700000000000102, 12.700000000000047, -2.199999999999737, -34.19999999999956, 10.400000000000025, -2.9999999999998725, 29.100000000000126, 35.80000000000024, 3.1999999999999384, -9.499999999999627, 23.900000000000066, -563.4, 0.4000000000002427, 10.300000000000074, 95.9999999999996, 145.39999999999912, 61.40000000000017, -125.2000000000003, 4.400000000000066, 33.10000000000023, 68.59999999999997, 21.099999999999994, 21.800000000000015, 37.80000000000026, 37.30000000000026, 26.4000000000001, 183.399999999999, 23.50000000000003, 7.000000000000149, 107.59999999999943, 40.0000000000003, 33.200000000000195, 40.90000000000031, 29.300000000000153, 19.19999999999997, 13.100000000000035, 103.1999999999995, 43.700000000000195, 109.89999999999965, 105.79999999999981, 89.49999999999962, 15.799999999999983, 17.99999999999996, 21.100000000000012, -83.70000000000005, -185.20000000000013, 134.39999999999978, 33.4000000000002, 31.200000000000166, 29.000000000000124, 31.200000000000166, 17.999999999999975, -580.1, 63.90000000000017, 36.70000000000025, 29.90000000000014, 36.10000000000024, -18.49999999999951, -129.4000000000006, -156.1000000000005, 52.000000000000256, -155.00000000000054, -278.0000000000003, -89.60000000000122, 79.79999999999998, 98.39999999999982, 73.20000000000005, 137.9999999999997, 40.3000000000003, 126.89999999999922, -102.8000000000012, 92.69999999999996, 36.60000000000025, -595.0, 19.99999999999997, 38.80000000000028, 39.60000000000029, 36.300000000000246, -30.499999999999524, 127.79999999999959, 162.49999999999903, 27.00000000000009, 111.39999999999868, 29.000000000000124, 7.000000000000124, 34.50000000000022, 10.400000000000091, 45.20000000000038, 31.10000000000016, 205.6999999999992, 30.00000000000031], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [1.0999999999999865, -51.399999999999935, 20.000000000000014, 11.599999999999964, 15.799999999999963, 20.000000000000014, -61.90000000000041, -30.399999999999764, 26.000000000000085, -15.699999999999747, 96.79999999999987, 20.000000000000014, -68.20000000000074, 1.0999999999999865, -77.80000000000055, 15.799999999999963, 20.000000000000014, -70.30000000000089, 10.399999999999965, 5.299999999999965, 1.999999999999991, -49.29999999999976, -24.099999999999753, -24.099999999999746, -131.20000000000073, 20.000000000000014, 20.000000000000014, -76.60000000000069, 13.699999999999964, -162.70000000000064, 7.399999999999965, 13.699999999999964, 31.70000000000022, -82.90000000000076, 11.599999999999964, -75.40000000000038, -68.2000000000009, 13.699999999999964, 20.90000000000003, -64.0000000000006, -400.0, -366.4, -9.399999999999855, -26.199999999999747, 3.1999999999999615, -19.899999999999757, 68.59999999999985, 4.399999999999968, 79.69999999999999, 46.70000000000012, -49.29999999999976, 76.70000000000012, -290.50000000000006, 5.299999999999965, 23.00000000000007, -118.60000000000076, 23.900000000000105, -38.79999999999976, 10.09999999999997, 36.50000000000016, 7.399999999999965, -4.299999999999958, 5.299999999999965, 9.499999999999964, 17.899999999999988, 17.899999999999988, 20.000000000000014, 5.299999999999965, 20.000000000000014, -13.599999999999808, 113.59999999999985, 66.79999999999997, -0.9999999999999846, 9.499999999999964, -28.29999999999975, 5.299999999999965, 89.89999999999986, 13.699999999999964, 20.000000000000014, 20.000000000000014, 16.69999999999997, 9.499999999999964, 20.000000000000014, 20.90000000000003, -38.7999999999998, 1.0999999999999865, -80.80000000000004, 20.000000000000014, -0.9999999999999846, -19.89999999999975, 81.19999999999996, -1.0000000000000098, 4.700000000000024, 20.000000000000014, 11.599999999999964, 65.30000000000007, 11.599999999999964, 87.19999999999999, 74.0, 9.499999999999964, -13.59999999999979, 7.399999999999965, -7.299999999999905, 5.299999999999965, 20.000000000000014, -25.899999999999757, 106.3999999999997, -381.1, -279.70000000000005, -275.49999999999983, 1.999999999999991, 118.40000000000005, 11.599999999999964, 15.799999999999963, 3.1999999999999615, 20.000000000000014, 11.599999999999964, 7.399999999999965, 17.899999999999988, 5.299999999999965, -21.999999999999744, 20.000000000000014, -381.1, -400.0, -80.8000000000006, 67.70000000000012, 13.699999999999964, 20.000000000000014, 3.1999999999999615, 13.699999999999964, -28.900000000000126, -21.999999999999744, -64.00000000000082, -11.499999999999819, -0.9999999999999846, -372.3999999999999, 20.000000000000014, -360.1, 9.499999999999964, 3.5000000000001235, -400.0, 20.000000000000014, -288.70000000000016, -364.30000000000007, -68.20000000000061, -72.4000000000006, -7.299999999999891, 70.10000000000002, 79.09999999999997, 5.299999999999965, 20.000000000000014, 15.200000000000145, 118.10000000000002, 17.899999999999988, -0.9999999999999846, 26.300000000000114, 15.799999999999963, 109.09999999999975, -24.099999999999746, -210.7000000000003, 23.600000000000065, 55.1, 20.000000000000014, 11.599999999999964, -400.0, -400.0, -13.599999999999783, 14.599999999999964, 20.000000000000014, 15.799999999999963, 19.70000000000001, 17.899999999999988, 20.000000000000014, 5.299999999999965, -85.00000000000085, -11.499999999999819, 109.99999999999991, -8.199999999999902, 35.90000000000011, 95.59999999999934, 7.399999999999965, 11.599999999999964, 13.699999999999964, 94.69999999999938, 1.0999999999999865, 17.899999999999988, -40.89999999999976, 17.899999999999988, 9.499999999999964, 20.000000000000014, -18.999999999999744, 7.399999999999965, 17.899999999999984, 26.300000000000114, 7.399999999999965, 13.699999999999964, 100.09999999999968, 80.59999999999974, -265.5999999999997, 11.599999999999964], "policy_predator_policy_reward": [31.0, 19.0, 3.0, 4.0, 2.0, 2.0, 47.0, 50.0, 13.0, 17.0, 6.0, 14.0, 42.0, 9.0, 31.0, 40.0, 39.0, 43.0, 7.0, 5.0, 27.0, 33.0, 22.0, 24.0, 72.0, 5.0, 21.0, 46.0, 84.0, 62.0, 6.0, 2.0, 39.0, 48.0, 39.0, 28.0, 42.0, 3.0, 31.0, 36.0, 3.0, 200.0, 22.0, 14.0, 4.0, 23.0, 12.0, 11.0, 11.0, 8.0, 1.0, 33.0, 155.0, 5.0, 66.0, 34.0, 27.0, 21.0, 17.0, 5.0, 0.0, 18.0, 7.0, 0.0, 0.0, 2.0, 5.0, 7.0, 6.0, 14.0, 1.0, 2.0, 5.0, 10.0, 7.0, 23.0, 3.0, 1.0, 0.0, 0.0, 5.0, 2.0, 0.0, 0.0, 35.0, 32.0, 46.0, 34.0, 19.0, 15.0, 1.0, 22.0, 9.0, 10.0, 16.0, 17.0, 4.0, 3.0, 5.0, 1.0, 8.0, 14.0, 13.0, 7.0, 15.0, 12.0, 191.0, 0.0, 188.0, 182.0, 9.0, 5.0, 4.0, 2.0, 0.0, 8.0, 6.0, 4.0, 1.0, 7.0, 0.0, 20.0, 1.0, 200.0, 35.0, 42.0, 0.0, 3.0, 5.0, 8.0, 14.0, 73.0, 12.0, 45.0, 58.0, 186.0, 2.0, 182.0, 12.0, 27.0, 25.0, 200.0, 189.0, 186.0, 44.0, 7.0, 13.0, 4.0, 7.0, 7.0, 30.0, 8.0, 1.0, 1.0, 10.0, 5.0, 0.0, 2.0, 123.0, 9.0, 9.0, 5.0, 1.0, 4.0, 200.0, 5.0, 3.0, 16.0, 1.0, 2.0, 1.0, 1.0, 7.0, 4.0, 50.0, 16.0, 19.0, 7.0, 17.0, 14.0, 6.0, 2.0, 3.0, 0.0, 1.0, 9.0, 1.0, 29.0, 0.0, 5.0, 2.0, 20.0, 0.0, 1.0, 6.0, 4.0, 12.0, 13.0, 138.0, 146.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5884364845271187, "mean_inference_ms": 1.816457011505884, "mean_action_processing_ms": 0.25183131949245324, "mean_env_wait_ms": 0.19605741056104847, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0036107301712036133, "StateBufferConnector_ms": 0.0032693147659301758, "ViewRequirementAgentConnector_ms": 0.0977177619934082}, "num_episodes": 18, "episode_return_max": 205.6999999999992, "episode_return_min": -595.0, "episode_return_mean": 9.920999999999971, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 3120000, "num_agent_steps_trained": 3120000, "num_env_steps_sampled": 780000, "num_env_steps_trained": 780000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 355.83865235666633, "num_env_steps_trained_throughput_per_sec": 355.83865235666633, "timesteps_total": 780000, "num_env_steps_sampled_lifetime": 780000, "num_agent_steps_sampled_lifetime": 3120000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 3120000, "timers": {"training_iteration_time_ms": 10695.196, "restore_workers_time_ms": 0.013, "training_step_time_ms": 10695.155, "sample_time_ms": 1382.151, "learn_time_ms": 9297.884, "learn_throughput": 430.205, "synch_weights_time_ms": 13.822}, "counters": {"num_env_steps_sampled": 780000, "num_env_steps_trained": 780000, "num_agent_steps_sampled": 3120000, "num_agent_steps_trained": 3120000}, "done": false, "training_iteration": 195, "trial_id": "3dae5_00000", "date": "2024-08-14_09-42-47", "timestamp": 1723642967, "time_this_iter_s": 11.284824848175049, "time_total_s": 3783.9723081588745, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b38efb80>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3783.9723081588745, "iterations_since_restore": 195, "perf": {"cpu_util_percent": 34.59375, "ram_util_percent": 83.38749999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.3106249312559766, "cur_kl_coeff": 0.0005011297878809274, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.882415747973654, "policy_loss": -0.005525883414570695, "vf_loss": 0.8879351872773398, "vf_explained_var": 0.12728001260883592, "kl": 0.012858357669558736, "entropy": 0.8960386163027829, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 369495.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.3496656503626907, "cur_kl_coeff": 0.060067749023437485, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.4560815615628764, "policy_loss": -0.007871806560079296, "vf_loss": 3.463484089967435, "vf_explained_var": 0.5968594981564416, "kl": 0.007812474479605797, "entropy": 0.557881393744832, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 369495.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 784000, "num_env_steps_trained": 784000, "num_agent_steps_sampled": 3136000, "num_agent_steps_trained": 3136000}, "env_runners": {"episode_reward_max": 291.4000000000002, "episode_reward_min": -595.0, "episode_reward_mean": 35.778999999999925, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 194.60000000000002, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -3.2455000000000234, "predator_policy": 21.135}, "custom_metrics": {}, "hist_stats": {"episode_reward": [4.400000000000066, 33.10000000000023, 68.59999999999997, 21.099999999999994, 21.800000000000015, 37.80000000000026, 37.30000000000026, 26.4000000000001, 183.399999999999, 23.50000000000003, 7.000000000000149, 107.59999999999943, 40.0000000000003, 33.200000000000195, 40.90000000000031, 29.300000000000153, 19.19999999999997, 13.100000000000035, 103.1999999999995, 43.700000000000195, 109.89999999999965, 105.79999999999981, 89.49999999999962, 15.799999999999983, 17.99999999999996, 21.100000000000012, -83.70000000000005, -185.20000000000013, 134.39999999999978, 33.4000000000002, 31.200000000000166, 29.000000000000124, 31.200000000000166, 17.999999999999975, -580.1, 63.90000000000017, 36.70000000000025, 29.90000000000014, 36.10000000000024, -18.49999999999951, -129.4000000000006, -156.1000000000005, 52.000000000000256, -155.00000000000054, -278.0000000000003, -89.60000000000122, 79.79999999999998, 98.39999999999982, 73.20000000000005, 137.9999999999997, 40.3000000000003, 126.89999999999922, -102.8000000000012, 92.69999999999996, 36.60000000000025, -595.0, 19.99999999999997, 38.80000000000028, 39.60000000000029, 36.300000000000246, -30.499999999999524, 127.79999999999959, 162.49999999999903, 27.00000000000009, 111.39999999999868, 29.000000000000124, 7.000000000000124, 34.50000000000022, 10.400000000000091, 45.20000000000038, 31.10000000000016, 205.6999999999992, 30.00000000000031, 46.70000000000033, 36.70000000000025, -6.599999999999708, 125.39999999999947, 131.79999999999944, 172.19999999999948, 90.799999999999, 37.80000000000027, 139.29999999999941, 151.59999999999957, 41.40000000000032, 115.49999999999947, 36.60000000000025, 291.4000000000002, 24.600000000000048, 153.69999999999945, 137.8999999999991, 17.999999999999936, -1.399999999999729, -0.49999999999999933, 266.49999999999966, 34.50000000000022, 186.39999999999938, 263.0000000000003, 50.00000000000024, 40.0000000000003, 5.800000000000075], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [23.00000000000007, -118.60000000000076, 23.900000000000105, -38.79999999999976, 10.09999999999997, 36.50000000000016, 7.399999999999965, -4.299999999999958, 5.299999999999965, 9.499999999999964, 17.899999999999988, 17.899999999999988, 20.000000000000014, 5.299999999999965, 20.000000000000014, -13.599999999999808, 113.59999999999985, 66.79999999999997, -0.9999999999999846, 9.499999999999964, -28.29999999999975, 5.299999999999965, 89.89999999999986, 13.699999999999964, 20.000000000000014, 20.000000000000014, 16.69999999999997, 9.499999999999964, 20.000000000000014, 20.90000000000003, -38.7999999999998, 1.0999999999999865, -80.80000000000004, 20.000000000000014, -0.9999999999999846, -19.89999999999975, 81.19999999999996, -1.0000000000000098, 4.700000000000024, 20.000000000000014, 11.599999999999964, 65.30000000000007, 11.599999999999964, 87.19999999999999, 74.0, 9.499999999999964, -13.59999999999979, 7.399999999999965, -7.299999999999905, 5.299999999999965, 20.000000000000014, -25.899999999999757, 106.3999999999997, -381.1, -279.70000000000005, -275.49999999999983, 1.999999999999991, 118.40000000000005, 11.599999999999964, 15.799999999999963, 3.1999999999999615, 20.000000000000014, 11.599999999999964, 7.399999999999965, 17.899999999999988, 5.299999999999965, -21.999999999999744, 20.000000000000014, -381.1, -400.0, -80.8000000000006, 67.70000000000012, 13.699999999999964, 20.000000000000014, 3.1999999999999615, 13.699999999999964, -28.900000000000126, -21.999999999999744, -64.00000000000082, -11.499999999999819, -0.9999999999999846, -372.3999999999999, 20.000000000000014, -360.1, 9.499999999999964, 3.5000000000001235, -400.0, 20.000000000000014, -288.70000000000016, -364.30000000000007, -68.20000000000061, -72.4000000000006, -7.299999999999891, 70.10000000000002, 79.09999999999997, 5.299999999999965, 20.000000000000014, 15.200000000000145, 118.10000000000002, 17.899999999999988, -0.9999999999999846, 26.300000000000114, 15.799999999999963, 109.09999999999975, -24.099999999999746, -210.7000000000003, 23.600000000000065, 55.1, 20.000000000000014, 11.599999999999964, -400.0, -400.0, -13.599999999999783, 14.599999999999964, 20.000000000000014, 15.799999999999963, 19.70000000000001, 17.899999999999988, 20.000000000000014, 5.299999999999965, -85.00000000000085, -11.499999999999819, 109.99999999999991, -8.199999999999902, 35.90000000000011, 95.59999999999934, 7.399999999999965, 11.599999999999964, 13.699999999999964, 94.69999999999938, 1.0999999999999865, 17.899999999999988, -40.89999999999976, 17.899999999999988, 9.499999999999964, 20.000000000000014, -18.999999999999744, 7.399999999999965, 17.899999999999984, 26.300000000000114, 7.399999999999965, 13.699999999999964, 100.09999999999968, 80.59999999999974, -265.5999999999997, 11.599999999999964, 17.899999999999988, 21.80000000000004, 13.699999999999964, 20.000000000000014, -3.099999999999958, -56.50000000000012, 20.000000000000014, 88.39999999999986, 5.299999999999965, 117.49999999999989, 142.7, 24.50000000000008, 66.79999999999997, 20.000000000000014, 15.799999999999963, 20.000000000000014, 110.29999999999986, 20.000000000000014, 117.79999999999998, 15.799999999999963, 20.000000000000014, 19.400000000000006, 20.000000000000014, 81.50000000000011, 20.000000000000014, 8.599999999999968, 135.49999999999994, 146.9, -5.1999999999999265, 15.799999999999963, 20.000000000000014, 130.6999999999999, -0.9999999999999846, 128.8999999999997, 15.799999999999963, -17.79999999999974, -26.199999999999747, -5.1999999999999265, -50.79999999999981, 5.299999999999965, 194.60000000000002, 53.900000000000155, 17.899999999999988, 11.599999999999964, 160.39999999999998, 20.000000000000014, 151.39999999999975, 101.59999999999994, 7.399999999999965, 29.600000000000097, 20.000000000000014, 20.000000000000014, -87.70000000000081, 9.499999999999964], "policy_predator_policy_reward": [66.0, 34.0, 27.0, 21.0, 17.0, 5.0, 0.0, 18.0, 7.0, 0.0, 0.0, 2.0, 5.0, 7.0, 6.0, 14.0, 1.0, 2.0, 5.0, 10.0, 7.0, 23.0, 3.0, 1.0, 0.0, 0.0, 5.0, 2.0, 0.0, 0.0, 35.0, 32.0, 46.0, 34.0, 19.0, 15.0, 1.0, 22.0, 9.0, 10.0, 16.0, 17.0, 4.0, 3.0, 5.0, 1.0, 8.0, 14.0, 13.0, 7.0, 15.0, 12.0, 191.0, 0.0, 188.0, 182.0, 9.0, 5.0, 4.0, 2.0, 0.0, 8.0, 6.0, 4.0, 1.0, 7.0, 0.0, 20.0, 1.0, 200.0, 35.0, 42.0, 0.0, 3.0, 5.0, 8.0, 14.0, 73.0, 12.0, 45.0, 58.0, 186.0, 2.0, 182.0, 12.0, 27.0, 25.0, 200.0, 189.0, 186.0, 44.0, 7.0, 13.0, 4.0, 7.0, 7.0, 30.0, 8.0, 1.0, 1.0, 10.0, 5.0, 0.0, 2.0, 123.0, 9.0, 9.0, 5.0, 1.0, 4.0, 200.0, 5.0, 3.0, 16.0, 1.0, 2.0, 1.0, 1.0, 7.0, 4.0, 50.0, 16.0, 19.0, 7.0, 17.0, 14.0, 6.0, 2.0, 3.0, 0.0, 1.0, 9.0, 1.0, 29.0, 0.0, 5.0, 2.0, 20.0, 0.0, 1.0, 6.0, 4.0, 12.0, 13.0, 138.0, 146.0, 6.0, 1.0, 0.0, 3.0, 16.0, 37.0, 8.0, 9.0, 2.0, 7.0, 5.0, 0.0, 3.0, 1.0, 2.0, 0.0, 8.0, 1.0, 2.0, 16.0, 2.0, 0.0, 0.0, 14.0, 0.0, 8.0, 4.0, 5.0, 12.0, 2.0, 0.0, 3.0, 0.0, 10.0, 5.0, 15.0, 22.0, 8.0, 10.0, 35.0, 2.0, 16.0, 1.0, 4.0, 3.0, 3.0, 1.0, 9.0, 7.0, 6.0, 0.0, 0.0, 48.0, 36.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5883112756581703, "mean_inference_ms": 1.8169972977832933, "mean_action_processing_ms": 0.251521919844423, "mean_env_wait_ms": 0.19617946796989602, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0037418603897094727, "StateBufferConnector_ms": 0.003283977508544922, "ViewRequirementAgentConnector_ms": 0.09552562236785889}, "num_episodes": 27, "episode_return_max": 291.4000000000002, "episode_return_min": -595.0, "episode_return_mean": 35.778999999999925, "episodes_this_iter": 27}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 3136000, "num_agent_steps_trained": 3136000, "num_env_steps_sampled": 784000, "num_env_steps_trained": 784000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 384.4514412366652, "num_env_steps_trained_throughput_per_sec": 384.4514412366652, "timesteps_total": 784000, "num_env_steps_sampled_lifetime": 784000, "num_agent_steps_sampled_lifetime": 3136000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 3136000, "timers": {"training_iteration_time_ms": 10639.295, "restore_workers_time_ms": 0.014, "training_step_time_ms": 10639.255, "sample_time_ms": 1387.18, "learn_time_ms": 9237.116, "learn_throughput": 433.036, "synch_weights_time_ms": 13.736}, "counters": {"num_env_steps_sampled": 784000, "num_env_steps_trained": 784000, "num_agent_steps_sampled": 3136000, "num_agent_steps_trained": 3136000}, "done": false, "training_iteration": 196, "trial_id": "3dae5_00000", "date": "2024-08-14_09-42-58", "timestamp": 1723642978, "time_this_iter_s": 10.409763097763062, "time_total_s": 3794.3820712566376, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b44439d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3794.3820712566376, "iterations_since_restore": 196, "perf": {"cpu_util_percent": 29.314285714285713, "ram_util_percent": 83.32142857142856}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5364553697998562, "cur_kl_coeff": 0.0005011297878809274, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.9151571066921982, "policy_loss": -0.0024158882570980244, "vf_loss": 1.9175624041014878, "vf_explained_var": 0.0832916659337503, "kl": 0.021133327684482325, "entropy": 0.7443377224225847, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 371385.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.8594541804500357, "cur_kl_coeff": 0.060067749023437485, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.026795459676672, "policy_loss": -0.0054031351683464235, "vf_loss": 4.031931365482391, "vf_explained_var": 0.033619515889536135, "kl": 0.0044488507479994496, "entropy": 0.4929144025006622, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 371385.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 788000, "num_env_steps_trained": 788000, "num_agent_steps_sampled": 3152000, "num_agent_steps_trained": 3152000}, "env_runners": {"episode_reward_max": 313.5000000000003, "episode_reward_min": -595.0, "episode_reward_mean": 39.28199999999986, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 194.60000000000002, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -3.829000000000035, "predator_policy": 23.47}, "custom_metrics": {}, "hist_stats": {"episode_reward": [103.1999999999995, 43.700000000000195, 109.89999999999965, 105.79999999999981, 89.49999999999962, 15.799999999999983, 17.99999999999996, 21.100000000000012, -83.70000000000005, -185.20000000000013, 134.39999999999978, 33.4000000000002, 31.200000000000166, 29.000000000000124, 31.200000000000166, 17.999999999999975, -580.1, 63.90000000000017, 36.70000000000025, 29.90000000000014, 36.10000000000024, -18.49999999999951, -129.4000000000006, -156.1000000000005, 52.000000000000256, -155.00000000000054, -278.0000000000003, -89.60000000000122, 79.79999999999998, 98.39999999999982, 73.20000000000005, 137.9999999999997, 40.3000000000003, 126.89999999999922, -102.8000000000012, 92.69999999999996, 36.60000000000025, -595.0, 19.99999999999997, 38.80000000000028, 39.60000000000029, 36.300000000000246, -30.499999999999524, 127.79999999999959, 162.49999999999903, 27.00000000000009, 111.39999999999868, 29.000000000000124, 7.000000000000124, 34.50000000000022, 10.400000000000091, 45.20000000000038, 31.10000000000016, 205.6999999999992, 30.00000000000031, 46.70000000000033, 36.70000000000025, -6.599999999999708, 125.39999999999947, 131.79999999999944, 172.19999999999948, 90.799999999999, 37.80000000000027, 139.29999999999941, 151.59999999999957, 41.40000000000032, 115.49999999999947, 36.60000000000025, 291.4000000000002, 24.600000000000048, 153.69999999999945, 137.8999999999991, 17.999999999999936, -1.399999999999729, -0.49999999999999933, 266.49999999999966, 34.50000000000022, 186.39999999999938, 263.0000000000003, 50.00000000000024, 40.0000000000003, 5.800000000000075, 16.89999999999998, 180.39999999999944, 153.09999999999945, 33.4000000000002, 165.6999999999995, -133.40000000000038, 126.39999999999932, 35.600000000000236, -55.80000000000028, -121.00000000000034, 132.99999999999937, 313.5000000000003, -230.30000000000095, 150.39999999999935, 27.10000000000009, 6.9999999999999005, 263.70000000000005, 32.30000000000018], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [81.19999999999996, -1.0000000000000098, 4.700000000000024, 20.000000000000014, 11.599999999999964, 65.30000000000007, 11.599999999999964, 87.19999999999999, 74.0, 9.499999999999964, -13.59999999999979, 7.399999999999965, -7.299999999999905, 5.299999999999965, 20.000000000000014, -25.899999999999757, 106.3999999999997, -381.1, -279.70000000000005, -275.49999999999983, 1.999999999999991, 118.40000000000005, 11.599999999999964, 15.799999999999963, 3.1999999999999615, 20.000000000000014, 11.599999999999964, 7.399999999999965, 17.899999999999988, 5.299999999999965, -21.999999999999744, 20.000000000000014, -381.1, -400.0, -80.8000000000006, 67.70000000000012, 13.699999999999964, 20.000000000000014, 3.1999999999999615, 13.699999999999964, -28.900000000000126, -21.999999999999744, -64.00000000000082, -11.499999999999819, -0.9999999999999846, -372.3999999999999, 20.000000000000014, -360.1, 9.499999999999964, 3.5000000000001235, -400.0, 20.000000000000014, -288.70000000000016, -364.30000000000007, -68.20000000000061, -72.4000000000006, -7.299999999999891, 70.10000000000002, 79.09999999999997, 5.299999999999965, 20.000000000000014, 15.200000000000145, 118.10000000000002, 17.899999999999988, -0.9999999999999846, 26.300000000000114, 15.799999999999963, 109.09999999999975, -24.099999999999746, -210.7000000000003, 23.600000000000065, 55.1, 20.000000000000014, 11.599999999999964, -400.0, -400.0, -13.599999999999783, 14.599999999999964, 20.000000000000014, 15.799999999999963, 19.70000000000001, 17.899999999999988, 20.000000000000014, 5.299999999999965, -85.00000000000085, -11.499999999999819, 109.99999999999991, -8.199999999999902, 35.90000000000011, 95.59999999999934, 7.399999999999965, 11.599999999999964, 13.699999999999964, 94.69999999999938, 1.0999999999999865, 17.899999999999988, -40.89999999999976, 17.899999999999988, 9.499999999999964, 20.000000000000014, -18.999999999999744, 7.399999999999965, 17.899999999999984, 26.300000000000114, 7.399999999999965, 13.699999999999964, 100.09999999999968, 80.59999999999974, -265.5999999999997, 11.599999999999964, 17.899999999999988, 21.80000000000004, 13.699999999999964, 20.000000000000014, -3.099999999999958, -56.50000000000012, 20.000000000000014, 88.39999999999986, 5.299999999999965, 117.49999999999989, 142.7, 24.50000000000008, 66.79999999999997, 20.000000000000014, 15.799999999999963, 20.000000000000014, 110.29999999999986, 20.000000000000014, 117.79999999999998, 15.799999999999963, 20.000000000000014, 19.400000000000006, 20.000000000000014, 81.50000000000011, 20.000000000000014, 8.599999999999968, 135.49999999999994, 146.9, -5.1999999999999265, 15.799999999999963, 20.000000000000014, 130.6999999999999, -0.9999999999999846, 128.8999999999997, 15.799999999999963, -17.79999999999974, -26.199999999999747, -5.1999999999999265, -50.79999999999981, 5.299999999999965, 194.60000000000002, 53.900000000000155, 17.899999999999988, 11.599999999999964, 160.39999999999998, 20.000000000000014, 151.39999999999975, 101.59999999999994, 7.399999999999965, 29.600000000000097, 20.000000000000014, 20.000000000000014, -87.70000000000081, 9.499999999999964, 13.699999999999964, -17.79999999999974, 151.40000000000003, 20.000000000000014, 9.499999999999964, 137.59999999999994, 9.499999999999979, 17.899999999999988, 20.000000000000014, 127.70000000000005, 11.599999999999964, -319.0, 107.89999999999976, 9.499999999999964, 11.599999999999964, 20.000000000000014, -135.40000000000072, -72.40000000000035, -288.99999999999994, 20.000000000000014, 13.699999999999964, 98.29999999999983, 117.20000000000005, 170.29999999999987, -55.600000000000335, -384.70000000000005, 130.69999999999987, 13.699999999999964, 11.599999999999964, 9.499999999999964, 20.000000000000014, -97.0, 132.20000000000005, 102.50000000000006, 5.299999999999965, 20.000000000000014], "policy_predator_policy_reward": [1.0, 22.0, 9.0, 10.0, 16.0, 17.0, 4.0, 3.0, 5.0, 1.0, 8.0, 14.0, 13.0, 7.0, 15.0, 12.0, 191.0, 0.0, 188.0, 182.0, 9.0, 5.0, 4.0, 2.0, 0.0, 8.0, 6.0, 4.0, 1.0, 7.0, 0.0, 20.0, 1.0, 200.0, 35.0, 42.0, 0.0, 3.0, 5.0, 8.0, 14.0, 73.0, 12.0, 45.0, 58.0, 186.0, 2.0, 182.0, 12.0, 27.0, 25.0, 200.0, 189.0, 186.0, 44.0, 7.0, 13.0, 4.0, 7.0, 7.0, 30.0, 8.0, 1.0, 1.0, 10.0, 5.0, 0.0, 2.0, 123.0, 9.0, 9.0, 5.0, 1.0, 4.0, 200.0, 5.0, 3.0, 16.0, 1.0, 2.0, 1.0, 1.0, 7.0, 4.0, 50.0, 16.0, 19.0, 7.0, 17.0, 14.0, 6.0, 2.0, 3.0, 0.0, 1.0, 9.0, 1.0, 29.0, 0.0, 5.0, 2.0, 20.0, 0.0, 1.0, 6.0, 4.0, 12.0, 13.0, 138.0, 146.0, 6.0, 1.0, 0.0, 3.0, 16.0, 37.0, 8.0, 9.0, 2.0, 7.0, 5.0, 0.0, 3.0, 1.0, 2.0, 0.0, 8.0, 1.0, 2.0, 16.0, 2.0, 0.0, 0.0, 14.0, 0.0, 8.0, 4.0, 5.0, 12.0, 2.0, 0.0, 3.0, 0.0, 10.0, 5.0, 15.0, 22.0, 8.0, 10.0, 35.0, 2.0, 16.0, 1.0, 4.0, 3.0, 3.0, 1.0, 9.0, 7.0, 6.0, 0.0, 0.0, 48.0, 36.0, 3.0, 18.0, 9.0, 0.0, 5.0, 1.0, 5.0, 1.0, 8.0, 10.0, 173.0, 1.0, 3.0, 6.0, 4.0, 0.0, 116.0, 36.0, 135.0, 13.0, 3.0, 18.0, 15.0, 11.0, 13.0, 197.0, 3.0, 3.0, 1.0, 5.0, 82.0, 2.0, 18.0, 11.0, 1.0, 6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5882463382692595, "mean_inference_ms": 1.8172886943961317, "mean_action_processing_ms": 0.2516378986943291, "mean_env_wait_ms": 0.19605832903369616, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0037306547164916992, "StateBufferConnector_ms": 0.003271937370300293, "ViewRequirementAgentConnector_ms": 0.09558284282684326}, "num_episodes": 18, "episode_return_max": 313.5000000000003, "episode_return_min": -595.0, "episode_return_mean": 39.28199999999986, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 3152000, "num_agent_steps_trained": 3152000, "num_env_steps_sampled": 788000, "num_env_steps_trained": 788000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 373.8683202678322, "num_env_steps_trained_throughput_per_sec": 373.8683202678322, "timesteps_total": 788000, "num_env_steps_sampled_lifetime": 788000, "num_agent_steps_sampled_lifetime": 3152000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 3152000, "timers": {"training_iteration_time_ms": 10668.108, "restore_workers_time_ms": 0.014, "training_step_time_ms": 10668.061, "sample_time_ms": 1376.188, "learn_time_ms": 9276.371, "learn_throughput": 431.203, "synch_weights_time_ms": 13.905}, "counters": {"num_env_steps_sampled": 788000, "num_env_steps_trained": 788000, "num_agent_steps_sampled": 3152000, "num_agent_steps_trained": 3152000}, "done": false, "training_iteration": 197, "trial_id": "3dae5_00000", "date": "2024-08-14_09-43-09", "timestamp": 1723642989, "time_this_iter_s": 10.741072177886963, "time_total_s": 3805.1231434345245, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b44d0430>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3805.1231434345245, "iterations_since_restore": 197, "perf": {"cpu_util_percent": 29.943749999999998, "ram_util_percent": 83.48750000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.468631380891043, "cur_kl_coeff": 0.000751694681821391, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.560351890609378, "policy_loss": -0.00225030832022192, "vf_loss": 2.5625930232345744, "vf_explained_var": 0.1277657073326212, "kl": 0.012207836502929935, "entropy": 0.737835913833487, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 373275.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.986859866235622, "cur_kl_coeff": 0.030033874511718742, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.419553571403342, "policy_loss": -0.0027219206535764946, "vf_loss": 4.4221259726418385, "vf_explained_var": 0.0293588104386809, "kl": 0.0049782274547021535, "entropy": 0.5296693823482624, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 373275.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 792000, "num_env_steps_trained": 792000, "num_agent_steps_sampled": 3168000, "num_agent_steps_trained": 3168000}, "env_runners": {"episode_reward_max": 313.5000000000003, "episode_reward_min": -595.0, "episode_reward_mean": 41.34699999999982, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -456.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 194.60000000000002, "predator_policy": 263.0}, "policy_reward_mean": {"prey_policy": -7.656500000000038, "predator_policy": 28.33}, "custom_metrics": {}, "hist_stats": {"episode_reward": [36.70000000000025, 29.90000000000014, 36.10000000000024, -18.49999999999951, -129.4000000000006, -156.1000000000005, 52.000000000000256, -155.00000000000054, -278.0000000000003, -89.60000000000122, 79.79999999999998, 98.39999999999982, 73.20000000000005, 137.9999999999997, 40.3000000000003, 126.89999999999922, -102.8000000000012, 92.69999999999996, 36.60000000000025, -595.0, 19.99999999999997, 38.80000000000028, 39.60000000000029, 36.300000000000246, -30.499999999999524, 127.79999999999959, 162.49999999999903, 27.00000000000009, 111.39999999999868, 29.000000000000124, 7.000000000000124, 34.50000000000022, 10.400000000000091, 45.20000000000038, 31.10000000000016, 205.6999999999992, 30.00000000000031, 46.70000000000033, 36.70000000000025, -6.599999999999708, 125.39999999999947, 131.79999999999944, 172.19999999999948, 90.799999999999, 37.80000000000027, 139.29999999999941, 151.59999999999957, 41.40000000000032, 115.49999999999947, 36.60000000000025, 291.4000000000002, 24.600000000000048, 153.69999999999945, 137.8999999999991, 17.999999999999936, -1.399999999999729, -0.49999999999999933, 266.49999999999966, 34.50000000000022, 186.39999999999938, 263.0000000000003, 50.00000000000024, 40.0000000000003, 5.800000000000075, 16.89999999999998, 180.39999999999944, 153.09999999999945, 33.4000000000002, 165.6999999999995, -133.40000000000038, 126.39999999999932, 35.600000000000236, -55.80000000000028, -121.00000000000034, 132.99999999999937, 313.5000000000003, -230.30000000000095, 150.39999999999935, 27.10000000000009, 6.9999999999999005, 263.70000000000005, 32.30000000000018, 15.999999999999947, 229.8999999999998, -141.50000000000045, -185.5000000000007, 153.6999999999996, 168.2999999999993, -12.8, 176.8999999999994, -148.80000000000047, 68.40000000000009, 26.900000000000087, -205.00000000000094, -126.10000000000016, 38.80000000000028, 249.8000000000001, 6.1999999999999655, 81.4, -191.00000000000074], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [13.699999999999964, 20.000000000000014, 3.1999999999999615, 13.699999999999964, -28.900000000000126, -21.999999999999744, -64.00000000000082, -11.499999999999819, -0.9999999999999846, -372.3999999999999, 20.000000000000014, -360.1, 9.499999999999964, 3.5000000000001235, -400.0, 20.000000000000014, -288.70000000000016, -364.30000000000007, -68.20000000000061, -72.4000000000006, -7.299999999999891, 70.10000000000002, 79.09999999999997, 5.299999999999965, 20.000000000000014, 15.200000000000145, 118.10000000000002, 17.899999999999988, -0.9999999999999846, 26.300000000000114, 15.799999999999963, 109.09999999999975, -24.099999999999746, -210.7000000000003, 23.600000000000065, 55.1, 20.000000000000014, 11.599999999999964, -400.0, -400.0, -13.599999999999783, 14.599999999999964, 20.000000000000014, 15.799999999999963, 19.70000000000001, 17.899999999999988, 20.000000000000014, 5.299999999999965, -85.00000000000085, -11.499999999999819, 109.99999999999991, -8.199999999999902, 35.90000000000011, 95.59999999999934, 7.399999999999965, 11.599999999999964, 13.699999999999964, 94.69999999999938, 1.0999999999999865, 17.899999999999988, -40.89999999999976, 17.899999999999988, 9.499999999999964, 20.000000000000014, -18.999999999999744, 7.399999999999965, 17.899999999999984, 26.300000000000114, 7.399999999999965, 13.699999999999964, 100.09999999999968, 80.59999999999974, -265.5999999999997, 11.599999999999964, 17.899999999999988, 21.80000000000004, 13.699999999999964, 20.000000000000014, -3.099999999999958, -56.50000000000012, 20.000000000000014, 88.39999999999986, 5.299999999999965, 117.49999999999989, 142.7, 24.50000000000008, 66.79999999999997, 20.000000000000014, 15.799999999999963, 20.000000000000014, 110.29999999999986, 20.000000000000014, 117.79999999999998, 15.799999999999963, 20.000000000000014, 19.400000000000006, 20.000000000000014, 81.50000000000011, 20.000000000000014, 8.599999999999968, 135.49999999999994, 146.9, -5.1999999999999265, 15.799999999999963, 20.000000000000014, 130.6999999999999, -0.9999999999999846, 128.8999999999997, 15.799999999999963, -17.79999999999974, -26.199999999999747, -5.1999999999999265, -50.79999999999981, 5.299999999999965, 194.60000000000002, 53.900000000000155, 17.899999999999988, 11.599999999999964, 160.39999999999998, 20.000000000000014, 151.39999999999975, 101.59999999999994, 7.399999999999965, 29.600000000000097, 20.000000000000014, 20.000000000000014, -87.70000000000081, 9.499999999999964, 13.699999999999964, -17.79999999999974, 151.40000000000003, 20.000000000000014, 9.499999999999964, 137.59999999999994, 9.499999999999979, 17.899999999999988, 20.000000000000014, 127.70000000000005, 11.599999999999964, -319.0, 107.89999999999976, 9.499999999999964, 11.599999999999964, 20.000000000000014, -135.40000000000072, -72.40000000000035, -288.99999999999994, 20.000000000000014, 13.699999999999964, 98.29999999999983, 117.20000000000005, 170.29999999999987, -55.600000000000335, -384.70000000000005, 130.69999999999987, 13.699999999999964, 11.599999999999964, 9.499999999999964, 20.000000000000014, -97.0, 132.20000000000005, 102.50000000000006, 5.299999999999965, 20.000000000000014, 15.799999999999963, -38.799999999999756, 74.60000000000008, 119.29999999999988, -318.0999999999999, 11.599999999999964, 9.499999999999964, -400.0, 147.49999999999997, -17.79999999999974, 13.699999999999964, 149.59999999999988, -400.0, 162.19999999999993, 9.499999999999964, 160.40000000000003, 23.600000000000065, -351.4, 77.60000000000002, -68.2000000000009, 7.399999999999965, 9.499999999999964, -42.99999999999976, -456.0, 15.799999999999963, -292.9000000000003, 20.000000000000014, 15.799999999999963, 106.4, 94.40000000000003, -282.4, 11.599999999999964, -7.0, -7.599999999999994, -400.0, -0.9999999999999846], "policy_predator_policy_reward": [0.0, 3.0, 5.0, 8.0, 14.0, 73.0, 12.0, 45.0, 58.0, 186.0, 2.0, 182.0, 12.0, 27.0, 25.0, 200.0, 189.0, 186.0, 44.0, 7.0, 13.0, 4.0, 7.0, 7.0, 30.0, 8.0, 1.0, 1.0, 10.0, 5.0, 0.0, 2.0, 123.0, 9.0, 9.0, 5.0, 1.0, 4.0, 200.0, 5.0, 3.0, 16.0, 1.0, 2.0, 1.0, 1.0, 7.0, 4.0, 50.0, 16.0, 19.0, 7.0, 17.0, 14.0, 6.0, 2.0, 3.0, 0.0, 1.0, 9.0, 1.0, 29.0, 0.0, 5.0, 2.0, 20.0, 0.0, 1.0, 6.0, 4.0, 12.0, 13.0, 138.0, 146.0, 6.0, 1.0, 0.0, 3.0, 16.0, 37.0, 8.0, 9.0, 2.0, 7.0, 5.0, 0.0, 3.0, 1.0, 2.0, 0.0, 8.0, 1.0, 2.0, 16.0, 2.0, 0.0, 0.0, 14.0, 0.0, 8.0, 4.0, 5.0, 12.0, 2.0, 0.0, 3.0, 0.0, 10.0, 5.0, 15.0, 22.0, 8.0, 10.0, 35.0, 2.0, 16.0, 1.0, 4.0, 3.0, 3.0, 1.0, 9.0, 7.0, 6.0, 0.0, 0.0, 48.0, 36.0, 3.0, 18.0, 9.0, 0.0, 5.0, 1.0, 5.0, 1.0, 8.0, 10.0, 173.0, 1.0, 3.0, 6.0, 4.0, 0.0, 116.0, 36.0, 135.0, 13.0, 3.0, 18.0, 15.0, 11.0, 13.0, 197.0, 3.0, 3.0, 1.0, 5.0, 82.0, 2.0, 18.0, 11.0, 1.0, 6.0, 11.0, 28.0, 14.0, 22.0, 13.0, 152.0, 5.0, 200.0, 24.0, 0.0, 2.0, 3.0, 25.0, 200.0, 4.0, 3.0, 179.0, 0.0, 36.0, 23.0, 6.0, 4.0, 263.0, 31.0, 117.0, 34.0, 1.0, 2.0, 22.0, 27.0, 129.0, 148.0, 84.0, 12.0, 200.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5881662807049248, "mean_inference_ms": 1.8175580029045313, "mean_action_processing_ms": 0.2515553562734475, "mean_env_wait_ms": 0.19605542706171483, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0037415027618408203, "StateBufferConnector_ms": 0.003136277198791504, "ViewRequirementAgentConnector_ms": 0.09702551364898682}, "num_episodes": 18, "episode_return_max": 313.5000000000003, "episode_return_min": -595.0, "episode_return_mean": 41.34699999999982, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 3168000, "num_agent_steps_trained": 3168000, "num_env_steps_sampled": 792000, "num_env_steps_trained": 792000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 367.4315350838723, "num_env_steps_trained_throughput_per_sec": 367.4315350838723, "timesteps_total": 792000, "num_env_steps_sampled_lifetime": 792000, "num_agent_steps_sampled_lifetime": 3168000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 3168000, "timers": {"training_iteration_time_ms": 10688.221, "restore_workers_time_ms": 0.014, "training_step_time_ms": 10688.173, "sample_time_ms": 1383.808, "learn_time_ms": 9289.125, "learn_throughput": 430.611, "synch_weights_time_ms": 13.544}, "counters": {"num_env_steps_sampled": 792000, "num_env_steps_trained": 792000, "num_agent_steps_sampled": 3168000, "num_agent_steps_trained": 3168000}, "done": false, "training_iteration": 198, "trial_id": "3dae5_00000", "date": "2024-08-14_09-43-20", "timestamp": 1723643000, "time_this_iter_s": 10.936891078948975, "time_total_s": 3816.0600345134735, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b39bc310>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3816.0600345134735, "iterations_since_restore": 198, "perf": {"cpu_util_percent": 34.413333333333334, "ram_util_percent": 83.61333333333333}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1188869318634114, "cur_kl_coeff": 0.000751694681821391, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.5590510264906303, "policy_loss": -0.0028172152641687603, "vf_loss": 1.5618534020015171, "vf_explained_var": 0.17037986945853661, "kl": 0.019738300127035768, "entropy": 1.06648848138789, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 375165.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.475841979627256, "cur_kl_coeff": 0.015016937255859371, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.966019757084115, "policy_loss": -0.0038120964423768106, "vf_loss": 4.969737194959449, "vf_explained_var": 0.17677552715811148, "kl": 0.006302134093718066, "entropy": 0.5130733552906248, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 375165.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 796000, "num_env_steps_trained": 796000, "num_agent_steps_sampled": 3184000, "num_agent_steps_trained": 3184000}, "env_runners": {"episode_reward_max": 313.5000000000003, "episode_reward_min": -595.0, "episode_reward_mean": 49.823999999999835, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -456.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 194.60000000000002, "predator_policy": 263.0}, "policy_reward_mean": {"prey_policy": -1.328000000000028, "predator_policy": 26.24}, "custom_metrics": {}, "hist_stats": {"episode_reward": [36.60000000000025, -595.0, 19.99999999999997, 38.80000000000028, 39.60000000000029, 36.300000000000246, -30.499999999999524, 127.79999999999959, 162.49999999999903, 27.00000000000009, 111.39999999999868, 29.000000000000124, 7.000000000000124, 34.50000000000022, 10.400000000000091, 45.20000000000038, 31.10000000000016, 205.6999999999992, 30.00000000000031, 46.70000000000033, 36.70000000000025, -6.599999999999708, 125.39999999999947, 131.79999999999944, 172.19999999999948, 90.799999999999, 37.80000000000027, 139.29999999999941, 151.59999999999957, 41.40000000000032, 115.49999999999947, 36.60000000000025, 291.4000000000002, 24.600000000000048, 153.69999999999945, 137.8999999999991, 17.999999999999936, -1.399999999999729, -0.49999999999999933, 266.49999999999966, 34.50000000000022, 186.39999999999938, 263.0000000000003, 50.00000000000024, 40.0000000000003, 5.800000000000075, 16.89999999999998, 180.39999999999944, 153.09999999999945, 33.4000000000002, 165.6999999999995, -133.40000000000038, 126.39999999999932, 35.600000000000236, -55.80000000000028, -121.00000000000034, 132.99999999999937, 313.5000000000003, -230.30000000000095, 150.39999999999935, 27.10000000000009, 6.9999999999999005, 263.70000000000005, 32.30000000000018, 15.999999999999947, 229.8999999999998, -141.50000000000045, -185.5000000000007, 153.6999999999996, 168.2999999999993, -12.8, 176.8999999999994, -148.80000000000047, 68.40000000000009, 26.900000000000087, -205.00000000000094, -126.10000000000016, 38.80000000000028, 249.8000000000001, 6.1999999999999655, 81.4, -191.00000000000074, 21.299999999999994, 161.69999999999948, 37.10000000000026, 187.09999999999934, 157.9999999999995, 38.60000000000028, 120.89999999999986, 258.79999999999967, 183.39999999999927, -154.1000000000005, 6.999999999999961, -455.2999999999999, -70.49999999999989, 202.99999999999983, 154.5999999999994, 149.3999999999995, 24.700000000000053, -303.4], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 11.599999999999964, -400.0, -400.0, -13.599999999999783, 14.599999999999964, 20.000000000000014, 15.799999999999963, 19.70000000000001, 17.899999999999988, 20.000000000000014, 5.299999999999965, -85.00000000000085, -11.499999999999819, 109.99999999999991, -8.199999999999902, 35.90000000000011, 95.59999999999934, 7.399999999999965, 11.599999999999964, 13.699999999999964, 94.69999999999938, 1.0999999999999865, 17.899999999999988, -40.89999999999976, 17.899999999999988, 9.499999999999964, 20.000000000000014, -18.999999999999744, 7.399999999999965, 17.899999999999984, 26.300000000000114, 7.399999999999965, 13.699999999999964, 100.09999999999968, 80.59999999999974, -265.5999999999997, 11.599999999999964, 17.899999999999988, 21.80000000000004, 13.699999999999964, 20.000000000000014, -3.099999999999958, -56.50000000000012, 20.000000000000014, 88.39999999999986, 5.299999999999965, 117.49999999999989, 142.7, 24.50000000000008, 66.79999999999997, 20.000000000000014, 15.799999999999963, 20.000000000000014, 110.29999999999986, 20.000000000000014, 117.79999999999998, 15.799999999999963, 20.000000000000014, 19.400000000000006, 20.000000000000014, 81.50000000000011, 20.000000000000014, 8.599999999999968, 135.49999999999994, 146.9, -5.1999999999999265, 15.799999999999963, 20.000000000000014, 130.6999999999999, -0.9999999999999846, 128.8999999999997, 15.799999999999963, -17.79999999999974, -26.199999999999747, -5.1999999999999265, -50.79999999999981, 5.299999999999965, 194.60000000000002, 53.900000000000155, 17.899999999999988, 11.599999999999964, 160.39999999999998, 20.000000000000014, 151.39999999999975, 101.59999999999994, 7.399999999999965, 29.600000000000097, 20.000000000000014, 20.000000000000014, -87.70000000000081, 9.499999999999964, 13.699999999999964, -17.79999999999974, 151.40000000000003, 20.000000000000014, 9.499999999999964, 137.59999999999994, 9.499999999999979, 17.899999999999988, 20.000000000000014, 127.70000000000005, 11.599999999999964, -319.0, 107.89999999999976, 9.499999999999964, 11.599999999999964, 20.000000000000014, -135.40000000000072, -72.40000000000035, -288.99999999999994, 20.000000000000014, 13.699999999999964, 98.29999999999983, 117.20000000000005, 170.29999999999987, -55.600000000000335, -384.70000000000005, 130.69999999999987, 13.699999999999964, 11.599999999999964, 9.499999999999964, 20.000000000000014, -97.0, 132.20000000000005, 102.50000000000006, 5.299999999999965, 20.000000000000014, 15.799999999999963, -38.799999999999756, 74.60000000000008, 119.29999999999988, -318.0999999999999, 11.599999999999964, 9.499999999999964, -400.0, 147.49999999999997, -17.79999999999974, 13.699999999999964, 149.59999999999988, -400.0, 162.19999999999993, 9.499999999999964, 160.40000000000003, 23.600000000000065, -351.4, 77.60000000000002, -68.2000000000009, 7.399999999999965, 9.499999999999964, -42.99999999999976, -456.0, 15.799999999999963, -292.9000000000003, 20.000000000000014, 15.799999999999963, 106.4, 94.40000000000003, -282.4, 11.599999999999964, -7.0, -7.599999999999994, -400.0, -0.9999999999999846, 20.000000000000014, -15.699999999999747, 20.000000000000014, 133.7, 7.099999999999966, 20.000000000000014, 168.49999999999997, 11.599999999999964, 118.99999999999997, 20.000000000000014, 20.000000000000014, 11.599999999999964, 81.50000000000003, 7.399999999999965, 149.5999999999998, 102.19999999999987, 17.899999999999988, 162.49999999999991, 12.499999999999964, -349.59999999999997, -28.299999999999827, 5.299999999999965, -314.20000000000005, -339.09999999999997, 17.899999999999988, -222.4, 102.80000000000001, 87.2000000000001, 5.299999999999965, 137.2999999999999, 131.59999999999997, 15.799999999999963, 15.799999999999963, -3.099999999999958, -303.4, -400.0], "policy_predator_policy_reward": [1.0, 4.0, 200.0, 5.0, 3.0, 16.0, 1.0, 2.0, 1.0, 1.0, 7.0, 4.0, 50.0, 16.0, 19.0, 7.0, 17.0, 14.0, 6.0, 2.0, 3.0, 0.0, 1.0, 9.0, 1.0, 29.0, 0.0, 5.0, 2.0, 20.0, 0.0, 1.0, 6.0, 4.0, 12.0, 13.0, 138.0, 146.0, 6.0, 1.0, 0.0, 3.0, 16.0, 37.0, 8.0, 9.0, 2.0, 7.0, 5.0, 0.0, 3.0, 1.0, 2.0, 0.0, 8.0, 1.0, 2.0, 16.0, 2.0, 0.0, 0.0, 14.0, 0.0, 8.0, 4.0, 5.0, 12.0, 2.0, 0.0, 3.0, 0.0, 10.0, 5.0, 15.0, 22.0, 8.0, 10.0, 35.0, 2.0, 16.0, 1.0, 4.0, 3.0, 3.0, 1.0, 9.0, 7.0, 6.0, 0.0, 0.0, 48.0, 36.0, 3.0, 18.0, 9.0, 0.0, 5.0, 1.0, 5.0, 1.0, 8.0, 10.0, 173.0, 1.0, 3.0, 6.0, 4.0, 0.0, 116.0, 36.0, 135.0, 13.0, 3.0, 18.0, 15.0, 11.0, 13.0, 197.0, 3.0, 3.0, 1.0, 5.0, 82.0, 2.0, 18.0, 11.0, 1.0, 6.0, 11.0, 28.0, 14.0, 22.0, 13.0, 152.0, 5.0, 200.0, 24.0, 0.0, 2.0, 3.0, 25.0, 200.0, 4.0, 3.0, 179.0, 0.0, 36.0, 23.0, 6.0, 4.0, 263.0, 31.0, 117.0, 34.0, 1.0, 2.0, 22.0, 27.0, 129.0, 148.0, 84.0, 12.0, 200.0, 10.0, 17.0, 0.0, 3.0, 5.0, 7.0, 3.0, 3.0, 4.0, 7.0, 12.0, 3.0, 4.0, 1.0, 31.0, 5.0, 2.0, 1.0, 2.0, 3.0, 180.0, 23.0, 7.0, 32.0, 166.0, 0.0, 134.0, 13.0, 0.0, 3.0, 9.0, 2.0, 0.0, 1.0, 11.0, 200.0, 200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5880281766071667, "mean_inference_ms": 1.8174769886335695, "mean_action_processing_ms": 0.2514554150224298, "mean_env_wait_ms": 0.19603992432011702, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003699183464050293, "StateBufferConnector_ms": 0.0030411481857299805, "ViewRequirementAgentConnector_ms": 0.09615492820739746}, "num_episodes": 18, "episode_return_max": 313.5000000000003, "episode_return_min": -595.0, "episode_return_mean": 49.823999999999835, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 3184000, "num_agent_steps_trained": 3184000, "num_env_steps_sampled": 796000, "num_env_steps_trained": 796000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 369.9009332200164, "num_env_steps_trained_throughput_per_sec": 369.9009332200164, "timesteps_total": 796000, "num_env_steps_sampled_lifetime": 796000, "num_agent_steps_sampled_lifetime": 3184000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 3184000, "timers": {"training_iteration_time_ms": 10748.131, "restore_workers_time_ms": 0.014, "training_step_time_ms": 10748.083, "sample_time_ms": 1378.899, "learn_time_ms": 9353.966, "learn_throughput": 427.626, "synch_weights_time_ms": 13.305}, "counters": {"num_env_steps_sampled": 796000, "num_env_steps_trained": 796000, "num_agent_steps_sampled": 3184000, "num_agent_steps_trained": 3184000}, "done": false, "training_iteration": 199, "trial_id": "3dae5_00000", "date": "2024-08-14_09-43-31", "timestamp": 1723643011, "time_this_iter_s": 10.851478099822998, "time_total_s": 3826.9115126132965, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b44d0310>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3826.9115126132965, "iterations_since_restore": 199, "perf": {"cpu_util_percent": 33.26666666666667, "ram_util_percent": 83.27333333333334}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3176559857432804, "cur_kl_coeff": 0.000751694681821391, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.636333385314891, "policy_loss": -0.004067282125885997, "vf_loss": 1.6403880670903221, "vf_explained_var": 0.136563797350283, "kl": 0.016765747754593618, "entropy": 0.9522155592996607, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 377055.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.317812667668812, "cur_kl_coeff": 0.015016937255859371, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.221183339754741, "policy_loss": 0.0003742755614910965, "vf_loss": 4.220624638360644, "vf_explained_var": 0.19128464227000241, "kl": 0.012281450479401702, "entropy": 0.4808793561641501, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 377055.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 800000, "num_env_steps_trained": 800000, "num_agent_steps_sampled": 3200000, "num_agent_steps_trained": 3200000}, "env_runners": {"episode_reward_max": 313.5000000000003, "episode_reward_min": -455.2999999999999, "episode_reward_mean": 65.97399999999976, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -456.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 194.60000000000002, "predator_policy": 263.0}, "policy_reward_mean": {"prey_policy": 3.5469999999999833, "predator_policy": 29.44}, "custom_metrics": {}, "hist_stats": {"episode_reward": [139.29999999999941, 151.59999999999957, 41.40000000000032, 115.49999999999947, 36.60000000000025, 291.4000000000002, 24.600000000000048, 153.69999999999945, 137.8999999999991, 17.999999999999936, -1.399999999999729, -0.49999999999999933, 266.49999999999966, 34.50000000000022, 186.39999999999938, 263.0000000000003, 50.00000000000024, 40.0000000000003, 5.800000000000075, 16.89999999999998, 180.39999999999944, 153.09999999999945, 33.4000000000002, 165.6999999999995, -133.40000000000038, 126.39999999999932, 35.600000000000236, -55.80000000000028, -121.00000000000034, 132.99999999999937, 313.5000000000003, -230.30000000000095, 150.39999999999935, 27.10000000000009, 6.9999999999999005, 263.70000000000005, 32.30000000000018, 15.999999999999947, 229.8999999999998, -141.50000000000045, -185.5000000000007, 153.6999999999996, 168.2999999999993, -12.8, 176.8999999999994, -148.80000000000047, 68.40000000000009, 26.900000000000087, -205.00000000000094, -126.10000000000016, 38.80000000000028, 249.8000000000001, 6.1999999999999655, 81.4, -191.00000000000074, 21.299999999999994, 161.69999999999948, 37.10000000000026, 187.09999999999934, 157.9999999999995, 38.60000000000028, 120.89999999999986, 258.79999999999967, 183.39999999999927, -154.1000000000005, 6.999999999999961, -455.2999999999999, -70.49999999999989, 202.99999999999983, 154.5999999999994, 149.3999999999995, 24.700000000000053, -303.4, -141.00000000000043, 86.40000000000006, -186.3000000000007, 156.29999999999927, 291.5999999999999, 31.90000000000018, 12.600000000000044, 123.99999999999955, 143.7999999999995, 288.3999999999998, 22.40000000000001, -145.50000000000043, 263.30000000000007, 31.000000000000163, -84.3000000000007, 135.19999999999925, -155.10000000000076, 92.89999999999978, 133.6999999999998, 125.79999999999941, 263.4999999999998, 156.4999999999994, 304.20000000000005, 164.49999999999932, 165.39999999999935, 298.39999999999964, 37.600000000000264], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [110.29999999999986, 20.000000000000014, 117.79999999999998, 15.799999999999963, 20.000000000000014, 19.400000000000006, 20.000000000000014, 81.50000000000011, 20.000000000000014, 8.599999999999968, 135.49999999999994, 146.9, -5.1999999999999265, 15.799999999999963, 20.000000000000014, 130.6999999999999, -0.9999999999999846, 128.8999999999997, 15.799999999999963, -17.79999999999974, -26.199999999999747, -5.1999999999999265, -50.79999999999981, 5.299999999999965, 194.60000000000002, 53.900000000000155, 17.899999999999988, 11.599999999999964, 160.39999999999998, 20.000000000000014, 151.39999999999975, 101.59999999999994, 7.399999999999965, 29.600000000000097, 20.000000000000014, 20.000000000000014, -87.70000000000081, 9.499999999999964, 13.699999999999964, -17.79999999999974, 151.40000000000003, 20.000000000000014, 9.499999999999964, 137.59999999999994, 9.499999999999979, 17.899999999999988, 20.000000000000014, 127.70000000000005, 11.599999999999964, -319.0, 107.89999999999976, 9.499999999999964, 11.599999999999964, 20.000000000000014, -135.40000000000072, -72.40000000000035, -288.99999999999994, 20.000000000000014, 13.699999999999964, 98.29999999999983, 117.20000000000005, 170.29999999999987, -55.600000000000335, -384.70000000000005, 130.69999999999987, 13.699999999999964, 11.599999999999964, 9.499999999999964, 20.000000000000014, -97.0, 132.20000000000005, 102.50000000000006, 5.299999999999965, 20.000000000000014, 15.799999999999963, -38.799999999999756, 74.60000000000008, 119.29999999999988, -318.0999999999999, 11.599999999999964, 9.499999999999964, -400.0, 147.49999999999997, -17.79999999999974, 13.699999999999964, 149.59999999999988, -400.0, 162.19999999999993, 9.499999999999964, 160.40000000000003, 23.600000000000065, -351.4, 77.60000000000002, -68.2000000000009, 7.399999999999965, 9.499999999999964, -42.99999999999976, -456.0, 15.799999999999963, -292.9000000000003, 20.000000000000014, 15.799999999999963, 106.4, 94.40000000000003, -282.4, 11.599999999999964, -7.0, -7.599999999999994, -400.0, -0.9999999999999846, 20.000000000000014, -15.699999999999747, 20.000000000000014, 133.7, 7.099999999999966, 20.000000000000014, 168.49999999999997, 11.599999999999964, 118.99999999999997, 20.000000000000014, 20.000000000000014, 11.599999999999964, 81.50000000000003, 7.399999999999965, 149.5999999999998, 102.19999999999987, 17.899999999999988, 162.49999999999991, 12.499999999999964, -349.59999999999997, -28.299999999999827, 5.299999999999965, -314.20000000000005, -339.09999999999997, 17.899999999999988, -222.4, 102.80000000000001, 87.2000000000001, 5.299999999999965, 137.2999999999999, 131.59999999999997, 15.799999999999963, 15.799999999999963, -3.099999999999958, -303.4, -400.0, 17.899999999999988, -334.9, 17.899999999999988, 48.500000000000064, -13.599999999999783, -381.7, 20.000000000000014, 128.29999999999993, 147.5, 127.10000000000002, 21.80000000000004, 1.0999999999999865, 11.599999999999964, -21.999999999999744, 59.00000000000008, 20.000000000000014, 20.000000000000014, 78.80000000000004, 155.89999999999984, 117.50000000000004, 9.499999999999964, -3.099999999999958, 16.399999999999967, -337.90000000000003, 135.79999999999995, 105.50000000000004, -0.9999999999999846, 20.000000000000014, 7.399999999999965, -393.70000000000005, 90.20000000000009, 20.000000000000014, 20.90000000000003, -357.99999999999955, 7.399999999999965, 30.500000000000036, 9.499999999999964, 93.2, 102.19999999999996, 11.599999999999964, 105.50000000000007, 136.9999999999999, -40.89999999999976, 142.3999999999999, 136.0999999999999, 163.09999999999994, 132.49999999999997, 20.000000000000014, 14.599999999999964, 147.79999999999993, 169.39999999999992, 124.99999999999989, 20.000000000000014, 11.599999999999964], "policy_predator_policy_reward": [8.0, 1.0, 2.0, 16.0, 2.0, 0.0, 0.0, 14.0, 0.0, 8.0, 4.0, 5.0, 12.0, 2.0, 0.0, 3.0, 0.0, 10.0, 5.0, 15.0, 22.0, 8.0, 10.0, 35.0, 2.0, 16.0, 1.0, 4.0, 3.0, 3.0, 1.0, 9.0, 7.0, 6.0, 0.0, 0.0, 48.0, 36.0, 3.0, 18.0, 9.0, 0.0, 5.0, 1.0, 5.0, 1.0, 8.0, 10.0, 173.0, 1.0, 3.0, 6.0, 4.0, 0.0, 116.0, 36.0, 135.0, 13.0, 3.0, 18.0, 15.0, 11.0, 13.0, 197.0, 3.0, 3.0, 1.0, 5.0, 82.0, 2.0, 18.0, 11.0, 1.0, 6.0, 11.0, 28.0, 14.0, 22.0, 13.0, 152.0, 5.0, 200.0, 24.0, 0.0, 2.0, 3.0, 25.0, 200.0, 4.0, 3.0, 179.0, 0.0, 36.0, 23.0, 6.0, 4.0, 263.0, 31.0, 117.0, 34.0, 1.0, 2.0, 22.0, 27.0, 129.0, 148.0, 84.0, 12.0, 200.0, 10.0, 17.0, 0.0, 3.0, 5.0, 7.0, 3.0, 3.0, 4.0, 7.0, 12.0, 3.0, 4.0, 1.0, 31.0, 5.0, 2.0, 1.0, 2.0, 3.0, 180.0, 23.0, 7.0, 32.0, 166.0, 0.0, 134.0, 13.0, 0.0, 3.0, 9.0, 2.0, 0.0, 1.0, 11.0, 200.0, 200.0, 1.0, 175.0, 9.0, 11.0, 200.0, 9.0, 0.0, 8.0, 4.0, 13.0, 9.0, 0.0, 20.0, 3.0, 28.0, 17.0, 23.0, 22.0, 14.0, 1.0, 5.0, 11.0, 6.0, 170.0, 16.0, 6.0, 2.0, 10.0, 197.0, 105.0, 10.0, 15.0, 2.0, 180.0, 30.0, 25.0, 5.0, 26.0, 8.0, 4.0, 12.0, 9.0, 28.0, 27.0, 3.0, 2.0, 6.0, 6.0, 3.0, 0.0, 4.0, 0.0, 4.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5881325751210398, "mean_inference_ms": 1.8174561764753197, "mean_action_processing_ms": 0.2514347490616694, "mean_env_wait_ms": 0.19602772755035155, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0036797523498535156, "StateBufferConnector_ms": 0.002977728843688965, "ViewRequirementAgentConnector_ms": 0.09575939178466797}, "num_episodes": 27, "episode_return_max": 313.5000000000003, "episode_return_min": -455.2999999999999, "episode_return_mean": 65.97399999999976, "episodes_this_iter": 27}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 3200000, "num_agent_steps_trained": 3200000, "num_env_steps_sampled": 800000, "num_env_steps_trained": 800000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 360.8393923402636, "num_env_steps_trained_throughput_per_sec": 360.8393923402636, "timesteps_total": 800000, "num_env_steps_sampled_lifetime": 800000, "num_agent_steps_sampled_lifetime": 3200000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 3200000, "timers": {"training_iteration_time_ms": 10759.961, "restore_workers_time_ms": 0.014, "training_step_time_ms": 10759.912, "sample_time_ms": 1333.397, "learn_time_ms": 9409.556, "learn_throughput": 425.1, "synch_weights_time_ms": 14.885}, "counters": {"num_env_steps_sampled": 800000, "num_env_steps_trained": 800000, "num_agent_steps_sampled": 3200000, "num_agent_steps_trained": 3200000}, "done": true, "training_iteration": 200, "trial_id": "3dae5_00000", "date": "2024-08-14_09-43-42", "timestamp": 1723643022, "time_this_iter_s": 11.148033142089844, "time_total_s": 3838.0595457553864, "pid": 85399, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b39cdd30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3838.0595457553864, "iterations_since_restore": 200, "perf": {"cpu_util_percent": 33.668749999999996, "ram_util_percent": 83.4375}}
