{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9623159837509905, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.39811100076746, "policy_loss": -0.0013382519068068296, "vf_loss": 8.398605127435513, "vf_explained_var": 0.00571092442860679, "kl": 0.004220623641965694, "entropy": 1.6050418766087324, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 945.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.1987276640834001, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.01750234258238, "policy_loss": -0.0011285895326485237, "vf_loss": 4.018112325668335, "vf_explained_var": -0.000331252308749648, "kl": 0.0025930469213694364, "entropy": 1.6067700716553541, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 945.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 4000, "num_env_steps_trained": 4000, "num_agent_steps_sampled": 16000, "num_agent_steps_trained": 16000}, "env_runners": {"episode_reward_max": 185.89999999999972, "episode_reward_min": -413.4999999999997, "episode_reward_mean": 21.366666666666536, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 3600, "policy_reward_min": {"prey_policy": -358.49999999999966, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 145.99999999999966, "predator_policy": 219.0}, "policy_reward_mean": {"prey_policy": -23.5944444444445, "predator_policy": 34.27777777777778}, "custom_metrics": {}, "hist_stats": {"episode_reward": [18.000000000000234, -175.50000000000063, 43.60000000000036, 85.10000000000016, 185.89999999999972, -413.4999999999997, 81.49999999999913, 137.99999999999926, 137.40000000000018, 95.80000000000011, 165.99999999999892, 39.3000000000002, 19.200000000000088, 73.70000000000003, -72.40000000000008, 62.500000000000036, 56.80000000000023, -156.80000000000055], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [59.60000000000007, -97.5999999999998, -217.3000000000005, -134.20000000000005, 23.60000000000008, 20.000000000000014, -7.299999999999933, 79.40000000000013, 144.19999999999993, -7.300000000000033, -274.0000000000002, -358.49999999999966, 20.000000000000014, 48.50000000000008, 14.599999999999953, 94.39999999999986, 2.2999999999996845, 91.09999999999998, 38.000000000000185, 57.80000000000001, 20.000000000000014, 145.99999999999966, 67.69999999999985, -72.39999999999995, -84.10000000000014, -15.699999999999996, -31.599999999999987, 53.3, -131.19999999999996, -98.20000000000076, 66.79999999999997, -28.299999999999777, 32.600000000000044, 18.20000000000001, -219.00000000000048, -170.8], "policy_predator_policy_reward": [2.0, 54.0, 176.0, 0.0, 0.0, 0.0, 13.0, 0.0, 34.0, 15.0, 219.0, 0.0, 0.0, 13.0, 29.0, 0.0, 3.0, 41.0, 0.0, 0.0, 0.0, 0.0, 17.0, 27.0, 82.0, 37.0, 34.0, 18.0, 28.0, 129.0, 22.0, 2.0, 0.0, 6.0, 108.0, 125.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4263244105371227, "mean_inference_ms": 3.7422154593798598, "mean_action_processing_ms": 0.6284720256069467, "mean_env_wait_ms": 0.508596069801843, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.010077158610026041, "StateBufferConnector_ms": 0.0055895911322699655, "ViewRequirementAgentConnector_ms": 0.17153090900844997}, "num_episodes": 18, "episode_return_max": 185.89999999999972, "episode_return_min": -413.4999999999997, "episode_return_mean": 21.366666666666536, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 16000, "num_agent_steps_trained": 16000, "num_env_steps_sampled": 4000, "num_env_steps_trained": 4000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 215.9191815526442, "num_env_steps_trained_throughput_per_sec": 215.9191815526442, "timesteps_total": 4000, "num_env_steps_sampled_lifetime": 4000, "num_agent_steps_sampled_lifetime": 16000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 16000, "timers": {"training_iteration_time_ms": 18525.46, "restore_workers_time_ms": 0.022, "training_step_time_ms": 18525.4, "sample_time_ms": 2948.811, "learn_time_ms": 15550.915, "learn_throughput": 257.22, "synch_weights_time_ms": 19.277}, "counters": {"num_env_steps_sampled": 4000, "num_env_steps_trained": 4000, "num_agent_steps_sampled": 16000, "num_agent_steps_trained": 16000}, "done": false, "training_iteration": 1, "trial_id": "75ec3_00000", "date": "2024-08-13_01-19-16", "timestamp": 1723526356, "time_this_iter_s": 18.593956232070923, "time_total_s": 18.593956232070923, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b1a5f820>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 18.593956232070923, "iterations_since_restore": 1, "perf": {"cpu_util_percent": 89.01111111111112, "ram_util_percent": 83.90370370370371}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.1670933192211486, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.682957064159333, "policy_loss": -0.0005879683546948606, "vf_loss": 6.683070099290717, "vf_explained_var": 0.00160138796246241, "kl": 0.004749294354036208, "entropy": 1.5927330410038982, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 2835.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.25460226842887185, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.384345967618246, "policy_loss": -0.0012281959627572663, "vf_loss": 2.385314090226693, "vf_explained_var": 0.010407973124236657, "kl": 0.002600773971293377, "entropy": 1.6016440615452157, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 2835.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 8000, "num_env_steps_trained": 8000, "num_agent_steps_sampled": 32000, "num_agent_steps_trained": 32000}, "env_runners": {"episode_reward_max": 185.89999999999972, "episode_reward_min": -413.4999999999997, "episode_reward_mean": 44.33611111111101, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 7200, "policy_reward_min": {"prey_policy": -358.49999999999966, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 145.99999999999966, "predator_policy": 219.0}, "policy_reward_mean": {"prey_policy": -3.276388888888906, "predator_policy": 25.444444444444443}, "custom_metrics": {}, "hist_stats": {"episode_reward": [18.000000000000234, -175.50000000000063, 43.60000000000036, 85.10000000000016, 185.89999999999972, -413.4999999999997, 81.49999999999913, 137.99999999999926, 137.40000000000018, 95.80000000000011, 165.99999999999892, 39.3000000000002, 19.200000000000088, 73.70000000000003, -72.40000000000008, 62.500000000000036, 56.80000000000023, -156.80000000000055, 69.09999999999991, 87.99999999999935, 66.9999999999992, 159.69999999999908, 131.7999999999998, 53.40000000000017, 44.900000000000226, -18.800000000000033, 153.49999999999972, 86.80000000000013, 26.400000000000095, 79.60000000000005, 42.000000000000185, 58.900000000000304, 24.100000000000204, -2.8999999999999773, 29.70000000000025, 118.29999999999966], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [59.60000000000007, -97.5999999999998, -217.3000000000005, -134.20000000000005, 23.60000000000008, 20.000000000000014, -7.299999999999933, 79.40000000000013, 144.19999999999993, -7.300000000000033, -274.0000000000002, -358.49999999999966, 20.000000000000014, 48.50000000000008, 14.599999999999953, 94.39999999999986, 2.2999999999996845, 91.09999999999998, 38.000000000000185, 57.80000000000001, 20.000000000000014, 145.99999999999966, 67.69999999999985, -72.39999999999995, -84.10000000000014, -15.699999999999996, -31.599999999999987, 53.3, -131.19999999999996, -98.20000000000076, 66.79999999999997, -28.299999999999777, 32.600000000000044, 18.20000000000001, -219.00000000000048, -170.8, 20.000000000000014, 46.10000000000009, 21.80000000000001, 45.200000000000145, -41.49999999999994, 24.500000000000036, 136.09999999999985, 23.60000000000001, 89.29999999999995, 42.499999999999986, 20.000000000000014, 19.400000000000023, 3.1999999999999704, -28.30000000000002, -30.999999999999787, -56.800000000000004, 21.500000000000053, 128.00000000000009, 66.8, 20.000000000000014, -14.499999999999794, 17.899999999999988, 50.60000000000001, -30.999999999999915, -56.800000000000395, 36.80000000000013, 35.30000000000015, 23.60000000000001, 43.40000000000016, -94.30000000000001, -47.19999999999981, 5.299999999999958, 30.20000000000008, -74.50000000000085, 27.200000000000113, 91.10000000000001], "policy_predator_policy_reward": [2.0, 54.0, 176.0, 0.0, 0.0, 0.0, 13.0, 0.0, 34.0, 15.0, 219.0, 0.0, 0.0, 13.0, 29.0, 0.0, 3.0, 41.0, 0.0, 0.0, 0.0, 0.0, 17.0, 27.0, 82.0, 37.0, 34.0, 18.0, 28.0, 129.0, 22.0, 2.0, 0.0, 6.0, 108.0, 125.0, 3.0, 0.0, 0.0, 21.0, 49.0, 35.0, 0.0, 0.0, 0.0, 0.0, 14.0, 0.0, 34.0, 36.0, 37.0, 32.0, 0.0, 4.0, 0.0, 0.0, 1.0, 22.0, 60.0, 0.0, 2.0, 60.0, 0.0, 0.0, 0.0, 75.0, 7.0, 32.0, 24.0, 50.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3131310447774869, "mean_inference_ms": 3.3977214232867334, "mean_action_processing_ms": 0.5652193356470231, "mean_env_wait_ms": 0.47063998850784183, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.008505582809448242, "StateBufferConnector_ms": 0.004610419273376465, "ViewRequirementAgentConnector_ms": 0.1469764444563124}, "num_episodes": 18, "episode_return_max": 185.89999999999972, "episode_return_min": -413.4999999999997, "episode_return_mean": 44.33611111111101, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 32000, "num_agent_steps_trained": 32000, "num_env_steps_sampled": 8000, "num_env_steps_trained": 8000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 246.54905207099787, "num_env_steps_trained_throughput_per_sec": 246.54905207099787, "timesteps_total": 8000, "num_env_steps_sampled_lifetime": 8000, "num_agent_steps_sampled_lifetime": 32000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 32000, "timers": {"training_iteration_time_ms": 17374.728, "restore_workers_time_ms": 0.047, "training_step_time_ms": 17374.617, "sample_time_ms": 2435.133, "learn_time_ms": 14918.534, "learn_throughput": 268.123, "synch_weights_time_ms": 16.296}, "counters": {"num_env_steps_sampled": 8000, "num_env_steps_trained": 8000, "num_agent_steps_sampled": 32000, "num_agent_steps_trained": 32000}, "done": false, "training_iteration": 2, "trial_id": "75ec3_00000", "date": "2024-08-13_01-19-36", "timestamp": 1723526376, "time_this_iter_s": 16.276997089385986, "time_total_s": 34.87095332145691, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b1a5dee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 34.87095332145691, "iterations_since_restore": 2, "perf": {"cpu_util_percent": 81.70714285714284, "ram_util_percent": 83.72500000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8100970275897197, "cur_kl_coeff": 0.05, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.588083605286936, "policy_loss": -0.002630491592248695, "vf_loss": 4.589662277004706, "vf_explained_var": 0.005821565976218572, "kl": 0.021036587844435815, "entropy": 1.5455519942379503, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 4725.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.22161611526534356, "cur_kl_coeff": 0.05, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.0400981588969156, "policy_loss": -0.003957459684485993, "vf_loss": 3.043719992751167, "vf_explained_var": 0.003472011429922921, "kl": 0.0067124788604859065, "entropy": 1.60398123251698, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 4725.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 12000, "num_env_steps_trained": 12000, "num_agent_steps_sampled": 48000, "num_agent_steps_trained": 48000}, "env_runners": {"episode_reward_max": 185.89999999999972, "episode_reward_min": -413.4999999999997, "episode_reward_mean": 40.690740740740665, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 10800, "policy_reward_min": {"prey_policy": -358.49999999999966, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 145.99999999999966, "predator_policy": 219.0}, "policy_reward_mean": {"prey_policy": -5.20092592592595, "predator_policy": 25.546296296296298}, "custom_metrics": {}, "hist_stats": {"episode_reward": [18.000000000000234, -175.50000000000063, 43.60000000000036, 85.10000000000016, 185.89999999999972, -413.4999999999997, 81.49999999999913, 137.99999999999926, 137.40000000000018, 95.80000000000011, 165.99999999999892, 39.3000000000002, 19.200000000000088, 73.70000000000003, -72.40000000000008, 62.500000000000036, 56.80000000000023, -156.80000000000055, 69.09999999999991, 87.99999999999935, 66.9999999999992, 159.69999999999908, 131.7999999999998, 53.40000000000017, 44.900000000000226, -18.800000000000033, 153.49999999999972, 86.80000000000013, 26.400000000000095, 79.60000000000005, 42.000000000000185, 58.900000000000304, 24.100000000000204, -2.8999999999999773, 29.70000000000025, 118.29999999999966, 50.2000000000002, -3.799999999999978, 104.29999999999902, 78.79999999999967, 34.80000000000035, 52.60000000000034, 19.499999999999982, -14.899999999999885, 23.200000000000223, 65.19999999999968, 54.800000000000324, -66.70000000000078, 46.30000000000018, 61.300000000000296, -0.9999999999998549, 16.800000000000082, 45.30000000000022, 34.50000000000022], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [59.60000000000007, -97.5999999999998, -217.3000000000005, -134.20000000000005, 23.60000000000008, 20.000000000000014, -7.299999999999933, 79.40000000000013, 144.19999999999993, -7.300000000000033, -274.0000000000002, -358.49999999999966, 20.000000000000014, 48.50000000000008, 14.599999999999953, 94.39999999999986, 2.2999999999996845, 91.09999999999998, 38.000000000000185, 57.80000000000001, 20.000000000000014, 145.99999999999966, 67.69999999999985, -72.39999999999995, -84.10000000000014, -15.699999999999996, -31.599999999999987, 53.3, -131.19999999999996, -98.20000000000076, 66.79999999999997, -28.299999999999777, 32.600000000000044, 18.20000000000001, -219.00000000000048, -170.8, 20.000000000000014, 46.10000000000009, 21.80000000000001, 45.200000000000145, -41.49999999999994, 24.500000000000036, 136.09999999999985, 23.60000000000001, 89.29999999999995, 42.499999999999986, 20.000000000000014, 19.400000000000023, 3.1999999999999704, -28.30000000000002, -30.999999999999787, -56.800000000000004, 21.500000000000053, 128.00000000000009, 66.8, 20.000000000000014, -14.499999999999794, 17.899999999999988, 50.60000000000001, -30.999999999999915, -56.800000000000395, 36.80000000000013, 35.30000000000015, 23.60000000000001, 43.40000000000016, -94.30000000000001, -47.19999999999981, 5.299999999999958, 30.20000000000008, -74.50000000000085, 27.200000000000113, 91.10000000000001, 37.10000000000002, -52.899999999999956, -107.80000000000032, 20.000000000000014, 115.09999999999954, -38.79999999999976, 35.60000000000003, 12.199999999999973, -11.19999999999993, 20.000000000000014, 32.600000000000165, 20.000000000000014, -26.499999999999766, 20.000000000000014, -124.90000000000006, 20.000000000000014, -96.70000000000005, 44.90000000000017, -87.10000000000066, 71.29999999999993, 20.000000000000014, -8.20000000000033, 20.000000000000014, -201.70000000000047, -45.7, 20.000000000000014, 37.40000000000019, 8.899999999999988, 20.000000000000014, -118.00000000000034, -30.99999999999998, 15.799999999999962, -13.59999999999995, 17.9000000000001, 9.499999999999973, 20.000000000000014], "policy_predator_policy_reward": [2.0, 54.0, 176.0, 0.0, 0.0, 0.0, 13.0, 0.0, 34.0, 15.0, 219.0, 0.0, 0.0, 13.0, 29.0, 0.0, 3.0, 41.0, 0.0, 0.0, 0.0, 0.0, 17.0, 27.0, 82.0, 37.0, 34.0, 18.0, 28.0, 129.0, 22.0, 2.0, 0.0, 6.0, 108.0, 125.0, 3.0, 0.0, 0.0, 21.0, 49.0, 35.0, 0.0, 0.0, 0.0, 0.0, 14.0, 0.0, 34.0, 36.0, 37.0, 32.0, 0.0, 4.0, 0.0, 0.0, 1.0, 22.0, 60.0, 0.0, 2.0, 60.0, 0.0, 0.0, 0.0, 75.0, 7.0, 32.0, 24.0, 50.0, 0.0, 0.0, 26.0, 40.0, 41.0, 43.0, 28.0, 0.0, 0.0, 31.0, 26.0, 0.0, 0.0, 0.0, 26.0, 0.0, 90.0, 0.0, 75.0, 0.0, 81.0, 0.0, 43.0, 0.0, 73.0, 42.0, 72.0, 0.0, 7.0, 8.0, 52.0, 45.0, 32.0, 0.0, 41.0, 0.0, 0.0, 5.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 27.192095128269404, "mean_inference_ms": 132.51516296452553, "mean_action_processing_ms": 26.400686982633268, "mean_env_wait_ms": 52.035069843522166, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.008226324010778356, "StateBufferConnector_ms": 0.007290751845748337, "ViewRequirementAgentConnector_ms": 0.1818681204760516}, "num_episodes": 18, "episode_return_max": 185.89999999999972, "episode_return_min": -413.4999999999997, "episode_return_mean": 40.690740740740665, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 48000, "num_agent_steps_trained": 48000, "num_env_steps_sampled": 12000, "num_env_steps_trained": 12000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 4.172084517750527, "num_env_steps_trained_throughput_per_sec": 4.172084517750527, "timesteps_total": 12000, "num_env_steps_sampled_lifetime": 12000, "num_agent_steps_sampled_lifetime": 48000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 48000, "timers": {"training_iteration_time_ms": 331167.604, "restore_workers_time_ms": 0.036, "training_step_time_ms": 331167.514, "sample_time_ms": 312826.639, "learn_time_ms": 18317.792, "learn_throughput": 218.367, "synch_weights_time_ms": 17.608}, "counters": {"num_env_steps_sampled": 12000, "num_env_steps_trained": 12000, "num_agent_steps_sampled": 48000, "num_agent_steps_trained": 48000}, "done": false, "training_iteration": 3, "trial_id": "75ec3_00000", "date": "2024-08-13_01-35-35", "timestamp": 1723527335, "time_this_iter_s": 958.9310913085938, "time_total_s": 993.8020446300507, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b1ada1f0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 993.8020446300507, "iterations_since_restore": 3, "perf": {"cpu_util_percent": 94.26097560975609, "ram_util_percent": 83.69024390243902}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4579488739134774, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.489727308005883, "policy_loss": -0.0049341828187819195, "vf_loss": 3.493348272389205, "vf_explained_var": -0.0017453506194725237, "kl": 0.017509530499580657, "entropy": 1.5007388962639703, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 6615.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.46251800027158524, "cur_kl_coeff": 0.05, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.7049929120553236, "policy_loss": -0.002440898122990297, "vf_loss": 2.7071717394092096, "vf_explained_var": 0.01889103436596179, "kl": 0.005241212919642917, "entropy": 1.5955151024949614, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 6615.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 16000, "num_env_steps_trained": 16000, "num_agent_steps_sampled": 64000, "num_agent_steps_trained": 64000}, "env_runners": {"episode_reward_max": 185.89999999999972, "episode_reward_min": -413.4999999999997, "episode_reward_mean": 33.72361111111101, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 14400, "policy_reward_min": {"prey_policy": -358.49999999999966, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 145.99999999999966, "predator_policy": 219.0}, "policy_reward_mean": {"prey_policy": -8.742361111111142, "predator_policy": 25.604166666666668}, "custom_metrics": {}, "hist_stats": {"episode_reward": [18.000000000000234, -175.50000000000063, 43.60000000000036, 85.10000000000016, 185.89999999999972, -413.4999999999997, 81.49999999999913, 137.99999999999926, 137.40000000000018, 95.80000000000011, 165.99999999999892, 39.3000000000002, 19.200000000000088, 73.70000000000003, -72.40000000000008, 62.500000000000036, 56.80000000000023, -156.80000000000055, 69.09999999999991, 87.99999999999935, 66.9999999999992, 159.69999999999908, 131.7999999999998, 53.40000000000017, 44.900000000000226, -18.800000000000033, 153.49999999999972, 86.80000000000013, 26.400000000000095, 79.60000000000005, 42.000000000000185, 58.900000000000304, 24.100000000000204, -2.8999999999999773, 29.70000000000025, 118.29999999999966, 50.2000000000002, -3.799999999999978, 104.29999999999902, 78.79999999999967, 34.80000000000035, 52.60000000000034, 19.499999999999982, -14.899999999999885, 23.200000000000223, 65.19999999999968, 54.800000000000324, -66.70000000000078, 46.30000000000018, 61.300000000000296, -0.9999999999998549, 16.800000000000082, 45.30000000000022, 34.50000000000022, 106.19999999999862, -139.10000000000073, 31.000000000000135, -105.30000000000052, -11.299999999999834, 7.499999999999947, 41.40000000000029, 40.0000000000003, 79.69999999999933, -44.09999999999958, 32.600000000000136, 43.80000000000003, 77.79999999999936, -73.30000000000084, 73.69999999999914, 40.0000000000003, -40.89999999999968, 71.0999999999999], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [59.60000000000007, -97.5999999999998, -217.3000000000005, -134.20000000000005, 23.60000000000008, 20.000000000000014, -7.299999999999933, 79.40000000000013, 144.19999999999993, -7.300000000000033, -274.0000000000002, -358.49999999999966, 20.000000000000014, 48.50000000000008, 14.599999999999953, 94.39999999999986, 2.2999999999996845, 91.09999999999998, 38.000000000000185, 57.80000000000001, 20.000000000000014, 145.99999999999966, 67.69999999999985, -72.39999999999995, -84.10000000000014, -15.699999999999996, -31.599999999999987, 53.3, -131.19999999999996, -98.20000000000076, 66.79999999999997, -28.299999999999777, 32.600000000000044, 18.20000000000001, -219.00000000000048, -170.8, 20.000000000000014, 46.10000000000009, 21.80000000000001, 45.200000000000145, -41.49999999999994, 24.500000000000036, 136.09999999999985, 23.60000000000001, 89.29999999999995, 42.499999999999986, 20.000000000000014, 19.400000000000023, 3.1999999999999704, -28.30000000000002, -30.999999999999787, -56.800000000000004, 21.500000000000053, 128.00000000000009, 66.8, 20.000000000000014, -14.499999999999794, 17.899999999999988, 50.60000000000001, -30.999999999999915, -56.800000000000395, 36.80000000000013, 35.30000000000015, 23.60000000000001, 43.40000000000016, -94.30000000000001, -47.19999999999981, 5.299999999999958, 30.20000000000008, -74.50000000000085, 27.200000000000113, 91.10000000000001, 37.10000000000002, -52.899999999999956, -107.80000000000032, 20.000000000000014, 115.09999999999954, -38.79999999999976, 35.60000000000003, 12.199999999999973, -11.19999999999993, 20.000000000000014, 32.600000000000165, 20.000000000000014, -26.499999999999766, 20.000000000000014, -124.90000000000006, 20.000000000000014, -96.70000000000005, 44.90000000000017, -87.10000000000066, 71.29999999999993, 20.000000000000014, -8.20000000000033, 20.000000000000014, -201.70000000000047, -45.7, 20.000000000000014, 37.40000000000019, 8.899999999999988, 20.000000000000014, -118.00000000000034, -30.99999999999998, 15.799999999999962, -13.59999999999995, 17.9000000000001, 9.499999999999973, 20.000000000000014, 31.40000000000014, 54.80000000000021, -173.2000000000006, -124.90000000000013, 20.000000000000014, 1.9999999999999873, -129.1000000000006, -131.20000000000022, -69.40000000000012, 7.100000000000083, -77.20000000000056, 16.69999999999997, -33.10000000000002, 27.500000000000146, 20.000000000000014, 20.000000000000014, 20.000000000000014, 55.70000000000021, -144.10000000000045, 20.000000000000014, 20.000000000000014, -6.399999999999881, 8.599999999999966, -38.799999999999756, 21.800000000000047, 56.000000000000156, -196.30000000000044, 20.000000000000014, 50.900000000000226, -11.200000000000031, 20.000000000000014, 20.000000000000014, -145.9000000000004, 20.000000000000014, 55.10000000000019, -3.999999999999987], "policy_predator_policy_reward": [2.0, 54.0, 176.0, 0.0, 0.0, 0.0, 13.0, 0.0, 34.0, 15.0, 219.0, 0.0, 0.0, 13.0, 29.0, 0.0, 3.0, 41.0, 0.0, 0.0, 0.0, 0.0, 17.0, 27.0, 82.0, 37.0, 34.0, 18.0, 28.0, 129.0, 22.0, 2.0, 0.0, 6.0, 108.0, 125.0, 3.0, 0.0, 0.0, 21.0, 49.0, 35.0, 0.0, 0.0, 0.0, 0.0, 14.0, 0.0, 34.0, 36.0, 37.0, 32.0, 0.0, 4.0, 0.0, 0.0, 1.0, 22.0, 60.0, 0.0, 2.0, 60.0, 0.0, 0.0, 0.0, 75.0, 7.0, 32.0, 24.0, 50.0, 0.0, 0.0, 26.0, 40.0, 41.0, 43.0, 28.0, 0.0, 0.0, 31.0, 26.0, 0.0, 0.0, 0.0, 26.0, 0.0, 90.0, 0.0, 75.0, 0.0, 81.0, 0.0, 43.0, 0.0, 73.0, 42.0, 72.0, 0.0, 7.0, 8.0, 52.0, 45.0, 32.0, 0.0, 41.0, 0.0, 0.0, 5.0, 17.0, 3.0, 0.0, 159.0, 9.0, 0.0, 35.0, 120.0, 5.0, 46.0, 36.0, 32.0, 10.0, 37.0, 0.0, 0.0, 4.0, 0.0, 49.0, 31.0, 0.0, 19.0, 32.0, 42.0, 0.0, 0.0, 103.0, 0.0, 0.0, 34.0, 0.0, 0.0, 47.0, 38.0, 20.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 35.36627232482182, "mean_inference_ms": 173.02134697461196, "mean_action_processing_ms": 34.49374098372275, "mean_env_wait_ms": 68.17271604789335, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00972201426823934, "StateBufferConnector_ms": 0.012827912966410318, "ViewRequirementAgentConnector_ms": 0.2487060096528795}, "num_episodes": 18, "episode_return_max": 185.89999999999972, "episode_return_min": -413.4999999999997, "episode_return_mean": 33.72361111111101, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 64000, "num_agent_steps_trained": 64000, "num_env_steps_sampled": 16000, "num_env_steps_trained": 16000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 179.54995089810313, "num_env_steps_trained_throughput_per_sec": 179.54995089810313, "timesteps_total": 16000, "num_env_steps_sampled_lifetime": 16000, "num_agent_steps_sampled_lifetime": 64000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 64000, "timers": {"training_iteration_time_ms": 253945.186, "restore_workers_time_ms": 0.031, "training_step_time_ms": 253945.105, "sample_time_ms": 235800.39, "learn_time_ms": 18120.911, "learn_throughput": 220.739, "synch_weights_time_ms": 18.602}, "counters": {"num_env_steps_sampled": 16000, "num_env_steps_trained": 16000, "num_agent_steps_sampled": 64000, "num_agent_steps_trained": 64000}, "done": false, "training_iteration": 4, "trial_id": "75ec3_00000", "date": "2024-08-13_01-35-57", "timestamp": 1723527357, "time_this_iter_s": 22.36392378807068, "time_total_s": 1016.1659684181213, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b1ada280>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1016.1659684181213, "iterations_since_restore": 4, "perf": {"cpu_util_percent": 93.52258064516127, "ram_util_percent": 83.77096774193548}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.184724526990343, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.31191065500653, "policy_loss": -0.0020951399471236284, "vf_loss": 5.313071070398603, "vf_explained_var": 0.0004091016514591439, "kl": 0.012462849446654982, "entropy": 1.471597463176364, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 8505.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.365911753919153, "cur_kl_coeff": 0.05, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.5816766978571652, "policy_loss": -0.003449072481611024, "vf_loss": 3.5847374609538485, "vf_explained_var": 0.0048535844636341885, "kl": 0.007766171873228029, "entropy": 1.5848754411021237, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 8505.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 20000, "num_env_steps_trained": 20000, "num_agent_steps_sampled": 80000, "num_agent_steps_trained": 80000}, "env_runners": {"episode_reward_max": 185.89999999999972, "episode_reward_min": -413.4999999999997, "episode_reward_mean": 11.999999999999867, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 19800, "policy_reward_min": {"prey_policy": -358.59999999999934, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 145.99999999999966, "predator_policy": 252.0}, "policy_reward_mean": {"prey_policy": -22.646464646464683, "predator_policy": 28.646464646464647}, "custom_metrics": {}, "hist_stats": {"episode_reward": [18.000000000000234, -175.50000000000063, 43.60000000000036, 85.10000000000016, 185.89999999999972, -413.4999999999997, 81.49999999999913, 137.99999999999926, 137.40000000000018, 95.80000000000011, 165.99999999999892, 39.3000000000002, 19.200000000000088, 73.70000000000003, -72.40000000000008, 62.500000000000036, 56.80000000000023, -156.80000000000055, 69.09999999999991, 87.99999999999935, 66.9999999999992, 159.69999999999908, 131.7999999999998, 53.40000000000017, 44.900000000000226, -18.800000000000033, 153.49999999999972, 86.80000000000013, 26.400000000000095, 79.60000000000005, 42.000000000000185, 58.900000000000304, 24.100000000000204, -2.8999999999999773, 29.70000000000025, 118.29999999999966, 50.2000000000002, -3.799999999999978, 104.29999999999902, 78.79999999999967, 34.80000000000035, 52.60000000000034, 19.499999999999982, -14.899999999999885, 23.200000000000223, 65.19999999999968, 54.800000000000324, -66.70000000000078, 46.30000000000018, 61.300000000000296, -0.9999999999998549, 16.800000000000082, 45.30000000000022, 34.50000000000022, 106.19999999999862, -139.10000000000073, 31.000000000000135, -105.30000000000052, -11.299999999999834, 7.499999999999947, 41.40000000000029, 40.0000000000003, 79.69999999999933, -44.09999999999958, 32.600000000000136, 43.80000000000003, 77.79999999999936, -73.30000000000084, 73.69999999999914, 40.0000000000003, -40.89999999999968, 71.0999999999999, 66.00000000000033, -272.8999999999987, -283.2999999999985, 53.50000000000052, 40.0000000000003, -77.9000000000016, 50.80000000000048, 83.89999999999901, -84.40000000000049, -95.90000000000151, 65.20000000000041, -91.0000000000001, -205.80000000000038, 77.79999999999946, -190.4000000000007, -49.4999999999996, -179.0, 45.49999999999933, -79.20000000000053, -91.40000000000035, -143.20000000000155, 145.29999999999882, -45.4999999999998, -124.29999999999974, 40.0000000000003, 87.69999999999878, 17.90000000000014], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [59.60000000000007, -97.5999999999998, -217.3000000000005, -134.20000000000005, 23.60000000000008, 20.000000000000014, -7.299999999999933, 79.40000000000013, 144.19999999999993, -7.300000000000033, -274.0000000000002, -358.49999999999966, 20.000000000000014, 48.50000000000008, 14.599999999999953, 94.39999999999986, 2.2999999999996845, 91.09999999999998, 38.000000000000185, 57.80000000000001, 20.000000000000014, 145.99999999999966, 67.69999999999985, -72.39999999999995, -84.10000000000014, -15.699999999999996, -31.599999999999987, 53.3, -131.19999999999996, -98.20000000000076, 66.79999999999997, -28.299999999999777, 32.600000000000044, 18.20000000000001, -219.00000000000048, -170.8, 20.000000000000014, 46.10000000000009, 21.80000000000001, 45.200000000000145, -41.49999999999994, 24.500000000000036, 136.09999999999985, 23.60000000000001, 89.29999999999995, 42.499999999999986, 20.000000000000014, 19.400000000000023, 3.1999999999999704, -28.30000000000002, -30.999999999999787, -56.800000000000004, 21.500000000000053, 128.00000000000009, 66.8, 20.000000000000014, -14.499999999999794, 17.899999999999988, 50.60000000000001, -30.999999999999915, -56.800000000000395, 36.80000000000013, 35.30000000000015, 23.60000000000001, 43.40000000000016, -94.30000000000001, -47.19999999999981, 5.299999999999958, 30.20000000000008, -74.50000000000085, 27.200000000000113, 91.10000000000001, 37.10000000000002, -52.899999999999956, -107.80000000000032, 20.000000000000014, 115.09999999999954, -38.79999999999976, 35.60000000000003, 12.199999999999973, -11.19999999999993, 20.000000000000014, 32.600000000000165, 20.000000000000014, -26.499999999999766, 20.000000000000014, -124.90000000000006, 20.000000000000014, -96.70000000000005, 44.90000000000017, -87.10000000000066, 71.29999999999993, 20.000000000000014, -8.20000000000033, 20.000000000000014, -201.70000000000047, -45.7, 20.000000000000014, 37.40000000000019, 8.899999999999988, 20.000000000000014, -118.00000000000034, -30.99999999999998, 15.799999999999962, -13.59999999999995, 17.9000000000001, 9.499999999999973, 20.000000000000014, 31.40000000000014, 54.80000000000021, -173.2000000000006, -124.90000000000013, 20.000000000000014, 1.9999999999999873, -129.1000000000006, -131.20000000000022, -69.40000000000012, 7.100000000000083, -77.20000000000056, 16.69999999999997, -33.10000000000002, 27.500000000000146, 20.000000000000014, 20.000000000000014, 20.000000000000014, 55.70000000000021, -144.10000000000045, 20.000000000000014, 20.000000000000014, -6.399999999999881, 8.599999999999966, -38.799999999999756, 21.800000000000047, 56.000000000000156, -196.30000000000044, 20.000000000000014, 50.900000000000226, -11.200000000000031, 20.000000000000014, 20.000000000000014, -145.9000000000004, 20.000000000000014, 55.10000000000019, -3.999999999999987, 20.000000000000014, 41.00000000000023, -358.59999999999934, -189.30000000000015, -160.80000000000018, -308.4999999999993, 20.000000000000014, 33.50000000000024, 20.000000000000014, 20.000000000000014, -97.00000000000068, -58.90000000000055, 20.000000000000014, 30.800000000000196, 17.59999999999998, 56.3000000000002, -108.10000000000029, -46.29999999999986, -59.80000000000018, -96.10000000000075, 45.200000000000244, 20.000000000000014, -277.40000000000003, 34.40000000000026, -169.60000000000022, -152.2000000000002, 57.800000000000196, 20.000000000000014, -111.00000000000038, -255.40000000000038, -152.50000000000065, 20.000000000000014, -156.00000000000003, -199.00000000000006, 9.500000000000112, 17.000000000000103, -303.3999999999992, 45.20000000000023, -163.00000000000028, -21.399999999999885, -102.10000000000076, -108.10000000000079, 55.10000000000023, 90.19999999999955, -110.2000000000003, -7.299999999999901, -59.40000000000004, -198.90000000000035, 20.000000000000014, 20.000000000000014, 20.000000000000014, 67.69999999999995, 33.200000000000145, -49.29999999999997], "policy_predator_policy_reward": [2.0, 54.0, 176.0, 0.0, 0.0, 0.0, 13.0, 0.0, 34.0, 15.0, 219.0, 0.0, 0.0, 13.0, 29.0, 0.0, 3.0, 41.0, 0.0, 0.0, 0.0, 0.0, 17.0, 27.0, 82.0, 37.0, 34.0, 18.0, 28.0, 129.0, 22.0, 2.0, 0.0, 6.0, 108.0, 125.0, 3.0, 0.0, 0.0, 21.0, 49.0, 35.0, 0.0, 0.0, 0.0, 0.0, 14.0, 0.0, 34.0, 36.0, 37.0, 32.0, 0.0, 4.0, 0.0, 0.0, 1.0, 22.0, 60.0, 0.0, 2.0, 60.0, 0.0, 0.0, 0.0, 75.0, 7.0, 32.0, 24.0, 50.0, 0.0, 0.0, 26.0, 40.0, 41.0, 43.0, 28.0, 0.0, 0.0, 31.0, 26.0, 0.0, 0.0, 0.0, 26.0, 0.0, 90.0, 0.0, 75.0, 0.0, 81.0, 0.0, 43.0, 0.0, 73.0, 42.0, 72.0, 0.0, 7.0, 8.0, 52.0, 45.0, 32.0, 0.0, 41.0, 0.0, 0.0, 5.0, 17.0, 3.0, 0.0, 159.0, 9.0, 0.0, 35.0, 120.0, 5.0, 46.0, 36.0, 32.0, 10.0, 37.0, 0.0, 0.0, 4.0, 0.0, 49.0, 31.0, 0.0, 19.0, 32.0, 42.0, 0.0, 0.0, 103.0, 0.0, 0.0, 34.0, 0.0, 0.0, 47.0, 38.0, 20.0, 0.0, 5.0, 0.0, 23.0, 252.0, 2.0, 184.0, 0.0, 0.0, 0.0, 0.0, 0.0, 78.0, 0.0, 0.0, 5.0, 5.0, 65.0, 5.0, 5.0, 55.0, 0.0, 0.0, 152.0, 0.0, 0.0, 116.0, 0.0, 0.0, 108.0, 68.0, 0.0, 83.0, 63.0, 113.0, 0.0, 19.0, 25.0, 154.0, 93.0, 0.0, 11.0, 56.0, 0.0, 0.0, 72.0, 0.0, 64.0, 70.0, 0.0, 0.0, 0.0, 0.0, 1.0, 33.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 38.86908530809412, "mean_inference_ms": 190.33340291248493, "mean_action_processing_ms": 37.9452115919311, "mean_env_wait_ms": 75.04996865133849, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.054898406520034325, "StateBufferConnector_ms": 0.01067850324842665, "ViewRequirementAgentConnector_ms": 0.253323834351819}, "num_episodes": 27, "episode_return_max": 185.89999999999972, "episode_return_min": -413.4999999999997, "episode_return_mean": 11.999999999999867, "episodes_this_iter": 27}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 80000, "num_agent_steps_trained": 80000, "num_env_steps_sampled": 20000, "num_env_steps_trained": 20000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 236.58815755364142, "num_env_steps_trained_throughput_per_sec": 236.58815755364142, "timesteps_total": 20000, "num_env_steps_sampled_lifetime": 20000, "num_agent_steps_sampled_lifetime": 80000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 80000, "timers": {"training_iteration_time_ms": 206537.554, "restore_workers_time_ms": 0.028, "training_step_time_ms": 206537.476, "sample_time_ms": 189274.519, "learn_time_ms": 17240.244, "learn_throughput": 232.015, "synch_weights_time_ms": 17.275}, "counters": {"num_env_steps_sampled": 20000, "num_env_steps_trained": 20000, "num_agent_steps_sampled": 80000, "num_agent_steps_trained": 80000}, "done": false, "training_iteration": 5, "trial_id": "75ec3_00000", "date": "2024-08-13_01-36-14", "timestamp": 1723527374, "time_this_iter_s": 16.95832085609436, "time_total_s": 1033.1242892742157, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b1bcbee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1033.1242892742157, "iterations_since_restore": 5, "perf": {"cpu_util_percent": 87.96250000000002, "ram_util_percent": 83.72916666666667}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9478353024632843, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.491083240509033, "policy_loss": -0.0016835656152574946, "vf_loss": 9.492252328660753, "vf_explained_var": 0.003551794549144765, "kl": 0.006859757858127395, "entropy": 1.4971099690154748, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 10395.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.38804578930139544, "cur_kl_coeff": 0.05, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.317281353915179, "policy_loss": -0.005709283559450082, "vf_loss": 7.322149597147785, "vf_explained_var": 0.0047013286560300795, "kl": 0.016820757453406065, "entropy": 1.518432344709124, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 10395.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 24000, "num_env_steps_trained": 24000, "num_agent_steps_sampled": 96000, "num_agent_steps_trained": 96000}, "env_runners": {"episode_reward_max": 159.69999999999908, "episode_reward_min": -458.1, "episode_reward_mean": -37.79600000000013, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -550.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 136.09999999999985, "predator_policy": 396.0}, "policy_reward_mean": {"prey_policy": -71.73800000000003, "predator_policy": 52.84}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-156.80000000000055, 69.09999999999991, 87.99999999999935, 66.9999999999992, 159.69999999999908, 131.7999999999998, 53.40000000000017, 44.900000000000226, -18.800000000000033, 153.49999999999972, 86.80000000000013, 26.400000000000095, 79.60000000000005, 42.000000000000185, 58.900000000000304, 24.100000000000204, -2.8999999999999773, 29.70000000000025, 118.29999999999966, 50.2000000000002, -3.799999999999978, 104.29999999999902, 78.79999999999967, 34.80000000000035, 52.60000000000034, 19.499999999999982, -14.899999999999885, 23.200000000000223, 65.19999999999968, 54.800000000000324, -66.70000000000078, 46.30000000000018, 61.300000000000296, -0.9999999999998549, 16.800000000000082, 45.30000000000022, 34.50000000000022, 106.19999999999862, -139.10000000000073, 31.000000000000135, -105.30000000000052, -11.299999999999834, 7.499999999999947, 41.40000000000029, 40.0000000000003, 79.69999999999933, -44.09999999999958, 32.600000000000136, 43.80000000000003, 77.79999999999936, -73.30000000000084, 73.69999999999914, 40.0000000000003, -40.89999999999968, 71.0999999999999, 66.00000000000033, -272.8999999999987, -283.2999999999985, 53.50000000000052, 40.0000000000003, -77.9000000000016, 50.80000000000048, 83.89999999999901, -84.40000000000049, -95.90000000000151, 65.20000000000041, -91.0000000000001, -205.80000000000038, 77.79999999999946, -190.4000000000007, -49.4999999999996, -179.0, 45.49999999999933, -79.20000000000053, -91.40000000000035, -143.20000000000155, 145.29999999999882, -45.4999999999998, -124.29999999999974, 40.0000000000003, 87.69999999999878, 17.90000000000014, -294.09999999999997, -206.49999999999994, -295.6, -85.29999999999997, 23.09999999999863, -141.50000000000003, -338.7, -244.10000000000002, -303.9, -274.90000000000055, -458.1, -250.30000000000035, -172.09999999999985, -303.79999999999995, -150.4999999999999, -351.69999999999993, -400.89999999999975, -177.29999999999978], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-219.00000000000048, -170.8, 20.000000000000014, 46.10000000000009, 21.80000000000001, 45.200000000000145, -41.49999999999994, 24.500000000000036, 136.09999999999985, 23.60000000000001, 89.29999999999995, 42.499999999999986, 20.000000000000014, 19.400000000000023, 3.1999999999999704, -28.30000000000002, -30.999999999999787, -56.800000000000004, 21.500000000000053, 128.00000000000009, 66.8, 20.000000000000014, -14.499999999999794, 17.899999999999988, 50.60000000000001, -30.999999999999915, -56.800000000000395, 36.80000000000013, 35.30000000000015, 23.60000000000001, 43.40000000000016, -94.30000000000001, -47.19999999999981, 5.299999999999958, 30.20000000000008, -74.50000000000085, 27.200000000000113, 91.10000000000001, 37.10000000000002, -52.899999999999956, -107.80000000000032, 20.000000000000014, 115.09999999999954, -38.79999999999976, 35.60000000000003, 12.199999999999973, -11.19999999999993, 20.000000000000014, 32.600000000000165, 20.000000000000014, -26.499999999999766, 20.000000000000014, -124.90000000000006, 20.000000000000014, -96.70000000000005, 44.90000000000017, -87.10000000000066, 71.29999999999993, 20.000000000000014, -8.20000000000033, 20.000000000000014, -201.70000000000047, -45.7, 20.000000000000014, 37.40000000000019, 8.899999999999988, 20.000000000000014, -118.00000000000034, -30.99999999999998, 15.799999999999962, -13.59999999999995, 17.9000000000001, 9.499999999999973, 20.000000000000014, 31.40000000000014, 54.80000000000021, -173.2000000000006, -124.90000000000013, 20.000000000000014, 1.9999999999999873, -129.1000000000006, -131.20000000000022, -69.40000000000012, 7.100000000000083, -77.20000000000056, 16.69999999999997, -33.10000000000002, 27.500000000000146, 20.000000000000014, 20.000000000000014, 20.000000000000014, 55.70000000000021, -144.10000000000045, 20.000000000000014, 20.000000000000014, -6.399999999999881, 8.599999999999966, -38.799999999999756, 21.800000000000047, 56.000000000000156, -196.30000000000044, 20.000000000000014, 50.900000000000226, -11.200000000000031, 20.000000000000014, 20.000000000000014, -145.9000000000004, 20.000000000000014, 55.10000000000019, -3.999999999999987, 20.000000000000014, 41.00000000000023, -358.59999999999934, -189.30000000000015, -160.80000000000018, -308.4999999999993, 20.000000000000014, 33.50000000000024, 20.000000000000014, 20.000000000000014, -97.00000000000068, -58.90000000000055, 20.000000000000014, 30.800000000000196, 17.59999999999998, 56.3000000000002, -108.10000000000029, -46.29999999999986, -59.80000000000018, -96.10000000000075, 45.200000000000244, 20.000000000000014, -277.40000000000003, 34.40000000000026, -169.60000000000022, -152.2000000000002, 57.800000000000196, 20.000000000000014, -111.00000000000038, -255.40000000000038, -152.50000000000065, 20.000000000000014, -156.00000000000003, -199.00000000000006, 9.500000000000112, 17.000000000000103, -303.3999999999992, 45.20000000000023, -163.00000000000028, -21.399999999999885, -102.10000000000076, -108.10000000000079, 55.10000000000023, 90.19999999999955, -110.2000000000003, -7.299999999999901, -59.40000000000004, -198.90000000000035, 20.000000000000014, 20.000000000000014, 20.000000000000014, 67.69999999999995, 33.200000000000145, -49.29999999999997, -269.5, -309.6, -235.60000000000008, -184.8999999999999, -362.4, -443.19999999999993, -227.00000000000028, 13.700000000000195, 18.900000000000183, -71.79999999999981, -444.0, -166.5, -377.7, -502.0, -227.10000000000002, -329.99999999999994, -361.29999999999995, -305.6, -245.99999999999997, -224.90000000000023, -337.6, -414.5, -112.29999999999981, -550.0, -412.0, -365.0999999999999, -412.30000000000007, -285.5, -198.90000000000052, -102.59999999999997, -362.40000000000003, -375.29999999999995, -426.9999999999999, -255.89999999999992, -132.10000000000002, -323.19999999999993], "policy_predator_policy_reward": [108.0, 125.0, 3.0, 0.0, 0.0, 21.0, 49.0, 35.0, 0.0, 0.0, 0.0, 0.0, 14.0, 0.0, 34.0, 36.0, 37.0, 32.0, 0.0, 4.0, 0.0, 0.0, 1.0, 22.0, 60.0, 0.0, 2.0, 60.0, 0.0, 0.0, 0.0, 75.0, 7.0, 32.0, 24.0, 50.0, 0.0, 0.0, 26.0, 40.0, 41.0, 43.0, 28.0, 0.0, 0.0, 31.0, 26.0, 0.0, 0.0, 0.0, 26.0, 0.0, 90.0, 0.0, 75.0, 0.0, 81.0, 0.0, 43.0, 0.0, 73.0, 42.0, 72.0, 0.0, 7.0, 8.0, 52.0, 45.0, 32.0, 0.0, 41.0, 0.0, 0.0, 5.0, 17.0, 3.0, 0.0, 159.0, 9.0, 0.0, 35.0, 120.0, 5.0, 46.0, 36.0, 32.0, 10.0, 37.0, 0.0, 0.0, 4.0, 0.0, 49.0, 31.0, 0.0, 19.0, 32.0, 42.0, 0.0, 0.0, 103.0, 0.0, 0.0, 34.0, 0.0, 0.0, 47.0, 38.0, 20.0, 0.0, 5.0, 0.0, 23.0, 252.0, 2.0, 184.0, 0.0, 0.0, 0.0, 0.0, 0.0, 78.0, 0.0, 0.0, 5.0, 5.0, 65.0, 5.0, 5.0, 55.0, 0.0, 0.0, 152.0, 0.0, 0.0, 116.0, 0.0, 0.0, 108.0, 68.0, 0.0, 83.0, 63.0, 113.0, 0.0, 19.0, 25.0, 154.0, 93.0, 0.0, 11.0, 56.0, 0.0, 0.0, 72.0, 0.0, 64.0, 70.0, 0.0, 0.0, 0.0, 0.0, 1.0, 33.0, 213.0, 72.0, 165.0, 49.0, 175.0, 335.0, 128.0, 0.0, 0.0, 76.0, 270.0, 199.0, 145.0, 396.0, 0.0, 313.0, 232.0, 131.0, 0.0, 196.0, 294.0, 0.0, 396.0, 16.0, 334.0, 271.0, 149.0, 245.0, 25.0, 126.0, 181.0, 205.0, 282.0, 0.0, 18.0, 260.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 45.502791125936135, "mean_inference_ms": 223.35383445524093, "mean_action_processing_ms": 44.544193892974114, "mean_env_wait_ms": 88.23293808072151, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.05363130569458008, "StateBufferConnector_ms": 0.010270833969116211, "ViewRequirementAgentConnector_ms": 0.2635084390640259}, "num_episodes": 18, "episode_return_max": 159.69999999999908, "episode_return_min": -458.1, "episode_return_mean": -37.79600000000013, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 96000, "num_agent_steps_trained": 96000, "num_env_steps_sampled": 24000, "num_env_steps_trained": 24000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 212.50156030273197, "num_env_steps_trained_throughput_per_sec": 212.50156030273197, "timesteps_total": 24000, "num_env_steps_sampled_lifetime": 24000, "num_agent_steps_sampled_lifetime": 96000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 96000, "timers": {"training_iteration_time_ms": 175251.861, "restore_workers_time_ms": 0.026, "training_step_time_ms": 175251.787, "sample_time_ms": 158091.132, "learn_time_ms": 17139.018, "learn_throughput": 233.386, "synch_weights_time_ms": 16.791}, "counters": {"num_env_steps_sampled": 24000, "num_env_steps_trained": 24000, "num_agent_steps_sampled": 96000, "num_agent_steps_trained": 96000}, "done": false, "training_iteration": 6, "trial_id": "75ec3_00000", "date": "2024-08-13_01-36-33", "timestamp": 1723527393, "time_this_iter_s": 18.863830089569092, "time_total_s": 1051.9881193637848, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b1ada1f0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1051.9881193637848, "iterations_since_restore": 6, "perf": {"cpu_util_percent": 91.12222222222223, "ram_util_percent": 83.72592592592592}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8924384316439351, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.511462927116918, "policy_loss": -0.0028487068895378677, "vf_loss": 9.513407580562369, "vf_explained_var": 0.002920221336304195, "kl": 0.012054053898458974, "entropy": 1.5114532386815107, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 12285.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.3993945209950051, "cur_kl_coeff": 0.05, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.130955688284818, "policy_loss": -0.007740190347641825, "vf_loss": 8.137730111268462, "vf_explained_var": 0.0030333119410055655, "kl": 0.019315234893093374, "entropy": 1.4201296242456587, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 12285.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 28000, "num_env_steps_trained": 28000, "num_agent_steps_sampled": 112000, "num_agent_steps_trained": 112000}, "env_runners": {"episode_reward_max": 145.29999999999882, "episode_reward_min": -458.1, "episode_reward_mean": -84.06700000000009, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -727.3, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 115.09999999999954, "predator_policy": 626.0}, "policy_reward_mean": {"prey_policy": -141.87850000000003, "predator_policy": 99.845}, "custom_metrics": {}, "hist_stats": {"episode_reward": [118.29999999999966, 50.2000000000002, -3.799999999999978, 104.29999999999902, 78.79999999999967, 34.80000000000035, 52.60000000000034, 19.499999999999982, -14.899999999999885, 23.200000000000223, 65.19999999999968, 54.800000000000324, -66.70000000000078, 46.30000000000018, 61.300000000000296, -0.9999999999998549, 16.800000000000082, 45.30000000000022, 34.50000000000022, 106.19999999999862, -139.10000000000073, 31.000000000000135, -105.30000000000052, -11.299999999999834, 7.499999999999947, 41.40000000000029, 40.0000000000003, 79.69999999999933, -44.09999999999958, 32.600000000000136, 43.80000000000003, 77.79999999999936, -73.30000000000084, 73.69999999999914, 40.0000000000003, -40.89999999999968, 71.0999999999999, 66.00000000000033, -272.8999999999987, -283.2999999999985, 53.50000000000052, 40.0000000000003, -77.9000000000016, 50.80000000000048, 83.89999999999901, -84.40000000000049, -95.90000000000151, 65.20000000000041, -91.0000000000001, -205.80000000000038, 77.79999999999946, -190.4000000000007, -49.4999999999996, -179.0, 45.49999999999933, -79.20000000000053, -91.40000000000035, -143.20000000000155, 145.29999999999882, -45.4999999999998, -124.29999999999974, 40.0000000000003, 87.69999999999878, 17.90000000000014, -294.09999999999997, -206.49999999999994, -295.6, -85.29999999999997, 23.09999999999863, -141.50000000000003, -338.7, -244.10000000000002, -303.9, -274.90000000000055, -458.1, -250.30000000000035, -172.09999999999985, -303.79999999999995, -150.4999999999999, -351.69999999999993, -400.89999999999975, -177.29999999999978, -155.8, -43.80000000000061, -295.69999999999993, -188.89999999999986, -236.59999999999997, -231.39999999999984, -138.89999999999998, -240.39999999999998, -205.29999999999995, -1.8999999999999488, -266.9, -288.7, -194.89999999999998, -281.3, -263.50000000000006, -317.5000000000001, -265.9, -73.30000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [27.200000000000113, 91.10000000000001, 37.10000000000002, -52.899999999999956, -107.80000000000032, 20.000000000000014, 115.09999999999954, -38.79999999999976, 35.60000000000003, 12.199999999999973, -11.19999999999993, 20.000000000000014, 32.600000000000165, 20.000000000000014, -26.499999999999766, 20.000000000000014, -124.90000000000006, 20.000000000000014, -96.70000000000005, 44.90000000000017, -87.10000000000066, 71.29999999999993, 20.000000000000014, -8.20000000000033, 20.000000000000014, -201.70000000000047, -45.7, 20.000000000000014, 37.40000000000019, 8.899999999999988, 20.000000000000014, -118.00000000000034, -30.99999999999998, 15.799999999999962, -13.59999999999995, 17.9000000000001, 9.499999999999973, 20.000000000000014, 31.40000000000014, 54.80000000000021, -173.2000000000006, -124.90000000000013, 20.000000000000014, 1.9999999999999873, -129.1000000000006, -131.20000000000022, -69.40000000000012, 7.100000000000083, -77.20000000000056, 16.69999999999997, -33.10000000000002, 27.500000000000146, 20.000000000000014, 20.000000000000014, 20.000000000000014, 55.70000000000021, -144.10000000000045, 20.000000000000014, 20.000000000000014, -6.399999999999881, 8.599999999999966, -38.799999999999756, 21.800000000000047, 56.000000000000156, -196.30000000000044, 20.000000000000014, 50.900000000000226, -11.200000000000031, 20.000000000000014, 20.000000000000014, -145.9000000000004, 20.000000000000014, 55.10000000000019, -3.999999999999987, 20.000000000000014, 41.00000000000023, -358.59999999999934, -189.30000000000015, -160.80000000000018, -308.4999999999993, 20.000000000000014, 33.50000000000024, 20.000000000000014, 20.000000000000014, -97.00000000000068, -58.90000000000055, 20.000000000000014, 30.800000000000196, 17.59999999999998, 56.3000000000002, -108.10000000000029, -46.29999999999986, -59.80000000000018, -96.10000000000075, 45.200000000000244, 20.000000000000014, -277.40000000000003, 34.40000000000026, -169.60000000000022, -152.2000000000002, 57.800000000000196, 20.000000000000014, -111.00000000000038, -255.40000000000038, -152.50000000000065, 20.000000000000014, -156.00000000000003, -199.00000000000006, 9.500000000000112, 17.000000000000103, -303.3999999999992, 45.20000000000023, -163.00000000000028, -21.399999999999885, -102.10000000000076, -108.10000000000079, 55.10000000000023, 90.19999999999955, -110.2000000000003, -7.299999999999901, -59.40000000000004, -198.90000000000035, 20.000000000000014, 20.000000000000014, 20.000000000000014, 67.69999999999995, 33.200000000000145, -49.29999999999997, -269.5, -309.6, -235.60000000000008, -184.8999999999999, -362.4, -443.19999999999993, -227.00000000000028, 13.700000000000195, 18.900000000000183, -71.79999999999981, -444.0, -166.5, -377.7, -502.0, -227.10000000000002, -329.99999999999994, -361.29999999999995, -305.6, -245.99999999999997, -224.90000000000023, -337.6, -414.5, -112.29999999999981, -550.0, -412.0, -365.0999999999999, -412.30000000000007, -285.5, -198.90000000000052, -102.59999999999997, -362.40000000000003, -375.29999999999995, -426.9999999999999, -255.89999999999992, -132.10000000000002, -323.19999999999993, -587.3, -106.50000000000004, -174.4, -365.3999999999999, -643.0999999999999, -357.6, -396.4, -95.50000000000003, -628.3, -187.29999999999995, -420.09999999999997, -178.29999999999987, -449.90000000000003, -407.0, -625.0999999999999, -727.3, -338.29999999999995, -495.0, -277.70000000000005, -556.1999999999999, -303.8, -555.1, -351.59999999999997, -492.1, -274.0000000000002, -220.89999999999992, -487.80000000000024, -366.49999999999994, -198.50000000000009, -277.0000000000003, -329.7, -360.80000000000007, -430.9, -688.0, -461.5, -107.80000000000004], "policy_predator_policy_reward": [0.0, 0.0, 26.0, 40.0, 41.0, 43.0, 28.0, 0.0, 0.0, 31.0, 26.0, 0.0, 0.0, 0.0, 26.0, 0.0, 90.0, 0.0, 75.0, 0.0, 81.0, 0.0, 43.0, 0.0, 73.0, 42.0, 72.0, 0.0, 7.0, 8.0, 52.0, 45.0, 32.0, 0.0, 41.0, 0.0, 0.0, 5.0, 17.0, 3.0, 0.0, 159.0, 9.0, 0.0, 35.0, 120.0, 5.0, 46.0, 36.0, 32.0, 10.0, 37.0, 0.0, 0.0, 4.0, 0.0, 49.0, 31.0, 0.0, 19.0, 32.0, 42.0, 0.0, 0.0, 103.0, 0.0, 0.0, 34.0, 0.0, 0.0, 47.0, 38.0, 20.0, 0.0, 5.0, 0.0, 23.0, 252.0, 2.0, 184.0, 0.0, 0.0, 0.0, 0.0, 0.0, 78.0, 0.0, 0.0, 5.0, 5.0, 65.0, 5.0, 5.0, 55.0, 0.0, 0.0, 152.0, 0.0, 0.0, 116.0, 0.0, 0.0, 108.0, 68.0, 0.0, 83.0, 63.0, 113.0, 0.0, 19.0, 25.0, 154.0, 93.0, 0.0, 11.0, 56.0, 0.0, 0.0, 72.0, 0.0, 64.0, 70.0, 0.0, 0.0, 0.0, 0.0, 1.0, 33.0, 213.0, 72.0, 165.0, 49.0, 175.0, 335.0, 128.0, 0.0, 0.0, 76.0, 270.0, 199.0, 145.0, 396.0, 0.0, 313.0, 232.0, 131.0, 0.0, 196.0, 294.0, 0.0, 396.0, 16.0, 334.0, 271.0, 149.0, 245.0, 25.0, 126.0, 181.0, 205.0, 282.0, 0.0, 18.0, 260.0, 538.0, 0.0, 310.0, 186.0, 594.0, 111.0, 249.0, 54.0, 193.0, 386.0, 367.0, 0.0, 369.0, 349.0, 486.0, 626.0, 249.0, 379.0, 348.0, 484.0, 169.0, 423.0, 70.0, 485.0, 173.0, 127.0, 202.0, 371.0, 0.0, 212.0, 3.0, 370.0, 320.0, 533.0, 285.0, 211.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 51.54260447677774, "mean_inference_ms": 253.35449647673616, "mean_action_processing_ms": 50.53860380708277, "mean_env_wait_ms": 100.18389559923108, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.054335951805114746, "StateBufferConnector_ms": 0.010461807250976562, "ViewRequirementAgentConnector_ms": 0.2768211364746094}, "num_episodes": 18, "episode_return_max": 145.29999999999882, "episode_return_min": -458.1, "episode_return_mean": -84.06700000000009, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 112000, "num_agent_steps_trained": 112000, "num_env_steps_sampled": 28000, "num_env_steps_trained": 28000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 200.6257308867378, "num_env_steps_trained_throughput_per_sec": 200.6257308867378, "timesteps_total": 28000, "num_env_steps_sampled_lifetime": 28000, "num_agent_steps_sampled_lifetime": 112000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 112000, "timers": {"training_iteration_time_ms": 153064.114, "restore_workers_time_ms": 0.024, "training_step_time_ms": 153064.042, "sample_time_ms": 135849.55, "learn_time_ms": 17193.217, "learn_throughput": 232.65, "synch_weights_time_ms": 16.522}, "counters": {"num_env_steps_sampled": 28000, "num_env_steps_trained": 28000, "num_agent_steps_sampled": 112000, "num_agent_steps_trained": 112000}, "done": false, "training_iteration": 7, "trial_id": "75ec3_00000", "date": "2024-08-13_01-36-53", "timestamp": 1723527413, "time_this_iter_s": 20.01335906982422, "time_total_s": 1072.001478433609, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b1adfdc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1072.001478433609, "iterations_since_restore": 7, "perf": {"cpu_util_percent": 90.98571428571428, "ram_util_percent": 83.66071428571429}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9709863123400186, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.551476860046387, "policy_loss": -0.012560916388229955, "vf_loss": 8.56244296977129, "vf_explained_var": 0.006732357841320139, "kl": 0.021263844144169847, "entropy": 1.5219952040248448, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 14175.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8159547888018467, "cur_kl_coeff": 0.05, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.37909069464951, "policy_loss": -0.0012635561583376434, "vf_loss": 9.37970972313452, "vf_explained_var": 0.0010188401376128827, "kl": 0.012890256031274226, "entropy": 1.3683501743765736, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 14175.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 32000, "num_env_steps_trained": 32000, "num_agent_steps_sampled": 128000, "num_agent_steps_trained": 128000}, "env_runners": {"episode_reward_max": 145.29999999999882, "episode_reward_min": -489.3, "episode_reward_mean": -115.92400000000009, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -774.4, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 90.19999999999955, "predator_policy": 864.0}, "policy_reward_mean": {"prey_policy": -206.02200000000005, "predator_policy": 148.06}, "custom_metrics": {}, "hist_stats": {"episode_reward": [34.50000000000022, 106.19999999999862, -139.10000000000073, 31.000000000000135, -105.30000000000052, -11.299999999999834, 7.499999999999947, 41.40000000000029, 40.0000000000003, 79.69999999999933, -44.09999999999958, 32.600000000000136, 43.80000000000003, 77.79999999999936, -73.30000000000084, 73.69999999999914, 40.0000000000003, -40.89999999999968, 71.0999999999999, 66.00000000000033, -272.8999999999987, -283.2999999999985, 53.50000000000052, 40.0000000000003, -77.9000000000016, 50.80000000000048, 83.89999999999901, -84.40000000000049, -95.90000000000151, 65.20000000000041, -91.0000000000001, -205.80000000000038, 77.79999999999946, -190.4000000000007, -49.4999999999996, -179.0, 45.49999999999933, -79.20000000000053, -91.40000000000035, -143.20000000000155, 145.29999999999882, -45.4999999999998, -124.29999999999974, 40.0000000000003, 87.69999999999878, 17.90000000000014, -294.09999999999997, -206.49999999999994, -295.6, -85.29999999999997, 23.09999999999863, -141.50000000000003, -338.7, -244.10000000000002, -303.9, -274.90000000000055, -458.1, -250.30000000000035, -172.09999999999985, -303.79999999999995, -150.4999999999999, -351.69999999999993, -400.89999999999975, -177.29999999999978, -155.8, -43.80000000000061, -295.69999999999993, -188.89999999999986, -236.59999999999997, -231.39999999999984, -138.89999999999998, -240.39999999999998, -205.29999999999995, -1.8999999999999488, -266.9, -288.7, -194.89999999999998, -281.3, -263.50000000000006, -317.5000000000001, -265.9, -73.30000000000003, -115.30000000000004, -50.1999999999999, 31.79999999999975, -136.90000000000015, -53.29999999999998, 49.800000000000146, -150.00000000000003, -162.40000000000015, -218.20000000000013, -67.40000000000016, -117.29999999999978, -222.0, 24.000000000000295, -114.4999999999998, -208.3000000000001, -489.3, -205.99999999999994, -295.1999999999998], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [9.499999999999973, 20.000000000000014, 31.40000000000014, 54.80000000000021, -173.2000000000006, -124.90000000000013, 20.000000000000014, 1.9999999999999873, -129.1000000000006, -131.20000000000022, -69.40000000000012, 7.100000000000083, -77.20000000000056, 16.69999999999997, -33.10000000000002, 27.500000000000146, 20.000000000000014, 20.000000000000014, 20.000000000000014, 55.70000000000021, -144.10000000000045, 20.000000000000014, 20.000000000000014, -6.399999999999881, 8.599999999999966, -38.799999999999756, 21.800000000000047, 56.000000000000156, -196.30000000000044, 20.000000000000014, 50.900000000000226, -11.200000000000031, 20.000000000000014, 20.000000000000014, -145.9000000000004, 20.000000000000014, 55.10000000000019, -3.999999999999987, 20.000000000000014, 41.00000000000023, -358.59999999999934, -189.30000000000015, -160.80000000000018, -308.4999999999993, 20.000000000000014, 33.50000000000024, 20.000000000000014, 20.000000000000014, -97.00000000000068, -58.90000000000055, 20.000000000000014, 30.800000000000196, 17.59999999999998, 56.3000000000002, -108.10000000000029, -46.29999999999986, -59.80000000000018, -96.10000000000075, 45.200000000000244, 20.000000000000014, -277.40000000000003, 34.40000000000026, -169.60000000000022, -152.2000000000002, 57.800000000000196, 20.000000000000014, -111.00000000000038, -255.40000000000038, -152.50000000000065, 20.000000000000014, -156.00000000000003, -199.00000000000006, 9.500000000000112, 17.000000000000103, -303.3999999999992, 45.20000000000023, -163.00000000000028, -21.399999999999885, -102.10000000000076, -108.10000000000079, 55.10000000000023, 90.19999999999955, -110.2000000000003, -7.299999999999901, -59.40000000000004, -198.90000000000035, 20.000000000000014, 20.000000000000014, 20.000000000000014, 67.69999999999995, 33.200000000000145, -49.29999999999997, -269.5, -309.6, -235.60000000000008, -184.8999999999999, -362.4, -443.19999999999993, -227.00000000000028, 13.700000000000195, 18.900000000000183, -71.79999999999981, -444.0, -166.5, -377.7, -502.0, -227.10000000000002, -329.99999999999994, -361.29999999999995, -305.6, -245.99999999999997, -224.90000000000023, -337.6, -414.5, -112.29999999999981, -550.0, -412.0, -365.0999999999999, -412.30000000000007, -285.5, -198.90000000000052, -102.59999999999997, -362.40000000000003, -375.29999999999995, -426.9999999999999, -255.89999999999992, -132.10000000000002, -323.19999999999993, -587.3, -106.50000000000004, -174.4, -365.3999999999999, -643.0999999999999, -357.6, -396.4, -95.50000000000003, -628.3, -187.29999999999995, -420.09999999999997, -178.29999999999987, -449.90000000000003, -407.0, -625.0999999999999, -727.3, -338.29999999999995, -495.0, -277.70000000000005, -556.1999999999999, -303.8, -555.1, -351.59999999999997, -492.1, -274.0000000000002, -220.89999999999992, -487.80000000000024, -366.49999999999994, -198.50000000000009, -277.0000000000003, -329.7, -360.80000000000007, -430.9, -688.0, -461.5, -107.80000000000004, -403.40000000000003, -525.9000000000001, -252.00000000000003, -443.19999999999993, -269.4, -240.8000000000001, -116.50000000000007, -533.4, -374.2999999999997, -674.9999999999999, 20.000000000000014, -315.20000000000005, -55.600000000000044, -455.4000000000001, -157.99999999999991, -225.39999999999998, -334.70000000000005, -446.4999999999999, -422.79999999999995, -288.59999999999985, -238.90000000000003, -132.4, -600.7, -558.3, 20.000000000000014, -175.9999999999999, -229.90000000000046, -179.60000000000002, -310.8, -274.4999999999999, -509.7, -549.6, -774.4, -643.6, -697.2999999999998, -693.9], "policy_predator_policy_reward": [0.0, 5.0, 17.0, 3.0, 0.0, 159.0, 9.0, 0.0, 35.0, 120.0, 5.0, 46.0, 36.0, 32.0, 10.0, 37.0, 0.0, 0.0, 4.0, 0.0, 49.0, 31.0, 0.0, 19.0, 32.0, 42.0, 0.0, 0.0, 103.0, 0.0, 0.0, 34.0, 0.0, 0.0, 47.0, 38.0, 20.0, 0.0, 5.0, 0.0, 23.0, 252.0, 2.0, 184.0, 0.0, 0.0, 0.0, 0.0, 0.0, 78.0, 0.0, 0.0, 5.0, 5.0, 65.0, 5.0, 5.0, 55.0, 0.0, 0.0, 152.0, 0.0, 0.0, 116.0, 0.0, 0.0, 108.0, 68.0, 0.0, 83.0, 63.0, 113.0, 0.0, 19.0, 25.0, 154.0, 93.0, 0.0, 11.0, 56.0, 0.0, 0.0, 72.0, 0.0, 64.0, 70.0, 0.0, 0.0, 0.0, 0.0, 1.0, 33.0, 213.0, 72.0, 165.0, 49.0, 175.0, 335.0, 128.0, 0.0, 0.0, 76.0, 270.0, 199.0, 145.0, 396.0, 0.0, 313.0, 232.0, 131.0, 0.0, 196.0, 294.0, 0.0, 396.0, 16.0, 334.0, 271.0, 149.0, 245.0, 25.0, 126.0, 181.0, 205.0, 282.0, 0.0, 18.0, 260.0, 538.0, 0.0, 310.0, 186.0, 594.0, 111.0, 249.0, 54.0, 193.0, 386.0, 367.0, 0.0, 369.0, 349.0, 486.0, 626.0, 249.0, 379.0, 348.0, 484.0, 169.0, 423.0, 70.0, 485.0, 173.0, 127.0, 202.0, 371.0, 0.0, 212.0, 3.0, 370.0, 320.0, 533.0, 285.0, 211.0, 468.0, 346.0, 327.0, 318.0, 289.0, 253.0, 162.0, 351.0, 564.0, 432.0, 175.0, 170.0, 36.0, 325.0, 194.0, 27.0, 276.0, 287.0, 280.0, 364.0, 55.0, 199.0, 303.0, 634.0, 90.0, 90.0, 104.0, 191.0, 311.0, 66.0, 545.0, 25.0, 864.0, 348.0, 497.0, 599.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 42.84079454387166, "mean_inference_ms": 209.84523261681443, "mean_action_processing_ms": 48.79873400280472, "mean_env_wait_ms": 82.79223281587261, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.05735898017883301, "StateBufferConnector_ms": 0.010500788688659668, "ViewRequirementAgentConnector_ms": 0.2930072546005249}, "num_episodes": 18, "episode_return_max": 145.29999999999882, "episode_return_min": -489.3, "episode_return_mean": -115.92400000000009, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 128000, "num_agent_steps_trained": 128000, "num_env_steps_sampled": 32000, "num_env_steps_trained": 32000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 202.4475920950621, "num_env_steps_trained_throughput_per_sec": 202.4475920950621, "timesteps_total": 32000, "num_env_steps_sampled_lifetime": 32000, "num_agent_steps_sampled_lifetime": 128000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 128000, "timers": {"training_iteration_time_ms": 136400.896, "restore_workers_time_ms": 0.024, "training_step_time_ms": 136400.805, "sample_time_ms": 119215.271, "learn_time_ms": 17164.522, "learn_throughput": 233.039, "synch_weights_time_ms": 16.53}, "counters": {"num_env_steps_sampled": 32000, "num_env_steps_trained": 32000, "num_agent_steps_sampled": 128000, "num_agent_steps_trained": 128000}, "done": false, "training_iteration": 8, "trial_id": "75ec3_00000", "date": "2024-08-13_01-37-13", "timestamp": 1723527433, "time_this_iter_s": 19.80418086051941, "time_total_s": 1091.8056592941284, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b1bcbc10>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1091.8056592941284, "iterations_since_restore": 8, "perf": {"cpu_util_percent": 88.4107142857143, "ram_util_percent": 83.32142857142857}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3954575281925303, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.228872783600338, "policy_loss": -0.010436627206210265, "vf_loss": 5.236882091325427, "vf_explained_var": 0.008788798883478478, "kl": 0.021576180795277948, "entropy": 1.5047437506378012, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 16065.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.860874529447032, "cur_kl_coeff": 0.05, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.88313408200703, "policy_loss": 0.00024397281902748598, "vf_loss": 5.882105154209036, "vf_explained_var": 0.00032627005425710524, "kl": 0.015699108638736383, "entropy": 1.436123091833932, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 16065.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 36000, "num_env_steps_trained": 36000, "num_agent_steps_sampled": 144000, "num_agent_steps_trained": 144000}, "env_runners": {"episode_reward_max": 163.29999999999976, "episode_reward_min": -489.3, "episode_reward_mean": -106.84500000000008, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -774.4, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 139.6999999999998, "predator_policy": 864.0}, "policy_reward_mean": {"prey_policy": -217.0325, "predator_policy": 163.61}, "custom_metrics": {}, "hist_stats": {"episode_reward": [53.50000000000052, 40.0000000000003, -77.9000000000016, 50.80000000000048, 83.89999999999901, -84.40000000000049, -95.90000000000151, 65.20000000000041, -91.0000000000001, -205.80000000000038, 77.79999999999946, -190.4000000000007, -49.4999999999996, -179.0, 45.49999999999933, -79.20000000000053, -91.40000000000035, -143.20000000000155, 145.29999999999882, -45.4999999999998, -124.29999999999974, 40.0000000000003, 87.69999999999878, 17.90000000000014, -294.09999999999997, -206.49999999999994, -295.6, -85.29999999999997, 23.09999999999863, -141.50000000000003, -338.7, -244.10000000000002, -303.9, -274.90000000000055, -458.1, -250.30000000000035, -172.09999999999985, -303.79999999999995, -150.4999999999999, -351.69999999999993, -400.89999999999975, -177.29999999999978, -155.8, -43.80000000000061, -295.69999999999993, -188.89999999999986, -236.59999999999997, -231.39999999999984, -138.89999999999998, -240.39999999999998, -205.29999999999995, -1.8999999999999488, -266.9, -288.7, -194.89999999999998, -281.3, -263.50000000000006, -317.5000000000001, -265.9, -73.30000000000003, -115.30000000000004, -50.1999999999999, 31.79999999999975, -136.90000000000015, -53.29999999999998, 49.800000000000146, -150.00000000000003, -162.40000000000015, -218.20000000000013, -67.40000000000016, -117.29999999999978, -222.0, 24.000000000000295, -114.4999999999998, -208.3000000000001, -489.3, -205.99999999999994, -295.1999999999998, 54.10000000000004, 109.79999999999995, 1.9000000000000445, 81.89999999999912, 17.999999999999975, 163.29999999999976, 63.500000000000284, 7.299999999999929, 73.69999999999959, 66.19999999999993, 24.10000000000007, 62.50000000000051, -18.599999999999785, 48.100000000000364, -282.4, 108.19999999999993, 12.200000000000124, 28.60000000000008, -32.79999999999993, 45.40000000000038, -113.50000000000037, 161.49999999999918], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 33.50000000000024, 20.000000000000014, 20.000000000000014, -97.00000000000068, -58.90000000000055, 20.000000000000014, 30.800000000000196, 17.59999999999998, 56.3000000000002, -108.10000000000029, -46.29999999999986, -59.80000000000018, -96.10000000000075, 45.200000000000244, 20.000000000000014, -277.40000000000003, 34.40000000000026, -169.60000000000022, -152.2000000000002, 57.800000000000196, 20.000000000000014, -111.00000000000038, -255.40000000000038, -152.50000000000065, 20.000000000000014, -156.00000000000003, -199.00000000000006, 9.500000000000112, 17.000000000000103, -303.3999999999992, 45.20000000000023, -163.00000000000028, -21.399999999999885, -102.10000000000076, -108.10000000000079, 55.10000000000023, 90.19999999999955, -110.2000000000003, -7.299999999999901, -59.40000000000004, -198.90000000000035, 20.000000000000014, 20.000000000000014, 20.000000000000014, 67.69999999999995, 33.200000000000145, -49.29999999999997, -269.5, -309.6, -235.60000000000008, -184.8999999999999, -362.4, -443.19999999999993, -227.00000000000028, 13.700000000000195, 18.900000000000183, -71.79999999999981, -444.0, -166.5, -377.7, -502.0, -227.10000000000002, -329.99999999999994, -361.29999999999995, -305.6, -245.99999999999997, -224.90000000000023, -337.6, -414.5, -112.29999999999981, -550.0, -412.0, -365.0999999999999, -412.30000000000007, -285.5, -198.90000000000052, -102.59999999999997, -362.40000000000003, -375.29999999999995, -426.9999999999999, -255.89999999999992, -132.10000000000002, -323.19999999999993, -587.3, -106.50000000000004, -174.4, -365.3999999999999, -643.0999999999999, -357.6, -396.4, -95.50000000000003, -628.3, -187.29999999999995, -420.09999999999997, -178.29999999999987, -449.90000000000003, -407.0, -625.0999999999999, -727.3, -338.29999999999995, -495.0, -277.70000000000005, -556.1999999999999, -303.8, -555.1, -351.59999999999997, -492.1, -274.0000000000002, -220.89999999999992, -487.80000000000024, -366.49999999999994, -198.50000000000009, -277.0000000000003, -329.7, -360.80000000000007, -430.9, -688.0, -461.5, -107.80000000000004, -403.40000000000003, -525.9000000000001, -252.00000000000003, -443.19999999999993, -269.4, -240.8000000000001, -116.50000000000007, -533.4, -374.2999999999997, -674.9999999999999, 20.000000000000014, -315.20000000000005, -55.600000000000044, -455.4000000000001, -157.99999999999991, -225.39999999999998, -334.70000000000005, -446.4999999999999, -422.79999999999995, -288.59999999999985, -238.90000000000003, -132.4, -600.7, -558.3, 20.000000000000014, -175.9999999999999, -229.90000000000046, -179.60000000000002, -310.8, -274.4999999999999, -509.7, -549.6, -774.4, -643.6, -697.2999999999998, -693.9, -30.69999999999977, -146.2000000000001, 3.1999999999999647, -335.4, 43.40000000000025, -248.5000000000003, 20.000000000000014, -30.099999999999916, -17.799999999999756, -68.20000000000002, -484.7, 20.000000000000014, 23.60000000000001, -121.09999999999992, -78.70000000000027, -43.00000000000002, -5.2000000000000455, 56.900000000000205, -219.90000000000003, 55.10000000000017, -12.99999999999987, -7.899999999999917, 42.50000000000025, 20.000000000000014, -141.70000000000044, 46.10000000000016, 28.10000000000016, 20.000000000000014, -243.6999999999999, -450.6999999999996, 38.900000000000105, -411.69999999999993, -489.8000000000001, 20.000000000000014, -122.8000000000007, 43.40000000000025, -312.0, -5.799999999999898, 25.400000000000098, 20.000000000000014, -372.9, -112.60000000000036, 21.800000000000047, 139.6999999999998], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 78.0, 0.0, 0.0, 5.0, 5.0, 65.0, 5.0, 5.0, 55.0, 0.0, 0.0, 152.0, 0.0, 0.0, 116.0, 0.0, 0.0, 108.0, 68.0, 0.0, 83.0, 63.0, 113.0, 0.0, 19.0, 25.0, 154.0, 93.0, 0.0, 11.0, 56.0, 0.0, 0.0, 72.0, 0.0, 64.0, 70.0, 0.0, 0.0, 0.0, 0.0, 1.0, 33.0, 213.0, 72.0, 165.0, 49.0, 175.0, 335.0, 128.0, 0.0, 0.0, 76.0, 270.0, 199.0, 145.0, 396.0, 0.0, 313.0, 232.0, 131.0, 0.0, 196.0, 294.0, 0.0, 396.0, 16.0, 334.0, 271.0, 149.0, 245.0, 25.0, 126.0, 181.0, 205.0, 282.0, 0.0, 18.0, 260.0, 538.0, 0.0, 310.0, 186.0, 594.0, 111.0, 249.0, 54.0, 193.0, 386.0, 367.0, 0.0, 369.0, 349.0, 486.0, 626.0, 249.0, 379.0, 348.0, 484.0, 169.0, 423.0, 70.0, 485.0, 173.0, 127.0, 202.0, 371.0, 0.0, 212.0, 3.0, 370.0, 320.0, 533.0, 285.0, 211.0, 468.0, 346.0, 327.0, 318.0, 289.0, 253.0, 162.0, 351.0, 564.0, 432.0, 175.0, 170.0, 36.0, 325.0, 194.0, 27.0, 276.0, 287.0, 280.0, 364.0, 55.0, 199.0, 303.0, 634.0, 90.0, 90.0, 104.0, 191.0, 311.0, 66.0, 545.0, 25.0, 864.0, 348.0, 497.0, 599.0, 122.0, 109.0, 182.0, 260.0, 149.0, 58.0, 45.0, 47.0, 38.0, 66.0, 282.0, 346.0, 85.0, 76.0, 64.0, 65.0, 11.0, 11.0, 126.0, 105.0, 45.0, 0.0, 0.0, 0.0, 0.0, 77.0, 0.0, 0.0, 25.0, 387.0, 231.0, 250.0, 241.0, 241.0, 54.0, 54.0, 110.0, 175.0, 0.0, 0.0, 182.0, 190.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 36.97619922599599, "mean_inference_ms": 185.3618756695529, "mean_action_processing_ms": 35.997864957165476, "mean_env_wait_ms": 63.292202675084454, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.05358994007110596, "StateBufferConnector_ms": 0.00880444049835205, "ViewRequirementAgentConnector_ms": 0.25594472885131836}, "num_episodes": 22, "episode_return_max": 163.29999999999976, "episode_return_min": -489.3, "episode_return_mean": -106.84500000000008, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 144000, "num_agent_steps_trained": 144000, "num_env_steps_sampled": 36000, "num_env_steps_trained": 36000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 211.61821115174135, "num_env_steps_trained_throughput_per_sec": 211.61821115174135, "timesteps_total": 36000, "num_env_steps_sampled_lifetime": 36000, "num_agent_steps_sampled_lifetime": 144000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 144000, "timers": {"training_iteration_time_ms": 123345.46, "restore_workers_time_ms": 0.023, "training_step_time_ms": 123345.371, "sample_time_ms": 106242.137, "learn_time_ms": 17081.023, "learn_throughput": 234.178, "synch_weights_time_ms": 17.493}, "counters": {"num_env_steps_sampled": 36000, "num_env_steps_trained": 36000, "num_agent_steps_sampled": 144000, "num_agent_steps_trained": 144000}, "done": false, "training_iteration": 9, "trial_id": "75ec3_00000", "date": "2024-08-13_01-37-32", "timestamp": 1723527452, "time_this_iter_s": 18.955855131149292, "time_total_s": 1110.7615144252777, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b1a5ff70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1110.7615144252777, "iterations_since_restore": 9, "perf": {"cpu_util_percent": 86.0888888888889, "ram_util_percent": 83.47407407407407}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5735584459765248, "cur_kl_coeff": 0.16875, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.8705082537635924, "policy_loss": -0.004495971962913043, "vf_loss": 3.8726723768092968, "vf_explained_var": 0.024709835727378806, "kl": 0.013818347471116085, "entropy": 1.4911500911233286, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 17955.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5331198919820722, "cur_kl_coeff": 0.05, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.0016216190403733, "policy_loss": -0.00255290656646211, "vf_loss": 2.003587890712042, "vf_explained_var": -0.012560917586876602, "kl": 0.011732704682777506, "entropy": 1.4720014835791613, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 17955.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 40000, "num_env_steps_trained": 40000, "num_agent_steps_sampled": 160000, "num_agent_steps_trained": 160000}, "env_runners": {"episode_reward_max": 173.99999999999952, "episode_reward_min": -489.3, "episode_reward_mean": -85.75600000000011, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -774.4, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 140.5999999999997, "predator_policy": 864.0}, "policy_reward_mean": {"prey_policy": -206.42300000000003, "predator_policy": 163.545}, "custom_metrics": {}, "hist_stats": {"episode_reward": [17.90000000000014, -294.09999999999997, -206.49999999999994, -295.6, -85.29999999999997, 23.09999999999863, -141.50000000000003, -338.7, -244.10000000000002, -303.9, -274.90000000000055, -458.1, -250.30000000000035, -172.09999999999985, -303.79999999999995, -150.4999999999999, -351.69999999999993, -400.89999999999975, -177.29999999999978, -155.8, -43.80000000000061, -295.69999999999993, -188.89999999999986, -236.59999999999997, -231.39999999999984, -138.89999999999998, -240.39999999999998, -205.29999999999995, -1.8999999999999488, -266.9, -288.7, -194.89999999999998, -281.3, -263.50000000000006, -317.5000000000001, -265.9, -73.30000000000003, -115.30000000000004, -50.1999999999999, 31.79999999999975, -136.90000000000015, -53.29999999999998, 49.800000000000146, -150.00000000000003, -162.40000000000015, -218.20000000000013, -67.40000000000016, -117.29999999999978, -222.0, 24.000000000000295, -114.4999999999998, -208.3000000000001, -489.3, -205.99999999999994, -295.1999999999998, 54.10000000000004, 109.79999999999995, 1.9000000000000445, 81.89999999999912, 17.999999999999975, 163.29999999999976, 63.500000000000284, 7.299999999999929, 73.69999999999959, 66.19999999999993, 24.10000000000007, 62.50000000000051, -18.599999999999785, 48.100000000000364, -282.4, 108.19999999999993, 12.200000000000124, 28.60000000000008, -32.79999999999993, 45.40000000000038, -113.50000000000037, 161.49999999999918, 31.30000000000017, -125.90000000000134, 173.99999999999952, 57.09999999999996, 32.80000000000032, 35.90000000000018, 89.59999999999863, 119.49999999999929, 166.79999999999885, 93.09999999999923, -7.199999999999786, -58.999999999999815, 93.99999999999918, 54.40000000000044, -5.199999999999781, 126.99999999999949, 74.69999999999976, 170.9999999999989, -65.90000000000185, 5.199999999999985, 137.29999999999995, 70.89999999999985, 69.70000000000006], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [33.200000000000145, -49.29999999999997, -269.5, -309.6, -235.60000000000008, -184.8999999999999, -362.4, -443.19999999999993, -227.00000000000028, 13.700000000000195, 18.900000000000183, -71.79999999999981, -444.0, -166.5, -377.7, -502.0, -227.10000000000002, -329.99999999999994, -361.29999999999995, -305.6, -245.99999999999997, -224.90000000000023, -337.6, -414.5, -112.29999999999981, -550.0, -412.0, -365.0999999999999, -412.30000000000007, -285.5, -198.90000000000052, -102.59999999999997, -362.40000000000003, -375.29999999999995, -426.9999999999999, -255.89999999999992, -132.10000000000002, -323.19999999999993, -587.3, -106.50000000000004, -174.4, -365.3999999999999, -643.0999999999999, -357.6, -396.4, -95.50000000000003, -628.3, -187.29999999999995, -420.09999999999997, -178.29999999999987, -449.90000000000003, -407.0, -625.0999999999999, -727.3, -338.29999999999995, -495.0, -277.70000000000005, -556.1999999999999, -303.8, -555.1, -351.59999999999997, -492.1, -274.0000000000002, -220.89999999999992, -487.80000000000024, -366.49999999999994, -198.50000000000009, -277.0000000000003, -329.7, -360.80000000000007, -430.9, -688.0, -461.5, -107.80000000000004, -403.40000000000003, -525.9000000000001, -252.00000000000003, -443.19999999999993, -269.4, -240.8000000000001, -116.50000000000007, -533.4, -374.2999999999997, -674.9999999999999, 20.000000000000014, -315.20000000000005, -55.600000000000044, -455.4000000000001, -157.99999999999991, -225.39999999999998, -334.70000000000005, -446.4999999999999, -422.79999999999995, -288.59999999999985, -238.90000000000003, -132.4, -600.7, -558.3, 20.000000000000014, -175.9999999999999, -229.90000000000046, -179.60000000000002, -310.8, -274.4999999999999, -509.7, -549.6, -774.4, -643.6, -697.2999999999998, -693.9, -30.69999999999977, -146.2000000000001, 3.1999999999999647, -335.4, 43.40000000000025, -248.5000000000003, 20.000000000000014, -30.099999999999916, -17.799999999999756, -68.20000000000002, -484.7, 20.000000000000014, 23.60000000000001, -121.09999999999992, -78.70000000000027, -43.00000000000002, -5.2000000000000455, 56.900000000000205, -219.90000000000003, 55.10000000000017, -12.99999999999987, -7.899999999999917, 42.50000000000025, 20.000000000000014, -141.70000000000044, 46.10000000000016, 28.10000000000016, 20.000000000000014, -243.6999999999999, -450.6999999999996, 38.900000000000105, -411.69999999999993, -489.8000000000001, 20.000000000000014, -122.8000000000007, 43.40000000000025, -312.0, -5.799999999999898, 25.400000000000098, 20.000000000000014, -372.9, -112.60000000000036, 21.800000000000047, 139.6999999999998, 20.000000000000014, -0.6999999999999993, -156.40000000000055, -71.50000000000048, 140.5999999999997, -7.59999999999998, 56.000000000000135, -25.899999999999885, -62.2000000000005, 20.000000000000014, 8.899999999999961, 20.000000000000014, 69.79999999999978, 15.799999999999963, 20.000000000000014, 78.4999999999999, 66.8, 94.99999999999969, 73.09999999999962, 20.000000000000014, -59.80000000000027, -21.399999999999864, 23.000000000000092, -315.99999999999943, 56.00000000000013, 20.000000000000014, 24.2000000000001, 3.1999999999999615, -59.80000000000031, 11.599999999999964, -30.399999999999814, 115.39999999999984, 48.80000000000023, 14.899999999999967, 66.80000000000005, 84.19999999999987, -51.400000000000034, -53.50000000000015, 28.100000000000144, -61.90000000000054, -474.69999999999925, 20.000000000000014, 49.70000000000019, -17.79999999999987, 49.70000000000022, 20.000000000000014], "policy_predator_policy_reward": [1.0, 33.0, 213.0, 72.0, 165.0, 49.0, 175.0, 335.0, 128.0, 0.0, 0.0, 76.0, 270.0, 199.0, 145.0, 396.0, 0.0, 313.0, 232.0, 131.0, 0.0, 196.0, 294.0, 0.0, 396.0, 16.0, 334.0, 271.0, 149.0, 245.0, 25.0, 126.0, 181.0, 205.0, 282.0, 0.0, 18.0, 260.0, 538.0, 0.0, 310.0, 186.0, 594.0, 111.0, 249.0, 54.0, 193.0, 386.0, 367.0, 0.0, 369.0, 349.0, 486.0, 626.0, 249.0, 379.0, 348.0, 484.0, 169.0, 423.0, 70.0, 485.0, 173.0, 127.0, 202.0, 371.0, 0.0, 212.0, 3.0, 370.0, 320.0, 533.0, 285.0, 211.0, 468.0, 346.0, 327.0, 318.0, 289.0, 253.0, 162.0, 351.0, 564.0, 432.0, 175.0, 170.0, 36.0, 325.0, 194.0, 27.0, 276.0, 287.0, 280.0, 364.0, 55.0, 199.0, 303.0, 634.0, 90.0, 90.0, 104.0, 191.0, 311.0, 66.0, 545.0, 25.0, 864.0, 348.0, 497.0, 599.0, 122.0, 109.0, 182.0, 260.0, 149.0, 58.0, 45.0, 47.0, 38.0, 66.0, 282.0, 346.0, 85.0, 76.0, 64.0, 65.0, 11.0, 11.0, 126.0, 105.0, 45.0, 0.0, 0.0, 0.0, 0.0, 77.0, 0.0, 0.0, 25.0, 387.0, 231.0, 250.0, 241.0, 241.0, 54.0, 54.0, 110.0, 175.0, 0.0, 0.0, 182.0, 190.0, 0.0, 0.0, 0.0, 12.0, 34.0, 68.0, 14.0, 27.0, 27.0, 0.0, 24.0, 51.0, 0.0, 7.0, 0.0, 4.0, 21.0, 0.0, 0.0, 5.0, 0.0, 0.0, 33.0, 41.0, 165.0, 69.0, 0.0, 18.0, 0.0, 27.0, 24.0, 19.0, 18.0, 24.0, 11.0, 0.0, 0.0, 20.0, 0.0, 39.0, 39.0, 0.0, 285.0, 307.0, 21.0, 18.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 30.643715243972192, "mean_inference_ms": 149.69876032792726, "mean_action_processing_ms": 33.88873235593122, "mean_env_wait_ms": 59.09994735025258, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.011054754257202148, "StateBufferConnector_ms": 0.010146260261535645, "ViewRequirementAgentConnector_ms": 0.2500110864639282}, "num_episodes": 23, "episode_return_max": 173.99999999999952, "episode_return_min": -489.3, "episode_return_mean": -85.75600000000011, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 160000, "num_agent_steps_trained": 160000, "num_env_steps_sampled": 40000, "num_env_steps_trained": 40000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 186.09315587866945, "num_env_steps_trained_throughput_per_sec": 186.09315587866945, "timesteps_total": 40000, "num_env_steps_sampled_lifetime": 40000, "num_agent_steps_sampled_lifetime": 160000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 160000, "timers": {"training_iteration_time_ms": 113160.376, "restore_workers_time_ms": 0.023, "training_step_time_ms": 113160.29, "sample_time_ms": 95860.618, "learn_time_ms": 17277.685, "learn_throughput": 231.512, "synch_weights_time_ms": 17.433}, "counters": {"num_env_steps_sampled": 40000, "num_env_steps_trained": 40000, "num_agent_steps_sampled": 160000, "num_agent_steps_trained": 160000}, "done": false, "training_iteration": 10, "trial_id": "75ec3_00000", "date": "2024-08-13_01-37-54", "timestamp": 1723527474, "time_this_iter_s": 21.559766054153442, "time_total_s": 1132.3212804794312, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b1bc68b0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1132.3212804794312, "iterations_since_restore": 10, "perf": {"cpu_util_percent": 86.86, "ram_util_percent": 83.55}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2707406933424334, "cur_kl_coeff": 0.16875, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.3473070511742242, "policy_loss": -0.0019199313331030744, "vf_loss": 2.348166319365224, "vf_explained_var": 0.04855430561398703, "kl": 0.006285363865775803, "entropy": 1.4619527039704499, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 19845.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.33370334155187403, "cur_kl_coeff": 0.05, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.0175367431981224, "policy_loss": -0.0007850077105488963, "vf_loss": 1.0180820896827354, "vf_explained_var": -0.013224316999395058, "kl": 0.004793214073761769, "entropy": 1.461238270398801, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 19845.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 44000, "num_env_steps_trained": 44000, "num_agent_steps_sampled": 176000, "num_agent_steps_trained": 176000}, "env_runners": {"episode_reward_max": 173.99999999999952, "episode_reward_min": -489.3, "episode_reward_mean": -34.066000000000116, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -774.4, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 140.5999999999997, "predator_policy": 864.0}, "policy_reward_mean": {"prey_policy": -154.19799999999998, "predator_policy": 137.165}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-177.29999999999978, -155.8, -43.80000000000061, -295.69999999999993, -188.89999999999986, -236.59999999999997, -231.39999999999984, -138.89999999999998, -240.39999999999998, -205.29999999999995, -1.8999999999999488, -266.9, -288.7, -194.89999999999998, -281.3, -263.50000000000006, -317.5000000000001, -265.9, -73.30000000000003, -115.30000000000004, -50.1999999999999, 31.79999999999975, -136.90000000000015, -53.29999999999998, 49.800000000000146, -150.00000000000003, -162.40000000000015, -218.20000000000013, -67.40000000000016, -117.29999999999978, -222.0, 24.000000000000295, -114.4999999999998, -208.3000000000001, -489.3, -205.99999999999994, -295.1999999999998, 54.10000000000004, 109.79999999999995, 1.9000000000000445, 81.89999999999912, 17.999999999999975, 163.29999999999976, 63.500000000000284, 7.299999999999929, 73.69999999999959, 66.19999999999993, 24.10000000000007, 62.50000000000051, -18.599999999999785, 48.100000000000364, -282.4, 108.19999999999993, 12.200000000000124, 28.60000000000008, -32.79999999999993, 45.40000000000038, -113.50000000000037, 161.49999999999918, 31.30000000000017, -125.90000000000134, 173.99999999999952, 57.09999999999996, 32.80000000000032, 35.90000000000018, 89.59999999999863, 119.49999999999929, 166.79999999999885, 93.09999999999923, -7.199999999999786, -58.999999999999815, 93.99999999999918, 54.40000000000044, -5.199999999999781, 126.99999999999949, 74.69999999999976, 170.9999999999989, -65.90000000000185, 5.199999999999985, 137.29999999999995, 70.89999999999985, 69.70000000000006, 21.400000000000105, 80.09999999999921, 95.3999999999989, 39.40000000000029, 17.499999999999954, 44.50000000000037, 67.00000000000026, 23.200000000000074, 68.19999999999995, 41.800000000000324, 84.79999999999896, 90.19999999999858, 43.90000000000027, 92.09999999999968, 50.000000000000284, -4.699999999999736, 27.90000000000011, 55.3000000000005], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-132.10000000000002, -323.19999999999993, -587.3, -106.50000000000004, -174.4, -365.3999999999999, -643.0999999999999, -357.6, -396.4, -95.50000000000003, -628.3, -187.29999999999995, -420.09999999999997, -178.29999999999987, -449.90000000000003, -407.0, -625.0999999999999, -727.3, -338.29999999999995, -495.0, -277.70000000000005, -556.1999999999999, -303.8, -555.1, -351.59999999999997, -492.1, -274.0000000000002, -220.89999999999992, -487.80000000000024, -366.49999999999994, -198.50000000000009, -277.0000000000003, -329.7, -360.80000000000007, -430.9, -688.0, -461.5, -107.80000000000004, -403.40000000000003, -525.9000000000001, -252.00000000000003, -443.19999999999993, -269.4, -240.8000000000001, -116.50000000000007, -533.4, -374.2999999999997, -674.9999999999999, 20.000000000000014, -315.20000000000005, -55.600000000000044, -455.4000000000001, -157.99999999999991, -225.39999999999998, -334.70000000000005, -446.4999999999999, -422.79999999999995, -288.59999999999985, -238.90000000000003, -132.4, -600.7, -558.3, 20.000000000000014, -175.9999999999999, -229.90000000000046, -179.60000000000002, -310.8, -274.4999999999999, -509.7, -549.6, -774.4, -643.6, -697.2999999999998, -693.9, -30.69999999999977, -146.2000000000001, 3.1999999999999647, -335.4, 43.40000000000025, -248.5000000000003, 20.000000000000014, -30.099999999999916, -17.799999999999756, -68.20000000000002, -484.7, 20.000000000000014, 23.60000000000001, -121.09999999999992, -78.70000000000027, -43.00000000000002, -5.2000000000000455, 56.900000000000205, -219.90000000000003, 55.10000000000017, -12.99999999999987, -7.899999999999917, 42.50000000000025, 20.000000000000014, -141.70000000000044, 46.10000000000016, 28.10000000000016, 20.000000000000014, -243.6999999999999, -450.6999999999996, 38.900000000000105, -411.69999999999993, -489.8000000000001, 20.000000000000014, -122.8000000000007, 43.40000000000025, -312.0, -5.799999999999898, 25.400000000000098, 20.000000000000014, -372.9, -112.60000000000036, 21.800000000000047, 139.6999999999998, 20.000000000000014, -0.6999999999999993, -156.40000000000055, -71.50000000000048, 140.5999999999997, -7.59999999999998, 56.000000000000135, -25.899999999999885, -62.2000000000005, 20.000000000000014, 8.899999999999961, 20.000000000000014, 69.79999999999978, 15.799999999999963, 20.000000000000014, 78.4999999999999, 66.8, 94.99999999999969, 73.09999999999962, 20.000000000000014, -59.80000000000027, -21.399999999999864, 23.000000000000092, -315.99999999999943, 56.00000000000013, 20.000000000000014, 24.2000000000001, 3.1999999999999615, -59.80000000000031, 11.599999999999964, -30.399999999999814, 115.39999999999984, 48.80000000000023, 14.899999999999967, 66.80000000000005, 84.19999999999987, -51.400000000000034, -53.50000000000015, 28.100000000000144, -61.90000000000054, -474.69999999999925, 20.000000000000014, 49.70000000000019, -17.79999999999987, 49.70000000000022, 20.000000000000014, -28.59999999999979, 20.000000000000014, 49.10000000000016, 20.000000000000014, 70.69999999999972, 4.699999999999992, 7.399999999999972, 20.000000000000014, 17.899999999999988, -51.39999999999985, 20.000000000000014, 24.50000000000008, 45.20000000000021, 21.80000000000004, 6.4999999999999805, -7.299999999999901, 18.200000000000017, 20.000000000000014, 21.80000000000004, 20.000000000000014, 28.100000000000154, 46.70000000000022, 13.39999999999997, 66.80000000000001, 30.800000000000207, -7.8999999999999595, 67.69999999999985, -34.59999999999975, -31.29999999999984, 41.30000000000017, -26.499999999999822, -26.199999999999754, 20.000000000000014, -3.099999999999958, 35.300000000000246, 20.000000000000014], "policy_predator_policy_reward": [18.0, 260.0, 538.0, 0.0, 310.0, 186.0, 594.0, 111.0, 249.0, 54.0, 193.0, 386.0, 367.0, 0.0, 369.0, 349.0, 486.0, 626.0, 249.0, 379.0, 348.0, 484.0, 169.0, 423.0, 70.0, 485.0, 173.0, 127.0, 202.0, 371.0, 0.0, 212.0, 3.0, 370.0, 320.0, 533.0, 285.0, 211.0, 468.0, 346.0, 327.0, 318.0, 289.0, 253.0, 162.0, 351.0, 564.0, 432.0, 175.0, 170.0, 36.0, 325.0, 194.0, 27.0, 276.0, 287.0, 280.0, 364.0, 55.0, 199.0, 303.0, 634.0, 90.0, 90.0, 104.0, 191.0, 311.0, 66.0, 545.0, 25.0, 864.0, 348.0, 497.0, 599.0, 122.0, 109.0, 182.0, 260.0, 149.0, 58.0, 45.0, 47.0, 38.0, 66.0, 282.0, 346.0, 85.0, 76.0, 64.0, 65.0, 11.0, 11.0, 126.0, 105.0, 45.0, 0.0, 0.0, 0.0, 0.0, 77.0, 0.0, 0.0, 25.0, 387.0, 231.0, 250.0, 241.0, 241.0, 54.0, 54.0, 110.0, 175.0, 0.0, 0.0, 182.0, 190.0, 0.0, 0.0, 0.0, 12.0, 34.0, 68.0, 14.0, 27.0, 27.0, 0.0, 24.0, 51.0, 0.0, 7.0, 0.0, 4.0, 21.0, 0.0, 0.0, 5.0, 0.0, 0.0, 33.0, 41.0, 165.0, 69.0, 0.0, 18.0, 0.0, 27.0, 24.0, 19.0, 18.0, 24.0, 11.0, 0.0, 0.0, 20.0, 0.0, 39.0, 39.0, 0.0, 285.0, 307.0, 21.0, 18.0, 0.0, 0.0, 0.0, 30.0, 11.0, 0.0, 6.0, 14.0, 12.0, 0.0, 26.0, 25.0, 0.0, 0.0, 0.0, 0.0, 15.0, 9.0, 30.0, 0.0, 0.0, 0.0, 10.0, 0.0, 10.0, 0.0, 0.0, 21.0, 52.0, 7.0, 0.0, 40.0, 10.0, 38.0, 0.0, 11.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 27.454535186455598, "mean_inference_ms": 133.81733992017965, "mean_action_processing_ms": 30.013896963141796, "mean_env_wait_ms": 52.76640148029938, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.02951037883758545, "StateBufferConnector_ms": 0.019862651824951172, "ViewRequirementAgentConnector_ms": 0.2574493885040283}, "num_episodes": 18, "episode_return_max": 173.99999999999952, "episode_return_min": -489.3, "episode_return_mean": -34.066000000000116, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 176000, "num_agent_steps_trained": 176000, "num_env_steps_sampled": 44000, "num_env_steps_trained": 44000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 184.03070001044586, "num_env_steps_trained_throughput_per_sec": 184.03070001044586, "timesteps_total": 44000, "num_env_steps_sampled_lifetime": 44000, "num_agent_steps_sampled_lifetime": 176000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 176000, "timers": {"training_iteration_time_ms": 113481.381, "restore_workers_time_ms": 0.022, "training_step_time_ms": 113481.295, "sample_time_ms": 95908.018, "learn_time_ms": 17543.786, "learn_throughput": 228.001, "synch_weights_time_ms": 24.946}, "counters": {"num_env_steps_sampled": 44000, "num_env_steps_trained": 44000, "num_agent_steps_sampled": 176000, "num_agent_steps_trained": 176000}, "done": false, "training_iteration": 11, "trial_id": "75ec3_00000", "date": "2024-08-13_01-38-16", "timestamp": 1723527496, "time_this_iter_s": 21.808495044708252, "time_total_s": 1154.1297755241394, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b1b08670>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1154.1297755241394, "iterations_since_restore": 11, "perf": {"cpu_util_percent": 87.47096774193548, "ram_util_percent": 82.99354838709677}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1291110012424055, "cur_kl_coeff": 0.16875, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.7716348859683546, "policy_loss": -0.005603453944309087, "vf_loss": 1.774744634495841, "vf_explained_var": 0.07550423940022787, "kl": 0.014777498609575751, "entropy": 1.4274983274873603, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 21735.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.27778102958959244, "cur_kl_coeff": 0.025, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.660685533805499, "policy_loss": -0.002155835017384518, "vf_loss": 0.6626305175836755, "vf_explained_var": -0.01051894259200525, "kl": 0.008434097820909614, "entropy": 1.3932627327858456, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 21735.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 48000, "num_env_steps_trained": 48000, "num_agent_steps_sampled": 192000, "num_agent_steps_trained": 192000}, "env_runners": {"episode_reward_max": 208.29999999999885, "episode_reward_min": -489.3, "episode_reward_mean": 14.928999999999869, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -774.4, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 140.5999999999997, "predator_policy": 864.0}, "policy_reward_mean": {"prey_policy": -81.51550000000002, "predator_policy": 88.98}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-73.30000000000003, -115.30000000000004, -50.1999999999999, 31.79999999999975, -136.90000000000015, -53.29999999999998, 49.800000000000146, -150.00000000000003, -162.40000000000015, -218.20000000000013, -67.40000000000016, -117.29999999999978, -222.0, 24.000000000000295, -114.4999999999998, -208.3000000000001, -489.3, -205.99999999999994, -295.1999999999998, 54.10000000000004, 109.79999999999995, 1.9000000000000445, 81.89999999999912, 17.999999999999975, 163.29999999999976, 63.500000000000284, 7.299999999999929, 73.69999999999959, 66.19999999999993, 24.10000000000007, 62.50000000000051, -18.599999999999785, 48.100000000000364, -282.4, 108.19999999999993, 12.200000000000124, 28.60000000000008, -32.79999999999993, 45.40000000000038, -113.50000000000037, 161.49999999999918, 31.30000000000017, -125.90000000000134, 173.99999999999952, 57.09999999999996, 32.80000000000032, 35.90000000000018, 89.59999999999863, 119.49999999999929, 166.79999999999885, 93.09999999999923, -7.199999999999786, -58.999999999999815, 93.99999999999918, 54.40000000000044, -5.199999999999781, 126.99999999999949, 74.69999999999976, 170.9999999999989, -65.90000000000185, 5.199999999999985, 137.29999999999995, 70.89999999999985, 69.70000000000006, 21.400000000000105, 80.09999999999921, 95.3999999999989, 39.40000000000029, 17.499999999999954, 44.50000000000037, 67.00000000000026, 23.200000000000074, 68.19999999999995, 41.800000000000324, 84.79999999999896, 90.19999999999858, 43.90000000000027, 92.09999999999968, 50.000000000000284, -4.699999999999736, 27.90000000000011, 55.3000000000005, 71.39999999999978, 59.70000000000048, 49.1000000000003, 78.79999999999957, 36.20000000000028, 38.000000000000256, 208.29999999999885, 51.800000000000324, 5.400000000000119, 32.30000000000018, 40.0000000000003, 50.8000000000003, 7.800000000000161, 32.30000000000019, 92.19999999999851, 48.10000000000006, 130.39999999999904, 72.19999999999976], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-461.5, -107.80000000000004, -403.40000000000003, -525.9000000000001, -252.00000000000003, -443.19999999999993, -269.4, -240.8000000000001, -116.50000000000007, -533.4, -374.2999999999997, -674.9999999999999, 20.000000000000014, -315.20000000000005, -55.600000000000044, -455.4000000000001, -157.99999999999991, -225.39999999999998, -334.70000000000005, -446.4999999999999, -422.79999999999995, -288.59999999999985, -238.90000000000003, -132.4, -600.7, -558.3, 20.000000000000014, -175.9999999999999, -229.90000000000046, -179.60000000000002, -310.8, -274.4999999999999, -509.7, -549.6, -774.4, -643.6, -697.2999999999998, -693.9, -30.69999999999977, -146.2000000000001, 3.1999999999999647, -335.4, 43.40000000000025, -248.5000000000003, 20.000000000000014, -30.099999999999916, -17.799999999999756, -68.20000000000002, -484.7, 20.000000000000014, 23.60000000000001, -121.09999999999992, -78.70000000000027, -43.00000000000002, -5.2000000000000455, 56.900000000000205, -219.90000000000003, 55.10000000000017, -12.99999999999987, -7.899999999999917, 42.50000000000025, 20.000000000000014, -141.70000000000044, 46.10000000000016, 28.10000000000016, 20.000000000000014, -243.6999999999999, -450.6999999999996, 38.900000000000105, -411.69999999999993, -489.8000000000001, 20.000000000000014, -122.8000000000007, 43.40000000000025, -312.0, -5.799999999999898, 25.400000000000098, 20.000000000000014, -372.9, -112.60000000000036, 21.800000000000047, 139.6999999999998, 20.000000000000014, -0.6999999999999993, -156.40000000000055, -71.50000000000048, 140.5999999999997, -7.59999999999998, 56.000000000000135, -25.899999999999885, -62.2000000000005, 20.000000000000014, 8.899999999999961, 20.000000000000014, 69.79999999999978, 15.799999999999963, 20.000000000000014, 78.4999999999999, 66.8, 94.99999999999969, 73.09999999999962, 20.000000000000014, -59.80000000000027, -21.399999999999864, 23.000000000000092, -315.99999999999943, 56.00000000000013, 20.000000000000014, 24.2000000000001, 3.1999999999999615, -59.80000000000031, 11.599999999999964, -30.399999999999814, 115.39999999999984, 48.80000000000023, 14.899999999999967, 66.80000000000005, 84.19999999999987, -51.400000000000034, -53.50000000000015, 28.100000000000144, -61.90000000000054, -474.69999999999925, 20.000000000000014, 49.70000000000019, -17.79999999999987, 49.70000000000022, 20.000000000000014, -28.59999999999979, 20.000000000000014, 49.10000000000016, 20.000000000000014, 70.69999999999972, 4.699999999999992, 7.399999999999972, 20.000000000000014, 17.899999999999988, -51.39999999999985, 20.000000000000014, 24.50000000000008, 45.20000000000021, 21.80000000000004, 6.4999999999999805, -7.299999999999901, 18.200000000000017, 20.000000000000014, 21.80000000000004, 20.000000000000014, 28.100000000000154, 46.70000000000022, 13.39999999999997, 66.80000000000001, 30.800000000000207, -7.8999999999999595, 67.69999999999985, -34.59999999999975, -31.29999999999984, 41.30000000000017, -26.499999999999822, -26.199999999999754, 20.000000000000014, -3.099999999999958, 35.300000000000246, 20.000000000000014, -25.59999999999978, 47.00000000000014, 20.000000000000014, 34.70000000000024, 20.000000000000014, 25.10000000000011, 9.499999999999968, 44.30000000000008, -8.199999999999958, 16.399999999999963, -9.999999999999888, 20.000000000000014, 91.09999999999931, 117.1999999999996, 1.9999999999999731, 27.800000000000143, -64.60000000000076, 20.000000000000014, 20.000000000000014, 5.299999999999965, 20.000000000000014, 20.000000000000014, -15.699999999999747, 21.50000000000008, 26.30000000000011, -53.50000000000016, 20.000000000000014, 5.299999999999967, 72.1999999999996, 20.000000000000014, -9.399999999999855, 42.50000000000001, 73.69999999999966, 40.70000000000025, -7.599999999999982, 39.80000000000018], "policy_predator_policy_reward": [285.0, 211.0, 468.0, 346.0, 327.0, 318.0, 289.0, 253.0, 162.0, 351.0, 564.0, 432.0, 175.0, 170.0, 36.0, 325.0, 194.0, 27.0, 276.0, 287.0, 280.0, 364.0, 55.0, 199.0, 303.0, 634.0, 90.0, 90.0, 104.0, 191.0, 311.0, 66.0, 545.0, 25.0, 864.0, 348.0, 497.0, 599.0, 122.0, 109.0, 182.0, 260.0, 149.0, 58.0, 45.0, 47.0, 38.0, 66.0, 282.0, 346.0, 85.0, 76.0, 64.0, 65.0, 11.0, 11.0, 126.0, 105.0, 45.0, 0.0, 0.0, 0.0, 0.0, 77.0, 0.0, 0.0, 25.0, 387.0, 231.0, 250.0, 241.0, 241.0, 54.0, 54.0, 110.0, 175.0, 0.0, 0.0, 182.0, 190.0, 0.0, 0.0, 0.0, 12.0, 34.0, 68.0, 14.0, 27.0, 27.0, 0.0, 24.0, 51.0, 0.0, 7.0, 0.0, 4.0, 21.0, 0.0, 0.0, 5.0, 0.0, 0.0, 33.0, 41.0, 165.0, 69.0, 0.0, 18.0, 0.0, 27.0, 24.0, 19.0, 18.0, 24.0, 11.0, 0.0, 0.0, 20.0, 0.0, 39.0, 39.0, 0.0, 285.0, 307.0, 21.0, 18.0, 0.0, 0.0, 0.0, 30.0, 11.0, 0.0, 6.0, 14.0, 12.0, 0.0, 26.0, 25.0, 0.0, 0.0, 0.0, 0.0, 15.0, 9.0, 30.0, 0.0, 0.0, 0.0, 10.0, 0.0, 10.0, 0.0, 0.0, 21.0, 52.0, 7.0, 0.0, 40.0, 10.0, 38.0, 0.0, 11.0, 0.0, 0.0, 20.0, 30.0, 0.0, 5.0, 4.0, 0.0, 12.0, 13.0, 0.0, 28.0, 9.0, 19.0, 0.0, 0.0, 22.0, 0.0, 42.0, 8.0, 0.0, 7.0, 0.0, 0.0, 8.0, 37.0, 0.0, 35.0, 0.0, 7.0, 0.0, 0.0, 14.0, 1.0, 16.0, 0.0, 31.0, 9.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 24.953928577777816, "mean_inference_ms": 121.35059907745821, "mean_action_processing_ms": 27.020460835661723, "mean_env_wait_ms": 47.790805860270915, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.028765559196472168, "StateBufferConnector_ms": 0.020009160041809082, "ViewRequirementAgentConnector_ms": 0.27137482166290283}, "num_episodes": 18, "episode_return_max": 208.29999999999885, "episode_return_min": -489.3, "episode_return_mean": 14.928999999999869, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 192000, "num_agent_steps_trained": 192000, "num_env_steps_sampled": 48000, "num_env_steps_trained": 48000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 199.68032040988913, "num_env_steps_trained_throughput_per_sec": 199.68032040988913, "timesteps_total": 48000, "num_env_steps_sampled_lifetime": 48000, "num_agent_steps_sampled_lifetime": 192000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 192000, "timers": {"training_iteration_time_ms": 113862.185, "restore_workers_time_ms": 0.017, "training_step_time_ms": 113862.108, "sample_time_ms": 95995.381, "learn_time_ms": 17835.631, "learn_throughput": 224.27, "synch_weights_time_ms": 25.699}, "counters": {"num_env_steps_sampled": 48000, "num_env_steps_trained": 48000, "num_agent_steps_sampled": 192000, "num_agent_steps_trained": 192000}, "done": false, "training_iteration": 12, "trial_id": "75ec3_00000", "date": "2024-08-13_01-38-36", "timestamp": 1723527516, "time_this_iter_s": 20.09356188774109, "time_total_s": 1174.2233374118805, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b1bc6a60>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1174.2233374118805, "iterations_since_restore": 12, "perf": {"cpu_util_percent": 83.6857142857143, "ram_util_percent": 83.37857142857142}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2631933760784921, "cur_kl_coeff": 0.16875, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.8144169126868879, "policy_loss": -0.00018119002284639805, "vf_loss": 1.814129796450731, "vf_explained_var": 0.07506794626750643, "kl": 0.0027751696752359215, "entropy": 1.4319938769416203, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 23625.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.2743091967075117, "cur_kl_coeff": 0.025, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.5056899746416738, "policy_loss": -0.0019350162081459843, "vf_loss": 0.5074742439286734, "vf_explained_var": 0.007595542057481392, "kl": 0.006029888410593663, "entropy": 1.3618153092722414, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 23625.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 52000, "num_env_steps_trained": 52000, "num_agent_steps_sampled": 208000, "num_agent_steps_trained": 208000}, "env_runners": {"episode_reward_max": 208.29999999999885, "episode_reward_min": -295.1999999999998, "episode_reward_mean": 49.00999999999987, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -697.2999999999998, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 140.5999999999997, "predator_policy": 599.0}, "policy_reward_mean": {"prey_policy": -15.569999999999986, "predator_policy": 40.075}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-295.1999999999998, 54.10000000000004, 109.79999999999995, 1.9000000000000445, 81.89999999999912, 17.999999999999975, 163.29999999999976, 63.500000000000284, 7.299999999999929, 73.69999999999959, 66.19999999999993, 24.10000000000007, 62.50000000000051, -18.599999999999785, 48.100000000000364, -282.4, 108.19999999999993, 12.200000000000124, 28.60000000000008, -32.79999999999993, 45.40000000000038, -113.50000000000037, 161.49999999999918, 31.30000000000017, -125.90000000000134, 173.99999999999952, 57.09999999999996, 32.80000000000032, 35.90000000000018, 89.59999999999863, 119.49999999999929, 166.79999999999885, 93.09999999999923, -7.199999999999786, -58.999999999999815, 93.99999999999918, 54.40000000000044, -5.199999999999781, 126.99999999999949, 74.69999999999976, 170.9999999999989, -65.90000000000185, 5.199999999999985, 137.29999999999995, 70.89999999999985, 69.70000000000006, 21.400000000000105, 80.09999999999921, 95.3999999999989, 39.40000000000029, 17.499999999999954, 44.50000000000037, 67.00000000000026, 23.200000000000074, 68.19999999999995, 41.800000000000324, 84.79999999999896, 90.19999999999858, 43.90000000000027, 92.09999999999968, 50.000000000000284, -4.699999999999736, 27.90000000000011, 55.3000000000005, 71.39999999999978, 59.70000000000048, 49.1000000000003, 78.79999999999957, 36.20000000000028, 38.000000000000256, 208.29999999999885, 51.800000000000324, 5.400000000000119, 32.30000000000018, 40.0000000000003, 50.8000000000003, 7.800000000000161, 32.30000000000019, 92.19999999999851, 48.10000000000006, 130.39999999999904, 72.19999999999976, 50.00000000000037, 88.59999999999883, -3.999999999999696, 133.8999999999988, 53.800000000000445, 77.59999999999954, 67.90000000000022, 91.999999999999, 58.00000000000052, 7.200000000000099, 40.90000000000031, 60.40000000000037, 48.10000000000043, 39.20000000000035, 62.50000000000053, 57.600000000000406, 130.39999999999912, 65.20000000000041], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-697.2999999999998, -693.9, -30.69999999999977, -146.2000000000001, 3.1999999999999647, -335.4, 43.40000000000025, -248.5000000000003, 20.000000000000014, -30.099999999999916, -17.799999999999756, -68.20000000000002, -484.7, 20.000000000000014, 23.60000000000001, -121.09999999999992, -78.70000000000027, -43.00000000000002, -5.2000000000000455, 56.900000000000205, -219.90000000000003, 55.10000000000017, -12.99999999999987, -7.899999999999917, 42.50000000000025, 20.000000000000014, -141.70000000000044, 46.10000000000016, 28.10000000000016, 20.000000000000014, -243.6999999999999, -450.6999999999996, 38.900000000000105, -411.69999999999993, -489.8000000000001, 20.000000000000014, -122.8000000000007, 43.40000000000025, -312.0, -5.799999999999898, 25.400000000000098, 20.000000000000014, -372.9, -112.60000000000036, 21.800000000000047, 139.6999999999998, 20.000000000000014, -0.6999999999999993, -156.40000000000055, -71.50000000000048, 140.5999999999997, -7.59999999999998, 56.000000000000135, -25.899999999999885, -62.2000000000005, 20.000000000000014, 8.899999999999961, 20.000000000000014, 69.79999999999978, 15.799999999999963, 20.000000000000014, 78.4999999999999, 66.8, 94.99999999999969, 73.09999999999962, 20.000000000000014, -59.80000000000027, -21.399999999999864, 23.000000000000092, -315.99999999999943, 56.00000000000013, 20.000000000000014, 24.2000000000001, 3.1999999999999615, -59.80000000000031, 11.599999999999964, -30.399999999999814, 115.39999999999984, 48.80000000000023, 14.899999999999967, 66.80000000000005, 84.19999999999987, -51.400000000000034, -53.50000000000015, 28.100000000000144, -61.90000000000054, -474.69999999999925, 20.000000000000014, 49.70000000000019, -17.79999999999987, 49.70000000000022, 20.000000000000014, -28.59999999999979, 20.000000000000014, 49.10000000000016, 20.000000000000014, 70.69999999999972, 4.699999999999992, 7.399999999999972, 20.000000000000014, 17.899999999999988, -51.39999999999985, 20.000000000000014, 24.50000000000008, 45.20000000000021, 21.80000000000004, 6.4999999999999805, -7.299999999999901, 18.200000000000017, 20.000000000000014, 21.80000000000004, 20.000000000000014, 28.100000000000154, 46.70000000000022, 13.39999999999997, 66.80000000000001, 30.800000000000207, -7.8999999999999595, 67.69999999999985, -34.59999999999975, -31.29999999999984, 41.30000000000017, -26.499999999999822, -26.199999999999754, 20.000000000000014, -3.099999999999958, 35.300000000000246, 20.000000000000014, -25.59999999999978, 47.00000000000014, 20.000000000000014, 34.70000000000024, 20.000000000000014, 25.10000000000011, 9.499999999999968, 44.30000000000008, -8.199999999999958, 16.399999999999963, -9.999999999999888, 20.000000000000014, 91.09999999999931, 117.1999999999996, 1.9999999999999731, 27.800000000000143, -64.60000000000076, 20.000000000000014, 20.000000000000014, 5.299999999999965, 20.000000000000014, 20.000000000000014, -15.699999999999747, 21.50000000000008, 26.30000000000011, -53.50000000000016, 20.000000000000014, 5.299999999999967, 72.1999999999996, 20.000000000000014, -9.399999999999855, 42.50000000000001, 73.69999999999966, 40.70000000000025, -7.599999999999982, 39.80000000000018, 7.9999999999999885, 20.000000000000014, 68.59999999999982, 20.000000000000014, -19.899999999999743, -3.0999999999999615, 20.000000000000014, 110.8999999999995, 38.90000000000022, -0.09999999999998116, 36.800000000000246, 39.80000000000025, 20.000000000000014, 47.90000000000024, -5.1999999999999265, 84.19999999999949, 38.000000000000256, 20.000000000000014, -17.19999999999977, -13.599999999999797, 20.90000000000003, 20.000000000000014, 11.599999999999971, 33.800000000000146, 20.000000000000014, 28.100000000000147, -2.7999999999999896, 20.000000000000014, 28.100000000000147, 34.40000000000026, 28.70000000000017, 8.899999999999977, 94.39999999999966, 20.000000000000014, 45.200000000000244, 20.000000000000014], "policy_predator_policy_reward": [497.0, 599.0, 122.0, 109.0, 182.0, 260.0, 149.0, 58.0, 45.0, 47.0, 38.0, 66.0, 282.0, 346.0, 85.0, 76.0, 64.0, 65.0, 11.0, 11.0, 126.0, 105.0, 45.0, 0.0, 0.0, 0.0, 0.0, 77.0, 0.0, 0.0, 25.0, 387.0, 231.0, 250.0, 241.0, 241.0, 54.0, 54.0, 110.0, 175.0, 0.0, 0.0, 182.0, 190.0, 0.0, 0.0, 0.0, 12.0, 34.0, 68.0, 14.0, 27.0, 27.0, 0.0, 24.0, 51.0, 0.0, 7.0, 0.0, 4.0, 21.0, 0.0, 0.0, 5.0, 0.0, 0.0, 33.0, 41.0, 165.0, 69.0, 0.0, 18.0, 0.0, 27.0, 24.0, 19.0, 18.0, 24.0, 11.0, 0.0, 0.0, 20.0, 0.0, 39.0, 39.0, 0.0, 285.0, 307.0, 21.0, 18.0, 0.0, 0.0, 0.0, 30.0, 11.0, 0.0, 6.0, 14.0, 12.0, 0.0, 26.0, 25.0, 0.0, 0.0, 0.0, 0.0, 15.0, 9.0, 30.0, 0.0, 0.0, 0.0, 10.0, 0.0, 10.0, 0.0, 0.0, 21.0, 52.0, 7.0, 0.0, 40.0, 10.0, 38.0, 0.0, 11.0, 0.0, 0.0, 20.0, 30.0, 0.0, 5.0, 4.0, 0.0, 12.0, 13.0, 0.0, 28.0, 9.0, 19.0, 0.0, 0.0, 22.0, 0.0, 42.0, 8.0, 0.0, 7.0, 0.0, 0.0, 8.0, 37.0, 0.0, 35.0, 0.0, 7.0, 0.0, 0.0, 14.0, 1.0, 16.0, 0.0, 31.0, 9.0, 0.0, 22.0, 0.0, 0.0, 0.0, 19.0, 3.0, 0.0, 10.0, 5.0, 0.0, 1.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 15.0, 23.0, 0.0, 0.0, 2.0, 13.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 20.0, 0.0, 7.0, 9.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 22.952616782010363, "mean_inference_ms": 111.32460866957787, "mean_action_processing_ms": 24.640364804796164, "mean_env_wait_ms": 43.77848479286569, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.027274489402770996, "StateBufferConnector_ms": 0.018724918365478516, "ViewRequirementAgentConnector_ms": 0.2751123905181885}, "num_episodes": 18, "episode_return_max": 208.29999999999885, "episode_return_min": -295.1999999999998, "episode_return_mean": 49.00999999999987, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 208000, "num_agent_steps_trained": 208000, "num_env_steps_sampled": 52000, "num_env_steps_trained": 52000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 154.9122253996399, "num_env_steps_trained_throughput_per_sec": 154.9122253996399, "timesteps_total": 52000, "num_env_steps_sampled_lifetime": 52000, "num_agent_steps_sampled_lifetime": 208000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 208000, "timers": {"training_iteration_time_ms": 20568.957, "restore_workers_time_ms": 0.017, "training_step_time_ms": 20568.88, "sample_time_ms": 3177.969, "learn_time_ms": 17360.465, "learn_throughput": 230.409, "synch_weights_time_ms": 25.552}, "counters": {"num_env_steps_sampled": 52000, "num_env_steps_trained": 52000, "num_agent_steps_sampled": 208000, "num_agent_steps_trained": 208000}, "done": false, "training_iteration": 13, "trial_id": "75ec3_00000", "date": "2024-08-13_01-39-02", "timestamp": 1723527542, "time_this_iter_s": 25.880815982818604, "time_total_s": 1200.104153394699, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b1ada0d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1200.104153394699, "iterations_since_restore": 13, "perf": {"cpu_util_percent": 86.88918918918918, "ram_util_percent": 83.63513513513513}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.204798158601163, "cur_kl_coeff": 0.084375, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.6803638235601799, "policy_loss": -0.003311870865297144, "vf_loss": 1.6827138423919679, "vf_explained_var": 0.11267615799550657, "kl": 0.011399759813918185, "entropy": 1.387252852021071, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 25515.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.32806329261413014, "cur_kl_coeff": 0.025, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.3571654825614243, "policy_loss": -0.002296501993837338, "vf_loss": 0.3592198342937365, "vf_explained_var": 0.09523710031358022, "kl": 0.009685980576457781, "entropy": 1.4445595751994502, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 25515.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 56000, "num_env_steps_trained": 56000, "num_agent_steps_sampled": 224000, "num_agent_steps_trained": 224000}, "env_runners": {"episode_reward_max": 208.29999999999885, "episode_reward_min": -65.90000000000185, "episode_reward_mean": 60.194999999999865, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -474.69999999999925, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 117.1999999999996, "predator_policy": 307.0}, "policy_reward_mean": {"prey_policy": 17.66750000000003, "predator_policy": 12.43}, "custom_metrics": {}, "hist_stats": {"episode_reward": [32.80000000000032, 35.90000000000018, 89.59999999999863, 119.49999999999929, 166.79999999999885, 93.09999999999923, -7.199999999999786, -58.999999999999815, 93.99999999999918, 54.40000000000044, -5.199999999999781, 126.99999999999949, 74.69999999999976, 170.9999999999989, -65.90000000000185, 5.199999999999985, 137.29999999999995, 70.89999999999985, 69.70000000000006, 21.400000000000105, 80.09999999999921, 95.3999999999989, 39.40000000000029, 17.499999999999954, 44.50000000000037, 67.00000000000026, 23.200000000000074, 68.19999999999995, 41.800000000000324, 84.79999999999896, 90.19999999999858, 43.90000000000027, 92.09999999999968, 50.000000000000284, -4.699999999999736, 27.90000000000011, 55.3000000000005, 71.39999999999978, 59.70000000000048, 49.1000000000003, 78.79999999999957, 36.20000000000028, 38.000000000000256, 208.29999999999885, 51.800000000000324, 5.400000000000119, 32.30000000000018, 40.0000000000003, 50.8000000000003, 7.800000000000161, 32.30000000000019, 92.19999999999851, 48.10000000000006, 130.39999999999904, 72.19999999999976, 50.00000000000037, 88.59999999999883, -3.999999999999696, 133.8999999999988, 53.800000000000445, 77.59999999999954, 67.90000000000022, 91.999999999999, 58.00000000000052, 7.200000000000099, 40.90000000000031, 60.40000000000037, 48.10000000000043, 39.20000000000035, 62.50000000000053, 57.600000000000406, 130.39999999999912, 65.20000000000041, 26.900000000000095, 161.09999999999886, 45.40000000000038, 124.29999999999926, 40.0000000000003, 40.0000000000003, 54.40000000000051, 69.99999999999993, 121.09999999999837, 40.0000000000003, 36.80000000000026, 88.5999999999987, 77.99999999999935, 62.30000000000031, 68.20000000000012, 48.90000000000043, 75.99999999999949, 5.900000000000096, 19.700000000000028, 59.60000000000046, 29.000000000000128, 41.30000000000031, 39.90000000000029, 40.0000000000003, 70.69999999999995, 111.29999999999876, 43.40000000000016], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-62.2000000000005, 20.000000000000014, 8.899999999999961, 20.000000000000014, 69.79999999999978, 15.799999999999963, 20.000000000000014, 78.4999999999999, 66.8, 94.99999999999969, 73.09999999999962, 20.000000000000014, -59.80000000000027, -21.399999999999864, 23.000000000000092, -315.99999999999943, 56.00000000000013, 20.000000000000014, 24.2000000000001, 3.1999999999999615, -59.80000000000031, 11.599999999999964, -30.399999999999814, 115.39999999999984, 48.80000000000023, 14.899999999999967, 66.80000000000005, 84.19999999999987, -51.400000000000034, -53.50000000000015, 28.100000000000144, -61.90000000000054, -474.69999999999925, 20.000000000000014, 49.70000000000019, -17.79999999999987, 49.70000000000022, 20.000000000000014, -28.59999999999979, 20.000000000000014, 49.10000000000016, 20.000000000000014, 70.69999999999972, 4.699999999999992, 7.399999999999972, 20.000000000000014, 17.899999999999988, -51.39999999999985, 20.000000000000014, 24.50000000000008, 45.20000000000021, 21.80000000000004, 6.4999999999999805, -7.299999999999901, 18.200000000000017, 20.000000000000014, 21.80000000000004, 20.000000000000014, 28.100000000000154, 46.70000000000022, 13.39999999999997, 66.80000000000001, 30.800000000000207, -7.8999999999999595, 67.69999999999985, -34.59999999999975, -31.29999999999984, 41.30000000000017, -26.499999999999822, -26.199999999999754, 20.000000000000014, -3.099999999999958, 35.300000000000246, 20.000000000000014, -25.59999999999978, 47.00000000000014, 20.000000000000014, 34.70000000000024, 20.000000000000014, 25.10000000000011, 9.499999999999968, 44.30000000000008, -8.199999999999958, 16.399999999999963, -9.999999999999888, 20.000000000000014, 91.09999999999931, 117.1999999999996, 1.9999999999999731, 27.800000000000143, -64.60000000000076, 20.000000000000014, 20.000000000000014, 5.299999999999965, 20.000000000000014, 20.000000000000014, -15.699999999999747, 21.50000000000008, 26.30000000000011, -53.50000000000016, 20.000000000000014, 5.299999999999967, 72.1999999999996, 20.000000000000014, -9.399999999999855, 42.50000000000001, 73.69999999999966, 40.70000000000025, -7.599999999999982, 39.80000000000018, 7.9999999999999885, 20.000000000000014, 68.59999999999982, 20.000000000000014, -19.899999999999743, -3.0999999999999615, 20.000000000000014, 110.8999999999995, 38.90000000000022, -0.09999999999998116, 36.800000000000246, 39.80000000000025, 20.000000000000014, 47.90000000000024, -5.1999999999999265, 84.19999999999949, 38.000000000000256, 20.000000000000014, -17.19999999999977, -13.599999999999797, 20.90000000000003, 20.000000000000014, 11.599999999999971, 33.800000000000146, 20.000000000000014, 28.100000000000147, -2.7999999999999896, 20.000000000000014, 28.100000000000147, 34.40000000000026, 28.70000000000017, 8.899999999999977, 94.39999999999966, 20.000000000000014, 45.200000000000244, 20.000000000000014, 24.50000000000008, -13.599999999999783, 100.39999999999957, 58.700000000000166, 25.400000000000098, 20.000000000000014, 49.70000000000024, 62.60000000000011, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 21.800000000000047, 32.60000000000023, -3.099999999999972, 43.10000000000016, 47.00000000000023, 70.09999999999975, 20.000000000000014, 20.000000000000014, 21.800000000000047, 7.999999999999966, 20.900000000000027, 67.69999999999993, -53.50000000000012, 96.4999999999994, 39.50000000000015, 21.80000000000004, 36.2000000000002, 20.000000000000014, 29.300000000000182, 8.599999999999968, 24.50000000000008, 51.50000000000016, -9.399999999999869, -15.699999999999783, -25.29999999999977, 20.000000000000014, 35.900000000000226, 13.699999999999967, -0.9999999999999881, 20.000000000000014, 5.299999999999965, 29.000000000000163, 25.400000000000098, 9.499999999999968, 20.000000000000014, 20.000000000000014, 13.699999999999969, 35.00000000000018, 20.000000000000014, 83.29999999999967, 22.700000000000053, 10.699999999999992], "policy_predator_policy_reward": [24.0, 51.0, 0.0, 7.0, 0.0, 4.0, 21.0, 0.0, 0.0, 5.0, 0.0, 0.0, 33.0, 41.0, 165.0, 69.0, 0.0, 18.0, 0.0, 27.0, 24.0, 19.0, 18.0, 24.0, 11.0, 0.0, 0.0, 20.0, 0.0, 39.0, 39.0, 0.0, 285.0, 307.0, 21.0, 18.0, 0.0, 0.0, 0.0, 30.0, 11.0, 0.0, 6.0, 14.0, 12.0, 0.0, 26.0, 25.0, 0.0, 0.0, 0.0, 0.0, 15.0, 9.0, 30.0, 0.0, 0.0, 0.0, 10.0, 0.0, 10.0, 0.0, 0.0, 21.0, 52.0, 7.0, 0.0, 40.0, 10.0, 38.0, 0.0, 11.0, 0.0, 0.0, 20.0, 30.0, 0.0, 5.0, 4.0, 0.0, 12.0, 13.0, 0.0, 28.0, 9.0, 19.0, 0.0, 0.0, 22.0, 0.0, 42.0, 8.0, 0.0, 7.0, 0.0, 0.0, 8.0, 37.0, 0.0, 35.0, 0.0, 7.0, 0.0, 0.0, 14.0, 1.0, 16.0, 0.0, 31.0, 9.0, 0.0, 22.0, 0.0, 0.0, 0.0, 19.0, 3.0, 0.0, 10.0, 5.0, 0.0, 1.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 15.0, 23.0, 0.0, 0.0, 2.0, 13.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 20.0, 0.0, 7.0, 9.0, 0.0, 0.0, 0.0, 16.0, 0.0, 2.0, 0.0, 0.0, 1.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 15.0, 15.0, 0.0, 4.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 10.0, 25.0, 1.0, 0.0, 0.0, 12.0, 0.0, 11.0, 0.0, 0.0, 1.0, 30.0, 0.0, 25.0, 7.0, 3.0, 10.0, 0.0, 0.0, 7.0, 0.0, 5.0, 0.0, 0.0, 0.0, 22.0, 8.0, 0.0, 10.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 22.81417149683432, "mean_inference_ms": 101.73839534036371, "mean_action_processing_ms": 21.86734910732368, "mean_env_wait_ms": 34.63513896045625, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.028307080268859863, "StateBufferConnector_ms": 0.017018675804138184, "ViewRequirementAgentConnector_ms": 0.2834203243255615}, "num_episodes": 27, "episode_return_max": 208.29999999999885, "episode_return_min": -65.90000000000185, "episode_return_mean": 60.194999999999865, "episodes_this_iter": 27}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 224000, "num_agent_steps_trained": 224000, "num_env_steps_sampled": 56000, "num_env_steps_trained": 56000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 180.85242172094456, "num_env_steps_trained_throughput_per_sec": 180.85242172094456, "timesteps_total": 56000, "num_env_steps_sampled_lifetime": 56000, "num_agent_steps_sampled_lifetime": 224000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 224000, "timers": {"training_iteration_time_ms": 20552.914, "restore_workers_time_ms": 0.017, "training_step_time_ms": 20552.835, "sample_time_ms": 2997.335, "learn_time_ms": 17525.142, "learn_throughput": 228.244, "synch_weights_time_ms": 25.64}, "counters": {"num_env_steps_sampled": 56000, "num_env_steps_trained": 56000, "num_agent_steps_sampled": 224000, "num_agent_steps_trained": 224000}, "done": false, "training_iteration": 14, "trial_id": "75ec3_00000", "date": "2024-08-13_01-39-24", "timestamp": 1723527564, "time_this_iter_s": 22.171813011169434, "time_total_s": 1222.2759664058685, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b1bcbc10>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1222.2759664058685, "iterations_since_restore": 14, "perf": {"cpu_util_percent": 85.3741935483871, "ram_util_percent": 83.53870967741935}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2399408086661308, "cur_kl_coeff": 0.084375, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.1413077159533427, "policy_loss": -0.0009620738710971579, "vf_loss": 2.14181145681906, "vf_explained_var": 0.07749424176241355, "kl": 0.005432163104838165, "entropy": 1.3957605580173473, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 27405.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.30776294679553423, "cur_kl_coeff": 0.025, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.578362037840659, "policy_loss": -0.002121024947396662, "vf_loss": 0.5802430865862382, "vf_explained_var": 0.032573720670881726, "kl": 0.009599077816914676, "entropy": 1.3638238265400842, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 27405.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 60000, "num_env_steps_trained": 60000, "num_agent_steps_sampled": 240000, "num_agent_steps_trained": 240000}, "env_runners": {"episode_reward_max": 208.29999999999885, "episode_reward_min": -4.699999999999736, "episode_reward_mean": 63.204999999999835, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -64.60000000000076, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 117.1999999999996, "predator_policy": 52.0}, "policy_reward_mean": {"prey_policy": 24.642500000000027, "predator_policy": 6.96}, "custom_metrics": {}, "hist_stats": {"episode_reward": [69.70000000000006, 21.400000000000105, 80.09999999999921, 95.3999999999989, 39.40000000000029, 17.499999999999954, 44.50000000000037, 67.00000000000026, 23.200000000000074, 68.19999999999995, 41.800000000000324, 84.79999999999896, 90.19999999999858, 43.90000000000027, 92.09999999999968, 50.000000000000284, -4.699999999999736, 27.90000000000011, 55.3000000000005, 71.39999999999978, 59.70000000000048, 49.1000000000003, 78.79999999999957, 36.20000000000028, 38.000000000000256, 208.29999999999885, 51.800000000000324, 5.400000000000119, 32.30000000000018, 40.0000000000003, 50.8000000000003, 7.800000000000161, 32.30000000000019, 92.19999999999851, 48.10000000000006, 130.39999999999904, 72.19999999999976, 50.00000000000037, 88.59999999999883, -3.999999999999696, 133.8999999999988, 53.800000000000445, 77.59999999999954, 67.90000000000022, 91.999999999999, 58.00000000000052, 7.200000000000099, 40.90000000000031, 60.40000000000037, 48.10000000000043, 39.20000000000035, 62.50000000000053, 57.600000000000406, 130.39999999999912, 65.20000000000041, 26.900000000000095, 161.09999999999886, 45.40000000000038, 124.29999999999926, 40.0000000000003, 40.0000000000003, 54.40000000000051, 69.99999999999993, 121.09999999999837, 40.0000000000003, 36.80000000000026, 88.5999999999987, 77.99999999999935, 62.30000000000031, 68.20000000000012, 48.90000000000043, 75.99999999999949, 5.900000000000096, 19.700000000000028, 59.60000000000046, 29.000000000000128, 41.30000000000031, 39.90000000000029, 40.0000000000003, 70.69999999999995, 111.29999999999876, 43.40000000000016, 86.79999999999882, 37.80000000000027, 98.59999999999862, 31.000000000000163, 76.89999999999957, 107.49999999999855, 57.40000000000048, 63.10000000000025, 58.0000000000004, 111.69999999999871, 112.0999999999992, 120.89999999999874, 82.39999999999905, 24.100000000000048, 133.59999999999906, 88.59999999999867, 25.10000000000007, 120.29999999999848], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [49.70000000000022, 20.000000000000014, -28.59999999999979, 20.000000000000014, 49.10000000000016, 20.000000000000014, 70.69999999999972, 4.699999999999992, 7.399999999999972, 20.000000000000014, 17.899999999999988, -51.39999999999985, 20.000000000000014, 24.50000000000008, 45.20000000000021, 21.80000000000004, 6.4999999999999805, -7.299999999999901, 18.200000000000017, 20.000000000000014, 21.80000000000004, 20.000000000000014, 28.100000000000154, 46.70000000000022, 13.39999999999997, 66.80000000000001, 30.800000000000207, -7.8999999999999595, 67.69999999999985, -34.59999999999975, -31.29999999999984, 41.30000000000017, -26.499999999999822, -26.199999999999754, 20.000000000000014, -3.099999999999958, 35.300000000000246, 20.000000000000014, -25.59999999999978, 47.00000000000014, 20.000000000000014, 34.70000000000024, 20.000000000000014, 25.10000000000011, 9.499999999999968, 44.30000000000008, -8.199999999999958, 16.399999999999963, -9.999999999999888, 20.000000000000014, 91.09999999999931, 117.1999999999996, 1.9999999999999731, 27.800000000000143, -64.60000000000076, 20.000000000000014, 20.000000000000014, 5.299999999999965, 20.000000000000014, 20.000000000000014, -15.699999999999747, 21.50000000000008, 26.30000000000011, -53.50000000000016, 20.000000000000014, 5.299999999999967, 72.1999999999996, 20.000000000000014, -9.399999999999855, 42.50000000000001, 73.69999999999966, 40.70000000000025, -7.599999999999982, 39.80000000000018, 7.9999999999999885, 20.000000000000014, 68.59999999999982, 20.000000000000014, -19.899999999999743, -3.0999999999999615, 20.000000000000014, 110.8999999999995, 38.90000000000022, -0.09999999999998116, 36.800000000000246, 39.80000000000025, 20.000000000000014, 47.90000000000024, -5.1999999999999265, 84.19999999999949, 38.000000000000256, 20.000000000000014, -17.19999999999977, -13.599999999999797, 20.90000000000003, 20.000000000000014, 11.599999999999971, 33.800000000000146, 20.000000000000014, 28.100000000000147, -2.7999999999999896, 20.000000000000014, 28.100000000000147, 34.40000000000026, 28.70000000000017, 8.899999999999977, 94.39999999999966, 20.000000000000014, 45.200000000000244, 20.000000000000014, 24.50000000000008, -13.599999999999783, 100.39999999999957, 58.700000000000166, 25.400000000000098, 20.000000000000014, 49.70000000000024, 62.60000000000011, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 21.800000000000047, 32.60000000000023, -3.099999999999972, 43.10000000000016, 47.00000000000023, 70.09999999999975, 20.000000000000014, 20.000000000000014, 21.800000000000047, 7.999999999999966, 20.900000000000027, 67.69999999999993, -53.50000000000012, 96.4999999999994, 39.50000000000015, 21.80000000000004, 36.2000000000002, 20.000000000000014, 29.300000000000182, 8.599999999999968, 24.50000000000008, 51.50000000000016, -9.399999999999869, -15.699999999999783, -25.29999999999977, 20.000000000000014, 35.900000000000226, 13.699999999999967, -0.9999999999999881, 20.000000000000014, 5.299999999999965, 29.000000000000163, 25.400000000000098, 9.499999999999968, 20.000000000000014, 20.000000000000014, 13.699999999999969, 35.00000000000018, 20.000000000000014, 83.29999999999967, 22.700000000000053, 10.699999999999992, 31.700000000000188, 46.1000000000002, 20.000000000000014, 15.799999999999963, 24.500000000000096, 70.09999999999974, -0.9999999999999846, 20.000000000000014, 20.000000000000014, 56.900000000000226, 87.49999999999929, 20.000000000000014, 20.000000000000014, 34.40000000000024, 28.100000000000154, 20.000000000000014, 20.000000000000014, 38.0000000000002, -6.099999999999923, 102.7999999999994, 58.10000000000009, 20.000000000000014, 62.00000000000014, 44.90000000000024, 58.40000000000014, 20.000000000000014, 27.20000000000013, -24.099999999999746, 41.60000000000025, 91.9999999999996, 79.09999999999931, -11.499999999999819, -6.99999999999992, 7.099999999999964, 13.999999999999975, 89.2999999999993], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 30.0, 11.0, 0.0, 6.0, 14.0, 12.0, 0.0, 26.0, 25.0, 0.0, 0.0, 0.0, 0.0, 15.0, 9.0, 30.0, 0.0, 0.0, 0.0, 10.0, 0.0, 10.0, 0.0, 0.0, 21.0, 52.0, 7.0, 0.0, 40.0, 10.0, 38.0, 0.0, 11.0, 0.0, 0.0, 20.0, 30.0, 0.0, 5.0, 4.0, 0.0, 12.0, 13.0, 0.0, 28.0, 9.0, 19.0, 0.0, 0.0, 22.0, 0.0, 42.0, 8.0, 0.0, 7.0, 0.0, 0.0, 8.0, 37.0, 0.0, 35.0, 0.0, 7.0, 0.0, 0.0, 14.0, 1.0, 16.0, 0.0, 31.0, 9.0, 0.0, 22.0, 0.0, 0.0, 0.0, 19.0, 3.0, 0.0, 10.0, 5.0, 0.0, 1.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 15.0, 23.0, 0.0, 0.0, 2.0, 13.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 20.0, 0.0, 7.0, 9.0, 0.0, 0.0, 0.0, 16.0, 0.0, 2.0, 0.0, 0.0, 1.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 15.0, 15.0, 0.0, 4.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 10.0, 25.0, 1.0, 0.0, 0.0, 12.0, 0.0, 11.0, 0.0, 0.0, 1.0, 30.0, 0.0, 25.0, 7.0, 3.0, 10.0, 0.0, 0.0, 7.0, 0.0, 5.0, 0.0, 0.0, 0.0, 22.0, 8.0, 0.0, 10.0, 0.0, 0.0, 9.0, 0.0, 2.0, 0.0, 4.0, 4.0, 8.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 15.0, 0.0, 0.0, 0.0, 6.0, 9.0, 29.0, 5.0, 14.0, 0.0, 4.0, 0.0, 0.0, 21.0, 0.0, 0.0, 6.0, 15.0, 18.0, 7.0, 0.0, 17.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 19.34382881418962, "mean_inference_ms": 92.71602912153362, "mean_action_processing_ms": 20.48277045700505, "mean_env_wait_ms": 36.03536639667183, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.027698755264282227, "StateBufferConnector_ms": 0.016704082489013672, "ViewRequirementAgentConnector_ms": 0.28547608852386475}, "num_episodes": 18, "episode_return_max": 208.29999999999885, "episode_return_min": -4.699999999999736, "episode_return_mean": 63.204999999999835, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 240000, "num_agent_steps_trained": 240000, "num_env_steps_sampled": 60000, "num_env_steps_trained": 60000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 175.0425104101064, "num_env_steps_trained_throughput_per_sec": 175.0425104101064, "timesteps_total": 60000, "num_env_steps_sampled_lifetime": 60000, "num_agent_steps_sampled_lifetime": 240000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 240000, "timers": {"training_iteration_time_ms": 21147.371, "restore_workers_time_ms": 0.017, "training_step_time_ms": 21147.293, "sample_time_ms": 2995.284, "learn_time_ms": 18117.831, "learn_throughput": 220.777, "synch_weights_time_ms": 28.874}, "counters": {"num_env_steps_sampled": 60000, "num_env_steps_trained": 60000, "num_agent_steps_sampled": 240000, "num_agent_steps_trained": 240000}, "done": false, "training_iteration": 15, "trial_id": "75ec3_00000", "date": "2024-08-13_01-39-47", "timestamp": 1723527587, "time_this_iter_s": 22.920471906661987, "time_total_s": 1245.1964383125305, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2058790>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1245.1964383125305, "iterations_since_restore": 15, "perf": {"cpu_util_percent": 86.43636363636364, "ram_util_percent": 83.48484848484848}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2934908120562791, "cur_kl_coeff": 0.084375, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.319626555619416, "policy_loss": -0.007072910038192594, "vf_loss": 2.3253352834434105, "vf_explained_var": 0.12805030601365225, "kl": 0.016168035381051594, "entropy": 1.427797035565452, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 29295.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.2956629642497295, "cur_kl_coeff": 0.025, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.511293766194235, "policy_loss": -0.002339904422492341, "vf_loss": 0.5135595523895173, "vf_explained_var": 0.05116282414506983, "kl": 0.0029647035052375917, "entropy": 1.367942351071292, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 29295.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 64000, "num_env_steps_trained": 64000, "num_agent_steps_sampled": 256000, "num_agent_steps_trained": 256000}, "env_runners": {"episode_reward_max": 208.29999999999885, "episode_reward_min": -3.999999999999696, "episode_reward_mean": 67.06799999999983, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -65.50000000000068, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 117.1999999999996, "predator_policy": 53.0}, "policy_reward_mean": {"prey_policy": 27.134000000000015, "predator_policy": 6.4}, "custom_metrics": {}, "hist_stats": {"episode_reward": [55.3000000000005, 71.39999999999978, 59.70000000000048, 49.1000000000003, 78.79999999999957, 36.20000000000028, 38.000000000000256, 208.29999999999885, 51.800000000000324, 5.400000000000119, 32.30000000000018, 40.0000000000003, 50.8000000000003, 7.800000000000161, 32.30000000000019, 92.19999999999851, 48.10000000000006, 130.39999999999904, 72.19999999999976, 50.00000000000037, 88.59999999999883, -3.999999999999696, 133.8999999999988, 53.800000000000445, 77.59999999999954, 67.90000000000022, 91.999999999999, 58.00000000000052, 7.200000000000099, 40.90000000000031, 60.40000000000037, 48.10000000000043, 39.20000000000035, 62.50000000000053, 57.600000000000406, 130.39999999999912, 65.20000000000041, 26.900000000000095, 161.09999999999886, 45.40000000000038, 124.29999999999926, 40.0000000000003, 40.0000000000003, 54.40000000000051, 69.99999999999993, 121.09999999999837, 40.0000000000003, 36.80000000000026, 88.5999999999987, 77.99999999999935, 62.30000000000031, 68.20000000000012, 48.90000000000043, 75.99999999999949, 5.900000000000096, 19.700000000000028, 59.60000000000046, 29.000000000000128, 41.30000000000031, 39.90000000000029, 40.0000000000003, 70.69999999999995, 111.29999999999876, 43.40000000000016, 86.79999999999882, 37.80000000000027, 98.59999999999862, 31.000000000000163, 76.89999999999957, 107.49999999999855, 57.40000000000048, 63.10000000000025, 58.0000000000004, 111.69999999999871, 112.0999999999992, 120.89999999999874, 82.39999999999905, 24.100000000000048, 133.59999999999906, 88.59999999999867, 25.10000000000007, 120.29999999999848, 60.70000000000051, 71.09999999999992, 3.3000000000000527, 113.59999999999877, 108.2999999999991, 53.50000000000035, 13.900000000000045, 67.60000000000018, 38.90000000000028, 64.50000000000041, 109.19999999999928, 52.20000000000046, 166.6999999999989, 160.19999999999902, 40.0000000000003, 83.99999999999974, 76.69999999999958, 54.30000000000047], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [35.300000000000246, 20.000000000000014, -25.59999999999978, 47.00000000000014, 20.000000000000014, 34.70000000000024, 20.000000000000014, 25.10000000000011, 9.499999999999968, 44.30000000000008, -8.199999999999958, 16.399999999999963, -9.999999999999888, 20.000000000000014, 91.09999999999931, 117.1999999999996, 1.9999999999999731, 27.800000000000143, -64.60000000000076, 20.000000000000014, 20.000000000000014, 5.299999999999965, 20.000000000000014, 20.000000000000014, -15.699999999999747, 21.50000000000008, 26.30000000000011, -53.50000000000016, 20.000000000000014, 5.299999999999967, 72.1999999999996, 20.000000000000014, -9.399999999999855, 42.50000000000001, 73.69999999999966, 40.70000000000025, -7.599999999999982, 39.80000000000018, 7.9999999999999885, 20.000000000000014, 68.59999999999982, 20.000000000000014, -19.899999999999743, -3.0999999999999615, 20.000000000000014, 110.8999999999995, 38.90000000000022, -0.09999999999998116, 36.800000000000246, 39.80000000000025, 20.000000000000014, 47.90000000000024, -5.1999999999999265, 84.19999999999949, 38.000000000000256, 20.000000000000014, -17.19999999999977, -13.599999999999797, 20.90000000000003, 20.000000000000014, 11.599999999999971, 33.800000000000146, 20.000000000000014, 28.100000000000147, -2.7999999999999896, 20.000000000000014, 28.100000000000147, 34.40000000000026, 28.70000000000017, 8.899999999999977, 94.39999999999966, 20.000000000000014, 45.200000000000244, 20.000000000000014, 24.50000000000008, -13.599999999999783, 100.39999999999957, 58.700000000000166, 25.400000000000098, 20.000000000000014, 49.70000000000024, 62.60000000000011, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 21.800000000000047, 32.60000000000023, -3.099999999999972, 43.10000000000016, 47.00000000000023, 70.09999999999975, 20.000000000000014, 20.000000000000014, 21.800000000000047, 7.999999999999966, 20.900000000000027, 67.69999999999993, -53.50000000000012, 96.4999999999994, 39.50000000000015, 21.80000000000004, 36.2000000000002, 20.000000000000014, 29.300000000000182, 8.599999999999968, 24.50000000000008, 51.50000000000016, -9.399999999999869, -15.699999999999783, -25.29999999999977, 20.000000000000014, 35.900000000000226, 13.699999999999967, -0.9999999999999881, 20.000000000000014, 5.299999999999965, 29.000000000000163, 25.400000000000098, 9.499999999999968, 20.000000000000014, 20.000000000000014, 13.699999999999969, 35.00000000000018, 20.000000000000014, 83.29999999999967, 22.700000000000053, 10.699999999999992, 31.700000000000188, 46.1000000000002, 20.000000000000014, 15.799999999999963, 24.500000000000096, 70.09999999999974, -0.9999999999999846, 20.000000000000014, 20.000000000000014, 56.900000000000226, 87.49999999999929, 20.000000000000014, 20.000000000000014, 34.40000000000024, 28.100000000000154, 20.000000000000014, 20.000000000000014, 38.0000000000002, -6.099999999999923, 102.7999999999994, 58.10000000000009, 20.000000000000014, 62.00000000000014, 44.90000000000024, 58.40000000000014, 20.000000000000014, 27.20000000000013, -24.099999999999746, 41.60000000000025, 91.9999999999996, 79.09999999999931, -11.499999999999819, -6.99999999999992, 7.099999999999964, 13.999999999999975, 89.2999999999993, 20.000000000000014, 40.70000000000025, 40.1000000000002, 20.000000000000014, 15.799999999999963, -65.50000000000068, 72.79999999999951, 30.800000000000196, 80.59999999999968, 22.700000000000053, 20.000000000000014, 33.50000000000018, -45.69999999999986, -3.3999999999999795, 16.69999999999997, 29.900000000000187, 17.899999999999984, 20.000000000000014, -15.699999999999747, 63.200000000000216, -5.799999999999963, 91.99999999999972, 21.200000000000042, 20.000000000000014, 70.99999999999967, 94.69999999999992, 70.99999999999972, 60.20000000000016, 20.000000000000014, 20.000000000000014, 65.89999999999988, 13.099999999999966, 55.70000000000022, 20.000000000000014, -9.39999999999989, 49.70000000000024], "policy_predator_policy_reward": [0.0, 0.0, 20.0, 30.0, 0.0, 5.0, 4.0, 0.0, 12.0, 13.0, 0.0, 28.0, 9.0, 19.0, 0.0, 0.0, 22.0, 0.0, 42.0, 8.0, 0.0, 7.0, 0.0, 0.0, 8.0, 37.0, 0.0, 35.0, 0.0, 7.0, 0.0, 0.0, 14.0, 1.0, 16.0, 0.0, 31.0, 9.0, 0.0, 22.0, 0.0, 0.0, 0.0, 19.0, 3.0, 0.0, 10.0, 5.0, 0.0, 1.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 15.0, 23.0, 0.0, 0.0, 2.0, 13.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 20.0, 0.0, 7.0, 9.0, 0.0, 0.0, 0.0, 16.0, 0.0, 2.0, 0.0, 0.0, 1.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 15.0, 15.0, 0.0, 4.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 10.0, 25.0, 1.0, 0.0, 0.0, 12.0, 0.0, 11.0, 0.0, 0.0, 1.0, 30.0, 0.0, 25.0, 7.0, 3.0, 10.0, 0.0, 0.0, 7.0, 0.0, 5.0, 0.0, 0.0, 0.0, 22.0, 8.0, 0.0, 10.0, 0.0, 0.0, 9.0, 0.0, 2.0, 0.0, 4.0, 4.0, 8.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 15.0, 0.0, 0.0, 0.0, 6.0, 9.0, 29.0, 5.0, 14.0, 0.0, 4.0, 0.0, 0.0, 21.0, 0.0, 0.0, 6.0, 15.0, 18.0, 7.0, 0.0, 17.0, 0.0, 0.0, 11.0, 0.0, 53.0, 0.0, 10.0, 0.0, 0.0, 5.0, 0.0, 0.0, 32.0, 31.0, 12.0, 9.0, 1.0, 0.0, 17.0, 0.0, 23.0, 0.0, 10.0, 1.0, 0.0, 1.0, 29.0, 0.0, 0.0, 0.0, 5.0, 0.0, 1.0, 0.0, 0.0, 14.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 18.16902511532496, "mean_inference_ms": 86.81338537245789, "mean_action_processing_ms": 19.11084304938721, "mean_env_wait_ms": 33.66677044547578, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.009572625160217285, "StateBufferConnector_ms": 0.007147073745727539, "ViewRequirementAgentConnector_ms": 0.2716867923736572}, "num_episodes": 18, "episode_return_max": 208.29999999999885, "episode_return_min": -3.999999999999696, "episode_return_mean": 67.06799999999983, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 256000, "num_agent_steps_trained": 256000, "num_env_steps_sampled": 64000, "num_env_steps_trained": 64000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 176.98696883362584, "num_env_steps_trained_throughput_per_sec": 176.98696883362584, "timesteps_total": 64000, "num_env_steps_sampled_lifetime": 64000, "num_agent_steps_sampled_lifetime": 256000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 256000, "timers": {"training_iteration_time_ms": 21525.086, "restore_workers_time_ms": 0.018, "training_step_time_ms": 21525.007, "sample_time_ms": 3076.974, "learn_time_ms": 18412.632, "learn_throughput": 217.242, "synch_weights_time_ms": 29.944}, "counters": {"num_env_steps_sampled": 64000, "num_env_steps_trained": 64000, "num_agent_steps_sampled": 256000, "num_agent_steps_trained": 256000}, "done": false, "training_iteration": 16, "trial_id": "75ec3_00000", "date": "2024-08-13_01-40-10", "timestamp": 1723527610, "time_this_iter_s": 22.69880509376526, "time_total_s": 1267.8952434062958, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b20589d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1267.8952434062958, "iterations_since_restore": 16, "perf": {"cpu_util_percent": 85.071875, "ram_util_percent": 83.521875}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.233630810748963, "cur_kl_coeff": 0.084375, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.669280675479344, "policy_loss": -0.0053429773958183074, "vf_loss": 3.673353642130655, "vf_explained_var": 0.07425377075634305, "kl": 0.015051999542486044, "entropy": 1.3971516761199507, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 31185.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.2850688797791326, "cur_kl_coeff": 0.0125, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.0292295172416344, "policy_loss": -0.002679315699934565, "vf_loss": 1.031810750548171, "vf_explained_var": 0.010458157239136873, "kl": 0.007846623172925102, "entropy": 1.4204063555550954, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 31185.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 68000, "num_env_steps_trained": 68000, "num_agent_steps_sampled": 272000, "num_agent_steps_trained": 272000}, "env_runners": {"episode_reward_max": 269.40000000000094, "episode_reward_min": -3.999999999999696, "episode_reward_mean": 71.71999999999983, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -65.50000000000068, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 140.6, "predator_policy": 53.0}, "policy_reward_mean": {"prey_policy": 30.170000000000012, "predator_policy": 5.69}, "custom_metrics": {}, "hist_stats": {"episode_reward": [72.19999999999976, 50.00000000000037, 88.59999999999883, -3.999999999999696, 133.8999999999988, 53.800000000000445, 77.59999999999954, 67.90000000000022, 91.999999999999, 58.00000000000052, 7.200000000000099, 40.90000000000031, 60.40000000000037, 48.10000000000043, 39.20000000000035, 62.50000000000053, 57.600000000000406, 130.39999999999912, 65.20000000000041, 26.900000000000095, 161.09999999999886, 45.40000000000038, 124.29999999999926, 40.0000000000003, 40.0000000000003, 54.40000000000051, 69.99999999999993, 121.09999999999837, 40.0000000000003, 36.80000000000026, 88.5999999999987, 77.99999999999935, 62.30000000000031, 68.20000000000012, 48.90000000000043, 75.99999999999949, 5.900000000000096, 19.700000000000028, 59.60000000000046, 29.000000000000128, 41.30000000000031, 39.90000000000029, 40.0000000000003, 70.69999999999995, 111.29999999999876, 43.40000000000016, 86.79999999999882, 37.80000000000027, 98.59999999999862, 31.000000000000163, 76.89999999999957, 107.49999999999855, 57.40000000000048, 63.10000000000025, 58.0000000000004, 111.69999999999871, 112.0999999999992, 120.89999999999874, 82.39999999999905, 24.100000000000048, 133.59999999999906, 88.59999999999867, 25.10000000000007, 120.29999999999848, 60.70000000000051, 71.09999999999992, 3.3000000000000527, 113.59999999999877, 108.2999999999991, 53.50000000000035, 13.900000000000045, 67.60000000000018, 38.90000000000028, 64.50000000000041, 109.19999999999928, 52.20000000000046, 166.6999999999989, 160.19999999999902, 40.0000000000003, 83.99999999999974, 76.69999999999958, 54.30000000000047, 19.30000000000003, 42.700000000000344, 36.20000000000012, 22.400000000000027, 113.49999999999889, 69.10000000000004, 145.49999999999883, 159.6999999999991, 63.400000000000446, 155.99999999999957, 24.20000000000004, 269.40000000000094, 50.60000000000038, 131.49999999999966, 46.700000000000415, 40.0000000000003, 35.600000000000236, 127.29999999999889], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-7.599999999999982, 39.80000000000018, 7.9999999999999885, 20.000000000000014, 68.59999999999982, 20.000000000000014, -19.899999999999743, -3.0999999999999615, 20.000000000000014, 110.8999999999995, 38.90000000000022, -0.09999999999998116, 36.800000000000246, 39.80000000000025, 20.000000000000014, 47.90000000000024, -5.1999999999999265, 84.19999999999949, 38.000000000000256, 20.000000000000014, -17.19999999999977, -13.599999999999797, 20.90000000000003, 20.000000000000014, 11.599999999999971, 33.800000000000146, 20.000000000000014, 28.100000000000147, -2.7999999999999896, 20.000000000000014, 28.100000000000147, 34.40000000000026, 28.70000000000017, 8.899999999999977, 94.39999999999966, 20.000000000000014, 45.200000000000244, 20.000000000000014, 24.50000000000008, -13.599999999999783, 100.39999999999957, 58.700000000000166, 25.400000000000098, 20.000000000000014, 49.70000000000024, 62.60000000000011, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 21.800000000000047, 32.60000000000023, -3.099999999999972, 43.10000000000016, 47.00000000000023, 70.09999999999975, 20.000000000000014, 20.000000000000014, 21.800000000000047, 7.999999999999966, 20.900000000000027, 67.69999999999993, -53.50000000000012, 96.4999999999994, 39.50000000000015, 21.80000000000004, 36.2000000000002, 20.000000000000014, 29.300000000000182, 8.599999999999968, 24.50000000000008, 51.50000000000016, -9.399999999999869, -15.699999999999783, -25.29999999999977, 20.000000000000014, 35.900000000000226, 13.699999999999967, -0.9999999999999881, 20.000000000000014, 5.299999999999965, 29.000000000000163, 25.400000000000098, 9.499999999999968, 20.000000000000014, 20.000000000000014, 13.699999999999969, 35.00000000000018, 20.000000000000014, 83.29999999999967, 22.700000000000053, 10.699999999999992, 31.700000000000188, 46.1000000000002, 20.000000000000014, 15.799999999999963, 24.500000000000096, 70.09999999999974, -0.9999999999999846, 20.000000000000014, 20.000000000000014, 56.900000000000226, 87.49999999999929, 20.000000000000014, 20.000000000000014, 34.40000000000024, 28.100000000000154, 20.000000000000014, 20.000000000000014, 38.0000000000002, -6.099999999999923, 102.7999999999994, 58.10000000000009, 20.000000000000014, 62.00000000000014, 44.90000000000024, 58.40000000000014, 20.000000000000014, 27.20000000000013, -24.099999999999746, 41.60000000000025, 91.9999999999996, 79.09999999999931, -11.499999999999819, -6.99999999999992, 7.099999999999964, 13.999999999999975, 89.2999999999993, 20.000000000000014, 40.70000000000025, 40.1000000000002, 20.000000000000014, 15.799999999999963, -65.50000000000068, 72.79999999999951, 30.800000000000196, 80.59999999999968, 22.700000000000053, 20.000000000000014, 33.50000000000018, -45.69999999999986, -3.3999999999999795, 16.69999999999997, 29.900000000000187, 17.899999999999984, 20.000000000000014, -15.699999999999747, 63.200000000000216, -5.799999999999963, 91.99999999999972, 21.200000000000042, 20.000000000000014, 70.99999999999967, 94.69999999999992, 70.99999999999972, 60.20000000000016, 20.000000000000014, 20.000000000000014, 65.89999999999988, 13.099999999999966, 55.70000000000022, 20.000000000000014, -9.39999999999989, 49.70000000000024, -11.499999999999833, 3.7999999999999994, 20.000000000000014, 22.700000000000056, -0.9999999999999846, 27.200000000000003, 20.000000000000014, -22.599999999999767, 21.800000000000043, 85.69999999999949, 20.000000000000014, 37.10000000000019, 18.800000000000022, 100.69999999999958, 20.000000000000014, 139.69999999999973, 20.000000000000014, 43.40000000000021, 10.399999999999965, 140.6, -12.6999999999998, 20.900000000000027, 133.3999999999998, 118.99999999999979, 11.599999999999977, 20.000000000000014, 100.99999999999996, 24.50000000000008, 37.10000000000026, -12.399999999999816, 20.000000000000014, 20.000000000000014, 20.000000000000014, 11.599999999999966, 107.29999999999953, 20.000000000000014], "policy_predator_policy_reward": [31.0, 9.0, 0.0, 22.0, 0.0, 0.0, 0.0, 19.0, 3.0, 0.0, 10.0, 5.0, 0.0, 1.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 15.0, 23.0, 0.0, 0.0, 2.0, 13.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 20.0, 0.0, 7.0, 9.0, 0.0, 0.0, 0.0, 16.0, 0.0, 2.0, 0.0, 0.0, 1.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 15.0, 15.0, 0.0, 4.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 10.0, 25.0, 1.0, 0.0, 0.0, 12.0, 0.0, 11.0, 0.0, 0.0, 1.0, 30.0, 0.0, 25.0, 7.0, 3.0, 10.0, 0.0, 0.0, 7.0, 0.0, 5.0, 0.0, 0.0, 0.0, 22.0, 8.0, 0.0, 10.0, 0.0, 0.0, 9.0, 0.0, 2.0, 0.0, 4.0, 4.0, 8.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 15.0, 0.0, 0.0, 0.0, 6.0, 9.0, 29.0, 5.0, 14.0, 0.0, 4.0, 0.0, 0.0, 21.0, 0.0, 0.0, 6.0, 15.0, 18.0, 7.0, 0.0, 17.0, 0.0, 0.0, 11.0, 0.0, 53.0, 0.0, 10.0, 0.0, 0.0, 5.0, 0.0, 0.0, 32.0, 31.0, 12.0, 9.0, 1.0, 0.0, 17.0, 0.0, 23.0, 0.0, 10.0, 1.0, 0.0, 1.0, 29.0, 0.0, 0.0, 0.0, 5.0, 0.0, 1.0, 0.0, 0.0, 14.0, 12.0, 15.0, 0.0, 0.0, 0.0, 10.0, 20.0, 5.0, 6.0, 0.0, 6.0, 6.0, 8.0, 18.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 16.0, 15.0, 2.0, 0.0, 19.0, 0.0, 6.0, 14.0, 8.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 17.158713430991128, "mean_inference_ms": 81.7288648396105, "mean_action_processing_ms": 17.93408466458175, "mean_env_wait_ms": 31.624293007869788, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00961160659790039, "StateBufferConnector_ms": 0.007883429527282715, "ViewRequirementAgentConnector_ms": 0.2759438753128052}, "num_episodes": 18, "episode_return_max": 269.40000000000094, "episode_return_min": -3.999999999999696, "episode_return_mean": 71.71999999999983, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 272000, "num_agent_steps_trained": 272000, "num_env_steps_sampled": 68000, "num_env_steps_trained": 68000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 176.30443054675317, "num_env_steps_trained_throughput_per_sec": 176.30443054675317, "timesteps_total": 68000, "num_env_steps_sampled_lifetime": 68000, "num_agent_steps_sampled_lifetime": 272000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 272000, "timers": {"training_iteration_time_ms": 21800.128, "restore_workers_time_ms": 0.024, "training_step_time_ms": 21800.037, "sample_time_ms": 3153.344, "learn_time_ms": 18607.462, "learn_throughput": 214.968, "synch_weights_time_ms": 32.676}, "counters": {"num_env_steps_sampled": 68000, "num_env_steps_trained": 68000, "num_agent_steps_sampled": 272000, "num_agent_steps_trained": 272000}, "done": false, "training_iteration": 17, "trial_id": "75ec3_00000", "date": "2024-08-13_01-40-33", "timestamp": 1723527633, "time_this_iter_s": 22.748615264892578, "time_total_s": 1290.6438586711884, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b1adfc10>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1290.6438586711884, "iterations_since_restore": 17, "perf": {"cpu_util_percent": 84.30625, "ram_util_percent": 83.359375}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4165354667123033, "cur_kl_coeff": 0.084375, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.260528700692313, "policy_loss": -0.002274362411763933, "vf_loss": 3.2622690302985053, "vf_explained_var": 0.09654511292144735, "kl": 0.006329185308788439, "entropy": 1.4144439555980541, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 33075.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.28556473747132316, "cur_kl_coeff": 0.0125, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.8448239492360877, "policy_loss": -0.0021355105280659345, "vf_loss": 0.8468468863418493, "vf_explained_var": 0.012992638980270062, "kl": 0.009005810771962153, "entropy": 1.3818711342004242, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 33075.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 72000, "num_env_steps_trained": 72000, "num_agent_steps_sampled": 288000, "num_agent_steps_trained": 288000}, "env_runners": {"episode_reward_max": 269.40000000000094, "episode_reward_min": -24.400000000000446, "episode_reward_mean": 76.52899999999975, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -101.50000000000014, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 172.99999999999983, "predator_policy": 53.0}, "policy_reward_mean": {"prey_policy": 31.014499999999988, "predator_policy": 7.25}, "custom_metrics": {}, "hist_stats": {"episode_reward": [124.29999999999926, 40.0000000000003, 40.0000000000003, 54.40000000000051, 69.99999999999993, 121.09999999999837, 40.0000000000003, 36.80000000000026, 88.5999999999987, 77.99999999999935, 62.30000000000031, 68.20000000000012, 48.90000000000043, 75.99999999999949, 5.900000000000096, 19.700000000000028, 59.60000000000046, 29.000000000000128, 41.30000000000031, 39.90000000000029, 40.0000000000003, 70.69999999999995, 111.29999999999876, 43.40000000000016, 86.79999999999882, 37.80000000000027, 98.59999999999862, 31.000000000000163, 76.89999999999957, 107.49999999999855, 57.40000000000048, 63.10000000000025, 58.0000000000004, 111.69999999999871, 112.0999999999992, 120.89999999999874, 82.39999999999905, 24.100000000000048, 133.59999999999906, 88.59999999999867, 25.10000000000007, 120.29999999999848, 60.70000000000051, 71.09999999999992, 3.3000000000000527, 113.59999999999877, 108.2999999999991, 53.50000000000035, 13.900000000000045, 67.60000000000018, 38.90000000000028, 64.50000000000041, 109.19999999999928, 52.20000000000046, 166.6999999999989, 160.19999999999902, 40.0000000000003, 83.99999999999974, 76.69999999999958, 54.30000000000047, 19.30000000000003, 42.700000000000344, 36.20000000000012, 22.400000000000027, 113.49999999999889, 69.10000000000004, 145.49999999999883, 159.6999999999991, 63.400000000000446, 155.99999999999957, 24.20000000000004, 269.40000000000094, 50.60000000000038, 131.49999999999966, 46.700000000000415, 40.0000000000003, 35.600000000000236, 127.29999999999889, 177.0999999999993, 190.49999999999972, 36.500000000000234, 147.99999999999875, 164.3999999999993, 55.90000000000017, 107.69999999999956, 46.50000000000006, 81.79999999999922, -0.9999999999997664, 150.09999999999914, 103.89999999999893, 70.20000000000006, 37.80000000000027, -24.400000000000446, 31.200000000000166, 64.90000000000008, 122.39999999999903, 112.89999999999876, 64.90000000000042, 126.19999999999973, 48.300000000000175], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [49.70000000000024, 62.60000000000011, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 21.800000000000047, 32.60000000000023, -3.099999999999972, 43.10000000000016, 47.00000000000023, 70.09999999999975, 20.000000000000014, 20.000000000000014, 21.800000000000047, 7.999999999999966, 20.900000000000027, 67.69999999999993, -53.50000000000012, 96.4999999999994, 39.50000000000015, 21.80000000000004, 36.2000000000002, 20.000000000000014, 29.300000000000182, 8.599999999999968, 24.50000000000008, 51.50000000000016, -9.399999999999869, -15.699999999999783, -25.29999999999977, 20.000000000000014, 35.900000000000226, 13.699999999999967, -0.9999999999999881, 20.000000000000014, 5.299999999999965, 29.000000000000163, 25.400000000000098, 9.499999999999968, 20.000000000000014, 20.000000000000014, 13.699999999999969, 35.00000000000018, 20.000000000000014, 83.29999999999967, 22.700000000000053, 10.699999999999992, 31.700000000000188, 46.1000000000002, 20.000000000000014, 15.799999999999963, 24.500000000000096, 70.09999999999974, -0.9999999999999846, 20.000000000000014, 20.000000000000014, 56.900000000000226, 87.49999999999929, 20.000000000000014, 20.000000000000014, 34.40000000000024, 28.100000000000154, 20.000000000000014, 20.000000000000014, 38.0000000000002, -6.099999999999923, 102.7999999999994, 58.10000000000009, 20.000000000000014, 62.00000000000014, 44.90000000000024, 58.40000000000014, 20.000000000000014, 27.20000000000013, -24.099999999999746, 41.60000000000025, 91.9999999999996, 79.09999999999931, -11.499999999999819, -6.99999999999992, 7.099999999999964, 13.999999999999975, 89.2999999999993, 20.000000000000014, 40.70000000000025, 40.1000000000002, 20.000000000000014, 15.799999999999963, -65.50000000000068, 72.79999999999951, 30.800000000000196, 80.59999999999968, 22.700000000000053, 20.000000000000014, 33.50000000000018, -45.69999999999986, -3.3999999999999795, 16.69999999999997, 29.900000000000187, 17.899999999999984, 20.000000000000014, -15.699999999999747, 63.200000000000216, -5.799999999999963, 91.99999999999972, 21.200000000000042, 20.000000000000014, 70.99999999999967, 94.69999999999992, 70.99999999999972, 60.20000000000016, 20.000000000000014, 20.000000000000014, 65.89999999999988, 13.099999999999966, 55.70000000000022, 20.000000000000014, -9.39999999999989, 49.70000000000024, -11.499999999999833, 3.7999999999999994, 20.000000000000014, 22.700000000000056, -0.9999999999999846, 27.200000000000003, 20.000000000000014, -22.599999999999767, 21.800000000000043, 85.69999999999949, 20.000000000000014, 37.10000000000019, 18.800000000000022, 100.69999999999958, 20.000000000000014, 139.69999999999973, 20.000000000000014, 43.40000000000021, 10.399999999999965, 140.6, -12.6999999999998, 20.900000000000027, 133.3999999999998, 118.99999999999979, 11.599999999999977, 20.000000000000014, 100.99999999999996, 24.50000000000008, 37.10000000000026, -12.399999999999816, 20.000000000000014, 20.000000000000014, 20.000000000000014, 11.599999999999966, 107.29999999999953, 20.000000000000014, 172.99999999999983, -22.89999999999977, 92.89999999999971, 59.600000000000044, 12.499999999999966, 20.000000000000014, 64.10000000000021, 83.89999999999961, 136.39999999999986, 20.000000000000014, 15.799999999999963, 25.10000000000019, 79.69999999999996, 20.000000000000014, -54.400000000000404, 35.90000000000021, 7.399999999999967, 58.400000000000176, 9.499999999999964, -101.50000000000014, 22.700000000000063, 109.39999999999975, 53.300000000000146, 50.60000000000021, -43.900000000000404, 37.10000000000016, 15.799999999999963, 20.000000000000014, -21.999999999999744, -60.40000000000025, 3.1999999999999615, 20.000000000000014, -64.00000000000063, 86.89999999999985, 100.39999999999961, 20.000000000000014, 85.99999999999943, 17.899999999999984, 7.39999999999997, 51.500000000000234, 92.30000000000004, 20.90000000000003, 13.699999999999962, -12.399999999999865], "policy_predator_policy_reward": [1.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 15.0, 15.0, 0.0, 4.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 10.0, 25.0, 1.0, 0.0, 0.0, 12.0, 0.0, 11.0, 0.0, 0.0, 1.0, 30.0, 0.0, 25.0, 7.0, 3.0, 10.0, 0.0, 0.0, 7.0, 0.0, 5.0, 0.0, 0.0, 0.0, 22.0, 8.0, 0.0, 10.0, 0.0, 0.0, 9.0, 0.0, 2.0, 0.0, 4.0, 4.0, 8.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 15.0, 0.0, 0.0, 0.0, 6.0, 9.0, 29.0, 5.0, 14.0, 0.0, 4.0, 0.0, 0.0, 21.0, 0.0, 0.0, 6.0, 15.0, 18.0, 7.0, 0.0, 17.0, 0.0, 0.0, 11.0, 0.0, 53.0, 0.0, 10.0, 0.0, 0.0, 5.0, 0.0, 0.0, 32.0, 31.0, 12.0, 9.0, 1.0, 0.0, 17.0, 0.0, 23.0, 0.0, 10.0, 1.0, 0.0, 1.0, 29.0, 0.0, 0.0, 0.0, 5.0, 0.0, 1.0, 0.0, 0.0, 14.0, 12.0, 15.0, 0.0, 0.0, 0.0, 10.0, 20.0, 5.0, 6.0, 0.0, 6.0, 6.0, 8.0, 18.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 16.0, 15.0, 2.0, 0.0, 19.0, 0.0, 6.0, 14.0, 8.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 26.0, 1.0, 22.0, 16.0, 0.0, 4.0, 0.0, 0.0, 0.0, 8.0, 13.0, 2.0, 8.0, 0.0, 36.0, 29.0, 16.0, 0.0, 52.0, 39.0, 5.0, 13.0, 0.0, 0.0, 49.0, 28.0, 2.0, 0.0, 8.0, 50.0, 0.0, 8.0, 2.0, 40.0, 0.0, 2.0, 8.0, 1.0, 0.0, 6.0, 5.0, 8.0, 25.0, 22.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 16.26547586789592, "mean_inference_ms": 79.58658823391964, "mean_action_processing_ms": 15.296061229348021, "mean_env_wait_ms": 27.68403581617169, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007951140403747559, "StateBufferConnector_ms": 0.02258157730102539, "ViewRequirementAgentConnector_ms": 0.25025880336761475}, "num_episodes": 22, "episode_return_max": 269.40000000000094, "episode_return_min": -24.400000000000446, "episode_return_mean": 76.52899999999975, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 288000, "num_agent_steps_trained": 288000, "num_env_steps_sampled": 72000, "num_env_steps_trained": 72000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 3.9937863226612866, "num_env_steps_trained_throughput_per_sec": 3.9937863226612866, "timesteps_total": 72000, "num_env_steps_sampled_lifetime": 72000, "num_agent_steps_sampled_lifetime": 288000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 288000, "timers": {"training_iteration_time_ms": 119979.876, "restore_workers_time_ms": 0.024, "training_step_time_ms": 119979.801, "sample_time_ms": 3199.746, "learn_time_ms": 116739.895, "learn_throughput": 34.264, "synch_weights_time_ms": 33.679}, "counters": {"num_env_steps_sampled": 72000, "num_env_steps_trained": 72000, "num_agent_steps_sampled": 288000, "num_agent_steps_trained": 288000}, "done": false, "training_iteration": 18, "trial_id": "75ec3_00000", "date": "2024-08-13_01-57-14", "timestamp": 1723528634, "time_this_iter_s": 1001.6632490158081, "time_total_s": 2292.3071076869965, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b1bc6430>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2292.3071076869965, "iterations_since_restore": 18, "perf": {"cpu_util_percent": 91.46428571428571, "ram_util_percent": 83.63095238095238}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3816981434822082, "cur_kl_coeff": 0.084375, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.503715138586741, "policy_loss": -0.004849449917550873, "vf_loss": 4.5069639705476305, "vf_explained_var": 0.08324150638605551, "kl": 0.018970431457756474, "entropy": 1.360023376550624, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 34965.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.3202550535794919, "cur_kl_coeff": 0.0125, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.2720743353089328, "policy_loss": -0.003023459078625791, "vf_loss": 1.2750102048040066, "vf_explained_var": 0.017068857995290603, "kl": 0.007007157546770351, "entropy": 1.3763710623695737, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 34965.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 76000, "num_env_steps_trained": 76000, "num_agent_steps_sampled": 304000, "num_agent_steps_trained": 304000}, "env_runners": {"episode_reward_max": 269.40000000000094, "episode_reward_min": -30.39999999999955, "episode_reward_mean": 81.25899999999973, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -114.40000000000074, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 172.99999999999983, "predator_policy": 61.0}, "policy_reward_mean": {"prey_policy": 31.95949999999997, "predator_policy": 8.67}, "custom_metrics": {}, "hist_stats": {"episode_reward": [43.40000000000016, 86.79999999999882, 37.80000000000027, 98.59999999999862, 31.000000000000163, 76.89999999999957, 107.49999999999855, 57.40000000000048, 63.10000000000025, 58.0000000000004, 111.69999999999871, 112.0999999999992, 120.89999999999874, 82.39999999999905, 24.100000000000048, 133.59999999999906, 88.59999999999867, 25.10000000000007, 120.29999999999848, 60.70000000000051, 71.09999999999992, 3.3000000000000527, 113.59999999999877, 108.2999999999991, 53.50000000000035, 13.900000000000045, 67.60000000000018, 38.90000000000028, 64.50000000000041, 109.19999999999928, 52.20000000000046, 166.6999999999989, 160.19999999999902, 40.0000000000003, 83.99999999999974, 76.69999999999958, 54.30000000000047, 19.30000000000003, 42.700000000000344, 36.20000000000012, 22.400000000000027, 113.49999999999889, 69.10000000000004, 145.49999999999883, 159.6999999999991, 63.400000000000446, 155.99999999999957, 24.20000000000004, 269.40000000000094, 50.60000000000038, 131.49999999999966, 46.700000000000415, 40.0000000000003, 35.600000000000236, 127.29999999999889, 177.0999999999993, 190.49999999999972, 36.500000000000234, 147.99999999999875, 164.3999999999993, 55.90000000000017, 107.69999999999956, 46.50000000000006, 81.79999999999922, -0.9999999999997664, 150.09999999999914, 103.89999999999893, 70.20000000000006, 37.80000000000027, -24.400000000000446, 31.200000000000166, 64.90000000000008, 122.39999999999903, 112.89999999999876, 64.90000000000042, 126.19999999999973, 48.300000000000175, 0.7000000000002395, 228.7999999999995, 25.300000000000026, 93.19999999999891, -11.099999999999579, 158.0999999999992, 97.59999999999894, -8.999999999999693, 123.49999999999926, 50.00000000000033, 37.60000000000011, 25.700000000000113, 80.5000000000001, 119.19999999999865, 51.70000000000049, 178.69999999999956, 218.4999999999995, 56.20000000000046, 135.39999999999898, 47.80000000000038, 76.89999999999964, -30.39999999999955, 84.09999999999934], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [22.700000000000053, 10.699999999999992, 31.700000000000188, 46.1000000000002, 20.000000000000014, 15.799999999999963, 24.500000000000096, 70.09999999999974, -0.9999999999999846, 20.000000000000014, 20.000000000000014, 56.900000000000226, 87.49999999999929, 20.000000000000014, 20.000000000000014, 34.40000000000024, 28.100000000000154, 20.000000000000014, 20.000000000000014, 38.0000000000002, -6.099999999999923, 102.7999999999994, 58.10000000000009, 20.000000000000014, 62.00000000000014, 44.90000000000024, 58.40000000000014, 20.000000000000014, 27.20000000000013, -24.099999999999746, 41.60000000000025, 91.9999999999996, 79.09999999999931, -11.499999999999819, -6.99999999999992, 7.099999999999964, 13.999999999999975, 89.2999999999993, 20.000000000000014, 40.70000000000025, 40.1000000000002, 20.000000000000014, 15.799999999999963, -65.50000000000068, 72.79999999999951, 30.800000000000196, 80.59999999999968, 22.700000000000053, 20.000000000000014, 33.50000000000018, -45.69999999999986, -3.3999999999999795, 16.69999999999997, 29.900000000000187, 17.899999999999984, 20.000000000000014, -15.699999999999747, 63.200000000000216, -5.799999999999963, 91.99999999999972, 21.200000000000042, 20.000000000000014, 70.99999999999967, 94.69999999999992, 70.99999999999972, 60.20000000000016, 20.000000000000014, 20.000000000000014, 65.89999999999988, 13.099999999999966, 55.70000000000022, 20.000000000000014, -9.39999999999989, 49.70000000000024, -11.499999999999833, 3.7999999999999994, 20.000000000000014, 22.700000000000056, -0.9999999999999846, 27.200000000000003, 20.000000000000014, -22.599999999999767, 21.800000000000043, 85.69999999999949, 20.000000000000014, 37.10000000000019, 18.800000000000022, 100.69999999999958, 20.000000000000014, 139.69999999999973, 20.000000000000014, 43.40000000000021, 10.399999999999965, 140.6, -12.6999999999998, 20.900000000000027, 133.3999999999998, 118.99999999999979, 11.599999999999977, 20.000000000000014, 100.99999999999996, 24.50000000000008, 37.10000000000026, -12.399999999999816, 20.000000000000014, 20.000000000000014, 20.000000000000014, 11.599999999999966, 107.29999999999953, 20.000000000000014, 172.99999999999983, -22.89999999999977, 92.89999999999971, 59.600000000000044, 12.499999999999966, 20.000000000000014, 64.10000000000021, 83.89999999999961, 136.39999999999986, 20.000000000000014, 15.799999999999963, 25.10000000000019, 79.69999999999996, 20.000000000000014, -54.400000000000404, 35.90000000000021, 7.399999999999967, 58.400000000000176, 9.499999999999964, -101.50000000000014, 22.700000000000063, 109.39999999999975, 53.300000000000146, 50.60000000000021, -43.900000000000404, 37.10000000000016, 15.799999999999963, 20.000000000000014, -21.999999999999744, -60.40000000000025, 3.1999999999999615, 20.000000000000014, -64.00000000000063, 86.89999999999985, 100.39999999999961, 20.000000000000014, 85.99999999999943, 17.899999999999984, 7.39999999999997, 51.500000000000234, 92.30000000000004, 20.90000000000003, 13.699999999999962, -12.399999999999865, -76.3000000000005, 20.000000000000014, 82.99999999999987, 120.79999999999961, -32.49999999999975, 30.799999999999997, 87.49999999999946, -7.299999999999926, -42.999999999999766, -3.099999999999958, 107.59999999999951, 24.500000000000046, 20.000000000000014, 77.59999999999958, -14.799999999999807, -26.199999999999775, 84.49999999999974, 20.000000000000014, -31.59999999999981, 50.600000000000236, 40.70000000000013, -24.099999999999753, 40.70000000000021, -64.00000000000075, 51.49999999999997, 20.000000000000014, 99.19999999999939, 20.000000000000014, 31.700000000000212, 20.000000000000014, 108.49999999999989, 39.20000000000009, 88.69999999999987, 96.79999999999984, 27.20000000000014, 20.000000000000014, 115.39999999999961, 20.000000000000014, 41.300000000000146, -26.49999999999978, 56.90000000000022, 20.000000000000014, 20.000000000000014, -114.40000000000074, 20.90000000000003, 63.20000000000008], "policy_predator_policy_reward": [10.0, 0.0, 0.0, 9.0, 0.0, 2.0, 0.0, 4.0, 4.0, 8.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 15.0, 0.0, 0.0, 0.0, 6.0, 9.0, 29.0, 5.0, 14.0, 0.0, 4.0, 0.0, 0.0, 21.0, 0.0, 0.0, 6.0, 15.0, 18.0, 7.0, 0.0, 17.0, 0.0, 0.0, 11.0, 0.0, 53.0, 0.0, 10.0, 0.0, 0.0, 5.0, 0.0, 0.0, 32.0, 31.0, 12.0, 9.0, 1.0, 0.0, 17.0, 0.0, 23.0, 0.0, 10.0, 1.0, 0.0, 1.0, 29.0, 0.0, 0.0, 0.0, 5.0, 0.0, 1.0, 0.0, 0.0, 14.0, 12.0, 15.0, 0.0, 0.0, 0.0, 10.0, 20.0, 5.0, 6.0, 0.0, 6.0, 6.0, 8.0, 18.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 16.0, 15.0, 2.0, 0.0, 19.0, 0.0, 6.0, 14.0, 8.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 26.0, 1.0, 22.0, 16.0, 0.0, 4.0, 0.0, 0.0, 0.0, 8.0, 13.0, 2.0, 8.0, 0.0, 36.0, 29.0, 16.0, 0.0, 52.0, 39.0, 5.0, 13.0, 0.0, 0.0, 49.0, 28.0, 2.0, 0.0, 8.0, 50.0, 0.0, 8.0, 2.0, 40.0, 0.0, 2.0, 8.0, 1.0, 0.0, 6.0, 5.0, 8.0, 25.0, 22.0, 44.0, 13.0, 15.0, 10.0, 20.0, 7.0, 13.0, 0.0, 11.0, 24.0, 4.0, 22.0, 0.0, 0.0, 32.0, 0.0, 19.0, 0.0, 0.0, 31.0, 20.0, 1.0, 9.0, 40.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 31.0, 0.0, 20.0, 13.0, 9.0, 0.0, 0.0, 0.0, 13.0, 20.0, 0.0, 0.0, 3.0, 61.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 15.083102285370833, "mean_inference_ms": 71.48721357379725, "mean_action_processing_ms": 15.61307125238058, "mean_env_wait_ms": 27.60508491633172, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.009266018867492676, "StateBufferConnector_ms": 0.021346330642700195, "ViewRequirementAgentConnector_ms": 0.24550390243530273}, "num_episodes": 23, "episode_return_max": 269.40000000000094, "episode_return_min": -30.39999999999955, "episode_return_mean": 81.25899999999973, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 304000, "num_agent_steps_trained": 304000, "num_env_steps_sampled": 76000, "num_env_steps_trained": 76000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 224.74787456446367, "num_env_steps_trained_throughput_per_sec": 224.74787456446367, "timesteps_total": 76000, "num_env_steps_sampled_lifetime": 76000, "num_agent_steps_sampled_lifetime": 304000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 304000, "timers": {"training_iteration_time_ms": 119869.452, "restore_workers_time_ms": 0.024, "training_step_time_ms": 119869.376, "sample_time_ms": 3241.455, "learn_time_ms": 116582.017, "learn_throughput": 34.311, "synch_weights_time_ms": 36.634}, "counters": {"num_env_steps_sampled": 76000, "num_env_steps_trained": 76000, "num_agent_steps_sampled": 304000, "num_agent_steps_trained": 304000}, "done": false, "training_iteration": 19, "trial_id": "75ec3_00000", "date": "2024-08-13_01-57-32", "timestamp": 1723528652, "time_this_iter_s": 17.886645793914795, "time_total_s": 2310.1937534809113, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b1be08b0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2310.1937534809113, "iterations_since_restore": 19, "perf": {"cpu_util_percent": 85.68799999999999, "ram_util_percent": 83.48}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.294367429054288, "cur_kl_coeff": 0.084375, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.0699980342829667, "policy_loss": -0.003347883484001079, "vf_loss": 3.0724372328273835, "vf_explained_var": 0.06287524233419428, "kl": 0.010769537470128357, "entropy": 1.363693372786991, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 36855.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.3183427024711534, "cur_kl_coeff": 0.0125, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.798588730718093, "policy_loss": -0.003987212867658368, "vf_loss": 0.802439668411931, "vf_explained_var": 0.029205711241121646, "kl": 0.010901977297048651, "entropy": 1.4584643720949768, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 36855.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 80000, "num_env_steps_trained": 80000, "num_agent_steps_sampled": 320000, "num_agent_steps_trained": 320000}, "env_runners": {"episode_reward_max": 269.40000000000094, "episode_reward_min": -30.39999999999955, "episode_reward_mean": 83.52099999999975, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -114.40000000000074, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 172.99999999999983, "predator_policy": 61.0}, "policy_reward_mean": {"prey_policy": 32.865499999999976, "predator_policy": 8.895}, "custom_metrics": {}, "hist_stats": {"episode_reward": [120.29999999999848, 60.70000000000051, 71.09999999999992, 3.3000000000000527, 113.59999999999877, 108.2999999999991, 53.50000000000035, 13.900000000000045, 67.60000000000018, 38.90000000000028, 64.50000000000041, 109.19999999999928, 52.20000000000046, 166.6999999999989, 160.19999999999902, 40.0000000000003, 83.99999999999974, 76.69999999999958, 54.30000000000047, 19.30000000000003, 42.700000000000344, 36.20000000000012, 22.400000000000027, 113.49999999999889, 69.10000000000004, 145.49999999999883, 159.6999999999991, 63.400000000000446, 155.99999999999957, 24.20000000000004, 269.40000000000094, 50.60000000000038, 131.49999999999966, 46.700000000000415, 40.0000000000003, 35.600000000000236, 127.29999999999889, 177.0999999999993, 190.49999999999972, 36.500000000000234, 147.99999999999875, 164.3999999999993, 55.90000000000017, 107.69999999999956, 46.50000000000006, 81.79999999999922, -0.9999999999997664, 150.09999999999914, 103.89999999999893, 70.20000000000006, 37.80000000000027, -24.400000000000446, 31.200000000000166, 64.90000000000008, 122.39999999999903, 112.89999999999876, 64.90000000000042, 126.19999999999973, 48.300000000000175, 0.7000000000002395, 228.7999999999995, 25.300000000000026, 93.19999999999891, -11.099999999999579, 158.0999999999992, 97.59999999999894, -8.999999999999693, 123.49999999999926, 50.00000000000033, 37.60000000000011, 25.700000000000113, 80.5000000000001, 119.19999999999865, 51.70000000000049, 178.69999999999956, 218.4999999999995, 56.20000000000046, 135.39999999999898, 47.80000000000038, 76.89999999999964, -30.39999999999955, 84.09999999999934, 193.49999999999898, 228.09999999999917, 107.09999999999923, 62.80000000000041, 22.50000000000004, 95.19999999999874, 93.49999999999937, 37.000000000000256, 33.5000000000002, 22.500000000000018, 82.49999999999906, 164.19999999999868, 165.09999999999908, 78.39999999999948, 40.0000000000003, 45.40000000000038, 82.4, 31.500000000000192], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [13.999999999999975, 89.2999999999993, 20.000000000000014, 40.70000000000025, 40.1000000000002, 20.000000000000014, 15.799999999999963, -65.50000000000068, 72.79999999999951, 30.800000000000196, 80.59999999999968, 22.700000000000053, 20.000000000000014, 33.50000000000018, -45.69999999999986, -3.3999999999999795, 16.69999999999997, 29.900000000000187, 17.899999999999984, 20.000000000000014, -15.699999999999747, 63.200000000000216, -5.799999999999963, 91.99999999999972, 21.200000000000042, 20.000000000000014, 70.99999999999967, 94.69999999999992, 70.99999999999972, 60.20000000000016, 20.000000000000014, 20.000000000000014, 65.89999999999988, 13.099999999999966, 55.70000000000022, 20.000000000000014, -9.39999999999989, 49.70000000000024, -11.499999999999833, 3.7999999999999994, 20.000000000000014, 22.700000000000056, -0.9999999999999846, 27.200000000000003, 20.000000000000014, -22.599999999999767, 21.800000000000043, 85.69999999999949, 20.000000000000014, 37.10000000000019, 18.800000000000022, 100.69999999999958, 20.000000000000014, 139.69999999999973, 20.000000000000014, 43.40000000000021, 10.399999999999965, 140.6, -12.6999999999998, 20.900000000000027, 133.3999999999998, 118.99999999999979, 11.599999999999977, 20.000000000000014, 100.99999999999996, 24.50000000000008, 37.10000000000026, -12.399999999999816, 20.000000000000014, 20.000000000000014, 20.000000000000014, 11.599999999999966, 107.29999999999953, 20.000000000000014, 172.99999999999983, -22.89999999999977, 92.89999999999971, 59.600000000000044, 12.499999999999966, 20.000000000000014, 64.10000000000021, 83.89999999999961, 136.39999999999986, 20.000000000000014, 15.799999999999963, 25.10000000000019, 79.69999999999996, 20.000000000000014, -54.400000000000404, 35.90000000000021, 7.399999999999967, 58.400000000000176, 9.499999999999964, -101.50000000000014, 22.700000000000063, 109.39999999999975, 53.300000000000146, 50.60000000000021, -43.900000000000404, 37.10000000000016, 15.799999999999963, 20.000000000000014, -21.999999999999744, -60.40000000000025, 3.1999999999999615, 20.000000000000014, -64.00000000000063, 86.89999999999985, 100.39999999999961, 20.000000000000014, 85.99999999999943, 17.899999999999984, 7.39999999999997, 51.500000000000234, 92.30000000000004, 20.90000000000003, 13.699999999999962, -12.399999999999865, -76.3000000000005, 20.000000000000014, 82.99999999999987, 120.79999999999961, -32.49999999999975, 30.799999999999997, 87.49999999999946, -7.299999999999926, -42.999999999999766, -3.099999999999958, 107.59999999999951, 24.500000000000046, 20.000000000000014, 77.59999999999958, -14.799999999999807, -26.199999999999775, 84.49999999999974, 20.000000000000014, -31.59999999999981, 50.600000000000236, 40.70000000000013, -24.099999999999753, 40.70000000000021, -64.00000000000075, 51.49999999999997, 20.000000000000014, 99.19999999999939, 20.000000000000014, 31.700000000000212, 20.000000000000014, 108.49999999999989, 39.20000000000009, 88.69999999999987, 96.79999999999984, 27.20000000000014, 20.000000000000014, 115.39999999999961, 20.000000000000014, 41.300000000000146, -26.49999999999978, 56.90000000000022, 20.000000000000014, 20.000000000000014, -114.40000000000074, 20.90000000000003, 63.20000000000008, 92.59999999999971, 89.8999999999995, 172.09999999999982, 56.00000000000017, 76.10000000000014, 20.000000000000014, 20.000000000000014, 30.800000000000196, -33.699999999999775, 27.20000000000014, 60.20000000000016, 20.000000000000014, 15.799999999999963, 61.70000000000012, 1.09999999999996, 20.90000000000003, -6.39999999999994, 20.90000000000003, 24.500000000000096, -21.9999999999998, 7.6999999999999815, 57.800000000000175, 111.79999999999944, 52.40000000000019, 21.800000000000047, 143.29999999999976, 64.10000000000018, 5.299999999999965, 20.000000000000014, 20.000000000000014, 20.000000000000014, 25.400000000000098, 31.40000000000005, 20.000000000000014, -0.9999999999999473, 3.499999999999999], "policy_predator_policy_reward": [0.0, 17.0, 0.0, 0.0, 11.0, 0.0, 53.0, 0.0, 10.0, 0.0, 0.0, 5.0, 0.0, 0.0, 32.0, 31.0, 12.0, 9.0, 1.0, 0.0, 17.0, 0.0, 23.0, 0.0, 10.0, 1.0, 0.0, 1.0, 29.0, 0.0, 0.0, 0.0, 5.0, 0.0, 1.0, 0.0, 0.0, 14.0, 12.0, 15.0, 0.0, 0.0, 0.0, 10.0, 20.0, 5.0, 6.0, 0.0, 6.0, 6.0, 8.0, 18.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 16.0, 15.0, 2.0, 0.0, 19.0, 0.0, 6.0, 14.0, 8.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 26.0, 1.0, 22.0, 16.0, 0.0, 4.0, 0.0, 0.0, 0.0, 8.0, 13.0, 2.0, 8.0, 0.0, 36.0, 29.0, 16.0, 0.0, 52.0, 39.0, 5.0, 13.0, 0.0, 0.0, 49.0, 28.0, 2.0, 0.0, 8.0, 50.0, 0.0, 8.0, 2.0, 40.0, 0.0, 2.0, 8.0, 1.0, 0.0, 6.0, 5.0, 8.0, 25.0, 22.0, 44.0, 13.0, 15.0, 10.0, 20.0, 7.0, 13.0, 0.0, 11.0, 24.0, 4.0, 22.0, 0.0, 0.0, 32.0, 0.0, 19.0, 0.0, 0.0, 31.0, 20.0, 1.0, 9.0, 40.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 31.0, 0.0, 20.0, 13.0, 9.0, 0.0, 0.0, 0.0, 13.0, 20.0, 0.0, 0.0, 3.0, 61.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 11.0, 0.0, 12.0, 0.0, 4.0, 25.0, 9.0, 6.0, 16.0, 0.0, 15.0, 0.0, 19.0, 0.0, 20.0, 0.0, 0.0, 17.0, 0.0, 0.0, 0.0, 0.0, 2.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 31.0, 0.0, 29.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.384653375210164, "mean_inference_ms": 68.0014273555202, "mean_action_processing_ms": 14.816103862332307, "mean_env_wait_ms": 26.21300043081077, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.008038520812988281, "StateBufferConnector_ms": 0.0205230712890625, "ViewRequirementAgentConnector_ms": 0.2366088628768921}, "num_episodes": 18, "episode_return_max": 269.40000000000094, "episode_return_min": -30.39999999999955, "episode_return_mean": 83.52099999999975, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 320000, "num_agent_steps_trained": 320000, "num_env_steps_sampled": 80000, "num_env_steps_trained": 80000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 4.227453662443121, "num_env_steps_trained_throughput_per_sec": 4.227453662443121, "timesteps_total": 80000, "num_env_steps_sampled_lifetime": 80000, "num_agent_steps_sampled_lifetime": 320000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 320000, "timers": {"training_iteration_time_ms": 212339.597, "restore_workers_time_ms": 0.024, "training_step_time_ms": 212339.521, "sample_time_ms": 3315.867, "learn_time_ms": 208970.834, "learn_throughput": 19.141, "synch_weights_time_ms": 43.203}, "counters": {"num_env_steps_sampled": 80000, "num_env_steps_trained": 80000, "num_agent_steps_sampled": 320000, "num_agent_steps_trained": 320000}, "done": false, "training_iteration": 20, "trial_id": "75ec3_00000", "date": "2024-08-13_02-13-19", "timestamp": 1723529599, "time_this_iter_s": 946.3521869182587, "time_total_s": 3256.54594039917, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b19b2790>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3256.54594039917, "iterations_since_restore": 20, "perf": {"cpu_util_percent": 88.77368421052631, "ram_util_percent": 83.52368421052631}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3830453990391953, "cur_kl_coeff": 0.084375, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.318812459864945, "policy_loss": -0.003821522392155159, "vf_loss": 5.32172918761218, "vf_explained_var": 0.07170778478264178, "kl": 0.010723219132624934, "entropy": 1.418225945240606, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 38745.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.32282089531106295, "cur_kl_coeff": 0.0125, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.7308541015973167, "policy_loss": -0.0012449566809529507, "vf_loss": 1.7320502101744293, "vf_explained_var": 0.0018230214636161845, "kl": 0.0039082195592835545, "entropy": 1.4796709521737679, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 38745.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 84000, "num_env_steps_trained": 84000, "num_agent_steps_sampled": 336000, "num_agent_steps_trained": 336000}, "env_runners": {"episode_reward_max": 269.40000000000094, "episode_reward_min": -30.39999999999955, "episode_reward_mean": 86.49399999999977, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -123.10000000000034, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 180.19999999999996, "predator_policy": 87.0}, "policy_reward_mean": {"prey_policy": 33.73699999999998, "predator_policy": 9.51}, "custom_metrics": {}, "hist_stats": {"episode_reward": [54.30000000000047, 19.30000000000003, 42.700000000000344, 36.20000000000012, 22.400000000000027, 113.49999999999889, 69.10000000000004, 145.49999999999883, 159.6999999999991, 63.400000000000446, 155.99999999999957, 24.20000000000004, 269.40000000000094, 50.60000000000038, 131.49999999999966, 46.700000000000415, 40.0000000000003, 35.600000000000236, 127.29999999999889, 177.0999999999993, 190.49999999999972, 36.500000000000234, 147.99999999999875, 164.3999999999993, 55.90000000000017, 107.69999999999956, 46.50000000000006, 81.79999999999922, -0.9999999999997664, 150.09999999999914, 103.89999999999893, 70.20000000000006, 37.80000000000027, -24.400000000000446, 31.200000000000166, 64.90000000000008, 122.39999999999903, 112.89999999999876, 64.90000000000042, 126.19999999999973, 48.300000000000175, 0.7000000000002395, 228.7999999999995, 25.300000000000026, 93.19999999999891, -11.099999999999579, 158.0999999999992, 97.59999999999894, -8.999999999999693, 123.49999999999926, 50.00000000000033, 37.60000000000011, 25.700000000000113, 80.5000000000001, 119.19999999999865, 51.70000000000049, 178.69999999999956, 218.4999999999995, 56.20000000000046, 135.39999999999898, 47.80000000000038, 76.89999999999964, -30.39999999999955, 84.09999999999934, 193.49999999999898, 228.09999999999917, 107.09999999999923, 62.80000000000041, 22.50000000000004, 95.19999999999874, 93.49999999999937, 37.000000000000256, 33.5000000000002, 22.500000000000018, 82.49999999999906, 164.19999999999868, 165.09999999999908, 78.39999999999948, 40.0000000000003, 45.40000000000038, 82.4, 31.500000000000192, 130.39999999999918, 154.59999999999954, 42.80000000000035, 174.99999999999966, 25.300000000000466, 200.19999999999928, 35.600000000000236, 99.1999999999997, 33.400000000000205, 216.39999999999975, 164.69999999999968, 84.09999999999948, 20.50000000000017, 71.00000000000003, -16.099999999999724, 178.59999999999928, 30.100000000000147, 56.20000000000038], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-9.39999999999989, 49.70000000000024, -11.499999999999833, 3.7999999999999994, 20.000000000000014, 22.700000000000056, -0.9999999999999846, 27.200000000000003, 20.000000000000014, -22.599999999999767, 21.800000000000043, 85.69999999999949, 20.000000000000014, 37.10000000000019, 18.800000000000022, 100.69999999999958, 20.000000000000014, 139.69999999999973, 20.000000000000014, 43.40000000000021, 10.399999999999965, 140.6, -12.6999999999998, 20.900000000000027, 133.3999999999998, 118.99999999999979, 11.599999999999977, 20.000000000000014, 100.99999999999996, 24.50000000000008, 37.10000000000026, -12.399999999999816, 20.000000000000014, 20.000000000000014, 20.000000000000014, 11.599999999999966, 107.29999999999953, 20.000000000000014, 172.99999999999983, -22.89999999999977, 92.89999999999971, 59.600000000000044, 12.499999999999966, 20.000000000000014, 64.10000000000021, 83.89999999999961, 136.39999999999986, 20.000000000000014, 15.799999999999963, 25.10000000000019, 79.69999999999996, 20.000000000000014, -54.400000000000404, 35.90000000000021, 7.399999999999967, 58.400000000000176, 9.499999999999964, -101.50000000000014, 22.700000000000063, 109.39999999999975, 53.300000000000146, 50.60000000000021, -43.900000000000404, 37.10000000000016, 15.799999999999963, 20.000000000000014, -21.999999999999744, -60.40000000000025, 3.1999999999999615, 20.000000000000014, -64.00000000000063, 86.89999999999985, 100.39999999999961, 20.000000000000014, 85.99999999999943, 17.899999999999984, 7.39999999999997, 51.500000000000234, 92.30000000000004, 20.90000000000003, 13.699999999999962, -12.399999999999865, -76.3000000000005, 20.000000000000014, 82.99999999999987, 120.79999999999961, -32.49999999999975, 30.799999999999997, 87.49999999999946, -7.299999999999926, -42.999999999999766, -3.099999999999958, 107.59999999999951, 24.500000000000046, 20.000000000000014, 77.59999999999958, -14.799999999999807, -26.199999999999775, 84.49999999999974, 20.000000000000014, -31.59999999999981, 50.600000000000236, 40.70000000000013, -24.099999999999753, 40.70000000000021, -64.00000000000075, 51.49999999999997, 20.000000000000014, 99.19999999999939, 20.000000000000014, 31.700000000000212, 20.000000000000014, 108.49999999999989, 39.20000000000009, 88.69999999999987, 96.79999999999984, 27.20000000000014, 20.000000000000014, 115.39999999999961, 20.000000000000014, 41.300000000000146, -26.49999999999978, 56.90000000000022, 20.000000000000014, 20.000000000000014, -114.40000000000074, 20.90000000000003, 63.20000000000008, 92.59999999999971, 89.8999999999995, 172.09999999999982, 56.00000000000017, 76.10000000000014, 20.000000000000014, 20.000000000000014, 30.800000000000196, -33.699999999999775, 27.20000000000014, 60.20000000000016, 20.000000000000014, 15.799999999999963, 61.70000000000012, 1.09999999999996, 20.90000000000003, -6.39999999999994, 20.90000000000003, 24.500000000000096, -21.9999999999998, 7.6999999999999815, 57.800000000000175, 111.79999999999944, 52.40000000000019, 21.800000000000047, 143.29999999999976, 64.10000000000018, 5.299999999999965, 20.000000000000014, 20.000000000000014, 20.000000000000014, 25.400000000000098, 31.40000000000005, 20.000000000000014, -0.9999999999999473, 3.499999999999999, 109.09999999999967, -0.6999999999999207, -49.59999999999988, 129.2, -21.99999999999978, 42.80000000000019, 36.19999999999999, 138.79999999999998, -36.69999999999999, 29.000000000000163, 20.000000000000014, 180.19999999999996, 11.599999999999968, 20.000000000000014, -49.299999999999905, 99.49999999999994, 7.39999999999997, 20.000000000000014, 71.30000000000013, 145.10000000000008, 88.99999999999977, 55.69999999999997, 64.10000000000011, 20.000000000000014, -16.59999999999996, -19.89999999999975, 20.000000000000014, 44.00000000000005, -123.10000000000034, 20.000000000000014, 158.60000000000002, 20.000000000000014, 20.000000000000014, 1.0999999999999865, 20.000000000000014, 36.200000000000095], "policy_predator_policy_reward": [0.0, 14.0, 12.0, 15.0, 0.0, 0.0, 0.0, 10.0, 20.0, 5.0, 6.0, 0.0, 6.0, 6.0, 8.0, 18.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 16.0, 15.0, 2.0, 0.0, 19.0, 0.0, 6.0, 14.0, 8.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 26.0, 1.0, 22.0, 16.0, 0.0, 4.0, 0.0, 0.0, 0.0, 8.0, 13.0, 2.0, 8.0, 0.0, 36.0, 29.0, 16.0, 0.0, 52.0, 39.0, 5.0, 13.0, 0.0, 0.0, 49.0, 28.0, 2.0, 0.0, 8.0, 50.0, 0.0, 8.0, 2.0, 40.0, 0.0, 2.0, 8.0, 1.0, 0.0, 6.0, 5.0, 8.0, 25.0, 22.0, 44.0, 13.0, 15.0, 10.0, 20.0, 7.0, 13.0, 0.0, 11.0, 24.0, 4.0, 22.0, 0.0, 0.0, 32.0, 0.0, 19.0, 0.0, 0.0, 31.0, 20.0, 1.0, 9.0, 40.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 31.0, 0.0, 20.0, 13.0, 9.0, 0.0, 0.0, 0.0, 13.0, 20.0, 0.0, 0.0, 3.0, 61.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 11.0, 0.0, 12.0, 0.0, 4.0, 25.0, 9.0, 6.0, 16.0, 0.0, 15.0, 0.0, 19.0, 0.0, 20.0, 0.0, 0.0, 17.0, 0.0, 0.0, 0.0, 0.0, 2.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 31.0, 0.0, 29.0, 12.0, 10.0, 23.0, 52.0, 2.0, 20.0, 0.0, 0.0, 30.0, 3.0, 0.0, 0.0, 0.0, 4.0, 49.0, 0.0, 6.0, 0.0, 0.0, 0.0, 20.0, 0.0, 0.0, 0.0, 10.0, 47.0, 7.0, 0.0, 0.0, 87.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 13.769756270365356, "mean_inference_ms": 64.91950969794851, "mean_action_processing_ms": 14.110133899129599, "mean_env_wait_ms": 24.97437699680089, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.008566856384277344, "StateBufferConnector_ms": 0.020552873611450195, "ViewRequirementAgentConnector_ms": 0.26016902923583984}, "num_episodes": 18, "episode_return_max": 269.40000000000094, "episode_return_min": -30.39999999999955, "episode_return_mean": 86.49399999999977, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 336000, "num_agent_steps_trained": 336000, "num_env_steps_sampled": 84000, "num_env_steps_trained": 84000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 222.92080856509796, "num_env_steps_trained_throughput_per_sec": 222.92080856509796, "timesteps_total": 84000, "num_env_steps_sampled_lifetime": 84000, "num_agent_steps_sampled_lifetime": 336000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 336000, "timers": {"training_iteration_time_ms": 211960.408, "restore_workers_time_ms": 0.045, "training_step_time_ms": 211960.307, "sample_time_ms": 3525.817, "learn_time_ms": 208388.444, "learn_throughput": 19.195, "synch_weights_time_ms": 36.145}, "counters": {"num_env_steps_sampled": 84000, "num_env_steps_trained": 84000, "num_agent_steps_sampled": 336000, "num_agent_steps_trained": 336000}, "done": false, "training_iteration": 21, "trial_id": "75ec3_00000", "date": "2024-08-13_02-13-37", "timestamp": 1723529617, "time_this_iter_s": 18.04067897796631, "time_total_s": 3274.5866193771362, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2071dc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3274.5866193771362, "iterations_since_restore": 21, "perf": {"cpu_util_percent": 89.65384615384616, "ram_util_percent": 83.7076923076923}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6890588462352754, "cur_kl_coeff": 0.084375, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.0581394215740225, "policy_loss": -0.0014434330182632915, "vf_loss": 3.05898226354488, "vf_explained_var": 0.11558573788436001, "kl": 0.007118081840669823, "entropy": 1.4425739740568495, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 40635.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.3435392514738456, "cur_kl_coeff": 0.00625, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.743176254157036, "policy_loss": -0.0009849917813741342, "vf_loss": 0.7441529250570706, "vf_explained_var": 0.01119761309295735, "kl": 0.0013317728358989568, "entropy": 1.4775158181392327, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 40635.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 88000, "num_env_steps_trained": 88000, "num_agent_steps_sampled": 352000, "num_agent_steps_trained": 352000}, "env_runners": {"episode_reward_max": 236.39999999999912, "episode_reward_min": -30.39999999999955, "episode_reward_mean": 84.98499999999979, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -124.00000000000057, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 180.19999999999996, "predator_policy": 87.0}, "policy_reward_mean": {"prey_policy": 32.442499999999974, "predator_policy": 10.05}, "custom_metrics": {}, "hist_stats": {"episode_reward": [127.29999999999889, 177.0999999999993, 190.49999999999972, 36.500000000000234, 147.99999999999875, 164.3999999999993, 55.90000000000017, 107.69999999999956, 46.50000000000006, 81.79999999999922, -0.9999999999997664, 150.09999999999914, 103.89999999999893, 70.20000000000006, 37.80000000000027, -24.400000000000446, 31.200000000000166, 64.90000000000008, 122.39999999999903, 112.89999999999876, 64.90000000000042, 126.19999999999973, 48.300000000000175, 0.7000000000002395, 228.7999999999995, 25.300000000000026, 93.19999999999891, -11.099999999999579, 158.0999999999992, 97.59999999999894, -8.999999999999693, 123.49999999999926, 50.00000000000033, 37.60000000000011, 25.700000000000113, 80.5000000000001, 119.19999999999865, 51.70000000000049, 178.69999999999956, 218.4999999999995, 56.20000000000046, 135.39999999999898, 47.80000000000038, 76.89999999999964, -30.39999999999955, 84.09999999999934, 193.49999999999898, 228.09999999999917, 107.09999999999923, 62.80000000000041, 22.50000000000004, 95.19999999999874, 93.49999999999937, 37.000000000000256, 33.5000000000002, 22.500000000000018, 82.49999999999906, 164.19999999999868, 165.09999999999908, 78.39999999999948, 40.0000000000003, 45.40000000000038, 82.4, 31.500000000000192, 130.39999999999918, 154.59999999999954, 42.80000000000035, 174.99999999999966, 25.300000000000466, 200.19999999999928, 35.600000000000236, 99.1999999999997, 33.400000000000205, 216.39999999999975, 164.69999999999968, 84.09999999999948, 20.50000000000017, 71.00000000000003, -16.099999999999724, 178.59999999999928, 30.100000000000147, 56.20000000000038, 43.20000000000005, 41.70000000000033, 111.09999999999997, 47.20000000000038, 141.6999999999994, 75.69999999999955, 87.3, 63.700000000000486, 236.39999999999912, 58.900000000000325, 39.600000000000264, 57.20000000000036, 8.90000000000015, 66.10000000000011, -27.999999999999638, 44.60000000000038, 193.89999999999935, 40.0000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [107.29999999999953, 20.000000000000014, 172.99999999999983, -22.89999999999977, 92.89999999999971, 59.600000000000044, 12.499999999999966, 20.000000000000014, 64.10000000000021, 83.89999999999961, 136.39999999999986, 20.000000000000014, 15.799999999999963, 25.10000000000019, 79.69999999999996, 20.000000000000014, -54.400000000000404, 35.90000000000021, 7.399999999999967, 58.400000000000176, 9.499999999999964, -101.50000000000014, 22.700000000000063, 109.39999999999975, 53.300000000000146, 50.60000000000021, -43.900000000000404, 37.10000000000016, 15.799999999999963, 20.000000000000014, -21.999999999999744, -60.40000000000025, 3.1999999999999615, 20.000000000000014, -64.00000000000063, 86.89999999999985, 100.39999999999961, 20.000000000000014, 85.99999999999943, 17.899999999999984, 7.39999999999997, 51.500000000000234, 92.30000000000004, 20.90000000000003, 13.699999999999962, -12.399999999999865, -76.3000000000005, 20.000000000000014, 82.99999999999987, 120.79999999999961, -32.49999999999975, 30.799999999999997, 87.49999999999946, -7.299999999999926, -42.999999999999766, -3.099999999999958, 107.59999999999951, 24.500000000000046, 20.000000000000014, 77.59999999999958, -14.799999999999807, -26.199999999999775, 84.49999999999974, 20.000000000000014, -31.59999999999981, 50.600000000000236, 40.70000000000013, -24.099999999999753, 40.70000000000021, -64.00000000000075, 51.49999999999997, 20.000000000000014, 99.19999999999939, 20.000000000000014, 31.700000000000212, 20.000000000000014, 108.49999999999989, 39.20000000000009, 88.69999999999987, 96.79999999999984, 27.20000000000014, 20.000000000000014, 115.39999999999961, 20.000000000000014, 41.300000000000146, -26.49999999999978, 56.90000000000022, 20.000000000000014, 20.000000000000014, -114.40000000000074, 20.90000000000003, 63.20000000000008, 92.59999999999971, 89.8999999999995, 172.09999999999982, 56.00000000000017, 76.10000000000014, 20.000000000000014, 20.000000000000014, 30.800000000000196, -33.699999999999775, 27.20000000000014, 60.20000000000016, 20.000000000000014, 15.799999999999963, 61.70000000000012, 1.09999999999996, 20.90000000000003, -6.39999999999994, 20.90000000000003, 24.500000000000096, -21.9999999999998, 7.6999999999999815, 57.800000000000175, 111.79999999999944, 52.40000000000019, 21.800000000000047, 143.29999999999976, 64.10000000000018, 5.299999999999965, 20.000000000000014, 20.000000000000014, 20.000000000000014, 25.400000000000098, 31.40000000000005, 20.000000000000014, -0.9999999999999473, 3.499999999999999, 109.09999999999967, -0.6999999999999207, -49.59999999999988, 129.2, -21.99999999999978, 42.80000000000019, 36.19999999999999, 138.79999999999998, -36.69999999999999, 29.000000000000163, 20.000000000000014, 180.19999999999996, 11.599999999999968, 20.000000000000014, -49.299999999999905, 99.49999999999994, 7.39999999999997, 20.000000000000014, 71.30000000000013, 145.10000000000008, 88.99999999999977, 55.69999999999997, 64.10000000000011, 20.000000000000014, -16.59999999999996, -19.89999999999975, 20.000000000000014, 44.00000000000005, -123.10000000000034, 20.000000000000014, 158.60000000000002, 20.000000000000014, 20.000000000000014, 1.0999999999999865, 20.000000000000014, 36.200000000000095, -97.60000000000062, 66.80000000000003, 9.499999999999973, 27.200000000000138, 66.79999999999988, 44.300000000000026, 22.700000000000063, 24.50000000000009, 121.69999999999997, 20.000000000000014, 20.900000000000045, 30.800000000000196, 65.3, 20.000000000000014, 20.90000000000003, 39.80000000000024, 101.29999999999973, 118.09999999999948, 38.90000000000011, 20.000000000000014, 17.59999999999999, 20.000000000000014, 23.60000000000003, 20.599999999999973, -24.10000000000003, -49.00000000000022, 20.000000000000014, 37.09999999999997, 20.000000000000014, -124.00000000000057, 25.700000000000117, 8.89999999999997, 100.99999999999957, 92.89999999999998, 20.000000000000014, 20.000000000000014], "policy_predator_policy_reward": [0.0, 0.0, 26.0, 1.0, 22.0, 16.0, 0.0, 4.0, 0.0, 0.0, 0.0, 8.0, 13.0, 2.0, 8.0, 0.0, 36.0, 29.0, 16.0, 0.0, 52.0, 39.0, 5.0, 13.0, 0.0, 0.0, 49.0, 28.0, 2.0, 0.0, 8.0, 50.0, 0.0, 8.0, 2.0, 40.0, 0.0, 2.0, 8.0, 1.0, 0.0, 6.0, 5.0, 8.0, 25.0, 22.0, 44.0, 13.0, 15.0, 10.0, 20.0, 7.0, 13.0, 0.0, 11.0, 24.0, 4.0, 22.0, 0.0, 0.0, 32.0, 0.0, 19.0, 0.0, 0.0, 31.0, 20.0, 1.0, 9.0, 40.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 31.0, 0.0, 20.0, 13.0, 9.0, 0.0, 0.0, 0.0, 13.0, 20.0, 0.0, 0.0, 3.0, 61.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 11.0, 0.0, 12.0, 0.0, 4.0, 25.0, 9.0, 6.0, 16.0, 0.0, 15.0, 0.0, 19.0, 0.0, 20.0, 0.0, 0.0, 17.0, 0.0, 0.0, 0.0, 0.0, 2.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 31.0, 0.0, 29.0, 12.0, 10.0, 23.0, 52.0, 2.0, 20.0, 0.0, 0.0, 30.0, 3.0, 0.0, 0.0, 0.0, 4.0, 49.0, 0.0, 6.0, 0.0, 0.0, 0.0, 20.0, 0.0, 0.0, 0.0, 10.0, 47.0, 7.0, 0.0, 0.0, 87.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 27.0, 47.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.0, 0.0, 2.0, 0.0, 3.0, 0.0, 4.0, 13.0, 0.0, 0.0, 2.0, 0.0, 13.0, 0.0, 59.0, 23.0, 0.0, 9.0, 58.0, 18.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 13.219696574748665, "mean_inference_ms": 62.160681186152495, "mean_action_processing_ms": 13.477848556138392, "mean_env_wait_ms": 23.863990005959277, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.008033990859985352, "StateBufferConnector_ms": 0.019458651542663574, "ViewRequirementAgentConnector_ms": 0.27302682399749756}, "num_episodes": 18, "episode_return_max": 236.39999999999912, "episode_return_min": -30.39999999999955, "episode_return_mean": 84.98499999999979, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 352000, "num_agent_steps_trained": 352000, "num_env_steps_sampled": 88000, "num_env_steps_trained": 88000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 253.69994229409994, "num_env_steps_trained_throughput_per_sec": 253.69994229409994, "timesteps_total": 88000, "num_env_steps_sampled_lifetime": 88000, "num_agent_steps_sampled_lifetime": 352000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 352000, "timers": {"training_iteration_time_ms": 211533.873, "restore_workers_time_ms": 0.047, "training_step_time_ms": 211533.769, "sample_time_ms": 3646.695, "learn_time_ms": 207841.868, "learn_throughput": 19.245, "synch_weights_time_ms": 36.284}, "counters": {"num_env_steps_sampled": 88000, "num_env_steps_trained": 88000, "num_agent_steps_sampled": 352000, "num_agent_steps_trained": 352000}, "done": false, "training_iteration": 22, "trial_id": "75ec3_00000", "date": "2024-08-13_02-13-53", "timestamp": 1723529633, "time_this_iter_s": 15.841286897659302, "time_total_s": 3290.4279062747955, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2071280>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3290.4279062747955, "iterations_since_restore": 22, "perf": {"cpu_util_percent": 86.73636363636365, "ram_util_percent": 83.51363636363637}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5411937942068097, "cur_kl_coeff": 0.084375, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.398890570105699, "policy_loss": -0.0045635055888582155, "vf_loss": 5.401841913455378, "vf_explained_var": 0.05040208262110513, "kl": 0.019107118512332013, "entropy": 1.4260901073299388, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 42525.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.3825609243420697, "cur_kl_coeff": 0.003125, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.026487859090169, "policy_loss": -0.0037398909519194925, "vf_loss": 2.0301725794713965, "vf_explained_var": 0.0016940180586759376, "kl": 0.01765510591543684, "entropy": 1.3739834908455137, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 42525.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 92000, "num_env_steps_trained": 92000, "num_agent_steps_sampled": 368000, "num_agent_steps_trained": 368000}, "env_runners": {"episode_reward_max": 296.4999999999999, "episode_reward_min": -75.7000000000007, "episode_reward_mean": 85.44399999999979, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -221.39999999999998, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 184.0}, "policy_reward_mean": {"prey_policy": 31.66199999999997, "predator_policy": 11.06}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-11.099999999999579, 158.0999999999992, 97.59999999999894, -8.999999999999693, 123.49999999999926, 50.00000000000033, 37.60000000000011, 25.700000000000113, 80.5000000000001, 119.19999999999865, 51.70000000000049, 178.69999999999956, 218.4999999999995, 56.20000000000046, 135.39999999999898, 47.80000000000038, 76.89999999999964, -30.39999999999955, 84.09999999999934, 193.49999999999898, 228.09999999999917, 107.09999999999923, 62.80000000000041, 22.50000000000004, 95.19999999999874, 93.49999999999937, 37.000000000000256, 33.5000000000002, 22.500000000000018, 82.49999999999906, 164.19999999999868, 165.09999999999908, 78.39999999999948, 40.0000000000003, 45.40000000000038, 82.4, 31.500000000000192, 130.39999999999918, 154.59999999999954, 42.80000000000035, 174.99999999999966, 25.300000000000466, 200.19999999999928, 35.600000000000236, 99.1999999999997, 33.400000000000205, 216.39999999999975, 164.69999999999968, 84.09999999999948, 20.50000000000017, 71.00000000000003, -16.099999999999724, 178.59999999999928, 30.100000000000147, 56.20000000000038, 43.20000000000005, 41.70000000000033, 111.09999999999997, 47.20000000000038, 141.6999999999994, 75.69999999999955, 87.3, 63.700000000000486, 236.39999999999912, 58.900000000000325, 39.600000000000264, 57.20000000000036, 8.90000000000015, 66.10000000000011, -27.999999999999638, 44.60000000000038, 193.89999999999935, 40.0000000000003, 115.2999999999989, 44.50000000000029, 138.69999999999882, -5.499999999999858, 296.4999999999999, 231.09999999999917, 81.49999999999925, 11.399999999999949, 144.39999999999964, 106.89999999999924, -75.7000000000007, 158.7999999999992, 30.20000000000015, 174.8999999999995, 76.8000000000001, 132.6999999999987, 65.8000000000003, 48.30000000000039, 113.7999999999997, 52.40000000000049, 76.09999999999954, 30.100000000000165, 67.40000000000013, 10.500000000000357, 152.69999999999933, 42.700000000000294, 114.69999999999959], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-42.999999999999766, -3.099999999999958, 107.59999999999951, 24.500000000000046, 20.000000000000014, 77.59999999999958, -14.799999999999807, -26.199999999999775, 84.49999999999974, 20.000000000000014, -31.59999999999981, 50.600000000000236, 40.70000000000013, -24.099999999999753, 40.70000000000021, -64.00000000000075, 51.49999999999997, 20.000000000000014, 99.19999999999939, 20.000000000000014, 31.700000000000212, 20.000000000000014, 108.49999999999989, 39.20000000000009, 88.69999999999987, 96.79999999999984, 27.20000000000014, 20.000000000000014, 115.39999999999961, 20.000000000000014, 41.300000000000146, -26.49999999999978, 56.90000000000022, 20.000000000000014, 20.000000000000014, -114.40000000000074, 20.90000000000003, 63.20000000000008, 92.59999999999971, 89.8999999999995, 172.09999999999982, 56.00000000000017, 76.10000000000014, 20.000000000000014, 20.000000000000014, 30.800000000000196, -33.699999999999775, 27.20000000000014, 60.20000000000016, 20.000000000000014, 15.799999999999963, 61.70000000000012, 1.09999999999996, 20.90000000000003, -6.39999999999994, 20.90000000000003, 24.500000000000096, -21.9999999999998, 7.6999999999999815, 57.800000000000175, 111.79999999999944, 52.40000000000019, 21.800000000000047, 143.29999999999976, 64.10000000000018, 5.299999999999965, 20.000000000000014, 20.000000000000014, 20.000000000000014, 25.400000000000098, 31.40000000000005, 20.000000000000014, -0.9999999999999473, 3.499999999999999, 109.09999999999967, -0.6999999999999207, -49.59999999999988, 129.2, -21.99999999999978, 42.80000000000019, 36.19999999999999, 138.79999999999998, -36.69999999999999, 29.000000000000163, 20.000000000000014, 180.19999999999996, 11.599999999999968, 20.000000000000014, -49.299999999999905, 99.49999999999994, 7.39999999999997, 20.000000000000014, 71.30000000000013, 145.10000000000008, 88.99999999999977, 55.69999999999997, 64.10000000000011, 20.000000000000014, -16.59999999999996, -19.89999999999975, 20.000000000000014, 44.00000000000005, -123.10000000000034, 20.000000000000014, 158.60000000000002, 20.000000000000014, 20.000000000000014, 1.0999999999999865, 20.000000000000014, 36.200000000000095, -97.60000000000062, 66.80000000000003, 9.499999999999973, 27.200000000000138, 66.79999999999988, 44.300000000000026, 22.700000000000063, 24.50000000000009, 121.69999999999997, 20.000000000000014, 20.900000000000045, 30.800000000000196, 65.3, 20.000000000000014, 20.90000000000003, 39.80000000000024, 101.29999999999973, 118.09999999999948, 38.90000000000011, 20.000000000000014, 17.59999999999999, 20.000000000000014, 23.60000000000003, 20.599999999999973, -24.10000000000003, -49.00000000000022, 20.000000000000014, 37.09999999999997, 20.000000000000014, -124.00000000000057, 25.700000000000117, 8.89999999999997, 100.99999999999957, 92.89999999999998, 20.000000000000014, 20.000000000000014, 75.79999999999956, 24.50000000000008, 24.500000000000007, 20.000000000000014, 9.499999999999988, 123.19999999999953, -68.50000000000065, 20.000000000000014, 96.49999999999994, 200.0, 60.500000000000185, 167.59999999999985, -11.499999999999819, 70.99999999999963, -5.19999999999999, -21.399999999999793, 87.5, 56.89999999999998, 20.000000000000014, 83.89999999999964, -151.30000000000047, -221.39999999999998, 20.000000000000014, 138.79999999999978, 24.500000000000096, -7.299999999999898, 183.8, -40.8999999999998, -3.1000000000000294, 11.899999999999938, 112.69999999999945, 20.000000000000014, -68.2000000000008, 91.99999999999997, 37.100000000000236, 3.1999999999999615, 20.000000000000014, 93.79999999999987, 20.000000000000014, 22.40000000000007, -37.599999999999966, -7.299999999999898, 5.299999999999976, 15.799999999999962, 41.60000000000016, 15.799999999999963, 32.29999999999999, -59.80000000000048, 145.39999999999986, -15.699999999999754, 20.000000000000014, 22.70000000000001, -85.49999999999986, 123.1999999999999], "policy_predator_policy_reward": [11.0, 24.0, 4.0, 22.0, 0.0, 0.0, 32.0, 0.0, 19.0, 0.0, 0.0, 31.0, 20.0, 1.0, 9.0, 40.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 31.0, 0.0, 20.0, 13.0, 9.0, 0.0, 0.0, 0.0, 13.0, 20.0, 0.0, 0.0, 3.0, 61.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 11.0, 0.0, 12.0, 0.0, 4.0, 25.0, 9.0, 6.0, 16.0, 0.0, 15.0, 0.0, 19.0, 0.0, 20.0, 0.0, 0.0, 17.0, 0.0, 0.0, 0.0, 0.0, 2.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 31.0, 0.0, 29.0, 12.0, 10.0, 23.0, 52.0, 2.0, 20.0, 0.0, 0.0, 30.0, 3.0, 0.0, 0.0, 0.0, 4.0, 49.0, 0.0, 6.0, 0.0, 0.0, 0.0, 20.0, 0.0, 0.0, 0.0, 10.0, 47.0, 7.0, 0.0, 0.0, 87.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 27.0, 47.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.0, 0.0, 2.0, 0.0, 3.0, 0.0, 4.0, 13.0, 0.0, 0.0, 2.0, 0.0, 13.0, 0.0, 59.0, 23.0, 0.0, 9.0, 58.0, 18.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 15.0, 0.0, 0.0, 0.0, 6.0, 43.0, 0.0, 0.0, 0.0, 3.0, 0.0, 7.0, 15.0, 29.0, 9.0, 0.0, 0.0, 3.0, 0.0, 113.0, 184.0, 0.0, 0.0, 0.0, 13.0, 3.0, 29.0, 35.0, 33.0, 0.0, 0.0, 42.0, 0.0, 8.0, 0.0, 0.0, 0.0, 10.0, 0.0, 79.0, 42.0, 0.0, 9.0, 10.0, 0.0, 38.0, 0.0, 22.0, 1.0, 0.0, 0.0, 60.0, 17.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 13.639241863882443, "mean_inference_ms": 59.712983032425626, "mean_action_processing_ms": 12.654099074626734, "mean_env_wait_ms": 20.159128000152847, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.012243866920471191, "StateBufferConnector_ms": 0.00559687614440918, "ViewRequirementAgentConnector_ms": 0.2913099527359009}, "num_episodes": 27, "episode_return_max": 296.4999999999999, "episode_return_min": -75.7000000000007, "episode_return_mean": 85.44399999999979, "episodes_this_iter": 27}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 368000, "num_agent_steps_trained": 368000, "num_env_steps_sampled": 92000, "num_env_steps_trained": 92000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 231.9075686968429, "num_env_steps_trained_throughput_per_sec": 231.9075686968429, "timesteps_total": 92000, "num_env_steps_sampled_lifetime": 92000, "num_agent_steps_sampled_lifetime": 368000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 368000, "timers": {"training_iteration_time_ms": 210676.59, "restore_workers_time_ms": 0.047, "training_step_time_ms": 210676.486, "sample_time_ms": 3412.489, "learn_time_ms": 207219.426, "learn_throughput": 19.303, "synch_weights_time_ms": 35.656}, "counters": {"num_env_steps_sampled": 92000, "num_env_steps_trained": 92000, "num_agent_steps_sampled": 368000, "num_agent_steps_trained": 368000}, "done": false, "training_iteration": 23, "trial_id": "75ec3_00000", "date": "2024-08-13_02-14-10", "timestamp": 1723529650, "time_this_iter_s": 17.32529377937317, "time_total_s": 3307.7532000541687, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b1be0f70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3307.7532000541687, "iterations_since_restore": 23, "perf": {"cpu_util_percent": 90.176, "ram_util_percent": 83.62799999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7241432395246294, "cur_kl_coeff": 0.084375, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.3533724928659105, "policy_loss": -0.007259536535779714, "vf_loss": 3.359077294793709, "vf_explained_var": 0.12104743208203997, "kl": 0.01842655806058678, "entropy": 1.4497928482514841, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 44415.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.3147230336137077, "cur_kl_coeff": 0.003125, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.3435958198690541, "policy_loss": -0.003939541404150308, "vf_loss": 0.347514466354722, "vf_explained_var": 0.020768811715343012, "kl": 0.0066862364248519495, "entropy": 1.338277815700208, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 44415.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 96000, "num_env_steps_trained": 96000, "num_agent_steps_sampled": 384000, "num_agent_steps_trained": 384000}, "env_runners": {"episode_reward_max": 296.4999999999999, "episode_reward_min": -75.7000000000007, "episode_reward_mean": 84.44999999999978, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -221.39999999999998, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 184.0}, "policy_reward_mean": {"prey_policy": 32.534999999999975, "predator_policy": 9.69}, "custom_metrics": {}, "hist_stats": {"episode_reward": [84.09999999999934, 193.49999999999898, 228.09999999999917, 107.09999999999923, 62.80000000000041, 22.50000000000004, 95.19999999999874, 93.49999999999937, 37.000000000000256, 33.5000000000002, 22.500000000000018, 82.49999999999906, 164.19999999999868, 165.09999999999908, 78.39999999999948, 40.0000000000003, 45.40000000000038, 82.4, 31.500000000000192, 130.39999999999918, 154.59999999999954, 42.80000000000035, 174.99999999999966, 25.300000000000466, 200.19999999999928, 35.600000000000236, 99.1999999999997, 33.400000000000205, 216.39999999999975, 164.69999999999968, 84.09999999999948, 20.50000000000017, 71.00000000000003, -16.099999999999724, 178.59999999999928, 30.100000000000147, 56.20000000000038, 43.20000000000005, 41.70000000000033, 111.09999999999997, 47.20000000000038, 141.6999999999994, 75.69999999999955, 87.3, 63.700000000000486, 236.39999999999912, 58.900000000000325, 39.600000000000264, 57.20000000000036, 8.90000000000015, 66.10000000000011, -27.999999999999638, 44.60000000000038, 193.89999999999935, 40.0000000000003, 115.2999999999989, 44.50000000000029, 138.69999999999882, -5.499999999999858, 296.4999999999999, 231.09999999999917, 81.49999999999925, 11.399999999999949, 144.39999999999964, 106.89999999999924, -75.7000000000007, 158.7999999999992, 30.20000000000015, 174.8999999999995, 76.8000000000001, 132.6999999999987, 65.8000000000003, 48.30000000000039, 113.7999999999997, 52.40000000000049, 76.09999999999954, 30.100000000000165, 67.40000000000013, 10.500000000000357, 152.69999999999933, 42.700000000000294, 114.69999999999959, 133.5999999999987, 84.99999999999957, 37.80000000000027, 99.3999999999985, 87.89999999999904, 64.30000000000027, 80.4999999999993, 46.900000000000226, 43.600000000000364, 35.60000000000023, 54.50000000000006, 29.000000000000128, 61.600000000000264, 100.09999999999876, 110.89999999999995, 66.10000000000026, 101.19999999999901, 69.50000000000045], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.90000000000003, 63.20000000000008, 92.59999999999971, 89.8999999999995, 172.09999999999982, 56.00000000000017, 76.10000000000014, 20.000000000000014, 20.000000000000014, 30.800000000000196, -33.699999999999775, 27.20000000000014, 60.20000000000016, 20.000000000000014, 15.799999999999963, 61.70000000000012, 1.09999999999996, 20.90000000000003, -6.39999999999994, 20.90000000000003, 24.500000000000096, -21.9999999999998, 7.6999999999999815, 57.800000000000175, 111.79999999999944, 52.40000000000019, 21.800000000000047, 143.29999999999976, 64.10000000000018, 5.299999999999965, 20.000000000000014, 20.000000000000014, 20.000000000000014, 25.400000000000098, 31.40000000000005, 20.000000000000014, -0.9999999999999473, 3.499999999999999, 109.09999999999967, -0.6999999999999207, -49.59999999999988, 129.2, -21.99999999999978, 42.80000000000019, 36.19999999999999, 138.79999999999998, -36.69999999999999, 29.000000000000163, 20.000000000000014, 180.19999999999996, 11.599999999999968, 20.000000000000014, -49.299999999999905, 99.49999999999994, 7.39999999999997, 20.000000000000014, 71.30000000000013, 145.10000000000008, 88.99999999999977, 55.69999999999997, 64.10000000000011, 20.000000000000014, -16.59999999999996, -19.89999999999975, 20.000000000000014, 44.00000000000005, -123.10000000000034, 20.000000000000014, 158.60000000000002, 20.000000000000014, 20.000000000000014, 1.0999999999999865, 20.000000000000014, 36.200000000000095, -97.60000000000062, 66.80000000000003, 9.499999999999973, 27.200000000000138, 66.79999999999988, 44.300000000000026, 22.700000000000063, 24.50000000000009, 121.69999999999997, 20.000000000000014, 20.900000000000045, 30.800000000000196, 65.3, 20.000000000000014, 20.90000000000003, 39.80000000000024, 101.29999999999973, 118.09999999999948, 38.90000000000011, 20.000000000000014, 17.59999999999999, 20.000000000000014, 23.60000000000003, 20.599999999999973, -24.10000000000003, -49.00000000000022, 20.000000000000014, 37.09999999999997, 20.000000000000014, -124.00000000000057, 25.700000000000117, 8.89999999999997, 100.99999999999957, 92.89999999999998, 20.000000000000014, 20.000000000000014, 75.79999999999956, 24.50000000000008, 24.500000000000007, 20.000000000000014, 9.499999999999988, 123.19999999999953, -68.50000000000065, 20.000000000000014, 96.49999999999994, 200.0, 60.500000000000185, 167.59999999999985, -11.499999999999819, 70.99999999999963, -5.19999999999999, -21.399999999999793, 87.5, 56.89999999999998, 20.000000000000014, 83.89999999999964, -151.30000000000047, -221.39999999999998, 20.000000000000014, 138.79999999999978, 24.500000000000096, -7.299999999999898, 183.8, -40.8999999999998, -3.1000000000000294, 11.899999999999938, 112.69999999999945, 20.000000000000014, -68.2000000000008, 91.99999999999997, 37.100000000000236, 3.1999999999999615, 20.000000000000014, 93.79999999999987, 20.000000000000014, 22.40000000000007, -37.599999999999966, -7.299999999999898, 5.299999999999976, 15.799999999999962, 41.60000000000016, 15.799999999999963, 32.29999999999999, -59.80000000000048, 145.39999999999986, -15.699999999999754, 20.000000000000014, 22.70000000000001, -85.49999999999986, 123.1999999999999, 91.99999999999932, 41.60000000000015, 64.99999999999996, 20.000000000000014, 15.799999999999962, 20.000000000000014, 20.900000000000027, 78.49999999999935, 3.1999999999999615, 76.6999999999995, 37.10000000000011, 27.20000000000008, 20.000000000000014, 60.50000000000022, 36.800000000000175, -22.899999999999785, 20.000000000000014, 23.600000000000076, 11.599999999999975, 20.000000000000014, 21.500000000000135, 20.000000000000014, -0.9999999999999846, 20.000000000000014, 41.59999999999998, 20.000000000000014, 88.3999999999994, 1.6999999999999604, 49.39999999999981, 24.500000000000064, 20.000000000000014, 46.1000000000002, 71.29999999999993, 29.9, 25.999999999999975, 42.50000000000025], "policy_predator_policy_reward": [0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 11.0, 0.0, 12.0, 0.0, 4.0, 25.0, 9.0, 6.0, 16.0, 0.0, 15.0, 0.0, 19.0, 0.0, 20.0, 0.0, 0.0, 17.0, 0.0, 0.0, 0.0, 0.0, 2.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 31.0, 0.0, 29.0, 12.0, 10.0, 23.0, 52.0, 2.0, 20.0, 0.0, 0.0, 30.0, 3.0, 0.0, 0.0, 0.0, 4.0, 49.0, 0.0, 6.0, 0.0, 0.0, 0.0, 20.0, 0.0, 0.0, 0.0, 10.0, 47.0, 7.0, 0.0, 0.0, 87.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 27.0, 47.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.0, 0.0, 2.0, 0.0, 3.0, 0.0, 4.0, 13.0, 0.0, 0.0, 2.0, 0.0, 13.0, 0.0, 59.0, 23.0, 0.0, 9.0, 58.0, 18.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 15.0, 0.0, 0.0, 0.0, 6.0, 43.0, 0.0, 0.0, 0.0, 3.0, 0.0, 7.0, 15.0, 29.0, 9.0, 0.0, 0.0, 3.0, 0.0, 113.0, 184.0, 0.0, 0.0, 0.0, 13.0, 3.0, 29.0, 35.0, 33.0, 0.0, 0.0, 42.0, 0.0, 8.0, 0.0, 0.0, 0.0, 10.0, 0.0, 79.0, 42.0, 0.0, 9.0, 10.0, 0.0, 38.0, 0.0, 22.0, 1.0, 0.0, 0.0, 60.0, 17.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.0, 9.0, 0.0, 0.0, 4.0, 0.0, 13.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 37.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 12.082998074125685, "mean_inference_ms": 56.33598793766468, "mean_action_processing_ms": 12.198356870179289, "mean_env_wait_ms": 21.446828803928614, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.010877132415771484, "StateBufferConnector_ms": 0.00539708137512207, "ViewRequirementAgentConnector_ms": 0.2717607021331787}, "num_episodes": 18, "episode_return_max": 296.4999999999999, "episode_return_min": -75.7000000000007, "episode_return_mean": 84.44999999999978, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 384000, "num_agent_steps_trained": 384000, "num_env_steps_sampled": 96000, "num_env_steps_trained": 96000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 208.87296675796603, "num_env_steps_trained_throughput_per_sec": 208.87296675796603, "timesteps_total": 96000, "num_env_steps_sampled_lifetime": 96000, "num_agent_steps_sampled_lifetime": 384000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 384000, "timers": {"training_iteration_time_ms": 210379.882, "restore_workers_time_ms": 0.047, "training_step_time_ms": 210379.776, "sample_time_ms": 3319.407, "learn_time_ms": 207014.794, "learn_throughput": 19.322, "synch_weights_time_ms": 35.849}, "counters": {"num_env_steps_sampled": 96000, "num_env_steps_trained": 96000, "num_agent_steps_sampled": 384000, "num_agent_steps_trained": 384000}, "done": false, "training_iteration": 24, "trial_id": "75ec3_00000", "date": "2024-08-13_02-14-30", "timestamp": 1723529670, "time_this_iter_s": 19.238885164260864, "time_total_s": 3326.9920852184296, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b1ada0d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3326.9920852184296, "iterations_since_restore": 24, "perf": {"cpu_util_percent": 93.34814814814814, "ram_util_percent": 83.65555555555555}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5743068932698516, "cur_kl_coeff": 0.084375, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.625265686348002, "policy_loss": -0.003435161156597099, "vf_loss": 5.6280963824539585, "vf_explained_var": 0.05370652376028596, "kl": 0.0071641512071344855, "entropy": 1.465556399342875, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 46305.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4643846807735307, "cur_kl_coeff": 0.003125, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.3977866864708997, "policy_loss": -0.0006880578121771573, "vf_loss": 2.398455412804134, "vf_explained_var": 0.014229666776758023, "kl": 0.006187261049469995, "entropy": 1.3402024499323002, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 46305.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 100000, "num_env_steps_trained": 100000, "num_agent_steps_sampled": 400000, "num_agent_steps_trained": 400000}, "env_runners": {"episode_reward_max": 296.4999999999999, "episode_reward_min": -75.7000000000007, "episode_reward_mean": 88.7219999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -221.39999999999998, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 184.0}, "policy_reward_mean": {"prey_policy": 33.45599999999996, "predator_policy": 10.905}, "custom_metrics": {}, "hist_stats": {"episode_reward": [31.500000000000192, 130.39999999999918, 154.59999999999954, 42.80000000000035, 174.99999999999966, 25.300000000000466, 200.19999999999928, 35.600000000000236, 99.1999999999997, 33.400000000000205, 216.39999999999975, 164.69999999999968, 84.09999999999948, 20.50000000000017, 71.00000000000003, -16.099999999999724, 178.59999999999928, 30.100000000000147, 56.20000000000038, 43.20000000000005, 41.70000000000033, 111.09999999999997, 47.20000000000038, 141.6999999999994, 75.69999999999955, 87.3, 63.700000000000486, 236.39999999999912, 58.900000000000325, 39.600000000000264, 57.20000000000036, 8.90000000000015, 66.10000000000011, -27.999999999999638, 44.60000000000038, 193.89999999999935, 40.0000000000003, 115.2999999999989, 44.50000000000029, 138.69999999999882, -5.499999999999858, 296.4999999999999, 231.09999999999917, 81.49999999999925, 11.399999999999949, 144.39999999999964, 106.89999999999924, -75.7000000000007, 158.7999999999992, 30.20000000000015, 174.8999999999995, 76.8000000000001, 132.6999999999987, 65.8000000000003, 48.30000000000039, 113.7999999999997, 52.40000000000049, 76.09999999999954, 30.100000000000165, 67.40000000000013, 10.500000000000357, 152.69999999999933, 42.700000000000294, 114.69999999999959, 133.5999999999987, 84.99999999999957, 37.80000000000027, 99.3999999999985, 87.89999999999904, 64.30000000000027, 80.4999999999993, 46.900000000000226, 43.600000000000364, 35.60000000000023, 54.50000000000006, 29.000000000000128, 61.600000000000264, 100.09999999999876, 110.89999999999995, 66.10000000000026, 101.19999999999901, 69.50000000000045, 127.99999999999885, -15.699999999999683, 119.69999999999865, 64.30000000000038, 86.89999999999932, 106.60000000000018, 152.4999999999998, 134.9999999999998, 119.49999999999977, 51.10000000000036, 148.2999999999996, 177.19999999999868, 97.79999999999953, 119.6999999999995, 114.79999999999944, 111.79999999999905, 288.39999999999975, 59.099999999999476], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-0.9999999999999473, 3.499999999999999, 109.09999999999967, -0.6999999999999207, -49.59999999999988, 129.2, -21.99999999999978, 42.80000000000019, 36.19999999999999, 138.79999999999998, -36.69999999999999, 29.000000000000163, 20.000000000000014, 180.19999999999996, 11.599999999999968, 20.000000000000014, -49.299999999999905, 99.49999999999994, 7.39999999999997, 20.000000000000014, 71.30000000000013, 145.10000000000008, 88.99999999999977, 55.69999999999997, 64.10000000000011, 20.000000000000014, -16.59999999999996, -19.89999999999975, 20.000000000000014, 44.00000000000005, -123.10000000000034, 20.000000000000014, 158.60000000000002, 20.000000000000014, 20.000000000000014, 1.0999999999999865, 20.000000000000014, 36.200000000000095, -97.60000000000062, 66.80000000000003, 9.499999999999973, 27.200000000000138, 66.79999999999988, 44.300000000000026, 22.700000000000063, 24.50000000000009, 121.69999999999997, 20.000000000000014, 20.900000000000045, 30.800000000000196, 65.3, 20.000000000000014, 20.90000000000003, 39.80000000000024, 101.29999999999973, 118.09999999999948, 38.90000000000011, 20.000000000000014, 17.59999999999999, 20.000000000000014, 23.60000000000003, 20.599999999999973, -24.10000000000003, -49.00000000000022, 20.000000000000014, 37.09999999999997, 20.000000000000014, -124.00000000000057, 25.700000000000117, 8.89999999999997, 100.99999999999957, 92.89999999999998, 20.000000000000014, 20.000000000000014, 75.79999999999956, 24.50000000000008, 24.500000000000007, 20.000000000000014, 9.499999999999988, 123.19999999999953, -68.50000000000065, 20.000000000000014, 96.49999999999994, 200.0, 60.500000000000185, 167.59999999999985, -11.499999999999819, 70.99999999999963, -5.19999999999999, -21.399999999999793, 87.5, 56.89999999999998, 20.000000000000014, 83.89999999999964, -151.30000000000047, -221.39999999999998, 20.000000000000014, 138.79999999999978, 24.500000000000096, -7.299999999999898, 183.8, -40.8999999999998, -3.1000000000000294, 11.899999999999938, 112.69999999999945, 20.000000000000014, -68.2000000000008, 91.99999999999997, 37.100000000000236, 3.1999999999999615, 20.000000000000014, 93.79999999999987, 20.000000000000014, 22.40000000000007, -37.599999999999966, -7.299999999999898, 5.299999999999976, 15.799999999999962, 41.60000000000016, 15.799999999999963, 32.29999999999999, -59.80000000000048, 145.39999999999986, -15.699999999999754, 20.000000000000014, 22.70000000000001, -85.49999999999986, 123.1999999999999, 91.99999999999932, 41.60000000000015, 64.99999999999996, 20.000000000000014, 15.799999999999962, 20.000000000000014, 20.900000000000027, 78.49999999999935, 3.1999999999999615, 76.6999999999995, 37.10000000000011, 27.20000000000008, 20.000000000000014, 60.50000000000022, 36.800000000000175, -22.899999999999785, 20.000000000000014, 23.600000000000076, 11.599999999999975, 20.000000000000014, 21.500000000000135, 20.000000000000014, -0.9999999999999846, 20.000000000000014, 41.59999999999998, 20.000000000000014, 88.3999999999994, 1.6999999999999604, 49.39999999999981, 24.500000000000064, 20.000000000000014, 46.1000000000002, 71.29999999999993, 29.9, 25.999999999999975, 42.50000000000025, 32.30000000000007, 76.69999999999985, 27.200000000000134, -103.90000000000062, 101.89999999999938, 15.799999999999962, 28.100000000000147, 36.2000000000001, 56.900000000000155, 20.000000000000014, 38.90000000000022, 67.70000000000012, 80.29999999999998, 72.19999999999989, 123.49999999999997, -71.5000000000004, 102.80000000000001, 13.699999999999964, 25.1000000000001, 13.999999999999945, 20.000000000000014, 107.30000000000007, 127.99999999999957, 42.200000000000216, 51.800000000000075, 20.000000000000014, 64.10000000000001, 23.60000000000011, 42.80000000000016, 53.00000000000019, -52.89999999999985, 124.69999999999956, 119.90000000000009, 168.49999999999991, -142.60000000000005, 88.69999999999956], "policy_predator_policy_reward": [0.0, 29.0, 12.0, 10.0, 23.0, 52.0, 2.0, 20.0, 0.0, 0.0, 30.0, 3.0, 0.0, 0.0, 0.0, 4.0, 49.0, 0.0, 6.0, 0.0, 0.0, 0.0, 20.0, 0.0, 0.0, 0.0, 10.0, 47.0, 7.0, 0.0, 0.0, 87.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 27.0, 47.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.0, 0.0, 2.0, 0.0, 3.0, 0.0, 4.0, 13.0, 0.0, 0.0, 2.0, 0.0, 13.0, 0.0, 59.0, 23.0, 0.0, 9.0, 58.0, 18.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 15.0, 0.0, 0.0, 0.0, 6.0, 43.0, 0.0, 0.0, 0.0, 3.0, 0.0, 7.0, 15.0, 29.0, 9.0, 0.0, 0.0, 3.0, 0.0, 113.0, 184.0, 0.0, 0.0, 0.0, 13.0, 3.0, 29.0, 35.0, 33.0, 0.0, 0.0, 42.0, 0.0, 8.0, 0.0, 0.0, 0.0, 10.0, 0.0, 79.0, 42.0, 0.0, 9.0, 10.0, 0.0, 38.0, 0.0, 22.0, 1.0, 0.0, 0.0, 60.0, 17.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.0, 9.0, 0.0, 0.0, 4.0, 0.0, 13.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 37.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 18.0, 1.0, 38.0, 23.0, 0.0, 2.0, 0.0, 0.0, 1.0, 9.0, 0.0, 0.0, 0.0, 0.0, 2.0, 81.0, 0.0, 3.0, 0.0, 12.0, 6.0, 15.0, 0.0, 7.0, 21.0, 5.0, 5.0, 27.0, 5.0, 14.0, 35.0, 5.0, 0.0, 0.0, 83.0, 30.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 11.665152725795927, "mean_inference_ms": 54.25749354268273, "mean_action_processing_ms": 11.725386751405074, "mean_env_wait_ms": 20.613945915408056, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.011619329452514648, "StateBufferConnector_ms": 0.005540132522583008, "ViewRequirementAgentConnector_ms": 0.26038074493408203}, "num_episodes": 18, "episode_return_max": 296.4999999999999, "episode_return_min": -75.7000000000007, "episode_return_mean": 88.7219999999998, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 400000, "num_agent_steps_trained": 400000, "num_env_steps_sampled": 100000, "num_env_steps_trained": 100000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 212.11011945045615, "num_env_steps_trained_throughput_per_sec": 212.11011945045615, "timesteps_total": 100000, "num_env_steps_sampled_lifetime": 100000, "num_agent_steps_sampled_lifetime": 400000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 400000, "timers": {"training_iteration_time_ms": 209980.536, "restore_workers_time_ms": 0.047, "training_step_time_ms": 209980.429, "sample_time_ms": 3225.238, "learn_time_ms": 206712.87, "learn_throughput": 19.351, "synch_weights_time_ms": 32.9}, "counters": {"num_env_steps_sampled": 100000, "num_env_steps_trained": 100000, "num_agent_steps_sampled": 400000, "num_agent_steps_trained": 400000}, "done": false, "training_iteration": 25, "trial_id": "75ec3_00000", "date": "2024-08-13_02-14-49", "timestamp": 1723529689, "time_this_iter_s": 18.912604331970215, "time_total_s": 3345.9046895504, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2058940>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3345.9046895504, "iterations_since_restore": 25, "perf": {"cpu_util_percent": 90.92592592592592, "ram_util_percent": 83.6}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.411092003525565, "cur_kl_coeff": 0.084375, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.301907452956709, "policy_loss": -0.009725153373145355, "vf_loss": 4.3095377011273905, "vf_explained_var": 0.07827948543129774, "kl": 0.024828575626158006, "entropy": 1.417087733745575, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 48195.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.3841684072559315, "cur_kl_coeff": 0.003125, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.2515933253146985, "policy_loss": -0.0008812201732927293, "vf_loss": 1.2524542742305331, "vf_explained_var": 0.005351662856561167, "kl": 0.006487437334379143, "entropy": 1.3125004055638794, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 48195.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 104000, "num_env_steps_trained": 104000, "num_agent_steps_sampled": 416000, "num_agent_steps_trained": 416000}, "env_runners": {"episode_reward_max": 296.4999999999999, "episode_reward_min": -75.7000000000007, "episode_reward_mean": 88.15899999999978, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -221.39999999999998, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 184.0}, "policy_reward_mean": {"prey_policy": 31.62449999999995, "predator_policy": 12.455}, "custom_metrics": {}, "hist_stats": {"episode_reward": [56.20000000000038, 43.20000000000005, 41.70000000000033, 111.09999999999997, 47.20000000000038, 141.6999999999994, 75.69999999999955, 87.3, 63.700000000000486, 236.39999999999912, 58.900000000000325, 39.600000000000264, 57.20000000000036, 8.90000000000015, 66.10000000000011, -27.999999999999638, 44.60000000000038, 193.89999999999935, 40.0000000000003, 115.2999999999989, 44.50000000000029, 138.69999999999882, -5.499999999999858, 296.4999999999999, 231.09999999999917, 81.49999999999925, 11.399999999999949, 144.39999999999964, 106.89999999999924, -75.7000000000007, 158.7999999999992, 30.20000000000015, 174.8999999999995, 76.8000000000001, 132.6999999999987, 65.8000000000003, 48.30000000000039, 113.7999999999997, 52.40000000000049, 76.09999999999954, 30.100000000000165, 67.40000000000013, 10.500000000000357, 152.69999999999933, 42.700000000000294, 114.69999999999959, 133.5999999999987, 84.99999999999957, 37.80000000000027, 99.3999999999985, 87.89999999999904, 64.30000000000027, 80.4999999999993, 46.900000000000226, 43.600000000000364, 35.60000000000023, 54.50000000000006, 29.000000000000128, 61.600000000000264, 100.09999999999876, 110.89999999999995, 66.10000000000026, 101.19999999999901, 69.50000000000045, 127.99999999999885, -15.699999999999683, 119.69999999999865, 64.30000000000038, 86.89999999999932, 106.60000000000018, 152.4999999999998, 134.9999999999998, 119.49999999999977, 51.10000000000036, 148.2999999999996, 177.19999999999868, 97.79999999999953, 119.6999999999995, 114.79999999999944, 111.79999999999905, 288.39999999999975, 59.099999999999476, 1.2000000000000506, 40.0000000000003, 32.400000000000205, 81.39999999999921, 149.6999999999989, 145.0999999999988, 58.50000000000031, 60.70000000000051, 69.69999999999987, 291.8000000000004, -0.7999999999998787, 131.29999999999924, 122.79999999999977, 31.900000000000173, 10.700000000000006, 100.29999999999949, 164.3999999999993, 129.89999999999927], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 36.200000000000095, -97.60000000000062, 66.80000000000003, 9.499999999999973, 27.200000000000138, 66.79999999999988, 44.300000000000026, 22.700000000000063, 24.50000000000009, 121.69999999999997, 20.000000000000014, 20.900000000000045, 30.800000000000196, 65.3, 20.000000000000014, 20.90000000000003, 39.80000000000024, 101.29999999999973, 118.09999999999948, 38.90000000000011, 20.000000000000014, 17.59999999999999, 20.000000000000014, 23.60000000000003, 20.599999999999973, -24.10000000000003, -49.00000000000022, 20.000000000000014, 37.09999999999997, 20.000000000000014, -124.00000000000057, 25.700000000000117, 8.89999999999997, 100.99999999999957, 92.89999999999998, 20.000000000000014, 20.000000000000014, 75.79999999999956, 24.50000000000008, 24.500000000000007, 20.000000000000014, 9.499999999999988, 123.19999999999953, -68.50000000000065, 20.000000000000014, 96.49999999999994, 200.0, 60.500000000000185, 167.59999999999985, -11.499999999999819, 70.99999999999963, -5.19999999999999, -21.399999999999793, 87.5, 56.89999999999998, 20.000000000000014, 83.89999999999964, -151.30000000000047, -221.39999999999998, 20.000000000000014, 138.79999999999978, 24.500000000000096, -7.299999999999898, 183.8, -40.8999999999998, -3.1000000000000294, 11.899999999999938, 112.69999999999945, 20.000000000000014, -68.2000000000008, 91.99999999999997, 37.100000000000236, 3.1999999999999615, 20.000000000000014, 93.79999999999987, 20.000000000000014, 22.40000000000007, -37.599999999999966, -7.299999999999898, 5.299999999999976, 15.799999999999962, 41.60000000000016, 15.799999999999963, 32.29999999999999, -59.80000000000048, 145.39999999999986, -15.699999999999754, 20.000000000000014, 22.70000000000001, -85.49999999999986, 123.1999999999999, 91.99999999999932, 41.60000000000015, 64.99999999999996, 20.000000000000014, 15.799999999999962, 20.000000000000014, 20.900000000000027, 78.49999999999935, 3.1999999999999615, 76.6999999999995, 37.10000000000011, 27.20000000000008, 20.000000000000014, 60.50000000000022, 36.800000000000175, -22.899999999999785, 20.000000000000014, 23.600000000000076, 11.599999999999975, 20.000000000000014, 21.500000000000135, 20.000000000000014, -0.9999999999999846, 20.000000000000014, 41.59999999999998, 20.000000000000014, 88.3999999999994, 1.6999999999999604, 49.39999999999981, 24.500000000000064, 20.000000000000014, 46.1000000000002, 71.29999999999993, 29.9, 25.999999999999975, 42.50000000000025, 32.30000000000007, 76.69999999999985, 27.200000000000134, -103.90000000000062, 101.89999999999938, 15.799999999999962, 28.100000000000147, 36.2000000000001, 56.900000000000155, 20.000000000000014, 38.90000000000022, 67.70000000000012, 80.29999999999998, 72.19999999999989, 123.49999999999997, -71.5000000000004, 102.80000000000001, 13.699999999999964, 25.1000000000001, 13.999999999999945, 20.000000000000014, 107.30000000000007, 127.99999999999957, 42.200000000000216, 51.800000000000075, 20.000000000000014, 64.10000000000001, 23.60000000000011, 42.80000000000016, 53.00000000000019, -52.89999999999985, 124.69999999999956, 119.90000000000009, 168.49999999999991, -142.60000000000005, 88.69999999999956, -194.50000000000048, 58.70000000000022, 20.000000000000014, 20.000000000000014, 87.19999999999945, -188.80000000000035, 61.400000000000205, 20.000000000000014, 75.19999999999976, 51.50000000000019, 29.900000000000073, 114.19999999999948, 53.300000000000146, -41.79999999999977, 20.000000000000014, 40.70000000000025, 22.700000000000166, 20.000000000000014, 104.89999999999944, 182.8999999999999, -204.70000000000013, 29.900000000000183, -6.399999999999936, 112.69999999999979, 29.9, 74.90000000000006, 49.70000000000013, -80.80000000000062, -24.099999999999753, -20.199999999999882, 44.300000000000054, 56.00000000000023, -5.1999999999999265, 152.59999999999985, 104.89999999999972, 20.000000000000014], "policy_predator_policy_reward": [0.0, 0.0, 27.0, 47.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.0, 0.0, 2.0, 0.0, 3.0, 0.0, 4.0, 13.0, 0.0, 0.0, 2.0, 0.0, 13.0, 0.0, 59.0, 23.0, 0.0, 9.0, 58.0, 18.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 15.0, 0.0, 0.0, 0.0, 6.0, 43.0, 0.0, 0.0, 0.0, 3.0, 0.0, 7.0, 15.0, 29.0, 9.0, 0.0, 0.0, 3.0, 0.0, 113.0, 184.0, 0.0, 0.0, 0.0, 13.0, 3.0, 29.0, 35.0, 33.0, 0.0, 0.0, 42.0, 0.0, 8.0, 0.0, 0.0, 0.0, 10.0, 0.0, 79.0, 42.0, 0.0, 9.0, 10.0, 0.0, 38.0, 0.0, 22.0, 1.0, 0.0, 0.0, 60.0, 17.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.0, 9.0, 0.0, 0.0, 4.0, 0.0, 13.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 37.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 18.0, 1.0, 38.0, 23.0, 0.0, 2.0, 0.0, 0.0, 1.0, 9.0, 0.0, 0.0, 0.0, 0.0, 2.0, 81.0, 0.0, 3.0, 0.0, 12.0, 6.0, 15.0, 0.0, 7.0, 21.0, 5.0, 5.0, 27.0, 5.0, 14.0, 35.0, 5.0, 0.0, 0.0, 83.0, 30.0, 31.0, 106.0, 0.0, 0.0, 66.0, 68.0, 0.0, 0.0, 21.0, 2.0, 1.0, 0.0, 32.0, 15.0, 0.0, 0.0, 18.0, 9.0, 2.0, 2.0, 69.0, 105.0, 6.0, 19.0, 18.0, 0.0, 25.0, 38.0, 30.0, 25.0, 0.0, 0.0, 17.0, 0.0, 0.0, 5.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 11.271395643418984, "mean_inference_ms": 52.31837589161505, "mean_action_processing_ms": 11.287981487078962, "mean_env_wait_ms": 19.846325051135903, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01221609115600586, "StateBufferConnector_ms": 0.005221247673034668, "ViewRequirementAgentConnector_ms": 0.2210918664932251}, "num_episodes": 18, "episode_return_max": 296.4999999999999, "episode_return_min": -75.7000000000007, "episode_return_mean": 88.15899999999978, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 416000, "num_agent_steps_trained": 416000, "num_env_steps_sampled": 104000, "num_env_steps_trained": 104000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 219.6364416322591, "num_env_steps_trained_throughput_per_sec": 219.6364416322591, "timesteps_total": 104000, "num_env_steps_sampled_lifetime": 104000, "num_agent_steps_sampled_lifetime": 416000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 416000, "timers": {"training_iteration_time_ms": 209541.673, "restore_workers_time_ms": 0.047, "training_step_time_ms": 209541.568, "sample_time_ms": 3142.725, "learn_time_ms": 206357.699, "learn_throughput": 19.384, "synch_weights_time_ms": 31.931}, "counters": {"num_env_steps_sampled": 104000, "num_env_steps_trained": 104000, "num_agent_steps_sampled": 416000, "num_agent_steps_trained": 416000}, "done": false, "training_iteration": 26, "trial_id": "75ec3_00000", "date": "2024-08-13_02-15-07", "timestamp": 1723529707, "time_this_iter_s": 18.28446102142334, "time_total_s": 3364.189150571823, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b208e430>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3364.189150571823, "iterations_since_restore": 26, "perf": {"cpu_util_percent": 88.66923076923075, "ram_util_percent": 83.46538461538461}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3333242795927815, "cur_kl_coeff": 0.12656249999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.3540229748165797, "policy_loss": -0.010298417486858964, "vf_loss": 1.3622417217209226, "vf_explained_var": 0.1775364093994968, "kl": 0.016431951412552073, "entropy": 1.4442786638068144, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 50085.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.3665479452866647, "cur_kl_coeff": 0.003125, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.2879794836596206, "policy_loss": -0.001624972304999434, "vf_loss": 0.2895955486255131, "vf_explained_var": 0.12267975428747753, "kl": 0.002850619720105846, "entropy": 1.2833790065750244, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 50085.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 108000, "num_env_steps_trained": 108000, "num_agent_steps_sampled": 432000, "num_agent_steps_trained": 432000}, "env_runners": {"episode_reward_max": 296.4999999999999, "episode_reward_min": -75.7000000000007, "episode_reward_mean": 89.1489999999997, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -221.39999999999998, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 209.0}, "policy_reward_mean": {"prey_policy": 31.539499999999958, "predator_policy": 13.035}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-5.499999999999858, 296.4999999999999, 231.09999999999917, 81.49999999999925, 11.399999999999949, 144.39999999999964, 106.89999999999924, -75.7000000000007, 158.7999999999992, 30.20000000000015, 174.8999999999995, 76.8000000000001, 132.6999999999987, 65.8000000000003, 48.30000000000039, 113.7999999999997, 52.40000000000049, 76.09999999999954, 30.100000000000165, 67.40000000000013, 10.500000000000357, 152.69999999999933, 42.700000000000294, 114.69999999999959, 133.5999999999987, 84.99999999999957, 37.80000000000027, 99.3999999999985, 87.89999999999904, 64.30000000000027, 80.4999999999993, 46.900000000000226, 43.600000000000364, 35.60000000000023, 54.50000000000006, 29.000000000000128, 61.600000000000264, 100.09999999999876, 110.89999999999995, 66.10000000000026, 101.19999999999901, 69.50000000000045, 127.99999999999885, -15.699999999999683, 119.69999999999865, 64.30000000000038, 86.89999999999932, 106.60000000000018, 152.4999999999998, 134.9999999999998, 119.49999999999977, 51.10000000000036, 148.2999999999996, 177.19999999999868, 97.79999999999953, 119.6999999999995, 114.79999999999944, 111.79999999999905, 288.39999999999975, 59.099999999999476, 1.2000000000000506, 40.0000000000003, 32.400000000000205, 81.39999999999921, 149.6999999999989, 145.0999999999988, 58.50000000000031, 60.70000000000051, 69.69999999999987, 291.8000000000004, -0.7999999999998787, 131.29999999999924, 122.79999999999977, 31.900000000000173, 10.700000000000006, 100.29999999999949, 164.3999999999993, 129.89999999999927, 112.09999999999901, 37.80000000000027, 26.60000000000009, 168.6999999999991, 68.49999999999996, 94.39999999999858, 75.09999999999965, 37.30000000000026, 74.19999999999969, 40.0000000000003, 54.20000000000043, 40.0000000000003, 185.499999999999, 100.29999999999913, 90.59999999999872, 94.89999999999893, 111.89999999999968, 63.6000000000005, 71.89999999999971, 102.9999999999985, 98.09999999999982, 34.200000000000216], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-68.50000000000065, 20.000000000000014, 96.49999999999994, 200.0, 60.500000000000185, 167.59999999999985, -11.499999999999819, 70.99999999999963, -5.19999999999999, -21.399999999999793, 87.5, 56.89999999999998, 20.000000000000014, 83.89999999999964, -151.30000000000047, -221.39999999999998, 20.000000000000014, 138.79999999999978, 24.500000000000096, -7.299999999999898, 183.8, -40.8999999999998, -3.1000000000000294, 11.899999999999938, 112.69999999999945, 20.000000000000014, -68.2000000000008, 91.99999999999997, 37.100000000000236, 3.1999999999999615, 20.000000000000014, 93.79999999999987, 20.000000000000014, 22.40000000000007, -37.599999999999966, -7.299999999999898, 5.299999999999976, 15.799999999999962, 41.60000000000016, 15.799999999999963, 32.29999999999999, -59.80000000000048, 145.39999999999986, -15.699999999999754, 20.000000000000014, 22.70000000000001, -85.49999999999986, 123.1999999999999, 91.99999999999932, 41.60000000000015, 64.99999999999996, 20.000000000000014, 15.799999999999962, 20.000000000000014, 20.900000000000027, 78.49999999999935, 3.1999999999999615, 76.6999999999995, 37.10000000000011, 27.20000000000008, 20.000000000000014, 60.50000000000022, 36.800000000000175, -22.899999999999785, 20.000000000000014, 23.600000000000076, 11.599999999999975, 20.000000000000014, 21.500000000000135, 20.000000000000014, -0.9999999999999846, 20.000000000000014, 41.59999999999998, 20.000000000000014, 88.3999999999994, 1.6999999999999604, 49.39999999999981, 24.500000000000064, 20.000000000000014, 46.1000000000002, 71.29999999999993, 29.9, 25.999999999999975, 42.50000000000025, 32.30000000000007, 76.69999999999985, 27.200000000000134, -103.90000000000062, 101.89999999999938, 15.799999999999962, 28.100000000000147, 36.2000000000001, 56.900000000000155, 20.000000000000014, 38.90000000000022, 67.70000000000012, 80.29999999999998, 72.19999999999989, 123.49999999999997, -71.5000000000004, 102.80000000000001, 13.699999999999964, 25.1000000000001, 13.999999999999945, 20.000000000000014, 107.30000000000007, 127.99999999999957, 42.200000000000216, 51.800000000000075, 20.000000000000014, 64.10000000000001, 23.60000000000011, 42.80000000000016, 53.00000000000019, -52.89999999999985, 124.69999999999956, 119.90000000000009, 168.49999999999991, -142.60000000000005, 88.69999999999956, -194.50000000000048, 58.70000000000022, 20.000000000000014, 20.000000000000014, 87.19999999999945, -188.80000000000035, 61.400000000000205, 20.000000000000014, 75.19999999999976, 51.50000000000019, 29.900000000000073, 114.19999999999948, 53.300000000000146, -41.79999999999977, 20.000000000000014, 40.70000000000025, 22.700000000000166, 20.000000000000014, 104.89999999999944, 182.8999999999999, -204.70000000000013, 29.900000000000183, -6.399999999999936, 112.69999999999979, 29.9, 74.90000000000006, 49.70000000000013, -80.80000000000062, -24.099999999999753, -20.199999999999882, 44.300000000000054, 56.00000000000023, -5.1999999999999265, 152.59999999999985, 104.89999999999972, 20.000000000000014, 20.000000000000014, 73.09999999999957, 15.799999999999963, 20.000000000000014, 11.89999999999997, -7.299999999999894, 31.700000000000212, 136.99999999999974, 55.100000000000115, 7.399999999999965, 46.70000000000018, 31.70000000000022, 20.000000000000014, 55.10000000000021, 8.299999999999969, 20.000000000000014, 38.90000000000019, 26.300000000000114, 20.000000000000014, 20.000000000000014, 24.20000000000009, 20.000000000000014, 20.000000000000014, 20.000000000000014, 98.89999999999966, 80.59999999999934, 71.29999999999964, 20.000000000000014, 10.399999999999963, 72.19999999999962, 20.000000000000014, 74.89999999999948, 92.29999999999964, -221.3999999999994, 32.60000000000023, 20.000000000000014, 20.000000000000014, 5.899999999999951, 81.19999999999925, 21.800000000000043, 29.000000000000163, 40.100000000000044, 26.300000000000118, -3.0999999999999757], "policy_predator_policy_reward": [43.0, 0.0, 0.0, 0.0, 3.0, 0.0, 7.0, 15.0, 29.0, 9.0, 0.0, 0.0, 3.0, 0.0, 113.0, 184.0, 0.0, 0.0, 0.0, 13.0, 3.0, 29.0, 35.0, 33.0, 0.0, 0.0, 42.0, 0.0, 8.0, 0.0, 0.0, 0.0, 10.0, 0.0, 79.0, 42.0, 0.0, 9.0, 10.0, 0.0, 38.0, 0.0, 22.0, 1.0, 0.0, 0.0, 60.0, 17.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.0, 9.0, 0.0, 0.0, 4.0, 0.0, 13.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 37.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 18.0, 1.0, 38.0, 23.0, 0.0, 2.0, 0.0, 0.0, 1.0, 9.0, 0.0, 0.0, 0.0, 0.0, 2.0, 81.0, 0.0, 3.0, 0.0, 12.0, 6.0, 15.0, 0.0, 7.0, 21.0, 5.0, 5.0, 27.0, 5.0, 14.0, 35.0, 5.0, 0.0, 0.0, 83.0, 30.0, 31.0, 106.0, 0.0, 0.0, 66.0, 68.0, 0.0, 0.0, 21.0, 2.0, 1.0, 0.0, 32.0, 15.0, 0.0, 0.0, 18.0, 9.0, 2.0, 2.0, 69.0, 105.0, 6.0, 19.0, 18.0, 0.0, 25.0, 38.0, 30.0, 25.0, 0.0, 0.0, 17.0, 0.0, 0.0, 5.0, 14.0, 5.0, 2.0, 0.0, 9.0, 13.0, 0.0, 0.0, 0.0, 6.0, 9.0, 7.0, 0.0, 0.0, 3.0, 6.0, 7.0, 2.0, 0.0, 0.0, 1.0, 9.0, 0.0, 0.0, 1.0, 5.0, 9.0, 0.0, 8.0, 0.0, 0.0, 0.0, 209.0, 32.0, 9.0, 2.0, 23.0, 23.0, 0.0, 0.0, 8.0, 21.0, 11.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 10.902542592958303, "mean_inference_ms": 52.05724365181783, "mean_action_processing_ms": 9.931646982899963, "mean_env_wait_ms": 17.960558235497, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.013583540916442871, "StateBufferConnector_ms": 0.005383014678955078, "ViewRequirementAgentConnector_ms": 0.19698011875152588}, "num_episodes": 22, "episode_return_max": 296.4999999999999, "episode_return_min": -75.7000000000007, "episode_return_mean": 89.1489999999997, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 432000, "num_agent_steps_trained": 432000, "num_env_steps_sampled": 108000, "num_env_steps_trained": 108000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 208.19874281694422, "num_env_steps_trained_throughput_per_sec": 208.19874281694422, "timesteps_total": 108000, "num_env_steps_sampled_lifetime": 108000, "num_agent_steps_sampled_lifetime": 432000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 432000, "timers": {"training_iteration_time_ms": 209194.111, "restore_workers_time_ms": 0.04, "training_step_time_ms": 209194.018, "sample_time_ms": 3060.738, "learn_time_ms": 206096.111, "learn_throughput": 19.408, "synch_weights_time_ms": 29.362}, "counters": {"num_env_steps_sampled": 108000, "num_env_steps_trained": 108000, "num_agent_steps_sampled": 432000, "num_agent_steps_trained": 432000}, "done": false, "training_iteration": 27, "trial_id": "75ec3_00000", "date": "2024-08-13_02-15-26", "timestamp": 1723529726, "time_this_iter_s": 19.26535701751709, "time_total_s": 3383.45450758934, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b1bcb820>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3383.45450758934, "iterations_since_restore": 27, "perf": {"cpu_util_percent": 87.7, "ram_util_percent": 83.60740740740741}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.615294787610965, "cur_kl_coeff": 0.12656249999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.7443475325271565, "policy_loss": -0.0017439099271392459, "vf_loss": 2.7449006689919364, "vf_explained_var": 0.10346240439112224, "kl": 0.009408600839182614, "entropy": 1.4210078620406055, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 51975.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.36620444395239393, "cur_kl_coeff": 0.0015625, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.7004039363570945, "policy_loss": -0.0033693989924840117, "vf_loss": 0.7037442128573145, "vf_explained_var": 0.015057550946240703, "kl": 0.01863853501423222, "entropy": 1.0988889387675693, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 51975.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 112000, "num_env_steps_trained": 112000, "num_agent_steps_sampled": 448000, "num_agent_steps_trained": 448000}, "env_runners": {"episode_reward_max": 291.8000000000004, "episode_reward_min": -15.699999999999683, "episode_reward_mean": 85.05499999999975, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -221.3999999999994, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 182.8999999999999, "predator_policy": 209.0}, "policy_reward_mean": {"prey_policy": 32.047499999999985, "predator_policy": 10.48}, "custom_metrics": {}, "hist_stats": {"episode_reward": [114.69999999999959, 133.5999999999987, 84.99999999999957, 37.80000000000027, 99.3999999999985, 87.89999999999904, 64.30000000000027, 80.4999999999993, 46.900000000000226, 43.600000000000364, 35.60000000000023, 54.50000000000006, 29.000000000000128, 61.600000000000264, 100.09999999999876, 110.89999999999995, 66.10000000000026, 101.19999999999901, 69.50000000000045, 127.99999999999885, -15.699999999999683, 119.69999999999865, 64.30000000000038, 86.89999999999932, 106.60000000000018, 152.4999999999998, 134.9999999999998, 119.49999999999977, 51.10000000000036, 148.2999999999996, 177.19999999999868, 97.79999999999953, 119.6999999999995, 114.79999999999944, 111.79999999999905, 288.39999999999975, 59.099999999999476, 1.2000000000000506, 40.0000000000003, 32.400000000000205, 81.39999999999921, 149.6999999999989, 145.0999999999988, 58.50000000000031, 60.70000000000051, 69.69999999999987, 291.8000000000004, -0.7999999999998787, 131.29999999999924, 122.79999999999977, 31.900000000000173, 10.700000000000006, 100.29999999999949, 164.3999999999993, 129.89999999999927, 112.09999999999901, 37.80000000000027, 26.60000000000009, 168.6999999999991, 68.49999999999996, 94.39999999999858, 75.09999999999965, 37.30000000000026, 74.19999999999969, 40.0000000000003, 54.20000000000043, 40.0000000000003, 185.499999999999, 100.29999999999913, 90.59999999999872, 94.89999999999893, 111.89999999999968, 63.6000000000005, 71.89999999999971, 102.9999999999985, 98.09999999999982, 34.200000000000216, 54.70000000000035, 54.40000000000052, 63.20000000000033, 113.99999999999896, 51.70000000000048, 178.399999999999, 59.40000000000043, 46.30000000000029, 61.60000000000038, 40.0000000000003, 50.800000000000374, 44.100000000000364, 106.49999999999886, 55.3000000000003, 58.00000000000052, 156.9999999999989, 33.39999999999997, 78.69999999999943, 66.30000000000027, 88.59999999999872, 47.00000000000042, 43.500000000000334, 61.5000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-85.49999999999986, 123.1999999999999, 91.99999999999932, 41.60000000000015, 64.99999999999996, 20.000000000000014, 15.799999999999962, 20.000000000000014, 20.900000000000027, 78.49999999999935, 3.1999999999999615, 76.6999999999995, 37.10000000000011, 27.20000000000008, 20.000000000000014, 60.50000000000022, 36.800000000000175, -22.899999999999785, 20.000000000000014, 23.600000000000076, 11.599999999999975, 20.000000000000014, 21.500000000000135, 20.000000000000014, -0.9999999999999846, 20.000000000000014, 41.59999999999998, 20.000000000000014, 88.3999999999994, 1.6999999999999604, 49.39999999999981, 24.500000000000064, 20.000000000000014, 46.1000000000002, 71.29999999999993, 29.9, 25.999999999999975, 42.50000000000025, 32.30000000000007, 76.69999999999985, 27.200000000000134, -103.90000000000062, 101.89999999999938, 15.799999999999962, 28.100000000000147, 36.2000000000001, 56.900000000000155, 20.000000000000014, 38.90000000000022, 67.70000000000012, 80.29999999999998, 72.19999999999989, 123.49999999999997, -71.5000000000004, 102.80000000000001, 13.699999999999964, 25.1000000000001, 13.999999999999945, 20.000000000000014, 107.30000000000007, 127.99999999999957, 42.200000000000216, 51.800000000000075, 20.000000000000014, 64.10000000000001, 23.60000000000011, 42.80000000000016, 53.00000000000019, -52.89999999999985, 124.69999999999956, 119.90000000000009, 168.49999999999991, -142.60000000000005, 88.69999999999956, -194.50000000000048, 58.70000000000022, 20.000000000000014, 20.000000000000014, 87.19999999999945, -188.80000000000035, 61.400000000000205, 20.000000000000014, 75.19999999999976, 51.50000000000019, 29.900000000000073, 114.19999999999948, 53.300000000000146, -41.79999999999977, 20.000000000000014, 40.70000000000025, 22.700000000000166, 20.000000000000014, 104.89999999999944, 182.8999999999999, -204.70000000000013, 29.900000000000183, -6.399999999999936, 112.69999999999979, 29.9, 74.90000000000006, 49.70000000000013, -80.80000000000062, -24.099999999999753, -20.199999999999882, 44.300000000000054, 56.00000000000023, -5.1999999999999265, 152.59999999999985, 104.89999999999972, 20.000000000000014, 20.000000000000014, 73.09999999999957, 15.799999999999963, 20.000000000000014, 11.89999999999997, -7.299999999999894, 31.700000000000212, 136.99999999999974, 55.100000000000115, 7.399999999999965, 46.70000000000018, 31.70000000000022, 20.000000000000014, 55.10000000000021, 8.299999999999969, 20.000000000000014, 38.90000000000019, 26.300000000000114, 20.000000000000014, 20.000000000000014, 24.20000000000009, 20.000000000000014, 20.000000000000014, 20.000000000000014, 98.89999999999966, 80.59999999999934, 71.29999999999964, 20.000000000000014, 10.399999999999963, 72.19999999999962, 20.000000000000014, 74.89999999999948, 92.29999999999964, -221.3999999999994, 32.60000000000023, 20.000000000000014, 20.000000000000014, 5.899999999999951, 81.19999999999925, 21.800000000000043, 29.000000000000163, 40.100000000000044, 26.300000000000118, -3.0999999999999757, 13.699999999999966, 38.00000000000017, 20.000000000000014, 34.40000000000026, 15.200000000000045, 20.000000000000014, 32.00000000000008, 56.000000000000156, 31.700000000000195, 20.000000000000014, 24.80000000000016, 128.59999999999968, -3.0999999999999615, 51.50000000000021, 24.500000000000064, 21.800000000000047, 41.600000000000186, 20.000000000000014, 20.000000000000014, 20.000000000000014, 25.4000000000001, 25.400000000000027, 22.100000000000044, 20.000000000000014, -9.399999999999862, 101.89999999999947, -17.79999999999974, 37.10000000000013, 38.000000000000256, 20.000000000000014, 136.99999999999963, 20.000000000000014, -45.69999999999992, 25.099999999999955, 58.70000000000022, 20.000000000000014, 32.3000000000002, 20.000000000000014, 20.000000000000014, 68.59999999999988, 29.60000000000018, 7.399999999999965, 29.900000000000173, -9.399999999999869, -21.99999999999975, 60.50000000000015], "policy_predator_policy_reward": [60.0, 17.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.0, 9.0, 0.0, 0.0, 4.0, 0.0, 13.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 37.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 18.0, 1.0, 38.0, 23.0, 0.0, 2.0, 0.0, 0.0, 1.0, 9.0, 0.0, 0.0, 0.0, 0.0, 2.0, 81.0, 0.0, 3.0, 0.0, 12.0, 6.0, 15.0, 0.0, 7.0, 21.0, 5.0, 5.0, 27.0, 5.0, 14.0, 35.0, 5.0, 0.0, 0.0, 83.0, 30.0, 31.0, 106.0, 0.0, 0.0, 66.0, 68.0, 0.0, 0.0, 21.0, 2.0, 1.0, 0.0, 32.0, 15.0, 0.0, 0.0, 18.0, 9.0, 2.0, 2.0, 69.0, 105.0, 6.0, 19.0, 18.0, 0.0, 25.0, 38.0, 30.0, 25.0, 0.0, 0.0, 17.0, 0.0, 0.0, 5.0, 14.0, 5.0, 2.0, 0.0, 9.0, 13.0, 0.0, 0.0, 0.0, 6.0, 9.0, 7.0, 0.0, 0.0, 3.0, 6.0, 7.0, 2.0, 0.0, 0.0, 1.0, 9.0, 0.0, 0.0, 1.0, 5.0, 9.0, 0.0, 8.0, 0.0, 0.0, 0.0, 209.0, 32.0, 9.0, 2.0, 23.0, 23.0, 0.0, 0.0, 8.0, 21.0, 11.0, 0.0, 0.0, 3.0, 0.0, 0.0, 28.0, 0.0, 23.0, 3.0, 0.0, 0.0, 15.0, 10.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 13.0, 36.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 53.0, 0.0, 0.0, 1.0, 13.0, 0.0, 0.0, 4.0, 6.0, 9.0, 14.0, 10.0, 13.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 10.392691647683419, "mean_inference_ms": 48.07788481830555, "mean_action_processing_ms": 10.40960893841047, "mean_env_wait_ms": 18.212085147861384, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.012905716896057129, "StateBufferConnector_ms": 0.004409313201904297, "ViewRequirementAgentConnector_ms": 0.18878412246704102}, "num_episodes": 23, "episode_return_max": 291.8000000000004, "episode_return_min": -15.699999999999683, "episode_return_mean": 85.05499999999975, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 448000, "num_agent_steps_trained": 448000, "num_env_steps_sampled": 112000, "num_env_steps_trained": 112000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 174.7371878004705, "num_env_steps_trained_throughput_per_sec": 174.7371878004705, "timesteps_total": 112000, "num_env_steps_sampled_lifetime": 112000, "num_agent_steps_sampled_lifetime": 448000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 448000, "timers": {"training_iteration_time_ms": 111327.679, "restore_workers_time_ms": 0.04, "training_step_time_ms": 111327.587, "sample_time_ms": 3390.63, "learn_time_ms": 107900.374, "learn_throughput": 37.071, "synch_weights_time_ms": 28.44}, "counters": {"num_env_steps_sampled": 112000, "num_env_steps_trained": 112000, "num_agent_steps_sampled": 448000, "num_agent_steps_trained": 448000}, "done": false, "training_iteration": 28, "trial_id": "75ec3_00000", "date": "2024-08-13_02-15-49", "timestamp": 1723529749, "time_this_iter_s": 22.94847297668457, "time_total_s": 3406.402980566025, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b1a5f4c0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3406.402980566025, "iterations_since_restore": 28, "perf": {"cpu_util_percent": 86.5625, "ram_util_percent": 83.571875}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1487014584282718, "cur_kl_coeff": 0.12656249999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.835676298696528, "policy_loss": -0.0014134959828985669, "vf_loss": 3.836373538441128, "vf_explained_var": 0.06531696269121119, "kl": 0.005659265999147714, "entropy": 1.3955319244394857, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 53865.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.37014360390012224, "cur_kl_coeff": 0.0015625, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.9735119285249205, "policy_loss": -0.0025448345847762922, "vf_loss": 0.9760282571590136, "vf_explained_var": 0.0026952566293181567, "kl": 0.018243627370119735, "entropy": 0.9527890069144113, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 53865.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 116000, "num_env_steps_trained": 116000, "num_agent_steps_sampled": 464000, "num_agent_steps_trained": 464000}, "env_runners": {"episode_reward_max": 291.8000000000004, "episode_reward_min": -45.79999999999983, "episode_reward_mean": 83.32399999999978, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -221.3999999999994, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 182.8999999999999, "predator_policy": 209.0}, "policy_reward_mean": {"prey_policy": 30.18699999999998, "predator_policy": 11.475}, "custom_metrics": {}, "hist_stats": {"episode_reward": [69.50000000000045, 127.99999999999885, -15.699999999999683, 119.69999999999865, 64.30000000000038, 86.89999999999932, 106.60000000000018, 152.4999999999998, 134.9999999999998, 119.49999999999977, 51.10000000000036, 148.2999999999996, 177.19999999999868, 97.79999999999953, 119.6999999999995, 114.79999999999944, 111.79999999999905, 288.39999999999975, 59.099999999999476, 1.2000000000000506, 40.0000000000003, 32.400000000000205, 81.39999999999921, 149.6999999999989, 145.0999999999988, 58.50000000000031, 60.70000000000051, 69.69999999999987, 291.8000000000004, -0.7999999999998787, 131.29999999999924, 122.79999999999977, 31.900000000000173, 10.700000000000006, 100.29999999999949, 164.3999999999993, 129.89999999999927, 112.09999999999901, 37.80000000000027, 26.60000000000009, 168.6999999999991, 68.49999999999996, 94.39999999999858, 75.09999999999965, 37.30000000000026, 74.19999999999969, 40.0000000000003, 54.20000000000043, 40.0000000000003, 185.499999999999, 100.29999999999913, 90.59999999999872, 94.89999999999893, 111.89999999999968, 63.6000000000005, 71.89999999999971, 102.9999999999985, 98.09999999999982, 34.200000000000216, 54.70000000000035, 54.40000000000052, 63.20000000000033, 113.99999999999896, 51.70000000000048, 178.399999999999, 59.40000000000043, 46.30000000000029, 61.60000000000038, 40.0000000000003, 50.800000000000374, 44.100000000000364, 106.49999999999886, 55.3000000000003, 58.00000000000052, 156.9999999999989, 33.39999999999997, 78.69999999999943, 66.30000000000027, 88.59999999999872, 47.00000000000042, 43.500000000000334, 61.5000000000003, 86.89999999999934, 40.9000000000003, 66.1000000000001, 128.1999999999989, 133.5999999999991, 40.0000000000003, 46.10000000000027, 19.50000000000022, 37.80000000000026, -45.79999999999983, 123.59999999999957, 117.39999999999867, 26.800000000000093, 189.29999999999973, 81.50000000000004, -35.79999999999966, 103.89999999999868, 19.60000000000006], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [25.999999999999975, 42.50000000000025, 32.30000000000007, 76.69999999999985, 27.200000000000134, -103.90000000000062, 101.89999999999938, 15.799999999999962, 28.100000000000147, 36.2000000000001, 56.900000000000155, 20.000000000000014, 38.90000000000022, 67.70000000000012, 80.29999999999998, 72.19999999999989, 123.49999999999997, -71.5000000000004, 102.80000000000001, 13.699999999999964, 25.1000000000001, 13.999999999999945, 20.000000000000014, 107.30000000000007, 127.99999999999957, 42.200000000000216, 51.800000000000075, 20.000000000000014, 64.10000000000001, 23.60000000000011, 42.80000000000016, 53.00000000000019, -52.89999999999985, 124.69999999999956, 119.90000000000009, 168.49999999999991, -142.60000000000005, 88.69999999999956, -194.50000000000048, 58.70000000000022, 20.000000000000014, 20.000000000000014, 87.19999999999945, -188.80000000000035, 61.400000000000205, 20.000000000000014, 75.19999999999976, 51.50000000000019, 29.900000000000073, 114.19999999999948, 53.300000000000146, -41.79999999999977, 20.000000000000014, 40.70000000000025, 22.700000000000166, 20.000000000000014, 104.89999999999944, 182.8999999999999, -204.70000000000013, 29.900000000000183, -6.399999999999936, 112.69999999999979, 29.9, 74.90000000000006, 49.70000000000013, -80.80000000000062, -24.099999999999753, -20.199999999999882, 44.300000000000054, 56.00000000000023, -5.1999999999999265, 152.59999999999985, 104.89999999999972, 20.000000000000014, 20.000000000000014, 73.09999999999957, 15.799999999999963, 20.000000000000014, 11.89999999999997, -7.299999999999894, 31.700000000000212, 136.99999999999974, 55.100000000000115, 7.399999999999965, 46.70000000000018, 31.70000000000022, 20.000000000000014, 55.10000000000021, 8.299999999999969, 20.000000000000014, 38.90000000000019, 26.300000000000114, 20.000000000000014, 20.000000000000014, 24.20000000000009, 20.000000000000014, 20.000000000000014, 20.000000000000014, 98.89999999999966, 80.59999999999934, 71.29999999999964, 20.000000000000014, 10.399999999999963, 72.19999999999962, 20.000000000000014, 74.89999999999948, 92.29999999999964, -221.3999999999994, 32.60000000000023, 20.000000000000014, 20.000000000000014, 5.899999999999951, 81.19999999999925, 21.800000000000043, 29.000000000000163, 40.100000000000044, 26.300000000000118, -3.0999999999999757, 13.699999999999966, 38.00000000000017, 20.000000000000014, 34.40000000000026, 15.200000000000045, 20.000000000000014, 32.00000000000008, 56.000000000000156, 31.700000000000195, 20.000000000000014, 24.80000000000016, 128.59999999999968, -3.0999999999999615, 51.50000000000021, 24.500000000000064, 21.800000000000047, 41.600000000000186, 20.000000000000014, 20.000000000000014, 20.000000000000014, 25.4000000000001, 25.400000000000027, 22.100000000000044, 20.000000000000014, -9.399999999999862, 101.89999999999947, -17.79999999999974, 37.10000000000013, 38.000000000000256, 20.000000000000014, 136.99999999999963, 20.000000000000014, -45.69999999999992, 25.099999999999955, 58.70000000000022, 20.000000000000014, 32.3000000000002, 20.000000000000014, 20.000000000000014, 68.59999999999988, 29.60000000000018, 7.399999999999965, 29.900000000000173, -9.399999999999869, -21.99999999999975, 60.50000000000015, 62.9000000000002, 20.000000000000014, 20.900000000000013, 20.000000000000014, 20.000000000000014, 10.099999999999845, 20.000000000000014, 108.19999999999953, 50.60000000000004, 83.00000000000006, 20.000000000000014, 20.000000000000014, 27.200000000000056, 17.899999999999988, -110.20000000000076, 67.70000000000013, 20.000000000000014, 15.799999999999962, 20.000000000000014, -143.80000000000067, 1.399999999999969, 78.20000000000005, 97.39999999999938, 20.000000000000014, 5.299999999999969, 9.499999999999964, 8.600000000000106, 148.69999999999996, 48.49999999999997, 20.000000000000014, -5.19999999999998, -124.60000000000042, 73.99999999999964, 29.90000000000018, 9.79999999999997, -5.1999999999999265], "policy_predator_policy_reward": [0.0, 1.0, 18.0, 1.0, 38.0, 23.0, 0.0, 2.0, 0.0, 0.0, 1.0, 9.0, 0.0, 0.0, 0.0, 0.0, 2.0, 81.0, 0.0, 3.0, 0.0, 12.0, 6.0, 15.0, 0.0, 7.0, 21.0, 5.0, 5.0, 27.0, 5.0, 14.0, 35.0, 5.0, 0.0, 0.0, 83.0, 30.0, 31.0, 106.0, 0.0, 0.0, 66.0, 68.0, 0.0, 0.0, 21.0, 2.0, 1.0, 0.0, 32.0, 15.0, 0.0, 0.0, 18.0, 9.0, 2.0, 2.0, 69.0, 105.0, 6.0, 19.0, 18.0, 0.0, 25.0, 38.0, 30.0, 25.0, 0.0, 0.0, 17.0, 0.0, 0.0, 5.0, 14.0, 5.0, 2.0, 0.0, 9.0, 13.0, 0.0, 0.0, 0.0, 6.0, 9.0, 7.0, 0.0, 0.0, 3.0, 6.0, 7.0, 2.0, 0.0, 0.0, 1.0, 9.0, 0.0, 0.0, 1.0, 5.0, 9.0, 0.0, 8.0, 0.0, 0.0, 0.0, 209.0, 32.0, 9.0, 2.0, 23.0, 23.0, 0.0, 0.0, 8.0, 21.0, 11.0, 0.0, 0.0, 3.0, 0.0, 0.0, 28.0, 0.0, 23.0, 3.0, 0.0, 0.0, 15.0, 10.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 13.0, 36.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 53.0, 0.0, 0.0, 1.0, 13.0, 0.0, 0.0, 4.0, 6.0, 9.0, 14.0, 10.0, 13.0, 4.0, 0.0, 0.0, 0.0, 0.0, 36.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 62.0, 0.0, 2.0, 0.0, 78.0, 0.0, 17.0, 27.0, 0.0, 0.0, 0.0, 12.0, 29.0, 3.0, 13.0, 0.0, 44.0, 50.0, 0.0, 0.0, 15.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 10.079326084441513, "mean_inference_ms": 46.54280838348155, "mean_action_processing_ms": 10.112720327712719, "mean_env_wait_ms": 17.607445621740787, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01236581802368164, "StateBufferConnector_ms": 0.004448652267456055, "ViewRequirementAgentConnector_ms": 0.2179398536682129}, "num_episodes": 18, "episode_return_max": 291.8000000000004, "episode_return_min": -45.79999999999983, "episode_return_mean": 83.32399999999978, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 464000, "num_agent_steps_trained": 464000, "num_env_steps_sampled": 116000, "num_env_steps_trained": 116000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 198.74600078725007, "num_env_steps_trained_throughput_per_sec": 198.74600078725007, "timesteps_total": 116000, "num_env_steps_sampled_lifetime": 116000, "num_agent_steps_sampled_lifetime": 464000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 464000, "timers": {"training_iteration_time_ms": 111560.526, "restore_workers_time_ms": 0.04, "training_step_time_ms": 111560.436, "sample_time_ms": 3376.394, "learn_time_ms": 108154.697, "learn_throughput": 36.984, "synch_weights_time_ms": 24.522}, "counters": {"num_env_steps_sampled": 116000, "num_env_steps_trained": 116000, "num_agent_steps_sampled": 464000, "num_agent_steps_trained": 464000}, "done": false, "training_iteration": 29, "trial_id": "75ec3_00000", "date": "2024-08-13_02-16-10", "timestamp": 1723529770, "time_this_iter_s": 20.172123908996582, "time_total_s": 3426.5751044750214, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2071700>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3426.5751044750214, "iterations_since_restore": 29, "perf": {"cpu_util_percent": 86.55862068965519, "ram_util_percent": 83.5448275862069}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5728138216036969, "cur_kl_coeff": 0.12656249999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.9831499357072135, "policy_loss": -0.0007304015065538426, "vf_loss": 3.9834115352580155, "vf_explained_var": 0.06444136714809155, "kl": 0.003704124301417267, "entropy": 1.3952162805688444, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 55755.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.37128972380998587, "cur_kl_coeff": 0.0015625, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.9396455275949347, "policy_loss": -0.001955418290925168, "vf_loss": 0.9415902085168651, "vf_explained_var": 0.0006813181455803927, "kl": 0.006870169189483419, "entropy": 0.9295024149316959, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 55755.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 120000, "num_env_steps_trained": 120000, "num_agent_steps_sampled": 480000, "num_agent_steps_trained": 480000}, "env_runners": {"episode_reward_max": 291.8000000000004, "episode_reward_min": -83.90000000000028, "episode_reward_mean": 80.67599999999973, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -229.90000000000018, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 182.8999999999999, "predator_policy": 209.0}, "policy_reward_mean": {"prey_policy": 27.807999999999964, "predator_policy": 12.53}, "custom_metrics": {}, "hist_stats": {"episode_reward": [59.099999999999476, 1.2000000000000506, 40.0000000000003, 32.400000000000205, 81.39999999999921, 149.6999999999989, 145.0999999999988, 58.50000000000031, 60.70000000000051, 69.69999999999987, 291.8000000000004, -0.7999999999998787, 131.29999999999924, 122.79999999999977, 31.900000000000173, 10.700000000000006, 100.29999999999949, 164.3999999999993, 129.89999999999927, 112.09999999999901, 37.80000000000027, 26.60000000000009, 168.6999999999991, 68.49999999999996, 94.39999999999858, 75.09999999999965, 37.30000000000026, 74.19999999999969, 40.0000000000003, 54.20000000000043, 40.0000000000003, 185.499999999999, 100.29999999999913, 90.59999999999872, 94.89999999999893, 111.89999999999968, 63.6000000000005, 71.89999999999971, 102.9999999999985, 98.09999999999982, 34.200000000000216, 54.70000000000035, 54.40000000000052, 63.20000000000033, 113.99999999999896, 51.70000000000048, 178.399999999999, 59.40000000000043, 46.30000000000029, 61.60000000000038, 40.0000000000003, 50.800000000000374, 44.100000000000364, 106.49999999999886, 55.3000000000003, 58.00000000000052, 156.9999999999989, 33.39999999999997, 78.69999999999943, 66.30000000000027, 88.59999999999872, 47.00000000000042, 43.500000000000334, 61.5000000000003, 86.89999999999934, 40.9000000000003, 66.1000000000001, 128.1999999999989, 133.5999999999991, 40.0000000000003, 46.10000000000027, 19.50000000000022, 37.80000000000026, -45.79999999999983, 123.59999999999957, 117.39999999999867, 26.800000000000093, 189.29999999999973, 81.50000000000004, -35.79999999999966, 103.89999999999868, 19.60000000000006, 101.69999999999862, 165.99999999999977, 61.00000000000035, 40.0000000000003, 228.09999999999962, 179.49999999999872, -83.90000000000028, 210.99999999999915, 133.7999999999988, -48.7999999999998, 75.89999999999979, 130.99999999999898, 181.59999999999883, 110.29999999999876, 54.90000000000032, 99.39999999999907, 40.90000000000031, 128.19999999999925], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-142.60000000000005, 88.69999999999956, -194.50000000000048, 58.70000000000022, 20.000000000000014, 20.000000000000014, 87.19999999999945, -188.80000000000035, 61.400000000000205, 20.000000000000014, 75.19999999999976, 51.50000000000019, 29.900000000000073, 114.19999999999948, 53.300000000000146, -41.79999999999977, 20.000000000000014, 40.70000000000025, 22.700000000000166, 20.000000000000014, 104.89999999999944, 182.8999999999999, -204.70000000000013, 29.900000000000183, -6.399999999999936, 112.69999999999979, 29.9, 74.90000000000006, 49.70000000000013, -80.80000000000062, -24.099999999999753, -20.199999999999882, 44.300000000000054, 56.00000000000023, -5.1999999999999265, 152.59999999999985, 104.89999999999972, 20.000000000000014, 20.000000000000014, 73.09999999999957, 15.799999999999963, 20.000000000000014, 11.89999999999997, -7.299999999999894, 31.700000000000212, 136.99999999999974, 55.100000000000115, 7.399999999999965, 46.70000000000018, 31.70000000000022, 20.000000000000014, 55.10000000000021, 8.299999999999969, 20.000000000000014, 38.90000000000019, 26.300000000000114, 20.000000000000014, 20.000000000000014, 24.20000000000009, 20.000000000000014, 20.000000000000014, 20.000000000000014, 98.89999999999966, 80.59999999999934, 71.29999999999964, 20.000000000000014, 10.399999999999963, 72.19999999999962, 20.000000000000014, 74.89999999999948, 92.29999999999964, -221.3999999999994, 32.60000000000023, 20.000000000000014, 20.000000000000014, 5.899999999999951, 81.19999999999925, 21.800000000000043, 29.000000000000163, 40.100000000000044, 26.300000000000118, -3.0999999999999757, 13.699999999999966, 38.00000000000017, 20.000000000000014, 34.40000000000026, 15.200000000000045, 20.000000000000014, 32.00000000000008, 56.000000000000156, 31.700000000000195, 20.000000000000014, 24.80000000000016, 128.59999999999968, -3.0999999999999615, 51.50000000000021, 24.500000000000064, 21.800000000000047, 41.600000000000186, 20.000000000000014, 20.000000000000014, 20.000000000000014, 25.4000000000001, 25.400000000000027, 22.100000000000044, 20.000000000000014, -9.399999999999862, 101.89999999999947, -17.79999999999974, 37.10000000000013, 38.000000000000256, 20.000000000000014, 136.99999999999963, 20.000000000000014, -45.69999999999992, 25.099999999999955, 58.70000000000022, 20.000000000000014, 32.3000000000002, 20.000000000000014, 20.000000000000014, 68.59999999999988, 29.60000000000018, 7.399999999999965, 29.900000000000173, -9.399999999999869, -21.99999999999975, 60.50000000000015, 62.9000000000002, 20.000000000000014, 20.900000000000013, 20.000000000000014, 20.000000000000014, 10.099999999999845, 20.000000000000014, 108.19999999999953, 50.60000000000004, 83.00000000000006, 20.000000000000014, 20.000000000000014, 27.200000000000056, 17.899999999999988, -110.20000000000076, 67.70000000000013, 20.000000000000014, 15.799999999999962, 20.000000000000014, -143.80000000000067, 1.399999999999969, 78.20000000000005, 97.39999999999938, 20.000000000000014, 5.299999999999969, 9.499999999999964, 8.600000000000106, 148.69999999999996, 48.49999999999997, 20.000000000000014, -5.19999999999998, -124.60000000000042, 73.99999999999964, 29.90000000000018, 9.79999999999997, -5.1999999999999265, 26.30000000000004, 73.39999999999952, -6.699999999999827, 121.69999999999999, 0.8000000000000117, 30.200000000000113, 20.000000000000014, 20.000000000000014, 108.19999999999963, 119.89999999999995, 78.49999999999955, 100.99999999999937, -229.90000000000018, 20.000000000000014, 131.59999999999988, 79.39999999999932, 101.59999999999958, 15.199999999999958, -152.50000000000026, 1.7000000000000266, 80.89999999999972, -157.00000000000014, 59.30000000000016, 58.699999999999996, 104.59999999999965, 65.00000000000014, 72.79999999999954, 33.50000000000024, 11.29999999999996, 23.600000000000065, 54.20000000000011, 36.20000000000026, 20.000000000000014, 20.90000000000003, 9.199999999999985, 109.99999999999974], "policy_predator_policy_reward": [83.0, 30.0, 31.0, 106.0, 0.0, 0.0, 66.0, 68.0, 0.0, 0.0, 21.0, 2.0, 1.0, 0.0, 32.0, 15.0, 0.0, 0.0, 18.0, 9.0, 2.0, 2.0, 69.0, 105.0, 6.0, 19.0, 18.0, 0.0, 25.0, 38.0, 30.0, 25.0, 0.0, 0.0, 17.0, 0.0, 0.0, 5.0, 14.0, 5.0, 2.0, 0.0, 9.0, 13.0, 0.0, 0.0, 0.0, 6.0, 9.0, 7.0, 0.0, 0.0, 3.0, 6.0, 7.0, 2.0, 0.0, 0.0, 1.0, 9.0, 0.0, 0.0, 1.0, 5.0, 9.0, 0.0, 8.0, 0.0, 0.0, 0.0, 209.0, 32.0, 9.0, 2.0, 23.0, 23.0, 0.0, 0.0, 8.0, 21.0, 11.0, 0.0, 0.0, 3.0, 0.0, 0.0, 28.0, 0.0, 23.0, 3.0, 0.0, 0.0, 15.0, 10.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 13.0, 36.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 53.0, 0.0, 0.0, 1.0, 13.0, 0.0, 0.0, 4.0, 6.0, 9.0, 14.0, 10.0, 13.0, 4.0, 0.0, 0.0, 0.0, 0.0, 36.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 62.0, 0.0, 2.0, 0.0, 78.0, 0.0, 17.0, 27.0, 0.0, 0.0, 0.0, 12.0, 29.0, 3.0, 13.0, 0.0, 44.0, 50.0, 0.0, 0.0, 15.0, 0.0, 2.0, 0.0, 29.0, 22.0, 20.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 46.0, 80.0, 0.0, 0.0, 0.0, 17.0, 54.0, 48.0, 99.0, 53.0, 13.0, 0.0, 0.0, 12.0, 4.0, 0.0, 0.0, 20.0, 0.0, 9.0, 0.0, 0.0, 9.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 9.790346145348476, "mean_inference_ms": 45.12236500136923, "mean_action_processing_ms": 9.839923716563947, "mean_env_wait_ms": 17.047234168369435, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.011921167373657227, "StateBufferConnector_ms": 0.004701137542724609, "ViewRequirementAgentConnector_ms": 0.22947824001312256}, "num_episodes": 18, "episode_return_max": 291.8000000000004, "episode_return_min": -83.90000000000028, "episode_return_mean": 80.67599999999973, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 480000, "num_agent_steps_trained": 480000, "num_env_steps_sampled": 120000, "num_env_steps_trained": 120000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 205.63998612594526, "num_env_steps_trained_throughput_per_sec": 205.63998612594526, "timesteps_total": 120000, "num_env_steps_sampled_lifetime": 120000, "num_agent_steps_sampled_lifetime": 480000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 480000, "timers": {"training_iteration_time_ms": 18886.067, "restore_workers_time_ms": 0.041, "training_step_time_ms": 18885.977, "sample_time_ms": 3329.856, "learn_time_ms": 15531.673, "learn_throughput": 257.538, "synch_weights_time_ms": 20.119}, "counters": {"num_env_steps_sampled": 120000, "num_env_steps_trained": 120000, "num_agent_steps_sampled": 480000, "num_agent_steps_trained": 480000}, "done": false, "training_iteration": 30, "trial_id": "75ec3_00000", "date": "2024-08-13_02-16-29", "timestamp": 1723529789, "time_this_iter_s": 19.498568058013916, "time_total_s": 3446.0736725330353, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b208eaf0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3446.0736725330353, "iterations_since_restore": 30, "perf": {"cpu_util_percent": 83.84074074074073, "ram_util_percent": 83.57407407407408}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.125934742414762, "cur_kl_coeff": 0.06328124999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.906410038282001, "policy_loss": -0.006418857041613332, "vf_loss": 2.911967258857041, "vf_explained_var": 0.10636113191407824, "kl": 0.01361580372128906, "entropy": 1.378912410534248, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 57645.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.28126566087206206, "cur_kl_coeff": 0.0015625, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.2715611416156645, "policy_loss": -0.0010315559065294643, "vf_loss": 0.2725877263861654, "vf_explained_var": -0.008020786412809261, "kl": 0.0031818460566449226, "entropy": 0.915594110034761, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 57645.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 124000, "num_env_steps_trained": 124000, "num_agent_steps_sampled": 496000, "num_agent_steps_trained": 496000}, "env_runners": {"episode_reward_max": 228.09999999999962, "episode_reward_min": -83.90000000000028, "episode_reward_mean": 81.6519999999997, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -229.90000000000018, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 163.09999999999985, "predator_policy": 209.0}, "policy_reward_mean": {"prey_policy": 31.98099999999996, "predator_policy": 8.845}, "custom_metrics": {}, "hist_stats": {"episode_reward": [129.89999999999927, 112.09999999999901, 37.80000000000027, 26.60000000000009, 168.6999999999991, 68.49999999999996, 94.39999999999858, 75.09999999999965, 37.30000000000026, 74.19999999999969, 40.0000000000003, 54.20000000000043, 40.0000000000003, 185.499999999999, 100.29999999999913, 90.59999999999872, 94.89999999999893, 111.89999999999968, 63.6000000000005, 71.89999999999971, 102.9999999999985, 98.09999999999982, 34.200000000000216, 54.70000000000035, 54.40000000000052, 63.20000000000033, 113.99999999999896, 51.70000000000048, 178.399999999999, 59.40000000000043, 46.30000000000029, 61.60000000000038, 40.0000000000003, 50.800000000000374, 44.100000000000364, 106.49999999999886, 55.3000000000003, 58.00000000000052, 156.9999999999989, 33.39999999999997, 78.69999999999943, 66.30000000000027, 88.59999999999872, 47.00000000000042, 43.500000000000334, 61.5000000000003, 86.89999999999934, 40.9000000000003, 66.1000000000001, 128.1999999999989, 133.5999999999991, 40.0000000000003, 46.10000000000027, 19.50000000000022, 37.80000000000026, -45.79999999999983, 123.59999999999957, 117.39999999999867, 26.800000000000093, 189.29999999999973, 81.50000000000004, -35.79999999999966, 103.89999999999868, 19.60000000000006, 101.69999999999862, 165.99999999999977, 61.00000000000035, 40.0000000000003, 228.09999999999962, 179.49999999999872, -83.90000000000028, 210.99999999999915, 133.7999999999988, -48.7999999999998, 75.89999999999979, 130.99999999999898, 181.59999999999883, 110.29999999999876, 54.90000000000032, 99.39999999999907, 40.90000000000031, 128.19999999999925, 170.49999999999875, 176.49999999999923, 40.0000000000003, 40.0000000000003, 40.0000000000003, 67.10000000000008, 105.69999999999906, 101.09999999999945, 85.89999999999888, 133.79999999999936, 22.300000000000118, 40.0000000000003, 156.3999999999989, 51.70000000000049, 41.800000000000125, 193.39999999999884, 40.0000000000003, 141.59999999999945], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [104.89999999999972, 20.000000000000014, 20.000000000000014, 73.09999999999957, 15.799999999999963, 20.000000000000014, 11.89999999999997, -7.299999999999894, 31.700000000000212, 136.99999999999974, 55.100000000000115, 7.399999999999965, 46.70000000000018, 31.70000000000022, 20.000000000000014, 55.10000000000021, 8.299999999999969, 20.000000000000014, 38.90000000000019, 26.300000000000114, 20.000000000000014, 20.000000000000014, 24.20000000000009, 20.000000000000014, 20.000000000000014, 20.000000000000014, 98.89999999999966, 80.59999999999934, 71.29999999999964, 20.000000000000014, 10.399999999999963, 72.19999999999962, 20.000000000000014, 74.89999999999948, 92.29999999999964, -221.3999999999994, 32.60000000000023, 20.000000000000014, 20.000000000000014, 5.899999999999951, 81.19999999999925, 21.800000000000043, 29.000000000000163, 40.100000000000044, 26.300000000000118, -3.0999999999999757, 13.699999999999966, 38.00000000000017, 20.000000000000014, 34.40000000000026, 15.200000000000045, 20.000000000000014, 32.00000000000008, 56.000000000000156, 31.700000000000195, 20.000000000000014, 24.80000000000016, 128.59999999999968, -3.0999999999999615, 51.50000000000021, 24.500000000000064, 21.800000000000047, 41.600000000000186, 20.000000000000014, 20.000000000000014, 20.000000000000014, 25.4000000000001, 25.400000000000027, 22.100000000000044, 20.000000000000014, -9.399999999999862, 101.89999999999947, -17.79999999999974, 37.10000000000013, 38.000000000000256, 20.000000000000014, 136.99999999999963, 20.000000000000014, -45.69999999999992, 25.099999999999955, 58.70000000000022, 20.000000000000014, 32.3000000000002, 20.000000000000014, 20.000000000000014, 68.59999999999988, 29.60000000000018, 7.399999999999965, 29.900000000000173, -9.399999999999869, -21.99999999999975, 60.50000000000015, 62.9000000000002, 20.000000000000014, 20.900000000000013, 20.000000000000014, 20.000000000000014, 10.099999999999845, 20.000000000000014, 108.19999999999953, 50.60000000000004, 83.00000000000006, 20.000000000000014, 20.000000000000014, 27.200000000000056, 17.899999999999988, -110.20000000000076, 67.70000000000013, 20.000000000000014, 15.799999999999962, 20.000000000000014, -143.80000000000067, 1.399999999999969, 78.20000000000005, 97.39999999999938, 20.000000000000014, 5.299999999999969, 9.499999999999964, 8.600000000000106, 148.69999999999996, 48.49999999999997, 20.000000000000014, -5.19999999999998, -124.60000000000042, 73.99999999999964, 29.90000000000018, 9.79999999999997, -5.1999999999999265, 26.30000000000004, 73.39999999999952, -6.699999999999827, 121.69999999999999, 0.8000000000000117, 30.200000000000113, 20.000000000000014, 20.000000000000014, 108.19999999999963, 119.89999999999995, 78.49999999999955, 100.99999999999937, -229.90000000000018, 20.000000000000014, 131.59999999999988, 79.39999999999932, 101.59999999999958, 15.199999999999958, -152.50000000000026, 1.7000000000000266, 80.89999999999972, -157.00000000000014, 59.30000000000016, 58.699999999999996, 104.59999999999965, 65.00000000000014, 72.79999999999954, 33.50000000000024, 11.29999999999996, 23.600000000000065, 54.20000000000011, 36.20000000000026, 20.000000000000014, 20.90000000000003, 9.199999999999985, 109.99999999999974, 85.69999999999929, 84.79999999999943, 7.399999999999965, 163.09999999999985, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 11.599999999999964, 51.500000000000135, 34.400000000000155, 71.29999999999964, 53.30000000000007, 15.799999999999963, 34.40000000000024, 51.500000000000185, 107.2999999999998, 9.499999999999961, -5.1999999999999265, 9.499999999999968, 20.000000000000014, 20.000000000000014, 138.7999999999996, 14.599999999999964, 31.700000000000212, 20.000000000000014, 9.499999999999964, 23.299999999999976, 99.19999999999936, 87.19999999999953, 20.000000000000014, 20.000000000000014, 56.3000000000002, 80.29999999999993], "policy_predator_policy_reward": [0.0, 5.0, 14.0, 5.0, 2.0, 0.0, 9.0, 13.0, 0.0, 0.0, 0.0, 6.0, 9.0, 7.0, 0.0, 0.0, 3.0, 6.0, 7.0, 2.0, 0.0, 0.0, 1.0, 9.0, 0.0, 0.0, 1.0, 5.0, 9.0, 0.0, 8.0, 0.0, 0.0, 0.0, 209.0, 32.0, 9.0, 2.0, 23.0, 23.0, 0.0, 0.0, 8.0, 21.0, 11.0, 0.0, 0.0, 3.0, 0.0, 0.0, 28.0, 0.0, 23.0, 3.0, 0.0, 0.0, 15.0, 10.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 13.0, 36.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 53.0, 0.0, 0.0, 1.0, 13.0, 0.0, 0.0, 4.0, 6.0, 9.0, 14.0, 10.0, 13.0, 4.0, 0.0, 0.0, 0.0, 0.0, 36.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 62.0, 0.0, 2.0, 0.0, 78.0, 0.0, 17.0, 27.0, 0.0, 0.0, 0.0, 12.0, 29.0, 3.0, 13.0, 0.0, 44.0, 50.0, 0.0, 0.0, 15.0, 0.0, 2.0, 0.0, 29.0, 22.0, 20.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 46.0, 80.0, 0.0, 0.0, 0.0, 17.0, 54.0, 48.0, 99.0, 53.0, 13.0, 0.0, 0.0, 12.0, 4.0, 0.0, 0.0, 20.0, 0.0, 9.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 32.0, 0.0, 0.0, 0.0, 17.0, 0.0, 6.0, 12.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 4.0, 5.0, 7.0, 0.0, 0.0, 0.0, 0.0, 5.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 9.524465312684832, "mean_inference_ms": 43.806926929688636, "mean_action_processing_ms": 9.588735753972415, "mean_env_wait_ms": 16.526602621019016, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.010553121566772461, "StateBufferConnector_ms": 0.004925847053527832, "ViewRequirementAgentConnector_ms": 0.26578807830810547}, "num_episodes": 18, "episode_return_max": 228.09999999999962, "episode_return_min": -83.90000000000028, "episode_return_mean": 81.6519999999997, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 496000, "num_agent_steps_trained": 496000, "num_env_steps_sampled": 124000, "num_env_steps_trained": 124000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 210.43195491202528, "num_env_steps_trained_throughput_per_sec": 210.43195491202528, "timesteps_total": 124000, "num_env_steps_sampled_lifetime": 124000, "num_agent_steps_sampled_lifetime": 496000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 496000, "timers": {"training_iteration_time_ms": 18992.557, "restore_workers_time_ms": 0.02, "training_step_time_ms": 18992.493, "sample_time_ms": 3067.227, "learn_time_ms": 15902.273, "learn_throughput": 251.536, "synch_weights_time_ms": 19.373}, "counters": {"num_env_steps_sampled": 124000, "num_env_steps_trained": 124000, "num_agent_steps_sampled": 496000, "num_agent_steps_trained": 496000}, "done": false, "training_iteration": 31, "trial_id": "75ec3_00000", "date": "2024-08-13_02-16-48", "timestamp": 1723529808, "time_this_iter_s": 19.052491188049316, "time_total_s": 3465.1261637210846, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b1afe8b0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3465.1261637210846, "iterations_since_restore": 31, "perf": {"cpu_util_percent": 82.21111111111111, "ram_util_percent": 83.60370370370372}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5935523414422594, "cur_kl_coeff": 0.06328124999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.776030130739565, "policy_loss": -0.007527111528598994, "vf_loss": 5.781950917067351, "vf_explained_var": 0.05138881903476816, "kl": 0.02538389501482997, "entropy": 1.3418775297977306, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 59535.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4707877789954187, "cur_kl_coeff": 0.00078125, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.293750829797573, "policy_loss": -0.002300575136936334, "vf_loss": 2.296044629086893, "vf_explained_var": -0.00016991568620873507, "kl": 0.00867991407190732, "entropy": 0.9963641358431055, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 59535.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 128000, "num_env_steps_trained": 128000, "num_agent_steps_sampled": 512000, "num_agent_steps_trained": 512000}, "env_runners": {"episode_reward_max": 301.0000000000007, "episode_reward_min": -83.90000000000028, "episode_reward_mean": 87.10899999999975, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -276.10000000000036, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 116.0}, "policy_reward_mean": {"prey_policy": 32.99449999999995, "predator_policy": 10.56}, "custom_metrics": {}, "hist_stats": {"episode_reward": [51.70000000000048, 178.399999999999, 59.40000000000043, 46.30000000000029, 61.60000000000038, 40.0000000000003, 50.800000000000374, 44.100000000000364, 106.49999999999886, 55.3000000000003, 58.00000000000052, 156.9999999999989, 33.39999999999997, 78.69999999999943, 66.30000000000027, 88.59999999999872, 47.00000000000042, 43.500000000000334, 61.5000000000003, 86.89999999999934, 40.9000000000003, 66.1000000000001, 128.1999999999989, 133.5999999999991, 40.0000000000003, 46.10000000000027, 19.50000000000022, 37.80000000000026, -45.79999999999983, 123.59999999999957, 117.39999999999867, 26.800000000000093, 189.29999999999973, 81.50000000000004, -35.79999999999966, 103.89999999999868, 19.60000000000006, 101.69999999999862, 165.99999999999977, 61.00000000000035, 40.0000000000003, 228.09999999999962, 179.49999999999872, -83.90000000000028, 210.99999999999915, 133.7999999999988, -48.7999999999998, 75.89999999999979, 130.99999999999898, 181.59999999999883, 110.29999999999876, 54.90000000000032, 99.39999999999907, 40.90000000000031, 128.19999999999925, 170.49999999999875, 176.49999999999923, 40.0000000000003, 40.0000000000003, 40.0000000000003, 67.10000000000008, 105.69999999999906, 101.09999999999945, 85.89999999999888, 133.79999999999936, 22.300000000000118, 40.0000000000003, 156.3999999999989, 51.70000000000049, 41.800000000000125, 193.39999999999884, 40.0000000000003, 141.59999999999945, 66.00000000000028, 15.200000000000014, 263.40000000000055, 66.1000000000004, 37.20000000000007, -9.300000000000045, 40.90000000000031, 229.99999999999915, 209.89999999999952, 62.500000000000306, 131.79999999999927, -49.49999999999995, 40.0000000000003, 33.200000000000195, 107.39999999999952, 97.49999999999892, 17.900000000000237, 237.09999999999937, 132.49999999999858, 179.59999999999923, 54.60000000000035, 90.20000000000007, 50.80000000000048, 237.9999999999991, 124.29999999999936, -23.500000000000092, 301.0000000000007], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [31.700000000000195, 20.000000000000014, 24.80000000000016, 128.59999999999968, -3.0999999999999615, 51.50000000000021, 24.500000000000064, 21.800000000000047, 41.600000000000186, 20.000000000000014, 20.000000000000014, 20.000000000000014, 25.4000000000001, 25.400000000000027, 22.100000000000044, 20.000000000000014, -9.399999999999862, 101.89999999999947, -17.79999999999974, 37.10000000000013, 38.000000000000256, 20.000000000000014, 136.99999999999963, 20.000000000000014, -45.69999999999992, 25.099999999999955, 58.70000000000022, 20.000000000000014, 32.3000000000002, 20.000000000000014, 20.000000000000014, 68.59999999999988, 29.60000000000018, 7.399999999999965, 29.900000000000173, -9.399999999999869, -21.99999999999975, 60.50000000000015, 62.9000000000002, 20.000000000000014, 20.900000000000013, 20.000000000000014, 20.000000000000014, 10.099999999999845, 20.000000000000014, 108.19999999999953, 50.60000000000004, 83.00000000000006, 20.000000000000014, 20.000000000000014, 27.200000000000056, 17.899999999999988, -110.20000000000076, 67.70000000000013, 20.000000000000014, 15.799999999999962, 20.000000000000014, -143.80000000000067, 1.399999999999969, 78.20000000000005, 97.39999999999938, 20.000000000000014, 5.299999999999969, 9.499999999999964, 8.600000000000106, 148.69999999999996, 48.49999999999997, 20.000000000000014, -5.19999999999998, -124.60000000000042, 73.99999999999964, 29.90000000000018, 9.79999999999997, -5.1999999999999265, 26.30000000000004, 73.39999999999952, -6.699999999999827, 121.69999999999999, 0.8000000000000117, 30.200000000000113, 20.000000000000014, 20.000000000000014, 108.19999999999963, 119.89999999999995, 78.49999999999955, 100.99999999999937, -229.90000000000018, 20.000000000000014, 131.59999999999988, 79.39999999999932, 101.59999999999958, 15.199999999999958, -152.50000000000026, 1.7000000000000266, 80.89999999999972, -157.00000000000014, 59.30000000000016, 58.699999999999996, 104.59999999999965, 65.00000000000014, 72.79999999999954, 33.50000000000024, 11.29999999999996, 23.600000000000065, 54.20000000000011, 36.20000000000026, 20.000000000000014, 20.90000000000003, 9.199999999999985, 109.99999999999974, 85.69999999999929, 84.79999999999943, 7.399999999999965, 163.09999999999985, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 11.599999999999964, 51.500000000000135, 34.400000000000155, 71.29999999999964, 53.30000000000007, 15.799999999999963, 34.40000000000024, 51.500000000000185, 107.2999999999998, 9.499999999999961, -5.1999999999999265, 9.499999999999968, 20.000000000000014, 20.000000000000014, 138.7999999999996, 14.599999999999964, 31.700000000000212, 20.000000000000014, 9.499999999999964, 23.299999999999976, 99.19999999999936, 87.19999999999953, 20.000000000000014, 20.000000000000014, 56.3000000000002, 80.29999999999993, 50.900000000000205, 1.0999999999999865, 20.000000000000014, -98.80000000000047, 89.59999999999984, 156.79999999999978, 20.000000000000014, 46.100000000000186, -110.50000000000041, 22.700000000000195, -276.10000000000036, 42.80000000000015, 20.90000000000003, 20.000000000000014, 71.89999999999989, 151.09999999999982, 55.99999999999996, 143.89999999999992, 42.50000000000014, 20.000000000000014, 26.30000000000013, 105.50000000000009, -212.5000000000004, 35.000000000000085, 20.000000000000014, 20.000000000000014, 20.000000000000014, -11.799999999999889, 23.60000000000008, 69.79999999999987, 20.90000000000003, 62.60000000000015, -89.2000000000007, 55.100000000000016, 200.0, 37.10000000000009, 61.10000000000016, 61.40000000000022, 5.299999999999965, 161.29999999999987, 26.60000000000013, 20.000000000000014, 69.19999999999996, 20.000000000000014, 20.000000000000014, 30.800000000000196, 125.2999999999996, 112.6999999999995, 83.89999999999984, 34.400000000000084, 28.100000000000154, -148.60000000000022, 176.60000000000002, 124.3999999999996], "policy_predator_policy_reward": [0.0, 0.0, 15.0, 10.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 13.0, 36.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 53.0, 0.0, 0.0, 1.0, 13.0, 0.0, 0.0, 4.0, 6.0, 9.0, 14.0, 10.0, 13.0, 4.0, 0.0, 0.0, 0.0, 0.0, 36.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 62.0, 0.0, 2.0, 0.0, 78.0, 0.0, 17.0, 27.0, 0.0, 0.0, 0.0, 12.0, 29.0, 3.0, 13.0, 0.0, 44.0, 50.0, 0.0, 0.0, 15.0, 0.0, 2.0, 0.0, 29.0, 22.0, 20.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 46.0, 80.0, 0.0, 0.0, 0.0, 17.0, 54.0, 48.0, 99.0, 53.0, 13.0, 0.0, 0.0, 12.0, 4.0, 0.0, 0.0, 20.0, 0.0, 9.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 32.0, 0.0, 0.0, 0.0, 17.0, 0.0, 6.0, 12.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 4.0, 5.0, 7.0, 0.0, 0.0, 0.0, 0.0, 5.0, 9.0, 5.0, 45.0, 49.0, 17.0, 0.0, 0.0, 0.0, 56.0, 69.0, 108.0, 116.0, 0.0, 0.0, 0.0, 7.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 24.0, 104.0, 0.0, 0.0, 25.0, 0.0, 8.0, 6.0, 0.0, 14.0, 52.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 13.0, 0.0, 8.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 97.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 16.429649163384386, "mean_inference_ms": 51.4954460339577, "mean_action_processing_ms": 11.41314298575658, "mean_env_wait_ms": 16.47155994942463, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.010432243347167969, "StateBufferConnector_ms": 0.0061533451080322266, "ViewRequirementAgentConnector_ms": 0.41422736644744873}, "num_episodes": 27, "episode_return_max": 301.0000000000007, "episode_return_min": -83.90000000000028, "episode_return_mean": 87.10899999999975, "episodes_this_iter": 27}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 512000, "num_agent_steps_trained": 512000, "num_env_steps_sampled": 128000, "num_env_steps_trained": 128000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 3.78820021038093, "num_env_steps_trained_throughput_per_sec": 3.78820021038093, "timesteps_total": 128000, "num_env_steps_sampled_lifetime": 128000, "num_agent_steps_sampled_lifetime": 512000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 512000, "timers": {"training_iteration_time_ms": 123006.93, "restore_workers_time_ms": 0.018, "training_step_time_ms": 123006.869, "sample_time_ms": 105793.953, "learn_time_ms": 17189.647, "learn_throughput": 232.698, "synch_weights_time_ms": 18.769}, "counters": {"num_env_steps_sampled": 128000, "num_env_steps_trained": 128000, "num_agent_steps_sampled": 512000, "num_agent_steps_trained": 512000}, "done": false, "training_iteration": 32, "trial_id": "75ec3_00000", "date": "2024-08-13_02-34-24", "timestamp": 1723530864, "time_this_iter_s": 1056.0178220272064, "time_total_s": 4521.143985748291, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2071160>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 4521.143985748291, "iterations_since_restore": 32, "perf": {"cpu_util_percent": 94.81860465116279, "ram_util_percent": 83.47441860465116}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.185732895151648, "cur_kl_coeff": 0.09492187500000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.9095747957784663, "policy_loss": -0.0010686985781248758, "vf_loss": 1.910160786859573, "vf_explained_var": 0.11260375020995973, "kl": 0.005085358886632162, "entropy": 1.329756475567187, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 61425.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.42128239621718727, "cur_kl_coeff": 0.00078125, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.4696447946407177, "policy_loss": -0.0011362644612158417, "vf_loss": 0.47077658390158184, "vf_explained_var": 0.026843875457370093, "kl": 0.00572885426941407, "entropy": 1.087893578015938, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 61425.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 132000, "num_env_steps_trained": 132000, "num_agent_steps_sampled": 528000, "num_agent_steps_trained": 528000}, "env_runners": {"episode_reward_max": 301.0000000000007, "episode_reward_min": -83.90000000000028, "episode_reward_mean": 86.89499999999971, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -276.10000000000036, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 116.0}, "policy_reward_mean": {"prey_policy": 32.51749999999995, "predator_policy": 10.93}, "custom_metrics": {}, "hist_stats": {"episode_reward": [61.5000000000003, 86.89999999999934, 40.9000000000003, 66.1000000000001, 128.1999999999989, 133.5999999999991, 40.0000000000003, 46.10000000000027, 19.50000000000022, 37.80000000000026, -45.79999999999983, 123.59999999999957, 117.39999999999867, 26.800000000000093, 189.29999999999973, 81.50000000000004, -35.79999999999966, 103.89999999999868, 19.60000000000006, 101.69999999999862, 165.99999999999977, 61.00000000000035, 40.0000000000003, 228.09999999999962, 179.49999999999872, -83.90000000000028, 210.99999999999915, 133.7999999999988, -48.7999999999998, 75.89999999999979, 130.99999999999898, 181.59999999999883, 110.29999999999876, 54.90000000000032, 99.39999999999907, 40.90000000000031, 128.19999999999925, 170.49999999999875, 176.49999999999923, 40.0000000000003, 40.0000000000003, 40.0000000000003, 67.10000000000008, 105.69999999999906, 101.09999999999945, 85.89999999999888, 133.79999999999936, 22.300000000000118, 40.0000000000003, 156.3999999999989, 51.70000000000049, 41.800000000000125, 193.39999999999884, 40.0000000000003, 141.59999999999945, 66.00000000000028, 15.200000000000014, 263.40000000000055, 66.1000000000004, 37.20000000000007, -9.300000000000045, 40.90000000000031, 229.99999999999915, 209.89999999999952, 62.500000000000306, 131.79999999999927, -49.49999999999995, 40.0000000000003, 33.200000000000195, 107.39999999999952, 97.49999999999892, 17.900000000000237, 237.09999999999937, 132.49999999999858, 179.59999999999923, 54.60000000000035, 90.20000000000007, 50.80000000000048, 237.9999999999991, 124.29999999999936, -23.500000000000092, 301.0000000000007, 90.19999999999987, 62.200000000000365, 140.39999999999887, 142.89999999999876, 67.00000000000016, 40.0000000000003, 66.40000000000016, 40.0000000000003, 60.60000000000045, 94.99999999999875, 13.899999999999965, 48.000000000000405, 75.29999999999961, 79.5999999999993, 113.99999999999886, 27.90000000000011, 40.90000000000031, 40.90000000000031], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-21.99999999999975, 60.50000000000015, 62.9000000000002, 20.000000000000014, 20.900000000000013, 20.000000000000014, 20.000000000000014, 10.099999999999845, 20.000000000000014, 108.19999999999953, 50.60000000000004, 83.00000000000006, 20.000000000000014, 20.000000000000014, 27.200000000000056, 17.899999999999988, -110.20000000000076, 67.70000000000013, 20.000000000000014, 15.799999999999962, 20.000000000000014, -143.80000000000067, 1.399999999999969, 78.20000000000005, 97.39999999999938, 20.000000000000014, 5.299999999999969, 9.499999999999964, 8.600000000000106, 148.69999999999996, 48.49999999999997, 20.000000000000014, -5.19999999999998, -124.60000000000042, 73.99999999999964, 29.90000000000018, 9.79999999999997, -5.1999999999999265, 26.30000000000004, 73.39999999999952, -6.699999999999827, 121.69999999999999, 0.8000000000000117, 30.200000000000113, 20.000000000000014, 20.000000000000014, 108.19999999999963, 119.89999999999995, 78.49999999999955, 100.99999999999937, -229.90000000000018, 20.000000000000014, 131.59999999999988, 79.39999999999932, 101.59999999999958, 15.199999999999958, -152.50000000000026, 1.7000000000000266, 80.89999999999972, -157.00000000000014, 59.30000000000016, 58.699999999999996, 104.59999999999965, 65.00000000000014, 72.79999999999954, 33.50000000000024, 11.29999999999996, 23.600000000000065, 54.20000000000011, 36.20000000000026, 20.000000000000014, 20.90000000000003, 9.199999999999985, 109.99999999999974, 85.69999999999929, 84.79999999999943, 7.399999999999965, 163.09999999999985, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 11.599999999999964, 51.500000000000135, 34.400000000000155, 71.29999999999964, 53.30000000000007, 15.799999999999963, 34.40000000000024, 51.500000000000185, 107.2999999999998, 9.499999999999961, -5.1999999999999265, 9.499999999999968, 20.000000000000014, 20.000000000000014, 138.7999999999996, 14.599999999999964, 31.700000000000212, 20.000000000000014, 9.499999999999964, 23.299999999999976, 99.19999999999936, 87.19999999999953, 20.000000000000014, 20.000000000000014, 56.3000000000002, 80.29999999999993, 50.900000000000205, 1.0999999999999865, 20.000000000000014, -98.80000000000047, 89.59999999999984, 156.79999999999978, 20.000000000000014, 46.100000000000186, -110.50000000000041, 22.700000000000195, -276.10000000000036, 42.80000000000015, 20.90000000000003, 20.000000000000014, 71.89999999999989, 151.09999999999982, 55.99999999999996, 143.89999999999992, 42.50000000000014, 20.000000000000014, 26.30000000000013, 105.50000000000009, -212.5000000000004, 35.000000000000085, 20.000000000000014, 20.000000000000014, 20.000000000000014, -11.799999999999889, 23.60000000000008, 69.79999999999987, 20.90000000000003, 62.60000000000015, -89.2000000000007, 55.100000000000016, 200.0, 37.10000000000009, 61.10000000000016, 61.40000000000022, 5.299999999999965, 161.29999999999987, 26.60000000000013, 20.000000000000014, 69.19999999999996, 20.000000000000014, 20.000000000000014, 30.800000000000196, 125.2999999999996, 112.6999999999995, 83.89999999999984, 34.400000000000084, 28.100000000000154, -148.60000000000022, 176.60000000000002, 124.3999999999996, 54.2000000000002, -18.99999999999988, 33.500000000000135, 13.69999999999997, 75.79999999999957, 53.60000000000019, 70.39999999999971, 60.500000000000135, 20.000000000000014, 47.00000000000018, 20.000000000000014, 20.000000000000014, 69.49999999999976, -24.099999999999774, 20.000000000000014, 20.000000000000014, 41.30000000000022, 5.299999999999965, 41.300000000000225, 49.700000000000166, -78.70000000000078, 11.599999999999964, 26.00000000000012, 7.999999999999966, 20.000000000000014, 38.300000000000175, 20.000000000000014, 59.600000000000186, 85.99999999999949, 20.000000000000014, 20.000000000000014, -3.0999999999999615, 20.000000000000014, 20.900000000000027, 20.90000000000003, 20.000000000000014], "policy_predator_policy_reward": [10.0, 13.0, 4.0, 0.0, 0.0, 0.0, 0.0, 36.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 62.0, 0.0, 2.0, 0.0, 78.0, 0.0, 17.0, 27.0, 0.0, 0.0, 0.0, 12.0, 29.0, 3.0, 13.0, 0.0, 44.0, 50.0, 0.0, 0.0, 15.0, 0.0, 2.0, 0.0, 29.0, 22.0, 20.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 46.0, 80.0, 0.0, 0.0, 0.0, 17.0, 54.0, 48.0, 99.0, 53.0, 13.0, 0.0, 0.0, 12.0, 4.0, 0.0, 0.0, 20.0, 0.0, 9.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 32.0, 0.0, 0.0, 0.0, 17.0, 0.0, 6.0, 12.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 4.0, 5.0, 7.0, 0.0, 0.0, 0.0, 0.0, 5.0, 9.0, 5.0, 45.0, 49.0, 17.0, 0.0, 0.0, 0.0, 56.0, 69.0, 108.0, 116.0, 0.0, 0.0, 0.0, 7.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 24.0, 104.0, 0.0, 0.0, 25.0, 0.0, 8.0, 6.0, 0.0, 14.0, 52.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 13.0, 0.0, 8.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 97.0, 0.0, 0.0, 25.0, 30.0, 12.0, 3.0, 0.0, 11.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 21.0, 0.0, 0.0, 0.0, 7.0, 7.0, 1.0, 3.0, 43.0, 38.0, 0.0, 14.0, 17.0, 0.0, 0.0, 0.0, 8.0, 0.0, 5.0, 6.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 19.649187707411784, "mean_inference_ms": 55.211019713615826, "mean_action_processing_ms": 12.579996779385233, "mean_env_wait_ms": 18.909452574669427, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006840348243713379, "StateBufferConnector_ms": 0.005811572074890137, "ViewRequirementAgentConnector_ms": 0.3768090009689331}, "num_episodes": 18, "episode_return_max": 301.0000000000007, "episode_return_min": -83.90000000000028, "episode_return_mean": 86.89499999999971, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 528000, "num_agent_steps_trained": 528000, "num_env_steps_sampled": 132000, "num_env_steps_trained": 132000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 243.95682079482862, "num_env_steps_trained_throughput_per_sec": 243.95682079482862, "timesteps_total": 132000, "num_env_steps_sampled_lifetime": 132000, "num_agent_steps_sampled_lifetime": 528000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 528000, "timers": {"training_iteration_time_ms": 122921.74, "restore_workers_time_ms": 0.018, "training_step_time_ms": 122921.214, "sample_time_ms": 105673.247, "learn_time_ms": 17223.948, "learn_throughput": 232.235, "synch_weights_time_ms": 19.048}, "counters": {"num_env_steps_sampled": 132000, "num_env_steps_trained": 132000, "num_agent_steps_sampled": 528000, "num_agent_steps_trained": 528000}, "done": false, "training_iteration": 33, "trial_id": "75ec3_00000", "date": "2024-08-13_02-34-41", "timestamp": 1723530881, "time_this_iter_s": 16.469964742660522, "time_total_s": 4537.6139504909515, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b208eca0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 4537.6139504909515, "iterations_since_restore": 33, "perf": {"cpu_util_percent": 83.47391304347825, "ram_util_percent": 83.28260869565217}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5334158247583127, "cur_kl_coeff": 0.09492187500000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.4210420732144957, "policy_loss": -0.008447868067022196, "vf_loss": 2.4269679543202516, "vf_explained_var": 0.14786031671932764, "kl": 0.026569071781432044, "entropy": 1.3782171176854896, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 63315.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.29938305977377155, "cur_kl_coeff": 0.00078125, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.19304761964847486, "policy_loss": -0.0007108263799516612, "vf_loss": 0.19375462795191362, "vf_explained_var": 0.1493516517694665, "kl": 0.004887326820462608, "entropy": 0.9756718787882063, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 63315.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 136000, "num_env_steps_trained": 136000, "num_agent_steps_sampled": 544000, "num_agent_steps_trained": 544000}, "env_runners": {"episode_reward_max": 301.0000000000007, "episode_reward_min": -83.90000000000028, "episode_reward_mean": 87.72999999999973, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -276.10000000000036, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 116.0}, "policy_reward_mean": {"prey_policy": 34.30999999999995, "predator_policy": 9.555}, "custom_metrics": {}, "hist_stats": {"episode_reward": [19.60000000000006, 101.69999999999862, 165.99999999999977, 61.00000000000035, 40.0000000000003, 228.09999999999962, 179.49999999999872, -83.90000000000028, 210.99999999999915, 133.7999999999988, -48.7999999999998, 75.89999999999979, 130.99999999999898, 181.59999999999883, 110.29999999999876, 54.90000000000032, 99.39999999999907, 40.90000000000031, 128.19999999999925, 170.49999999999875, 176.49999999999923, 40.0000000000003, 40.0000000000003, 40.0000000000003, 67.10000000000008, 105.69999999999906, 101.09999999999945, 85.89999999999888, 133.79999999999936, 22.300000000000118, 40.0000000000003, 156.3999999999989, 51.70000000000049, 41.800000000000125, 193.39999999999884, 40.0000000000003, 141.59999999999945, 66.00000000000028, 15.200000000000014, 263.40000000000055, 66.1000000000004, 37.20000000000007, -9.300000000000045, 40.90000000000031, 229.99999999999915, 209.89999999999952, 62.500000000000306, 131.79999999999927, -49.49999999999995, 40.0000000000003, 33.200000000000195, 107.39999999999952, 97.49999999999892, 17.900000000000237, 237.09999999999937, 132.49999999999858, 179.59999999999923, 54.60000000000035, 90.20000000000007, 50.80000000000048, 237.9999999999991, 124.29999999999936, -23.500000000000092, 301.0000000000007, 90.19999999999987, 62.200000000000365, 140.39999999999887, 142.89999999999876, 67.00000000000016, 40.0000000000003, 66.40000000000016, 40.0000000000003, 60.60000000000045, 94.99999999999875, 13.899999999999965, 48.000000000000405, 75.29999999999961, 79.5999999999993, 113.99999999999886, 27.90000000000011, 40.90000000000031, 40.90000000000031, 62.500000000000504, 134.4999999999988, 81.49999999999923, 37.900000000000276, 43.900000000000354, 107.2999999999986, 69.89999999999993, 41.50000000000031, 63.20000000000041, 54.10000000000035, 26.00000000000007, 128.1999999999987, 47.20000000000029, 161.49999999999872, 44.50000000000036, 77.69999999999948, 58.900000000000375, 64.70000000000044], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [9.79999999999997, -5.1999999999999265, 26.30000000000004, 73.39999999999952, -6.699999999999827, 121.69999999999999, 0.8000000000000117, 30.200000000000113, 20.000000000000014, 20.000000000000014, 108.19999999999963, 119.89999999999995, 78.49999999999955, 100.99999999999937, -229.90000000000018, 20.000000000000014, 131.59999999999988, 79.39999999999932, 101.59999999999958, 15.199999999999958, -152.50000000000026, 1.7000000000000266, 80.89999999999972, -157.00000000000014, 59.30000000000016, 58.699999999999996, 104.59999999999965, 65.00000000000014, 72.79999999999954, 33.50000000000024, 11.29999999999996, 23.600000000000065, 54.20000000000011, 36.20000000000026, 20.000000000000014, 20.90000000000003, 9.199999999999985, 109.99999999999974, 85.69999999999929, 84.79999999999943, 7.399999999999965, 163.09999999999985, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 11.599999999999964, 51.500000000000135, 34.400000000000155, 71.29999999999964, 53.30000000000007, 15.799999999999963, 34.40000000000024, 51.500000000000185, 107.2999999999998, 9.499999999999961, -5.1999999999999265, 9.499999999999968, 20.000000000000014, 20.000000000000014, 138.7999999999996, 14.599999999999964, 31.700000000000212, 20.000000000000014, 9.499999999999964, 23.299999999999976, 99.19999999999936, 87.19999999999953, 20.000000000000014, 20.000000000000014, 56.3000000000002, 80.29999999999993, 50.900000000000205, 1.0999999999999865, 20.000000000000014, -98.80000000000047, 89.59999999999984, 156.79999999999978, 20.000000000000014, 46.100000000000186, -110.50000000000041, 22.700000000000195, -276.10000000000036, 42.80000000000015, 20.90000000000003, 20.000000000000014, 71.89999999999989, 151.09999999999982, 55.99999999999996, 143.89999999999992, 42.50000000000014, 20.000000000000014, 26.30000000000013, 105.50000000000009, -212.5000000000004, 35.000000000000085, 20.000000000000014, 20.000000000000014, 20.000000000000014, -11.799999999999889, 23.60000000000008, 69.79999999999987, 20.90000000000003, 62.60000000000015, -89.2000000000007, 55.100000000000016, 200.0, 37.10000000000009, 61.10000000000016, 61.40000000000022, 5.299999999999965, 161.29999999999987, 26.60000000000013, 20.000000000000014, 69.19999999999996, 20.000000000000014, 20.000000000000014, 30.800000000000196, 125.2999999999996, 112.6999999999995, 83.89999999999984, 34.400000000000084, 28.100000000000154, -148.60000000000022, 176.60000000000002, 124.3999999999996, 54.2000000000002, -18.99999999999988, 33.500000000000135, 13.69999999999997, 75.79999999999957, 53.60000000000019, 70.39999999999971, 60.500000000000135, 20.000000000000014, 47.00000000000018, 20.000000000000014, 20.000000000000014, 69.49999999999976, -24.099999999999774, 20.000000000000014, 20.000000000000014, 41.30000000000022, 5.299999999999965, 41.300000000000225, 49.700000000000166, -78.70000000000078, 11.599999999999964, 26.00000000000012, 7.999999999999966, 20.000000000000014, 38.300000000000175, 20.000000000000014, 59.600000000000186, 85.99999999999949, 20.000000000000014, 20.000000000000014, -3.0999999999999615, 20.000000000000014, 20.900000000000027, 20.90000000000003, 20.000000000000014, 20.000000000000014, 42.50000000000025, 60.500000000000206, 73.99999999999955, 55.70000000000018, 15.799999999999963, 24.500000000000096, 7.39999999999997, 13.699999999999964, 27.20000000000013, 20.000000000000014, 86.29999999999932, 35.00000000000016, 8.899999999999988, 20.000000000000014, 6.500000000000041, 7.399999999999965, 36.800000000000196, 29.90000000000007, 9.199999999999994, 13.699999999999964, 5.299999999999965, 14.599999999999966, 104.59999999999944, 27.20000000000013, 20.000000000000014, 74.89999999999944, 86.59999999999968, 20.000000000000014, 24.50000000000008, 20.90000000000003, 51.80000000000021, 32.60000000000009, 26.300000000000097, 30.800000000000196, 23.90000000000008], "policy_predator_policy_reward": [15.0, 0.0, 2.0, 0.0, 29.0, 22.0, 20.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 46.0, 80.0, 0.0, 0.0, 0.0, 17.0, 54.0, 48.0, 99.0, 53.0, 13.0, 0.0, 0.0, 12.0, 4.0, 0.0, 0.0, 20.0, 0.0, 9.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 32.0, 0.0, 0.0, 0.0, 17.0, 0.0, 6.0, 12.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 4.0, 5.0, 7.0, 0.0, 0.0, 0.0, 0.0, 5.0, 9.0, 5.0, 45.0, 49.0, 17.0, 0.0, 0.0, 0.0, 56.0, 69.0, 108.0, 116.0, 0.0, 0.0, 0.0, 7.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 24.0, 104.0, 0.0, 0.0, 25.0, 0.0, 8.0, 6.0, 0.0, 14.0, 52.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 13.0, 0.0, 8.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 97.0, 0.0, 0.0, 25.0, 30.0, 12.0, 3.0, 0.0, 11.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 21.0, 0.0, 0.0, 0.0, 7.0, 7.0, 1.0, 3.0, 43.0, 38.0, 0.0, 14.0, 17.0, 0.0, 0.0, 0.0, 8.0, 0.0, 5.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 2.0, 2.0, 4.0, 3.0, 0.0, 0.0, 1.0, 23.0, 3.0, 0.0, 15.0, 0.0, 19.0, 8.0, 7.0, 0.0, 7.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 2.0, 8.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 23.505536184393964, "mean_inference_ms": 59.57934703274026, "mean_action_processing_ms": 13.692862944768992, "mean_env_wait_ms": 19.841138824758062, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006511569023132324, "StateBufferConnector_ms": 0.005481719970703125, "ViewRequirementAgentConnector_ms": 0.33368444442749023}, "num_episodes": 18, "episode_return_max": 301.0000000000007, "episode_return_min": -83.90000000000028, "episode_return_mean": 87.72999999999973, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 544000, "num_agent_steps_trained": 544000, "num_env_steps_sampled": 136000, "num_env_steps_trained": 136000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 12.249973829224738, "num_env_steps_trained_throughput_per_sec": 12.249973829224738, "timesteps_total": 136000, "num_env_steps_sampled_lifetime": 136000, "num_agent_steps_sampled_lifetime": 544000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 544000, "timers": {"training_iteration_time_ms": 153659.831, "restore_workers_time_ms": 0.018, "training_step_time_ms": 153659.308, "sample_time_ms": 105637.571, "learn_time_ms": 47999.703, "learn_throughput": 83.334, "synch_weights_time_ms": 17.844}, "counters": {"num_env_steps_sampled": 136000, "num_env_steps_trained": 136000, "num_agent_steps_sampled": 544000, "num_agent_steps_trained": 544000}, "done": false, "training_iteration": 34, "trial_id": "75ec3_00000", "date": "2024-08-13_02-40-08", "timestamp": 1723531208, "time_this_iter_s": 326.62116384506226, "time_total_s": 4864.235114336014, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2058d30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 4864.235114336014, "iterations_since_restore": 34, "perf": {"cpu_util_percent": 89.5, "ram_util_percent": 83.73333333333335}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5663017528870748, "cur_kl_coeff": 0.14238281249999993, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.4590654465256545, "policy_loss": -0.0028032526737276128, "vf_loss": 4.460748697462536, "vf_explained_var": 0.09255657032053306, "kl": 0.007866140721260769, "entropy": 1.3983584804509683, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 65205.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5059557105340655, "cur_kl_coeff": 0.000390625, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.6812627073160555, "policy_loss": -0.0012865653155598217, "vf_loss": 0.6825467896603402, "vf_explained_var": 0.03167841639468279, "kl": 0.006358171571260065, "entropy": 1.0469788677162595, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 65205.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 140000, "num_env_steps_trained": 140000, "num_agent_steps_sampled": 560000, "num_agent_steps_trained": 560000}, "env_runners": {"episode_reward_max": 301.0000000000007, "episode_reward_min": -49.49999999999995, "episode_reward_mean": 88.33999999999975, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -276.10000000000036, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 116.0}, "policy_reward_mean": {"prey_policy": 36.22999999999996, "predator_policy": 7.94}, "custom_metrics": {}, "hist_stats": {"episode_reward": [128.19999999999925, 170.49999999999875, 176.49999999999923, 40.0000000000003, 40.0000000000003, 40.0000000000003, 67.10000000000008, 105.69999999999906, 101.09999999999945, 85.89999999999888, 133.79999999999936, 22.300000000000118, 40.0000000000003, 156.3999999999989, 51.70000000000049, 41.800000000000125, 193.39999999999884, 40.0000000000003, 141.59999999999945, 66.00000000000028, 15.200000000000014, 263.40000000000055, 66.1000000000004, 37.20000000000007, -9.300000000000045, 40.90000000000031, 229.99999999999915, 209.89999999999952, 62.500000000000306, 131.79999999999927, -49.49999999999995, 40.0000000000003, 33.200000000000195, 107.39999999999952, 97.49999999999892, 17.900000000000237, 237.09999999999937, 132.49999999999858, 179.59999999999923, 54.60000000000035, 90.20000000000007, 50.80000000000048, 237.9999999999991, 124.29999999999936, -23.500000000000092, 301.0000000000007, 90.19999999999987, 62.200000000000365, 140.39999999999887, 142.89999999999876, 67.00000000000016, 40.0000000000003, 66.40000000000016, 40.0000000000003, 60.60000000000045, 94.99999999999875, 13.899999999999965, 48.000000000000405, 75.29999999999961, 79.5999999999993, 113.99999999999886, 27.90000000000011, 40.90000000000031, 40.90000000000031, 62.500000000000504, 134.4999999999988, 81.49999999999923, 37.900000000000276, 43.900000000000354, 107.2999999999986, 69.89999999999993, 41.50000000000031, 63.20000000000041, 54.10000000000035, 26.00000000000007, 128.1999999999987, 47.20000000000029, 161.49999999999872, 44.50000000000036, 77.69999999999948, 58.900000000000375, 64.70000000000044, 112.89999999999849, 204.79999999999944, 90.40000000000009, 124.69999999999888, 96.69999999999906, 101.49999999999984, 61.30000000000043, 177.79999999999947, 112.0999999999988, 51.70000000000028, 45.20000000000027, 80.99999999999963, 78.39999999999941, 89.4999999999989, 93.39999999999877, -40.2999999999996, 132.99999999999898, 148.89999999999952], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [9.199999999999985, 109.99999999999974, 85.69999999999929, 84.79999999999943, 7.399999999999965, 163.09999999999985, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 11.599999999999964, 51.500000000000135, 34.400000000000155, 71.29999999999964, 53.30000000000007, 15.799999999999963, 34.40000000000024, 51.500000000000185, 107.2999999999998, 9.499999999999961, -5.1999999999999265, 9.499999999999968, 20.000000000000014, 20.000000000000014, 138.7999999999996, 14.599999999999964, 31.700000000000212, 20.000000000000014, 9.499999999999964, 23.299999999999976, 99.19999999999936, 87.19999999999953, 20.000000000000014, 20.000000000000014, 56.3000000000002, 80.29999999999993, 50.900000000000205, 1.0999999999999865, 20.000000000000014, -98.80000000000047, 89.59999999999984, 156.79999999999978, 20.000000000000014, 46.100000000000186, -110.50000000000041, 22.700000000000195, -276.10000000000036, 42.80000000000015, 20.90000000000003, 20.000000000000014, 71.89999999999989, 151.09999999999982, 55.99999999999996, 143.89999999999992, 42.50000000000014, 20.000000000000014, 26.30000000000013, 105.50000000000009, -212.5000000000004, 35.000000000000085, 20.000000000000014, 20.000000000000014, 20.000000000000014, -11.799999999999889, 23.60000000000008, 69.79999999999987, 20.90000000000003, 62.60000000000015, -89.2000000000007, 55.100000000000016, 200.0, 37.10000000000009, 61.10000000000016, 61.40000000000022, 5.299999999999965, 161.29999999999987, 26.60000000000013, 20.000000000000014, 69.19999999999996, 20.000000000000014, 20.000000000000014, 30.800000000000196, 125.2999999999996, 112.6999999999995, 83.89999999999984, 34.400000000000084, 28.100000000000154, -148.60000000000022, 176.60000000000002, 124.3999999999996, 54.2000000000002, -18.99999999999988, 33.500000000000135, 13.69999999999997, 75.79999999999957, 53.60000000000019, 70.39999999999971, 60.500000000000135, 20.000000000000014, 47.00000000000018, 20.000000000000014, 20.000000000000014, 69.49999999999976, -24.099999999999774, 20.000000000000014, 20.000000000000014, 41.30000000000022, 5.299999999999965, 41.300000000000225, 49.700000000000166, -78.70000000000078, 11.599999999999964, 26.00000000000012, 7.999999999999966, 20.000000000000014, 38.300000000000175, 20.000000000000014, 59.600000000000186, 85.99999999999949, 20.000000000000014, 20.000000000000014, -3.0999999999999615, 20.000000000000014, 20.900000000000027, 20.90000000000003, 20.000000000000014, 20.000000000000014, 42.50000000000025, 60.500000000000206, 73.99999999999955, 55.70000000000018, 15.799999999999963, 24.500000000000096, 7.39999999999997, 13.699999999999964, 27.20000000000013, 20.000000000000014, 86.29999999999932, 35.00000000000016, 8.899999999999988, 20.000000000000014, 6.500000000000041, 7.399999999999965, 36.800000000000196, 29.90000000000007, 9.199999999999994, 13.699999999999964, 5.299999999999965, 14.599999999999966, 104.59999999999944, 27.20000000000013, 20.000000000000014, 74.89999999999944, 86.59999999999968, 20.000000000000014, 24.50000000000008, 20.90000000000003, 51.80000000000021, 32.60000000000009, 26.300000000000097, 30.800000000000196, 23.90000000000008, 41.6000000000002, 71.29999999999968, 80.89999999999966, 119.89999999999975, 20.90000000000003, 60.5, 106.39999999999952, 5.299999999999965, 76.6999999999996, 20.000000000000014, -24.099999999999746, 104.6, 31.40000000000022, 14.899999999999944, 92.8999999999998, 53.90000000000004, 30.799999999999997, 77.29999999999939, 31.7000000000001, 20.000000000000014, 17.899999999999988, 26.300000000000004, 20.000000000000014, 59.00000000000016, 52.4000000000002, 20.000000000000014, 23.600000000000023, 65.90000000000006, 71.59999999999964, 9.799999999999967, -26.199999999999747, -105.10000000000046, 72.1999999999996, 57.800000000000004, 20.000000000000014, 110.9], "policy_predator_policy_reward": [9.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 32.0, 0.0, 0.0, 0.0, 17.0, 0.0, 6.0, 12.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 4.0, 5.0, 7.0, 0.0, 0.0, 0.0, 0.0, 5.0, 9.0, 5.0, 45.0, 49.0, 17.0, 0.0, 0.0, 0.0, 56.0, 69.0, 108.0, 116.0, 0.0, 0.0, 0.0, 7.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 24.0, 104.0, 0.0, 0.0, 25.0, 0.0, 8.0, 6.0, 0.0, 14.0, 52.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 13.0, 0.0, 8.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 97.0, 0.0, 0.0, 25.0, 30.0, 12.0, 3.0, 0.0, 11.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 21.0, 0.0, 0.0, 0.0, 7.0, 7.0, 1.0, 3.0, 43.0, 38.0, 0.0, 14.0, 17.0, 0.0, 0.0, 0.0, 8.0, 0.0, 5.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 2.0, 2.0, 4.0, 3.0, 0.0, 0.0, 1.0, 23.0, 3.0, 0.0, 15.0, 0.0, 19.0, 8.0, 7.0, 0.0, 7.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 2.0, 8.0, 0.0, 0.0, 4.0, 0.0, 9.0, 0.0, 7.0, 6.0, 0.0, 0.0, 0.0, 21.0, 11.0, 4.0, 5.0, 26.0, 0.0, 4.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 6.0, 0.0, 0.0, 0.0, 0.0, 12.0, 31.0, 60.0, 3.0, 0.0, 8.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 27.25996946192936, "mean_inference_ms": 63.860936402447166, "mean_action_processing_ms": 14.782373892247309, "mean_env_wait_ms": 20.760945621761593, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007681846618652344, "StateBufferConnector_ms": 0.005351901054382324, "ViewRequirementAgentConnector_ms": 0.3300672769546509}, "num_episodes": 18, "episode_return_max": 301.0000000000007, "episode_return_min": -49.49999999999995, "episode_return_mean": 88.33999999999975, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 560000, "num_agent_steps_trained": 560000, "num_env_steps_sampled": 140000, "num_env_steps_trained": 140000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 230.97036633421928, "num_env_steps_trained_throughput_per_sec": 230.97036633421928, "timesteps_total": 140000, "num_env_steps_sampled_lifetime": 140000, "num_agent_steps_sampled_lifetime": 560000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 560000, "timers": {"training_iteration_time_ms": 153505.842, "restore_workers_time_ms": 0.018, "training_step_time_ms": 153505.32, "sample_time_ms": 105740.22, "learn_time_ms": 47743.309, "learn_throughput": 83.781, "synch_weights_time_ms": 17.714}, "counters": {"num_env_steps_sampled": 140000, "num_env_steps_trained": 140000, "num_agent_steps_sampled": 560000, "num_agent_steps_trained": 560000}, "done": false, "training_iteration": 35, "trial_id": "75ec3_00000", "date": "2024-08-13_02-40-25", "timestamp": 1723531225, "time_this_iter_s": 17.35745596885681, "time_total_s": 4881.592570304871, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b20589d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 4881.592570304871, "iterations_since_restore": 35, "perf": {"cpu_util_percent": 85.58800000000001, "ram_util_percent": 83.71600000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4425776230200889, "cur_kl_coeff": 0.14238281249999993, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.341049762125368, "policy_loss": -0.0011490865173212513, "vf_loss": 4.341791745973012, "vf_explained_var": 0.11092902311572322, "kl": 0.0028592482095692027, "entropy": 1.407170413789295, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 67095.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.47038748597026503, "cur_kl_coeff": 0.000390625, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.5380089898115743, "policy_loss": -0.001762093841862032, "vf_loss": 0.5397697767607434, "vf_explained_var": 0.023007752939506812, "kl": 0.0033440317684852307, "entropy": 1.1044541020872731, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 67095.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 144000, "num_env_steps_trained": 144000, "num_agent_steps_sampled": 576000, "num_agent_steps_trained": 576000}, "env_runners": {"episode_reward_max": 340.4000000000004, "episode_reward_min": -49.49999999999995, "episode_reward_mean": 93.91099999999969, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -276.10000000000036, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 116.0}, "policy_reward_mean": {"prey_policy": 39.420499999999976, "predator_policy": 7.535}, "custom_metrics": {}, "hist_stats": {"episode_reward": [66.1000000000004, 37.20000000000007, -9.300000000000045, 40.90000000000031, 229.99999999999915, 209.89999999999952, 62.500000000000306, 131.79999999999927, -49.49999999999995, 40.0000000000003, 33.200000000000195, 107.39999999999952, 97.49999999999892, 17.900000000000237, 237.09999999999937, 132.49999999999858, 179.59999999999923, 54.60000000000035, 90.20000000000007, 50.80000000000048, 237.9999999999991, 124.29999999999936, -23.500000000000092, 301.0000000000007, 90.19999999999987, 62.200000000000365, 140.39999999999887, 142.89999999999876, 67.00000000000016, 40.0000000000003, 66.40000000000016, 40.0000000000003, 60.60000000000045, 94.99999999999875, 13.899999999999965, 48.000000000000405, 75.29999999999961, 79.5999999999993, 113.99999999999886, 27.90000000000011, 40.90000000000031, 40.90000000000031, 62.500000000000504, 134.4999999999988, 81.49999999999923, 37.900000000000276, 43.900000000000354, 107.2999999999986, 69.89999999999993, 41.50000000000031, 63.20000000000041, 54.10000000000035, 26.00000000000007, 128.1999999999987, 47.20000000000029, 161.49999999999872, 44.50000000000036, 77.69999999999948, 58.900000000000375, 64.70000000000044, 112.89999999999849, 204.79999999999944, 90.40000000000009, 124.69999999999888, 96.69999999999906, 101.49999999999984, 61.30000000000043, 177.79999999999947, 112.0999999999988, 51.70000000000028, 45.20000000000027, 80.99999999999963, 78.39999999999941, 89.4999999999989, 93.39999999999877, -40.2999999999996, 132.99999999999898, 148.89999999999952, 128.89999999999893, 10.300000000000066, 120.99999999999979, 100.59999999999863, 122.29999999999875, 137.19999999999894, 129.69999999999987, 168.5999999999991, 340.4000000000004, 198.59999999999945, 44.70000000000039, 40.9000000000003, 75.99999999999997, 139.89999999999927, 86.19999999999891, 68.19999999999995, 91.69999999999939, 133.89999999999938, 187.89999999999895, 61.600000000000286, 52.90000000000045, 236.19999999999897], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 46.100000000000186, -110.50000000000041, 22.700000000000195, -276.10000000000036, 42.80000000000015, 20.90000000000003, 20.000000000000014, 71.89999999999989, 151.09999999999982, 55.99999999999996, 143.89999999999992, 42.50000000000014, 20.000000000000014, 26.30000000000013, 105.50000000000009, -212.5000000000004, 35.000000000000085, 20.000000000000014, 20.000000000000014, 20.000000000000014, -11.799999999999889, 23.60000000000008, 69.79999999999987, 20.90000000000003, 62.60000000000015, -89.2000000000007, 55.100000000000016, 200.0, 37.10000000000009, 61.10000000000016, 61.40000000000022, 5.299999999999965, 161.29999999999987, 26.60000000000013, 20.000000000000014, 69.19999999999996, 20.000000000000014, 20.000000000000014, 30.800000000000196, 125.2999999999996, 112.6999999999995, 83.89999999999984, 34.400000000000084, 28.100000000000154, -148.60000000000022, 176.60000000000002, 124.3999999999996, 54.2000000000002, -18.99999999999988, 33.500000000000135, 13.69999999999997, 75.79999999999957, 53.60000000000019, 70.39999999999971, 60.500000000000135, 20.000000000000014, 47.00000000000018, 20.000000000000014, 20.000000000000014, 69.49999999999976, -24.099999999999774, 20.000000000000014, 20.000000000000014, 41.30000000000022, 5.299999999999965, 41.300000000000225, 49.700000000000166, -78.70000000000078, 11.599999999999964, 26.00000000000012, 7.999999999999966, 20.000000000000014, 38.300000000000175, 20.000000000000014, 59.600000000000186, 85.99999999999949, 20.000000000000014, 20.000000000000014, -3.0999999999999615, 20.000000000000014, 20.900000000000027, 20.90000000000003, 20.000000000000014, 20.000000000000014, 42.50000000000025, 60.500000000000206, 73.99999999999955, 55.70000000000018, 15.799999999999963, 24.500000000000096, 7.39999999999997, 13.699999999999964, 27.20000000000013, 20.000000000000014, 86.29999999999932, 35.00000000000016, 8.899999999999988, 20.000000000000014, 6.500000000000041, 7.399999999999965, 36.800000000000196, 29.90000000000007, 9.199999999999994, 13.699999999999964, 5.299999999999965, 14.599999999999966, 104.59999999999944, 27.20000000000013, 20.000000000000014, 74.89999999999944, 86.59999999999968, 20.000000000000014, 24.50000000000008, 20.90000000000003, 51.80000000000021, 32.60000000000009, 26.300000000000097, 30.800000000000196, 23.90000000000008, 41.6000000000002, 71.29999999999968, 80.89999999999966, 119.89999999999975, 20.90000000000003, 60.5, 106.39999999999952, 5.299999999999965, 76.6999999999996, 20.000000000000014, -24.099999999999746, 104.6, 31.40000000000022, 14.899999999999944, 92.8999999999998, 53.90000000000004, 30.799999999999997, 77.29999999999939, 31.7000000000001, 20.000000000000014, 17.899999999999988, 26.300000000000004, 20.000000000000014, 59.00000000000016, 52.4000000000002, 20.000000000000014, 23.600000000000023, 65.90000000000006, 71.59999999999964, 9.799999999999967, -26.199999999999747, -105.10000000000046, 72.1999999999996, 57.800000000000004, 20.000000000000014, 110.9, 58.39999999999999, 69.49999999999982, -36.699999999999754, 20.000000000000014, 88.39999999999995, 32.60000000000017, 24.50000000000008, 73.09999999999954, 76.69999999999963, 38.600000000000065, 50.6000000000002, 86.59999999999965, 80.29999999999997, 43.40000000000019, 133.6999999999998, 29.900000000000187, 196.4, 142.99999999999991, 104.00000000000001, 77.59999999999961, 28.10000000000015, 8.59999999999997, 20.000000000000014, 20.900000000000013, 65.29999999999998, -7.299999999999894, 20.000000000000014, 119.89999999999978, 37.40000000000015, 18.800000000000022, 51.500000000000085, 13.699999999999966, 32.599999999999994, 52.10000000000014, 110.89999999999975, 16.99999999999997, 144.7999999999997, 40.10000000000019, 20.000000000000014, 41.600000000000136, 20.000000000000014, 20.90000000000003, 172.99999999999983, 63.200000000000216], "policy_predator_policy_reward": [0.0, 0.0, 56.0, 69.0, 108.0, 116.0, 0.0, 0.0, 0.0, 7.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 24.0, 104.0, 0.0, 0.0, 25.0, 0.0, 8.0, 6.0, 0.0, 14.0, 52.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 13.0, 0.0, 8.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 97.0, 0.0, 0.0, 25.0, 30.0, 12.0, 3.0, 0.0, 11.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 21.0, 0.0, 0.0, 0.0, 7.0, 7.0, 1.0, 3.0, 43.0, 38.0, 0.0, 14.0, 17.0, 0.0, 0.0, 0.0, 8.0, 0.0, 5.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 2.0, 2.0, 4.0, 3.0, 0.0, 0.0, 1.0, 23.0, 3.0, 0.0, 15.0, 0.0, 19.0, 8.0, 7.0, 0.0, 7.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 2.0, 8.0, 0.0, 0.0, 4.0, 0.0, 9.0, 0.0, 7.0, 6.0, 0.0, 0.0, 0.0, 21.0, 11.0, 4.0, 5.0, 26.0, 0.0, 4.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 6.0, 0.0, 0.0, 0.0, 0.0, 12.0, 31.0, 60.0, 3.0, 0.0, 8.0, 10.0, 1.0, 0.0, 0.0, 27.0, 0.0, 0.0, 0.0, 3.0, 7.0, 0.0, 0.0, 0.0, 6.0, 0.0, 1.0, 4.0, 1.0, 0.0, 0.0, 17.0, 0.0, 8.0, 0.0, 0.0, 5.0, 13.0, 0.0, 0.0, 15.0, 15.0, 0.0, 3.0, 3.0, 4.0, 4.0, 2.0, 0.0, 3.0, 0.0, 0.0, 12.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 32.19311993353754, "mean_inference_ms": 67.68517050332377, "mean_action_processing_ms": 15.169432073205476, "mean_env_wait_ms": 21.509242391990938, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007215738296508789, "StateBufferConnector_ms": 0.004938364028930664, "ViewRequirementAgentConnector_ms": 0.3038520812988281}, "num_episodes": 22, "episode_return_max": 340.4000000000004, "episode_return_min": -49.49999999999995, "episode_return_mean": 93.91099999999969, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 576000, "num_agent_steps_trained": 576000, "num_env_steps_sampled": 144000, "num_env_steps_trained": 144000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 266.9854261125317, "num_env_steps_trained_throughput_per_sec": 266.9854261125317, "timesteps_total": 144000, "num_env_steps_sampled_lifetime": 144000, "num_agent_steps_sampled_lifetime": 576000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 576000, "timers": {"training_iteration_time_ms": 153182.859, "restore_workers_time_ms": 0.018, "training_step_time_ms": 153182.337, "sample_time_ms": 105707.597, "learn_time_ms": 47453.112, "learn_throughput": 84.294, "synch_weights_time_ms": 17.404}, "counters": {"num_env_steps_sampled": 144000, "num_env_steps_trained": 144000, "num_agent_steps_sampled": 576000, "num_agent_steps_trained": 576000}, "done": false, "training_iteration": 36, "trial_id": "75ec3_00000", "date": "2024-08-13_02-40-40", "timestamp": 1723531240, "time_this_iter_s": 15.02532696723938, "time_total_s": 4896.61789727211, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b1b128b0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 4896.61789727211, "iterations_since_restore": 36, "perf": {"cpu_util_percent": 84.97619047619048, "ram_util_percent": 83.56666666666666}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.026039158927385, "cur_kl_coeff": 0.07119140624999996, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.3948286824756195, "policy_loss": -0.008566055603315512, "vf_loss": 5.401582412618809, "vf_explained_var": 0.039269502358461814, "kl": 0.02545744267356673, "entropy": 1.401193007716426, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 68985.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.44441185678557427, "cur_kl_coeff": 0.0001953125, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.035354294348015, "policy_loss": -0.001092428225708544, "vf_loss": 2.0364451520657414, "vf_explained_var": 0.00047247570658486986, "kl": 0.00801211557024091, "entropy": 1.0237680682114192, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 68985.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 148000, "num_env_steps_trained": 148000, "num_agent_steps_sampled": 592000, "num_agent_steps_trained": 592000}, "env_runners": {"episode_reward_max": 340.4000000000004, "episode_reward_min": -40.2999999999996, "episode_reward_mean": 93.97699999999969, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -215.50000000000003, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 196.4, "predator_policy": 152.0}, "policy_reward_mean": {"prey_policy": 38.78849999999998, "predator_policy": 8.2}, "custom_metrics": {}, "hist_stats": {"episode_reward": [301.0000000000007, 90.19999999999987, 62.200000000000365, 140.39999999999887, 142.89999999999876, 67.00000000000016, 40.0000000000003, 66.40000000000016, 40.0000000000003, 60.60000000000045, 94.99999999999875, 13.899999999999965, 48.000000000000405, 75.29999999999961, 79.5999999999993, 113.99999999999886, 27.90000000000011, 40.90000000000031, 40.90000000000031, 62.500000000000504, 134.4999999999988, 81.49999999999923, 37.900000000000276, 43.900000000000354, 107.2999999999986, 69.89999999999993, 41.50000000000031, 63.20000000000041, 54.10000000000035, 26.00000000000007, 128.1999999999987, 47.20000000000029, 161.49999999999872, 44.50000000000036, 77.69999999999948, 58.900000000000375, 64.70000000000044, 112.89999999999849, 204.79999999999944, 90.40000000000009, 124.69999999999888, 96.69999999999906, 101.49999999999984, 61.30000000000043, 177.79999999999947, 112.0999999999988, 51.70000000000028, 45.20000000000027, 80.99999999999963, 78.39999999999941, 89.4999999999989, 93.39999999999877, -40.2999999999996, 132.99999999999898, 148.89999999999952, 128.89999999999893, 10.300000000000066, 120.99999999999979, 100.59999999999863, 122.29999999999875, 137.19999999999894, 129.69999999999987, 168.5999999999991, 340.4000000000004, 198.59999999999945, 44.70000000000039, 40.9000000000003, 75.99999999999997, 139.89999999999927, 86.19999999999891, 68.19999999999995, 91.69999999999939, 133.89999999999938, 187.89999999999895, 61.600000000000286, 52.90000000000045, 236.19999999999897, 180.69999999999948, 217.29999999999959, 99.29999999999981, 42.700000000000095, 70.6999999999997, 68.20000000000005, 2.9000000000001944, 157.99999999999875, 156.1999999999994, 40.9000000000003, 110.29999999999876, 179.79999999999922, 95.09999999999982, 15.399999999999915, 69.30000000000005, 4.399999999999991, 77.80000000000015, 41.00000000000033, 112.89999999999989, 118.39999999999922, 62.50000000000041, 119.19999999999979, 62.800000000000296], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [176.60000000000002, 124.3999999999996, 54.2000000000002, -18.99999999999988, 33.500000000000135, 13.69999999999997, 75.79999999999957, 53.60000000000019, 70.39999999999971, 60.500000000000135, 20.000000000000014, 47.00000000000018, 20.000000000000014, 20.000000000000014, 69.49999999999976, -24.099999999999774, 20.000000000000014, 20.000000000000014, 41.30000000000022, 5.299999999999965, 41.300000000000225, 49.700000000000166, -78.70000000000078, 11.599999999999964, 26.00000000000012, 7.999999999999966, 20.000000000000014, 38.300000000000175, 20.000000000000014, 59.600000000000186, 85.99999999999949, 20.000000000000014, 20.000000000000014, -3.0999999999999615, 20.000000000000014, 20.900000000000027, 20.90000000000003, 20.000000000000014, 20.000000000000014, 42.50000000000025, 60.500000000000206, 73.99999999999955, 55.70000000000018, 15.799999999999963, 24.500000000000096, 7.39999999999997, 13.699999999999964, 27.20000000000013, 20.000000000000014, 86.29999999999932, 35.00000000000016, 8.899999999999988, 20.000000000000014, 6.500000000000041, 7.399999999999965, 36.800000000000196, 29.90000000000007, 9.199999999999994, 13.699999999999964, 5.299999999999965, 14.599999999999966, 104.59999999999944, 27.20000000000013, 20.000000000000014, 74.89999999999944, 86.59999999999968, 20.000000000000014, 24.50000000000008, 20.90000000000003, 51.80000000000021, 32.60000000000009, 26.300000000000097, 30.800000000000196, 23.90000000000008, 41.6000000000002, 71.29999999999968, 80.89999999999966, 119.89999999999975, 20.90000000000003, 60.5, 106.39999999999952, 5.299999999999965, 76.6999999999996, 20.000000000000014, -24.099999999999746, 104.6, 31.40000000000022, 14.899999999999944, 92.8999999999998, 53.90000000000004, 30.799999999999997, 77.29999999999939, 31.7000000000001, 20.000000000000014, 17.899999999999988, 26.300000000000004, 20.000000000000014, 59.00000000000016, 52.4000000000002, 20.000000000000014, 23.600000000000023, 65.90000000000006, 71.59999999999964, 9.799999999999967, -26.199999999999747, -105.10000000000046, 72.1999999999996, 57.800000000000004, 20.000000000000014, 110.9, 58.39999999999999, 69.49999999999982, -36.699999999999754, 20.000000000000014, 88.39999999999995, 32.60000000000017, 24.50000000000008, 73.09999999999954, 76.69999999999963, 38.600000000000065, 50.6000000000002, 86.59999999999965, 80.29999999999997, 43.40000000000019, 133.6999999999998, 29.900000000000187, 196.4, 142.99999999999991, 104.00000000000001, 77.59999999999961, 28.10000000000015, 8.59999999999997, 20.000000000000014, 20.900000000000013, 65.29999999999998, -7.299999999999894, 20.000000000000014, 119.89999999999978, 37.40000000000015, 18.800000000000022, 51.500000000000085, 13.699999999999966, 32.599999999999994, 52.10000000000014, 110.89999999999975, 16.99999999999997, 144.7999999999997, 40.10000000000019, 20.000000000000014, 41.600000000000136, 20.000000000000014, 20.90000000000003, 172.99999999999983, 63.200000000000216, 143.29999999999998, -1.5999999999999561, 47.00000000000008, 170.3, 64.40000000000012, 20.900000000000013, 27.20000000000003, -2.4999999999998472, 46.70000000000007, 20.000000000000014, 40.70000000000015, 24.500000000000096, -7.299999999999905, -14.799999999999793, 53.90000000000015, 100.09999999999937, 73.3999999999998, 51.80000000000007, 20.000000000000014, 20.900000000000013, 26.300000000000004, 67.99999999999987, 126.19999999999987, 50.600000000000215, 93.79999999999988, -60.70000000000052, -47.199999999999804, 29.600000000000176, 47.3000000000002, 20.000000000000014, 22.700000000000063, -145.3000000000006, -215.50000000000003, 35.30000000000025, 20.000000000000014, -12.999999999999835, 51.50000000000018, 61.400000000000006, 4.400000000000064, 82.99999999999936, -28.29999999999975, 57.800000000000196, 20.000000000000014, 99.20000000000002, -93.50000000000004, 26.299999999999997], "policy_predator_policy_reward": [0.0, 0.0, 25.0, 30.0, 12.0, 3.0, 0.0, 11.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 21.0, 0.0, 0.0, 0.0, 7.0, 7.0, 1.0, 3.0, 43.0, 38.0, 0.0, 14.0, 17.0, 0.0, 0.0, 0.0, 8.0, 0.0, 5.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 2.0, 2.0, 4.0, 3.0, 0.0, 0.0, 1.0, 23.0, 3.0, 0.0, 15.0, 0.0, 19.0, 8.0, 7.0, 0.0, 7.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 2.0, 8.0, 0.0, 0.0, 4.0, 0.0, 9.0, 0.0, 7.0, 6.0, 0.0, 0.0, 0.0, 21.0, 11.0, 4.0, 5.0, 26.0, 0.0, 4.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 6.0, 0.0, 0.0, 0.0, 0.0, 12.0, 31.0, 60.0, 3.0, 0.0, 8.0, 10.0, 1.0, 0.0, 0.0, 27.0, 0.0, 0.0, 0.0, 3.0, 7.0, 0.0, 0.0, 0.0, 6.0, 0.0, 1.0, 4.0, 1.0, 0.0, 0.0, 17.0, 0.0, 8.0, 0.0, 0.0, 5.0, 13.0, 0.0, 0.0, 15.0, 15.0, 0.0, 3.0, 3.0, 4.0, 4.0, 2.0, 0.0, 3.0, 0.0, 0.0, 12.0, 0.0, 0.0, 0.0, 2.0, 37.0, 0.0, 0.0, 4.0, 10.0, 0.0, 18.0, 0.0, 4.0, 0.0, 3.0, 0.0, 25.0, 0.0, 4.0, 5.0, 26.0, 0.0, 0.0, 11.0, 5.0, 0.0, 3.0, 50.0, 12.0, 32.0, 1.0, 2.0, 0.0, 66.0, 61.0, 106.0, 152.0, 22.0, 12.0, 0.0, 0.0, 18.0, 13.0, 10.0, 23.0, 0.0, 0.0, 80.0, 50.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 30.50856236304411, "mean_inference_ms": 65.55492550420232, "mean_action_processing_ms": 15.253974234768764, "mean_env_wait_ms": 20.888494165285042, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005445241928100586, "StateBufferConnector_ms": 0.0035517215728759766, "ViewRequirementAgentConnector_ms": 0.1622523069381714}, "num_episodes": 23, "episode_return_max": 340.4000000000004, "episode_return_min": -40.2999999999996, "episode_return_mean": 93.97699999999969, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 592000, "num_agent_steps_trained": 592000, "num_env_steps_sampled": 148000, "num_env_steps_trained": 148000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 268.42641539832937, "num_env_steps_trained_throughput_per_sec": 268.42641539832937, "timesteps_total": 148000, "num_env_steps_sampled_lifetime": 148000, "num_agent_steps_sampled_lifetime": 592000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 592000, "timers": {"training_iteration_time_ms": 152751.784, "restore_workers_time_ms": 0.017, "training_step_time_ms": 152751.263, "sample_time_ms": 105634.211, "learn_time_ms": 47095.736, "learn_throughput": 84.933, "synch_weights_time_ms": 16.948}, "counters": {"num_env_steps_sampled": 148000, "num_env_steps_trained": 148000, "num_agent_steps_sampled": 592000, "num_agent_steps_trained": 592000}, "done": false, "training_iteration": 37, "trial_id": "75ec3_00000", "date": "2024-08-13_02-40-55", "timestamp": 1723531255, "time_this_iter_s": 14.960337162017822, "time_total_s": 4911.578234434128, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2058280>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 4911.578234434128, "iterations_since_restore": 37, "perf": {"cpu_util_percent": 86.29523809523809, "ram_util_percent": 83.60952380952381}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3790258572530494, "cur_kl_coeff": 0.10678710937499997, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.9579533578226807, "policy_loss": -0.005731497840369465, "vf_loss": 1.9619854385890658, "vf_explained_var": 0.10886169066504826, "kl": 0.01591405692649409, "entropy": 1.3948130827732188, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 70875.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.36143305765455047, "cur_kl_coeff": 0.0001953125, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.4936408841184207, "policy_loss": -0.00214624289132497, "vf_loss": 0.495784283150973, "vf_explained_var": 0.016520888874770472, "kl": 0.014556399217754267, "entropy": 0.8765268394871364, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 70875.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 152000, "num_env_steps_trained": 152000, "num_agent_steps_sampled": 608000, "num_agent_steps_trained": 608000}, "env_runners": {"episode_reward_max": 340.4000000000004, "episode_reward_min": -40.2999999999996, "episode_reward_mean": 93.64399999999965, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -215.50000000000003, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 196.4, "predator_policy": 152.0}, "policy_reward_mean": {"prey_policy": 39.22199999999997, "predator_policy": 7.6}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.90000000000031, 62.500000000000504, 134.4999999999988, 81.49999999999923, 37.900000000000276, 43.900000000000354, 107.2999999999986, 69.89999999999993, 41.50000000000031, 63.20000000000041, 54.10000000000035, 26.00000000000007, 128.1999999999987, 47.20000000000029, 161.49999999999872, 44.50000000000036, 77.69999999999948, 58.900000000000375, 64.70000000000044, 112.89999999999849, 204.79999999999944, 90.40000000000009, 124.69999999999888, 96.69999999999906, 101.49999999999984, 61.30000000000043, 177.79999999999947, 112.0999999999988, 51.70000000000028, 45.20000000000027, 80.99999999999963, 78.39999999999941, 89.4999999999989, 93.39999999999877, -40.2999999999996, 132.99999999999898, 148.89999999999952, 128.89999999999893, 10.300000000000066, 120.99999999999979, 100.59999999999863, 122.29999999999875, 137.19999999999894, 129.69999999999987, 168.5999999999991, 340.4000000000004, 198.59999999999945, 44.70000000000039, 40.9000000000003, 75.99999999999997, 139.89999999999927, 86.19999999999891, 68.19999999999995, 91.69999999999939, 133.89999999999938, 187.89999999999895, 61.600000000000286, 52.90000000000045, 236.19999999999897, 180.69999999999948, 217.29999999999959, 99.29999999999981, 42.700000000000095, 70.6999999999997, 68.20000000000005, 2.9000000000001944, 157.99999999999875, 156.1999999999994, 40.9000000000003, 110.29999999999876, 179.79999999999922, 95.09999999999982, 15.399999999999915, 69.30000000000005, 4.399999999999991, 77.80000000000015, 41.00000000000033, 112.89999999999989, 118.39999999999922, 62.50000000000041, 119.19999999999979, 62.800000000000296, 63.4000000000004, 49.000000000000455, 84.09999999999903, 130.4999999999987, 130.0999999999992, 73.79999999999995, 113.79999999999879, 132.6999999999992, 9.300000000000015, 47.30000000000042, 61.700000000000436, 40.0000000000003, 37.80000000000027, 68.80000000000015, 78.89999999999931, 99.79999999999887, 148.8999999999986, 102.09999999999849], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.90000000000003, 20.000000000000014, 20.000000000000014, 42.50000000000025, 60.500000000000206, 73.99999999999955, 55.70000000000018, 15.799999999999963, 24.500000000000096, 7.39999999999997, 13.699999999999964, 27.20000000000013, 20.000000000000014, 86.29999999999932, 35.00000000000016, 8.899999999999988, 20.000000000000014, 6.500000000000041, 7.399999999999965, 36.800000000000196, 29.90000000000007, 9.199999999999994, 13.699999999999964, 5.299999999999965, 14.599999999999966, 104.59999999999944, 27.20000000000013, 20.000000000000014, 74.89999999999944, 86.59999999999968, 20.000000000000014, 24.50000000000008, 20.90000000000003, 51.80000000000021, 32.60000000000009, 26.300000000000097, 30.800000000000196, 23.90000000000008, 41.6000000000002, 71.29999999999968, 80.89999999999966, 119.89999999999975, 20.90000000000003, 60.5, 106.39999999999952, 5.299999999999965, 76.6999999999996, 20.000000000000014, -24.099999999999746, 104.6, 31.40000000000022, 14.899999999999944, 92.8999999999998, 53.90000000000004, 30.799999999999997, 77.29999999999939, 31.7000000000001, 20.000000000000014, 17.899999999999988, 26.300000000000004, 20.000000000000014, 59.00000000000016, 52.4000000000002, 20.000000000000014, 23.600000000000023, 65.90000000000006, 71.59999999999964, 9.799999999999967, -26.199999999999747, -105.10000000000046, 72.1999999999996, 57.800000000000004, 20.000000000000014, 110.9, 58.39999999999999, 69.49999999999982, -36.699999999999754, 20.000000000000014, 88.39999999999995, 32.60000000000017, 24.50000000000008, 73.09999999999954, 76.69999999999963, 38.600000000000065, 50.6000000000002, 86.59999999999965, 80.29999999999997, 43.40000000000019, 133.6999999999998, 29.900000000000187, 196.4, 142.99999999999991, 104.00000000000001, 77.59999999999961, 28.10000000000015, 8.59999999999997, 20.000000000000014, 20.900000000000013, 65.29999999999998, -7.299999999999894, 20.000000000000014, 119.89999999999978, 37.40000000000015, 18.800000000000022, 51.500000000000085, 13.699999999999966, 32.599999999999994, 52.10000000000014, 110.89999999999975, 16.99999999999997, 144.7999999999997, 40.10000000000019, 20.000000000000014, 41.600000000000136, 20.000000000000014, 20.90000000000003, 172.99999999999983, 63.200000000000216, 143.29999999999998, -1.5999999999999561, 47.00000000000008, 170.3, 64.40000000000012, 20.900000000000013, 27.20000000000003, -2.4999999999998472, 46.70000000000007, 20.000000000000014, 40.70000000000015, 24.500000000000096, -7.299999999999905, -14.799999999999793, 53.90000000000015, 100.09999999999937, 73.3999999999998, 51.80000000000007, 20.000000000000014, 20.900000000000013, 26.300000000000004, 67.99999999999987, 126.19999999999987, 50.600000000000215, 93.79999999999988, -60.70000000000052, -47.199999999999804, 29.600000000000176, 47.3000000000002, 20.000000000000014, 22.700000000000063, -145.3000000000006, -215.50000000000003, 35.30000000000025, 20.000000000000014, -12.999999999999835, 51.50000000000018, 61.400000000000006, 4.400000000000064, 82.99999999999936, -28.29999999999975, 57.800000000000196, 20.000000000000014, 99.20000000000002, -93.50000000000004, 26.299999999999997, 41.60000000000019, 21.800000000000043, 20.000000000000014, 29.00000000000017, 20.000000000000014, 64.1000000000002, 76.69999999999929, 51.80000000000013, 73.9999999999995, -4.900000000000077, 65.90000000000003, -3.099999999999958, 93.79999999999944, 20.000000000000014, 112.69999999999973, 20.000000000000014, 23.60000000000008, -49.2999999999998, 20.000000000000014, 23.300000000000065, 21.800000000000043, 26.90000000000014, 20.000000000000014, 20.000000000000014, 15.799999999999963, 20.000000000000014, 48.80000000000024, 20.000000000000014, 48.50000000000017, 22.400000000000052, 17.899999999999988, 74.89999999999947, 33.50000000000022, 115.39999999999947, 80.29999999999924, 21.80000000000004], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 2.0, 2.0, 4.0, 3.0, 0.0, 0.0, 1.0, 23.0, 3.0, 0.0, 15.0, 0.0, 19.0, 8.0, 7.0, 0.0, 7.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 2.0, 8.0, 0.0, 0.0, 4.0, 0.0, 9.0, 0.0, 7.0, 6.0, 0.0, 0.0, 0.0, 21.0, 11.0, 4.0, 5.0, 26.0, 0.0, 4.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 6.0, 0.0, 0.0, 0.0, 0.0, 12.0, 31.0, 60.0, 3.0, 0.0, 8.0, 10.0, 1.0, 0.0, 0.0, 27.0, 0.0, 0.0, 0.0, 3.0, 7.0, 0.0, 0.0, 0.0, 6.0, 0.0, 1.0, 4.0, 1.0, 0.0, 0.0, 17.0, 0.0, 8.0, 0.0, 0.0, 5.0, 13.0, 0.0, 0.0, 15.0, 15.0, 0.0, 3.0, 3.0, 4.0, 4.0, 2.0, 0.0, 3.0, 0.0, 0.0, 12.0, 0.0, 0.0, 0.0, 2.0, 37.0, 0.0, 0.0, 4.0, 10.0, 0.0, 18.0, 0.0, 4.0, 0.0, 3.0, 0.0, 25.0, 0.0, 4.0, 5.0, 26.0, 0.0, 0.0, 11.0, 5.0, 0.0, 3.0, 50.0, 12.0, 32.0, 1.0, 2.0, 0.0, 66.0, 61.0, 106.0, 152.0, 22.0, 12.0, 0.0, 0.0, 18.0, 13.0, 10.0, 23.0, 0.0, 0.0, 80.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 43.0, 18.0, 4.0, 7.0, 0.0, 0.0, 0.0, 0.0, 19.0, 16.0, 4.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 7.0, 6.0, 1.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 29.7547987528318, "mean_inference_ms": 63.9516653315508, "mean_action_processing_ms": 14.872720250240448, "mean_env_wait_ms": 20.367631179553968, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0056917667388916016, "StateBufferConnector_ms": 0.003966331481933594, "ViewRequirementAgentConnector_ms": 0.14424097537994385}, "num_episodes": 18, "episode_return_max": 340.4000000000004, "episode_return_min": -40.2999999999996, "episode_return_mean": 93.64399999999965, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 608000, "num_agent_steps_trained": 608000, "num_env_steps_sampled": 152000, "num_env_steps_trained": 152000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 252.2011357308082, "num_env_steps_trained_throughput_per_sec": 252.2011357308082, "timesteps_total": 152000, "num_env_steps_sampled_lifetime": 152000, "num_agent_steps_sampled_lifetime": 608000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 608000, "timers": {"training_iteration_time_ms": 152048.668, "restore_workers_time_ms": 0.018, "training_step_time_ms": 152048.146, "sample_time_ms": 105156.715, "learn_time_ms": 46870.996, "learn_throughput": 85.341, "synch_weights_time_ms": 16.428}, "counters": {"num_env_steps_sampled": 152000, "num_env_steps_trained": 152000, "num_agent_steps_sampled": 608000, "num_agent_steps_trained": 608000}, "done": false, "training_iteration": 38, "trial_id": "75ec3_00000", "date": "2024-08-13_02-41-11", "timestamp": 1723531271, "time_this_iter_s": 15.930065155029297, "time_total_s": 4927.508299589157, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b1bc6820>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 4927.508299589157, "iterations_since_restore": 38, "perf": {"cpu_util_percent": 86.3826086956522, "ram_util_percent": 83.5304347826087}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.705495271354756, "cur_kl_coeff": 0.10678710937499997, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.122896910092187, "policy_loss": -0.0007006330792570398, "vf_loss": 4.1230991053202795, "vf_explained_var": 0.11732462379667494, "kl": 0.004667633881794874, "entropy": 1.407320810562719, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 72765.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.3506622872438538, "cur_kl_coeff": 0.0001953125, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.5898971557932556, "policy_loss": -0.0025813383355776155, "vf_loss": 0.5924755463090838, "vf_explained_var": 0.0061808735605270145, "kl": 0.015091597396123486, "entropy": 0.703333174866974, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 72765.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 156000, "num_env_steps_trained": 156000, "num_agent_steps_sampled": 624000, "num_agent_steps_trained": 624000}, "env_runners": {"episode_reward_max": 340.4000000000004, "episode_reward_min": -40.2999999999996, "episode_reward_mean": 96.15599999999968, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -215.50000000000003, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 196.4, "predator_policy": 152.0}, "policy_reward_mean": {"prey_policy": 39.872999999999976, "predator_policy": 8.205}, "custom_metrics": {}, "hist_stats": {"episode_reward": [64.70000000000044, 112.89999999999849, 204.79999999999944, 90.40000000000009, 124.69999999999888, 96.69999999999906, 101.49999999999984, 61.30000000000043, 177.79999999999947, 112.0999999999988, 51.70000000000028, 45.20000000000027, 80.99999999999963, 78.39999999999941, 89.4999999999989, 93.39999999999877, -40.2999999999996, 132.99999999999898, 148.89999999999952, 128.89999999999893, 10.300000000000066, 120.99999999999979, 100.59999999999863, 122.29999999999875, 137.19999999999894, 129.69999999999987, 168.5999999999991, 340.4000000000004, 198.59999999999945, 44.70000000000039, 40.9000000000003, 75.99999999999997, 139.89999999999927, 86.19999999999891, 68.19999999999995, 91.69999999999939, 133.89999999999938, 187.89999999999895, 61.600000000000286, 52.90000000000045, 236.19999999999897, 180.69999999999948, 217.29999999999959, 99.29999999999981, 42.700000000000095, 70.6999999999997, 68.20000000000005, 2.9000000000001944, 157.99999999999875, 156.1999999999994, 40.9000000000003, 110.29999999999876, 179.79999999999922, 95.09999999999982, 15.399999999999915, 69.30000000000005, 4.399999999999991, 77.80000000000015, 41.00000000000033, 112.89999999999989, 118.39999999999922, 62.50000000000041, 119.19999999999979, 62.800000000000296, 63.4000000000004, 49.000000000000455, 84.09999999999903, 130.4999999999987, 130.0999999999992, 73.79999999999995, 113.79999999999879, 132.6999999999992, 9.300000000000015, 47.30000000000042, 61.700000000000436, 40.0000000000003, 37.80000000000027, 68.80000000000015, 78.89999999999931, 99.79999999999887, 148.8999999999986, 102.09999999999849, 40.0000000000003, 238.89999999999904, 54.00000000000051, 40.0000000000003, 94.39999999999998, 94.99999999999986, 17.599999999999945, 192.99999999999923, 31.000000000000163, 142.6999999999995, 109.59999999999943, 40.0000000000003, 51.500000000000476, 94.00000000000017, 36.40000000000024, 77.79999999999964, 84.10000000000008, 92.40000000000018], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [30.800000000000196, 23.90000000000008, 41.6000000000002, 71.29999999999968, 80.89999999999966, 119.89999999999975, 20.90000000000003, 60.5, 106.39999999999952, 5.299999999999965, 76.6999999999996, 20.000000000000014, -24.099999999999746, 104.6, 31.40000000000022, 14.899999999999944, 92.8999999999998, 53.90000000000004, 30.799999999999997, 77.29999999999939, 31.7000000000001, 20.000000000000014, 17.899999999999988, 26.300000000000004, 20.000000000000014, 59.00000000000016, 52.4000000000002, 20.000000000000014, 23.600000000000023, 65.90000000000006, 71.59999999999964, 9.799999999999967, -26.199999999999747, -105.10000000000046, 72.1999999999996, 57.800000000000004, 20.000000000000014, 110.9, 58.39999999999999, 69.49999999999982, -36.699999999999754, 20.000000000000014, 88.39999999999995, 32.60000000000017, 24.50000000000008, 73.09999999999954, 76.69999999999963, 38.600000000000065, 50.6000000000002, 86.59999999999965, 80.29999999999997, 43.40000000000019, 133.6999999999998, 29.900000000000187, 196.4, 142.99999999999991, 104.00000000000001, 77.59999999999961, 28.10000000000015, 8.59999999999997, 20.000000000000014, 20.900000000000013, 65.29999999999998, -7.299999999999894, 20.000000000000014, 119.89999999999978, 37.40000000000015, 18.800000000000022, 51.500000000000085, 13.699999999999966, 32.599999999999994, 52.10000000000014, 110.89999999999975, 16.99999999999997, 144.7999999999997, 40.10000000000019, 20.000000000000014, 41.600000000000136, 20.000000000000014, 20.90000000000003, 172.99999999999983, 63.200000000000216, 143.29999999999998, -1.5999999999999561, 47.00000000000008, 170.3, 64.40000000000012, 20.900000000000013, 27.20000000000003, -2.4999999999998472, 46.70000000000007, 20.000000000000014, 40.70000000000015, 24.500000000000096, -7.299999999999905, -14.799999999999793, 53.90000000000015, 100.09999999999937, 73.3999999999998, 51.80000000000007, 20.000000000000014, 20.900000000000013, 26.300000000000004, 67.99999999999987, 126.19999999999987, 50.600000000000215, 93.79999999999988, -60.70000000000052, -47.199999999999804, 29.600000000000176, 47.3000000000002, 20.000000000000014, 22.700000000000063, -145.3000000000006, -215.50000000000003, 35.30000000000025, 20.000000000000014, -12.999999999999835, 51.50000000000018, 61.400000000000006, 4.400000000000064, 82.99999999999936, -28.29999999999975, 57.800000000000196, 20.000000000000014, 99.20000000000002, -93.50000000000004, 26.299999999999997, 41.60000000000019, 21.800000000000043, 20.000000000000014, 29.00000000000017, 20.000000000000014, 64.1000000000002, 76.69999999999929, 51.80000000000013, 73.9999999999995, -4.900000000000077, 65.90000000000003, -3.099999999999958, 93.79999999999944, 20.000000000000014, 112.69999999999973, 20.000000000000014, 23.60000000000008, -49.2999999999998, 20.000000000000014, 23.300000000000065, 21.800000000000043, 26.90000000000014, 20.000000000000014, 20.000000000000014, 15.799999999999963, 20.000000000000014, 48.80000000000024, 20.000000000000014, 48.50000000000017, 22.400000000000052, 17.899999999999988, 74.89999999999947, 33.50000000000022, 115.39999999999947, 80.29999999999924, 21.80000000000004, 20.000000000000014, 20.000000000000014, 158.60000000000005, 80.29999999999924, 32.00000000000022, 20.000000000000014, 20.000000000000014, 20.000000000000014, -66.40000000000045, 90.80000000000001, 43.70000000000004, 20.30000000000001, -48.700000000000024, 26.300000000000125, 109.99999999999952, 82.99999999999986, 20.000000000000014, 1.9999999999999838, 23.600000000000076, 97.09999999999994, 71.59999999999988, 20.000000000000014, 20.000000000000014, 20.000000000000014, 30.800000000000203, 13.699999999999966, 28.100000000000136, 56.89999999999999, 20.000000000000014, 7.399999999999979, 57.80000000000015, 20.000000000000014, 53.299999999999976, 30.800000000000082, 42.20000000000021, 30.200000000000003], "policy_predator_policy_reward": [2.0, 8.0, 0.0, 0.0, 4.0, 0.0, 9.0, 0.0, 7.0, 6.0, 0.0, 0.0, 0.0, 21.0, 11.0, 4.0, 5.0, 26.0, 0.0, 4.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 6.0, 0.0, 0.0, 0.0, 0.0, 12.0, 31.0, 60.0, 3.0, 0.0, 8.0, 10.0, 1.0, 0.0, 0.0, 27.0, 0.0, 0.0, 0.0, 3.0, 7.0, 0.0, 0.0, 0.0, 6.0, 0.0, 1.0, 4.0, 1.0, 0.0, 0.0, 17.0, 0.0, 8.0, 0.0, 0.0, 5.0, 13.0, 0.0, 0.0, 15.0, 15.0, 0.0, 3.0, 3.0, 4.0, 4.0, 2.0, 0.0, 3.0, 0.0, 0.0, 12.0, 0.0, 0.0, 0.0, 2.0, 37.0, 0.0, 0.0, 4.0, 10.0, 0.0, 18.0, 0.0, 4.0, 0.0, 3.0, 0.0, 25.0, 0.0, 4.0, 5.0, 26.0, 0.0, 0.0, 11.0, 5.0, 0.0, 3.0, 50.0, 12.0, 32.0, 1.0, 2.0, 0.0, 66.0, 61.0, 106.0, 152.0, 22.0, 12.0, 0.0, 0.0, 18.0, 13.0, 10.0, 23.0, 0.0, 0.0, 80.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 43.0, 18.0, 4.0, 7.0, 0.0, 0.0, 0.0, 0.0, 19.0, 16.0, 4.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 7.0, 6.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 38.0, 32.0, 6.0, 25.0, 23.0, 17.0, 0.0, 0.0, 0.0, 9.0, 0.0, 22.0, 15.0, 3.0, 0.0, 0.0, 7.0, 0.0, 9.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 12.0, 8.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 29.043768882543432, "mean_inference_ms": 62.43837226820279, "mean_action_processing_ms": 14.51252655949303, "mean_env_wait_ms": 19.87565161515288, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0059108734130859375, "StateBufferConnector_ms": 0.004149436950683594, "ViewRequirementAgentConnector_ms": 0.1913917064666748}, "num_episodes": 18, "episode_return_max": 340.4000000000004, "episode_return_min": -40.2999999999996, "episode_return_mean": 96.15599999999968, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 624000, "num_agent_steps_trained": 624000, "num_env_steps_sampled": 156000, "num_env_steps_trained": 156000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 261.5270169035282, "num_env_steps_trained_throughput_per_sec": 261.5270169035282, "timesteps_total": 156000, "num_env_steps_sampled_lifetime": 156000, "num_agent_steps_sampled_lifetime": 624000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 624000, "timers": {"training_iteration_time_ms": 151565.528, "restore_workers_time_ms": 0.018, "training_step_time_ms": 151565.006, "sample_time_ms": 105093.265, "learn_time_ms": 46451.366, "learn_throughput": 86.112, "synch_weights_time_ms": 16.261}, "counters": {"num_env_steps_sampled": 156000, "num_env_steps_trained": 156000, "num_agent_steps_sampled": 624000, "num_agent_steps_trained": 624000}, "done": false, "training_iteration": 39, "trial_id": "75ec3_00000", "date": "2024-08-13_02-41-26", "timestamp": 1723531286, "time_this_iter_s": 15.339739799499512, "time_total_s": 4942.848039388657, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2058550>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 4942.848039388657, "iterations_since_restore": 39, "perf": {"cpu_util_percent": 83.0809523809524, "ram_util_percent": 83.34285714285713}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5383474690100503, "cur_kl_coeff": 0.05339355468749998, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.516804418866596, "policy_loss": -0.001859025020896403, "vf_loss": 4.51801487844457, "vf_explained_var": 0.10852170063074304, "kl": 0.012147037837525356, "entropy": 1.3528374803129328, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 74655.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.3769510673625129, "cur_kl_coeff": 0.0001953125, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.8436008668135083, "policy_loss": -0.0023865436575814056, "vf_loss": 0.8459858310995279, "vf_explained_var": 0.005117541898495306, "kl": 0.008093293628061845, "entropy": 0.6399794231962275, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 74655.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 160000, "num_env_steps_trained": 160000, "num_agent_steps_sampled": 640000, "num_agent_steps_trained": 640000}, "env_runners": {"episode_reward_max": 340.4000000000004, "episode_reward_min": -37.99999999999977, "episode_reward_mean": 95.95299999999972, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -215.50000000000003, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 197.29999999999998, "predator_policy": 152.0}, "policy_reward_mean": {"prey_policy": 38.22149999999997, "predator_policy": 9.755}, "custom_metrics": {}, "hist_stats": {"episode_reward": [100.59999999999863, 122.29999999999875, 137.19999999999894, 129.69999999999987, 168.5999999999991, 340.4000000000004, 198.59999999999945, 44.70000000000039, 40.9000000000003, 75.99999999999997, 139.89999999999927, 86.19999999999891, 68.19999999999995, 91.69999999999939, 133.89999999999938, 187.89999999999895, 61.600000000000286, 52.90000000000045, 236.19999999999897, 180.69999999999948, 217.29999999999959, 99.29999999999981, 42.700000000000095, 70.6999999999997, 68.20000000000005, 2.9000000000001944, 157.99999999999875, 156.1999999999994, 40.9000000000003, 110.29999999999876, 179.79999999999922, 95.09999999999982, 15.399999999999915, 69.30000000000005, 4.399999999999991, 77.80000000000015, 41.00000000000033, 112.89999999999989, 118.39999999999922, 62.50000000000041, 119.19999999999979, 62.800000000000296, 63.4000000000004, 49.000000000000455, 84.09999999999903, 130.4999999999987, 130.0999999999992, 73.79999999999995, 113.79999999999879, 132.6999999999992, 9.300000000000015, 47.30000000000042, 61.700000000000436, 40.0000000000003, 37.80000000000027, 68.80000000000015, 78.89999999999931, 99.79999999999887, 148.8999999999986, 102.09999999999849, 40.0000000000003, 238.89999999999904, 54.00000000000051, 40.0000000000003, 94.39999999999998, 94.99999999999986, 17.599999999999945, 192.99999999999923, 31.000000000000163, 142.6999999999995, 109.59999999999943, 40.0000000000003, 51.500000000000476, 94.00000000000017, 36.40000000000024, 77.79999999999964, 84.10000000000008, 92.40000000000018, 29.200000000000134, 147.99999999999906, 319.2000000000013, 145.2999999999995, 60.70000000000036, 120.99999999999864, 88.69999999999894, 98.49999999999902, 106.69999999999982, 39.20000000000023, 5.800000000000118, 82.99999999999991, 117.0999999999999, 35.20000000000023, 40.10000000000009, 35.20000000000031, 249.69999999999908, 119.19999999999953, 93.89999999999864, 101.29999999999927, -37.99999999999977, 68.5999999999999], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [24.50000000000008, 73.09999999999954, 76.69999999999963, 38.600000000000065, 50.6000000000002, 86.59999999999965, 80.29999999999997, 43.40000000000019, 133.6999999999998, 29.900000000000187, 196.4, 142.99999999999991, 104.00000000000001, 77.59999999999961, 28.10000000000015, 8.59999999999997, 20.000000000000014, 20.900000000000013, 65.29999999999998, -7.299999999999894, 20.000000000000014, 119.89999999999978, 37.40000000000015, 18.800000000000022, 51.500000000000085, 13.699999999999966, 32.599999999999994, 52.10000000000014, 110.89999999999975, 16.99999999999997, 144.7999999999997, 40.10000000000019, 20.000000000000014, 41.600000000000136, 20.000000000000014, 20.90000000000003, 172.99999999999983, 63.200000000000216, 143.29999999999998, -1.5999999999999561, 47.00000000000008, 170.3, 64.40000000000012, 20.900000000000013, 27.20000000000003, -2.4999999999998472, 46.70000000000007, 20.000000000000014, 40.70000000000015, 24.500000000000096, -7.299999999999905, -14.799999999999793, 53.90000000000015, 100.09999999999937, 73.3999999999998, 51.80000000000007, 20.000000000000014, 20.900000000000013, 26.300000000000004, 67.99999999999987, 126.19999999999987, 50.600000000000215, 93.79999999999988, -60.70000000000052, -47.199999999999804, 29.600000000000176, 47.3000000000002, 20.000000000000014, 22.700000000000063, -145.3000000000006, -215.50000000000003, 35.30000000000025, 20.000000000000014, -12.999999999999835, 51.50000000000018, 61.400000000000006, 4.400000000000064, 82.99999999999936, -28.29999999999975, 57.800000000000196, 20.000000000000014, 99.20000000000002, -93.50000000000004, 26.299999999999997, 41.60000000000019, 21.800000000000043, 20.000000000000014, 29.00000000000017, 20.000000000000014, 64.1000000000002, 76.69999999999929, 51.80000000000013, 73.9999999999995, -4.900000000000077, 65.90000000000003, -3.099999999999958, 93.79999999999944, 20.000000000000014, 112.69999999999973, 20.000000000000014, 23.60000000000008, -49.2999999999998, 20.000000000000014, 23.300000000000065, 21.800000000000043, 26.90000000000014, 20.000000000000014, 20.000000000000014, 15.799999999999963, 20.000000000000014, 48.80000000000024, 20.000000000000014, 48.50000000000017, 22.400000000000052, 17.899999999999988, 74.89999999999947, 33.50000000000022, 115.39999999999947, 80.29999999999924, 21.80000000000004, 20.000000000000014, 20.000000000000014, 158.60000000000005, 80.29999999999924, 32.00000000000022, 20.000000000000014, 20.000000000000014, 20.000000000000014, -66.40000000000045, 90.80000000000001, 43.70000000000004, 20.30000000000001, -48.700000000000024, 26.300000000000125, 109.99999999999952, 82.99999999999986, 20.000000000000014, 1.9999999999999838, 23.600000000000076, 97.09999999999994, 71.59999999999988, 20.000000000000014, 20.000000000000014, 20.000000000000014, 30.800000000000203, 13.699999999999966, 28.100000000000136, 56.89999999999999, 20.000000000000014, 7.399999999999979, 57.80000000000015, 20.000000000000014, 53.299999999999976, 30.800000000000082, 42.20000000000021, 30.200000000000003, 10.99999999999997, 3.1999999999999633, 95.59999999999955, 52.4000000000001, 113.89999999999961, 197.29999999999998, 57.50000000000015, 60.80000000000009, 20.000000000000014, 40.700000000000166, 20.000000000000014, 100.99999999999937, 13.699999999999964, 62.00000000000014, 88.39999999999952, 1.0999999999999652, -34.30000000000007, 20.000000000000014, 15.199999999999966, 20.000000000000014, -34.59999999999977, 7.399999999999965, 67.69999999999992, 5.300000000000027, 3.1999999999999957, 47.90000000000017, 20.90000000000003, 8.299999999999965, -53.50000000000005, 17.600000000000016, -26.799999999999912, 29.000000000000128, 170.29999999999987, 79.39999999999927, 99.19999999999987, 20.000000000000014, 68.89999999999984, 20.000000000000014, -31.600000000000087, 83.8999999999995, -127.6000000000003, 5.599999999999975, 40.70000000000006, 8.899999999999968], "policy_predator_policy_reward": [0.0, 3.0, 7.0, 0.0, 0.0, 0.0, 6.0, 0.0, 1.0, 4.0, 1.0, 0.0, 0.0, 17.0, 0.0, 8.0, 0.0, 0.0, 5.0, 13.0, 0.0, 0.0, 15.0, 15.0, 0.0, 3.0, 3.0, 4.0, 4.0, 2.0, 0.0, 3.0, 0.0, 0.0, 12.0, 0.0, 0.0, 0.0, 2.0, 37.0, 0.0, 0.0, 4.0, 10.0, 0.0, 18.0, 0.0, 4.0, 0.0, 3.0, 0.0, 25.0, 0.0, 4.0, 5.0, 26.0, 0.0, 0.0, 11.0, 5.0, 0.0, 3.0, 50.0, 12.0, 32.0, 1.0, 2.0, 0.0, 66.0, 61.0, 106.0, 152.0, 22.0, 12.0, 0.0, 0.0, 18.0, 13.0, 10.0, 23.0, 0.0, 0.0, 80.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 43.0, 18.0, 4.0, 7.0, 0.0, 0.0, 0.0, 0.0, 19.0, 16.0, 4.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 7.0, 6.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 38.0, 32.0, 6.0, 25.0, 23.0, 17.0, 0.0, 0.0, 0.0, 9.0, 0.0, 22.0, 15.0, 3.0, 0.0, 0.0, 7.0, 0.0, 9.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 12.0, 8.0, 0.0, 15.0, 0.0, 0.0, 8.0, 0.0, 16.0, 11.0, 0.0, 0.0, 0.0, 0.0, 13.0, 0.0, 3.0, 6.0, 70.0, 51.0, 4.0, 0.0, 1.0, 32.0, 3.0, 7.0, 27.0, 39.0, 0.0, 6.0, 60.0, 16.0, 33.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 49.0, 0.0, 13.0, 71.0, 12.0, 7.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 28.861889403772146, "mean_inference_ms": 60.69729527369677, "mean_action_processing_ms": 13.570119217642345, "mean_env_wait_ms": 19.28846974576597, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005272507667541504, "StateBufferConnector_ms": 0.009143233299255371, "ViewRequirementAgentConnector_ms": 0.20135152339935303}, "num_episodes": 22, "episode_return_max": 340.4000000000004, "episode_return_min": -37.99999999999977, "episode_return_mean": 95.95299999999972, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 640000, "num_agent_steps_trained": 640000, "num_env_steps_sampled": 160000, "num_env_steps_trained": 160000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 234.4068760849579, "num_env_steps_trained_throughput_per_sec": 234.4068760849579, "timesteps_total": 160000, "num_env_steps_sampled_lifetime": 160000, "num_agent_steps_sampled_lifetime": 640000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 640000, "timers": {"training_iteration_time_ms": 151326.815, "restore_workers_time_ms": 0.017, "training_step_time_ms": 151326.293, "sample_time_ms": 105109.902, "learn_time_ms": 46198.243, "learn_throughput": 86.583, "synch_weights_time_ms": 13.849}, "counters": {"num_env_steps_sampled": 160000, "num_env_steps_trained": 160000, "num_agent_steps_sampled": 640000, "num_agent_steps_trained": 640000}, "done": false, "training_iteration": 40, "trial_id": "75ec3_00000", "date": "2024-08-13_02-41-44", "timestamp": 1723531304, "time_this_iter_s": 17.13077402114868, "time_total_s": 4959.978813409805, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b208e4c0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 4959.978813409805, "iterations_since_restore": 40, "perf": {"cpu_util_percent": 84.528, "ram_util_percent": 83.24}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5122886243990805, "cur_kl_coeff": 0.05339355468749998, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.6006856207494382, "policy_loss": -0.0063127884865497, "vf_loss": 1.6059583148312948, "vf_explained_var": 0.14706301036335173, "kl": 0.019479779694032435, "entropy": 1.3957945151934548, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 76545.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.2814655112339154, "cur_kl_coeff": 0.0001953125, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.3136838084333157, "policy_loss": -0.0007283848863114756, "vf_loss": 0.31441090553647855, "vf_explained_var": 0.005456407707204264, "kl": 0.006592943470942387, "entropy": 0.5532436687637259, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 76545.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 164000, "num_env_steps_trained": 164000, "num_agent_steps_sampled": 656000, "num_agent_steps_trained": 656000}, "env_runners": {"episode_reward_max": 319.2000000000013, "episode_reward_min": -37.99999999999977, "episode_reward_mean": 83.28199999999977, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -215.50000000000003, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 197.29999999999998, "predator_policy": 152.0}, "policy_reward_mean": {"prey_policy": 32.15099999999998, "predator_policy": 9.49}, "custom_metrics": {}, "hist_stats": {"episode_reward": [70.6999999999997, 68.20000000000005, 2.9000000000001944, 157.99999999999875, 156.1999999999994, 40.9000000000003, 110.29999999999876, 179.79999999999922, 95.09999999999982, 15.399999999999915, 69.30000000000005, 4.399999999999991, 77.80000000000015, 41.00000000000033, 112.89999999999989, 118.39999999999922, 62.50000000000041, 119.19999999999979, 62.800000000000296, 63.4000000000004, 49.000000000000455, 84.09999999999903, 130.4999999999987, 130.0999999999992, 73.79999999999995, 113.79999999999879, 132.6999999999992, 9.300000000000015, 47.30000000000042, 61.700000000000436, 40.0000000000003, 37.80000000000027, 68.80000000000015, 78.89999999999931, 99.79999999999887, 148.8999999999986, 102.09999999999849, 40.0000000000003, 238.89999999999904, 54.00000000000051, 40.0000000000003, 94.39999999999998, 94.99999999999986, 17.599999999999945, 192.99999999999923, 31.000000000000163, 142.6999999999995, 109.59999999999943, 40.0000000000003, 51.500000000000476, 94.00000000000017, 36.40000000000024, 77.79999999999964, 84.10000000000008, 92.40000000000018, 29.200000000000134, 147.99999999999906, 319.2000000000013, 145.2999999999995, 60.70000000000036, 120.99999999999864, 88.69999999999894, 98.49999999999902, 106.69999999999982, 39.20000000000023, 5.800000000000118, 82.99999999999991, 117.0999999999999, 35.20000000000023, 40.10000000000009, 35.20000000000031, 249.69999999999908, 119.19999999999953, 93.89999999999864, 101.29999999999927, -37.99999999999977, 68.5999999999999, 40.90000000000031, 50.80000000000048, 25.200000000000077, 62.50000000000042, 108.89999999999836, 119.69999999999885, 49.00000000000041, 106.99999999999935, 157.8999999999999, 49.50000000000047, 53.700000000000486, 88.79999999999957, 93.9999999999985, 41.800000000000296, 98.49999999999946, 92.39999999999985, 45.000000000000384, 76.89999999999952, 42.70000000000034, 92.19999999999877, 76.99999999999947, 75.99999999999963, 40.0000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [46.70000000000007, 20.000000000000014, 40.70000000000015, 24.500000000000096, -7.299999999999905, -14.799999999999793, 53.90000000000015, 100.09999999999937, 73.3999999999998, 51.80000000000007, 20.000000000000014, 20.900000000000013, 26.300000000000004, 67.99999999999987, 126.19999999999987, 50.600000000000215, 93.79999999999988, -60.70000000000052, -47.199999999999804, 29.600000000000176, 47.3000000000002, 20.000000000000014, 22.700000000000063, -145.3000000000006, -215.50000000000003, 35.30000000000025, 20.000000000000014, -12.999999999999835, 51.50000000000018, 61.400000000000006, 4.400000000000064, 82.99999999999936, -28.29999999999975, 57.800000000000196, 20.000000000000014, 99.20000000000002, -93.50000000000004, 26.299999999999997, 41.60000000000019, 21.800000000000043, 20.000000000000014, 29.00000000000017, 20.000000000000014, 64.1000000000002, 76.69999999999929, 51.80000000000013, 73.9999999999995, -4.900000000000077, 65.90000000000003, -3.099999999999958, 93.79999999999944, 20.000000000000014, 112.69999999999973, 20.000000000000014, 23.60000000000008, -49.2999999999998, 20.000000000000014, 23.300000000000065, 21.800000000000043, 26.90000000000014, 20.000000000000014, 20.000000000000014, 15.799999999999963, 20.000000000000014, 48.80000000000024, 20.000000000000014, 48.50000000000017, 22.400000000000052, 17.899999999999988, 74.89999999999947, 33.50000000000022, 115.39999999999947, 80.29999999999924, 21.80000000000004, 20.000000000000014, 20.000000000000014, 158.60000000000005, 80.29999999999924, 32.00000000000022, 20.000000000000014, 20.000000000000014, 20.000000000000014, -66.40000000000045, 90.80000000000001, 43.70000000000004, 20.30000000000001, -48.700000000000024, 26.300000000000125, 109.99999999999952, 82.99999999999986, 20.000000000000014, 1.9999999999999838, 23.600000000000076, 97.09999999999994, 71.59999999999988, 20.000000000000014, 20.000000000000014, 20.000000000000014, 30.800000000000203, 13.699999999999966, 28.100000000000136, 56.89999999999999, 20.000000000000014, 7.399999999999979, 57.80000000000015, 20.000000000000014, 53.299999999999976, 30.800000000000082, 42.20000000000021, 30.200000000000003, 10.99999999999997, 3.1999999999999633, 95.59999999999955, 52.4000000000001, 113.89999999999961, 197.29999999999998, 57.50000000000015, 60.80000000000009, 20.000000000000014, 40.700000000000166, 20.000000000000014, 100.99999999999937, 13.699999999999964, 62.00000000000014, 88.39999999999952, 1.0999999999999652, -34.30000000000007, 20.000000000000014, 15.199999999999966, 20.000000000000014, -34.59999999999977, 7.399999999999965, 67.69999999999992, 5.300000000000027, 3.1999999999999957, 47.90000000000017, 20.90000000000003, 8.299999999999965, -53.50000000000005, 17.600000000000016, -26.799999999999912, 29.000000000000128, 170.29999999999987, 79.39999999999927, 99.19999999999987, 20.000000000000014, 68.89999999999984, 20.000000000000014, -31.600000000000087, 83.8999999999995, -127.6000000000003, 5.599999999999975, 40.70000000000006, 8.899999999999968, 20.000000000000014, 20.90000000000003, 30.800000000000196, 20.000000000000014, 4.099999999999998, 1.0999999999999865, 28.10000000000015, 34.40000000000018, 54.500000000000206, 52.400000000000205, 79.69999999999949, 29.000000000000163, 29.00000000000016, 20.000000000000014, 44.000000000000085, 38.00000000000021, 73.99999999999974, 83.89999999999999, 27.200000000000134, 20.30000000000002, 17.599999999999984, 28.100000000000154, 18.50000000000004, 26.30000000000011, 73.99999999999949, 20.000000000000014, 20.000000000000014, 21.800000000000047, 78.49999999999976, 20.000000000000014, 20.000000000000014, 64.39999999999998, 32.90000000000023, 1.099999999999983, 56.90000000000018, 20.000000000000014, 20.900000000000027, 21.80000000000004, 58.70000000000019, 33.50000000000024, 22.700000000000063, 41.300000000000125, 56.00000000000023, 20.000000000000014, 20.000000000000014, 20.000000000000014], "policy_predator_policy_reward": [0.0, 4.0, 0.0, 3.0, 0.0, 25.0, 0.0, 4.0, 5.0, 26.0, 0.0, 0.0, 11.0, 5.0, 0.0, 3.0, 50.0, 12.0, 32.0, 1.0, 2.0, 0.0, 66.0, 61.0, 106.0, 152.0, 22.0, 12.0, 0.0, 0.0, 18.0, 13.0, 10.0, 23.0, 0.0, 0.0, 80.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 43.0, 18.0, 4.0, 7.0, 0.0, 0.0, 0.0, 0.0, 19.0, 16.0, 4.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 7.0, 6.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 38.0, 32.0, 6.0, 25.0, 23.0, 17.0, 0.0, 0.0, 0.0, 9.0, 0.0, 22.0, 15.0, 3.0, 0.0, 0.0, 7.0, 0.0, 9.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 12.0, 8.0, 0.0, 15.0, 0.0, 0.0, 8.0, 0.0, 16.0, 11.0, 0.0, 0.0, 0.0, 0.0, 13.0, 0.0, 3.0, 6.0, 70.0, 51.0, 4.0, 0.0, 1.0, 32.0, 3.0, 7.0, 27.0, 39.0, 0.0, 6.0, 60.0, 16.0, 33.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 49.0, 0.0, 13.0, 71.0, 12.0, 7.0, 0.0, 0.0, 0.0, 0.0, 20.0, 0.0, 0.0, 0.0, 0.0, 2.0, 11.0, 0.0, 0.0, 0.0, 25.0, 0.0, 0.0, 0.0, 2.0, 0.0, 2.0, 6.0, 27.0, 17.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 28.034149375956943, "mean_inference_ms": 60.2961367658328, "mean_action_processing_ms": 14.336863455920616, "mean_env_wait_ms": 16.409897113554745, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005528807640075684, "StateBufferConnector_ms": 0.00932323932647705, "ViewRequirementAgentConnector_ms": 0.1917949914932251}, "num_episodes": 23, "episode_return_max": 319.2000000000013, "episode_return_min": -37.99999999999977, "episode_return_mean": 83.28199999999977, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 656000, "num_agent_steps_trained": 656000, "num_env_steps_sampled": 164000, "num_env_steps_trained": 164000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 222.29865724303156, "num_env_steps_trained_throughput_per_sec": 222.29865724303156, "timesteps_total": 164000, "num_env_steps_sampled_lifetime": 164000, "num_agent_steps_sampled_lifetime": 656000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 656000, "timers": {"training_iteration_time_ms": 151225.344, "restore_workers_time_ms": 0.017, "training_step_time_ms": 151224.823, "sample_time_ms": 105035.81, "learn_time_ms": 46170.918, "learn_throughput": 86.635, "synch_weights_time_ms": 13.89}, "counters": {"num_env_steps_sampled": 164000, "num_env_steps_trained": 164000, "num_agent_steps_sampled": 656000, "num_agent_steps_trained": 656000}, "done": false, "training_iteration": 41, "trial_id": "75ec3_00000", "date": "2024-08-13_02-42-02", "timestamp": 1723531322, "time_this_iter_s": 18.041306018829346, "time_total_s": 4978.020119428635, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b1b12dc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 4978.020119428635, "iterations_since_restore": 41, "perf": {"cpu_util_percent": 87.16399999999997, "ram_util_percent": 83.18799999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6121296033223786, "cur_kl_coeff": 0.05339355468749998, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.69887898611644, "policy_loss": -0.009287010620547724, "vf_loss": 4.707046629385974, "vf_explained_var": 0.042159761322869194, "kl": 0.020964617419120174, "entropy": 1.3735020381432992, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 78435.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4215721779655685, "cur_kl_coeff": 0.0001953125, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.9580237920952852, "policy_loss": -0.0011807700540259402, "vf_loss": 1.9592035167116337, "vf_explained_var": 0.0019578117226797436, "kl": 0.005341484176039612, "entropy": 0.45064227052781947, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 78435.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 168000, "num_env_steps_trained": 168000, "num_agent_steps_sampled": 672000, "num_agent_steps_trained": 672000}, "env_runners": {"episode_reward_max": 319.2000000000013, "episode_reward_min": -37.99999999999977, "episode_reward_mean": 82.05499999999978, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -130.0000000000004, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 197.29999999999998, "predator_policy": 80.0}, "policy_reward_mean": {"prey_policy": 31.807499999999983, "predator_policy": 9.22}, "custom_metrics": {}, "hist_stats": {"episode_reward": [62.800000000000296, 63.4000000000004, 49.000000000000455, 84.09999999999903, 130.4999999999987, 130.0999999999992, 73.79999999999995, 113.79999999999879, 132.6999999999992, 9.300000000000015, 47.30000000000042, 61.700000000000436, 40.0000000000003, 37.80000000000027, 68.80000000000015, 78.89999999999931, 99.79999999999887, 148.8999999999986, 102.09999999999849, 40.0000000000003, 238.89999999999904, 54.00000000000051, 40.0000000000003, 94.39999999999998, 94.99999999999986, 17.599999999999945, 192.99999999999923, 31.000000000000163, 142.6999999999995, 109.59999999999943, 40.0000000000003, 51.500000000000476, 94.00000000000017, 36.40000000000024, 77.79999999999964, 84.10000000000008, 92.40000000000018, 29.200000000000134, 147.99999999999906, 319.2000000000013, 145.2999999999995, 60.70000000000036, 120.99999999999864, 88.69999999999894, 98.49999999999902, 106.69999999999982, 39.20000000000023, 5.800000000000118, 82.99999999999991, 117.0999999999999, 35.20000000000023, 40.10000000000009, 35.20000000000031, 249.69999999999908, 119.19999999999953, 93.89999999999864, 101.29999999999927, -37.99999999999977, 68.5999999999999, 40.90000000000031, 50.80000000000048, 25.200000000000077, 62.50000000000042, 108.89999999999836, 119.69999999999885, 49.00000000000041, 106.99999999999935, 157.8999999999999, 49.50000000000047, 53.700000000000486, 88.79999999999957, 93.9999999999985, 41.800000000000296, 98.49999999999946, 92.39999999999985, 45.000000000000384, 76.89999999999952, 42.70000000000034, 92.19999999999877, 76.99999999999947, 75.99999999999963, 40.0000000000003, 130.3999999999994, 191.59999999999917, 56.200000000000514, 143.99999999999903, 92.19999999999943, 53.79999999999977, 58.000000000000114, -16.299999999999585, 26.800000000000093, 40.0000000000003, 56.000000000000355, 167.79999999999973, 61.89999999999946, 61.300000000000416, 110.19999999999997, 17.59999999999995, -0.29999999999987104, 129.09999999999937], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-93.50000000000004, 26.299999999999997, 41.60000000000019, 21.800000000000043, 20.000000000000014, 29.00000000000017, 20.000000000000014, 64.1000000000002, 76.69999999999929, 51.80000000000013, 73.9999999999995, -4.900000000000077, 65.90000000000003, -3.099999999999958, 93.79999999999944, 20.000000000000014, 112.69999999999973, 20.000000000000014, 23.60000000000008, -49.2999999999998, 20.000000000000014, 23.300000000000065, 21.800000000000043, 26.90000000000014, 20.000000000000014, 20.000000000000014, 15.799999999999963, 20.000000000000014, 48.80000000000024, 20.000000000000014, 48.50000000000017, 22.400000000000052, 17.899999999999988, 74.89999999999947, 33.50000000000022, 115.39999999999947, 80.29999999999924, 21.80000000000004, 20.000000000000014, 20.000000000000014, 158.60000000000005, 80.29999999999924, 32.00000000000022, 20.000000000000014, 20.000000000000014, 20.000000000000014, -66.40000000000045, 90.80000000000001, 43.70000000000004, 20.30000000000001, -48.700000000000024, 26.300000000000125, 109.99999999999952, 82.99999999999986, 20.000000000000014, 1.9999999999999838, 23.600000000000076, 97.09999999999994, 71.59999999999988, 20.000000000000014, 20.000000000000014, 20.000000000000014, 30.800000000000203, 13.699999999999966, 28.100000000000136, 56.89999999999999, 20.000000000000014, 7.399999999999979, 57.80000000000015, 20.000000000000014, 53.299999999999976, 30.800000000000082, 42.20000000000021, 30.200000000000003, 10.99999999999997, 3.1999999999999633, 95.59999999999955, 52.4000000000001, 113.89999999999961, 197.29999999999998, 57.50000000000015, 60.80000000000009, 20.000000000000014, 40.700000000000166, 20.000000000000014, 100.99999999999937, 13.699999999999964, 62.00000000000014, 88.39999999999952, 1.0999999999999652, -34.30000000000007, 20.000000000000014, 15.199999999999966, 20.000000000000014, -34.59999999999977, 7.399999999999965, 67.69999999999992, 5.300000000000027, 3.1999999999999957, 47.90000000000017, 20.90000000000003, 8.299999999999965, -53.50000000000005, 17.600000000000016, -26.799999999999912, 29.000000000000128, 170.29999999999987, 79.39999999999927, 99.19999999999987, 20.000000000000014, 68.89999999999984, 20.000000000000014, -31.600000000000087, 83.8999999999995, -127.6000000000003, 5.599999999999975, 40.70000000000006, 8.899999999999968, 20.000000000000014, 20.90000000000003, 30.800000000000196, 20.000000000000014, 4.099999999999998, 1.0999999999999865, 28.10000000000015, 34.40000000000018, 54.500000000000206, 52.400000000000205, 79.69999999999949, 29.000000000000163, 29.00000000000016, 20.000000000000014, 44.000000000000085, 38.00000000000021, 73.99999999999974, 83.89999999999999, 27.200000000000134, 20.30000000000002, 17.599999999999984, 28.100000000000154, 18.50000000000004, 26.30000000000011, 73.99999999999949, 20.000000000000014, 20.000000000000014, 21.800000000000047, 78.49999999999976, 20.000000000000014, 20.000000000000014, 64.39999999999998, 32.90000000000023, 1.099999999999983, 56.90000000000018, 20.000000000000014, 20.900000000000027, 21.80000000000004, 58.70000000000019, 33.50000000000024, 22.700000000000063, 41.300000000000125, 56.00000000000023, 20.000000000000014, 20.000000000000014, 20.000000000000014, 41.60000000000018, 72.79999999999991, 47.60000000000011, 128.00000000000006, 20.000000000000014, 36.20000000000026, 83.29999999999949, 49.70000000000001, 58.70000000000022, 33.50000000000005, -123.10000000000018, 65.90000000000008, -92.50000000000028, 33.49999999999999, -113.80000000000064, 15.49999999999996, 20.000000000000014, -5.199999999999934, 20.000000000000014, 20.000000000000014, -21.99999999999983, 20.000000000000014, 88.39999999999975, 79.39999999999998, 63.19999999999981, -52.29999999999984, 20.000000000000014, 26.300000000000132, 90.2000000000001, 20.000000000000014, 21.80000000000003, -26.199999999999854, -130.0000000000004, 40.70000000000025, 105.4999999999998, 11.599999999999966], "policy_predator_policy_reward": [80.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 43.0, 18.0, 4.0, 7.0, 0.0, 0.0, 0.0, 0.0, 19.0, 16.0, 4.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 7.0, 6.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 38.0, 32.0, 6.0, 25.0, 23.0, 17.0, 0.0, 0.0, 0.0, 9.0, 0.0, 22.0, 15.0, 3.0, 0.0, 0.0, 7.0, 0.0, 9.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 12.0, 8.0, 0.0, 15.0, 0.0, 0.0, 8.0, 0.0, 16.0, 11.0, 0.0, 0.0, 0.0, 0.0, 13.0, 0.0, 3.0, 6.0, 70.0, 51.0, 4.0, 0.0, 1.0, 32.0, 3.0, 7.0, 27.0, 39.0, 0.0, 6.0, 60.0, 16.0, 33.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 49.0, 0.0, 13.0, 71.0, 12.0, 7.0, 0.0, 0.0, 0.0, 0.0, 20.0, 0.0, 0.0, 0.0, 0.0, 2.0, 11.0, 0.0, 0.0, 0.0, 25.0, 0.0, 0.0, 0.0, 2.0, 0.0, 2.0, 6.0, 27.0, 17.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 9.0, 8.0, 8.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 74.0, 37.0, 73.0, 44.0, 66.0, 16.0, 0.0, 12.0, 0.0, 0.0, 29.0, 29.0, 0.0, 0.0, 0.0, 51.0, 11.0, 4.0, 0.0, 0.0, 22.0, 0.0, 41.0, 48.0, 10.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 26.880495104764638, "mean_inference_ms": 57.813549687238044, "mean_action_processing_ms": 13.421934580906077, "mean_env_wait_ms": 18.364598387546152, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005732178688049316, "StateBufferConnector_ms": 0.009497880935668945, "ViewRequirementAgentConnector_ms": 0.22270441055297852}, "num_episodes": 18, "episode_return_max": 319.2000000000013, "episode_return_min": -37.99999999999977, "episode_return_mean": 82.05499999999978, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 672000, "num_agent_steps_trained": 672000, "num_env_steps_sampled": 168000, "num_env_steps_trained": 168000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 205.44442136858976, "num_env_steps_trained_throughput_per_sec": 205.44442136858976, "timesteps_total": 168000, "num_env_steps_sampled_lifetime": 168000, "num_agent_steps_sampled_lifetime": 672000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 672000, "timers": {"training_iteration_time_ms": 47581.302, "restore_workers_time_ms": 0.016, "training_step_time_ms": 47580.781, "sample_time_ms": 2141.73, "learn_time_ms": 45421.509, "learn_throughput": 88.064, "synch_weights_time_ms": 14.065}, "counters": {"num_env_steps_sampled": 168000, "num_env_steps_trained": 168000, "num_agent_steps_sampled": 672000, "num_agent_steps_trained": 672000}, "done": false, "training_iteration": 42, "trial_id": "75ec3_00000", "date": "2024-08-13_02-42-21", "timestamp": 1723531341, "time_this_iter_s": 19.535057067871094, "time_total_s": 4997.555176496506, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b208eb80>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 4997.555176496506, "iterations_since_restore": 42, "perf": {"cpu_util_percent": 87.48214285714285, "ram_util_percent": 83.45357142857141}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.666386907535886, "cur_kl_coeff": 0.08009033203125002, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.6173179013388497, "policy_loss": -0.0065989080720418505, "vf_loss": 2.622188400654566, "vf_explained_var": 0.14704147514212068, "kl": 0.021580785650684414, "entropy": 1.4232783093023553, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 80325.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.3239020797320538, "cur_kl_coeff": 0.0001953125, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.2900583285858076, "policy_loss": -0.001496032639480536, "vf_loss": 0.29155365842081626, "vf_explained_var": 0.003268279064269293, "kl": 0.0035993138706145607, "entropy": 0.47548818930431647, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 80325.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 172000, "num_env_steps_trained": 172000, "num_agent_steps_sampled": 688000, "num_agent_steps_trained": 688000}, "env_runners": {"episode_reward_max": 319.2000000000013, "episode_reward_min": -37.99999999999977, "episode_reward_mean": 83.76999999999977, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -130.0000000000004, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 197.29999999999998, "predator_policy": 74.0}, "policy_reward_mean": {"prey_policy": 33.394999999999975, "predator_policy": 8.49}, "custom_metrics": {}, "hist_stats": {"episode_reward": [102.09999999999849, 40.0000000000003, 238.89999999999904, 54.00000000000051, 40.0000000000003, 94.39999999999998, 94.99999999999986, 17.599999999999945, 192.99999999999923, 31.000000000000163, 142.6999999999995, 109.59999999999943, 40.0000000000003, 51.500000000000476, 94.00000000000017, 36.40000000000024, 77.79999999999964, 84.10000000000008, 92.40000000000018, 29.200000000000134, 147.99999999999906, 319.2000000000013, 145.2999999999995, 60.70000000000036, 120.99999999999864, 88.69999999999894, 98.49999999999902, 106.69999999999982, 39.20000000000023, 5.800000000000118, 82.99999999999991, 117.0999999999999, 35.20000000000023, 40.10000000000009, 35.20000000000031, 249.69999999999908, 119.19999999999953, 93.89999999999864, 101.29999999999927, -37.99999999999977, 68.5999999999999, 40.90000000000031, 50.80000000000048, 25.200000000000077, 62.50000000000042, 108.89999999999836, 119.69999999999885, 49.00000000000041, 106.99999999999935, 157.8999999999999, 49.50000000000047, 53.700000000000486, 88.79999999999957, 93.9999999999985, 41.800000000000296, 98.49999999999946, 92.39999999999985, 45.000000000000384, 76.89999999999952, 42.70000000000034, 92.19999999999877, 76.99999999999947, 75.99999999999963, 40.0000000000003, 130.3999999999994, 191.59999999999917, 56.200000000000514, 143.99999999999903, 92.19999999999943, 53.79999999999977, 58.000000000000114, -16.299999999999585, 26.800000000000093, 40.0000000000003, 56.000000000000355, 167.79999999999973, 61.89999999999946, 61.300000000000416, 110.19999999999997, 17.59999999999995, -0.29999999999987104, 129.09999999999937, 153.5999999999989, 200.89999999999898, 74.69999999999946, 55.700000000000465, 116.59999999999893, 49.90000000000032, 81.99999999999962, 49.30000000000042, 69.40000000000006, 133.59999999999854, 75.89999999999955, 107.69999999999882, 100.89999999999907, 83.19999999999908, 80.09999999999933, 98.09999999999869, 32.80000000000019, 39.80000000000028], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [80.29999999999924, 21.80000000000004, 20.000000000000014, 20.000000000000014, 158.60000000000005, 80.29999999999924, 32.00000000000022, 20.000000000000014, 20.000000000000014, 20.000000000000014, -66.40000000000045, 90.80000000000001, 43.70000000000004, 20.30000000000001, -48.700000000000024, 26.300000000000125, 109.99999999999952, 82.99999999999986, 20.000000000000014, 1.9999999999999838, 23.600000000000076, 97.09999999999994, 71.59999999999988, 20.000000000000014, 20.000000000000014, 20.000000000000014, 30.800000000000203, 13.699999999999966, 28.100000000000136, 56.89999999999999, 20.000000000000014, 7.399999999999979, 57.80000000000015, 20.000000000000014, 53.299999999999976, 30.800000000000082, 42.20000000000021, 30.200000000000003, 10.99999999999997, 3.1999999999999633, 95.59999999999955, 52.4000000000001, 113.89999999999961, 197.29999999999998, 57.50000000000015, 60.80000000000009, 20.000000000000014, 40.700000000000166, 20.000000000000014, 100.99999999999937, 13.699999999999964, 62.00000000000014, 88.39999999999952, 1.0999999999999652, -34.30000000000007, 20.000000000000014, 15.199999999999966, 20.000000000000014, -34.59999999999977, 7.399999999999965, 67.69999999999992, 5.300000000000027, 3.1999999999999957, 47.90000000000017, 20.90000000000003, 8.299999999999965, -53.50000000000005, 17.600000000000016, -26.799999999999912, 29.000000000000128, 170.29999999999987, 79.39999999999927, 99.19999999999987, 20.000000000000014, 68.89999999999984, 20.000000000000014, -31.600000000000087, 83.8999999999995, -127.6000000000003, 5.599999999999975, 40.70000000000006, 8.899999999999968, 20.000000000000014, 20.90000000000003, 30.800000000000196, 20.000000000000014, 4.099999999999998, 1.0999999999999865, 28.10000000000015, 34.40000000000018, 54.500000000000206, 52.400000000000205, 79.69999999999949, 29.000000000000163, 29.00000000000016, 20.000000000000014, 44.000000000000085, 38.00000000000021, 73.99999999999974, 83.89999999999999, 27.200000000000134, 20.30000000000002, 17.599999999999984, 28.100000000000154, 18.50000000000004, 26.30000000000011, 73.99999999999949, 20.000000000000014, 20.000000000000014, 21.800000000000047, 78.49999999999976, 20.000000000000014, 20.000000000000014, 64.39999999999998, 32.90000000000023, 1.099999999999983, 56.90000000000018, 20.000000000000014, 20.900000000000027, 21.80000000000004, 58.70000000000019, 33.50000000000024, 22.700000000000063, 41.300000000000125, 56.00000000000023, 20.000000000000014, 20.000000000000014, 20.000000000000014, 41.60000000000018, 72.79999999999991, 47.60000000000011, 128.00000000000006, 20.000000000000014, 36.20000000000026, 83.29999999999949, 49.70000000000001, 58.70000000000022, 33.50000000000005, -123.10000000000018, 65.90000000000008, -92.50000000000028, 33.49999999999999, -113.80000000000064, 15.49999999999996, 20.000000000000014, -5.199999999999934, 20.000000000000014, 20.000000000000014, -21.99999999999983, 20.000000000000014, 88.39999999999975, 79.39999999999998, 63.19999999999981, -52.29999999999984, 20.000000000000014, 26.300000000000132, 90.2000000000001, 20.000000000000014, 21.80000000000003, -26.199999999999854, -130.0000000000004, 40.70000000000025, 105.4999999999998, 11.599999999999966, 42.800000000000075, 102.79999999999941, 95.29999999999947, 86.59999999999951, 20.000000000000014, 52.70000000000011, 30.800000000000203, 17.899999999999988, 12.799999999999942, 90.7999999999995, 23.60000000000001, 26.30000000000013, 7.399999999999965, 68.59999999999988, 13.399999999999965, 29.900000000000187, 20.000000000000014, 43.4000000000001, 38.00000000000025, 95.59999999999961, 45.200000000000045, -1.2999999999999492, 79.69999999999943, 20.000000000000014, 74.89999999999951, 20.000000000000014, 32.60000000000023, 50.60000000000016, 37.100000000000236, 41.00000000000024, 20.000000000000014, 76.09999999999937, 9.499999999999964, 14.299999999999965, 20.000000000000014, 18.800000000000004], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 38.0, 32.0, 6.0, 25.0, 23.0, 17.0, 0.0, 0.0, 0.0, 9.0, 0.0, 22.0, 15.0, 3.0, 0.0, 0.0, 7.0, 0.0, 9.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 12.0, 8.0, 0.0, 15.0, 0.0, 0.0, 8.0, 0.0, 16.0, 11.0, 0.0, 0.0, 0.0, 0.0, 13.0, 0.0, 3.0, 6.0, 70.0, 51.0, 4.0, 0.0, 1.0, 32.0, 3.0, 7.0, 27.0, 39.0, 0.0, 6.0, 60.0, 16.0, 33.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 49.0, 0.0, 13.0, 71.0, 12.0, 7.0, 0.0, 0.0, 0.0, 0.0, 20.0, 0.0, 0.0, 0.0, 0.0, 2.0, 11.0, 0.0, 0.0, 0.0, 25.0, 0.0, 0.0, 0.0, 2.0, 0.0, 2.0, 6.0, 27.0, 17.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 9.0, 8.0, 8.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 74.0, 37.0, 73.0, 44.0, 66.0, 16.0, 0.0, 12.0, 0.0, 0.0, 29.0, 29.0, 0.0, 0.0, 0.0, 51.0, 11.0, 4.0, 0.0, 0.0, 22.0, 0.0, 41.0, 48.0, 10.0, 2.0, 0.0, 8.0, 8.0, 11.0, 0.0, 2.0, 1.0, 6.0, 7.0, 6.0, 0.0, 0.0, 6.0, 0.0, 0.0, 6.0, 0.0, 6.0, 0.0, 0.0, 10.0, 22.0, 0.0, 8.0, 0.0, 6.0, 0.0, 0.0, 0.0, 2.0, 0.0, 2.0, 5.0, 4.0, 0.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 26.307467271592895, "mean_inference_ms": 56.59337431975669, "mean_action_processing_ms": 13.131268667360212, "mean_env_wait_ms": 17.96603536504436, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0061397552490234375, "StateBufferConnector_ms": 0.0093611478805542, "ViewRequirementAgentConnector_ms": 0.2435145378112793}, "num_episodes": 18, "episode_return_max": 319.2000000000013, "episode_return_min": -37.99999999999977, "episode_return_mean": 83.76999999999977, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 688000, "num_agent_steps_trained": 688000, "num_env_steps_sampled": 172000, "num_env_steps_trained": 172000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 209.79754553662312, "num_env_steps_trained_throughput_per_sec": 209.79754553662312, "timesteps_total": 172000, "num_env_steps_sampled_lifetime": 172000, "num_agent_steps_sampled_lifetime": 688000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 688000, "timers": {"training_iteration_time_ms": 47848.268, "restore_workers_time_ms": 0.016, "training_step_time_ms": 47848.211, "sample_time_ms": 2216.097, "learn_time_ms": 45614.702, "learn_throughput": 87.691, "synch_weights_time_ms": 14.175}, "counters": {"num_env_steps_sampled": 172000, "num_env_steps_trained": 172000, "num_agent_steps_sampled": 688000, "num_agent_steps_trained": 688000}, "done": false, "training_iteration": 43, "trial_id": "75ec3_00000", "date": "2024-08-13_02-42-40", "timestamp": 1723531360, "time_this_iter_s": 19.119050979614258, "time_total_s": 5016.67422747612, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b1b12af0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 5016.67422747612, "iterations_since_restore": 43, "perf": {"cpu_util_percent": 86.94074074074075, "ram_util_percent": 83.28148148148149}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7076711358689758, "cur_kl_coeff": 0.12013549804687497, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.78923453603472, "policy_loss": -0.009320607212515026, "vf_loss": 6.797089333256716, "vf_explained_var": 0.02804931711267542, "kl": 0.012201254939728142, "entropy": 1.3914022113280322, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 82215.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.465076471155598, "cur_kl_coeff": 9.765625e-05, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.969658482390106, "policy_loss": -0.000829938174319015, "vf_loss": 3.970488201121174, "vf_explained_var": 9.452476703300678e-06, "kl": 0.0022238453031385398, "entropy": 0.48282828487101054, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 82215.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 176000, "num_env_steps_trained": 176000, "num_agent_steps_sampled": 704000, "num_agent_steps_trained": 704000}, "env_runners": {"episode_reward_max": 319.2000000000013, "episode_reward_min": -154.20000000000002, "episode_reward_mean": 78.58699999999975, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -309.09999999999997, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 199.1, "predator_policy": 220.0}, "policy_reward_mean": {"prey_policy": 26.193499999999972, "predator_policy": 13.1}, "custom_metrics": {}, "hist_stats": {"episode_reward": [92.40000000000018, 29.200000000000134, 147.99999999999906, 319.2000000000013, 145.2999999999995, 60.70000000000036, 120.99999999999864, 88.69999999999894, 98.49999999999902, 106.69999999999982, 39.20000000000023, 5.800000000000118, 82.99999999999991, 117.0999999999999, 35.20000000000023, 40.10000000000009, 35.20000000000031, 249.69999999999908, 119.19999999999953, 93.89999999999864, 101.29999999999927, -37.99999999999977, 68.5999999999999, 40.90000000000031, 50.80000000000048, 25.200000000000077, 62.50000000000042, 108.89999999999836, 119.69999999999885, 49.00000000000041, 106.99999999999935, 157.8999999999999, 49.50000000000047, 53.700000000000486, 88.79999999999957, 93.9999999999985, 41.800000000000296, 98.49999999999946, 92.39999999999985, 45.000000000000384, 76.89999999999952, 42.70000000000034, 92.19999999999877, 76.99999999999947, 75.99999999999963, 40.0000000000003, 130.3999999999994, 191.59999999999917, 56.200000000000514, 143.99999999999903, 92.19999999999943, 53.79999999999977, 58.000000000000114, -16.299999999999585, 26.800000000000093, 40.0000000000003, 56.000000000000355, 167.79999999999973, 61.89999999999946, 61.300000000000416, 110.19999999999997, 17.59999999999995, -0.29999999999987104, 129.09999999999937, 153.5999999999989, 200.89999999999898, 74.69999999999946, 55.700000000000465, 116.59999999999893, 49.90000000000032, 81.99999999999962, 49.30000000000042, 69.40000000000006, 133.59999999999854, 75.89999999999955, 107.69999999999882, 100.89999999999907, 83.19999999999908, 80.09999999999933, 98.09999999999869, 32.80000000000019, 39.80000000000028, 72.70000000000024, 103.09999999999957, -6.199999999999852, -154.20000000000002, 28.60000000000009, 58.90000000000014, 83.20000000000005, -65.80000000000052, 88.59999999999872, 31.100000000000115, 227.79999999999984, -71.90000000000086, 45.40000000000012, 78.29999999999961, 68.20000000000017, 101.19999999999997, 272.1999999999995, 62.60000000000028], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [42.20000000000021, 30.200000000000003, 10.99999999999997, 3.1999999999999633, 95.59999999999955, 52.4000000000001, 113.89999999999961, 197.29999999999998, 57.50000000000015, 60.80000000000009, 20.000000000000014, 40.700000000000166, 20.000000000000014, 100.99999999999937, 13.699999999999964, 62.00000000000014, 88.39999999999952, 1.0999999999999652, -34.30000000000007, 20.000000000000014, 15.199999999999966, 20.000000000000014, -34.59999999999977, 7.399999999999965, 67.69999999999992, 5.300000000000027, 3.1999999999999957, 47.90000000000017, 20.90000000000003, 8.299999999999965, -53.50000000000005, 17.600000000000016, -26.799999999999912, 29.000000000000128, 170.29999999999987, 79.39999999999927, 99.19999999999987, 20.000000000000014, 68.89999999999984, 20.000000000000014, -31.600000000000087, 83.8999999999995, -127.6000000000003, 5.599999999999975, 40.70000000000006, 8.899999999999968, 20.000000000000014, 20.90000000000003, 30.800000000000196, 20.000000000000014, 4.099999999999998, 1.0999999999999865, 28.10000000000015, 34.40000000000018, 54.500000000000206, 52.400000000000205, 79.69999999999949, 29.000000000000163, 29.00000000000016, 20.000000000000014, 44.000000000000085, 38.00000000000021, 73.99999999999974, 83.89999999999999, 27.200000000000134, 20.30000000000002, 17.599999999999984, 28.100000000000154, 18.50000000000004, 26.30000000000011, 73.99999999999949, 20.000000000000014, 20.000000000000014, 21.800000000000047, 78.49999999999976, 20.000000000000014, 20.000000000000014, 64.39999999999998, 32.90000000000023, 1.099999999999983, 56.90000000000018, 20.000000000000014, 20.900000000000027, 21.80000000000004, 58.70000000000019, 33.50000000000024, 22.700000000000063, 41.300000000000125, 56.00000000000023, 20.000000000000014, 20.000000000000014, 20.000000000000014, 41.60000000000018, 72.79999999999991, 47.60000000000011, 128.00000000000006, 20.000000000000014, 36.20000000000026, 83.29999999999949, 49.70000000000001, 58.70000000000022, 33.50000000000005, -123.10000000000018, 65.90000000000008, -92.50000000000028, 33.49999999999999, -113.80000000000064, 15.49999999999996, 20.000000000000014, -5.199999999999934, 20.000000000000014, 20.000000000000014, -21.99999999999983, 20.000000000000014, 88.39999999999975, 79.39999999999998, 63.19999999999981, -52.29999999999984, 20.000000000000014, 26.300000000000132, 90.2000000000001, 20.000000000000014, 21.80000000000003, -26.199999999999854, -130.0000000000004, 40.70000000000025, 105.4999999999998, 11.599999999999966, 42.800000000000075, 102.79999999999941, 95.29999999999947, 86.59999999999951, 20.000000000000014, 52.70000000000011, 30.800000000000203, 17.899999999999988, 12.799999999999942, 90.7999999999995, 23.60000000000001, 26.30000000000013, 7.399999999999965, 68.59999999999988, 13.399999999999965, 29.900000000000187, 20.000000000000014, 43.4000000000001, 38.00000000000025, 95.59999999999961, 45.200000000000045, -1.2999999999999492, 79.69999999999943, 20.000000000000014, 74.89999999999951, 20.000000000000014, 32.60000000000023, 50.60000000000016, 37.100000000000236, 41.00000000000024, 20.000000000000014, 76.09999999999937, 9.499999999999964, 14.299999999999965, 20.000000000000014, 18.800000000000004, 49.700000000000216, 20.000000000000014, -208.59999999999997, 112.69999999999968, -68.20000000000061, 20.000000000000014, -309.09999999999997, -66.10000000000004, 9.499999999999964, 7.0999999999999694, 22.700000000000063, 27.20000000000006, 20.000000000000014, 63.20000000000003, -15.400000000000375, -249.39999999999998, 20.000000000000014, 68.59999999999988, -120.70000000000002, 84.79999999999976, 35.900000000000105, 167.89999999999984, -219.40000000000046, 33.50000000000007, 7.399999999999965, 29.000000000000007, -78.99999999999999, 26.30000000000004, 45.20000000000023, 20.000000000000014, -19.299999999999976, 18.49999999999997, 73.09999999999977, 199.1, 29.900000000000084, 28.700000000000063], "policy_predator_policy_reward": [12.0, 8.0, 0.0, 15.0, 0.0, 0.0, 8.0, 0.0, 16.0, 11.0, 0.0, 0.0, 0.0, 0.0, 13.0, 0.0, 3.0, 6.0, 70.0, 51.0, 4.0, 0.0, 1.0, 32.0, 3.0, 7.0, 27.0, 39.0, 0.0, 6.0, 60.0, 16.0, 33.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 49.0, 0.0, 13.0, 71.0, 12.0, 7.0, 0.0, 0.0, 0.0, 0.0, 20.0, 0.0, 0.0, 0.0, 0.0, 2.0, 11.0, 0.0, 0.0, 0.0, 25.0, 0.0, 0.0, 0.0, 2.0, 0.0, 2.0, 6.0, 27.0, 17.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 9.0, 8.0, 8.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 74.0, 37.0, 73.0, 44.0, 66.0, 16.0, 0.0, 12.0, 0.0, 0.0, 29.0, 29.0, 0.0, 0.0, 0.0, 51.0, 11.0, 4.0, 0.0, 0.0, 22.0, 0.0, 41.0, 48.0, 10.0, 2.0, 0.0, 8.0, 8.0, 11.0, 0.0, 2.0, 1.0, 6.0, 7.0, 6.0, 0.0, 0.0, 6.0, 0.0, 0.0, 6.0, 0.0, 6.0, 0.0, 0.0, 10.0, 22.0, 0.0, 8.0, 0.0, 6.0, 0.0, 0.0, 0.0, 2.0, 0.0, 2.0, 5.0, 4.0, 0.0, 1.0, 3.0, 0.0, 82.0, 117.0, 0.0, 42.0, 220.0, 1.0, 12.0, 0.0, 0.0, 9.0, 0.0, 0.0, 139.0, 60.0, 0.0, 0.0, 0.0, 67.0, 2.0, 22.0, 114.0, 0.0, 6.0, 3.0, 66.0, 65.0, 0.0, 3.0, 11.0, 91.0, 0.0, 0.0, 4.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 25.762242280593817, "mean_inference_ms": 55.43371128196401, "mean_action_processing_ms": 12.855181524154391, "mean_env_wait_ms": 17.586799362269673, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007690072059631348, "StateBufferConnector_ms": 0.009534716606140137, "ViewRequirementAgentConnector_ms": 0.22060346603393555}, "num_episodes": 18, "episode_return_max": 319.2000000000013, "episode_return_min": -154.20000000000002, "episode_return_mean": 78.58699999999975, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 704000, "num_agent_steps_trained": 704000, "num_env_steps_sampled": 176000, "num_env_steps_trained": 176000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 203.2725354303878, "num_env_steps_trained_throughput_per_sec": 203.2725354303878, "timesteps_total": 176000, "num_env_steps_sampled_lifetime": 176000, "num_agent_steps_sampled_lifetime": 704000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 704000, "timers": {"training_iteration_time_ms": 17162.939, "restore_workers_time_ms": 0.017, "training_step_time_ms": 17162.881, "sample_time_ms": 2297.37, "learn_time_ms": 14846.928, "learn_throughput": 269.416, "synch_weights_time_ms": 14.768}, "counters": {"num_env_steps_sampled": 176000, "num_env_steps_trained": 176000, "num_agent_steps_sampled": 704000, "num_agent_steps_trained": 704000}, "done": false, "training_iteration": 44, "trial_id": "75ec3_00000", "date": "2024-08-13_02-43-00", "timestamp": 1723531380, "time_this_iter_s": 19.743685245513916, "time_total_s": 5036.417912721634, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b1adfaf0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 5036.417912721634, "iterations_since_restore": 44, "perf": {"cpu_util_percent": 87.6607142857143, "ram_util_percent": 83.37142857142855}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.120176745620039, "cur_kl_coeff": 0.12013549804687497, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.872544737846132, "policy_loss": -0.006433555479875948, "vf_loss": 3.876849831222857, "vf_explained_var": 0.1357388747116876, "kl": 0.01771722006592271, "entropy": 1.3512913703287721, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 84105.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.3384512735737695, "cur_kl_coeff": 4.8828125e-05, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.5707889143357832, "policy_loss": -0.0002316790462900249, "vf_loss": 0.5710204821612154, "vf_explained_var": 0.01552358279152522, "kl": 0.002221745027900406, "entropy": 0.4346555486873344, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 84105.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 180000, "num_env_steps_trained": 180000, "num_agent_steps_sampled": 720000, "num_agent_steps_trained": 720000}, "env_runners": {"episode_reward_max": 292.0000000000002, "episode_reward_min": -154.20000000000002, "episode_reward_mean": 78.36699999999972, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -309.09999999999997, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 199.1, "predator_policy": 220.0}, "policy_reward_mean": {"prey_policy": 24.85849999999997, "predator_policy": 14.325}, "custom_metrics": {}, "hist_stats": {"episode_reward": [68.5999999999999, 40.90000000000031, 50.80000000000048, 25.200000000000077, 62.50000000000042, 108.89999999999836, 119.69999999999885, 49.00000000000041, 106.99999999999935, 157.8999999999999, 49.50000000000047, 53.700000000000486, 88.79999999999957, 93.9999999999985, 41.800000000000296, 98.49999999999946, 92.39999999999985, 45.000000000000384, 76.89999999999952, 42.70000000000034, 92.19999999999877, 76.99999999999947, 75.99999999999963, 40.0000000000003, 130.3999999999994, 191.59999999999917, 56.200000000000514, 143.99999999999903, 92.19999999999943, 53.79999999999977, 58.000000000000114, -16.299999999999585, 26.800000000000093, 40.0000000000003, 56.000000000000355, 167.79999999999973, 61.89999999999946, 61.300000000000416, 110.19999999999997, 17.59999999999995, -0.29999999999987104, 129.09999999999937, 153.5999999999989, 200.89999999999898, 74.69999999999946, 55.700000000000465, 116.59999999999893, 49.90000000000032, 81.99999999999962, 49.30000000000042, 69.40000000000006, 133.59999999999854, 75.89999999999955, 107.69999999999882, 100.89999999999907, 83.19999999999908, 80.09999999999933, 98.09999999999869, 32.80000000000019, 39.80000000000028, 72.70000000000024, 103.09999999999957, -6.199999999999852, -154.20000000000002, 28.60000000000009, 58.90000000000014, 83.20000000000005, -65.80000000000052, 88.59999999999872, 31.100000000000115, 227.79999999999984, -71.90000000000086, 45.40000000000012, 78.29999999999961, 68.20000000000017, 101.19999999999997, 272.1999999999995, 62.60000000000028, 292.0000000000002, 78.50000000000009, 88.899999999999, -25.299999999999685, 90.19999999999969, 37.00000000000024, 67.2999999999999, 125.19999999999914, 40.0000000000003, 201.99999999999903, 133.09999999999906, 144.19999999999902, -117.2000000000009, 52.400000000000496, 233.1999999999992, 160.599999999999, 83.50000000000009, 64.7000000000003, 40.0000000000003, 81.29999999999923, 94.19999999999936, 103.59999999999873], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [40.70000000000006, 8.899999999999968, 20.000000000000014, 20.90000000000003, 30.800000000000196, 20.000000000000014, 4.099999999999998, 1.0999999999999865, 28.10000000000015, 34.40000000000018, 54.500000000000206, 52.400000000000205, 79.69999999999949, 29.000000000000163, 29.00000000000016, 20.000000000000014, 44.000000000000085, 38.00000000000021, 73.99999999999974, 83.89999999999999, 27.200000000000134, 20.30000000000002, 17.599999999999984, 28.100000000000154, 18.50000000000004, 26.30000000000011, 73.99999999999949, 20.000000000000014, 20.000000000000014, 21.800000000000047, 78.49999999999976, 20.000000000000014, 20.000000000000014, 64.39999999999998, 32.90000000000023, 1.099999999999983, 56.90000000000018, 20.000000000000014, 20.900000000000027, 21.80000000000004, 58.70000000000019, 33.50000000000024, 22.700000000000063, 41.300000000000125, 56.00000000000023, 20.000000000000014, 20.000000000000014, 20.000000000000014, 41.60000000000018, 72.79999999999991, 47.60000000000011, 128.00000000000006, 20.000000000000014, 36.20000000000026, 83.29999999999949, 49.70000000000001, 58.70000000000022, 33.50000000000005, -123.10000000000018, 65.90000000000008, -92.50000000000028, 33.49999999999999, -113.80000000000064, 15.49999999999996, 20.000000000000014, -5.199999999999934, 20.000000000000014, 20.000000000000014, -21.99999999999983, 20.000000000000014, 88.39999999999975, 79.39999999999998, 63.19999999999981, -52.29999999999984, 20.000000000000014, 26.300000000000132, 90.2000000000001, 20.000000000000014, 21.80000000000003, -26.199999999999854, -130.0000000000004, 40.70000000000025, 105.4999999999998, 11.599999999999966, 42.800000000000075, 102.79999999999941, 95.29999999999947, 86.59999999999951, 20.000000000000014, 52.70000000000011, 30.800000000000203, 17.899999999999988, 12.799999999999942, 90.7999999999995, 23.60000000000001, 26.30000000000013, 7.399999999999965, 68.59999999999988, 13.399999999999965, 29.900000000000187, 20.000000000000014, 43.4000000000001, 38.00000000000025, 95.59999999999961, 45.200000000000045, -1.2999999999999492, 79.69999999999943, 20.000000000000014, 74.89999999999951, 20.000000000000014, 32.60000000000023, 50.60000000000016, 37.100000000000236, 41.00000000000024, 20.000000000000014, 76.09999999999937, 9.499999999999964, 14.299999999999965, 20.000000000000014, 18.800000000000004, 49.700000000000216, 20.000000000000014, -208.59999999999997, 112.69999999999968, -68.20000000000061, 20.000000000000014, -309.09999999999997, -66.10000000000004, 9.499999999999964, 7.0999999999999694, 22.700000000000063, 27.20000000000006, 20.000000000000014, 63.20000000000003, -15.400000000000375, -249.39999999999998, 20.000000000000014, 68.59999999999988, -120.70000000000002, 84.79999999999976, 35.900000000000105, 167.89999999999984, -219.40000000000046, 33.50000000000007, 7.399999999999965, 29.000000000000007, -78.99999999999999, 26.30000000000004, 45.20000000000023, 20.000000000000014, -19.299999999999976, 18.49999999999997, 73.09999999999977, 199.1, 29.900000000000084, 28.700000000000063, 130.9999999999999, 134.00000000000006, 20.000000000000014, 57.50000000000005, 18.200000000000003, 67.69999999999992, 20.000000000000014, -295.2999999999996, 71.30000000000004, 17.899999999999988, -6.9999999999999165, 20.000000000000014, -120.70000000000007, 20.000000000000014, 23.60000000000008, 89.59999999999971, 20.000000000000014, 20.000000000000014, 132.49999999999983, 69.49999999999982, 1.0999999999999865, 115.99999999999966, 113.2999999999997, 20.90000000000003, -214.90000000000018, -40.30000000000039, 16.399999999999963, 20.000000000000014, 104.59999999999974, 110.59999999999948, 133.3999999999997, 27.200000000000124, 55.10000000000004, -22.600000000000463, 44.00000000000017, 13.699999999999958, 20.000000000000014, 20.000000000000014, 65.00000000000014, 11.299999999999965, 132.49999999999957, -109.30000000000018, 68.59999999999985, 29.000000000000064], "policy_predator_policy_reward": [12.0, 7.0, 0.0, 0.0, 0.0, 0.0, 20.0, 0.0, 0.0, 0.0, 0.0, 2.0, 11.0, 0.0, 0.0, 0.0, 25.0, 0.0, 0.0, 0.0, 2.0, 0.0, 2.0, 6.0, 27.0, 17.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 9.0, 8.0, 8.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 74.0, 37.0, 73.0, 44.0, 66.0, 16.0, 0.0, 12.0, 0.0, 0.0, 29.0, 29.0, 0.0, 0.0, 0.0, 51.0, 11.0, 4.0, 0.0, 0.0, 22.0, 0.0, 41.0, 48.0, 10.0, 2.0, 0.0, 8.0, 8.0, 11.0, 0.0, 2.0, 1.0, 6.0, 7.0, 6.0, 0.0, 0.0, 6.0, 0.0, 0.0, 6.0, 0.0, 6.0, 0.0, 0.0, 10.0, 22.0, 0.0, 8.0, 0.0, 6.0, 0.0, 0.0, 0.0, 2.0, 0.0, 2.0, 5.0, 4.0, 0.0, 1.0, 3.0, 0.0, 82.0, 117.0, 0.0, 42.0, 220.0, 1.0, 12.0, 0.0, 0.0, 9.0, 0.0, 0.0, 139.0, 60.0, 0.0, 0.0, 0.0, 67.0, 2.0, 22.0, 114.0, 0.0, 6.0, 3.0, 66.0, 65.0, 0.0, 3.0, 11.0, 91.0, 0.0, 0.0, 4.0, 0.0, 13.0, 14.0, 0.0, 1.0, 0.0, 3.0, 100.0, 150.0, 0.0, 1.0, 0.0, 24.0, 78.0, 90.0, 3.0, 9.0, 0.0, 0.0, 0.0, 0.0, 9.0, 7.0, 0.0, 10.0, 120.0, 18.0, 7.0, 9.0, 18.0, 0.0, 0.0, 0.0, 18.0, 33.0, 0.0, 7.0, 0.0, 0.0, 0.0, 5.0, 0.0, 71.0, 0.0, 6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 25.11224944745999, "mean_inference_ms": 54.1433159630997, "mean_action_processing_ms": 12.59030695500258, "mean_env_wait_ms": 17.044515294591417, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0071800947189331055, "StateBufferConnector_ms": 0.004597783088684082, "ViewRequirementAgentConnector_ms": 0.2202000617980957}, "num_episodes": 22, "episode_return_max": 292.0000000000002, "episode_return_min": -154.20000000000002, "episode_return_mean": 78.36699999999972, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 720000, "num_agent_steps_trained": 720000, "num_env_steps_sampled": 180000, "num_env_steps_trained": 180000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 196.51454888801922, "num_env_steps_trained_throughput_per_sec": 196.51454888801922, "timesteps_total": 180000, "num_env_steps_sampled_lifetime": 180000, "num_agent_steps_sampled_lifetime": 720000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 720000, "timers": {"training_iteration_time_ms": 17466.587, "restore_workers_time_ms": 0.017, "training_step_time_ms": 17466.53, "sample_time_ms": 2213.7, "learn_time_ms": 15234.705, "learn_throughput": 262.558, "synch_weights_time_ms": 14.899}, "counters": {"num_env_steps_sampled": 180000, "num_env_steps_trained": 180000, "num_agent_steps_sampled": 720000, "num_agent_steps_trained": 720000}, "done": false, "training_iteration": 45, "trial_id": "75ec3_00000", "date": "2024-08-13_02-43-21", "timestamp": 1723531401, "time_this_iter_s": 20.418344974517822, "time_total_s": 5056.836257696152, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2058790>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 5056.836257696152, "iterations_since_restore": 45, "perf": {"cpu_util_percent": 87.97586206896551, "ram_util_percent": 83.32758620689654}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.0981260706744496, "cur_kl_coeff": 0.12013549804687497, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.1295580398468745, "policy_loss": -0.0019561155010556813, "vf_loss": 5.1307705358222675, "vf_explained_var": 0.10860455957039324, "kl": 0.006189783896981138, "entropy": 1.2922630486034212, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 85995.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.36635636326674587, "cur_kl_coeff": 2.44140625e-05, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.2510833123846659, "policy_loss": -0.0014070820585681647, "vf_loss": 1.2524902819168, "vf_explained_var": 0.0045245692528114115, "kl": 0.0043416577214870624, "entropy": 0.360066215891056, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 85995.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 184000, "num_env_steps_trained": 184000, "num_agent_steps_sampled": 736000, "num_agent_steps_trained": 736000}, "env_runners": {"episode_reward_max": 352.6, "episode_reward_min": -154.20000000000002, "episode_reward_mean": 85.22399999999972, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -309.09999999999997, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 199.1, "predator_policy": 220.0}, "policy_reward_mean": {"prey_policy": 27.01699999999995, "predator_policy": 15.595}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0000000000003, 130.3999999999994, 191.59999999999917, 56.200000000000514, 143.99999999999903, 92.19999999999943, 53.79999999999977, 58.000000000000114, -16.299999999999585, 26.800000000000093, 40.0000000000003, 56.000000000000355, 167.79999999999973, 61.89999999999946, 61.300000000000416, 110.19999999999997, 17.59999999999995, -0.29999999999987104, 129.09999999999937, 153.5999999999989, 200.89999999999898, 74.69999999999946, 55.700000000000465, 116.59999999999893, 49.90000000000032, 81.99999999999962, 49.30000000000042, 69.40000000000006, 133.59999999999854, 75.89999999999955, 107.69999999999882, 100.89999999999907, 83.19999999999908, 80.09999999999933, 98.09999999999869, 32.80000000000019, 39.80000000000028, 72.70000000000024, 103.09999999999957, -6.199999999999852, -154.20000000000002, 28.60000000000009, 58.90000000000014, 83.20000000000005, -65.80000000000052, 88.59999999999872, 31.100000000000115, 227.79999999999984, -71.90000000000086, 45.40000000000012, 78.29999999999961, 68.20000000000017, 101.19999999999997, 272.1999999999995, 62.60000000000028, 292.0000000000002, 78.50000000000009, 88.899999999999, -25.299999999999685, 90.19999999999969, 37.00000000000024, 67.2999999999999, 125.19999999999914, 40.0000000000003, 201.99999999999903, 133.09999999999906, 144.19999999999902, -117.2000000000009, 52.400000000000496, 233.1999999999992, 160.599999999999, 83.50000000000009, 64.7000000000003, 40.0000000000003, 81.29999999999923, 94.19999999999936, 103.59999999999873, -62.4999999999997, 48.100000000000364, 40.0000000000003, 192.99999999999903, 53.10000000000014, 199.29999999999936, 158.3999999999994, 33.60000000000041, 56.20000000000027, 121.09999999999903, 58.00000000000045, 36.30000000000025, 143.0999999999995, 102.19999999999969, 69.29999999999991, 41.800000000000296, 151.69999999999982, 101.19999999999888, 352.6, 23.500000000000046, 195.49999999999875, 76.90000000000015, 212.29999999999927], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 20.000000000000014, 41.60000000000018, 72.79999999999991, 47.60000000000011, 128.00000000000006, 20.000000000000014, 36.20000000000026, 83.29999999999949, 49.70000000000001, 58.70000000000022, 33.50000000000005, -123.10000000000018, 65.90000000000008, -92.50000000000028, 33.49999999999999, -113.80000000000064, 15.49999999999996, 20.000000000000014, -5.199999999999934, 20.000000000000014, 20.000000000000014, -21.99999999999983, 20.000000000000014, 88.39999999999975, 79.39999999999998, 63.19999999999981, -52.29999999999984, 20.000000000000014, 26.300000000000132, 90.2000000000001, 20.000000000000014, 21.80000000000003, -26.199999999999854, -130.0000000000004, 40.70000000000025, 105.4999999999998, 11.599999999999966, 42.800000000000075, 102.79999999999941, 95.29999999999947, 86.59999999999951, 20.000000000000014, 52.70000000000011, 30.800000000000203, 17.899999999999988, 12.799999999999942, 90.7999999999995, 23.60000000000001, 26.30000000000013, 7.399999999999965, 68.59999999999988, 13.399999999999965, 29.900000000000187, 20.000000000000014, 43.4000000000001, 38.00000000000025, 95.59999999999961, 45.200000000000045, -1.2999999999999492, 79.69999999999943, 20.000000000000014, 74.89999999999951, 20.000000000000014, 32.60000000000023, 50.60000000000016, 37.100000000000236, 41.00000000000024, 20.000000000000014, 76.09999999999937, 9.499999999999964, 14.299999999999965, 20.000000000000014, 18.800000000000004, 49.700000000000216, 20.000000000000014, -208.59999999999997, 112.69999999999968, -68.20000000000061, 20.000000000000014, -309.09999999999997, -66.10000000000004, 9.499999999999964, 7.0999999999999694, 22.700000000000063, 27.20000000000006, 20.000000000000014, 63.20000000000003, -15.400000000000375, -249.39999999999998, 20.000000000000014, 68.59999999999988, -120.70000000000002, 84.79999999999976, 35.900000000000105, 167.89999999999984, -219.40000000000046, 33.50000000000007, 7.399999999999965, 29.000000000000007, -78.99999999999999, 26.30000000000004, 45.20000000000023, 20.000000000000014, -19.299999999999976, 18.49999999999997, 73.09999999999977, 199.1, 29.900000000000084, 28.700000000000063, 130.9999999999999, 134.00000000000006, 20.000000000000014, 57.50000000000005, 18.200000000000003, 67.69999999999992, 20.000000000000014, -295.2999999999996, 71.30000000000004, 17.899999999999988, -6.9999999999999165, 20.000000000000014, -120.70000000000007, 20.000000000000014, 23.60000000000008, 89.59999999999971, 20.000000000000014, 20.000000000000014, 132.49999999999983, 69.49999999999982, 1.0999999999999865, 115.99999999999966, 113.2999999999997, 20.90000000000003, -214.90000000000018, -40.30000000000039, 16.399999999999963, 20.000000000000014, 104.59999999999974, 110.59999999999948, 133.3999999999997, 27.200000000000124, 55.10000000000004, -22.600000000000463, 44.00000000000017, 13.699999999999958, 20.000000000000014, 20.000000000000014, 65.00000000000014, 11.299999999999965, 132.49999999999957, -109.30000000000018, 68.59999999999985, 29.000000000000064, -219.40000000000043, 35.90000000000013, 28.10000000000016, 20.000000000000014, 20.000000000000014, 20.000000000000014, 58.700000000000216, 134.3, -4.899999999999958, 29.000000000000135, 2.8999999999999613, 187.39999999999998, 127.3999999999999, 20.000000000000014, -24.099999999999987, 25.70000000000012, 20.000000000000014, 36.19999999999999, 19.100000000000016, 97.99999999999956, 20.900000000000027, 37.10000000000021, 9.499999999999966, 21.800000000000047, 23.599999999999998, 93.49999999999967, 25.4000000000001, 9.800000000000063, 108.7999999999995, -95.50000000000075, 20.000000000000014, 21.80000000000001, 49.39999999999999, 80.29999999999984, 20.000000000000014, 81.19999999999943, 167.6, 173.0, -11.49999999999984, 20.000000000000014, 72.79999999999961, 121.6999999999997, 56.89999999999998, 20.000000000000014, 158.89999999999984, 46.40000000000004], "policy_predator_policy_reward": [0.0, 0.0, 7.0, 9.0, 8.0, 8.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 74.0, 37.0, 73.0, 44.0, 66.0, 16.0, 0.0, 12.0, 0.0, 0.0, 29.0, 29.0, 0.0, 0.0, 0.0, 51.0, 11.0, 4.0, 0.0, 0.0, 22.0, 0.0, 41.0, 48.0, 10.0, 2.0, 0.0, 8.0, 8.0, 11.0, 0.0, 2.0, 1.0, 6.0, 7.0, 6.0, 0.0, 0.0, 6.0, 0.0, 0.0, 6.0, 0.0, 6.0, 0.0, 0.0, 10.0, 22.0, 0.0, 8.0, 0.0, 6.0, 0.0, 0.0, 0.0, 2.0, 0.0, 2.0, 5.0, 4.0, 0.0, 1.0, 3.0, 0.0, 82.0, 117.0, 0.0, 42.0, 220.0, 1.0, 12.0, 0.0, 0.0, 9.0, 0.0, 0.0, 139.0, 60.0, 0.0, 0.0, 0.0, 67.0, 2.0, 22.0, 114.0, 0.0, 6.0, 3.0, 66.0, 65.0, 0.0, 3.0, 11.0, 91.0, 0.0, 0.0, 4.0, 0.0, 13.0, 14.0, 0.0, 1.0, 0.0, 3.0, 100.0, 150.0, 0.0, 1.0, 0.0, 24.0, 78.0, 90.0, 3.0, 9.0, 0.0, 0.0, 0.0, 0.0, 9.0, 7.0, 0.0, 10.0, 120.0, 18.0, 7.0, 9.0, 18.0, 0.0, 0.0, 0.0, 18.0, 33.0, 0.0, 7.0, 0.0, 0.0, 0.0, 5.0, 0.0, 71.0, 0.0, 6.0, 7.0, 114.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 17.0, 12.0, 0.0, 9.0, 0.0, 11.0, 0.0, 32.0, 0.0, 0.0, 3.0, 1.0, 0.0, 0.0, 5.0, 0.0, 12.0, 14.0, 33.0, 34.0, 55.0, 1.0, 0.0, 0.0, 20.0, 2.0, 0.0, 0.0, 3.0, 9.0, 0.0, 15.0, 0.0, 1.0, 0.0, 0.0, 2.0, 5.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 24.498690399032938, "mean_inference_ms": 52.73591209258942, "mean_action_processing_ms": 12.220964904985863, "mean_env_wait_ms": 16.69909413865272, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0078355073928833, "StateBufferConnector_ms": 0.005055427551269531, "ViewRequirementAgentConnector_ms": 0.22784006595611572}, "num_episodes": 23, "episode_return_max": 352.6, "episode_return_min": -154.20000000000002, "episode_return_mean": 85.22399999999972, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 736000, "num_agent_steps_trained": 736000, "num_env_steps_sampled": 184000, "num_env_steps_trained": 184000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 189.42491046296593, "num_env_steps_trained_throughput_per_sec": 189.42491046296593, "timesteps_total": 184000, "num_env_steps_sampled_lifetime": 184000, "num_agent_steps_sampled_lifetime": 736000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 736000, "timers": {"training_iteration_time_ms": 18080.033, "restore_workers_time_ms": 0.017, "training_step_time_ms": 18079.975, "sample_time_ms": 2299.419, "learn_time_ms": 15760.049, "learn_throughput": 253.806, "synch_weights_time_ms": 17.102}, "counters": {"num_env_steps_sampled": 184000, "num_env_steps_trained": 184000, "num_agent_steps_sampled": 736000, "num_agent_steps_trained": 736000}, "done": false, "training_iteration": 46, "trial_id": "75ec3_00000", "date": "2024-08-13_02-43-42", "timestamp": 1723531422, "time_this_iter_s": 21.18041491508484, "time_total_s": 5078.016672611237, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b205cc10>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 5078.016672611237, "iterations_since_restore": 46, "perf": {"cpu_util_percent": 86.72333333333333, "ram_util_percent": 83.36666666666666}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.1216258112360875, "cur_kl_coeff": 0.12013549804687497, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.597869212539107, "policy_loss": -0.007306444172368006, "vf_loss": 5.602961686048558, "vf_explained_var": 0.07004190295461625, "kl": 0.01842897984791246, "entropy": 1.2616285377078587, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 87885.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4744313277757515, "cur_kl_coeff": 1.220703125e-05, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.9750474997613796, "policy_loss": -0.0013772511366932166, "vf_loss": 1.976424755778893, "vf_explained_var": 0.0014178302237596461, "kl": 0.002121433020525714, "entropy": 0.40594331969029057, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 87885.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 188000, "num_env_steps_trained": 188000, "num_agent_steps_sampled": 752000, "num_agent_steps_trained": 752000}, "env_runners": {"episode_reward_max": 352.6, "episode_reward_min": -154.20000000000002, "episode_reward_mean": 90.86399999999966, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -309.09999999999997, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 199.1, "predator_policy": 220.0}, "policy_reward_mean": {"prey_policy": 29.761999999999933, "predator_policy": 15.67}, "custom_metrics": {}, "hist_stats": {"episode_reward": [129.09999999999937, 153.5999999999989, 200.89999999999898, 74.69999999999946, 55.700000000000465, 116.59999999999893, 49.90000000000032, 81.99999999999962, 49.30000000000042, 69.40000000000006, 133.59999999999854, 75.89999999999955, 107.69999999999882, 100.89999999999907, 83.19999999999908, 80.09999999999933, 98.09999999999869, 32.80000000000019, 39.80000000000028, 72.70000000000024, 103.09999999999957, -6.199999999999852, -154.20000000000002, 28.60000000000009, 58.90000000000014, 83.20000000000005, -65.80000000000052, 88.59999999999872, 31.100000000000115, 227.79999999999984, -71.90000000000086, 45.40000000000012, 78.29999999999961, 68.20000000000017, 101.19999999999997, 272.1999999999995, 62.60000000000028, 292.0000000000002, 78.50000000000009, 88.899999999999, -25.299999999999685, 90.19999999999969, 37.00000000000024, 67.2999999999999, 125.19999999999914, 40.0000000000003, 201.99999999999903, 133.09999999999906, 144.19999999999902, -117.2000000000009, 52.400000000000496, 233.1999999999992, 160.599999999999, 83.50000000000009, 64.7000000000003, 40.0000000000003, 81.29999999999923, 94.19999999999936, 103.59999999999873, -62.4999999999997, 48.100000000000364, 40.0000000000003, 192.99999999999903, 53.10000000000014, 199.29999999999936, 158.3999999999994, 33.60000000000041, 56.20000000000027, 121.09999999999903, 58.00000000000045, 36.30000000000025, 143.0999999999995, 102.19999999999969, 69.29999999999991, 41.800000000000296, 151.69999999999982, 101.19999999999888, 352.6, 23.500000000000046, 195.49999999999875, 76.90000000000015, 212.29999999999927, 89.3, 158.199999999999, 65.1999999999992, 96.89999999999976, 161.19999999999962, 40.0000000000003, 166.6999999999996, 111.19999999999914, 95.79999999999993, 202.1999999999992, 113.59999999999874, 216.39999999999898, 53.50000000000005, 77.79999999999947, 33.400000000000155, 103.49999999999889, 42.60000000000027, 27.700000000000244], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [105.4999999999998, 11.599999999999966, 42.800000000000075, 102.79999999999941, 95.29999999999947, 86.59999999999951, 20.000000000000014, 52.70000000000011, 30.800000000000203, 17.899999999999988, 12.799999999999942, 90.7999999999995, 23.60000000000001, 26.30000000000013, 7.399999999999965, 68.59999999999988, 13.399999999999965, 29.900000000000187, 20.000000000000014, 43.4000000000001, 38.00000000000025, 95.59999999999961, 45.200000000000045, -1.2999999999999492, 79.69999999999943, 20.000000000000014, 74.89999999999951, 20.000000000000014, 32.60000000000023, 50.60000000000016, 37.100000000000236, 41.00000000000024, 20.000000000000014, 76.09999999999937, 9.499999999999964, 14.299999999999965, 20.000000000000014, 18.800000000000004, 49.700000000000216, 20.000000000000014, -208.59999999999997, 112.69999999999968, -68.20000000000061, 20.000000000000014, -309.09999999999997, -66.10000000000004, 9.499999999999964, 7.0999999999999694, 22.700000000000063, 27.20000000000006, 20.000000000000014, 63.20000000000003, -15.400000000000375, -249.39999999999998, 20.000000000000014, 68.59999999999988, -120.70000000000002, 84.79999999999976, 35.900000000000105, 167.89999999999984, -219.40000000000046, 33.50000000000007, 7.399999999999965, 29.000000000000007, -78.99999999999999, 26.30000000000004, 45.20000000000023, 20.000000000000014, -19.299999999999976, 18.49999999999997, 73.09999999999977, 199.1, 29.900000000000084, 28.700000000000063, 130.9999999999999, 134.00000000000006, 20.000000000000014, 57.50000000000005, 18.200000000000003, 67.69999999999992, 20.000000000000014, -295.2999999999996, 71.30000000000004, 17.899999999999988, -6.9999999999999165, 20.000000000000014, -120.70000000000007, 20.000000000000014, 23.60000000000008, 89.59999999999971, 20.000000000000014, 20.000000000000014, 132.49999999999983, 69.49999999999982, 1.0999999999999865, 115.99999999999966, 113.2999999999997, 20.90000000000003, -214.90000000000018, -40.30000000000039, 16.399999999999963, 20.000000000000014, 104.59999999999974, 110.59999999999948, 133.3999999999997, 27.200000000000124, 55.10000000000004, -22.600000000000463, 44.00000000000017, 13.699999999999958, 20.000000000000014, 20.000000000000014, 65.00000000000014, 11.299999999999965, 132.49999999999957, -109.30000000000018, 68.59999999999985, 29.000000000000064, -219.40000000000043, 35.90000000000013, 28.10000000000016, 20.000000000000014, 20.000000000000014, 20.000000000000014, 58.700000000000216, 134.3, -4.899999999999958, 29.000000000000135, 2.8999999999999613, 187.39999999999998, 127.3999999999999, 20.000000000000014, -24.099999999999987, 25.70000000000012, 20.000000000000014, 36.19999999999999, 19.100000000000016, 97.99999999999956, 20.900000000000027, 37.10000000000021, 9.499999999999966, 21.800000000000047, 23.599999999999998, 93.49999999999967, 25.4000000000001, 9.800000000000063, 108.7999999999995, -95.50000000000075, 20.000000000000014, 21.80000000000001, 49.39999999999999, 80.29999999999984, 20.000000000000014, 81.19999999999943, 167.6, 173.0, -11.49999999999984, 20.000000000000014, 72.79999999999961, 121.6999999999997, 56.89999999999998, 20.000000000000014, 158.89999999999984, 46.40000000000004, -208.60000000000005, 170.89999999999998, 141.49999999999963, 4.699999999999988, 20.000000000000014, -11.80000000000007, 5.299999999999965, 80.5999999999999, -3.0999999999999615, 152.3, 20.000000000000014, 20.000000000000014, -101.50000000000074, 198.2, 7.099999999999895, 55.10000000000016, 75.79999999999998, 20.000000000000014, 182.59999999999994, 11.599999999999964, 82.39999999999947, 21.2000000000001, 131.59999999999968, 75.79999999999943, -2.1999999999998145, 37.70000000000001, 20.000000000000014, 57.80000000000021, -171.70000000000007, 88.10000000000001, 78.19999999999949, 5.299999999999978, 1.100000000000058, 24.50000000000009, -85.90000000000003, 35.60000000000021], "policy_predator_policy_reward": [10.0, 2.0, 0.0, 8.0, 8.0, 11.0, 0.0, 2.0, 1.0, 6.0, 7.0, 6.0, 0.0, 0.0, 6.0, 0.0, 0.0, 6.0, 0.0, 6.0, 0.0, 0.0, 10.0, 22.0, 0.0, 8.0, 0.0, 6.0, 0.0, 0.0, 0.0, 2.0, 0.0, 2.0, 5.0, 4.0, 0.0, 1.0, 3.0, 0.0, 82.0, 117.0, 0.0, 42.0, 220.0, 1.0, 12.0, 0.0, 0.0, 9.0, 0.0, 0.0, 139.0, 60.0, 0.0, 0.0, 0.0, 67.0, 2.0, 22.0, 114.0, 0.0, 6.0, 3.0, 66.0, 65.0, 0.0, 3.0, 11.0, 91.0, 0.0, 0.0, 4.0, 0.0, 13.0, 14.0, 0.0, 1.0, 0.0, 3.0, 100.0, 150.0, 0.0, 1.0, 0.0, 24.0, 78.0, 90.0, 3.0, 9.0, 0.0, 0.0, 0.0, 0.0, 9.0, 7.0, 0.0, 10.0, 120.0, 18.0, 7.0, 9.0, 18.0, 0.0, 0.0, 0.0, 18.0, 33.0, 0.0, 7.0, 0.0, 0.0, 0.0, 5.0, 0.0, 71.0, 0.0, 6.0, 7.0, 114.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 17.0, 12.0, 0.0, 9.0, 0.0, 11.0, 0.0, 32.0, 0.0, 0.0, 3.0, 1.0, 0.0, 0.0, 5.0, 0.0, 12.0, 14.0, 33.0, 34.0, 55.0, 1.0, 0.0, 0.0, 20.0, 2.0, 0.0, 0.0, 3.0, 9.0, 0.0, 15.0, 0.0, 1.0, 0.0, 0.0, 2.0, 5.0, 1.0, 126.0, 12.0, 0.0, 54.0, 3.0, 11.0, 0.0, 12.0, 0.0, 0.0, 0.0, 15.0, 55.0, 0.0, 49.0, 0.0, 0.0, 5.0, 3.0, 1.0, 9.0, 0.0, 9.0, 0.0, 18.0, 0.0, 0.0, 31.0, 86.0, 12.0, 8.0, 10.0, 7.0, 42.0, 36.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 24.026320298938295, "mean_inference_ms": 51.731616448152764, "mean_action_processing_ms": 11.981374088089623, "mean_env_wait_ms": 16.369624882666656, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.011723756790161133, "StateBufferConnector_ms": 0.006062865257263184, "ViewRequirementAgentConnector_ms": 0.24025213718414307}, "num_episodes": 18, "episode_return_max": 352.6, "episode_return_min": -154.20000000000002, "episode_return_mean": 90.86399999999966, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 752000, "num_agent_steps_trained": 752000, "num_env_steps_sampled": 188000, "num_env_steps_trained": 188000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 192.1983174243168, "num_env_steps_trained_throughput_per_sec": 192.1983174243168, "timesteps_total": 188000, "num_env_steps_sampled_lifetime": 188000, "num_agent_steps_sampled_lifetime": 752000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 752000, "timers": {"training_iteration_time_ms": 18671.051, "restore_workers_time_ms": 0.018, "training_step_time_ms": 18670.99, "sample_time_ms": 2428.295, "learn_time_ms": 16211.089, "learn_throughput": 246.745, "synch_weights_time_ms": 27.346}, "counters": {"num_env_steps_sampled": 188000, "num_env_steps_trained": 188000, "num_agent_steps_sampled": 752000, "num_agent_steps_trained": 752000}, "done": false, "training_iteration": 47, "trial_id": "75ec3_00000", "date": "2024-08-13_02-44-03", "timestamp": 1723531443, "time_this_iter_s": 20.862895011901855, "time_total_s": 5098.879567623138, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b1afec10>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 5098.879567623138, "iterations_since_restore": 47, "perf": {"cpu_util_percent": 84.9793103448276, "ram_util_percent": 83.37586206896552}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.003526008476025, "cur_kl_coeff": 0.12013549804687497, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.502795546584659, "policy_loss": -0.007896474248695154, "vf_loss": 2.508895099036908, "vf_explained_var": 0.1821165455396844, "kl": 0.01495748080623648, "entropy": 1.3187165395292655, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 89775.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.25036629383703546, "cur_kl_coeff": 6.103515625e-06, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.2597118882432817, "policy_loss": -0.000658148399273318, "vf_loss": 0.26037002617416893, "vf_explained_var": -0.000426737940500653, "kl": 0.0017848637110037553, "entropy": 0.43149703566044095, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 89775.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 192000, "num_env_steps_trained": 192000, "num_agent_steps_sampled": 768000, "num_agent_steps_trained": 768000}, "env_runners": {"episode_reward_max": 352.6, "episode_reward_min": -154.20000000000002, "episode_reward_mean": 86.87399999999971, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -309.09999999999997, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 199.1, "predator_policy": 220.0}, "policy_reward_mean": {"prey_policy": 27.33199999999995, "predator_policy": 16.105}, "custom_metrics": {}, "hist_stats": {"episode_reward": [39.80000000000028, 72.70000000000024, 103.09999999999957, -6.199999999999852, -154.20000000000002, 28.60000000000009, 58.90000000000014, 83.20000000000005, -65.80000000000052, 88.59999999999872, 31.100000000000115, 227.79999999999984, -71.90000000000086, 45.40000000000012, 78.29999999999961, 68.20000000000017, 101.19999999999997, 272.1999999999995, 62.60000000000028, 292.0000000000002, 78.50000000000009, 88.899999999999, -25.299999999999685, 90.19999999999969, 37.00000000000024, 67.2999999999999, 125.19999999999914, 40.0000000000003, 201.99999999999903, 133.09999999999906, 144.19999999999902, -117.2000000000009, 52.400000000000496, 233.1999999999992, 160.599999999999, 83.50000000000009, 64.7000000000003, 40.0000000000003, 81.29999999999923, 94.19999999999936, 103.59999999999873, -62.4999999999997, 48.100000000000364, 40.0000000000003, 192.99999999999903, 53.10000000000014, 199.29999999999936, 158.3999999999994, 33.60000000000041, 56.20000000000027, 121.09999999999903, 58.00000000000045, 36.30000000000025, 143.0999999999995, 102.19999999999969, 69.29999999999991, 41.800000000000296, 151.69999999999982, 101.19999999999888, 352.6, 23.500000000000046, 195.49999999999875, 76.90000000000015, 212.29999999999927, 89.3, 158.199999999999, 65.1999999999992, 96.89999999999976, 161.19999999999962, 40.0000000000003, 166.6999999999996, 111.19999999999914, 95.79999999999993, 202.1999999999992, 113.59999999999874, 216.39999999999898, 53.50000000000005, 77.79999999999947, 33.400000000000155, 103.49999999999889, 42.60000000000027, 27.700000000000244, 75.99999999999946, 102.09999999999897, 0.7999999999998657, 22.700000000000024, 60.20000000000005, 42.700000000000344, 56.400000000000205, 88.5999999999987, 14.500000000000123, 87.69999999999878, 145.29999999999885, 160.99999999999918, 68.2000000000001, 89.49999999999866, 49.90000000000046, 40.0000000000003, 43.60000000000029, 145.29999999999882], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 18.800000000000004, 49.700000000000216, 20.000000000000014, -208.59999999999997, 112.69999999999968, -68.20000000000061, 20.000000000000014, -309.09999999999997, -66.10000000000004, 9.499999999999964, 7.0999999999999694, 22.700000000000063, 27.20000000000006, 20.000000000000014, 63.20000000000003, -15.400000000000375, -249.39999999999998, 20.000000000000014, 68.59999999999988, -120.70000000000002, 84.79999999999976, 35.900000000000105, 167.89999999999984, -219.40000000000046, 33.50000000000007, 7.399999999999965, 29.000000000000007, -78.99999999999999, 26.30000000000004, 45.20000000000023, 20.000000000000014, -19.299999999999976, 18.49999999999997, 73.09999999999977, 199.1, 29.900000000000084, 28.700000000000063, 130.9999999999999, 134.00000000000006, 20.000000000000014, 57.50000000000005, 18.200000000000003, 67.69999999999992, 20.000000000000014, -295.2999999999996, 71.30000000000004, 17.899999999999988, -6.9999999999999165, 20.000000000000014, -120.70000000000007, 20.000000000000014, 23.60000000000008, 89.59999999999971, 20.000000000000014, 20.000000000000014, 132.49999999999983, 69.49999999999982, 1.0999999999999865, 115.99999999999966, 113.2999999999997, 20.90000000000003, -214.90000000000018, -40.30000000000039, 16.399999999999963, 20.000000000000014, 104.59999999999974, 110.59999999999948, 133.3999999999997, 27.200000000000124, 55.10000000000004, -22.600000000000463, 44.00000000000017, 13.699999999999958, 20.000000000000014, 20.000000000000014, 65.00000000000014, 11.299999999999965, 132.49999999999957, -109.30000000000018, 68.59999999999985, 29.000000000000064, -219.40000000000043, 35.90000000000013, 28.10000000000016, 20.000000000000014, 20.000000000000014, 20.000000000000014, 58.700000000000216, 134.3, -4.899999999999958, 29.000000000000135, 2.8999999999999613, 187.39999999999998, 127.3999999999999, 20.000000000000014, -24.099999999999987, 25.70000000000012, 20.000000000000014, 36.19999999999999, 19.100000000000016, 97.99999999999956, 20.900000000000027, 37.10000000000021, 9.499999999999966, 21.800000000000047, 23.599999999999998, 93.49999999999967, 25.4000000000001, 9.800000000000063, 108.7999999999995, -95.50000000000075, 20.000000000000014, 21.80000000000001, 49.39999999999999, 80.29999999999984, 20.000000000000014, 81.19999999999943, 167.6, 173.0, -11.49999999999984, 20.000000000000014, 72.79999999999961, 121.6999999999997, 56.89999999999998, 20.000000000000014, 158.89999999999984, 46.40000000000004, -208.60000000000005, 170.89999999999998, 141.49999999999963, 4.699999999999988, 20.000000000000014, -11.80000000000007, 5.299999999999965, 80.5999999999999, -3.0999999999999615, 152.3, 20.000000000000014, 20.000000000000014, -101.50000000000074, 198.2, 7.099999999999895, 55.10000000000016, 75.79999999999998, 20.000000000000014, 182.59999999999994, 11.599999999999964, 82.39999999999947, 21.2000000000001, 131.59999999999968, 75.79999999999943, -2.1999999999998145, 37.70000000000001, 20.000000000000014, 57.80000000000021, -171.70000000000007, 88.10000000000001, 78.19999999999949, 5.299999999999978, 1.100000000000058, 24.50000000000009, -85.90000000000003, 35.60000000000021, 20.90000000000003, 55.100000000000136, 52.40000000000012, 49.70000000000021, 24.200000000000088, -123.40000000000043, 8.299999999999965, 7.399999999999967, 9.200000000000053, 20.000000000000014, 13.699999999999964, 20.000000000000014, 28.400000000000077, 20.000000000000014, 26.300000000000114, 62.3000000000002, -38.4999999999998, 20.000000000000014, 54.20000000000023, 33.500000000000234, 97.39999999999958, 47.90000000000019, 20.000000000000014, 133.9999999999998, 33.50000000000022, 13.700000000000031, 23.600000000000065, 65.90000000000008, 1.099999999999983, 39.80000000000023, 20.000000000000014, 20.000000000000014, 23.600000000000026, 20.000000000000014, 56.900000000000205, 88.39999999999955], "policy_predator_policy_reward": [0.0, 1.0, 3.0, 0.0, 82.0, 117.0, 0.0, 42.0, 220.0, 1.0, 12.0, 0.0, 0.0, 9.0, 0.0, 0.0, 139.0, 60.0, 0.0, 0.0, 0.0, 67.0, 2.0, 22.0, 114.0, 0.0, 6.0, 3.0, 66.0, 65.0, 0.0, 3.0, 11.0, 91.0, 0.0, 0.0, 4.0, 0.0, 13.0, 14.0, 0.0, 1.0, 0.0, 3.0, 100.0, 150.0, 0.0, 1.0, 0.0, 24.0, 78.0, 90.0, 3.0, 9.0, 0.0, 0.0, 0.0, 0.0, 9.0, 7.0, 0.0, 10.0, 120.0, 18.0, 7.0, 9.0, 18.0, 0.0, 0.0, 0.0, 18.0, 33.0, 0.0, 7.0, 0.0, 0.0, 0.0, 5.0, 0.0, 71.0, 0.0, 6.0, 7.0, 114.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 17.0, 12.0, 0.0, 9.0, 0.0, 11.0, 0.0, 32.0, 0.0, 0.0, 3.0, 1.0, 0.0, 0.0, 5.0, 0.0, 12.0, 14.0, 33.0, 34.0, 55.0, 1.0, 0.0, 0.0, 20.0, 2.0, 0.0, 0.0, 3.0, 9.0, 0.0, 15.0, 0.0, 1.0, 0.0, 0.0, 2.0, 5.0, 1.0, 126.0, 12.0, 0.0, 54.0, 3.0, 11.0, 0.0, 12.0, 0.0, 0.0, 0.0, 15.0, 55.0, 0.0, 49.0, 0.0, 0.0, 5.0, 3.0, 1.0, 9.0, 0.0, 9.0, 0.0, 18.0, 0.0, 0.0, 31.0, 86.0, 12.0, 8.0, 10.0, 7.0, 42.0, 36.0, 0.0, 0.0, 0.0, 0.0, 100.0, 0.0, 0.0, 7.0, 10.0, 21.0, 6.0, 3.0, 0.0, 8.0, 0.0, 0.0, 33.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 9.0, 12.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 23.577158322009904, "mean_inference_ms": 50.77954056638214, "mean_action_processing_ms": 11.75324821823155, "mean_env_wait_ms": 16.055723142107137, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01251685619354248, "StateBufferConnector_ms": 0.006167888641357422, "ViewRequirementAgentConnector_ms": 0.28003787994384766}, "num_episodes": 18, "episode_return_max": 352.6, "episode_return_min": -154.20000000000002, "episode_return_mean": 86.87399999999971, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 768000, "num_agent_steps_trained": 768000, "num_env_steps_sampled": 192000, "num_env_steps_trained": 192000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 192.5684016205472, "num_env_steps_trained_throughput_per_sec": 192.5684016205472, "timesteps_total": 192000, "num_env_steps_sampled_lifetime": 192000, "num_agent_steps_sampled_lifetime": 768000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 768000, "timers": {"training_iteration_time_ms": 19162.199, "restore_workers_time_ms": 0.018, "training_step_time_ms": 19162.138, "sample_time_ms": 2677.814, "learn_time_ms": 16451.109, "learn_throughput": 243.145, "synch_weights_time_ms": 28.956}, "counters": {"num_env_steps_sampled": 192000, "num_env_steps_trained": 192000, "num_agent_steps_sampled": 768000, "num_agent_steps_trained": 768000}, "done": false, "training_iteration": 48, "trial_id": "75ec3_00000", "date": "2024-08-13_02-44-24", "timestamp": 1723531464, "time_this_iter_s": 20.868069171905518, "time_total_s": 5119.747636795044, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2058940>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 5119.747636795044, "iterations_since_restore": 48, "perf": {"cpu_util_percent": 85.30999999999999, "ram_util_percent": 83.35999999999997}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.34375250315067, "cur_kl_coeff": 0.12013549804687497, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.879649760609581, "policy_loss": -0.0013137399706812131, "vf_loss": 3.8804415562796213, "vf_explained_var": 0.13401189194154486, "kl": 0.004344500288985845, "entropy": 1.2971847784582269, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 91665.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.3691465824803032, "cur_kl_coeff": 3.0517578125e-06, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.4980411197694521, "policy_loss": -0.0016178302161356129, "vf_loss": 0.4996589486185392, "vf_explained_var": 0.004344151575098593, "kl": 0.003915481630229913, "entropy": 0.5220742088619363, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 91665.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 196000, "num_env_steps_trained": 196000, "num_agent_steps_sampled": 784000, "num_agent_steps_trained": 784000}, "env_runners": {"episode_reward_max": 352.6, "episode_reward_min": -117.2000000000009, "episode_reward_mean": 95.47299999999959, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -295.2999999999996, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 198.2, "predator_policy": 150.0}, "policy_reward_mean": {"prey_policy": 36.06649999999995, "predator_policy": 11.67}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-25.299999999999685, 90.19999999999969, 37.00000000000024, 67.2999999999999, 125.19999999999914, 40.0000000000003, 201.99999999999903, 133.09999999999906, 144.19999999999902, -117.2000000000009, 52.400000000000496, 233.1999999999992, 160.599999999999, 83.50000000000009, 64.7000000000003, 40.0000000000003, 81.29999999999923, 94.19999999999936, 103.59999999999873, -62.4999999999997, 48.100000000000364, 40.0000000000003, 192.99999999999903, 53.10000000000014, 199.29999999999936, 158.3999999999994, 33.60000000000041, 56.20000000000027, 121.09999999999903, 58.00000000000045, 36.30000000000025, 143.0999999999995, 102.19999999999969, 69.29999999999991, 41.800000000000296, 151.69999999999982, 101.19999999999888, 352.6, 23.500000000000046, 195.49999999999875, 76.90000000000015, 212.29999999999927, 89.3, 158.199999999999, 65.1999999999992, 96.89999999999976, 161.19999999999962, 40.0000000000003, 166.6999999999996, 111.19999999999914, 95.79999999999993, 202.1999999999992, 113.59999999999874, 216.39999999999898, 53.50000000000005, 77.79999999999947, 33.400000000000155, 103.49999999999889, 42.60000000000027, 27.700000000000244, 75.99999999999946, 102.09999999999897, 0.7999999999998657, 22.700000000000024, 60.20000000000005, 42.700000000000344, 56.400000000000205, 88.5999999999987, 14.500000000000123, 87.69999999999878, 145.29999999999885, 160.99999999999918, 68.2000000000001, 89.49999999999866, 49.90000000000046, 40.0000000000003, 43.60000000000029, 145.29999999999882, 52.80000000000043, 128.1999999999987, 40.0000000000003, 137.4999999999997, 141.5999999999986, 186.79999999999913, 99.39999999999851, 117.39999999999863, 70.5999999999999, 99.2999999999989, 91.29999999999968, 154.09999999999886, 62.10000000000035, 199.0999999999989, 95.09999999999874, 97.6, 82.29999999999981, 108.79999999999887, 80.79999999999926, 72.79999999999896, 112.8999999999993, 152.39999999999958], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, -295.2999999999996, 71.30000000000004, 17.899999999999988, -6.9999999999999165, 20.000000000000014, -120.70000000000007, 20.000000000000014, 23.60000000000008, 89.59999999999971, 20.000000000000014, 20.000000000000014, 132.49999999999983, 69.49999999999982, 1.0999999999999865, 115.99999999999966, 113.2999999999997, 20.90000000000003, -214.90000000000018, -40.30000000000039, 16.399999999999963, 20.000000000000014, 104.59999999999974, 110.59999999999948, 133.3999999999997, 27.200000000000124, 55.10000000000004, -22.600000000000463, 44.00000000000017, 13.699999999999958, 20.000000000000014, 20.000000000000014, 65.00000000000014, 11.299999999999965, 132.49999999999957, -109.30000000000018, 68.59999999999985, 29.000000000000064, -219.40000000000043, 35.90000000000013, 28.10000000000016, 20.000000000000014, 20.000000000000014, 20.000000000000014, 58.700000000000216, 134.3, -4.899999999999958, 29.000000000000135, 2.8999999999999613, 187.39999999999998, 127.3999999999999, 20.000000000000014, -24.099999999999987, 25.70000000000012, 20.000000000000014, 36.19999999999999, 19.100000000000016, 97.99999999999956, 20.900000000000027, 37.10000000000021, 9.499999999999966, 21.800000000000047, 23.599999999999998, 93.49999999999967, 25.4000000000001, 9.800000000000063, 108.7999999999995, -95.50000000000075, 20.000000000000014, 21.80000000000001, 49.39999999999999, 80.29999999999984, 20.000000000000014, 81.19999999999943, 167.6, 173.0, -11.49999999999984, 20.000000000000014, 72.79999999999961, 121.6999999999997, 56.89999999999998, 20.000000000000014, 158.89999999999984, 46.40000000000004, -208.60000000000005, 170.89999999999998, 141.49999999999963, 4.699999999999988, 20.000000000000014, -11.80000000000007, 5.299999999999965, 80.5999999999999, -3.0999999999999615, 152.3, 20.000000000000014, 20.000000000000014, -101.50000000000074, 198.2, 7.099999999999895, 55.10000000000016, 75.79999999999998, 20.000000000000014, 182.59999999999994, 11.599999999999964, 82.39999999999947, 21.2000000000001, 131.59999999999968, 75.79999999999943, -2.1999999999998145, 37.70000000000001, 20.000000000000014, 57.80000000000021, -171.70000000000007, 88.10000000000001, 78.19999999999949, 5.299999999999978, 1.100000000000058, 24.50000000000009, -85.90000000000003, 35.60000000000021, 20.90000000000003, 55.100000000000136, 52.40000000000012, 49.70000000000021, 24.200000000000088, -123.40000000000043, 8.299999999999965, 7.399999999999967, 9.200000000000053, 20.000000000000014, 13.699999999999964, 20.000000000000014, 28.400000000000077, 20.000000000000014, 26.300000000000114, 62.3000000000002, -38.4999999999998, 20.000000000000014, 54.20000000000023, 33.500000000000234, 97.39999999999958, 47.90000000000019, 20.000000000000014, 133.9999999999998, 33.50000000000022, 13.700000000000031, 23.600000000000065, 65.90000000000008, 1.099999999999983, 39.80000000000023, 20.000000000000014, 20.000000000000014, 23.600000000000026, 20.000000000000014, 56.900000000000205, 88.39999999999955, 34.700000000000216, 1.0999999999999652, 20.000000000000014, 108.19999999999959, 20.000000000000014, 20.000000000000014, 111.80000000000001, -13.299999999999919, 42.50000000000025, 94.09999999999945, 20.000000000000014, 162.79999999999984, 79.39999999999927, 20.000000000000014, 20.000000000000014, 97.39999999999941, 20.000000000000014, 50.60000000000017, 33.80000000000014, 39.50000000000024, 91.09999999999971, -17.799999999999862, 47.90000000000022, 96.19999999999953, 7.699999999999967, 34.40000000000017, 90.19999999999992, 98.89999999999938, 28.100000000000154, 56.00000000000018, 77.59999999999997, 20.000000000000014, 62.30000000000022, 20.000000000000014, -91.30000000000081, 118.09999999999948, 20.000000000000014, 57.80000000000021, -8.199999999999973, 47.00000000000024, 20.000000000000014, 92.90000000000018, 20.000000000000014, 127.39999999999998], "policy_predator_policy_reward": [100.0, 150.0, 0.0, 1.0, 0.0, 24.0, 78.0, 90.0, 3.0, 9.0, 0.0, 0.0, 0.0, 0.0, 9.0, 7.0, 0.0, 10.0, 120.0, 18.0, 7.0, 9.0, 18.0, 0.0, 0.0, 0.0, 18.0, 33.0, 0.0, 7.0, 0.0, 0.0, 0.0, 5.0, 0.0, 71.0, 0.0, 6.0, 7.0, 114.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 17.0, 12.0, 0.0, 9.0, 0.0, 11.0, 0.0, 32.0, 0.0, 0.0, 3.0, 1.0, 0.0, 0.0, 5.0, 0.0, 12.0, 14.0, 33.0, 34.0, 55.0, 1.0, 0.0, 0.0, 20.0, 2.0, 0.0, 0.0, 3.0, 9.0, 0.0, 15.0, 0.0, 1.0, 0.0, 0.0, 2.0, 5.0, 1.0, 126.0, 12.0, 0.0, 54.0, 3.0, 11.0, 0.0, 12.0, 0.0, 0.0, 0.0, 15.0, 55.0, 0.0, 49.0, 0.0, 0.0, 5.0, 3.0, 1.0, 9.0, 0.0, 9.0, 0.0, 18.0, 0.0, 0.0, 31.0, 86.0, 12.0, 8.0, 10.0, 7.0, 42.0, 36.0, 0.0, 0.0, 0.0, 0.0, 100.0, 0.0, 0.0, 7.0, 10.0, 21.0, 6.0, 3.0, 0.0, 8.0, 0.0, 0.0, 33.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 9.0, 12.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 8.0, 0.0, 0.0, 0.0, 0.0, 39.0, 0.0, 5.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 15.0, 0.0, 18.0, 10.0, 0.0, 17.0, 3.0, 9.0, 1.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 41.0, 41.0, 0.0, 3.0, 0.0, 34.0, 0.0, 0.0, 0.0, 5.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 23.570999725799584, "mean_inference_ms": 49.67238497906417, "mean_action_processing_ms": 11.06021854390084, "mean_env_wait_ms": 15.6880898225587, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.020538687705993652, "StateBufferConnector_ms": 0.010678410530090332, "ViewRequirementAgentConnector_ms": 0.3029676675796509}, "num_episodes": 22, "episode_return_max": 352.6, "episode_return_min": -117.2000000000009, "episode_return_mean": 95.47299999999959, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 784000, "num_agent_steps_trained": 784000, "num_env_steps_sampled": 196000, "num_env_steps_trained": 196000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 177.95864827588431, "num_env_steps_trained_throughput_per_sec": 177.95864827588431, "timesteps_total": 196000, "num_env_steps_sampled_lifetime": 196000, "num_agent_steps_sampled_lifetime": 784000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 784000, "timers": {"training_iteration_time_ms": 19880.434, "restore_workers_time_ms": 0.018, "training_step_time_ms": 19880.372, "sample_time_ms": 2991.983, "learn_time_ms": 16853.784, "learn_throughput": 237.335, "synch_weights_time_ms": 30.305}, "counters": {"num_env_steps_sampled": 196000, "num_env_steps_trained": 196000, "num_agent_steps_sampled": 784000, "num_agent_steps_trained": 784000}, "done": false, "training_iteration": 49, "trial_id": "75ec3_00000", "date": "2024-08-13_02-44-47", "timestamp": 1723531487, "time_this_iter_s": 22.59588313102722, "time_total_s": 5142.343519926071, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b1be0700>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 5142.343519926071, "iterations_since_restore": 49, "perf": {"cpu_util_percent": 86.0625, "ram_util_percent": 83.128125}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9710738355678226, "cur_kl_coeff": 0.060067749023437485, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.962072876016929, "policy_loss": -0.003037793960954462, "vf_loss": 5.964148755300613, "vf_explained_var": 0.15021024784713827, "kl": 0.016013602226833575, "entropy": 1.2771265909154579, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 93555.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4371298705538114, "cur_kl_coeff": 1.52587890625e-06, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.6273668404215227, "policy_loss": -0.0012669073571771304, "vf_loss": 0.6286337478564332, "vf_explained_var": 0.012253140898608657, "kl": 0.0044833935449556115, "entropy": 0.6073641638276438, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 93555.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 200000, "num_env_steps_trained": 200000, "num_agent_steps_sampled": 800000, "num_agent_steps_trained": 800000}, "env_runners": {"episode_reward_max": 352.6, "episode_reward_min": 0.7999999999998657, "episode_reward_mean": 111.49499999999964, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -208.60000000000005, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 199.1, "predator_policy": 126.0}, "policy_reward_mean": {"prey_policy": 47.51749999999996, "predator_policy": 8.23}, "custom_metrics": {}, "hist_stats": {"episode_reward": [53.10000000000014, 199.29999999999936, 158.3999999999994, 33.60000000000041, 56.20000000000027, 121.09999999999903, 58.00000000000045, 36.30000000000025, 143.0999999999995, 102.19999999999969, 69.29999999999991, 41.800000000000296, 151.69999999999982, 101.19999999999888, 352.6, 23.500000000000046, 195.49999999999875, 76.90000000000015, 212.29999999999927, 89.3, 158.199999999999, 65.1999999999992, 96.89999999999976, 161.19999999999962, 40.0000000000003, 166.6999999999996, 111.19999999999914, 95.79999999999993, 202.1999999999992, 113.59999999999874, 216.39999999999898, 53.50000000000005, 77.79999999999947, 33.400000000000155, 103.49999999999889, 42.60000000000027, 27.700000000000244, 75.99999999999946, 102.09999999999897, 0.7999999999998657, 22.700000000000024, 60.20000000000005, 42.700000000000344, 56.400000000000205, 88.5999999999987, 14.500000000000123, 87.69999999999878, 145.29999999999885, 160.99999999999918, 68.2000000000001, 89.49999999999866, 49.90000000000046, 40.0000000000003, 43.60000000000029, 145.29999999999882, 52.80000000000043, 128.1999999999987, 40.0000000000003, 137.4999999999997, 141.5999999999986, 186.79999999999913, 99.39999999999851, 117.39999999999863, 70.5999999999999, 99.2999999999989, 91.29999999999968, 154.09999999999886, 62.10000000000035, 199.0999999999989, 95.09999999999874, 97.6, 82.29999999999981, 108.79999999999887, 80.79999999999926, 72.79999999999896, 112.8999999999993, 152.39999999999958, 192.19999999999948, 75.09999999999995, 50.80000000000018, 321.9000000000001, 71.49999999999996, 284.8000000000024, 257.69999999999953, 161.0999999999997, 93.29999999999976, 195.6999999999994, 82.29999999999932, 113.0999999999988, 32.100000000000335, 66.00000000000031, 199.7999999999992, 344.6, 112.49999999999861, 85.90000000000012, 100.2999999999999, 76.89999999999941, 144.99999999999918, 128.39999999999884, 239.79999999999976], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-4.899999999999958, 29.000000000000135, 2.8999999999999613, 187.39999999999998, 127.3999999999999, 20.000000000000014, -24.099999999999987, 25.70000000000012, 20.000000000000014, 36.19999999999999, 19.100000000000016, 97.99999999999956, 20.900000000000027, 37.10000000000021, 9.499999999999966, 21.800000000000047, 23.599999999999998, 93.49999999999967, 25.4000000000001, 9.800000000000063, 108.7999999999995, -95.50000000000075, 20.000000000000014, 21.80000000000001, 49.39999999999999, 80.29999999999984, 20.000000000000014, 81.19999999999943, 167.6, 173.0, -11.49999999999984, 20.000000000000014, 72.79999999999961, 121.6999999999997, 56.89999999999998, 20.000000000000014, 158.89999999999984, 46.40000000000004, -208.60000000000005, 170.89999999999998, 141.49999999999963, 4.699999999999988, 20.000000000000014, -11.80000000000007, 5.299999999999965, 80.5999999999999, -3.0999999999999615, 152.3, 20.000000000000014, 20.000000000000014, -101.50000000000074, 198.2, 7.099999999999895, 55.10000000000016, 75.79999999999998, 20.000000000000014, 182.59999999999994, 11.599999999999964, 82.39999999999947, 21.2000000000001, 131.59999999999968, 75.79999999999943, -2.1999999999998145, 37.70000000000001, 20.000000000000014, 57.80000000000021, -171.70000000000007, 88.10000000000001, 78.19999999999949, 5.299999999999978, 1.100000000000058, 24.50000000000009, -85.90000000000003, 35.60000000000021, 20.90000000000003, 55.100000000000136, 52.40000000000012, 49.70000000000021, 24.200000000000088, -123.40000000000043, 8.299999999999965, 7.399999999999967, 9.200000000000053, 20.000000000000014, 13.699999999999964, 20.000000000000014, 28.400000000000077, 20.000000000000014, 26.300000000000114, 62.3000000000002, -38.4999999999998, 20.000000000000014, 54.20000000000023, 33.500000000000234, 97.39999999999958, 47.90000000000019, 20.000000000000014, 133.9999999999998, 33.50000000000022, 13.700000000000031, 23.600000000000065, 65.90000000000008, 1.099999999999983, 39.80000000000023, 20.000000000000014, 20.000000000000014, 23.600000000000026, 20.000000000000014, 56.900000000000205, 88.39999999999955, 34.700000000000216, 1.0999999999999652, 20.000000000000014, 108.19999999999959, 20.000000000000014, 20.000000000000014, 111.80000000000001, -13.299999999999919, 42.50000000000025, 94.09999999999945, 20.000000000000014, 162.79999999999984, 79.39999999999927, 20.000000000000014, 20.000000000000014, 97.39999999999941, 20.000000000000014, 50.60000000000017, 33.80000000000014, 39.50000000000024, 91.09999999999971, -17.799999999999862, 47.90000000000022, 96.19999999999953, 7.699999999999967, 34.40000000000017, 90.19999999999992, 98.89999999999938, 28.100000000000154, 56.00000000000018, 77.59999999999997, 20.000000000000014, 62.30000000000022, 20.000000000000014, -91.30000000000081, 118.09999999999948, 20.000000000000014, 57.80000000000021, -8.199999999999973, 47.00000000000024, 20.000000000000014, 92.90000000000018, 20.000000000000014, 127.39999999999998, 122.29999999999987, 56.90000000000008, 47.00000000000002, 28.100000000000147, -23.199999999999953, 20.000000000000014, 163.39999999999995, 150.50000000000006, 51.500000000000234, 20.000000000000014, 159.49999999999974, 125.29999999999957, 56.599999999999994, 199.1, 36.20000000000005, 62.900000000000055, 48.200000000000195, 37.10000000000019, 175.7, 20.000000000000014, 53.30000000000009, 29.00000000000013, 32.000000000000206, 73.0999999999997, 18.199999999999992, -3.10000000000004, 51.500000000000156, 9.499999999999966, 58.9999999999996, 129.79999999999956, 156.2, 175.39999999999998, 20.90000000000003, 89.59999999999941, 20.000000000000014, 65.90000000000006, 67.69999999999992, 32.60000000000021, 20.000000000000014, 56.90000000000015, 115.99999999999977, 13.999999999999964, 86.89999999999944, 33.49999999999999, 123.49999999999994, 116.29999999999981], "policy_predator_policy_reward": [17.0, 12.0, 0.0, 9.0, 0.0, 11.0, 0.0, 32.0, 0.0, 0.0, 3.0, 1.0, 0.0, 0.0, 5.0, 0.0, 12.0, 14.0, 33.0, 34.0, 55.0, 1.0, 0.0, 0.0, 20.0, 2.0, 0.0, 0.0, 3.0, 9.0, 0.0, 15.0, 0.0, 1.0, 0.0, 0.0, 2.0, 5.0, 1.0, 126.0, 12.0, 0.0, 54.0, 3.0, 11.0, 0.0, 12.0, 0.0, 0.0, 0.0, 15.0, 55.0, 0.0, 49.0, 0.0, 0.0, 5.0, 3.0, 1.0, 9.0, 0.0, 9.0, 0.0, 18.0, 0.0, 0.0, 31.0, 86.0, 12.0, 8.0, 10.0, 7.0, 42.0, 36.0, 0.0, 0.0, 0.0, 0.0, 100.0, 0.0, 0.0, 7.0, 10.0, 21.0, 6.0, 3.0, 0.0, 8.0, 0.0, 0.0, 33.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 9.0, 12.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 8.0, 0.0, 0.0, 0.0, 0.0, 39.0, 0.0, 5.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 15.0, 0.0, 18.0, 10.0, 0.0, 17.0, 3.0, 9.0, 1.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 41.0, 41.0, 0.0, 3.0, 0.0, 34.0, 0.0, 0.0, 0.0, 5.0, 13.0, 0.0, 0.0, 0.0, 35.0, 19.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 33.0, 29.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 17.0, 0.0, 0.0, 5.0, 0.0, 11.0, 0.0, 13.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 8.0, 0.0, 8.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 23.0405883067143, "mean_inference_ms": 49.65665121509131, "mean_action_processing_ms": 11.747686889794176, "mean_env_wait_ms": 13.445655066382713, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.021927237510681152, "StateBufferConnector_ms": 0.010855436325073242, "ViewRequirementAgentConnector_ms": 0.31899869441986084}, "num_episodes": 23, "episode_return_max": 352.6, "episode_return_min": 0.7999999999998657, "episode_return_mean": 111.49499999999964, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 800000, "num_agent_steps_trained": 800000, "num_env_steps_sampled": 200000, "num_env_steps_trained": 200000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 163.77872692355038, "num_env_steps_trained_throughput_per_sec": 163.77872692355038, "timesteps_total": 200000, "num_env_steps_sampled_lifetime": 200000, "num_agent_steps_sampled_lifetime": 800000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 800000, "timers": {"training_iteration_time_ms": 20616.319, "restore_workers_time_ms": 0.018, "training_step_time_ms": 20616.257, "sample_time_ms": 3191.464, "learn_time_ms": 17389.47, "learn_throughput": 230.024, "synch_weights_time_ms": 30.87}, "counters": {"num_env_steps_sampled": 200000, "num_env_steps_trained": 200000, "num_agent_steps_sampled": 800000, "num_agent_steps_trained": 800000}, "done": false, "training_iteration": 50, "trial_id": "75ec3_00000", "date": "2024-08-13_02-45-11", "timestamp": 1723531511, "time_this_iter_s": 24.500048875808716, "time_total_s": 5166.84356880188, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b208e550>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 5166.84356880188, "iterations_since_restore": 50, "perf": {"cpu_util_percent": 88.0058823529412, "ram_util_percent": 83.31764705882352}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.672087719011559, "cur_kl_coeff": 0.060067749023437485, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.749555831485324, "policy_loss": -0.013114076189539104, "vf_loss": 5.761442586353847, "vf_explained_var": 0.020016901076786102, "kl": 0.020432307564360527, "entropy": 1.2981098134050923, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 95445.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.39576529365565094, "cur_kl_coeff": 7.62939453125e-07, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.5240803072692226, "policy_loss": -0.0013468711954792813, "vf_loss": 3.525427172171376, "vf_explained_var": 0.003353519319857239, "kl": 0.006550487194669426, "entropy": 0.5062057745992822, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 95445.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 204000, "num_env_steps_trained": 204000, "num_agent_steps_sampled": 816000, "num_agent_steps_trained": 816000}, "env_runners": {"episode_reward_max": 344.6, "episode_reward_min": -76.49999999999986, "episode_reward_mean": 100.26499999999956, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -208.60000000000005, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 199.1, "predator_policy": 131.0}, "policy_reward_mean": {"prey_policy": 38.45749999999994, "predator_policy": 11.675}, "custom_metrics": {}, "hist_stats": {"episode_reward": [212.29999999999927, 89.3, 158.199999999999, 65.1999999999992, 96.89999999999976, 161.19999999999962, 40.0000000000003, 166.6999999999996, 111.19999999999914, 95.79999999999993, 202.1999999999992, 113.59999999999874, 216.39999999999898, 53.50000000000005, 77.79999999999947, 33.400000000000155, 103.49999999999889, 42.60000000000027, 27.700000000000244, 75.99999999999946, 102.09999999999897, 0.7999999999998657, 22.700000000000024, 60.20000000000005, 42.700000000000344, 56.400000000000205, 88.5999999999987, 14.500000000000123, 87.69999999999878, 145.29999999999885, 160.99999999999918, 68.2000000000001, 89.49999999999866, 49.90000000000046, 40.0000000000003, 43.60000000000029, 145.29999999999882, 52.80000000000043, 128.1999999999987, 40.0000000000003, 137.4999999999997, 141.5999999999986, 186.79999999999913, 99.39999999999851, 117.39999999999863, 70.5999999999999, 99.2999999999989, 91.29999999999968, 154.09999999999886, 62.10000000000035, 199.0999999999989, 95.09999999999874, 97.6, 82.29999999999981, 108.79999999999887, 80.79999999999926, 72.79999999999896, 112.8999999999993, 152.39999999999958, 192.19999999999948, 75.09999999999995, 50.80000000000018, 321.9000000000001, 71.49999999999996, 284.8000000000024, 257.69999999999953, 161.0999999999997, 93.29999999999976, 195.6999999999994, 82.29999999999932, 113.0999999999988, 32.100000000000335, 66.00000000000031, 199.7999999999992, 344.6, 112.49999999999861, 85.90000000000012, 100.2999999999999, 76.89999999999941, 144.99999999999918, 128.39999999999884, 239.79999999999976, 140.69999999999976, -76.49999999999986, 113.69999999999874, -71.10000000000053, 106.59999999999883, 212.59999999999923, 124.89999999999893, -47.900000000000325, 106.59999999999893, 86.69999999999894, -54.79999999999982, -47.4999999999998, 31.200000000000152, 134.19999999999897, 100.09999999999908, 1.6000000000000087, 19.69999999999996, -29.99999999999976], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [158.89999999999984, 46.40000000000004, -208.60000000000005, 170.89999999999998, 141.49999999999963, 4.699999999999988, 20.000000000000014, -11.80000000000007, 5.299999999999965, 80.5999999999999, -3.0999999999999615, 152.3, 20.000000000000014, 20.000000000000014, -101.50000000000074, 198.2, 7.099999999999895, 55.10000000000016, 75.79999999999998, 20.000000000000014, 182.59999999999994, 11.599999999999964, 82.39999999999947, 21.2000000000001, 131.59999999999968, 75.79999999999943, -2.1999999999998145, 37.70000000000001, 20.000000000000014, 57.80000000000021, -171.70000000000007, 88.10000000000001, 78.19999999999949, 5.299999999999978, 1.100000000000058, 24.50000000000009, -85.90000000000003, 35.60000000000021, 20.90000000000003, 55.100000000000136, 52.40000000000012, 49.70000000000021, 24.200000000000088, -123.40000000000043, 8.299999999999965, 7.399999999999967, 9.200000000000053, 20.000000000000014, 13.699999999999964, 20.000000000000014, 28.400000000000077, 20.000000000000014, 26.300000000000114, 62.3000000000002, -38.4999999999998, 20.000000000000014, 54.20000000000023, 33.500000000000234, 97.39999999999958, 47.90000000000019, 20.000000000000014, 133.9999999999998, 33.50000000000022, 13.700000000000031, 23.600000000000065, 65.90000000000008, 1.099999999999983, 39.80000000000023, 20.000000000000014, 20.000000000000014, 23.600000000000026, 20.000000000000014, 56.900000000000205, 88.39999999999955, 34.700000000000216, 1.0999999999999652, 20.000000000000014, 108.19999999999959, 20.000000000000014, 20.000000000000014, 111.80000000000001, -13.299999999999919, 42.50000000000025, 94.09999999999945, 20.000000000000014, 162.79999999999984, 79.39999999999927, 20.000000000000014, 20.000000000000014, 97.39999999999941, 20.000000000000014, 50.60000000000017, 33.80000000000014, 39.50000000000024, 91.09999999999971, -17.799999999999862, 47.90000000000022, 96.19999999999953, 7.699999999999967, 34.40000000000017, 90.19999999999992, 98.89999999999938, 28.100000000000154, 56.00000000000018, 77.59999999999997, 20.000000000000014, 62.30000000000022, 20.000000000000014, -91.30000000000081, 118.09999999999948, 20.000000000000014, 57.80000000000021, -8.199999999999973, 47.00000000000024, 20.000000000000014, 92.90000000000018, 20.000000000000014, 127.39999999999998, 122.29999999999987, 56.90000000000008, 47.00000000000002, 28.100000000000147, -23.199999999999953, 20.000000000000014, 163.39999999999995, 150.50000000000006, 51.500000000000234, 20.000000000000014, 159.49999999999974, 125.29999999999957, 56.599999999999994, 199.1, 36.20000000000005, 62.900000000000055, 48.200000000000195, 37.10000000000019, 175.7, 20.000000000000014, 53.30000000000009, 29.00000000000013, 32.000000000000206, 73.0999999999997, 18.199999999999992, -3.10000000000004, 51.500000000000156, 9.499999999999966, 58.9999999999996, 129.79999999999956, 156.2, 175.39999999999998, 20.90000000000003, 89.59999999999941, 20.000000000000014, 65.90000000000006, 67.69999999999992, 32.60000000000021, 20.000000000000014, 56.90000000000015, 115.99999999999977, 13.999999999999964, 86.89999999999944, 33.49999999999999, 123.49999999999994, 116.29999999999981, 78.79999999999995, 47.90000000000018, -101.80000000000038, -132.69999999999996, 20.29999999999997, 88.39999999999935, 20.000000000000014, -201.10000000000025, 86.59999999999945, 20.000000000000014, 88.99999999999999, 122.59999999999951, 74.89999999999938, 46.99999999999999, -26.79999999999984, -114.10000000000025, 86.59999999999951, 20.000000000000014, 20.900000000000013, 33.800000000000075, -111.40000000000042, -48.39999999999988, 20.000000000000014, -158.50000000000017, 20.000000000000014, -5.799999999999953, 23.600000000000136, 86.5999999999995, 72.79999999999977, -18.699999999999932, -66.40000000000035, 20.000000000000014, 35.60000000000018, -103.9000000000008, -118.30000000000038, -54.70000000000011], "policy_predator_policy_reward": [2.0, 5.0, 1.0, 126.0, 12.0, 0.0, 54.0, 3.0, 11.0, 0.0, 12.0, 0.0, 0.0, 0.0, 15.0, 55.0, 0.0, 49.0, 0.0, 0.0, 5.0, 3.0, 1.0, 9.0, 0.0, 9.0, 0.0, 18.0, 0.0, 0.0, 31.0, 86.0, 12.0, 8.0, 10.0, 7.0, 42.0, 36.0, 0.0, 0.0, 0.0, 0.0, 100.0, 0.0, 0.0, 7.0, 10.0, 21.0, 6.0, 3.0, 0.0, 8.0, 0.0, 0.0, 33.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 9.0, 12.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 8.0, 0.0, 0.0, 0.0, 0.0, 39.0, 0.0, 5.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 15.0, 0.0, 18.0, 10.0, 0.0, 17.0, 3.0, 9.0, 1.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 41.0, 41.0, 0.0, 3.0, 0.0, 34.0, 0.0, 0.0, 0.0, 5.0, 13.0, 0.0, 0.0, 0.0, 35.0, 19.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 33.0, 29.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 17.0, 0.0, 0.0, 5.0, 0.0, 11.0, 0.0, 13.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 8.0, 0.0, 8.0, 0.0, 0.0, 8.0, 6.0, 131.0, 27.0, 0.0, 5.0, 0.0, 110.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 36.0, 57.0, 0.0, 0.0, 32.0, 0.0, 47.0, 58.0, 42.0, 49.0, 8.0, 9.0, 24.0, 0.0, 0.0, 46.0, 0.0, 48.0, 64.0, 24.0, 97.0, 46.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 22.215158999415763, "mean_inference_ms": 47.89208000897478, "mean_action_processing_ms": 11.060630859990647, "mean_env_wait_ms": 15.084105994171134, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.021680116653442383, "StateBufferConnector_ms": 0.011156201362609863, "ViewRequirementAgentConnector_ms": 0.33319199085235596}, "num_episodes": 18, "episode_return_max": 344.6, "episode_return_min": -76.49999999999986, "episode_return_mean": 100.26499999999956, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 816000, "num_agent_steps_trained": 816000, "num_env_steps_sampled": 204000, "num_env_steps_trained": 204000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 172.32310993963992, "num_env_steps_trained_throughput_per_sec": 172.32310993963992, "timesteps_total": 204000, "num_env_steps_sampled_lifetime": 204000, "num_agent_steps_sampled_lifetime": 816000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 816000, "timers": {"training_iteration_time_ms": 21138.159, "restore_workers_time_ms": 0.018, "training_step_time_ms": 21138.096, "sample_time_ms": 3475.802, "learn_time_ms": 17626.43, "learn_throughput": 226.932, "synch_weights_time_ms": 31.238}, "counters": {"num_env_steps_sampled": 204000, "num_env_steps_trained": 204000, "num_agent_steps_sampled": 816000, "num_agent_steps_trained": 816000}, "done": false, "training_iteration": 51, "trial_id": "75ec3_00000", "date": "2024-08-13_02-45-34", "timestamp": 1723531534, "time_this_iter_s": 23.27133011817932, "time_total_s": 5190.114898920059, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2084ee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 5190.114898920059, "iterations_since_restore": 51, "perf": {"cpu_util_percent": 87.21515151515153, "ram_util_percent": 83.43939393939394}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8885860641087804, "cur_kl_coeff": 0.09010162353515624, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.027389579222946, "policy_loss": -0.004628863522571034, "vf_loss": 4.030639947406829, "vf_explained_var": 0.15973902578076357, "kl": 0.015299306526158612, "entropy": 1.2600183387912771, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 97335.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.41456158429029444, "cur_kl_coeff": 7.62939453125e-07, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.9123886305976797, "policy_loss": -0.0011125071024739, "vf_loss": 0.9135011390285201, "vf_explained_var": 0.007935876505715506, "kl": 0.0038822526755867537, "entropy": 0.4438006847308426, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 97335.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 208000, "num_env_steps_trained": 208000, "num_agent_steps_sampled": 832000, "num_agent_steps_trained": 832000}, "env_runners": {"episode_reward_max": 344.6, "episode_reward_min": -138.80000000000112, "episode_reward_mean": 95.3609999999995, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -201.10000000000025, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 199.1, "predator_policy": 131.0}, "policy_reward_mean": {"prey_policy": 36.18049999999993, "predator_policy": 11.5}, "custom_metrics": {}, "hist_stats": {"episode_reward": [27.700000000000244, 75.99999999999946, 102.09999999999897, 0.7999999999998657, 22.700000000000024, 60.20000000000005, 42.700000000000344, 56.400000000000205, 88.5999999999987, 14.500000000000123, 87.69999999999878, 145.29999999999885, 160.99999999999918, 68.2000000000001, 89.49999999999866, 49.90000000000046, 40.0000000000003, 43.60000000000029, 145.29999999999882, 52.80000000000043, 128.1999999999987, 40.0000000000003, 137.4999999999997, 141.5999999999986, 186.79999999999913, 99.39999999999851, 117.39999999999863, 70.5999999999999, 99.2999999999989, 91.29999999999968, 154.09999999999886, 62.10000000000035, 199.0999999999989, 95.09999999999874, 97.6, 82.29999999999981, 108.79999999999887, 80.79999999999926, 72.79999999999896, 112.8999999999993, 152.39999999999958, 192.19999999999948, 75.09999999999995, 50.80000000000018, 321.9000000000001, 71.49999999999996, 284.8000000000024, 257.69999999999953, 161.0999999999997, 93.29999999999976, 195.6999999999994, 82.29999999999932, 113.0999999999988, 32.100000000000335, 66.00000000000031, 199.7999999999992, 344.6, 112.49999999999861, 85.90000000000012, 100.2999999999999, 76.89999999999941, 144.99999999999918, 128.39999999999884, 239.79999999999976, 140.69999999999976, -76.49999999999986, 113.69999999999874, -71.10000000000053, 106.59999999999883, 212.59999999999923, 124.89999999999893, -47.900000000000325, 106.59999999999893, 86.69999999999894, -54.79999999999982, -47.4999999999998, 31.200000000000152, 134.19999999999897, 100.09999999999908, 1.6000000000000087, 19.69999999999996, -29.99999999999976, -138.80000000000112, 145.2999999999988, 9.300000000000082, 75.39999999999952, 130.69999999999905, 142.5999999999986, -14.400000000000134, 78.9999999999994, 69.60000000000022, 141.39999999999873, 92.69999999999939, 108.39999999999927, 22.700000000000017, 166.8999999999993, 102.7999999999994, 118.0999999999988, 86.79999999999973, 210.899999999999], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-85.90000000000003, 35.60000000000021, 20.90000000000003, 55.100000000000136, 52.40000000000012, 49.70000000000021, 24.200000000000088, -123.40000000000043, 8.299999999999965, 7.399999999999967, 9.200000000000053, 20.000000000000014, 13.699999999999964, 20.000000000000014, 28.400000000000077, 20.000000000000014, 26.300000000000114, 62.3000000000002, -38.4999999999998, 20.000000000000014, 54.20000000000023, 33.500000000000234, 97.39999999999958, 47.90000000000019, 20.000000000000014, 133.9999999999998, 33.50000000000022, 13.700000000000031, 23.600000000000065, 65.90000000000008, 1.099999999999983, 39.80000000000023, 20.000000000000014, 20.000000000000014, 23.600000000000026, 20.000000000000014, 56.900000000000205, 88.39999999999955, 34.700000000000216, 1.0999999999999652, 20.000000000000014, 108.19999999999959, 20.000000000000014, 20.000000000000014, 111.80000000000001, -13.299999999999919, 42.50000000000025, 94.09999999999945, 20.000000000000014, 162.79999999999984, 79.39999999999927, 20.000000000000014, 20.000000000000014, 97.39999999999941, 20.000000000000014, 50.60000000000017, 33.80000000000014, 39.50000000000024, 91.09999999999971, -17.799999999999862, 47.90000000000022, 96.19999999999953, 7.699999999999967, 34.40000000000017, 90.19999999999992, 98.89999999999938, 28.100000000000154, 56.00000000000018, 77.59999999999997, 20.000000000000014, 62.30000000000022, 20.000000000000014, -91.30000000000081, 118.09999999999948, 20.000000000000014, 57.80000000000021, -8.199999999999973, 47.00000000000024, 20.000000000000014, 92.90000000000018, 20.000000000000014, 127.39999999999998, 122.29999999999987, 56.90000000000008, 47.00000000000002, 28.100000000000147, -23.199999999999953, 20.000000000000014, 163.39999999999995, 150.50000000000006, 51.500000000000234, 20.000000000000014, 159.49999999999974, 125.29999999999957, 56.599999999999994, 199.1, 36.20000000000005, 62.900000000000055, 48.200000000000195, 37.10000000000019, 175.7, 20.000000000000014, 53.30000000000009, 29.00000000000013, 32.000000000000206, 73.0999999999997, 18.199999999999992, -3.10000000000004, 51.500000000000156, 9.499999999999966, 58.9999999999996, 129.79999999999956, 156.2, 175.39999999999998, 20.90000000000003, 89.59999999999941, 20.000000000000014, 65.90000000000006, 67.69999999999992, 32.60000000000021, 20.000000000000014, 56.90000000000015, 115.99999999999977, 13.999999999999964, 86.89999999999944, 33.49999999999999, 123.49999999999994, 116.29999999999981, 78.79999999999995, 47.90000000000018, -101.80000000000038, -132.69999999999996, 20.29999999999997, 88.39999999999935, 20.000000000000014, -201.10000000000025, 86.59999999999945, 20.000000000000014, 88.99999999999999, 122.59999999999951, 74.89999999999938, 46.99999999999999, -26.79999999999984, -114.10000000000025, 86.59999999999951, 20.000000000000014, 20.900000000000013, 33.800000000000075, -111.40000000000042, -48.39999999999988, 20.000000000000014, -158.50000000000017, 20.000000000000014, -5.799999999999953, 23.600000000000136, 86.5999999999995, 72.79999999999977, -18.699999999999932, -66.40000000000035, 20.000000000000014, 35.60000000000018, -103.9000000000008, -118.30000000000038, -54.70000000000011, -137.50000000000065, -160.30000000000047, 20.000000000000014, 125.29999999999953, -51.7, 20.000000000000014, 46.40000000000008, 16.99999999999997, 99.19999999999963, 21.500000000000036, 61.40000000000021, 81.19999999999945, -68.50000000000047, -34.90000000000009, 41.000000000000135, 20.000000000000014, 20.000000000000014, -9.400000000000205, 118.99999999999949, 16.399999999999967, 72.19999999999956, -17.49999999999993, 88.3999999999997, 20.000000000000014, 14.599999999999957, -19.899999999999764, 110.89999999999984, 56.00000000000012, 39.8000000000001, 29.000000000000167, 17.899999999999988, 99.19999999999946, 50.600000000000215, 36.20000000000012, 67.3999999999999, 129.49999999999963], "policy_predator_policy_reward": [42.0, 36.0, 0.0, 0.0, 0.0, 0.0, 100.0, 0.0, 0.0, 7.0, 10.0, 21.0, 6.0, 3.0, 0.0, 8.0, 0.0, 0.0, 33.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 9.0, 12.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 8.0, 0.0, 0.0, 0.0, 0.0, 39.0, 0.0, 5.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 15.0, 0.0, 18.0, 10.0, 0.0, 17.0, 3.0, 9.0, 1.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 41.0, 41.0, 0.0, 3.0, 0.0, 34.0, 0.0, 0.0, 0.0, 5.0, 13.0, 0.0, 0.0, 0.0, 35.0, 19.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 33.0, 29.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 17.0, 0.0, 0.0, 5.0, 0.0, 11.0, 0.0, 13.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 8.0, 0.0, 8.0, 0.0, 0.0, 8.0, 6.0, 131.0, 27.0, 0.0, 5.0, 0.0, 110.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 36.0, 57.0, 0.0, 0.0, 32.0, 0.0, 47.0, 58.0, 42.0, 49.0, 8.0, 9.0, 24.0, 0.0, 0.0, 46.0, 0.0, 48.0, 64.0, 24.0, 97.0, 46.0, 122.0, 37.0, 0.0, 0.0, 36.0, 5.0, 10.0, 2.0, 4.0, 6.0, 0.0, 0.0, 46.0, 43.0, 2.0, 16.0, 59.0, 0.0, 6.0, 0.0, 6.0, 32.0, 0.0, 0.0, 28.0, 0.0, 0.0, 0.0, 25.0, 9.0, 1.0, 0.0, 0.0, 0.0, 0.0, 14.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 21.852901064932226, "mean_inference_ms": 47.128466035771424, "mean_action_processing_ms": 10.874711190305089, "mean_env_wait_ms": 14.82461492635432, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01909041404724121, "StateBufferConnector_ms": 0.01192772388458252, "ViewRequirementAgentConnector_ms": 0.3660709857940674}, "num_episodes": 18, "episode_return_max": 344.6, "episode_return_min": -138.80000000000112, "episode_return_mean": 95.3609999999995, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 832000, "num_agent_steps_trained": 832000, "num_env_steps_sampled": 208000, "num_env_steps_trained": 208000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 172.18094610266976, "num_env_steps_trained_throughput_per_sec": 172.18094610266976, "timesteps_total": 208000, "num_env_steps_sampled_lifetime": 208000, "num_agent_steps_sampled_lifetime": 832000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 832000, "timers": {"training_iteration_time_ms": 21514.298, "restore_workers_time_ms": 0.019, "training_step_time_ms": 21514.236, "sample_time_ms": 3694.989, "learn_time_ms": 17782.246, "learn_throughput": 224.943, "synch_weights_time_ms": 32.239}, "counters": {"num_env_steps_sampled": 208000, "num_env_steps_trained": 208000, "num_agent_steps_sampled": 832000, "num_agent_steps_trained": 832000}, "done": false, "training_iteration": 52, "trial_id": "75ec3_00000", "date": "2024-08-13_02-45-58", "timestamp": 1723531558, "time_this_iter_s": 23.298065185546875, "time_total_s": 5213.412964105606, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b20841f0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 5213.412964105606, "iterations_since_restore": 52, "perf": {"cpu_util_percent": 87.46666666666665, "ram_util_percent": 83.06666666666668}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.081745764589499, "cur_kl_coeff": 0.09010162353515624, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.289740100991789, "policy_loss": -0.011998392317059731, "vf_loss": 3.300275961431877, "vf_explained_var": 0.21672786726522697, "kl": 0.016232040030218775, "entropy": 1.3147908787878733, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 99225.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.19509558573798844, "cur_kl_coeff": 3.814697265625e-07, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.21175727049509685, "policy_loss": -0.0005205826082380203, "vf_loss": 0.21227785351349868, "vf_explained_var": 0.00024363158871887854, "kl": 0.002638444386131422, "entropy": 0.49072995818165877, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 99225.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 212000, "num_env_steps_trained": 212000, "num_agent_steps_sampled": 848000, "num_agent_steps_trained": 848000}, "env_runners": {"episode_reward_max": 344.6, "episode_reward_min": -138.80000000000112, "episode_reward_mean": 99.26899999999954, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -201.10000000000025, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 199.1, "predator_policy": 131.0}, "policy_reward_mean": {"prey_policy": 38.61949999999993, "predator_policy": 11.015}, "custom_metrics": {}, "hist_stats": {"episode_reward": [145.29999999999882, 52.80000000000043, 128.1999999999987, 40.0000000000003, 137.4999999999997, 141.5999999999986, 186.79999999999913, 99.39999999999851, 117.39999999999863, 70.5999999999999, 99.2999999999989, 91.29999999999968, 154.09999999999886, 62.10000000000035, 199.0999999999989, 95.09999999999874, 97.6, 82.29999999999981, 108.79999999999887, 80.79999999999926, 72.79999999999896, 112.8999999999993, 152.39999999999958, 192.19999999999948, 75.09999999999995, 50.80000000000018, 321.9000000000001, 71.49999999999996, 284.8000000000024, 257.69999999999953, 161.0999999999997, 93.29999999999976, 195.6999999999994, 82.29999999999932, 113.0999999999988, 32.100000000000335, 66.00000000000031, 199.7999999999992, 344.6, 112.49999999999861, 85.90000000000012, 100.2999999999999, 76.89999999999941, 144.99999999999918, 128.39999999999884, 239.79999999999976, 140.69999999999976, -76.49999999999986, 113.69999999999874, -71.10000000000053, 106.59999999999883, 212.59999999999923, 124.89999999999893, -47.900000000000325, 106.59999999999893, 86.69999999999894, -54.79999999999982, -47.4999999999998, 31.200000000000152, 134.19999999999897, 100.09999999999908, 1.6000000000000087, 19.69999999999996, -29.99999999999976, -138.80000000000112, 145.2999999999988, 9.300000000000082, 75.39999999999952, 130.69999999999905, 142.5999999999986, -14.400000000000134, 78.9999999999994, 69.60000000000022, 141.39999999999873, 92.69999999999939, 108.39999999999927, 22.700000000000017, 166.8999999999993, 102.7999999999994, 118.0999999999988, 86.79999999999973, 210.899999999999, 132.39999999999966, 67.60000000000012, 17.699999999999935, 40.0000000000003, 96.50000000000006, 122.29999999999869, 47.00000000000036, 148.89999999999927, 87.70000000000002, 112.19999999999888, 136.5999999999988, 87.6999999999993, 94.89999999999847, 49.50000000000025, 126.29999999999853, 72.39999999999984, 70.20000000000005, 57.80000000000025], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [56.900000000000205, 88.39999999999955, 34.700000000000216, 1.0999999999999652, 20.000000000000014, 108.19999999999959, 20.000000000000014, 20.000000000000014, 111.80000000000001, -13.299999999999919, 42.50000000000025, 94.09999999999945, 20.000000000000014, 162.79999999999984, 79.39999999999927, 20.000000000000014, 20.000000000000014, 97.39999999999941, 20.000000000000014, 50.60000000000017, 33.80000000000014, 39.50000000000024, 91.09999999999971, -17.799999999999862, 47.90000000000022, 96.19999999999953, 7.699999999999967, 34.40000000000017, 90.19999999999992, 98.89999999999938, 28.100000000000154, 56.00000000000018, 77.59999999999997, 20.000000000000014, 62.30000000000022, 20.000000000000014, -91.30000000000081, 118.09999999999948, 20.000000000000014, 57.80000000000021, -8.199999999999973, 47.00000000000024, 20.000000000000014, 92.90000000000018, 20.000000000000014, 127.39999999999998, 122.29999999999987, 56.90000000000008, 47.00000000000002, 28.100000000000147, -23.199999999999953, 20.000000000000014, 163.39999999999995, 150.50000000000006, 51.500000000000234, 20.000000000000014, 159.49999999999974, 125.29999999999957, 56.599999999999994, 199.1, 36.20000000000005, 62.900000000000055, 48.200000000000195, 37.10000000000019, 175.7, 20.000000000000014, 53.30000000000009, 29.00000000000013, 32.000000000000206, 73.0999999999997, 18.199999999999992, -3.10000000000004, 51.500000000000156, 9.499999999999966, 58.9999999999996, 129.79999999999956, 156.2, 175.39999999999998, 20.90000000000003, 89.59999999999941, 20.000000000000014, 65.90000000000006, 67.69999999999992, 32.60000000000021, 20.000000000000014, 56.90000000000015, 115.99999999999977, 13.999999999999964, 86.89999999999944, 33.49999999999999, 123.49999999999994, 116.29999999999981, 78.79999999999995, 47.90000000000018, -101.80000000000038, -132.69999999999996, 20.29999999999997, 88.39999999999935, 20.000000000000014, -201.10000000000025, 86.59999999999945, 20.000000000000014, 88.99999999999999, 122.59999999999951, 74.89999999999938, 46.99999999999999, -26.79999999999984, -114.10000000000025, 86.59999999999951, 20.000000000000014, 20.900000000000013, 33.800000000000075, -111.40000000000042, -48.39999999999988, 20.000000000000014, -158.50000000000017, 20.000000000000014, -5.799999999999953, 23.600000000000136, 86.5999999999995, 72.79999999999977, -18.699999999999932, -66.40000000000035, 20.000000000000014, 35.60000000000018, -103.9000000000008, -118.30000000000038, -54.70000000000011, -137.50000000000065, -160.30000000000047, 20.000000000000014, 125.29999999999953, -51.7, 20.000000000000014, 46.40000000000008, 16.99999999999997, 99.19999999999963, 21.500000000000036, 61.40000000000021, 81.19999999999945, -68.50000000000047, -34.90000000000009, 41.000000000000135, 20.000000000000014, 20.000000000000014, -9.400000000000205, 118.99999999999949, 16.399999999999967, 72.19999999999956, -17.49999999999993, 88.3999999999997, 20.000000000000014, 14.599999999999957, -19.899999999999764, 110.89999999999984, 56.00000000000012, 39.8000000000001, 29.000000000000167, 17.899999999999988, 99.19999999999946, 50.600000000000215, 36.20000000000012, 67.3999999999999, 129.49999999999963, 103.69999999999997, 22.700000000000056, 32.00000000000002, 20.60000000000003, -49.29999999999989, 20.000000000000014, 20.000000000000014, 20.000000000000014, 60.500000000000185, -19.0000000000002, 30.200000000000188, 85.09999999999971, 15.49999999999998, 9.499999999999964, 110.8999999999998, 20.000000000000014, 20.000000000000014, 67.69999999999995, 61.40000000000013, 42.80000000000021, 107.59999999999951, 20.000000000000014, 17.899999999999988, 60.80000000000007, 20.000000000000014, 74.89999999999942, 15.799999999999963, 31.699999999999996, 76.70000000000016, 44.60000000000022, 29.900000000000183, 42.500000000000156, 48.20000000000023, 20.000000000000014, 17.899999999999988, 38.900000000000055], "policy_predator_policy_reward": [0.0, 0.0, 9.0, 8.0, 0.0, 0.0, 0.0, 0.0, 39.0, 0.0, 5.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 15.0, 0.0, 18.0, 10.0, 0.0, 17.0, 3.0, 9.0, 1.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 41.0, 41.0, 0.0, 3.0, 0.0, 34.0, 0.0, 0.0, 0.0, 5.0, 13.0, 0.0, 0.0, 0.0, 35.0, 19.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 33.0, 29.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 17.0, 0.0, 0.0, 5.0, 0.0, 11.0, 0.0, 13.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 8.0, 0.0, 8.0, 0.0, 0.0, 8.0, 6.0, 131.0, 27.0, 0.0, 5.0, 0.0, 110.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 36.0, 57.0, 0.0, 0.0, 32.0, 0.0, 47.0, 58.0, 42.0, 49.0, 8.0, 9.0, 24.0, 0.0, 0.0, 46.0, 0.0, 48.0, 64.0, 24.0, 97.0, 46.0, 122.0, 37.0, 0.0, 0.0, 36.0, 5.0, 10.0, 2.0, 4.0, 6.0, 0.0, 0.0, 46.0, 43.0, 2.0, 16.0, 59.0, 0.0, 6.0, 0.0, 6.0, 32.0, 0.0, 0.0, 28.0, 0.0, 0.0, 0.0, 25.0, 9.0, 1.0, 0.0, 0.0, 0.0, 0.0, 14.0, 6.0, 0.0, 5.0, 10.0, 18.0, 29.0, 0.0, 0.0, 6.0, 49.0, 7.0, 0.0, 15.0, 7.0, 12.0, 6.0, 0.0, 0.0, 0.0, 8.0, 4.0, 5.0, 1.0, 8.0, 0.0, 0.0, 2.0, 0.0, 0.0, 5.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 21.50648223443862, "mean_inference_ms": 46.39430793725538, "mean_action_processing_ms": 10.696465308368625, "mean_env_wait_ms": 14.574987092353096, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.018268704414367676, "StateBufferConnector_ms": 0.011870503425598145, "ViewRequirementAgentConnector_ms": 0.3346383571624756}, "num_episodes": 18, "episode_return_max": 344.6, "episode_return_min": -138.80000000000112, "episode_return_mean": 99.26899999999954, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 848000, "num_agent_steps_trained": 848000, "num_env_steps_sampled": 212000, "num_env_steps_trained": 212000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 170.09712920864578, "num_env_steps_trained_throughput_per_sec": 170.09712920864578, "timesteps_total": 212000, "num_env_steps_sampled_lifetime": 212000, "num_agent_steps_sampled_lifetime": 848000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 848000, "timers": {"training_iteration_time_ms": 21959.295, "restore_workers_time_ms": 0.019, "training_step_time_ms": 21959.233, "sample_time_ms": 3863.259, "learn_time_ms": 18058.961, "learn_throughput": 221.497, "synch_weights_time_ms": 32.508}, "counters": {"num_env_steps_sampled": 212000, "num_env_steps_trained": 212000, "num_agent_steps_sampled": 848000, "num_agent_steps_trained": 848000}, "done": false, "training_iteration": 53, "trial_id": "75ec3_00000", "date": "2024-08-13_02-46-21", "timestamp": 1723531581, "time_this_iter_s": 23.565126180648804, "time_total_s": 5236.978090286255, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b1b12dc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 5236.978090286255, "iterations_since_restore": 53, "perf": {"cpu_util_percent": 87.49696969696969, "ram_util_percent": 82.92424242424242}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.20952384400147, "cur_kl_coeff": 0.09010162353515624, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.050444151358629, "policy_loss": -0.0033725859790734907, "vf_loss": 5.052737922264785, "vf_explained_var": 0.1391906729450932, "kl": 0.011973175363463767, "entropy": 1.3308847236885595, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 101115.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.37428051395706396, "cur_kl_coeff": 1.9073486328125e-07, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.2958285049155907, "policy_loss": -0.0010199526704295918, "vf_loss": 1.2968484595812186, "vf_explained_var": 0.0007362352161811143, "kl": 0.004415961603427561, "entropy": 0.4365565912591087, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 101115.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 216000, "num_env_steps_trained": 216000, "num_agent_steps_sampled": 864000, "num_agent_steps_trained": 864000}, "env_runners": {"episode_reward_max": 344.6, "episode_reward_min": -138.80000000000112, "episode_reward_mean": 100.6539999999996, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -201.10000000000025, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 199.1, "predator_policy": 131.0}, "policy_reward_mean": {"prey_policy": 39.01699999999993, "predator_policy": 11.31}, "custom_metrics": {}, "hist_stats": {"episode_reward": [152.39999999999958, 192.19999999999948, 75.09999999999995, 50.80000000000018, 321.9000000000001, 71.49999999999996, 284.8000000000024, 257.69999999999953, 161.0999999999997, 93.29999999999976, 195.6999999999994, 82.29999999999932, 113.0999999999988, 32.100000000000335, 66.00000000000031, 199.7999999999992, 344.6, 112.49999999999861, 85.90000000000012, 100.2999999999999, 76.89999999999941, 144.99999999999918, 128.39999999999884, 239.79999999999976, 140.69999999999976, -76.49999999999986, 113.69999999999874, -71.10000000000053, 106.59999999999883, 212.59999999999923, 124.89999999999893, -47.900000000000325, 106.59999999999893, 86.69999999999894, -54.79999999999982, -47.4999999999998, 31.200000000000152, 134.19999999999897, 100.09999999999908, 1.6000000000000087, 19.69999999999996, -29.99999999999976, -138.80000000000112, 145.2999999999988, 9.300000000000082, 75.39999999999952, 130.69999999999905, 142.5999999999986, -14.400000000000134, 78.9999999999994, 69.60000000000022, 141.39999999999873, 92.69999999999939, 108.39999999999927, 22.700000000000017, 166.8999999999993, 102.7999999999994, 118.0999999999988, 86.79999999999973, 210.899999999999, 132.39999999999966, 67.60000000000012, 17.699999999999935, 40.0000000000003, 96.50000000000006, 122.29999999999869, 47.00000000000036, 148.89999999999927, 87.70000000000002, 112.19999999999888, 136.5999999999988, 87.6999999999993, 94.89999999999847, 49.50000000000025, 126.29999999999853, 72.39999999999984, 70.20000000000005, 57.80000000000025, 106.59999999999924, 70.39999999999992, 136.29999999999885, 72.89999999999998, -21.899999999999714, 139.29999999999944, 40.0000000000003, 40.0000000000003, 182.3999999999992, 54.00000000000041, 51.29999999999966, 111.99999999999955, 232.2999999999996, 139.89999999999876, 239.7999999999991, 136.0999999999997, 31.70000000000018, 102.10000000000008, 111.99999999999861, 241.59999999999957, 170.49999999999935, 124.99999999999942], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 127.39999999999998, 122.29999999999987, 56.90000000000008, 47.00000000000002, 28.100000000000147, -23.199999999999953, 20.000000000000014, 163.39999999999995, 150.50000000000006, 51.500000000000234, 20.000000000000014, 159.49999999999974, 125.29999999999957, 56.599999999999994, 199.1, 36.20000000000005, 62.900000000000055, 48.200000000000195, 37.10000000000019, 175.7, 20.000000000000014, 53.30000000000009, 29.00000000000013, 32.000000000000206, 73.0999999999997, 18.199999999999992, -3.10000000000004, 51.500000000000156, 9.499999999999966, 58.9999999999996, 129.79999999999956, 156.2, 175.39999999999998, 20.90000000000003, 89.59999999999941, 20.000000000000014, 65.90000000000006, 67.69999999999992, 32.60000000000021, 20.000000000000014, 56.90000000000015, 115.99999999999977, 13.999999999999964, 86.89999999999944, 33.49999999999999, 123.49999999999994, 116.29999999999981, 78.79999999999995, 47.90000000000018, -101.80000000000038, -132.69999999999996, 20.29999999999997, 88.39999999999935, 20.000000000000014, -201.10000000000025, 86.59999999999945, 20.000000000000014, 88.99999999999999, 122.59999999999951, 74.89999999999938, 46.99999999999999, -26.79999999999984, -114.10000000000025, 86.59999999999951, 20.000000000000014, 20.900000000000013, 33.800000000000075, -111.40000000000042, -48.39999999999988, 20.000000000000014, -158.50000000000017, 20.000000000000014, -5.799999999999953, 23.600000000000136, 86.5999999999995, 72.79999999999977, -18.699999999999932, -66.40000000000035, 20.000000000000014, 35.60000000000018, -103.9000000000008, -118.30000000000038, -54.70000000000011, -137.50000000000065, -160.30000000000047, 20.000000000000014, 125.29999999999953, -51.7, 20.000000000000014, 46.40000000000008, 16.99999999999997, 99.19999999999963, 21.500000000000036, 61.40000000000021, 81.19999999999945, -68.50000000000047, -34.90000000000009, 41.000000000000135, 20.000000000000014, 20.000000000000014, -9.400000000000205, 118.99999999999949, 16.399999999999967, 72.19999999999956, -17.49999999999993, 88.3999999999997, 20.000000000000014, 14.599999999999957, -19.899999999999764, 110.89999999999984, 56.00000000000012, 39.8000000000001, 29.000000000000167, 17.899999999999988, 99.19999999999946, 50.600000000000215, 36.20000000000012, 67.3999999999999, 129.49999999999963, 103.69999999999997, 22.700000000000056, 32.00000000000002, 20.60000000000003, -49.29999999999989, 20.000000000000014, 20.000000000000014, 20.000000000000014, 60.500000000000185, -19.0000000000002, 30.200000000000188, 85.09999999999971, 15.49999999999998, 9.499999999999964, 110.8999999999998, 20.000000000000014, 20.000000000000014, 67.69999999999995, 61.40000000000013, 42.80000000000021, 107.59999999999951, 20.000000000000014, 17.899999999999988, 60.80000000000007, 20.000000000000014, 74.89999999999942, 15.799999999999963, 31.699999999999996, 76.70000000000016, 44.60000000000022, 29.900000000000183, 42.500000000000156, 48.20000000000023, 20.000000000000014, 17.899999999999988, 38.900000000000055, 20.000000000000014, 86.59999999999982, -51.39999999999988, 84.79999999999933, 74.89999999999996, 61.40000000000014, 17.899999999999988, 44.000000000000185, 20.000000000000014, -124.90000000000035, 23.60000000000008, 88.69999999999989, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 171.19999999999982, -14.799999999999821, 32.60000000000021, 1.3999999999999726, -129.10000000000005, 97.39999999999968, 92.00000000000007, 20.000000000000014, 145.09999999999997, 63.19999999999996, 20.000000000000014, 119.8999999999995, 174.79999999999993, 65.00000000000013, 26.300000000000114, 99.80000000000001, -0.9999999999999952, 22.700000000000053, 71.30000000000001, 30.799999999999997, 20.000000000000014, 91.99999999999935, 65.00000000000003, 176.59999999999994, 117.20000000000002, 53.30000000000019, 20.000000000000014, 97.99999999999983], "policy_predator_policy_reward": [0.0, 5.0, 13.0, 0.0, 0.0, 0.0, 35.0, 19.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 33.0, 29.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 17.0, 0.0, 0.0, 5.0, 0.0, 11.0, 0.0, 13.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 8.0, 0.0, 8.0, 0.0, 0.0, 8.0, 6.0, 131.0, 27.0, 0.0, 5.0, 0.0, 110.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 36.0, 57.0, 0.0, 0.0, 32.0, 0.0, 47.0, 58.0, 42.0, 49.0, 8.0, 9.0, 24.0, 0.0, 0.0, 46.0, 0.0, 48.0, 64.0, 24.0, 97.0, 46.0, 122.0, 37.0, 0.0, 0.0, 36.0, 5.0, 10.0, 2.0, 4.0, 6.0, 0.0, 0.0, 46.0, 43.0, 2.0, 16.0, 59.0, 0.0, 6.0, 0.0, 6.0, 32.0, 0.0, 0.0, 28.0, 0.0, 0.0, 0.0, 25.0, 9.0, 1.0, 0.0, 0.0, 0.0, 0.0, 14.0, 6.0, 0.0, 5.0, 10.0, 18.0, 29.0, 0.0, 0.0, 6.0, 49.0, 7.0, 0.0, 15.0, 7.0, 12.0, 6.0, 0.0, 0.0, 0.0, 8.0, 4.0, 5.0, 1.0, 8.0, 0.0, 0.0, 2.0, 0.0, 0.0, 5.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 37.0, 0.0, 0.0, 0.0, 11.0, 64.0, 19.0, 4.0, 23.0, 0.0, 0.0, 0.0, 0.0, 26.0, 0.0, 8.0, 12.0, 16.0, 67.0, 0.0, 0.0, 12.0, 12.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 21.08547865584731, "mean_inference_ms": 45.56425372907571, "mean_action_processing_ms": 10.524445089986315, "mean_env_wait_ms": 14.212492207601144, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.009090781211853027, "StateBufferConnector_ms": 0.008000493049621582, "ViewRequirementAgentConnector_ms": 0.33529090881347656}, "num_episodes": 22, "episode_return_max": 344.6, "episode_return_min": -138.80000000000112, "episode_return_mean": 100.6539999999996, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 864000, "num_agent_steps_trained": 864000, "num_env_steps_sampled": 216000, "num_env_steps_trained": 216000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 176.12687388020018, "num_env_steps_trained_throughput_per_sec": 176.12687388020018, "timesteps_total": 216000, "num_env_steps_sampled_lifetime": 216000, "num_agent_steps_sampled_lifetime": 864000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 864000, "timers": {"training_iteration_time_ms": 22262.584, "restore_workers_time_ms": 0.019, "training_step_time_ms": 22262.521, "sample_time_ms": 3944.322, "learn_time_ms": 18282.142, "learn_throughput": 218.793, "synch_weights_time_ms": 32.073}, "counters": {"num_env_steps_sampled": 216000, "num_env_steps_trained": 216000, "num_agent_steps_sampled": 864000, "num_agent_steps_trained": 864000}, "done": false, "training_iteration": 54, "trial_id": "75ec3_00000", "date": "2024-08-13_02-46-44", "timestamp": 1723531604, "time_this_iter_s": 22.771209955215454, "time_total_s": 5259.74930024147, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b1afe700>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 5259.74930024147, "iterations_since_restore": 54, "perf": {"cpu_util_percent": 86.66562499999999, "ram_util_percent": 83.275}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.8133380445696057, "cur_kl_coeff": 0.09010162353515624, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.185894538107372, "policy_loss": -0.01015919516412492, "vf_loss": 4.194789333822866, "vf_explained_var": 0.2499842301878349, "kl": 0.014033037862094398, "entropy": 1.337524073653751, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 103005.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.27276582659946547, "cur_kl_coeff": 9.5367431640625e-08, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.298573425372757, "policy_loss": -0.0007515419200654068, "vf_loss": 0.2993249663851216, "vf_explained_var": 0.00588276502947328, "kl": 0.003921159129621644, "entropy": 0.33553666612773975, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 103005.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 220000, "num_env_steps_trained": 220000, "num_agent_steps_sampled": 880000, "num_agent_steps_trained": 880000}, "env_runners": {"episode_reward_max": 286.1000000000008, "episode_reward_min": -138.80000000000112, "episode_reward_mean": 94.32499999999956, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -201.10000000000025, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 190.99999999999994, "predator_policy": 131.0}, "policy_reward_mean": {"prey_policy": 36.16249999999993, "predator_policy": 11.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [239.79999999999976, 140.69999999999976, -76.49999999999986, 113.69999999999874, -71.10000000000053, 106.59999999999883, 212.59999999999923, 124.89999999999893, -47.900000000000325, 106.59999999999893, 86.69999999999894, -54.79999999999982, -47.4999999999998, 31.200000000000152, 134.19999999999897, 100.09999999999908, 1.6000000000000087, 19.69999999999996, -29.99999999999976, -138.80000000000112, 145.2999999999988, 9.300000000000082, 75.39999999999952, 130.69999999999905, 142.5999999999986, -14.400000000000134, 78.9999999999994, 69.60000000000022, 141.39999999999873, 92.69999999999939, 108.39999999999927, 22.700000000000017, 166.8999999999993, 102.7999999999994, 118.0999999999988, 86.79999999999973, 210.899999999999, 132.39999999999966, 67.60000000000012, 17.699999999999935, 40.0000000000003, 96.50000000000006, 122.29999999999869, 47.00000000000036, 148.89999999999927, 87.70000000000002, 112.19999999999888, 136.5999999999988, 87.6999999999993, 94.89999999999847, 49.50000000000025, 126.29999999999853, 72.39999999999984, 70.20000000000005, 57.80000000000025, 106.59999999999924, 70.39999999999992, 136.29999999999885, 72.89999999999998, -21.899999999999714, 139.29999999999944, 40.0000000000003, 40.0000000000003, 182.3999999999992, 54.00000000000041, 51.29999999999966, 111.99999999999955, 232.2999999999996, 139.89999999999876, 239.7999999999991, 136.0999999999997, 31.70000000000018, 102.10000000000008, 111.99999999999861, 241.59999999999957, 170.49999999999935, 124.99999999999942, 75.09999999999995, 33.90000000000021, 139.59999999999943, 283.8999999999996, 100.29999999999853, 34.50000000000022, 40.0000000000003, 170.79999999999944, 114.89999999999998, 36.20000000000025, 185.6999999999993, 92.49999999999908, 42.50000000000033, 40.0000000000003, 40.0000000000003, 90.29999999999923, 286.1000000000008, 40.0000000000003, 127.29999999999862, 152.4999999999993, 209.1999999999992, 200.19999999999882, 174.99999999999935], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [123.49999999999994, 116.29999999999981, 78.79999999999995, 47.90000000000018, -101.80000000000038, -132.69999999999996, 20.29999999999997, 88.39999999999935, 20.000000000000014, -201.10000000000025, 86.59999999999945, 20.000000000000014, 88.99999999999999, 122.59999999999951, 74.89999999999938, 46.99999999999999, -26.79999999999984, -114.10000000000025, 86.59999999999951, 20.000000000000014, 20.900000000000013, 33.800000000000075, -111.40000000000042, -48.39999999999988, 20.000000000000014, -158.50000000000017, 20.000000000000014, -5.799999999999953, 23.600000000000136, 86.5999999999995, 72.79999999999977, -18.699999999999932, -66.40000000000035, 20.000000000000014, 35.60000000000018, -103.9000000000008, -118.30000000000038, -54.70000000000011, -137.50000000000065, -160.30000000000047, 20.000000000000014, 125.29999999999953, -51.7, 20.000000000000014, 46.40000000000008, 16.99999999999997, 99.19999999999963, 21.500000000000036, 61.40000000000021, 81.19999999999945, -68.50000000000047, -34.90000000000009, 41.000000000000135, 20.000000000000014, 20.000000000000014, -9.400000000000205, 118.99999999999949, 16.399999999999967, 72.19999999999956, -17.49999999999993, 88.3999999999997, 20.000000000000014, 14.599999999999957, -19.899999999999764, 110.89999999999984, 56.00000000000012, 39.8000000000001, 29.000000000000167, 17.899999999999988, 99.19999999999946, 50.600000000000215, 36.20000000000012, 67.3999999999999, 129.49999999999963, 103.69999999999997, 22.700000000000056, 32.00000000000002, 20.60000000000003, -49.29999999999989, 20.000000000000014, 20.000000000000014, 20.000000000000014, 60.500000000000185, -19.0000000000002, 30.200000000000188, 85.09999999999971, 15.49999999999998, 9.499999999999964, 110.8999999999998, 20.000000000000014, 20.000000000000014, 67.69999999999995, 61.40000000000013, 42.80000000000021, 107.59999999999951, 20.000000000000014, 17.899999999999988, 60.80000000000007, 20.000000000000014, 74.89999999999942, 15.799999999999963, 31.699999999999996, 76.70000000000016, 44.60000000000022, 29.900000000000183, 42.500000000000156, 48.20000000000023, 20.000000000000014, 17.899999999999988, 38.900000000000055, 20.000000000000014, 86.59999999999982, -51.39999999999988, 84.79999999999933, 74.89999999999996, 61.40000000000014, 17.899999999999988, 44.000000000000185, 20.000000000000014, -124.90000000000035, 23.60000000000008, 88.69999999999989, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 171.19999999999982, -14.799999999999821, 32.60000000000021, 1.3999999999999726, -129.10000000000005, 97.39999999999968, 92.00000000000007, 20.000000000000014, 145.09999999999997, 63.19999999999996, 20.000000000000014, 119.8999999999995, 174.79999999999993, 65.00000000000013, 26.300000000000114, 99.80000000000001, -0.9999999999999952, 22.700000000000053, 71.30000000000001, 30.799999999999997, 20.000000000000014, 91.99999999999935, 65.00000000000003, 176.59999999999994, 117.20000000000002, 53.30000000000019, 20.000000000000014, 97.99999999999983, 27.200000000000003, 47.900000000000155, 5.899999999999967, 20.000000000000014, 86.59999999999954, 38.00000000000016, 92.89999999999986, 190.99999999999994, 20.000000000000014, 80.29999999999927, 20.000000000000014, 9.499999999999964, 20.000000000000014, 20.000000000000014, 53.30000000000016, 72.5, 4.700000000000124, 72.19999999999996, 21.800000000000047, 7.399999999999965, 165.19999999999993, 12.499999999999968, 72.79999999999971, 7.699999999999973, 20.000000000000014, 12.499999999999968, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 21.800000000000047, 63.500000000000114, 171.19999999999985, 107.89999999999975, 20.000000000000014, 20.000000000000014, 41.60000000000017, 85.69999999999929, 20.000000000000014, 132.49999999999983, 189.19999999999993, 20.000000000000014, 50.60000000000023, 149.5999999999997, 132.49999999999983, 33.49999999999999], "policy_predator_policy_reward": [0.0, 0.0, 8.0, 6.0, 131.0, 27.0, 0.0, 5.0, 0.0, 110.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 36.0, 57.0, 0.0, 0.0, 32.0, 0.0, 47.0, 58.0, 42.0, 49.0, 8.0, 9.0, 24.0, 0.0, 0.0, 46.0, 0.0, 48.0, 64.0, 24.0, 97.0, 46.0, 122.0, 37.0, 0.0, 0.0, 36.0, 5.0, 10.0, 2.0, 4.0, 6.0, 0.0, 0.0, 46.0, 43.0, 2.0, 16.0, 59.0, 0.0, 6.0, 0.0, 6.0, 32.0, 0.0, 0.0, 28.0, 0.0, 0.0, 0.0, 25.0, 9.0, 1.0, 0.0, 0.0, 0.0, 0.0, 14.0, 6.0, 0.0, 5.0, 10.0, 18.0, 29.0, 0.0, 0.0, 6.0, 49.0, 7.0, 0.0, 15.0, 7.0, 12.0, 6.0, 0.0, 0.0, 0.0, 8.0, 4.0, 5.0, 1.0, 8.0, 0.0, 0.0, 2.0, 0.0, 0.0, 5.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 37.0, 0.0, 0.0, 0.0, 11.0, 64.0, 19.0, 4.0, 23.0, 0.0, 0.0, 0.0, 0.0, 26.0, 0.0, 8.0, 12.0, 16.0, 67.0, 0.0, 0.0, 12.0, 12.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 8.0, 0.0, 7.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 35.0, 10.0, 13.0, 25.0, 6.0, 1.0, 8.0, 0.0, 11.0, 1.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 20.681486266628, "mean_inference_ms": 44.635258584226186, "mean_action_processing_ms": 10.277591271944448, "mean_env_wait_ms": 13.980387830889105, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0088348388671875, "StateBufferConnector_ms": 0.008533358573913574, "ViewRequirementAgentConnector_ms": 0.3129006624221802}, "num_episodes": 23, "episode_return_max": 286.1000000000008, "episode_return_min": -138.80000000000112, "episode_return_mean": 94.32499999999956, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 880000, "num_agent_steps_trained": 880000, "num_env_steps_sampled": 220000, "num_env_steps_trained": 220000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 176.05427787288875, "num_env_steps_trained_throughput_per_sec": 176.05427787288875, "timesteps_total": 220000, "num_env_steps_sampled_lifetime": 220000, "num_agent_steps_sampled_lifetime": 880000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 880000, "timers": {"training_iteration_time_ms": 22499.138, "restore_workers_time_ms": 0.019, "training_step_time_ms": 22499.073, "sample_time_ms": 4008.371, "learn_time_ms": 18453.781, "learn_throughput": 216.758, "synch_weights_time_ms": 32.429}, "counters": {"num_env_steps_sampled": 220000, "num_env_steps_trained": 220000, "num_agent_steps_sampled": 880000, "num_agent_steps_trained": 880000}, "done": false, "training_iteration": 55, "trial_id": "75ec3_00000", "date": "2024-08-13_02-47-07", "timestamp": 1723531627, "time_this_iter_s": 22.780449151992798, "time_total_s": 5282.529749393463, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b205cdc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 5282.529749393463, "iterations_since_restore": 55, "perf": {"cpu_util_percent": 86.184375, "ram_util_percent": 83.178125}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.661974425834638, "cur_kl_coeff": 0.09010162353515624, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.078232053221849, "policy_loss": -0.007047756807755423, "vf_loss": 5.083796126375754, "vf_explained_var": 0.11211885712134144, "kl": 0.016466569899335797, "entropy": 1.3083013879559027, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 104895.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4114485288679442, "cur_kl_coeff": 4.76837158203125e-08, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.9238390763127614, "policy_loss": -0.000733828271133086, "vf_loss": 0.9245729033514936, "vf_explained_var": 0.0009510306138840933, "kl": 0.0013950427866091899, "entropy": 0.37783700019594224, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 104895.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 224000, "num_env_steps_trained": 224000, "num_agent_steps_sampled": 896000, "num_agent_steps_trained": 896000}, "env_runners": {"episode_reward_max": 303.6999999999998, "episode_reward_min": -138.80000000000112, "episode_reward_mean": 104.12099999999963, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -160.30000000000047, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 197.3, "predator_policy": 122.0}, "policy_reward_mean": {"prey_policy": 43.89049999999995, "predator_policy": 8.17}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-29.99999999999976, -138.80000000000112, 145.2999999999988, 9.300000000000082, 75.39999999999952, 130.69999999999905, 142.5999999999986, -14.400000000000134, 78.9999999999994, 69.60000000000022, 141.39999999999873, 92.69999999999939, 108.39999999999927, 22.700000000000017, 166.8999999999993, 102.7999999999994, 118.0999999999988, 86.79999999999973, 210.899999999999, 132.39999999999966, 67.60000000000012, 17.699999999999935, 40.0000000000003, 96.50000000000006, 122.29999999999869, 47.00000000000036, 148.89999999999927, 87.70000000000002, 112.19999999999888, 136.5999999999988, 87.6999999999993, 94.89999999999847, 49.50000000000025, 126.29999999999853, 72.39999999999984, 70.20000000000005, 57.80000000000025, 106.59999999999924, 70.39999999999992, 136.29999999999885, 72.89999999999998, -21.899999999999714, 139.29999999999944, 40.0000000000003, 40.0000000000003, 182.3999999999992, 54.00000000000041, 51.29999999999966, 111.99999999999955, 232.2999999999996, 139.89999999999876, 239.7999999999991, 136.0999999999997, 31.70000000000018, 102.10000000000008, 111.99999999999861, 241.59999999999957, 170.49999999999935, 124.99999999999942, 75.09999999999995, 33.90000000000021, 139.59999999999943, 283.8999999999996, 100.29999999999853, 34.50000000000022, 40.0000000000003, 170.79999999999944, 114.89999999999998, 36.20000000000025, 185.6999999999993, 92.49999999999908, 42.50000000000033, 40.0000000000003, 40.0000000000003, 90.29999999999923, 286.1000000000008, 40.0000000000003, 127.29999999999862, 152.4999999999993, 209.1999999999992, 200.19999999999882, 174.99999999999935, 64.60000000000029, -32.600000000000044, 190.09999999999957, -8.999999999999826, 213.99999999999915, 159.6999999999996, 47.20000000000035, 120.7999999999987, 30.100000000000147, 200.99999999999935, 165.09999999999917, 195.19999999999976, 40.0000000000003, 78.50000000000006, 66.10000000000021, 79.59999999999954, 303.6999999999998, 186.09999999999937], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-118.30000000000038, -54.70000000000011, -137.50000000000065, -160.30000000000047, 20.000000000000014, 125.29999999999953, -51.7, 20.000000000000014, 46.40000000000008, 16.99999999999997, 99.19999999999963, 21.500000000000036, 61.40000000000021, 81.19999999999945, -68.50000000000047, -34.90000000000009, 41.000000000000135, 20.000000000000014, 20.000000000000014, -9.400000000000205, 118.99999999999949, 16.399999999999967, 72.19999999999956, -17.49999999999993, 88.3999999999997, 20.000000000000014, 14.599999999999957, -19.899999999999764, 110.89999999999984, 56.00000000000012, 39.8000000000001, 29.000000000000167, 17.899999999999988, 99.19999999999946, 50.600000000000215, 36.20000000000012, 67.3999999999999, 129.49999999999963, 103.69999999999997, 22.700000000000056, 32.00000000000002, 20.60000000000003, -49.29999999999989, 20.000000000000014, 20.000000000000014, 20.000000000000014, 60.500000000000185, -19.0000000000002, 30.200000000000188, 85.09999999999971, 15.49999999999998, 9.499999999999964, 110.8999999999998, 20.000000000000014, 20.000000000000014, 67.69999999999995, 61.40000000000013, 42.80000000000021, 107.59999999999951, 20.000000000000014, 17.899999999999988, 60.80000000000007, 20.000000000000014, 74.89999999999942, 15.799999999999963, 31.699999999999996, 76.70000000000016, 44.60000000000022, 29.900000000000183, 42.500000000000156, 48.20000000000023, 20.000000000000014, 17.899999999999988, 38.900000000000055, 20.000000000000014, 86.59999999999982, -51.39999999999988, 84.79999999999933, 74.89999999999996, 61.40000000000014, 17.899999999999988, 44.000000000000185, 20.000000000000014, -124.90000000000035, 23.60000000000008, 88.69999999999989, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 171.19999999999982, -14.799999999999821, 32.60000000000021, 1.3999999999999726, -129.10000000000005, 97.39999999999968, 92.00000000000007, 20.000000000000014, 145.09999999999997, 63.19999999999996, 20.000000000000014, 119.8999999999995, 174.79999999999993, 65.00000000000013, 26.300000000000114, 99.80000000000001, -0.9999999999999952, 22.700000000000053, 71.30000000000001, 30.799999999999997, 20.000000000000014, 91.99999999999935, 65.00000000000003, 176.59999999999994, 117.20000000000002, 53.30000000000019, 20.000000000000014, 97.99999999999983, 27.200000000000003, 47.900000000000155, 5.899999999999967, 20.000000000000014, 86.59999999999954, 38.00000000000016, 92.89999999999986, 190.99999999999994, 20.000000000000014, 80.29999999999927, 20.000000000000014, 9.499999999999964, 20.000000000000014, 20.000000000000014, 53.30000000000016, 72.5, 4.700000000000124, 72.19999999999996, 21.800000000000047, 7.399999999999965, 165.19999999999993, 12.499999999999968, 72.79999999999971, 7.699999999999973, 20.000000000000014, 12.499999999999968, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 21.800000000000047, 63.500000000000114, 171.19999999999985, 107.89999999999975, 20.000000000000014, 20.000000000000014, 41.60000000000017, 85.69999999999929, 20.000000000000014, 132.49999999999983, 189.19999999999993, 20.000000000000014, 50.60000000000023, 149.5999999999997, 132.49999999999983, 33.49999999999999, 20.000000000000014, 41.60000000000013, 20.000000000000014, -118.59999999999997, 155.90000000000003, 24.20000000000004, 5.299999999999965, -139.3000000000001, 127.99999999999955, 73.99999999999979, 23.60000000000008, 136.10000000000002, 23.60000000000008, 23.60000000000007, 99.79999999999941, 20.000000000000014, 1.099999999999983, 20.000000000000014, 32.00000000000022, 164.0, 136.09999999999982, 20.000000000000014, 127.99999999999999, 51.20000000000009, 20.000000000000014, 20.000000000000014, 5.300000000000026, 63.19999999999999, 20.000000000000014, 46.10000000000016, 59.60000000000019, 20.000000000000014, 106.39999999999998, 197.3, 91.10000000000014, 92.00000000000014], "policy_predator_policy_reward": [97.0, 46.0, 122.0, 37.0, 0.0, 0.0, 36.0, 5.0, 10.0, 2.0, 4.0, 6.0, 0.0, 0.0, 46.0, 43.0, 2.0, 16.0, 59.0, 0.0, 6.0, 0.0, 6.0, 32.0, 0.0, 0.0, 28.0, 0.0, 0.0, 0.0, 25.0, 9.0, 1.0, 0.0, 0.0, 0.0, 0.0, 14.0, 6.0, 0.0, 5.0, 10.0, 18.0, 29.0, 0.0, 0.0, 6.0, 49.0, 7.0, 0.0, 15.0, 7.0, 12.0, 6.0, 0.0, 0.0, 0.0, 8.0, 4.0, 5.0, 1.0, 8.0, 0.0, 0.0, 2.0, 0.0, 0.0, 5.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 37.0, 0.0, 0.0, 0.0, 11.0, 64.0, 19.0, 4.0, 23.0, 0.0, 0.0, 0.0, 0.0, 26.0, 0.0, 8.0, 12.0, 16.0, 67.0, 0.0, 0.0, 12.0, 12.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 8.0, 0.0, 7.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 35.0, 10.0, 13.0, 25.0, 6.0, 1.0, 8.0, 0.0, 11.0, 1.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 3.0, 0.0, 66.0, 0.0, 10.0, 96.0, 29.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 9.0, 0.0, 0.0, 5.0, 0.0, 9.0, 0.0, 16.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 20.364533203925877, "mean_inference_ms": 43.95962060415842, "mean_action_processing_ms": 10.115344646383276, "mean_env_wait_ms": 13.755258681885785, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.008832335472106934, "StateBufferConnector_ms": 0.008688211441040039, "ViewRequirementAgentConnector_ms": 0.3082423210144043}, "num_episodes": 18, "episode_return_max": 303.6999999999998, "episode_return_min": -138.80000000000112, "episode_return_mean": 104.12099999999963, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 896000, "num_agent_steps_trained": 896000, "num_env_steps_sampled": 224000, "num_env_steps_trained": 224000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 142.82438970920316, "num_env_steps_trained_throughput_per_sec": 142.82438970920316, "timesteps_total": 224000, "num_env_steps_sampled_lifetime": 224000, "num_agent_steps_sampled_lifetime": 896000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 896000, "timers": {"training_iteration_time_ms": 23188.126, "restore_workers_time_ms": 0.019, "training_step_time_ms": 23188.058, "sample_time_ms": 4090.153, "learn_time_ms": 19061.709, "learn_throughput": 209.845, "synch_weights_time_ms": 30.925}, "counters": {"num_env_steps_sampled": 224000, "num_env_steps_trained": 224000, "num_agent_steps_sampled": 896000, "num_agent_steps_trained": 896000}, "done": false, "training_iteration": 56, "trial_id": "75ec3_00000", "date": "2024-08-13_02-47-35", "timestamp": 1723531655, "time_this_iter_s": 28.09053111076355, "time_total_s": 5310.620280504227, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b1a5de50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 5310.620280504227, "iterations_since_restore": 56, "perf": {"cpu_util_percent": 89.025, "ram_util_percent": 83.49749999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.5061058870620196, "cur_kl_coeff": 0.09010162353515624, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.8077793914805014, "policy_loss": -0.00871949929746469, "vf_loss": 3.81498437432385, "vf_explained_var": 0.19083863670233064, "kl": 0.016808985748124502, "entropy": 1.335363120881338, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 106785.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.2912125782242843, "cur_kl_coeff": 2.384185791015625e-08, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.24820033610064202, "policy_loss": -0.001303862587538937, "vf_loss": 0.24950419896556048, "vf_explained_var": 0.01001621027472158, "kl": 0.0014324011633528172, "entropy": 0.3869800442425662, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 106785.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 228000, "num_env_steps_trained": 228000, "num_agent_steps_sampled": 912000, "num_agent_steps_trained": 912000}, "env_runners": {"episode_reward_max": 303.6999999999998, "episode_reward_min": -32.600000000000044, "episode_reward_mean": 110.85799999999966, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -139.3000000000001, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 197.3, "predator_policy": 96.0}, "policy_reward_mean": {"prey_policy": 49.843999999999966, "predator_policy": 5.585}, "custom_metrics": {}, "hist_stats": {"episode_reward": [210.899999999999, 132.39999999999966, 67.60000000000012, 17.699999999999935, 40.0000000000003, 96.50000000000006, 122.29999999999869, 47.00000000000036, 148.89999999999927, 87.70000000000002, 112.19999999999888, 136.5999999999988, 87.6999999999993, 94.89999999999847, 49.50000000000025, 126.29999999999853, 72.39999999999984, 70.20000000000005, 57.80000000000025, 106.59999999999924, 70.39999999999992, 136.29999999999885, 72.89999999999998, -21.899999999999714, 139.29999999999944, 40.0000000000003, 40.0000000000003, 182.3999999999992, 54.00000000000041, 51.29999999999966, 111.99999999999955, 232.2999999999996, 139.89999999999876, 239.7999999999991, 136.0999999999997, 31.70000000000018, 102.10000000000008, 111.99999999999861, 241.59999999999957, 170.49999999999935, 124.99999999999942, 75.09999999999995, 33.90000000000021, 139.59999999999943, 283.8999999999996, 100.29999999999853, 34.50000000000022, 40.0000000000003, 170.79999999999944, 114.89999999999998, 36.20000000000025, 185.6999999999993, 92.49999999999908, 42.50000000000033, 40.0000000000003, 40.0000000000003, 90.29999999999923, 286.1000000000008, 40.0000000000003, 127.29999999999862, 152.4999999999993, 209.1999999999992, 200.19999999999882, 174.99999999999935, 64.60000000000029, -32.600000000000044, 190.09999999999957, -8.999999999999826, 213.99999999999915, 159.6999999999996, 47.20000000000035, 120.7999999999987, 30.100000000000147, 200.99999999999935, 165.09999999999917, 195.19999999999976, 40.0000000000003, 78.50000000000006, 66.10000000000021, 79.59999999999954, 303.6999999999998, 186.09999999999937, 267.7, 47.400000000000354, 145.9999999999997, 129.0999999999998, 53.90000000000017, 151.59999999999943, 128.5999999999997, 167.79999999999913, 184.79999999999953, 116.49999999999861, 67.90000000000012, 32.500000000000185, 67.40000000000009, 110.39999999999947, 26.8000000000001, 31.200000000000166, 181.0999999999992, 71.50000000000031], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [67.3999999999999, 129.49999999999963, 103.69999999999997, 22.700000000000056, 32.00000000000002, 20.60000000000003, -49.29999999999989, 20.000000000000014, 20.000000000000014, 20.000000000000014, 60.500000000000185, -19.0000000000002, 30.200000000000188, 85.09999999999971, 15.49999999999998, 9.499999999999964, 110.8999999999998, 20.000000000000014, 20.000000000000014, 67.69999999999995, 61.40000000000013, 42.80000000000021, 107.59999999999951, 20.000000000000014, 17.899999999999988, 60.80000000000007, 20.000000000000014, 74.89999999999942, 15.799999999999963, 31.699999999999996, 76.70000000000016, 44.60000000000022, 29.900000000000183, 42.500000000000156, 48.20000000000023, 20.000000000000014, 17.899999999999988, 38.900000000000055, 20.000000000000014, 86.59999999999982, -51.39999999999988, 84.79999999999933, 74.89999999999996, 61.40000000000014, 17.899999999999988, 44.000000000000185, 20.000000000000014, -124.90000000000035, 23.60000000000008, 88.69999999999989, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 171.19999999999982, -14.799999999999821, 32.60000000000021, 1.3999999999999726, -129.10000000000005, 97.39999999999968, 92.00000000000007, 20.000000000000014, 145.09999999999997, 63.19999999999996, 20.000000000000014, 119.8999999999995, 174.79999999999993, 65.00000000000013, 26.300000000000114, 99.80000000000001, -0.9999999999999952, 22.700000000000053, 71.30000000000001, 30.799999999999997, 20.000000000000014, 91.99999999999935, 65.00000000000003, 176.59999999999994, 117.20000000000002, 53.30000000000019, 20.000000000000014, 97.99999999999983, 27.200000000000003, 47.900000000000155, 5.899999999999967, 20.000000000000014, 86.59999999999954, 38.00000000000016, 92.89999999999986, 190.99999999999994, 20.000000000000014, 80.29999999999927, 20.000000000000014, 9.499999999999964, 20.000000000000014, 20.000000000000014, 53.30000000000016, 72.5, 4.700000000000124, 72.19999999999996, 21.800000000000047, 7.399999999999965, 165.19999999999993, 12.499999999999968, 72.79999999999971, 7.699999999999973, 20.000000000000014, 12.499999999999968, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 21.800000000000047, 63.500000000000114, 171.19999999999985, 107.89999999999975, 20.000000000000014, 20.000000000000014, 41.60000000000017, 85.69999999999929, 20.000000000000014, 132.49999999999983, 189.19999999999993, 20.000000000000014, 50.60000000000023, 149.5999999999997, 132.49999999999983, 33.49999999999999, 20.000000000000014, 41.60000000000013, 20.000000000000014, -118.59999999999997, 155.90000000000003, 24.20000000000004, 5.299999999999965, -139.3000000000001, 127.99999999999955, 73.99999999999979, 23.60000000000008, 136.10000000000002, 23.60000000000008, 23.60000000000007, 99.79999999999941, 20.000000000000014, 1.099999999999983, 20.000000000000014, 32.00000000000022, 164.0, 136.09999999999982, 20.000000000000014, 127.99999999999999, 51.20000000000009, 20.000000000000014, 20.000000000000014, 5.300000000000026, 63.19999999999999, 20.000000000000014, 46.10000000000016, 59.60000000000019, 20.000000000000014, 106.39999999999998, 197.3, 91.10000000000014, 92.00000000000014, 99.19999999999982, 168.4999999999998, 29.300000000000168, 1.099999999999983, 105.2, 39.80000000000025, 32.60000000000016, 96.49999999999997, 5.299999999999965, 41.600000000000016, 9.199999999999973, 133.3999999999999, 22.70000000000001, 89.89999999999995, 147.79999999999978, 20.000000000000014, 127.99999999999977, 39.80000000000009, 96.49999999999935, 20.000000000000014, 20.000000000000014, 47.90000000000016, 15.799999999999963, 13.699999999999964, 20.000000000000014, 40.400000000000134, 72.79999999999977, 29.600000000000186, 11.599999999999964, 3.199999999999967, 3.1999999999999615, 20.000000000000014, 160.09999999999988, 20.000000000000014, -5.199999999999941, 61.70000000000016], "policy_predator_policy_reward": [0.0, 14.0, 6.0, 0.0, 5.0, 10.0, 18.0, 29.0, 0.0, 0.0, 6.0, 49.0, 7.0, 0.0, 15.0, 7.0, 12.0, 6.0, 0.0, 0.0, 0.0, 8.0, 4.0, 5.0, 1.0, 8.0, 0.0, 0.0, 2.0, 0.0, 0.0, 5.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 37.0, 0.0, 0.0, 0.0, 11.0, 64.0, 19.0, 4.0, 23.0, 0.0, 0.0, 0.0, 0.0, 26.0, 0.0, 8.0, 12.0, 16.0, 67.0, 0.0, 0.0, 12.0, 12.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 8.0, 0.0, 7.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 35.0, 10.0, 13.0, 25.0, 6.0, 1.0, 8.0, 0.0, 11.0, 1.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 3.0, 0.0, 66.0, 0.0, 10.0, 96.0, 29.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 9.0, 0.0, 0.0, 5.0, 0.0, 9.0, 0.0, 16.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 9.0, 8.0, 0.0, 1.0, 0.0, 0.0, 0.0, 7.0, 9.0, 0.0, 16.0, 0.0, 0.0, 0.0, 12.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 7.0, 0.0, 8.0, 0.0, 12.0, 8.0, 0.0, 0.0, 1.0, 7.0, 8.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 20.057043990556124, "mean_inference_ms": 43.30344839268588, "mean_action_processing_ms": 9.958469658876, "mean_env_wait_ms": 13.537471894713116, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.009652018547058105, "StateBufferConnector_ms": 0.0075234174728393555, "ViewRequirementAgentConnector_ms": 0.2613344192504883}, "num_episodes": 18, "episode_return_max": 303.6999999999998, "episode_return_min": -32.600000000000044, "episode_return_mean": 110.85799999999966, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 912000, "num_agent_steps_trained": 912000, "num_env_steps_sampled": 228000, "num_env_steps_trained": 228000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 177.65708175087636, "num_env_steps_trained_throughput_per_sec": 177.65708175087636, "timesteps_total": 228000, "num_env_steps_sampled_lifetime": 228000, "num_agent_steps_sampled_lifetime": 912000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 912000, "timers": {"training_iteration_time_ms": 23358.471, "restore_workers_time_ms": 0.019, "training_step_time_ms": 23358.404, "sample_time_ms": 4137.834, "learn_time_ms": 19191.809, "learn_throughput": 208.422, "synch_weights_time_ms": 24.418}, "counters": {"num_env_steps_sampled": 228000, "num_env_steps_trained": 228000, "num_agent_steps_sampled": 912000, "num_agent_steps_trained": 912000}, "done": false, "training_iteration": 57, "trial_id": "75ec3_00000", "date": "2024-08-13_02-47-58", "timestamp": 1723531678, "time_this_iter_s": 22.595251321792603, "time_total_s": 5333.215531826019, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b1afec10>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 5333.215531826019, "iterations_since_restore": 57, "perf": {"cpu_util_percent": 85.4, "ram_util_percent": 83.53125}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.3113630933184472, "cur_kl_coeff": 0.09010162353515624, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.118015374456133, "policy_loss": -0.007828595453415008, "vf_loss": 4.12444168978898, "vf_explained_var": 0.1451712719347111, "kl": 0.015563381589188742, "entropy": 1.3174616611193097, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 108675.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.356690458781899, "cur_kl_coeff": 1.1920928955078126e-08, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.7528205837995287, "policy_loss": -0.0007288939196360174, "vf_loss": 0.7535494792753111, "vf_explained_var": 0.004061634452254684, "kl": 0.002006487384132303, "entropy": 0.3368581909351248, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 108675.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 232000, "num_env_steps_trained": 232000, "num_agent_steps_sampled": 928000, "num_agent_steps_trained": 928000}, "env_runners": {"episode_reward_max": 303.6999999999998, "episode_reward_min": -32.600000000000044, "episode_reward_mean": 116.8379999999997, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -139.3000000000001, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 197.3, "predator_policy": 96.0}, "policy_reward_mean": {"prey_policy": 52.96399999999996, "predator_policy": 5.455}, "custom_metrics": {}, "hist_stats": {"episode_reward": [72.89999999999998, -21.899999999999714, 139.29999999999944, 40.0000000000003, 40.0000000000003, 182.3999999999992, 54.00000000000041, 51.29999999999966, 111.99999999999955, 232.2999999999996, 139.89999999999876, 239.7999999999991, 136.0999999999997, 31.70000000000018, 102.10000000000008, 111.99999999999861, 241.59999999999957, 170.49999999999935, 124.99999999999942, 75.09999999999995, 33.90000000000021, 139.59999999999943, 283.8999999999996, 100.29999999999853, 34.50000000000022, 40.0000000000003, 170.79999999999944, 114.89999999999998, 36.20000000000025, 185.6999999999993, 92.49999999999908, 42.50000000000033, 40.0000000000003, 40.0000000000003, 90.29999999999923, 286.1000000000008, 40.0000000000003, 127.29999999999862, 152.4999999999993, 209.1999999999992, 200.19999999999882, 174.99999999999935, 64.60000000000029, -32.600000000000044, 190.09999999999957, -8.999999999999826, 213.99999999999915, 159.6999999999996, 47.20000000000035, 120.7999999999987, 30.100000000000147, 200.99999999999935, 165.09999999999917, 195.19999999999976, 40.0000000000003, 78.50000000000006, 66.10000000000021, 79.59999999999954, 303.6999999999998, 186.09999999999937, 267.7, 47.400000000000354, 145.9999999999997, 129.0999999999998, 53.90000000000017, 151.59999999999943, 128.5999999999997, 167.79999999999913, 184.79999999999953, 116.49999999999861, 67.90000000000012, 32.500000000000185, 67.40000000000009, 110.39999999999947, 26.8000000000001, 31.200000000000166, 181.0999999999992, 71.50000000000031, 73.09999999999971, 286.6000000000016, 146.89999999999964, 200.5999999999993, 197.49999999999912, -11.199999999999925, 125.89999999999965, 149.79999999999936, 27.20000000000009, 42.100000000000335, 62.50000000000048, 165.99999999999923, 38.300000000000274, 192.0999999999994, 84.9999999999994, 136.2999999999998, 135.09999999999877, 192.59999999999883, 67.70000000000023, 145.69999999999936, 153.09999999999937, 76.99999999999949], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [17.899999999999988, 44.000000000000185, 20.000000000000014, -124.90000000000035, 23.60000000000008, 88.69999999999989, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 171.19999999999982, -14.799999999999821, 32.60000000000021, 1.3999999999999726, -129.10000000000005, 97.39999999999968, 92.00000000000007, 20.000000000000014, 145.09999999999997, 63.19999999999996, 20.000000000000014, 119.8999999999995, 174.79999999999993, 65.00000000000013, 26.300000000000114, 99.80000000000001, -0.9999999999999952, 22.700000000000053, 71.30000000000001, 30.799999999999997, 20.000000000000014, 91.99999999999935, 65.00000000000003, 176.59999999999994, 117.20000000000002, 53.30000000000019, 20.000000000000014, 97.99999999999983, 27.200000000000003, 47.900000000000155, 5.899999999999967, 20.000000000000014, 86.59999999999954, 38.00000000000016, 92.89999999999986, 190.99999999999994, 20.000000000000014, 80.29999999999927, 20.000000000000014, 9.499999999999964, 20.000000000000014, 20.000000000000014, 53.30000000000016, 72.5, 4.700000000000124, 72.19999999999996, 21.800000000000047, 7.399999999999965, 165.19999999999993, 12.499999999999968, 72.79999999999971, 7.699999999999973, 20.000000000000014, 12.499999999999968, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 21.800000000000047, 63.500000000000114, 171.19999999999985, 107.89999999999975, 20.000000000000014, 20.000000000000014, 41.60000000000017, 85.69999999999929, 20.000000000000014, 132.49999999999983, 189.19999999999993, 20.000000000000014, 50.60000000000023, 149.5999999999997, 132.49999999999983, 33.49999999999999, 20.000000000000014, 41.60000000000013, 20.000000000000014, -118.59999999999997, 155.90000000000003, 24.20000000000004, 5.299999999999965, -139.3000000000001, 127.99999999999955, 73.99999999999979, 23.60000000000008, 136.10000000000002, 23.60000000000008, 23.60000000000007, 99.79999999999941, 20.000000000000014, 1.099999999999983, 20.000000000000014, 32.00000000000022, 164.0, 136.09999999999982, 20.000000000000014, 127.99999999999999, 51.20000000000009, 20.000000000000014, 20.000000000000014, 5.300000000000026, 63.19999999999999, 20.000000000000014, 46.10000000000016, 59.60000000000019, 20.000000000000014, 106.39999999999998, 197.3, 91.10000000000014, 92.00000000000014, 99.19999999999982, 168.4999999999998, 29.300000000000168, 1.099999999999983, 105.2, 39.80000000000025, 32.60000000000016, 96.49999999999997, 5.299999999999965, 41.600000000000016, 9.199999999999973, 133.3999999999999, 22.70000000000001, 89.89999999999995, 147.79999999999978, 20.000000000000014, 127.99999999999977, 39.80000000000009, 96.49999999999935, 20.000000000000014, 20.000000000000014, 47.90000000000016, 15.799999999999963, 13.699999999999964, 20.000000000000014, 40.400000000000134, 72.79999999999977, 29.600000000000186, 11.599999999999964, 3.199999999999967, 3.1999999999999615, 20.000000000000014, 160.09999999999988, 20.000000000000014, -5.199999999999941, 61.70000000000016, 53.60000000000016, 9.499999999999964, 154.09999999999982, 132.49999999999957, 125.90000000000003, 20.000000000000014, 20.000000000000014, 173.59999999999997, 29.000000000000064, 168.49999999999986, -85.60000000000053, 7.399999999999968, 85.69999999999938, -20.800000000000175, 129.79999999999987, 20.000000000000014, 11.599999999999964, 11.599999999999964, 20.000000000000014, 19.1, 42.500000000000206, 20.000000000000014, 23.600000000000065, 142.39999999999984, 20.000000000000014, 14.29999999999996, 172.1, 20.000000000000014, 25.400000000000006, 59.60000000000022, 104.59999999999994, 31.700000000000216, 18.799999999999986, 110.2999999999995, 70.39999999999972, 114.1999999999996, 23.60000000000008, 43.10000000000024, 74.59999999999944, 46.09999999999999, 49.400000000000176, 82.6999999999999, 30.800000000000196, 33.2000000000002], "policy_predator_policy_reward": [0.0, 11.0, 64.0, 19.0, 4.0, 23.0, 0.0, 0.0, 0.0, 0.0, 26.0, 0.0, 8.0, 12.0, 16.0, 67.0, 0.0, 0.0, 12.0, 12.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 8.0, 0.0, 7.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 35.0, 10.0, 13.0, 25.0, 6.0, 1.0, 8.0, 0.0, 11.0, 1.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 3.0, 0.0, 66.0, 0.0, 10.0, 96.0, 29.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 9.0, 0.0, 0.0, 5.0, 0.0, 9.0, 0.0, 16.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 9.0, 8.0, 0.0, 1.0, 0.0, 0.0, 0.0, 7.0, 9.0, 0.0, 16.0, 0.0, 0.0, 0.0, 12.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 7.0, 0.0, 8.0, 0.0, 12.0, 8.0, 0.0, 0.0, 1.0, 7.0, 8.0, 5.0, 5.0, 0.0, 0.0, 1.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 67.0, 61.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 2.0, 2.0, 6.0, 0.0, 1.0, 0.0, 25.0, 3.0, 18.0, 0.0, 13.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 20.121874240189992, "mean_inference_ms": 42.515448885185585, "mean_action_processing_ms": 9.412190775430481, "mean_env_wait_ms": 13.286285192597015, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.011950969696044922, "StateBufferConnector_ms": 0.008515596389770508, "ViewRequirementAgentConnector_ms": 0.32356178760528564}, "num_episodes": 22, "episode_return_max": 303.6999999999998, "episode_return_min": -32.600000000000044, "episode_return_mean": 116.8379999999997, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 928000, "num_agent_steps_trained": 928000, "num_env_steps_sampled": 232000, "num_env_steps_trained": 232000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 140.14005338267438, "num_env_steps_trained_throughput_per_sec": 140.14005338267438, "timesteps_total": 232000, "num_env_steps_sampled_lifetime": 232000, "num_agent_steps_sampled_lifetime": 928000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 928000, "timers": {"training_iteration_time_ms": 24135.575, "restore_workers_time_ms": 0.02, "training_step_time_ms": 24135.505, "sample_time_ms": 4240.977, "learn_time_ms": 19865.949, "learn_throughput": 201.35, "synch_weights_time_ms": 23.62}, "counters": {"num_env_steps_sampled": 232000, "num_env_steps_trained": 232000, "num_agent_steps_sampled": 928000, "num_agent_steps_trained": 928000}, "done": false, "training_iteration": 58, "trial_id": "75ec3_00000", "date": "2024-08-13_02-48-27", "timestamp": 1723531707, "time_this_iter_s": 28.594461917877197, "time_total_s": 5361.8099937438965, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2058280>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 5361.8099937438965, "iterations_since_restore": 58, "perf": {"cpu_util_percent": 88.17692307692307, "ram_util_percent": 83.57692307692308}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.2620777194777495, "cur_kl_coeff": 0.09010162353515624, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.575170208915831, "policy_loss": -0.0021391577486480984, "vf_loss": 5.5765761988503595, "vf_explained_var": 0.21558433657600767, "kl": 0.00813692534567755, "entropy": 1.2799915883276198, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 110565.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.24457334053934252, "cur_kl_coeff": 5.960464477539063e-09, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.20504335248596453, "policy_loss": -0.00045045131235999403, "vf_loss": 0.20549380435765705, "vf_explained_var": -0.022552732342765443, "kl": 0.0015237796285788917, "entropy": 0.3332009401270952, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 110565.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 236000, "num_env_steps_trained": 236000, "num_agent_steps_sampled": 944000, "num_agent_steps_trained": 944000}, "env_runners": {"episode_reward_max": 309.10000000000076, "episode_reward_min": -32.600000000000044, "episode_reward_mean": 123.6229999999997, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -139.3000000000001, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 96.0}, "policy_reward_mean": {"prey_policy": 56.96149999999996, "predator_policy": 4.85}, "custom_metrics": {}, "hist_stats": {"episode_reward": [124.99999999999942, 75.09999999999995, 33.90000000000021, 139.59999999999943, 283.8999999999996, 100.29999999999853, 34.50000000000022, 40.0000000000003, 170.79999999999944, 114.89999999999998, 36.20000000000025, 185.6999999999993, 92.49999999999908, 42.50000000000033, 40.0000000000003, 40.0000000000003, 90.29999999999923, 286.1000000000008, 40.0000000000003, 127.29999999999862, 152.4999999999993, 209.1999999999992, 200.19999999999882, 174.99999999999935, 64.60000000000029, -32.600000000000044, 190.09999999999957, -8.999999999999826, 213.99999999999915, 159.6999999999996, 47.20000000000035, 120.7999999999987, 30.100000000000147, 200.99999999999935, 165.09999999999917, 195.19999999999976, 40.0000000000003, 78.50000000000006, 66.10000000000021, 79.59999999999954, 303.6999999999998, 186.09999999999937, 267.7, 47.400000000000354, 145.9999999999997, 129.0999999999998, 53.90000000000017, 151.59999999999943, 128.5999999999997, 167.79999999999913, 184.79999999999953, 116.49999999999861, 67.90000000000012, 32.500000000000185, 67.40000000000009, 110.39999999999947, 26.8000000000001, 31.200000000000166, 181.0999999999992, 71.50000000000031, 73.09999999999971, 286.6000000000016, 146.89999999999964, 200.5999999999993, 197.49999999999912, -11.199999999999925, 125.89999999999965, 149.79999999999936, 27.20000000000009, 42.100000000000335, 62.50000000000048, 165.99999999999923, 38.300000000000274, 192.0999999999994, 84.9999999999994, 136.2999999999998, 135.09999999999877, 192.59999999999883, 67.70000000000023, 145.69999999999936, 153.09999999999937, 76.99999999999949, 137.49999999999915, 271.29999999999984, 165.9999999999989, 165.29999999999993, 125.4999999999999, 153.39999999999884, 61.00000000000045, 237.5999999999996, 108.19999999999916, 309.10000000000076, 167.3999999999996, 40.0000000000003, 34.60000000000028, 229.89999999999932, 40.0000000000003, 177.69999999999922, 152.19999999999916, 177.79999999999922], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 97.99999999999983, 27.200000000000003, 47.900000000000155, 5.899999999999967, 20.000000000000014, 86.59999999999954, 38.00000000000016, 92.89999999999986, 190.99999999999994, 20.000000000000014, 80.29999999999927, 20.000000000000014, 9.499999999999964, 20.000000000000014, 20.000000000000014, 53.30000000000016, 72.5, 4.700000000000124, 72.19999999999996, 21.800000000000047, 7.399999999999965, 165.19999999999993, 12.499999999999968, 72.79999999999971, 7.699999999999973, 20.000000000000014, 12.499999999999968, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 21.800000000000047, 63.500000000000114, 171.19999999999985, 107.89999999999975, 20.000000000000014, 20.000000000000014, 41.60000000000017, 85.69999999999929, 20.000000000000014, 132.49999999999983, 189.19999999999993, 20.000000000000014, 50.60000000000023, 149.5999999999997, 132.49999999999983, 33.49999999999999, 20.000000000000014, 41.60000000000013, 20.000000000000014, -118.59999999999997, 155.90000000000003, 24.20000000000004, 5.299999999999965, -139.3000000000001, 127.99999999999955, 73.99999999999979, 23.60000000000008, 136.10000000000002, 23.60000000000008, 23.60000000000007, 99.79999999999941, 20.000000000000014, 1.099999999999983, 20.000000000000014, 32.00000000000022, 164.0, 136.09999999999982, 20.000000000000014, 127.99999999999999, 51.20000000000009, 20.000000000000014, 20.000000000000014, 5.300000000000026, 63.19999999999999, 20.000000000000014, 46.10000000000016, 59.60000000000019, 20.000000000000014, 106.39999999999998, 197.3, 91.10000000000014, 92.00000000000014, 99.19999999999982, 168.4999999999998, 29.300000000000168, 1.099999999999983, 105.2, 39.80000000000025, 32.60000000000016, 96.49999999999997, 5.299999999999965, 41.600000000000016, 9.199999999999973, 133.3999999999999, 22.70000000000001, 89.89999999999995, 147.79999999999978, 20.000000000000014, 127.99999999999977, 39.80000000000009, 96.49999999999935, 20.000000000000014, 20.000000000000014, 47.90000000000016, 15.799999999999963, 13.699999999999964, 20.000000000000014, 40.400000000000134, 72.79999999999977, 29.600000000000186, 11.599999999999964, 3.199999999999967, 3.1999999999999615, 20.000000000000014, 160.09999999999988, 20.000000000000014, -5.199999999999941, 61.70000000000016, 53.60000000000016, 9.499999999999964, 154.09999999999982, 132.49999999999957, 125.90000000000003, 20.000000000000014, 20.000000000000014, 173.59999999999997, 29.000000000000064, 168.49999999999986, -85.60000000000053, 7.399999999999968, 85.69999999999938, -20.800000000000175, 129.79999999999987, 20.000000000000014, 11.599999999999964, 11.599999999999964, 20.000000000000014, 19.1, 42.500000000000206, 20.000000000000014, 23.600000000000065, 142.39999999999984, 20.000000000000014, 14.29999999999996, 172.1, 20.000000000000014, 25.400000000000006, 59.60000000000022, 104.59999999999994, 31.700000000000216, 18.799999999999986, 110.2999999999995, 70.39999999999972, 114.1999999999996, 23.60000000000008, 43.10000000000024, 74.59999999999944, 46.09999999999999, 49.400000000000176, 82.6999999999999, 30.800000000000196, 33.2000000000002, 127.99999999999972, -11.499999999999822, 189.2, 82.09999999999957, 137.00000000000009, 29.000000000000167, 110.9, 19.400000000000183, 32.600000000000186, 92.89999999999998, 22.700000000000017, 130.69999999999956, 15.799999999999962, 42.200000000000216, 115.99999999999966, 110.6, 39.20000000000008, 20.000000000000014, 111.79999999999967, 197.29999999999998, 38.00000000000023, 121.39999999999998, 20.000000000000014, 20.000000000000014, 20.000000000000014, 5.599999999999973, 200.0, 29.90000000000015, 20.000000000000014, 20.000000000000014, 157.69999999999985, 20.000000000000014, 138.79999999999976, 7.399999999999967, 12.19999999999996, 134.5999999999998], "policy_predator_policy_reward": [7.0, 0.0, 0.0, 0.0, 8.0, 0.0, 7.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 35.0, 10.0, 13.0, 25.0, 6.0, 1.0, 8.0, 0.0, 11.0, 1.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 3.0, 0.0, 66.0, 0.0, 10.0, 96.0, 29.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 9.0, 0.0, 0.0, 5.0, 0.0, 9.0, 0.0, 16.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 9.0, 8.0, 0.0, 1.0, 0.0, 0.0, 0.0, 7.0, 9.0, 0.0, 16.0, 0.0, 0.0, 0.0, 12.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 7.0, 0.0, 8.0, 0.0, 12.0, 8.0, 0.0, 0.0, 1.0, 7.0, 8.0, 5.0, 5.0, 0.0, 0.0, 1.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 67.0, 61.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 2.0, 2.0, 6.0, 0.0, 1.0, 0.0, 25.0, 3.0, 18.0, 0.0, 13.0, 15.0, 6.0, 0.0, 0.0, 0.0, 0.0, 20.0, 15.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 10.0, 32.0, 17.0, 0.0, 0.0, 5.0, 3.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 14.0, 17.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 19.417420853778644, "mean_inference_ms": 41.98934444105109, "mean_action_processing_ms": 9.662747868074545, "mean_env_wait_ms": 13.044167645865977, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.012032032012939453, "StateBufferConnector_ms": 0.008306622505187988, "ViewRequirementAgentConnector_ms": 0.3256281614303589}, "num_episodes": 18, "episode_return_max": 309.10000000000076, "episode_return_min": -32.600000000000044, "episode_return_mean": 123.6229999999997, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 944000, "num_agent_steps_trained": 944000, "num_env_steps_sampled": 236000, "num_env_steps_trained": 236000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 154.0325815709169, "num_env_steps_trained_throughput_per_sec": 154.0325815709169, "timesteps_total": 236000, "num_env_steps_sampled_lifetime": 236000, "num_agent_steps_sampled_lifetime": 944000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 944000, "timers": {"training_iteration_time_ms": 24484.715, "restore_workers_time_ms": 0.02, "training_step_time_ms": 24484.645, "sample_time_ms": 4063.289, "learn_time_ms": 20393.345, "learn_throughput": 196.142, "synch_weights_time_ms": 22.395}, "counters": {"num_env_steps_sampled": 236000, "num_env_steps_trained": 236000, "num_agent_steps_sampled": 944000, "num_agent_steps_trained": 944000}, "done": false, "training_iteration": 59, "trial_id": "75ec3_00000", "date": "2024-08-13_02-48-53", "timestamp": 1723531733, "time_this_iter_s": 26.024574995040894, "time_total_s": 5387.834568738937, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b20588b0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 5387.834568738937, "iterations_since_restore": 59, "perf": {"cpu_util_percent": 89.21891891891893, "ram_util_percent": 83.54594594594595}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.9048116113616045, "cur_kl_coeff": 0.09010162353515624, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.06845054525547, "policy_loss": -0.001414108272794654, "vf_loss": 6.069408320623731, "vf_explained_var": 0.22420918531518766, "kl": 0.005064544142547769, "entropy": 1.2294091705922727, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 112455.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.389983891943105, "cur_kl_coeff": 2.9802322387695314e-09, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.557289008796215, "policy_loss": -0.0003914789461762344, "vf_loss": 0.5576804879466417, "vf_explained_var": 0.01098187701411979, "kl": 0.0014769642765820473, "entropy": 0.3355574075664793, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 112455.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 240000, "num_env_steps_trained": 240000, "num_agent_steps_sampled": 960000, "num_agent_steps_trained": 960000}, "env_runners": {"episode_reward_max": 352.0, "episode_reward_min": -32.600000000000044, "episode_reward_mean": 140.90699999999973, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -139.3000000000001, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 96.0}, "policy_reward_mean": {"prey_policy": 65.56849999999997, "predator_policy": 4.885}, "custom_metrics": {}, "hist_stats": {"episode_reward": [174.99999999999935, 64.60000000000029, -32.600000000000044, 190.09999999999957, -8.999999999999826, 213.99999999999915, 159.6999999999996, 47.20000000000035, 120.7999999999987, 30.100000000000147, 200.99999999999935, 165.09999999999917, 195.19999999999976, 40.0000000000003, 78.50000000000006, 66.10000000000021, 79.59999999999954, 303.6999999999998, 186.09999999999937, 267.7, 47.400000000000354, 145.9999999999997, 129.0999999999998, 53.90000000000017, 151.59999999999943, 128.5999999999997, 167.79999999999913, 184.79999999999953, 116.49999999999861, 67.90000000000012, 32.500000000000185, 67.40000000000009, 110.39999999999947, 26.8000000000001, 31.200000000000166, 181.0999999999992, 71.50000000000031, 73.09999999999971, 286.6000000000016, 146.89999999999964, 200.5999999999993, 197.49999999999912, -11.199999999999925, 125.89999999999965, 149.79999999999936, 27.20000000000009, 42.100000000000335, 62.50000000000048, 165.99999999999923, 38.300000000000274, 192.0999999999994, 84.9999999999994, 136.2999999999998, 135.09999999999877, 192.59999999999883, 67.70000000000023, 145.69999999999936, 153.09999999999937, 76.99999999999949, 137.49999999999915, 271.29999999999984, 165.9999999999989, 165.29999999999993, 125.4999999999999, 153.39999999999884, 61.00000000000045, 237.5999999999996, 108.19999999999916, 309.10000000000076, 167.3999999999996, 40.0000000000003, 34.60000000000028, 229.89999999999932, 40.0000000000003, 177.69999999999922, 152.19999999999916, 177.79999999999922, 219.99999999999926, 170.49999999999977, 352.0, 123.69999999999882, 250.39999999999947, 240.89999999999907, 219.99999999999926, 43.60000000000029, 137.19999999999874, 267.6999999999996, 147.29999999999964, 351.00000000000045, 165.79999999999941, 183.59999999999943, 179.499999999999, 107.80000000000003, 259.9, 32.80000000000019, 299.1999999999998, 176.79999999999953, 189.89999999999975, 229.59999999999945, 39.700000000000294], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [132.49999999999983, 33.49999999999999, 20.000000000000014, 41.60000000000013, 20.000000000000014, -118.59999999999997, 155.90000000000003, 24.20000000000004, 5.299999999999965, -139.3000000000001, 127.99999999999955, 73.99999999999979, 23.60000000000008, 136.10000000000002, 23.60000000000008, 23.60000000000007, 99.79999999999941, 20.000000000000014, 1.099999999999983, 20.000000000000014, 32.00000000000022, 164.0, 136.09999999999982, 20.000000000000014, 127.99999999999999, 51.20000000000009, 20.000000000000014, 20.000000000000014, 5.300000000000026, 63.19999999999999, 20.000000000000014, 46.10000000000016, 59.60000000000019, 20.000000000000014, 106.39999999999998, 197.3, 91.10000000000014, 92.00000000000014, 99.19999999999982, 168.4999999999998, 29.300000000000168, 1.099999999999983, 105.2, 39.80000000000025, 32.60000000000016, 96.49999999999997, 5.299999999999965, 41.600000000000016, 9.199999999999973, 133.3999999999999, 22.70000000000001, 89.89999999999995, 147.79999999999978, 20.000000000000014, 127.99999999999977, 39.80000000000009, 96.49999999999935, 20.000000000000014, 20.000000000000014, 47.90000000000016, 15.799999999999963, 13.699999999999964, 20.000000000000014, 40.400000000000134, 72.79999999999977, 29.600000000000186, 11.599999999999964, 3.199999999999967, 3.1999999999999615, 20.000000000000014, 160.09999999999988, 20.000000000000014, -5.199999999999941, 61.70000000000016, 53.60000000000016, 9.499999999999964, 154.09999999999982, 132.49999999999957, 125.90000000000003, 20.000000000000014, 20.000000000000014, 173.59999999999997, 29.000000000000064, 168.49999999999986, -85.60000000000053, 7.399999999999968, 85.69999999999938, -20.800000000000175, 129.79999999999987, 20.000000000000014, 11.599999999999964, 11.599999999999964, 20.000000000000014, 19.1, 42.500000000000206, 20.000000000000014, 23.600000000000065, 142.39999999999984, 20.000000000000014, 14.29999999999996, 172.1, 20.000000000000014, 25.400000000000006, 59.60000000000022, 104.59999999999994, 31.700000000000216, 18.799999999999986, 110.2999999999995, 70.39999999999972, 114.1999999999996, 23.60000000000008, 43.10000000000024, 74.59999999999944, 46.09999999999999, 49.400000000000176, 82.6999999999999, 30.800000000000196, 33.2000000000002, 127.99999999999972, -11.499999999999822, 189.2, 82.09999999999957, 137.00000000000009, 29.000000000000167, 110.9, 19.400000000000183, 32.600000000000186, 92.89999999999998, 22.700000000000017, 130.69999999999956, 15.799999999999962, 42.200000000000216, 115.99999999999966, 110.6, 39.20000000000008, 20.000000000000014, 111.79999999999967, 197.29999999999998, 38.00000000000023, 121.39999999999998, 20.000000000000014, 20.000000000000014, 20.000000000000014, 5.599999999999973, 200.0, 29.90000000000015, 20.000000000000014, 20.000000000000014, 157.69999999999985, 20.000000000000014, 138.79999999999976, 7.399999999999967, 12.19999999999996, 134.5999999999998, 20.000000000000014, 200.0, 53.30000000000023, 117.20000000000005, 158.9, 178.1, 20.90000000000003, 102.79999999999949, 102.79999999999944, 146.59999999999997, 51.500000000000234, 181.4, 200.0, 20.000000000000014, 20.000000000000014, 23.60000000000008, 117.19999999999948, 20.000000000000014, 86.59999999999943, 181.0999999999999, 146.00000000000006, -15.699999999999793, 157.69999999999976, 191.3, 20.000000000000014, 135.79999999999993, -36.699999999999896, 191.29999999999998, 20.000000000000014, 159.49999999999974, 13.699999999999964, 91.10000000000011, 101.89999999999999, 136.99999999999983, 1.0999999999999794, 22.70000000000006, 194.6, 104.59999999999998, 128.89999999999998, 47.90000000000017, 135.7999999999999, 25.100000000000186, 96.1999999999995, 109.39999999999999, 7.399999999999965, 26.300000000000114], "policy_predator_policy_reward": [0.0, 9.0, 0.0, 3.0, 0.0, 66.0, 0.0, 10.0, 96.0, 29.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 9.0, 0.0, 0.0, 5.0, 0.0, 9.0, 0.0, 16.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 9.0, 8.0, 0.0, 1.0, 0.0, 0.0, 0.0, 7.0, 9.0, 0.0, 16.0, 0.0, 0.0, 0.0, 12.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 7.0, 0.0, 8.0, 0.0, 12.0, 8.0, 0.0, 0.0, 1.0, 7.0, 8.0, 5.0, 5.0, 0.0, 0.0, 1.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 67.0, 61.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 2.0, 2.0, 6.0, 0.0, 1.0, 0.0, 25.0, 3.0, 18.0, 0.0, 13.0, 15.0, 6.0, 0.0, 0.0, 0.0, 0.0, 20.0, 15.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 10.0, 32.0, 17.0, 0.0, 0.0, 5.0, 3.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 14.0, 17.0, 0.0, 0.0, 0.0, 0.0, 7.0, 8.0, 0.0, 0.0, 0.0, 1.0, 5.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 17.0, 2.0, 0.0, 9.0, 1.0, 0.0, 29.0, 0.0, 0.0, 0.0, 3.0, 9.0, 12.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 19.0, 10.0, 17.0, 7.0, 0.0, 6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 19.07626342792269, "mean_inference_ms": 41.20898122580122, "mean_action_processing_ms": 9.455940431237174, "mean_env_wait_ms": 12.850103769860237, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.016010403633117676, "StateBufferConnector_ms": 0.008298039436340332, "ViewRequirementAgentConnector_ms": 0.32338428497314453}, "num_episodes": 23, "episode_return_max": 352.0, "episode_return_min": -32.600000000000044, "episode_return_mean": 140.90699999999973, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 960000, "num_agent_steps_trained": 960000, "num_env_steps_sampled": 240000, "num_env_steps_trained": 240000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 109.14995968490763, "num_env_steps_trained_throughput_per_sec": 109.14995968490763, "timesteps_total": 240000, "num_env_steps_sampled_lifetime": 240000, "num_agent_steps_sampled_lifetime": 960000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 960000, "timers": {"training_iteration_time_ms": 25707.078, "restore_workers_time_ms": 0.02, "training_step_time_ms": 25707.008, "sample_time_ms": 3887.013, "learn_time_ms": 21791.532, "learn_throughput": 183.558, "synch_weights_time_ms": 22.901}, "counters": {"num_env_steps_sampled": 240000, "num_env_steps_trained": 240000, "num_agent_steps_sampled": 960000, "num_agent_steps_trained": 960000}, "done": false, "training_iteration": 60, "trial_id": "75ec3_00000", "date": "2024-08-13_02-49-29", "timestamp": 1723531769, "time_this_iter_s": 36.75807213783264, "time_total_s": 5424.59264087677, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b20843a0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 5424.59264087677, "iterations_since_restore": 60, "perf": {"cpu_util_percent": 93.8153846153846, "ram_util_percent": 83.58846153846154}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.0489043096070567, "cur_kl_coeff": 0.09010162353515624, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.9581706132838335, "policy_loss": -0.0027411021622361013, "vf_loss": 6.959932589152503, "vf_explained_var": 0.26185718415275455, "kl": 0.010867016297824213, "entropy": 1.2431151342139672, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 114345.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.2468547844934085, "cur_kl_coeff": 1.4901161193847657e-09, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.13800452764850682, "policy_loss": -0.0005099612608473137, "vf_loss": 0.1385144890799888, "vf_explained_var": 0.011487855766185377, "kl": 0.003036576797684248, "entropy": 0.4005360878018475, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 114345.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 244000, "num_env_steps_trained": 244000, "num_agent_steps_sampled": 976000, "num_agent_steps_trained": 976000}, "env_runners": {"episode_reward_max": 359.7, "episode_reward_min": -11.199999999999925, "episode_reward_mean": 159.10399999999967, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -85.60000000000053, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 67.0}, "policy_reward_mean": {"prey_policy": 75.43699999999995, "predator_policy": 4.115}, "custom_metrics": {}, "hist_stats": {"episode_reward": [186.09999999999937, 267.7, 47.400000000000354, 145.9999999999997, 129.0999999999998, 53.90000000000017, 151.59999999999943, 128.5999999999997, 167.79999999999913, 184.79999999999953, 116.49999999999861, 67.90000000000012, 32.500000000000185, 67.40000000000009, 110.39999999999947, 26.8000000000001, 31.200000000000166, 181.0999999999992, 71.50000000000031, 73.09999999999971, 286.6000000000016, 146.89999999999964, 200.5999999999993, 197.49999999999912, -11.199999999999925, 125.89999999999965, 149.79999999999936, 27.20000000000009, 42.100000000000335, 62.50000000000048, 165.99999999999923, 38.300000000000274, 192.0999999999994, 84.9999999999994, 136.2999999999998, 135.09999999999877, 192.59999999999883, 67.70000000000023, 145.69999999999936, 153.09999999999937, 76.99999999999949, 137.49999999999915, 271.29999999999984, 165.9999999999989, 165.29999999999993, 125.4999999999999, 153.39999999999884, 61.00000000000045, 237.5999999999996, 108.19999999999916, 309.10000000000076, 167.3999999999996, 40.0000000000003, 34.60000000000028, 229.89999999999932, 40.0000000000003, 177.69999999999922, 152.19999999999916, 177.79999999999922, 219.99999999999926, 170.49999999999977, 352.0, 123.69999999999882, 250.39999999999947, 240.89999999999907, 219.99999999999926, 43.60000000000029, 137.19999999999874, 267.6999999999996, 147.29999999999964, 351.00000000000045, 165.79999999999941, 183.59999999999943, 179.499999999999, 107.80000000000003, 259.9, 32.80000000000019, 299.1999999999998, 176.79999999999953, 189.89999999999975, 229.59999999999945, 39.700000000000294, 246.49999999999952, 274.20000000000005, 101.19999999999969, 198.29999999999922, 111.0999999999986, 240.4999999999993, 86.79999999999896, 201.69999999999933, 40.0000000000003, 249.1999999999997, 359.7, 355.9000000000003, 207.29999999999941, 281.40000000000003, 257.59999999999974, 248.19999999999965, 101.19999999999871, 348.0], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [91.10000000000014, 92.00000000000014, 99.19999999999982, 168.4999999999998, 29.300000000000168, 1.099999999999983, 105.2, 39.80000000000025, 32.60000000000016, 96.49999999999997, 5.299999999999965, 41.600000000000016, 9.199999999999973, 133.3999999999999, 22.70000000000001, 89.89999999999995, 147.79999999999978, 20.000000000000014, 127.99999999999977, 39.80000000000009, 96.49999999999935, 20.000000000000014, 20.000000000000014, 47.90000000000016, 15.799999999999963, 13.699999999999964, 20.000000000000014, 40.400000000000134, 72.79999999999977, 29.600000000000186, 11.599999999999964, 3.199999999999967, 3.1999999999999615, 20.000000000000014, 160.09999999999988, 20.000000000000014, -5.199999999999941, 61.70000000000016, 53.60000000000016, 9.499999999999964, 154.09999999999982, 132.49999999999957, 125.90000000000003, 20.000000000000014, 20.000000000000014, 173.59999999999997, 29.000000000000064, 168.49999999999986, -85.60000000000053, 7.399999999999968, 85.69999999999938, -20.800000000000175, 129.79999999999987, 20.000000000000014, 11.599999999999964, 11.599999999999964, 20.000000000000014, 19.1, 42.500000000000206, 20.000000000000014, 23.600000000000065, 142.39999999999984, 20.000000000000014, 14.29999999999996, 172.1, 20.000000000000014, 25.400000000000006, 59.60000000000022, 104.59999999999994, 31.700000000000216, 18.799999999999986, 110.2999999999995, 70.39999999999972, 114.1999999999996, 23.60000000000008, 43.10000000000024, 74.59999999999944, 46.09999999999999, 49.400000000000176, 82.6999999999999, 30.800000000000196, 33.2000000000002, 127.99999999999972, -11.499999999999822, 189.2, 82.09999999999957, 137.00000000000009, 29.000000000000167, 110.9, 19.400000000000183, 32.600000000000186, 92.89999999999998, 22.700000000000017, 130.69999999999956, 15.799999999999962, 42.200000000000216, 115.99999999999966, 110.6, 39.20000000000008, 20.000000000000014, 111.79999999999967, 197.29999999999998, 38.00000000000023, 121.39999999999998, 20.000000000000014, 20.000000000000014, 20.000000000000014, 5.599999999999973, 200.0, 29.90000000000015, 20.000000000000014, 20.000000000000014, 157.69999999999985, 20.000000000000014, 138.79999999999976, 7.399999999999967, 12.19999999999996, 134.5999999999998, 20.000000000000014, 200.0, 53.30000000000023, 117.20000000000005, 158.9, 178.1, 20.90000000000003, 102.79999999999949, 102.79999999999944, 146.59999999999997, 51.500000000000234, 181.4, 200.0, 20.000000000000014, 20.000000000000014, 23.60000000000008, 117.19999999999948, 20.000000000000014, 86.59999999999943, 181.0999999999999, 146.00000000000006, -15.699999999999793, 157.69999999999976, 191.3, 20.000000000000014, 135.79999999999993, -36.699999999999896, 191.29999999999998, 20.000000000000014, 159.49999999999974, 13.699999999999964, 91.10000000000011, 101.89999999999999, 136.99999999999983, 1.0999999999999794, 22.70000000000006, 194.6, 104.59999999999998, 128.89999999999998, 47.90000000000017, 135.7999999999999, 25.100000000000186, 96.1999999999995, 109.39999999999999, 7.399999999999965, 26.300000000000114, 185.5999999999999, 53.90000000000003, 109.39999999999998, 156.8, 39.80000000000001, 61.400000000000034, 9.499999999999964, 183.79999999999993, 71.29999999999968, 39.80000000000017, 92.5999999999997, 146.90000000000003, 66.79999999999998, 20.000000000000014, 175.7, 20.000000000000014, 20.000000000000014, 20.000000000000014, 177.5, 58.70000000000006, 144.5, 198.2, 183.8, 172.09999999999982, 55.69999999999997, 137.59999999999974, 96.80000000000001, 173.6, 80.29999999999974, 158.29999999999998, 97.39999999999998, 147.7999999999998, 81.19999999999936, 20.000000000000014, 163.1, 167.9], "policy_predator_policy_reward": [0.0, 3.0, 0.0, 0.0, 9.0, 8.0, 0.0, 1.0, 0.0, 0.0, 0.0, 7.0, 9.0, 0.0, 16.0, 0.0, 0.0, 0.0, 12.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 7.0, 0.0, 8.0, 0.0, 12.0, 8.0, 0.0, 0.0, 1.0, 7.0, 8.0, 5.0, 5.0, 0.0, 0.0, 1.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 67.0, 61.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 2.0, 2.0, 6.0, 0.0, 1.0, 0.0, 25.0, 3.0, 18.0, 0.0, 13.0, 15.0, 6.0, 0.0, 0.0, 0.0, 0.0, 20.0, 15.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 10.0, 32.0, 17.0, 0.0, 0.0, 5.0, 3.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 14.0, 17.0, 0.0, 0.0, 0.0, 0.0, 7.0, 8.0, 0.0, 0.0, 0.0, 1.0, 5.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 17.0, 2.0, 0.0, 9.0, 1.0, 0.0, 29.0, 0.0, 0.0, 0.0, 3.0, 9.0, 12.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 19.0, 10.0, 17.0, 7.0, 0.0, 6.0, 7.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 10.0, 3.0, 0.0, 17.0, 0.0, 0.0, 7.0, 7.0, 0.0, 11.0, 16.0, 3.0, 0.0, 3.0, 0.0, 0.0, 0.0, 17.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 18.809359442461773, "mean_inference_ms": 40.6445040635673, "mean_action_processing_ms": 9.320619775161282, "mean_env_wait_ms": 12.662057435830732, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.016210436820983887, "StateBufferConnector_ms": 0.008165955543518066, "ViewRequirementAgentConnector_ms": 0.3285503387451172}, "num_episodes": 18, "episode_return_max": 359.7, "episode_return_min": -11.199999999999925, "episode_return_mean": 159.10399999999967, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 976000, "num_agent_steps_trained": 976000, "num_env_steps_sampled": 244000, "num_env_steps_trained": 244000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 153.6801807395623, "num_env_steps_trained_throughput_per_sec": 153.6801807395623, "timesteps_total": 244000, "num_env_steps_sampled_lifetime": 244000, "num_agent_steps_sampled_lifetime": 976000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 976000, "timers": {"training_iteration_time_ms": 25988.665, "restore_workers_time_ms": 0.02, "training_step_time_ms": 25988.596, "sample_time_ms": 3719.554, "learn_time_ms": 22240.284, "learn_throughput": 179.854, "synch_weights_time_ms": 23.265}, "counters": {"num_env_steps_sampled": 244000, "num_env_steps_trained": 244000, "num_agent_steps_sampled": 976000, "num_agent_steps_trained": 976000}, "done": false, "training_iteration": 61, "trial_id": "75ec3_00000", "date": "2024-08-13_02-49-56", "timestamp": 1723531796, "time_this_iter_s": 26.087702989578247, "time_total_s": 5450.680343866348, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b1bc6430>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 5450.680343866348, "iterations_since_restore": 61, "perf": {"cpu_util_percent": 89.38918918918918, "ram_util_percent": 83.53513513513512}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.548403190383835, "cur_kl_coeff": 0.09010162353515624, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.457976460582995, "policy_loss": -0.007550471896187417, "vf_loss": 5.464184323568193, "vf_explained_var": 0.36416984023871246, "kl": 0.014901111936530093, "entropy": 1.281944968460729, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 116235.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.16300324654063733, "cur_kl_coeff": 7.450580596923829e-10, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.0721957136886746, "policy_loss": 0.0001778769964677474, "vf_loss": 0.07201783646166968, "vf_explained_var": -0.21502237234796798, "kl": 0.002654404475282257, "entropy": 0.3577398332811537, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 116235.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 248000, "num_env_steps_trained": 248000, "num_agent_steps_sampled": 992000, "num_agent_steps_trained": 992000}, "env_runners": {"episode_reward_max": 359.7, "episode_reward_min": -11.199999999999925, "episode_reward_mean": 165.2719999999996, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -85.60000000000053, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 67.0}, "policy_reward_mean": {"prey_policy": 78.73099999999997, "predator_policy": 3.905}, "custom_metrics": {}, "hist_stats": {"episode_reward": [71.50000000000031, 73.09999999999971, 286.6000000000016, 146.89999999999964, 200.5999999999993, 197.49999999999912, -11.199999999999925, 125.89999999999965, 149.79999999999936, 27.20000000000009, 42.100000000000335, 62.50000000000048, 165.99999999999923, 38.300000000000274, 192.0999999999994, 84.9999999999994, 136.2999999999998, 135.09999999999877, 192.59999999999883, 67.70000000000023, 145.69999999999936, 153.09999999999937, 76.99999999999949, 137.49999999999915, 271.29999999999984, 165.9999999999989, 165.29999999999993, 125.4999999999999, 153.39999999999884, 61.00000000000045, 237.5999999999996, 108.19999999999916, 309.10000000000076, 167.3999999999996, 40.0000000000003, 34.60000000000028, 229.89999999999932, 40.0000000000003, 177.69999999999922, 152.19999999999916, 177.79999999999922, 219.99999999999926, 170.49999999999977, 352.0, 123.69999999999882, 250.39999999999947, 240.89999999999907, 219.99999999999926, 43.60000000000029, 137.19999999999874, 267.6999999999996, 147.29999999999964, 351.00000000000045, 165.79999999999941, 183.59999999999943, 179.499999999999, 107.80000000000003, 259.9, 32.80000000000019, 299.1999999999998, 176.79999999999953, 189.89999999999975, 229.59999999999945, 39.700000000000294, 246.49999999999952, 274.20000000000005, 101.19999999999969, 198.29999999999922, 111.0999999999986, 240.4999999999993, 86.79999999999896, 201.69999999999933, 40.0000000000003, 249.1999999999997, 359.7, 355.9000000000003, 207.29999999999941, 281.40000000000003, 257.59999999999974, 248.19999999999965, 101.19999999999871, 348.0, 121.69999999999865, 89.49999999999896, 186.1999999999996, 104.79999999999863, 36.70000000000025, 107.59999999999965, 342.4, 108.69999999999976, 207.79999999999936, 90.79999999999941, 176.49999999999952, 214.59999999999914, 38.9000000000003, 115.59999999999923, 171.3999999999995, 269.4999999999999, 112.89999999999961, 217.99999999999926], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-5.199999999999941, 61.70000000000016, 53.60000000000016, 9.499999999999964, 154.09999999999982, 132.49999999999957, 125.90000000000003, 20.000000000000014, 20.000000000000014, 173.59999999999997, 29.000000000000064, 168.49999999999986, -85.60000000000053, 7.399999999999968, 85.69999999999938, -20.800000000000175, 129.79999999999987, 20.000000000000014, 11.599999999999964, 11.599999999999964, 20.000000000000014, 19.1, 42.500000000000206, 20.000000000000014, 23.600000000000065, 142.39999999999984, 20.000000000000014, 14.29999999999996, 172.1, 20.000000000000014, 25.400000000000006, 59.60000000000022, 104.59999999999994, 31.700000000000216, 18.799999999999986, 110.2999999999995, 70.39999999999972, 114.1999999999996, 23.60000000000008, 43.10000000000024, 74.59999999999944, 46.09999999999999, 49.400000000000176, 82.6999999999999, 30.800000000000196, 33.2000000000002, 127.99999999999972, -11.499999999999822, 189.2, 82.09999999999957, 137.00000000000009, 29.000000000000167, 110.9, 19.400000000000183, 32.600000000000186, 92.89999999999998, 22.700000000000017, 130.69999999999956, 15.799999999999962, 42.200000000000216, 115.99999999999966, 110.6, 39.20000000000008, 20.000000000000014, 111.79999999999967, 197.29999999999998, 38.00000000000023, 121.39999999999998, 20.000000000000014, 20.000000000000014, 20.000000000000014, 5.599999999999973, 200.0, 29.90000000000015, 20.000000000000014, 20.000000000000014, 157.69999999999985, 20.000000000000014, 138.79999999999976, 7.399999999999967, 12.19999999999996, 134.5999999999998, 20.000000000000014, 200.0, 53.30000000000023, 117.20000000000005, 158.9, 178.1, 20.90000000000003, 102.79999999999949, 102.79999999999944, 146.59999999999997, 51.500000000000234, 181.4, 200.0, 20.000000000000014, 20.000000000000014, 23.60000000000008, 117.19999999999948, 20.000000000000014, 86.59999999999943, 181.0999999999999, 146.00000000000006, -15.699999999999793, 157.69999999999976, 191.3, 20.000000000000014, 135.79999999999993, -36.699999999999896, 191.29999999999998, 20.000000000000014, 159.49999999999974, 13.699999999999964, 91.10000000000011, 101.89999999999999, 136.99999999999983, 1.0999999999999794, 22.70000000000006, 194.6, 104.59999999999998, 128.89999999999998, 47.90000000000017, 135.7999999999999, 25.100000000000186, 96.1999999999995, 109.39999999999999, 7.399999999999965, 26.300000000000114, 185.5999999999999, 53.90000000000003, 109.39999999999998, 156.8, 39.80000000000001, 61.400000000000034, 9.499999999999964, 183.79999999999993, 71.29999999999968, 39.80000000000017, 92.5999999999997, 146.90000000000003, 66.79999999999998, 20.000000000000014, 175.7, 20.000000000000014, 20.000000000000014, 20.000000000000014, 177.5, 58.70000000000006, 144.5, 198.2, 183.8, 172.09999999999982, 55.69999999999997, 137.59999999999974, 96.80000000000001, 173.6, 80.29999999999974, 158.29999999999998, 97.39999999999998, 147.7999999999998, 81.19999999999936, 20.000000000000014, 163.1, 167.9, 97.39999999999937, 23.300000000000086, 69.50000000000014, 20.000000000000014, 42.200000000000074, 137.0, 53.30000000000023, 51.500000000000234, 20.000000000000014, 13.699999999999964, -7.299999999999898, 101.89999999999989, 160.4, 173.0, 56.000000000000036, 49.70000000000022, 24.500000000000032, 176.3, 5.299999999999967, 78.4999999999998, 20.000000000000014, 150.5, 188.29999999999993, 26.30000000000013, 20.000000000000014, 17.899999999999977, 20.000000000000014, 95.59999999999971, 129.8, 32.60000000000023, 105.49999999999994, 164.0, 20.000000000000014, 92.89999999999998, 197.0, 20.000000000000014], "policy_predator_policy_reward": [7.0, 8.0, 5.0, 5.0, 0.0, 0.0, 1.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 67.0, 61.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 2.0, 2.0, 6.0, 0.0, 1.0, 0.0, 25.0, 3.0, 18.0, 0.0, 13.0, 15.0, 6.0, 0.0, 0.0, 0.0, 0.0, 20.0, 15.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 10.0, 32.0, 17.0, 0.0, 0.0, 5.0, 3.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 14.0, 17.0, 0.0, 0.0, 0.0, 0.0, 7.0, 8.0, 0.0, 0.0, 0.0, 1.0, 5.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 17.0, 2.0, 0.0, 9.0, 1.0, 0.0, 29.0, 0.0, 0.0, 0.0, 3.0, 9.0, 12.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 19.0, 10.0, 17.0, 7.0, 0.0, 6.0, 7.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 10.0, 3.0, 0.0, 17.0, 0.0, 0.0, 7.0, 7.0, 0.0, 11.0, 16.0, 3.0, 0.0, 3.0, 0.0, 0.0, 0.0, 17.0, 1.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 3.0, 0.0, 0.0, 13.0, 0.0, 9.0, 0.0, 3.0, 0.0, 7.0, 7.0, 0.0, 6.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 18.550436065445982, "mean_inference_ms": 40.097661511161306, "mean_action_processing_ms": 9.18949453797326, "mean_env_wait_ms": 12.480031844536557, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01430666446685791, "StateBufferConnector_ms": 0.008022904396057129, "ViewRequirementAgentConnector_ms": 0.33213090896606445}, "num_episodes": 18, "episode_return_max": 359.7, "episode_return_min": -11.199999999999925, "episode_return_mean": 165.2719999999996, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 992000, "num_agent_steps_trained": 992000, "num_env_steps_sampled": 248000, "num_env_steps_trained": 248000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 164.13670434235635, "num_env_steps_trained_throughput_per_sec": 164.13670434235635, "timesteps_total": 248000, "num_env_steps_sampled_lifetime": 248000, "num_agent_steps_sampled_lifetime": 992000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 992000, "timers": {"training_iteration_time_ms": 26102.521, "restore_workers_time_ms": 0.019, "training_step_time_ms": 26102.452, "sample_time_ms": 3554.311, "learn_time_ms": 22517.998, "learn_throughput": 177.636, "synch_weights_time_ms": 24.172}, "counters": {"num_env_steps_sampled": 248000, "num_env_steps_trained": 248000, "num_agent_steps_sampled": 992000, "num_agent_steps_trained": 992000}, "done": false, "training_iteration": 62, "trial_id": "75ec3_00000", "date": "2024-08-13_02-50-20", "timestamp": 1723531820, "time_this_iter_s": 24.458383321762085, "time_total_s": 5475.13872718811, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2058940>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 5475.13872718811, "iterations_since_restore": 62, "perf": {"cpu_util_percent": 88.24117647058824, "ram_util_percent": 83.47058823529412}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.7584526082352987, "cur_kl_coeff": 0.09010162353515624, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.836266502501473, "policy_loss": -0.004632964877660568, "vf_loss": 6.8397556529474, "vf_explained_var": 0.3562771210910151, "kl": 0.012694610351591378, "entropy": 1.2423982553381139, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 118125.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.17558208449876733, "cur_kl_coeff": 3.7252902984619143e-10, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.18592079485022517, "policy_loss": -0.0014757043360510752, "vf_loss": 0.18739649872860697, "vf_explained_var": -0.03804588898149117, "kl": 0.003925685397035772, "entropy": 0.33518038194961647, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 118125.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 252000, "num_env_steps_trained": 252000, "num_agent_steps_sampled": 1008000, "num_agent_steps_trained": 1008000}, "env_runners": {"episode_reward_max": 359.7, "episode_reward_min": 32.80000000000019, "episode_reward_mean": 183.79699999999954, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -36.699999999999896, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 32.0}, "policy_reward_mean": {"prey_policy": 88.74349999999997, "predator_policy": 3.155}, "custom_metrics": {}, "hist_stats": {"episode_reward": [76.99999999999949, 137.49999999999915, 271.29999999999984, 165.9999999999989, 165.29999999999993, 125.4999999999999, 153.39999999999884, 61.00000000000045, 237.5999999999996, 108.19999999999916, 309.10000000000076, 167.3999999999996, 40.0000000000003, 34.60000000000028, 229.89999999999932, 40.0000000000003, 177.69999999999922, 152.19999999999916, 177.79999999999922, 219.99999999999926, 170.49999999999977, 352.0, 123.69999999999882, 250.39999999999947, 240.89999999999907, 219.99999999999926, 43.60000000000029, 137.19999999999874, 267.6999999999996, 147.29999999999964, 351.00000000000045, 165.79999999999941, 183.59999999999943, 179.499999999999, 107.80000000000003, 259.9, 32.80000000000019, 299.1999999999998, 176.79999999999953, 189.89999999999975, 229.59999999999945, 39.700000000000294, 246.49999999999952, 274.20000000000005, 101.19999999999969, 198.29999999999922, 111.0999999999986, 240.4999999999993, 86.79999999999896, 201.69999999999933, 40.0000000000003, 249.1999999999997, 359.7, 355.9000000000003, 207.29999999999941, 281.40000000000003, 257.59999999999974, 248.19999999999965, 101.19999999999871, 348.0, 121.69999999999865, 89.49999999999896, 186.1999999999996, 104.79999999999863, 36.70000000000025, 107.59999999999965, 342.4, 108.69999999999976, 207.79999999999936, 90.79999999999941, 176.49999999999952, 214.59999999999914, 38.9000000000003, 115.59999999999923, 171.3999999999995, 269.4999999999999, 112.89999999999961, 217.99999999999926, 179.49999999999923, 315.20000000000033, 249.49999999999935, 81.69999999999942, 162.39999999999924, 228.09999999999897, 165.79999999999893, 209.1999999999993, 251.49999999999912, 125.09999999999917, 219.09999999999928, 291.9999999999998, 270.89999999999975, 296.50000000000045, 277.5999999999994, 218.19999999999902, 70.59999999999992, 233.79999999999944, 51.70000000000037, 320.0000000000007, 189.39999999999907, 129.09999999999985], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [30.800000000000196, 33.2000000000002, 127.99999999999972, -11.499999999999822, 189.2, 82.09999999999957, 137.00000000000009, 29.000000000000167, 110.9, 19.400000000000183, 32.600000000000186, 92.89999999999998, 22.700000000000017, 130.69999999999956, 15.799999999999962, 42.200000000000216, 115.99999999999966, 110.6, 39.20000000000008, 20.000000000000014, 111.79999999999967, 197.29999999999998, 38.00000000000023, 121.39999999999998, 20.000000000000014, 20.000000000000014, 20.000000000000014, 5.599999999999973, 200.0, 29.90000000000015, 20.000000000000014, 20.000000000000014, 157.69999999999985, 20.000000000000014, 138.79999999999976, 7.399999999999967, 12.19999999999996, 134.5999999999998, 20.000000000000014, 200.0, 53.30000000000023, 117.20000000000005, 158.9, 178.1, 20.90000000000003, 102.79999999999949, 102.79999999999944, 146.59999999999997, 51.500000000000234, 181.4, 200.0, 20.000000000000014, 20.000000000000014, 23.60000000000008, 117.19999999999948, 20.000000000000014, 86.59999999999943, 181.0999999999999, 146.00000000000006, -15.699999999999793, 157.69999999999976, 191.3, 20.000000000000014, 135.79999999999993, -36.699999999999896, 191.29999999999998, 20.000000000000014, 159.49999999999974, 13.699999999999964, 91.10000000000011, 101.89999999999999, 136.99999999999983, 1.0999999999999794, 22.70000000000006, 194.6, 104.59999999999998, 128.89999999999998, 47.90000000000017, 135.7999999999999, 25.100000000000186, 96.1999999999995, 109.39999999999999, 7.399999999999965, 26.300000000000114, 185.5999999999999, 53.90000000000003, 109.39999999999998, 156.8, 39.80000000000001, 61.400000000000034, 9.499999999999964, 183.79999999999993, 71.29999999999968, 39.80000000000017, 92.5999999999997, 146.90000000000003, 66.79999999999998, 20.000000000000014, 175.7, 20.000000000000014, 20.000000000000014, 20.000000000000014, 177.5, 58.70000000000006, 144.5, 198.2, 183.8, 172.09999999999982, 55.69999999999997, 137.59999999999974, 96.80000000000001, 173.6, 80.29999999999974, 158.29999999999998, 97.39999999999998, 147.7999999999998, 81.19999999999936, 20.000000000000014, 163.1, 167.9, 97.39999999999937, 23.300000000000086, 69.50000000000014, 20.000000000000014, 42.200000000000074, 137.0, 53.30000000000023, 51.500000000000234, 20.000000000000014, 13.699999999999964, -7.299999999999898, 101.89999999999989, 160.4, 173.0, 56.000000000000036, 49.70000000000022, 24.500000000000032, 176.3, 5.299999999999967, 78.4999999999998, 20.000000000000014, 150.5, 188.29999999999993, 26.30000000000013, 20.000000000000014, 17.899999999999977, 20.000000000000014, 95.59999999999971, 129.8, 32.60000000000023, 105.49999999999994, 164.0, 20.000000000000014, 92.89999999999998, 197.0, 20.000000000000014, 142.4, 28.100000000000037, 145.4, 144.79999999999993, 192.79999999999995, 37.70000000000016, 20.000000000000014, 58.70000000000007, 20.000000000000014, 142.39999999999984, 121.69999999999955, 106.39999999999941, 20.000000000000014, 144.79999999999967, 20.000000000000014, 189.2, 91.99999999999937, 159.49999999999974, 20.000000000000014, 94.10000000000008, 195.5, 23.60000000000001, 99.19999999999999, 192.8, 194.0, 74.89999999999954, 170.29999999999987, 126.19999999999999, 145.10000000000005, 132.4999999999996, 133.3999999999997, 84.79999999999936, 24.500000000000096, 46.10000000000017, 37.09999999999997, 193.7, 31.700000000000166, 20.000000000000014, 176.0, 133.99999999999983, 20.000000000000014, 169.39999999999984, 102.80000000000007, 26.300000000000118], "policy_predator_policy_reward": [0.0, 13.0, 15.0, 6.0, 0.0, 0.0, 0.0, 0.0, 20.0, 15.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 10.0, 32.0, 17.0, 0.0, 0.0, 5.0, 3.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 14.0, 17.0, 0.0, 0.0, 0.0, 0.0, 7.0, 8.0, 0.0, 0.0, 0.0, 1.0, 5.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 17.0, 2.0, 0.0, 9.0, 1.0, 0.0, 29.0, 0.0, 0.0, 0.0, 3.0, 9.0, 12.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 19.0, 10.0, 17.0, 7.0, 0.0, 6.0, 7.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 10.0, 3.0, 0.0, 17.0, 0.0, 0.0, 7.0, 7.0, 0.0, 11.0, 16.0, 3.0, 0.0, 3.0, 0.0, 0.0, 0.0, 17.0, 1.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 3.0, 0.0, 0.0, 13.0, 0.0, 9.0, 0.0, 3.0, 0.0, 7.0, 7.0, 0.0, 6.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 9.0, 11.0, 14.0, 0.0, 19.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 18.23446513525911, "mean_inference_ms": 39.473995173385475, "mean_action_processing_ms": 9.061254725265842, "mean_env_wait_ms": 12.214273767032774, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.012471795082092285, "StateBufferConnector_ms": 0.0071904659271240234, "ViewRequirementAgentConnector_ms": 0.2722896337509155}, "num_episodes": 22, "episode_return_max": 359.7, "episode_return_min": 32.80000000000019, "episode_return_mean": 183.79699999999954, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1008000, "num_agent_steps_trained": 1008000, "num_env_steps_sampled": 252000, "num_env_steps_trained": 252000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 160.65207297779017, "num_env_steps_trained_throughput_per_sec": 160.65207297779017, "timesteps_total": 252000, "num_env_steps_sampled_lifetime": 252000, "num_agent_steps_sampled_lifetime": 1008000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1008000, "timers": {"training_iteration_time_ms": 26240.776, "restore_workers_time_ms": 0.02, "training_step_time_ms": 26240.705, "sample_time_ms": 3461.654, "learn_time_ms": 22743.652, "learn_throughput": 175.873, "synch_weights_time_ms": 29.272}, "counters": {"num_env_steps_sampled": 252000, "num_env_steps_trained": 252000, "num_agent_steps_sampled": 1008000, "num_agent_steps_trained": 1008000}, "done": false, "training_iteration": 63, "trial_id": "75ec3_00000", "date": "2024-08-13_02-50-45", "timestamp": 1723531845, "time_this_iter_s": 24.999384880065918, "time_total_s": 5500.138112068176, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b205dc10>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 5500.138112068176, "iterations_since_restore": 63, "perf": {"cpu_util_percent": 86.80277777777776, "ram_util_percent": 83.55}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.883443121399198, "cur_kl_coeff": 0.09010162353515624, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.536337629197136, "policy_loss": -0.0035747563819987353, "vf_loss": 7.53933297717382, "vf_explained_var": 0.34602963486045757, "kl": 0.00643084136339384, "entropy": 1.236133320937081, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 120015.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.25247840698631036, "cur_kl_coeff": 1.8626451492309571e-10, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.35931020923471324, "policy_loss": -0.000351450100994457, "vf_loss": 0.35966165910817427, "vf_explained_var": 0.037199662034473724, "kl": 0.0025456154153122934, "entropy": 0.27265849554191823, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 120015.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 256000, "num_env_steps_trained": 256000, "num_agent_steps_sampled": 1024000, "num_agent_steps_trained": 1024000}, "env_runners": {"episode_reward_max": 382.9, "episode_reward_min": 32.80000000000019, "episode_reward_mean": 198.11599999999962, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -36.699999999999896, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 32.0}, "policy_reward_mean": {"prey_policy": 96.20299999999996, "predator_policy": 2.855}, "custom_metrics": {}, "hist_stats": {"episode_reward": [250.39999999999947, 240.89999999999907, 219.99999999999926, 43.60000000000029, 137.19999999999874, 267.6999999999996, 147.29999999999964, 351.00000000000045, 165.79999999999941, 183.59999999999943, 179.499999999999, 107.80000000000003, 259.9, 32.80000000000019, 299.1999999999998, 176.79999999999953, 189.89999999999975, 229.59999999999945, 39.700000000000294, 246.49999999999952, 274.20000000000005, 101.19999999999969, 198.29999999999922, 111.0999999999986, 240.4999999999993, 86.79999999999896, 201.69999999999933, 40.0000000000003, 249.1999999999997, 359.7, 355.9000000000003, 207.29999999999941, 281.40000000000003, 257.59999999999974, 248.19999999999965, 101.19999999999871, 348.0, 121.69999999999865, 89.49999999999896, 186.1999999999996, 104.79999999999863, 36.70000000000025, 107.59999999999965, 342.4, 108.69999999999976, 207.79999999999936, 90.79999999999941, 176.49999999999952, 214.59999999999914, 38.9000000000003, 115.59999999999923, 171.3999999999995, 269.4999999999999, 112.89999999999961, 217.99999999999926, 179.49999999999923, 315.20000000000033, 249.49999999999935, 81.69999999999942, 162.39999999999924, 228.09999999999897, 165.79999999999893, 209.1999999999993, 251.49999999999912, 125.09999999999917, 219.09999999999928, 291.9999999999998, 270.89999999999975, 296.50000000000045, 277.5999999999994, 218.19999999999902, 70.59999999999992, 233.79999999999944, 51.70000000000037, 320.0000000000007, 189.39999999999907, 129.09999999999985, 339.70000000000016, 149.59999999999954, 285.8000000000002, 136.2999999999986, 378.8000000000001, 260.6999999999997, 274.89999999999964, 276.50000000000017, 81.70000000000007, 274.90000000000117, 58.00000000000027, 120.09999999999985, 142.19999999999985, 279.29999999999995, 353.3, 54.90000000000042, 382.9, 106.59999999999991, 165.99999999999892, 374.8000000000003, 164.39999999999907, 274.2000000000003, 193.99999999999918], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [102.79999999999944, 146.59999999999997, 51.500000000000234, 181.4, 200.0, 20.000000000000014, 20.000000000000014, 23.60000000000008, 117.19999999999948, 20.000000000000014, 86.59999999999943, 181.0999999999999, 146.00000000000006, -15.699999999999793, 157.69999999999976, 191.3, 20.000000000000014, 135.79999999999993, -36.699999999999896, 191.29999999999998, 20.000000000000014, 159.49999999999974, 13.699999999999964, 91.10000000000011, 101.89999999999999, 136.99999999999983, 1.0999999999999794, 22.70000000000006, 194.6, 104.59999999999998, 128.89999999999998, 47.90000000000017, 135.7999999999999, 25.100000000000186, 96.1999999999995, 109.39999999999999, 7.399999999999965, 26.300000000000114, 185.5999999999999, 53.90000000000003, 109.39999999999998, 156.8, 39.80000000000001, 61.400000000000034, 9.499999999999964, 183.79999999999993, 71.29999999999968, 39.80000000000017, 92.5999999999997, 146.90000000000003, 66.79999999999998, 20.000000000000014, 175.7, 20.000000000000014, 20.000000000000014, 20.000000000000014, 177.5, 58.70000000000006, 144.5, 198.2, 183.8, 172.09999999999982, 55.69999999999997, 137.59999999999974, 96.80000000000001, 173.6, 80.29999999999974, 158.29999999999998, 97.39999999999998, 147.7999999999998, 81.19999999999936, 20.000000000000014, 163.1, 167.9, 97.39999999999937, 23.300000000000086, 69.50000000000014, 20.000000000000014, 42.200000000000074, 137.0, 53.30000000000023, 51.500000000000234, 20.000000000000014, 13.699999999999964, -7.299999999999898, 101.89999999999989, 160.4, 173.0, 56.000000000000036, 49.70000000000022, 24.500000000000032, 176.3, 5.299999999999967, 78.4999999999998, 20.000000000000014, 150.5, 188.29999999999993, 26.30000000000013, 20.000000000000014, 17.899999999999977, 20.000000000000014, 95.59999999999971, 129.8, 32.60000000000023, 105.49999999999994, 164.0, 20.000000000000014, 92.89999999999998, 197.0, 20.000000000000014, 142.4, 28.100000000000037, 145.4, 144.79999999999993, 192.79999999999995, 37.70000000000016, 20.000000000000014, 58.70000000000007, 20.000000000000014, 142.39999999999984, 121.69999999999955, 106.39999999999941, 20.000000000000014, 144.79999999999967, 20.000000000000014, 189.2, 91.99999999999937, 159.49999999999974, 20.000000000000014, 94.10000000000008, 195.5, 23.60000000000001, 99.19999999999999, 192.8, 194.0, 74.89999999999954, 170.29999999999987, 126.19999999999999, 145.10000000000005, 132.4999999999996, 133.3999999999997, 84.79999999999936, 24.500000000000096, 46.10000000000017, 37.09999999999997, 193.7, 31.700000000000166, 20.000000000000014, 176.0, 133.99999999999983, 20.000000000000014, 169.39999999999984, 102.80000000000007, 26.300000000000118, 182.0, 157.69999999999976, 117.79999999999988, 30.799999999999997, 80.00000000000009, 174.7999999999999, 72.20000000000016, 64.10000000000021, 199.1, 172.69999999999996, 119.89999999999955, 123.79999999999997, 197.29999999999998, 77.59999999999998, 91.69999999999942, 183.79999999999998, 20.000000000000014, 58.69999999999998, 103.69999999999948, 171.19999999999982, 20.000000000000014, 38.00000000000008, 82.1, 38.000000000000206, 103.69999999999999, 6.500000000000068, 106.3999999999997, 158.9, 157.4, 182.9, 31.100000000000207, 21.800000000000043, 189.2, 193.69999999999996, 86.59999999999997, 20.000000000000014, 145.99999999999977, 20.000000000000014, 200.0, 174.79999999999995, 136.39999999999975, 20.000000000000014, 88.99999999999982, 177.2, 22.70000000000001, 167.29999999999987], "policy_predator_policy_reward": [0.0, 1.0, 5.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 17.0, 2.0, 0.0, 9.0, 1.0, 0.0, 29.0, 0.0, 0.0, 0.0, 3.0, 9.0, 12.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 19.0, 10.0, 17.0, 7.0, 0.0, 6.0, 7.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 10.0, 3.0, 0.0, 17.0, 0.0, 0.0, 7.0, 7.0, 0.0, 11.0, 16.0, 3.0, 0.0, 3.0, 0.0, 0.0, 0.0, 17.0, 1.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 3.0, 0.0, 0.0, 13.0, 0.0, 9.0, 0.0, 3.0, 0.0, 7.0, 7.0, 0.0, 6.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 9.0, 11.0, 14.0, 0.0, 19.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 9.0, 22.0, 0.0, 0.0, 0.0, 7.0, 17.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 32.0, 0.0, 14.0, 0.0, 13.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 8.0, 0.0, 4.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 18.28818980704545, "mean_inference_ms": 39.55423554880422, "mean_action_processing_ms": 9.270471649689297, "mean_env_wait_ms": 10.578213259895053, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0124739408493042, "StateBufferConnector_ms": 0.00691068172454834, "ViewRequirementAgentConnector_ms": 0.27527856826782227}, "num_episodes": 23, "episode_return_max": 382.9, "episode_return_min": 32.80000000000019, "episode_return_mean": 198.11599999999962, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1024000, "num_agent_steps_trained": 1024000, "num_env_steps_sampled": 256000, "num_env_steps_trained": 256000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 157.38082357599487, "num_env_steps_trained_throughput_per_sec": 157.38082357599487, "timesteps_total": 256000, "num_env_steps_sampled_lifetime": 256000, "num_agent_steps_sampled_lifetime": 1024000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1024000, "timers": {"training_iteration_time_ms": 26511.292, "restore_workers_time_ms": 0.02, "training_step_time_ms": 26511.22, "sample_time_ms": 3482.442, "learn_time_ms": 22987.445, "learn_throughput": 174.008, "synch_weights_time_ms": 33.637}, "counters": {"num_env_steps_sampled": 256000, "num_env_steps_trained": 256000, "num_agent_steps_sampled": 1024000, "num_agent_steps_trained": 1024000}, "done": false, "training_iteration": 64, "trial_id": "75ec3_00000", "date": "2024-08-13_02-51-11", "timestamp": 1723531871, "time_this_iter_s": 25.58203411102295, "time_total_s": 5525.720146179199, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b206be50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 5525.720146179199, "iterations_since_restore": 64, "perf": {"cpu_util_percent": 88.36111111111111, "ram_util_percent": 83.52777777777777}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.879517509382238, "cur_kl_coeff": 0.09010162353515624, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.814753399702607, "policy_loss": -0.002646383617280258, "vf_loss": 7.8165740018168455, "vf_explained_var": 0.3430139716655489, "kl": 0.009165089303610811, "entropy": 1.238496610664186, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 121905.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.42457630967218724, "cur_kl_coeff": 9.313225746154786e-11, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.910748501870998, "policy_loss": -0.0006833480609452756, "vf_loss": 0.911431849034375, "vf_explained_var": 0.002230808564594814, "kl": 0.0013833897085824831, "entropy": 0.29369164038272133, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 121905.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 260000, "num_env_steps_trained": 260000, "num_agent_steps_sampled": 1040000, "num_agent_steps_trained": 1040000}, "env_runners": {"episode_reward_max": 382.9, "episode_reward_min": -66.70000000000027, "episode_reward_mean": 197.8279999999997, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -164.80000000000018, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 97.0}, "policy_reward_mean": {"prey_policy": 95.38399999999994, "predator_policy": 3.53}, "custom_metrics": {}, "hist_stats": {"episode_reward": [39.700000000000294, 246.49999999999952, 274.20000000000005, 101.19999999999969, 198.29999999999922, 111.0999999999986, 240.4999999999993, 86.79999999999896, 201.69999999999933, 40.0000000000003, 249.1999999999997, 359.7, 355.9000000000003, 207.29999999999941, 281.40000000000003, 257.59999999999974, 248.19999999999965, 101.19999999999871, 348.0, 121.69999999999865, 89.49999999999896, 186.1999999999996, 104.79999999999863, 36.70000000000025, 107.59999999999965, 342.4, 108.69999999999976, 207.79999999999936, 90.79999999999941, 176.49999999999952, 214.59999999999914, 38.9000000000003, 115.59999999999923, 171.3999999999995, 269.4999999999999, 112.89999999999961, 217.99999999999926, 179.49999999999923, 315.20000000000033, 249.49999999999935, 81.69999999999942, 162.39999999999924, 228.09999999999897, 165.79999999999893, 209.1999999999993, 251.49999999999912, 125.09999999999917, 219.09999999999928, 291.9999999999998, 270.89999999999975, 296.50000000000045, 277.5999999999994, 218.19999999999902, 70.59999999999992, 233.79999999999944, 51.70000000000037, 320.0000000000007, 189.39999999999907, 129.09999999999985, 339.70000000000016, 149.59999999999954, 285.8000000000002, 136.2999999999986, 378.8000000000001, 260.6999999999997, 274.89999999999964, 276.50000000000017, 81.70000000000007, 274.90000000000117, 58.00000000000027, 120.09999999999985, 142.19999999999985, 279.29999999999995, 353.3, 54.90000000000042, 382.9, 106.59999999999991, 165.99999999999892, 374.8000000000003, 164.39999999999907, 274.2000000000003, 193.99999999999918, 46.80000000000009, 257.79999999999995, 198.6999999999995, 255.89999999999947, 93.10000000000018, -66.70000000000027, 190.39999999999938, 282.4999999999999, 97.19999999999995, 106.3999999999998, 319.8000000000003, 346.90000000000003, 271.19999999999976, 267.69999999999976, 95.49999999999984, 130.8999999999997, 217.6999999999996, 342.40000000000066], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [7.399999999999965, 26.300000000000114, 185.5999999999999, 53.90000000000003, 109.39999999999998, 156.8, 39.80000000000001, 61.400000000000034, 9.499999999999964, 183.79999999999993, 71.29999999999968, 39.80000000000017, 92.5999999999997, 146.90000000000003, 66.79999999999998, 20.000000000000014, 175.7, 20.000000000000014, 20.000000000000014, 20.000000000000014, 177.5, 58.70000000000006, 144.5, 198.2, 183.8, 172.09999999999982, 55.69999999999997, 137.59999999999974, 96.80000000000001, 173.6, 80.29999999999974, 158.29999999999998, 97.39999999999998, 147.7999999999998, 81.19999999999936, 20.000000000000014, 163.1, 167.9, 97.39999999999937, 23.300000000000086, 69.50000000000014, 20.000000000000014, 42.200000000000074, 137.0, 53.30000000000023, 51.500000000000234, 20.000000000000014, 13.699999999999964, -7.299999999999898, 101.89999999999989, 160.4, 173.0, 56.000000000000036, 49.70000000000022, 24.500000000000032, 176.3, 5.299999999999967, 78.4999999999998, 20.000000000000014, 150.5, 188.29999999999993, 26.30000000000013, 20.000000000000014, 17.899999999999977, 20.000000000000014, 95.59999999999971, 129.8, 32.60000000000023, 105.49999999999994, 164.0, 20.000000000000014, 92.89999999999998, 197.0, 20.000000000000014, 142.4, 28.100000000000037, 145.4, 144.79999999999993, 192.79999999999995, 37.70000000000016, 20.000000000000014, 58.70000000000007, 20.000000000000014, 142.39999999999984, 121.69999999999955, 106.39999999999941, 20.000000000000014, 144.79999999999967, 20.000000000000014, 189.2, 91.99999999999937, 159.49999999999974, 20.000000000000014, 94.10000000000008, 195.5, 23.60000000000001, 99.19999999999999, 192.8, 194.0, 74.89999999999954, 170.29999999999987, 126.19999999999999, 145.10000000000005, 132.4999999999996, 133.3999999999997, 84.79999999999936, 24.500000000000096, 46.10000000000017, 37.09999999999997, 193.7, 31.700000000000166, 20.000000000000014, 176.0, 133.99999999999983, 20.000000000000014, 169.39999999999984, 102.80000000000007, 26.300000000000118, 182.0, 157.69999999999976, 117.79999999999988, 30.799999999999997, 80.00000000000009, 174.7999999999999, 72.20000000000016, 64.10000000000021, 199.1, 172.69999999999996, 119.89999999999955, 123.79999999999997, 197.29999999999998, 77.59999999999998, 91.69999999999942, 183.79999999999998, 20.000000000000014, 58.69999999999998, 103.69999999999948, 171.19999999999982, 20.000000000000014, 38.00000000000008, 82.1, 38.000000000000206, 103.69999999999999, 6.500000000000068, 106.3999999999997, 158.9, 157.4, 182.9, 31.100000000000207, 21.800000000000043, 189.2, 193.69999999999996, 86.59999999999997, 20.000000000000014, 145.99999999999977, 20.000000000000014, 200.0, 174.79999999999995, 136.39999999999975, 20.000000000000014, 88.99999999999982, 177.2, 22.70000000000001, 167.29999999999987, -3.0999999999999757, 38.899999999999984, 92.89999999999996, 164.90000000000003, 74.89999999999996, 102.80000000000003, 32.90000000000014, 200.0, 58.7000000000001, 34.400000000000055, 1.099999999999983, -164.80000000000018, 174.79999999999998, 11.599999999999968, 75.4999999999994, 200.0, 40.69999999999998, 54.50000000000007, 0.800000000000017, 95.59999999999997, 139.99999999999997, 165.8, 169.39999999999992, 177.5, 168.49999999999983, 73.7000000000001, 89.29999999999997, 178.39999999999998, 20.000000000000014, 69.5, 140.59999999999982, -36.699999999999754, 80.30000000000013, 100.4, 146.89999999999986, 195.49999999999997], "policy_predator_policy_reward": [0.0, 6.0, 7.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 10.0, 3.0, 0.0, 17.0, 0.0, 0.0, 7.0, 7.0, 0.0, 11.0, 16.0, 3.0, 0.0, 3.0, 0.0, 0.0, 0.0, 17.0, 1.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 3.0, 0.0, 0.0, 13.0, 0.0, 9.0, 0.0, 3.0, 0.0, 7.0, 7.0, 0.0, 6.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 9.0, 11.0, 14.0, 0.0, 19.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 9.0, 22.0, 0.0, 0.0, 0.0, 7.0, 17.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 32.0, 0.0, 14.0, 0.0, 13.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 8.0, 0.0, 4.0, 0.0, 0.0, 11.0, 0.0, 0.0, 7.0, 14.0, 3.0, 20.0, 0.0, 0.0, 97.0, 0.0, 4.0, 0.0, 0.0, 7.0, 0.0, 2.0, 10.0, 0.0, 0.0, 14.0, 0.0, 0.0, 16.0, 13.0, 0.0, 0.0, 0.0, 6.0, 0.0, 27.0, 8.0, 29.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 17.708587146526835, "mean_inference_ms": 38.31862101252574, "mean_action_processing_ms": 8.771978227341467, "mean_env_wait_ms": 11.87693882613765, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007847905158996582, "StateBufferConnector_ms": 0.006824374198913574, "ViewRequirementAgentConnector_ms": 0.31250035762786865}, "num_episodes": 18, "episode_return_max": 382.9, "episode_return_min": -66.70000000000027, "episode_return_mean": 197.8279999999997, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1040000, "num_agent_steps_trained": 1040000, "num_env_steps_sampled": 260000, "num_env_steps_trained": 260000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 161.67419262212977, "num_env_steps_trained_throughput_per_sec": 161.67419262212977, "timesteps_total": 260000, "num_env_steps_sampled_lifetime": 260000, "num_agent_steps_sampled_lifetime": 1040000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1040000, "timers": {"training_iteration_time_ms": 26713.377, "restore_workers_time_ms": 0.02, "training_step_time_ms": 26713.307, "sample_time_ms": 3586.843, "learn_time_ms": 23082.359, "learn_throughput": 173.293, "synch_weights_time_ms": 36.943}, "counters": {"num_env_steps_sampled": 260000, "num_env_steps_trained": 260000, "num_agent_steps_sampled": 1040000, "num_agent_steps_trained": 1040000}, "done": false, "training_iteration": 65, "trial_id": "75ec3_00000", "date": "2024-08-13_02-51-36", "timestamp": 1723531896, "time_this_iter_s": 24.79526400566101, "time_total_s": 5550.51541018486, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b206b310>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 5550.51541018486, "iterations_since_restore": 65, "perf": {"cpu_util_percent": 87.20857142857142, "ram_util_percent": 83.39714285714285}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.673113316849426, "cur_kl_coeff": 0.09010162353515624, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.079107650625643, "policy_loss": -0.005229538951621012, "vf_loss": 8.083232366218768, "vf_explained_var": 0.4205189625737528, "kl": 0.01226197738796173, "entropy": 1.2063714806364958, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 123795.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.15981016301367648, "cur_kl_coeff": 4.656612873077393e-11, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.1379476116679451, "policy_loss": -5.849098624099815e-05, "vf_loss": 0.1380061023257286, "vf_explained_var": -0.07875115332149324, "kl": 0.0007760103711505565, "entropy": 0.2783642158306465, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 123795.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 264000, "num_env_steps_trained": 264000, "num_agent_steps_sampled": 1056000, "num_agent_steps_trained": 1056000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -66.70000000000027, "episode_reward_mean": 209.82199999999975, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -164.80000000000018, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 97.0}, "policy_reward_mean": {"prey_policy": 101.41099999999994, "predator_policy": 3.5}, "custom_metrics": {}, "hist_stats": {"episode_reward": [348.0, 121.69999999999865, 89.49999999999896, 186.1999999999996, 104.79999999999863, 36.70000000000025, 107.59999999999965, 342.4, 108.69999999999976, 207.79999999999936, 90.79999999999941, 176.49999999999952, 214.59999999999914, 38.9000000000003, 115.59999999999923, 171.3999999999995, 269.4999999999999, 112.89999999999961, 217.99999999999926, 179.49999999999923, 315.20000000000033, 249.49999999999935, 81.69999999999942, 162.39999999999924, 228.09999999999897, 165.79999999999893, 209.1999999999993, 251.49999999999912, 125.09999999999917, 219.09999999999928, 291.9999999999998, 270.89999999999975, 296.50000000000045, 277.5999999999994, 218.19999999999902, 70.59999999999992, 233.79999999999944, 51.70000000000037, 320.0000000000007, 189.39999999999907, 129.09999999999985, 339.70000000000016, 149.59999999999954, 285.8000000000002, 136.2999999999986, 378.8000000000001, 260.6999999999997, 274.89999999999964, 276.50000000000017, 81.70000000000007, 274.90000000000117, 58.00000000000027, 120.09999999999985, 142.19999999999985, 279.29999999999995, 353.3, 54.90000000000042, 382.9, 106.59999999999991, 165.99999999999892, 374.8000000000003, 164.39999999999907, 274.2000000000003, 193.99999999999918, 46.80000000000009, 257.79999999999995, 198.6999999999995, 255.89999999999947, 93.10000000000018, -66.70000000000027, 190.39999999999938, 282.4999999999999, 97.19999999999995, 106.3999999999998, 319.8000000000003, 346.90000000000003, 271.19999999999976, 267.69999999999976, 95.49999999999984, 130.8999999999997, 217.6999999999996, 342.40000000000066, 199.8999999999992, 334.2999999999997, 341.70000000000005, 234.39999999999938, 387.4, 128.89999999999958, 313.2, 237.09999999999943, 254.19999999999948, 177.7000000000001, 208.89999999999944, 176.99999999999946, 314.20000000000164, 347.80000000000086, 148.89999999999984, 400.0, 239.29999999999953, 355.00000000000097], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [163.1, 167.9, 97.39999999999937, 23.300000000000086, 69.50000000000014, 20.000000000000014, 42.200000000000074, 137.0, 53.30000000000023, 51.500000000000234, 20.000000000000014, 13.699999999999964, -7.299999999999898, 101.89999999999989, 160.4, 173.0, 56.000000000000036, 49.70000000000022, 24.500000000000032, 176.3, 5.299999999999967, 78.4999999999998, 20.000000000000014, 150.5, 188.29999999999993, 26.30000000000013, 20.000000000000014, 17.899999999999977, 20.000000000000014, 95.59999999999971, 129.8, 32.60000000000023, 105.49999999999994, 164.0, 20.000000000000014, 92.89999999999998, 197.0, 20.000000000000014, 142.4, 28.100000000000037, 145.4, 144.79999999999993, 192.79999999999995, 37.70000000000016, 20.000000000000014, 58.70000000000007, 20.000000000000014, 142.39999999999984, 121.69999999999955, 106.39999999999941, 20.000000000000014, 144.79999999999967, 20.000000000000014, 189.2, 91.99999999999937, 159.49999999999974, 20.000000000000014, 94.10000000000008, 195.5, 23.60000000000001, 99.19999999999999, 192.8, 194.0, 74.89999999999954, 170.29999999999987, 126.19999999999999, 145.10000000000005, 132.4999999999996, 133.3999999999997, 84.79999999999936, 24.500000000000096, 46.10000000000017, 37.09999999999997, 193.7, 31.700000000000166, 20.000000000000014, 176.0, 133.99999999999983, 20.000000000000014, 169.39999999999984, 102.80000000000007, 26.300000000000118, 182.0, 157.69999999999976, 117.79999999999988, 30.799999999999997, 80.00000000000009, 174.7999999999999, 72.20000000000016, 64.10000000000021, 199.1, 172.69999999999996, 119.89999999999955, 123.79999999999997, 197.29999999999998, 77.59999999999998, 91.69999999999942, 183.79999999999998, 20.000000000000014, 58.69999999999998, 103.69999999999948, 171.19999999999982, 20.000000000000014, 38.00000000000008, 82.1, 38.000000000000206, 103.69999999999999, 6.500000000000068, 106.3999999999997, 158.9, 157.4, 182.9, 31.100000000000207, 21.800000000000043, 189.2, 193.69999999999996, 86.59999999999997, 20.000000000000014, 145.99999999999977, 20.000000000000014, 200.0, 174.79999999999995, 136.39999999999975, 20.000000000000014, 88.99999999999982, 177.2, 22.70000000000001, 167.29999999999987, -3.0999999999999757, 38.899999999999984, 92.89999999999996, 164.90000000000003, 74.89999999999996, 102.80000000000003, 32.90000000000014, 200.0, 58.7000000000001, 34.400000000000055, 1.099999999999983, -164.80000000000018, 174.79999999999998, 11.599999999999968, 75.4999999999994, 200.0, 40.69999999999998, 54.50000000000007, 0.800000000000017, 95.59999999999997, 139.99999999999997, 165.8, 169.39999999999992, 177.5, 168.49999999999983, 73.7000000000001, 89.29999999999997, 178.39999999999998, 20.000000000000014, 69.5, 140.59999999999982, -36.699999999999754, 80.30000000000013, 100.4, 146.89999999999986, 195.49999999999997, 186.49999999999991, 7.399999999999968, 185.6, 148.70000000000007, 130.70000000000002, 194.0, 37.10000000000014, 197.3, 197.3, 190.1, 9.499999999999964, 100.39999999999993, 106.70000000000006, 195.49999999999997, 169.39999999999998, 67.70000000000019, 200.0, 54.19999999999996, 92.00000000000004, 85.69999999999997, -16.59999999999981, 195.5, 4.099999999999966, 164.9, 159.79999999999978, 148.3999999999998, 191.0, 156.79999999999978, 37.09999999999999, 111.79999999999998, 200.0, 200.0, 54.19999999999997, 178.1, 200.0, 154.99999999999977], "policy_predator_policy_reward": [0.0, 17.0, 1.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 3.0, 0.0, 0.0, 13.0, 0.0, 9.0, 0.0, 3.0, 0.0, 7.0, 7.0, 0.0, 6.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 9.0, 11.0, 14.0, 0.0, 19.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 9.0, 22.0, 0.0, 0.0, 0.0, 7.0, 17.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 32.0, 0.0, 14.0, 0.0, 13.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 8.0, 0.0, 4.0, 0.0, 0.0, 11.0, 0.0, 0.0, 7.0, 14.0, 3.0, 20.0, 0.0, 0.0, 97.0, 0.0, 4.0, 0.0, 0.0, 7.0, 0.0, 2.0, 10.0, 0.0, 0.0, 14.0, 0.0, 0.0, 16.0, 13.0, 0.0, 0.0, 0.0, 6.0, 0.0, 27.0, 8.0, 29.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 17.0, 0.0, 0.0, 0.0, 0.0, 0.0, 19.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 8.0, 8.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 17.48135796722213, "mean_inference_ms": 37.840110426781095, "mean_action_processing_ms": 8.65694048991492, "mean_env_wait_ms": 11.717071500122307, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00794529914855957, "StateBufferConnector_ms": 0.006559491157531738, "ViewRequirementAgentConnector_ms": 0.33428120613098145}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -66.70000000000027, "episode_return_mean": 209.82199999999975, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1056000, "num_agent_steps_trained": 1056000, "num_env_steps_sampled": 264000, "num_env_steps_trained": 264000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 165.9649937375904, "num_env_steps_trained_throughput_per_sec": 165.9649937375904, "timesteps_total": 264000, "num_env_steps_sampled_lifetime": 264000, "num_agent_steps_sampled_lifetime": 1056000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1056000, "timers": {"training_iteration_time_ms": 26322.882, "restore_workers_time_ms": 0.022, "training_step_time_ms": 26322.81, "sample_time_ms": 3688.781, "learn_time_ms": 22582.363, "learn_throughput": 177.129, "synch_weights_time_ms": 45.556}, "counters": {"num_env_steps_sampled": 264000, "num_env_steps_trained": 264000, "num_agent_steps_sampled": 1056000, "num_agent_steps_trained": 1056000}, "done": false, "training_iteration": 66, "trial_id": "75ec3_00000", "date": "2024-08-13_02-52-00", "timestamp": 1723531920, "time_this_iter_s": 24.16914701461792, "time_total_s": 5574.684557199478, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b205cdc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 5574.684557199478, "iterations_since_restore": 66, "perf": {"cpu_util_percent": 85.6441176470588, "ram_util_percent": 83.50588235294119}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 6.374181249785045, "cur_kl_coeff": 0.09010162353515624, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.743826786929337, "policy_loss": -0.003848927888881277, "vf_loss": 7.74678928284418, "vf_explained_var": 0.40677062875379333, "kl": 0.009838366266758634, "entropy": 1.228392002443788, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 125685.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.24679026905910442, "cur_kl_coeff": 2.3283064365386964e-11, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.1739052874041061, "policy_loss": -0.0003726099509371336, "vf_loss": 0.1742778973568141, "vf_explained_var": -0.012337478790333662, "kl": 0.0019740715005889128, "entropy": 0.29275261638341127, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 125685.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 268000, "num_env_steps_trained": 268000, "num_agent_steps_sampled": 1072000, "num_agent_steps_trained": 1072000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -66.70000000000027, "episode_reward_mean": 221.8899999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -164.80000000000018, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 97.0}, "policy_reward_mean": {"prey_policy": 107.44999999999996, "predator_policy": 3.495}, "custom_metrics": {}, "hist_stats": {"episode_reward": [81.69999999999942, 162.39999999999924, 228.09999999999897, 165.79999999999893, 209.1999999999993, 251.49999999999912, 125.09999999999917, 219.09999999999928, 291.9999999999998, 270.89999999999975, 296.50000000000045, 277.5999999999994, 218.19999999999902, 70.59999999999992, 233.79999999999944, 51.70000000000037, 320.0000000000007, 189.39999999999907, 129.09999999999985, 339.70000000000016, 149.59999999999954, 285.8000000000002, 136.2999999999986, 378.8000000000001, 260.6999999999997, 274.89999999999964, 276.50000000000017, 81.70000000000007, 274.90000000000117, 58.00000000000027, 120.09999999999985, 142.19999999999985, 279.29999999999995, 353.3, 54.90000000000042, 382.9, 106.59999999999991, 165.99999999999892, 374.8000000000003, 164.39999999999907, 274.2000000000003, 193.99999999999918, 46.80000000000009, 257.79999999999995, 198.6999999999995, 255.89999999999947, 93.10000000000018, -66.70000000000027, 190.39999999999938, 282.4999999999999, 97.19999999999995, 106.3999999999998, 319.8000000000003, 346.90000000000003, 271.19999999999976, 267.69999999999976, 95.49999999999984, 130.8999999999997, 217.6999999999996, 342.40000000000066, 199.8999999999992, 334.2999999999997, 341.70000000000005, 234.39999999999938, 387.4, 128.89999999999958, 313.2, 237.09999999999943, 254.19999999999948, 177.7000000000001, 208.89999999999944, 176.99999999999946, 314.20000000000164, 347.80000000000086, 148.89999999999984, 400.0, 239.29999999999953, 355.00000000000097, 206.49999999999932, 306.39999999999986, 347.79999999999984, 327.79999999999995, 49.90000000000042, 254.49999999999923, 138.0999999999997, 68.30000000000005, 347.8000000000004, 237.79999999999959, 273.99999999999966, 45.40000000000029, 36.40000000000025, 177.19999999999942, 287.6999999999994, 299.8999999999997, 297.9999999999997, 279.89999999999964, 179.499999999999, 204.79999999999936, 337.5999999999998, 307.3000000000005], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 58.70000000000007, 20.000000000000014, 142.39999999999984, 121.69999999999955, 106.39999999999941, 20.000000000000014, 144.79999999999967, 20.000000000000014, 189.2, 91.99999999999937, 159.49999999999974, 20.000000000000014, 94.10000000000008, 195.5, 23.60000000000001, 99.19999999999999, 192.8, 194.0, 74.89999999999954, 170.29999999999987, 126.19999999999999, 145.10000000000005, 132.4999999999996, 133.3999999999997, 84.79999999999936, 24.500000000000096, 46.10000000000017, 37.09999999999997, 193.7, 31.700000000000166, 20.000000000000014, 176.0, 133.99999999999983, 20.000000000000014, 169.39999999999984, 102.80000000000007, 26.300000000000118, 182.0, 157.69999999999976, 117.79999999999988, 30.799999999999997, 80.00000000000009, 174.7999999999999, 72.20000000000016, 64.10000000000021, 199.1, 172.69999999999996, 119.89999999999955, 123.79999999999997, 197.29999999999998, 77.59999999999998, 91.69999999999942, 183.79999999999998, 20.000000000000014, 58.69999999999998, 103.69999999999948, 171.19999999999982, 20.000000000000014, 38.00000000000008, 82.1, 38.000000000000206, 103.69999999999999, 6.500000000000068, 106.3999999999997, 158.9, 157.4, 182.9, 31.100000000000207, 21.800000000000043, 189.2, 193.69999999999996, 86.59999999999997, 20.000000000000014, 145.99999999999977, 20.000000000000014, 200.0, 174.79999999999995, 136.39999999999975, 20.000000000000014, 88.99999999999982, 177.2, 22.70000000000001, 167.29999999999987, -3.0999999999999757, 38.899999999999984, 92.89999999999996, 164.90000000000003, 74.89999999999996, 102.80000000000003, 32.90000000000014, 200.0, 58.7000000000001, 34.400000000000055, 1.099999999999983, -164.80000000000018, 174.79999999999998, 11.599999999999968, 75.4999999999994, 200.0, 40.69999999999998, 54.50000000000007, 0.800000000000017, 95.59999999999997, 139.99999999999997, 165.8, 169.39999999999992, 177.5, 168.49999999999983, 73.7000000000001, 89.29999999999997, 178.39999999999998, 20.000000000000014, 69.5, 140.59999999999982, -36.699999999999754, 80.30000000000013, 100.4, 146.89999999999986, 195.49999999999997, 186.49999999999991, 7.399999999999968, 185.6, 148.70000000000007, 130.70000000000002, 194.0, 37.10000000000014, 197.3, 197.3, 190.1, 9.499999999999964, 100.39999999999993, 106.70000000000006, 195.49999999999997, 169.39999999999998, 67.70000000000019, 200.0, 54.19999999999996, 92.00000000000004, 85.69999999999997, -16.59999999999981, 195.5, 4.099999999999966, 164.9, 159.79999999999978, 148.3999999999998, 191.0, 156.79999999999978, 37.09999999999999, 111.79999999999998, 200.0, 200.0, 54.19999999999997, 178.1, 200.0, 154.99999999999977, 186.5, 20.000000000000014, 198.2, 108.19999999999996, 164.00000000000003, 183.7999999999999, 167.9, 146.9, 29.90000000000018, 20.000000000000014, 128.89999999999955, 113.59999999999994, 118.09999999999998, 20.000000000000014, 47.60000000000002, -1.2999999999998728, 179.2999999999999, 168.5, 57.80000000000003, 170.0, 162.2, 102.79999999999998, 25.400000000000006, 20.000000000000014, 26.300000000000118, 1.0999999999999865, 138.20000000000002, 20.000000000000014, 193.7, 86.00000000000014, 167.59999999999997, 122.29999999999976, 107.00000000000006, 179.0, 83.89999999999998, 194.0, 126.19999999999953, 53.29999999999996, 145.70000000000002, 55.10000000000014, 185.59999999999997, 145.99999999999986, 133.39999999999986, 173.89999999999986], "policy_predator_policy_reward": [3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 9.0, 22.0, 0.0, 0.0, 0.0, 7.0, 17.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 32.0, 0.0, 14.0, 0.0, 13.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 8.0, 0.0, 4.0, 0.0, 0.0, 11.0, 0.0, 0.0, 7.0, 14.0, 3.0, 20.0, 0.0, 0.0, 97.0, 0.0, 4.0, 0.0, 0.0, 7.0, 0.0, 2.0, 10.0, 0.0, 0.0, 14.0, 0.0, 0.0, 16.0, 13.0, 0.0, 0.0, 0.0, 6.0, 0.0, 27.0, 8.0, 29.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 17.0, 0.0, 0.0, 0.0, 0.0, 0.0, 19.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 8.0, 8.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 8.0, 0.0, 0.0, 12.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 10.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 9.0, 2.0, 17.0, 8.0, 0.0, 0.0, 10.0, 0.0, 12.0, 2.0, 0.0, 0.0, 0.0, 4.0, 0.0, 6.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 17.582966949430357, "mean_inference_ms": 37.26364492204456, "mean_action_processing_ms": 8.209370267025996, "mean_env_wait_ms": 11.537466022034193, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.008241653442382812, "StateBufferConnector_ms": 0.006606459617614746, "ViewRequirementAgentConnector_ms": 0.37362754344940186}, "num_episodes": 22, "episode_return_max": 400.0, "episode_return_min": -66.70000000000027, "episode_return_mean": 221.8899999999998, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1072000, "num_agent_steps_trained": 1072000, "num_env_steps_sampled": 268000, "num_env_steps_trained": 268000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 160.9712054458054, "num_env_steps_trained_throughput_per_sec": 160.9712054458054, "timesteps_total": 268000, "num_env_steps_sampled_lifetime": 268000, "num_agent_steps_sampled_lifetime": 1072000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1072000, "timers": {"training_iteration_time_ms": 26556.271, "restore_workers_time_ms": 0.024, "training_step_time_ms": 26556.194, "sample_time_ms": 3958.976, "learn_time_ms": 22546.783, "learn_throughput": 177.409, "synch_weights_time_ms": 43.737}, "counters": {"num_env_steps_sampled": 268000, "num_env_steps_trained": 268000, "num_agent_steps_sampled": 1072000, "num_agent_steps_trained": 1072000}, "done": false, "training_iteration": 67, "trial_id": "75ec3_00000", "date": "2024-08-13_02-52-25", "timestamp": 1723531945, "time_this_iter_s": 24.91695284843445, "time_total_s": 5599.601510047913, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b205c160>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 5599.601510047913, "iterations_since_restore": 67, "perf": {"cpu_util_percent": 85.16000000000001, "ram_util_percent": 83.48571428571427}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 6.869723867786624, "cur_kl_coeff": 0.09010162353515624, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.045496167329253, "policy_loss": -0.0028234185053469247, "vf_loss": 8.047326197699896, "vf_explained_var": 0.4286544957488933, "kl": 0.011025265522159239, "entropy": 1.1734311330255378, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 127575.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.291691062319531, "cur_kl_coeff": 1.1641532182693482e-11, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.3018037041343709, "policy_loss": -0.0014695903951568263, "vf_loss": 0.3032732945356565, "vf_explained_var": -0.01123499245870681, "kl": 0.0027766740134763344, "entropy": 0.2671132250201134, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 127575.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 272000, "num_env_steps_trained": 272000, "num_agent_steps_sampled": 1088000, "num_agent_steps_trained": 1088000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -66.70000000000027, "episode_reward_mean": 227.1149999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -164.80000000000018, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 97.0}, "policy_reward_mean": {"prey_policy": 109.64749999999997, "predator_policy": 3.91}, "custom_metrics": {}, "hist_stats": {"episode_reward": [129.09999999999985, 339.70000000000016, 149.59999999999954, 285.8000000000002, 136.2999999999986, 378.8000000000001, 260.6999999999997, 274.89999999999964, 276.50000000000017, 81.70000000000007, 274.90000000000117, 58.00000000000027, 120.09999999999985, 142.19999999999985, 279.29999999999995, 353.3, 54.90000000000042, 382.9, 106.59999999999991, 165.99999999999892, 374.8000000000003, 164.39999999999907, 274.2000000000003, 193.99999999999918, 46.80000000000009, 257.79999999999995, 198.6999999999995, 255.89999999999947, 93.10000000000018, -66.70000000000027, 190.39999999999938, 282.4999999999999, 97.19999999999995, 106.3999999999998, 319.8000000000003, 346.90000000000003, 271.19999999999976, 267.69999999999976, 95.49999999999984, 130.8999999999997, 217.6999999999996, 342.40000000000066, 199.8999999999992, 334.2999999999997, 341.70000000000005, 234.39999999999938, 387.4, 128.89999999999958, 313.2, 237.09999999999943, 254.19999999999948, 177.7000000000001, 208.89999999999944, 176.99999999999946, 314.20000000000164, 347.80000000000086, 148.89999999999984, 400.0, 239.29999999999953, 355.00000000000097, 206.49999999999932, 306.39999999999986, 347.79999999999984, 327.79999999999995, 49.90000000000042, 254.49999999999923, 138.0999999999997, 68.30000000000005, 347.8000000000004, 237.79999999999959, 273.99999999999966, 45.40000000000029, 36.40000000000025, 177.19999999999942, 287.6999999999994, 299.8999999999997, 297.9999999999997, 279.89999999999964, 179.499999999999, 204.79999999999936, 337.5999999999998, 307.3000000000005, 283.8999999999998, 304.5999999999998, 175.8999999999998, 233.49999999999955, 114.79999999999984, 278.20000000000016, 194.2999999999994, 341.0000000000003, 265.8999999999994, 348.70000000000005, 254.19999999999953, 287.5000000000001, 141.69999999999936, 37.80000000000027, 115.59999999999985, 323.5000000000013, 363.10000000000014, 121.89999999999952], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [102.80000000000007, 26.300000000000118, 182.0, 157.69999999999976, 117.79999999999988, 30.799999999999997, 80.00000000000009, 174.7999999999999, 72.20000000000016, 64.10000000000021, 199.1, 172.69999999999996, 119.89999999999955, 123.79999999999997, 197.29999999999998, 77.59999999999998, 91.69999999999942, 183.79999999999998, 20.000000000000014, 58.69999999999998, 103.69999999999948, 171.19999999999982, 20.000000000000014, 38.00000000000008, 82.1, 38.000000000000206, 103.69999999999999, 6.500000000000068, 106.3999999999997, 158.9, 157.4, 182.9, 31.100000000000207, 21.800000000000043, 189.2, 193.69999999999996, 86.59999999999997, 20.000000000000014, 145.99999999999977, 20.000000000000014, 200.0, 174.79999999999995, 136.39999999999975, 20.000000000000014, 88.99999999999982, 177.2, 22.70000000000001, 167.29999999999987, -3.0999999999999757, 38.899999999999984, 92.89999999999996, 164.90000000000003, 74.89999999999996, 102.80000000000003, 32.90000000000014, 200.0, 58.7000000000001, 34.400000000000055, 1.099999999999983, -164.80000000000018, 174.79999999999998, 11.599999999999968, 75.4999999999994, 200.0, 40.69999999999998, 54.50000000000007, 0.800000000000017, 95.59999999999997, 139.99999999999997, 165.8, 169.39999999999992, 177.5, 168.49999999999983, 73.7000000000001, 89.29999999999997, 178.39999999999998, 20.000000000000014, 69.5, 140.59999999999982, -36.699999999999754, 80.30000000000013, 100.4, 146.89999999999986, 195.49999999999997, 186.49999999999991, 7.399999999999968, 185.6, 148.70000000000007, 130.70000000000002, 194.0, 37.10000000000014, 197.3, 197.3, 190.1, 9.499999999999964, 100.39999999999993, 106.70000000000006, 195.49999999999997, 169.39999999999998, 67.70000000000019, 200.0, 54.19999999999996, 92.00000000000004, 85.69999999999997, -16.59999999999981, 195.5, 4.099999999999966, 164.9, 159.79999999999978, 148.3999999999998, 191.0, 156.79999999999978, 37.09999999999999, 111.79999999999998, 200.0, 200.0, 54.19999999999997, 178.1, 200.0, 154.99999999999977, 186.5, 20.000000000000014, 198.2, 108.19999999999996, 164.00000000000003, 183.7999999999999, 167.9, 146.9, 29.90000000000018, 20.000000000000014, 128.89999999999955, 113.59999999999994, 118.09999999999998, 20.000000000000014, 47.60000000000002, -1.2999999999998728, 179.2999999999999, 168.5, 57.80000000000003, 170.0, 162.2, 102.79999999999998, 25.400000000000006, 20.000000000000014, 26.300000000000118, 1.0999999999999865, 138.20000000000002, 20.000000000000014, 193.7, 86.00000000000014, 167.59999999999997, 122.29999999999976, 107.00000000000006, 179.0, 83.89999999999998, 194.0, 126.19999999999953, 53.29999999999996, 145.70000000000002, 55.10000000000014, 185.59999999999997, 145.99999999999986, 133.39999999999986, 173.89999999999986, 92.89999999999998, 190.99999999999994, 143.29999999999978, 161.29999999999987, 121.69999999999999, 54.200000000000195, 175.7, 57.800000000000104, -127.00000000000017, 165.8, 160.39999999999998, 111.79999999999956, 170.0, 11.29999999999997, 161.3, 172.6999999999999, 71.30000000000013, 194.59999999999997, 151.4, 197.3, 84.79999999999998, 169.39999999999986, 87.49999999999942, 200.0, 98.29999999999997, 43.39999999999998, 15.799999999999963, 20.000000000000014, 20.900000000000013, 94.69999999999997, 123.49999999999959, 200.0, 200.0, 163.1, 92.90000000000003, 20.000000000000014], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 9.0, 22.0, 0.0, 0.0, 0.0, 7.0, 17.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 32.0, 0.0, 14.0, 0.0, 13.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 8.0, 0.0, 4.0, 0.0, 0.0, 11.0, 0.0, 0.0, 7.0, 14.0, 3.0, 20.0, 0.0, 0.0, 97.0, 0.0, 4.0, 0.0, 0.0, 7.0, 0.0, 2.0, 10.0, 0.0, 0.0, 14.0, 0.0, 0.0, 16.0, 13.0, 0.0, 0.0, 0.0, 6.0, 0.0, 27.0, 8.0, 29.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 17.0, 0.0, 0.0, 0.0, 0.0, 0.0, 19.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 8.0, 8.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 8.0, 0.0, 0.0, 12.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 10.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 9.0, 2.0, 17.0, 8.0, 0.0, 0.0, 10.0, 0.0, 12.0, 2.0, 0.0, 0.0, 0.0, 4.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 76.0, 0.0, 6.0, 0.0, 0.0, 13.0, 4.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 17.018426637598846, "mean_inference_ms": 36.90298469006008, "mean_action_processing_ms": 8.44294134286588, "mean_env_wait_ms": 11.355328682005103, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00881969928741455, "StateBufferConnector_ms": 0.007168412208557129, "ViewRequirementAgentConnector_ms": 0.41801273822784424}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -66.70000000000027, "episode_return_mean": 227.1149999999998, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1088000, "num_agent_steps_trained": 1088000, "num_env_steps_sampled": 272000, "num_env_steps_trained": 272000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 150.64518670132512, "num_env_steps_trained_throughput_per_sec": 150.64518670132512, "timesteps_total": 272000, "num_env_steps_sampled_lifetime": 272000, "num_agent_steps_sampled_lifetime": 1088000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1088000, "timers": {"training_iteration_time_ms": 26357.229, "restore_workers_time_ms": 0.023, "training_step_time_ms": 26357.151, "sample_time_ms": 4087.03, "learn_time_ms": 22217.985, "learn_throughput": 180.034, "synch_weights_time_ms": 43.776}, "counters": {"num_env_steps_sampled": 272000, "num_env_steps_trained": 272000, "num_agent_steps_sampled": 1088000, "num_agent_steps_trained": 1088000}, "done": false, "training_iteration": 68, "trial_id": "75ec3_00000", "date": "2024-08-13_02-52-52", "timestamp": 1723531972, "time_this_iter_s": 26.62205696105957, "time_total_s": 5626.223567008972, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b1bb5ca0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 5626.223567008972, "iterations_since_restore": 68, "perf": {"cpu_util_percent": 87.25526315789475, "ram_util_percent": 83.33157894736841}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 10.120970364758577, "cur_kl_coeff": 0.09010162353515624, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.517286129351016, "policy_loss": -0.0024879143134784445, "vf_loss": 7.519403306517021, "vf_explained_var": 0.4490476045974348, "kl": 0.004114607336224479, "entropy": 1.224013021572557, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 129465.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.19140330484265058, "cur_kl_coeff": 5.820766091346741e-12, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.20359779912091436, "policy_loss": 0.0001574109451322959, "vf_loss": 0.2034403872496335, "vf_explained_var": 0.017289796298143093, "kl": 0.0008746324768117808, "entropy": 0.24539469490764002, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 129465.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 276000, "num_env_steps_trained": 276000, "num_agent_steps_sampled": 1104000, "num_agent_steps_trained": 1104000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -66.70000000000027, "episode_reward_mean": 231.47899999999984, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -164.80000000000018, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 97.0}, "policy_reward_mean": {"prey_policy": 112.02949999999997, "predator_policy": 3.71}, "custom_metrics": {}, "hist_stats": {"episode_reward": [193.99999999999918, 46.80000000000009, 257.79999999999995, 198.6999999999995, 255.89999999999947, 93.10000000000018, -66.70000000000027, 190.39999999999938, 282.4999999999999, 97.19999999999995, 106.3999999999998, 319.8000000000003, 346.90000000000003, 271.19999999999976, 267.69999999999976, 95.49999999999984, 130.8999999999997, 217.6999999999996, 342.40000000000066, 199.8999999999992, 334.2999999999997, 341.70000000000005, 234.39999999999938, 387.4, 128.89999999999958, 313.2, 237.09999999999943, 254.19999999999948, 177.7000000000001, 208.89999999999944, 176.99999999999946, 314.20000000000164, 347.80000000000086, 148.89999999999984, 400.0, 239.29999999999953, 355.00000000000097, 206.49999999999932, 306.39999999999986, 347.79999999999984, 327.79999999999995, 49.90000000000042, 254.49999999999923, 138.0999999999997, 68.30000000000005, 347.8000000000004, 237.79999999999959, 273.99999999999966, 45.40000000000029, 36.40000000000025, 177.19999999999942, 287.6999999999994, 299.8999999999997, 297.9999999999997, 279.89999999999964, 179.499999999999, 204.79999999999936, 337.5999999999998, 307.3000000000005, 283.8999999999998, 304.5999999999998, 175.8999999999998, 233.49999999999955, 114.79999999999984, 278.20000000000016, 194.2999999999994, 341.0000000000003, 265.8999999999994, 348.70000000000005, 254.19999999999953, 287.5000000000001, 141.69999999999936, 37.80000000000027, 115.59999999999985, 323.5000000000013, 363.10000000000014, 121.89999999999952, 239.79999999999905, 176.20000000000024, 246.09999999999943, 264.09999999999997, 218.19999999999925, 189.6999999999994, 303.49999999999966, 205.5999999999993, 345.10000000000053, 284.0999999999998, 220.49999999999932, 257.89999999999924, 354.0000000000003, 26.000000000000085, 374.7, 229.89999999999935, 273.19999999999993, 394.6, 40.0000000000003, 224.49999999999923, 301.9, 37.700000000000195, 293.80000000000007], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [22.70000000000001, 167.29999999999987, -3.0999999999999757, 38.899999999999984, 92.89999999999996, 164.90000000000003, 74.89999999999996, 102.80000000000003, 32.90000000000014, 200.0, 58.7000000000001, 34.400000000000055, 1.099999999999983, -164.80000000000018, 174.79999999999998, 11.599999999999968, 75.4999999999994, 200.0, 40.69999999999998, 54.50000000000007, 0.800000000000017, 95.59999999999997, 139.99999999999997, 165.8, 169.39999999999992, 177.5, 168.49999999999983, 73.7000000000001, 89.29999999999997, 178.39999999999998, 20.000000000000014, 69.5, 140.59999999999982, -36.699999999999754, 80.30000000000013, 100.4, 146.89999999999986, 195.49999999999997, 186.49999999999991, 7.399999999999968, 185.6, 148.70000000000007, 130.70000000000002, 194.0, 37.10000000000014, 197.3, 197.3, 190.1, 9.499999999999964, 100.39999999999993, 106.70000000000006, 195.49999999999997, 169.39999999999998, 67.70000000000019, 200.0, 54.19999999999996, 92.00000000000004, 85.69999999999997, -16.59999999999981, 195.5, 4.099999999999966, 164.9, 159.79999999999978, 148.3999999999998, 191.0, 156.79999999999978, 37.09999999999999, 111.79999999999998, 200.0, 200.0, 54.19999999999997, 178.1, 200.0, 154.99999999999977, 186.5, 20.000000000000014, 198.2, 108.19999999999996, 164.00000000000003, 183.7999999999999, 167.9, 146.9, 29.90000000000018, 20.000000000000014, 128.89999999999955, 113.59999999999994, 118.09999999999998, 20.000000000000014, 47.60000000000002, -1.2999999999998728, 179.2999999999999, 168.5, 57.80000000000003, 170.0, 162.2, 102.79999999999998, 25.400000000000006, 20.000000000000014, 26.300000000000118, 1.0999999999999865, 138.20000000000002, 20.000000000000014, 193.7, 86.00000000000014, 167.59999999999997, 122.29999999999976, 107.00000000000006, 179.0, 83.89999999999998, 194.0, 126.19999999999953, 53.29999999999996, 145.70000000000002, 55.10000000000014, 185.59999999999997, 145.99999999999986, 133.39999999999986, 173.89999999999986, 92.89999999999998, 190.99999999999994, 143.29999999999978, 161.29999999999987, 121.69999999999999, 54.200000000000195, 175.7, 57.800000000000104, -127.00000000000017, 165.8, 160.39999999999998, 111.79999999999956, 170.0, 11.29999999999997, 161.3, 172.6999999999999, 71.30000000000013, 194.59999999999997, 151.4, 197.3, 84.79999999999998, 169.39999999999986, 87.49999999999942, 200.0, 98.29999999999997, 43.39999999999998, 15.799999999999963, 20.000000000000014, 20.900000000000013, 94.69999999999997, 123.49999999999959, 200.0, 200.0, 163.1, 92.90000000000003, 20.000000000000014, 136.99999999999991, 102.80000000000014, 69.49999999999997, 97.70000000000013, 46.09999999999997, 200.0, 123.49999999999999, 140.59999999999997, 20.000000000000014, 198.2, -3.3999999999999653, 181.1, 168.2, 125.30000000000007, 182.9, 22.70000000000006, 165.7999999999998, 179.3, 175.7, 100.39999999999986, 22.10000000000007, 196.4, 197.3, 56.60000000000021, 168.79999999999993, 180.20000000000005, -2.799999999999986, 15.799999999999962, 169.7, 200.0, 143.3, 86.59999999999931, 96.20000000000003, 164.00000000000003, 194.6, 200.0, 20.000000000000014, 20.000000000000014, 180.19999999999987, 44.30000000000002, 179.3, 122.6, 20.000000000000014, 10.69999999999997, 176.6, 108.20000000000002], "policy_predator_policy_reward": [4.0, 0.0, 0.0, 11.0, 0.0, 0.0, 7.0, 14.0, 3.0, 20.0, 0.0, 0.0, 97.0, 0.0, 4.0, 0.0, 0.0, 7.0, 0.0, 2.0, 10.0, 0.0, 0.0, 14.0, 0.0, 0.0, 16.0, 13.0, 0.0, 0.0, 0.0, 6.0, 0.0, 27.0, 8.0, 29.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 17.0, 0.0, 0.0, 0.0, 0.0, 0.0, 19.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 8.0, 8.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 8.0, 0.0, 0.0, 12.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 10.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 9.0, 2.0, 17.0, 8.0, 0.0, 0.0, 10.0, 0.0, 12.0, 2.0, 0.0, 0.0, 0.0, 4.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 76.0, 0.0, 6.0, 0.0, 0.0, 13.0, 4.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 8.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 2.0, 0.0, 4.0, 0.0, 5.0, 0.0, 0.0, 13.0, 0.0, 5.0, 0.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 9.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 16.77774898153074, "mean_inference_ms": 36.35792168904726, "mean_action_processing_ms": 8.294219105707935, "mean_env_wait_ms": 11.214895071733283, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.017572760581970215, "StateBufferConnector_ms": 0.009096264839172363, "ViewRequirementAgentConnector_ms": 0.5106881856918335}, "num_episodes": 23, "episode_return_max": 400.0, "episode_return_min": -66.70000000000027, "episode_return_mean": 231.47899999999984, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1104000, "num_agent_steps_trained": 1104000, "num_env_steps_sampled": 276000, "num_env_steps_trained": 276000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 131.18082166552273, "num_env_steps_trained_throughput_per_sec": 131.18082166552273, "timesteps_total": 276000, "num_env_steps_sampled_lifetime": 276000, "num_agent_steps_sampled_lifetime": 1104000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1104000, "timers": {"training_iteration_time_ms": 26809.602, "restore_workers_time_ms": 0.023, "training_step_time_ms": 26809.523, "sample_time_ms": 4346.935, "learn_time_ms": 22409.719, "learn_throughput": 178.494, "synch_weights_time_ms": 44.666}, "counters": {"num_env_steps_sampled": 276000, "num_env_steps_trained": 276000, "num_agent_steps_sampled": 1104000, "num_agent_steps_trained": 1104000}, "done": false, "training_iteration": 69, "trial_id": "75ec3_00000", "date": "2024-08-13_02-53-22", "timestamp": 1723532002, "time_this_iter_s": 30.56821608543396, "time_total_s": 5656.791783094406, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2084430>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 5656.791783094406, "iterations_since_restore": 69, "perf": {"cpu_util_percent": 88.31162790697675, "ram_util_percent": 83.60000000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 7.193448224774113, "cur_kl_coeff": 0.04505081176757812, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.213345610149323, "policy_loss": -0.004135034348515094, "vf_loss": 8.217070860585208, "vf_explained_var": 0.4200074904179447, "kl": 0.009095914370956457, "entropy": 1.1567632715538065, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 131355.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.3256728317115515, "cur_kl_coeff": 2.9103830456733705e-12, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.32298345453051663, "policy_loss": -0.0002793090321892311, "vf_loss": 0.32326276370104917, "vf_explained_var": 0.0380312996566611, "kl": 0.001213406367902369, "entropy": 0.2555301332915271, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 131355.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 280000, "num_env_steps_trained": 280000, "num_agent_steps_sampled": 1120000, "num_agent_steps_trained": 1120000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": 26.000000000000085, "episode_reward_mean": 248.15299999999985, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -127.00000000000017, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 76.0}, "policy_reward_mean": {"prey_policy": 121.19149999999996, "predator_policy": 2.885}, "custom_metrics": {}, "hist_stats": {"episode_reward": [342.40000000000066, 199.8999999999992, 334.2999999999997, 341.70000000000005, 234.39999999999938, 387.4, 128.89999999999958, 313.2, 237.09999999999943, 254.19999999999948, 177.7000000000001, 208.89999999999944, 176.99999999999946, 314.20000000000164, 347.80000000000086, 148.89999999999984, 400.0, 239.29999999999953, 355.00000000000097, 206.49999999999932, 306.39999999999986, 347.79999999999984, 327.79999999999995, 49.90000000000042, 254.49999999999923, 138.0999999999997, 68.30000000000005, 347.8000000000004, 237.79999999999959, 273.99999999999966, 45.40000000000029, 36.40000000000025, 177.19999999999942, 287.6999999999994, 299.8999999999997, 297.9999999999997, 279.89999999999964, 179.499999999999, 204.79999999999936, 337.5999999999998, 307.3000000000005, 283.8999999999998, 304.5999999999998, 175.8999999999998, 233.49999999999955, 114.79999999999984, 278.20000000000016, 194.2999999999994, 341.0000000000003, 265.8999999999994, 348.70000000000005, 254.19999999999953, 287.5000000000001, 141.69999999999936, 37.80000000000027, 115.59999999999985, 323.5000000000013, 363.10000000000014, 121.89999999999952, 239.79999999999905, 176.20000000000024, 246.09999999999943, 264.09999999999997, 218.19999999999925, 189.6999999999994, 303.49999999999966, 205.5999999999993, 345.10000000000053, 284.0999999999998, 220.49999999999932, 257.89999999999924, 354.0000000000003, 26.000000000000085, 374.7, 229.89999999999935, 273.19999999999993, 394.6, 40.0000000000003, 224.49999999999923, 301.9, 37.700000000000195, 293.80000000000007, 228.09999999999937, 210.9999999999992, 215.9999999999993, 298.30000000000047, 179.2999999999994, 308.3999999999999, 350.10000000000065, 328.7000000000012, 272.1999999999998, 166.1000000000002, 291.6000000000005, 346.0, 363.1000000000007, 205.69999999999928, 320.7999999999997, 300.7999999999997, 257.7999999999995, 329.20000000000005], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [146.89999999999986, 195.49999999999997, 186.49999999999991, 7.399999999999968, 185.6, 148.70000000000007, 130.70000000000002, 194.0, 37.10000000000014, 197.3, 197.3, 190.1, 9.499999999999964, 100.39999999999993, 106.70000000000006, 195.49999999999997, 169.39999999999998, 67.70000000000019, 200.0, 54.19999999999996, 92.00000000000004, 85.69999999999997, -16.59999999999981, 195.5, 4.099999999999966, 164.9, 159.79999999999978, 148.3999999999998, 191.0, 156.79999999999978, 37.09999999999999, 111.79999999999998, 200.0, 200.0, 54.19999999999997, 178.1, 200.0, 154.99999999999977, 186.5, 20.000000000000014, 198.2, 108.19999999999996, 164.00000000000003, 183.7999999999999, 167.9, 146.9, 29.90000000000018, 20.000000000000014, 128.89999999999955, 113.59999999999994, 118.09999999999998, 20.000000000000014, 47.60000000000002, -1.2999999999998728, 179.2999999999999, 168.5, 57.80000000000003, 170.0, 162.2, 102.79999999999998, 25.400000000000006, 20.000000000000014, 26.300000000000118, 1.0999999999999865, 138.20000000000002, 20.000000000000014, 193.7, 86.00000000000014, 167.59999999999997, 122.29999999999976, 107.00000000000006, 179.0, 83.89999999999998, 194.0, 126.19999999999953, 53.29999999999996, 145.70000000000002, 55.10000000000014, 185.59999999999997, 145.99999999999986, 133.39999999999986, 173.89999999999986, 92.89999999999998, 190.99999999999994, 143.29999999999978, 161.29999999999987, 121.69999999999999, 54.200000000000195, 175.7, 57.800000000000104, -127.00000000000017, 165.8, 160.39999999999998, 111.79999999999956, 170.0, 11.29999999999997, 161.3, 172.6999999999999, 71.30000000000013, 194.59999999999997, 151.4, 197.3, 84.79999999999998, 169.39999999999986, 87.49999999999942, 200.0, 98.29999999999997, 43.39999999999998, 15.799999999999963, 20.000000000000014, 20.900000000000013, 94.69999999999997, 123.49999999999959, 200.0, 200.0, 163.1, 92.90000000000003, 20.000000000000014, 136.99999999999991, 102.80000000000014, 69.49999999999997, 97.70000000000013, 46.09999999999997, 200.0, 123.49999999999999, 140.59999999999997, 20.000000000000014, 198.2, -3.3999999999999653, 181.1, 168.2, 125.30000000000007, 182.9, 22.70000000000006, 165.7999999999998, 179.3, 175.7, 100.39999999999986, 22.10000000000007, 196.4, 197.3, 56.60000000000021, 168.79999999999993, 180.20000000000005, -2.799999999999986, 15.799999999999962, 169.7, 200.0, 143.3, 86.59999999999931, 96.20000000000003, 164.00000000000003, 194.6, 200.0, 20.000000000000014, 20.000000000000014, 180.19999999999987, 44.30000000000002, 179.3, 122.6, 20.000000000000014, 10.69999999999997, 176.6, 108.20000000000002, 84.79999999999998, 143.29999999999967, 20.000000000000014, 190.99999999999994, 20.000000000000014, 194.0, 199.1, 99.19999999999936, 170.29999999999995, -0.9999999999999992, 152.29999999999995, 139.09999999999974, 198.2, 140.89999999999986, 189.2, 129.4999999999997, 97.39999999999988, 165.79999999999993, 56.60000000000012, 84.50000000000009, 161.59999999999994, 127.9999999999996, 182.0, 158.0, 172.99999999999983, 190.09999999999997, 157.70000000000002, 44.00000000000016, 199.1, 121.69999999999968, 119.30000000000001, 162.49999999999997, 196.39999999999998, 61.399999999999984, 126.20000000000006, 191.0], "policy_predator_policy_reward": [0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 17.0, 0.0, 0.0, 0.0, 0.0, 0.0, 19.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 8.0, 8.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 8.0, 0.0, 0.0, 12.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 10.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 9.0, 2.0, 17.0, 8.0, 0.0, 0.0, 10.0, 0.0, 12.0, 2.0, 0.0, 0.0, 0.0, 4.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 76.0, 0.0, 6.0, 0.0, 0.0, 13.0, 4.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 8.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 2.0, 0.0, 4.0, 0.0, 5.0, 0.0, 0.0, 13.0, 0.0, 5.0, 0.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 4.0, 6.0, 8.0, 9.0, 0.0, 11.0, 0.0, 10.0, 9.0, 0.0, 0.0, 25.0, 0.0, 2.0, 0.0, 6.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 19.0, 0.0, 0.0, 0.0, 12.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 16.590612152588744, "mean_inference_ms": 35.96899305210779, "mean_action_processing_ms": 8.197683663596615, "mean_env_wait_ms": 11.077822151472493, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.018627405166625977, "StateBufferConnector_ms": 0.01913762092590332, "ViewRequirementAgentConnector_ms": 0.5027291774749756}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": 26.000000000000085, "episode_return_mean": 248.15299999999985, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1120000, "num_agent_steps_trained": 1120000, "num_env_steps_sampled": 280000, "num_env_steps_trained": 280000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 141.25428060757602, "num_env_steps_trained_throughput_per_sec": 141.25428060757602, "timesteps_total": 280000, "num_env_steps_sampled_lifetime": 280000, "num_agent_steps_sampled_lifetime": 1120000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1120000, "timers": {"training_iteration_time_ms": 25976.692, "restore_workers_time_ms": 0.024, "training_step_time_ms": 25976.612, "sample_time_ms": 4601.958, "learn_time_ms": 21321.883, "learn_throughput": 187.601, "synch_weights_time_ms": 44.598}, "counters": {"num_env_steps_sampled": 280000, "num_env_steps_trained": 280000, "num_agent_steps_sampled": 1120000, "num_agent_steps_trained": 1120000}, "done": false, "training_iteration": 70, "trial_id": "75ec3_00000", "date": "2024-08-13_02-53-51", "timestamp": 1723532031, "time_this_iter_s": 28.3675320148468, "time_total_s": 5685.159315109253, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2058d30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 5685.159315109253, "iterations_since_restore": 70, "perf": {"cpu_util_percent": 87.37, "ram_util_percent": 83.5225}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 9.200669712663958, "cur_kl_coeff": 0.04505081176757812, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.938631698568031, "policy_loss": -0.0024710688937120335, "vf_loss": 7.940794122534454, "vf_explained_var": 0.5268630227714619, "kl": 0.0068506941104888724, "entropy": 1.1756955064793744, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 133245.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.18766553382187215, "cur_kl_coeff": 1.4551915228366853e-12, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.19952632836879247, "policy_loss": 9.685429946455376e-05, "vf_loss": 0.19942947428602825, "vf_explained_var": -0.01965199352572204, "kl": 0.0005382393291058625, "entropy": 0.2222125671685688, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 133245.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 284000, "num_env_steps_trained": 284000, "num_agent_steps_sampled": 1136000, "num_agent_steps_trained": 1136000}, "env_runners": {"episode_reward_max": 394.6, "episode_reward_min": 26.000000000000085, "episode_reward_mean": 247.60399999999987, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -127.00000000000017, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 76.0}, "policy_reward_mean": {"prey_policy": 121.08199999999997, "predator_policy": 2.72}, "custom_metrics": {}, "hist_stats": {"episode_reward": [355.00000000000097, 206.49999999999932, 306.39999999999986, 347.79999999999984, 327.79999999999995, 49.90000000000042, 254.49999999999923, 138.0999999999997, 68.30000000000005, 347.8000000000004, 237.79999999999959, 273.99999999999966, 45.40000000000029, 36.40000000000025, 177.19999999999942, 287.6999999999994, 299.8999999999997, 297.9999999999997, 279.89999999999964, 179.499999999999, 204.79999999999936, 337.5999999999998, 307.3000000000005, 283.8999999999998, 304.5999999999998, 175.8999999999998, 233.49999999999955, 114.79999999999984, 278.20000000000016, 194.2999999999994, 341.0000000000003, 265.8999999999994, 348.70000000000005, 254.19999999999953, 287.5000000000001, 141.69999999999936, 37.80000000000027, 115.59999999999985, 323.5000000000013, 363.10000000000014, 121.89999999999952, 239.79999999999905, 176.20000000000024, 246.09999999999943, 264.09999999999997, 218.19999999999925, 189.6999999999994, 303.49999999999966, 205.5999999999993, 345.10000000000053, 284.0999999999998, 220.49999999999932, 257.89999999999924, 354.0000000000003, 26.000000000000085, 374.7, 229.89999999999935, 273.19999999999993, 394.6, 40.0000000000003, 224.49999999999923, 301.9, 37.700000000000195, 293.80000000000007, 228.09999999999937, 210.9999999999992, 215.9999999999993, 298.30000000000047, 179.2999999999994, 308.3999999999999, 350.10000000000065, 328.7000000000012, 272.1999999999998, 166.1000000000002, 291.6000000000005, 346.0, 363.1000000000007, 205.69999999999928, 320.7999999999997, 300.7999999999997, 257.7999999999995, 329.20000000000005, 209.49999999999932, 136.29999999999947, 386.5000000000002, 232.69999999999956, 351.40000000000043, 155.1999999999999, 177.69999999999897, 297.6000000000003, 269.4999999999998, 379.3, 371.5, 138.9999999999999, 364.1000000000001, 227.1999999999993, 185.89999999999944, 103.89999999999992, 389.2, 355.90000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [200.0, 154.99999999999977, 186.5, 20.000000000000014, 198.2, 108.19999999999996, 164.00000000000003, 183.7999999999999, 167.9, 146.9, 29.90000000000018, 20.000000000000014, 128.89999999999955, 113.59999999999994, 118.09999999999998, 20.000000000000014, 47.60000000000002, -1.2999999999998728, 179.2999999999999, 168.5, 57.80000000000003, 170.0, 162.2, 102.79999999999998, 25.400000000000006, 20.000000000000014, 26.300000000000118, 1.0999999999999865, 138.20000000000002, 20.000000000000014, 193.7, 86.00000000000014, 167.59999999999997, 122.29999999999976, 107.00000000000006, 179.0, 83.89999999999998, 194.0, 126.19999999999953, 53.29999999999996, 145.70000000000002, 55.10000000000014, 185.59999999999997, 145.99999999999986, 133.39999999999986, 173.89999999999986, 92.89999999999998, 190.99999999999994, 143.29999999999978, 161.29999999999987, 121.69999999999999, 54.200000000000195, 175.7, 57.800000000000104, -127.00000000000017, 165.8, 160.39999999999998, 111.79999999999956, 170.0, 11.29999999999997, 161.3, 172.6999999999999, 71.30000000000013, 194.59999999999997, 151.4, 197.3, 84.79999999999998, 169.39999999999986, 87.49999999999942, 200.0, 98.29999999999997, 43.39999999999998, 15.799999999999963, 20.000000000000014, 20.900000000000013, 94.69999999999997, 123.49999999999959, 200.0, 200.0, 163.1, 92.90000000000003, 20.000000000000014, 136.99999999999991, 102.80000000000014, 69.49999999999997, 97.70000000000013, 46.09999999999997, 200.0, 123.49999999999999, 140.59999999999997, 20.000000000000014, 198.2, -3.3999999999999653, 181.1, 168.2, 125.30000000000007, 182.9, 22.70000000000006, 165.7999999999998, 179.3, 175.7, 100.39999999999986, 22.10000000000007, 196.4, 197.3, 56.60000000000021, 168.79999999999993, 180.20000000000005, -2.799999999999986, 15.799999999999962, 169.7, 200.0, 143.3, 86.59999999999931, 96.20000000000003, 164.00000000000003, 194.6, 200.0, 20.000000000000014, 20.000000000000014, 180.19999999999987, 44.30000000000002, 179.3, 122.6, 20.000000000000014, 10.69999999999997, 176.6, 108.20000000000002, 84.79999999999998, 143.29999999999967, 20.000000000000014, 190.99999999999994, 20.000000000000014, 194.0, 199.1, 99.19999999999936, 170.29999999999995, -0.9999999999999992, 152.29999999999995, 139.09999999999974, 198.2, 140.89999999999986, 189.2, 129.4999999999997, 97.39999999999988, 165.79999999999993, 56.60000000000012, 84.50000000000009, 161.59999999999994, 127.9999999999996, 182.0, 158.0, 172.99999999999983, 190.09999999999997, 157.70000000000002, 44.00000000000016, 199.1, 121.69999999999968, 119.30000000000001, 162.49999999999997, 196.39999999999998, 61.399999999999984, 126.20000000000006, 191.0, 186.5, 20.000000000000014, -17.799999999999763, 136.09999999999988, 200.0, 186.49999999999991, 44.000000000000014, 184.7, 196.4, 154.99999999999991, 109.99999999999997, 45.20000000000009, 53.30000000000014, 124.39999999999954, 142.3999999999999, 147.19999999999985, 76.69999999999996, 192.8, 189.2, 190.1, 191.0, 177.5, 114.50000000000013, 24.500000000000096, 192.79999999999995, 155.3, 198.2, 29.0, 20.90000000000003, 146.0, 82.99999999999997, 20.90000000000003, 189.2, 200.0, 155.9, 200.0], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 8.0, 0.0, 0.0, 12.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 10.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 9.0, 2.0, 17.0, 8.0, 0.0, 0.0, 10.0, 0.0, 12.0, 2.0, 0.0, 0.0, 0.0, 4.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 76.0, 0.0, 6.0, 0.0, 0.0, 13.0, 4.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 8.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 2.0, 0.0, 4.0, 0.0, 5.0, 0.0, 0.0, 13.0, 0.0, 5.0, 0.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 4.0, 6.0, 8.0, 9.0, 0.0, 11.0, 0.0, 10.0, 9.0, 0.0, 0.0, 25.0, 0.0, 2.0, 0.0, 6.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 19.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 3.0, 18.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 11.0, 5.0, 0.0, 0.0, 9.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 16.408921962434093, "mean_inference_ms": 35.58967934501686, "mean_action_processing_ms": 8.103451651805786, "mean_env_wait_ms": 10.944446297066765, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.020471930503845215, "StateBufferConnector_ms": 0.019052743911743164, "ViewRequirementAgentConnector_ms": 0.46271002292633057}, "num_episodes": 18, "episode_return_max": 394.6, "episode_return_min": 26.000000000000085, "episode_return_mean": 247.60399999999987, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1136000, "num_agent_steps_trained": 1136000, "num_env_steps_sampled": 284000, "num_env_steps_trained": 284000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 148.2391392659139, "num_env_steps_trained_throughput_per_sec": 148.2391392659139, "timesteps_total": 284000, "num_env_steps_sampled_lifetime": 284000, "num_agent_steps_sampled_lifetime": 1136000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1136000, "timers": {"training_iteration_time_ms": 26072.227, "restore_workers_time_ms": 0.024, "training_step_time_ms": 26072.147, "sample_time_ms": 4682.531, "learn_time_ms": 21336.215, "learn_throughput": 187.475, "synch_weights_time_ms": 44.953}, "counters": {"num_env_steps_sampled": 284000, "num_env_steps_trained": 284000, "num_agent_steps_sampled": 1136000, "num_agent_steps_trained": 1136000}, "done": false, "training_iteration": 71, "trial_id": "75ec3_00000", "date": "2024-08-13_02-54-18", "timestamp": 1723532058, "time_this_iter_s": 27.045169830322266, "time_total_s": 5712.204484939575, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b205da60>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 5712.204484939575, "iterations_since_restore": 71, "perf": {"cpu_util_percent": 88.41052631578947, "ram_util_percent": 83.42631578947366}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 10.23558961998218, "cur_kl_coeff": 0.04505081176757812, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.25694440735711, "policy_loss": -0.0020968629939176102, "vf_loss": 8.258689848329656, "vf_explained_var": 0.4610681872203867, "kl": 0.00780057176777085, "entropy": 1.1433372232649062, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 135135.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.30116415159116505, "cur_kl_coeff": 7.275957614183426e-13, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.2964434335707987, "policy_loss": -0.0004621042852738389, "vf_loss": 0.2969055369074109, "vf_explained_var": 0.0295532745028299, "kl": 0.0014666324373443344, "entropy": 0.24646941878335185, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 135135.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 288000, "num_env_steps_trained": 288000, "num_agent_steps_sampled": 1152000, "num_agent_steps_trained": 1152000}, "env_runners": {"episode_reward_max": 394.6, "episode_reward_min": 26.000000000000085, "episode_reward_mean": 251.37699999999987, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -127.00000000000017, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 76.0}, "policy_reward_mean": {"prey_policy": 122.92849999999994, "predator_policy": 2.76}, "custom_metrics": {}, "hist_stats": {"episode_reward": [307.3000000000005, 283.8999999999998, 304.5999999999998, 175.8999999999998, 233.49999999999955, 114.79999999999984, 278.20000000000016, 194.2999999999994, 341.0000000000003, 265.8999999999994, 348.70000000000005, 254.19999999999953, 287.5000000000001, 141.69999999999936, 37.80000000000027, 115.59999999999985, 323.5000000000013, 363.10000000000014, 121.89999999999952, 239.79999999999905, 176.20000000000024, 246.09999999999943, 264.09999999999997, 218.19999999999925, 189.6999999999994, 303.49999999999966, 205.5999999999993, 345.10000000000053, 284.0999999999998, 220.49999999999932, 257.89999999999924, 354.0000000000003, 26.000000000000085, 374.7, 229.89999999999935, 273.19999999999993, 394.6, 40.0000000000003, 224.49999999999923, 301.9, 37.700000000000195, 293.80000000000007, 228.09999999999937, 210.9999999999992, 215.9999999999993, 298.30000000000047, 179.2999999999994, 308.3999999999999, 350.10000000000065, 328.7000000000012, 272.1999999999998, 166.1000000000002, 291.6000000000005, 346.0, 363.1000000000007, 205.69999999999928, 320.7999999999997, 300.7999999999997, 257.7999999999995, 329.20000000000005, 209.49999999999932, 136.29999999999947, 386.5000000000002, 232.69999999999956, 351.40000000000043, 155.1999999999999, 177.69999999999897, 297.6000000000003, 269.4999999999998, 379.3, 371.5, 138.9999999999999, 364.1000000000001, 227.1999999999993, 185.89999999999944, 103.89999999999992, 389.2, 355.90000000000003, 27.100000000000097, 362.90000000000015, 323.2000000000006, 370.59999999999997, 309.9000000000002, 378.40000000000043, 109.79999999999987, 198.39999999999978, 109.09999999999962, 150.5999999999996, 360.39999999999986, 121.19999999999973, 189.0999999999995, 103.89999999999995, 246.79999999999944, 384.7, 265.09999999999957, 191.89999999999958, 340.4000000000009, 264.29999999999984, 389.2, 240.59999999999954], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [133.39999999999986, 173.89999999999986, 92.89999999999998, 190.99999999999994, 143.29999999999978, 161.29999999999987, 121.69999999999999, 54.200000000000195, 175.7, 57.800000000000104, -127.00000000000017, 165.8, 160.39999999999998, 111.79999999999956, 170.0, 11.29999999999997, 161.3, 172.6999999999999, 71.30000000000013, 194.59999999999997, 151.4, 197.3, 84.79999999999998, 169.39999999999986, 87.49999999999942, 200.0, 98.29999999999997, 43.39999999999998, 15.799999999999963, 20.000000000000014, 20.900000000000013, 94.69999999999997, 123.49999999999959, 200.0, 200.0, 163.1, 92.90000000000003, 20.000000000000014, 136.99999999999991, 102.80000000000014, 69.49999999999997, 97.70000000000013, 46.09999999999997, 200.0, 123.49999999999999, 140.59999999999997, 20.000000000000014, 198.2, -3.3999999999999653, 181.1, 168.2, 125.30000000000007, 182.9, 22.70000000000006, 165.7999999999998, 179.3, 175.7, 100.39999999999986, 22.10000000000007, 196.4, 197.3, 56.60000000000021, 168.79999999999993, 180.20000000000005, -2.799999999999986, 15.799999999999962, 169.7, 200.0, 143.3, 86.59999999999931, 96.20000000000003, 164.00000000000003, 194.6, 200.0, 20.000000000000014, 20.000000000000014, 180.19999999999987, 44.30000000000002, 179.3, 122.6, 20.000000000000014, 10.69999999999997, 176.6, 108.20000000000002, 84.79999999999998, 143.29999999999967, 20.000000000000014, 190.99999999999994, 20.000000000000014, 194.0, 199.1, 99.19999999999936, 170.29999999999995, -0.9999999999999992, 152.29999999999995, 139.09999999999974, 198.2, 140.89999999999986, 189.2, 129.4999999999997, 97.39999999999988, 165.79999999999993, 56.60000000000012, 84.50000000000009, 161.59999999999994, 127.9999999999996, 182.0, 158.0, 172.99999999999983, 190.09999999999997, 157.70000000000002, 44.00000000000016, 199.1, 121.69999999999968, 119.30000000000001, 162.49999999999997, 196.39999999999998, 61.399999999999984, 126.20000000000006, 191.0, 186.5, 20.000000000000014, -17.799999999999763, 136.09999999999988, 200.0, 186.49999999999991, 44.000000000000014, 184.7, 196.4, 154.99999999999991, 109.99999999999997, 45.20000000000009, 53.30000000000014, 124.39999999999954, 142.3999999999999, 147.19999999999985, 76.69999999999996, 192.8, 189.2, 190.1, 191.0, 177.5, 114.50000000000013, 24.500000000000096, 192.79999999999995, 155.3, 198.2, 29.0, 20.90000000000003, 146.0, 82.99999999999997, 20.90000000000003, 189.2, 200.0, 155.9, 200.0, 7.399999999999965, 4.699999999999969, 197.29999999999998, 164.59999999999997, 132.50000000000003, 175.69999999999985, 189.2, 169.39999999999998, 200.0, 104.89999999999984, 180.19999999999987, 198.2, 20.000000000000014, 87.8, 137.0, 61.39999999999999, 88.09999999999988, 20.000000000000014, 134.89999999999998, 1.6999999999999693, 167.89999999999992, 186.5, 7.699999999999974, 105.49999999999997, 91.99999999999987, 91.0999999999999, 20.000000000000014, 83.89999999999998, 46.70000000000009, 199.1, 185.6, 199.1, 173.3, 75.7999999999995, 145.99999999999994, 44.90000000000004, 135.79999999999978, 194.6, 59.30000000000013, 188.0, 194.59999999999997, 194.6, 26.60000000000018, 200.0], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 76.0, 0.0, 6.0, 0.0, 0.0, 13.0, 4.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 8.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 2.0, 0.0, 4.0, 0.0, 5.0, 0.0, 0.0, 13.0, 0.0, 5.0, 0.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 4.0, 6.0, 8.0, 9.0, 0.0, 11.0, 0.0, 10.0, 9.0, 0.0, 0.0, 25.0, 0.0, 2.0, 0.0, 6.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 19.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 3.0, 18.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 11.0, 5.0, 0.0, 0.0, 9.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 15.0, 0.0, 0.0, 1.0, 15.0, 0.0, 12.0, 0.0, 0.0, 5.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 14.0, 0.0, 5.0, 1.0, 8.0, 0.0, 0.0, 6.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 8.0, 8.0, 0.0, 1.0, 8.0, 2.0, 13.0, 4.0, 0.0, 0.0, 0.0, 14.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 16.183952185398127, "mean_inference_ms": 35.15252676410803, "mean_action_processing_ms": 8.011139269057182, "mean_env_wait_ms": 10.74738383391043, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.023381471633911133, "StateBufferConnector_ms": 0.0208737850189209, "ViewRequirementAgentConnector_ms": 0.41177642345428467}, "num_episodes": 22, "episode_return_max": 394.6, "episode_return_min": 26.000000000000085, "episode_return_mean": 251.37699999999987, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1152000, "num_agent_steps_trained": 1152000, "num_env_steps_sampled": 288000, "num_env_steps_trained": 288000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 152.52239307999258, "num_env_steps_trained_throughput_per_sec": 152.52239307999258, "timesteps_total": 288000, "num_env_steps_sampled_lifetime": 288000, "num_agent_steps_sampled_lifetime": 1152000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1152000, "timers": {"training_iteration_time_ms": 26257.8, "restore_workers_time_ms": 0.027, "training_step_time_ms": 26257.713, "sample_time_ms": 4741.055, "learn_time_ms": 21465.449, "learn_throughput": 186.346, "synch_weights_time_ms": 43.0}, "counters": {"num_env_steps_sampled": 288000, "num_env_steps_trained": 288000, "num_agent_steps_sampled": 1152000, "num_agent_steps_trained": 1152000}, "done": false, "training_iteration": 72, "trial_id": "75ec3_00000", "date": "2024-08-13_02-54-44", "timestamp": 1723532084, "time_this_iter_s": 26.276170015335083, "time_total_s": 5738.48065495491, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b1bc1ee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 5738.48065495491, "iterations_since_restore": 72, "perf": {"cpu_util_percent": 86.22972972972974, "ram_util_percent": 83.32972972972972}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 13.606314032134556, "cur_kl_coeff": 0.04505081176757812, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.074111045352996, "policy_loss": -0.002460093532255284, "vf_loss": 8.076126224023325, "vf_explained_var": 0.5465275465811371, "kl": 0.009875461144316927, "entropy": 1.1518417528066685, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 137025.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.3419221883787522, "cur_kl_coeff": 3.637978807091713e-13, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.5502550343830118, "policy_loss": -9.408458579509031e-05, "vf_loss": 0.5503491170428417, "vf_explained_var": 0.06641413314001901, "kl": 0.0007153972103312886, "entropy": 0.22772448818204263, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 137025.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 292000, "num_env_steps_trained": 292000, "num_agent_steps_sampled": 1168000, "num_agent_steps_trained": 1168000}, "env_runners": {"episode_reward_max": 394.6, "episode_reward_min": 26.000000000000085, "episode_reward_mean": 259.04399999999987, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -24.099999999999753, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 25.0}, "policy_reward_mean": {"prey_policy": 126.04699999999997, "predator_policy": 3.475}, "custom_metrics": {}, "hist_stats": {"episode_reward": [218.19999999999925, 189.6999999999994, 303.49999999999966, 205.5999999999993, 345.10000000000053, 284.0999999999998, 220.49999999999932, 257.89999999999924, 354.0000000000003, 26.000000000000085, 374.7, 229.89999999999935, 273.19999999999993, 394.6, 40.0000000000003, 224.49999999999923, 301.9, 37.700000000000195, 293.80000000000007, 228.09999999999937, 210.9999999999992, 215.9999999999993, 298.30000000000047, 179.2999999999994, 308.3999999999999, 350.10000000000065, 328.7000000000012, 272.1999999999998, 166.1000000000002, 291.6000000000005, 346.0, 363.1000000000007, 205.69999999999928, 320.7999999999997, 300.7999999999997, 257.7999999999995, 329.20000000000005, 209.49999999999932, 136.29999999999947, 386.5000000000002, 232.69999999999956, 351.40000000000043, 155.1999999999999, 177.69999999999897, 297.6000000000003, 269.4999999999998, 379.3, 371.5, 138.9999999999999, 364.1000000000001, 227.1999999999993, 185.89999999999944, 103.89999999999992, 389.2, 355.90000000000003, 27.100000000000097, 362.90000000000015, 323.2000000000006, 370.59999999999997, 309.9000000000002, 378.40000000000043, 109.79999999999987, 198.39999999999978, 109.09999999999962, 150.5999999999996, 360.39999999999986, 121.19999999999973, 189.0999999999995, 103.89999999999995, 246.79999999999944, 384.7, 265.09999999999957, 191.89999999999958, 340.4000000000009, 264.29999999999984, 389.2, 240.59999999999954, 348.0000000000007, 280.59999999999957, 371.99999999999994, 205.0999999999993, 355.0000000000001, 359.69999999999993, 255.90000000000003, 93.0999999999999, 342.40000000000003, 386.1, 214.4999999999993, 330.00000000000085, 273.0999999999995, 83.70000000000019, 256.09999999999934, 303.8000000000005, 307.0999999999999, 359.70000000000005, 98.39999999999912, 359.3000000000001, 201.69999999999936, 163.09999999999943, 237.89999999999978], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 198.2, -3.3999999999999653, 181.1, 168.2, 125.30000000000007, 182.9, 22.70000000000006, 165.7999999999998, 179.3, 175.7, 100.39999999999986, 22.10000000000007, 196.4, 197.3, 56.60000000000021, 168.79999999999993, 180.20000000000005, -2.799999999999986, 15.799999999999962, 169.7, 200.0, 143.3, 86.59999999999931, 96.20000000000003, 164.00000000000003, 194.6, 200.0, 20.000000000000014, 20.000000000000014, 180.19999999999987, 44.30000000000002, 179.3, 122.6, 20.000000000000014, 10.69999999999997, 176.6, 108.20000000000002, 84.79999999999998, 143.29999999999967, 20.000000000000014, 190.99999999999994, 20.000000000000014, 194.0, 199.1, 99.19999999999936, 170.29999999999995, -0.9999999999999992, 152.29999999999995, 139.09999999999974, 198.2, 140.89999999999986, 189.2, 129.4999999999997, 97.39999999999988, 165.79999999999993, 56.60000000000012, 84.50000000000009, 161.59999999999994, 127.9999999999996, 182.0, 158.0, 172.99999999999983, 190.09999999999997, 157.70000000000002, 44.00000000000016, 199.1, 121.69999999999968, 119.30000000000001, 162.49999999999997, 196.39999999999998, 61.399999999999984, 126.20000000000006, 191.0, 186.5, 20.000000000000014, -17.799999999999763, 136.09999999999988, 200.0, 186.49999999999991, 44.000000000000014, 184.7, 196.4, 154.99999999999991, 109.99999999999997, 45.20000000000009, 53.30000000000014, 124.39999999999954, 142.3999999999999, 147.19999999999985, 76.69999999999996, 192.8, 189.2, 190.1, 191.0, 177.5, 114.50000000000013, 24.500000000000096, 192.79999999999995, 155.3, 198.2, 29.0, 20.90000000000003, 146.0, 82.99999999999997, 20.90000000000003, 189.2, 200.0, 155.9, 200.0, 7.399999999999965, 4.699999999999969, 197.29999999999998, 164.59999999999997, 132.50000000000003, 175.69999999999985, 189.2, 169.39999999999998, 200.0, 104.89999999999984, 180.19999999999987, 198.2, 20.000000000000014, 87.8, 137.0, 61.39999999999999, 88.09999999999988, 20.000000000000014, 134.89999999999998, 1.6999999999999693, 167.89999999999992, 186.5, 7.699999999999974, 105.49999999999997, 91.99999999999987, 91.0999999999999, 20.000000000000014, 83.89999999999998, 46.70000000000009, 199.1, 185.6, 199.1, 173.3, 75.7999999999995, 145.99999999999994, 44.90000000000004, 135.79999999999978, 194.6, 59.30000000000013, 188.0, 194.59999999999997, 194.6, 26.60000000000018, 200.0, 188.9, 151.09999999999982, 154.40000000000003, 123.20000000000007, 193.69999999999996, 173.3, 17.899999999999988, 180.2, 155.89999999999998, 199.1, 193.69999999999996, 149.0, 68.60000000000011, 161.3, 15.799999999999963, 62.29999999999999, 162.2, 171.2, 190.1, 194.0, 200.0, 9.499999999999964, 147.19999999999976, 177.79999999999998, 88.40000000000012, 184.7, 16.400000000000187, 41.300000000000146, 161.0, 82.09999999999968, 112.09999999999985, 187.7, 134.89999999999998, 162.19999999999987, 190.1, 161.6, 61.70000000000014, 22.699999999999985, 166.69999999999996, 173.6, -24.099999999999753, 192.8, 156.49999999999994, -9.400000000000011, 133.70000000000005, 84.20000000000005], "policy_predator_policy_reward": [0.0, 0.0, 12.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 2.0, 0.0, 4.0, 0.0, 5.0, 0.0, 0.0, 13.0, 0.0, 5.0, 0.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 4.0, 6.0, 8.0, 9.0, 0.0, 11.0, 0.0, 10.0, 9.0, 0.0, 0.0, 25.0, 0.0, 2.0, 0.0, 6.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 19.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 3.0, 18.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 11.0, 5.0, 0.0, 0.0, 9.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 15.0, 0.0, 0.0, 1.0, 15.0, 0.0, 12.0, 0.0, 0.0, 5.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 14.0, 0.0, 5.0, 1.0, 8.0, 0.0, 0.0, 6.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 8.0, 8.0, 0.0, 1.0, 8.0, 2.0, 13.0, 4.0, 0.0, 0.0, 0.0, 14.0, 0.0, 8.0, 1.0, 2.0, 5.0, 0.0, 1.0, 6.0, 0.0, 0.0, 0.0, 17.0, 20.0, 6.0, 6.0, 9.0, 9.0, 0.0, 0.0, 2.0, 5.0, 0.0, 5.0, 0.0, 0.0, 0.0, 5.0, 21.0, 0.0, 13.0, 0.0, 4.0, 10.0, 0.0, 8.0, 0.0, 14.0, 0.0, 9.0, 10.0, 21.0, 12.0, 0.0, 16.0, 8.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 16.270964750933913, "mean_inference_ms": 35.317794455260035, "mean_action_processing_ms": 8.214766869568338, "mean_env_wait_ms": 9.34590139440555, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.026938676834106445, "StateBufferConnector_ms": 0.023431062698364258, "ViewRequirementAgentConnector_ms": 0.3462238311767578}, "num_episodes": 23, "episode_return_max": 394.6, "episode_return_min": 26.000000000000085, "episode_return_mean": 259.04399999999987, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1168000, "num_agent_steps_trained": 1168000, "num_env_steps_sampled": 292000, "num_env_steps_trained": 292000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 139.40144431065428, "num_env_steps_trained_throughput_per_sec": 139.40144431065428, "timesteps_total": 292000, "num_env_steps_sampled_lifetime": 292000, "num_agent_steps_sampled_lifetime": 1168000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1168000, "timers": {"training_iteration_time_ms": 26637.358, "restore_workers_time_ms": 0.027, "training_step_time_ms": 26637.271, "sample_time_ms": 4772.662, "learn_time_ms": 21817.861, "learn_throughput": 183.336, "synch_weights_time_ms": 38.356}, "counters": {"num_env_steps_sampled": 292000, "num_env_steps_trained": 292000, "num_agent_steps_sampled": 1168000, "num_agent_steps_trained": 1168000}, "done": false, "training_iteration": 73, "trial_id": "75ec3_00000", "date": "2024-08-13_02-55-13", "timestamp": 1723532113, "time_this_iter_s": 28.759313821792603, "time_total_s": 5767.239968776703, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b206b160>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 5767.239968776703, "iterations_since_restore": 73, "perf": {"cpu_util_percent": 90.115, "ram_util_percent": 83.4675}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 16.60355260990284, "cur_kl_coeff": 0.04505081176757812, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.705443089096635, "policy_loss": -0.003966817229729954, "vf_loss": 7.708705053127632, "vf_explained_var": 0.5682090100472567, "kl": 0.015645452096818405, "entropy": 1.1409149979157422, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 138915.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.22674922677220175, "cur_kl_coeff": 1.8189894035458566e-13, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.23297024028641836, "policy_loss": -8.554542338643124e-05, "vf_loss": 0.23305578601622656, "vf_explained_var": 0.04417124548286357, "kl": 0.0020579237077178562, "entropy": 0.1972272424707337, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 138915.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 296000, "num_env_steps_trained": 296000, "num_agent_steps_sampled": 1184000, "num_agent_steps_trained": 1184000}, "env_runners": {"episode_reward_max": 389.2, "episode_reward_min": 27.100000000000097, "episode_reward_mean": 256.1429999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -24.099999999999753, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 25.0}, "policy_reward_mean": {"prey_policy": 124.26649999999998, "predator_policy": 3.805}, "custom_metrics": {}, "hist_stats": {"episode_reward": [293.80000000000007, 228.09999999999937, 210.9999999999992, 215.9999999999993, 298.30000000000047, 179.2999999999994, 308.3999999999999, 350.10000000000065, 328.7000000000012, 272.1999999999998, 166.1000000000002, 291.6000000000005, 346.0, 363.1000000000007, 205.69999999999928, 320.7999999999997, 300.7999999999997, 257.7999999999995, 329.20000000000005, 209.49999999999932, 136.29999999999947, 386.5000000000002, 232.69999999999956, 351.40000000000043, 155.1999999999999, 177.69999999999897, 297.6000000000003, 269.4999999999998, 379.3, 371.5, 138.9999999999999, 364.1000000000001, 227.1999999999993, 185.89999999999944, 103.89999999999992, 389.2, 355.90000000000003, 27.100000000000097, 362.90000000000015, 323.2000000000006, 370.59999999999997, 309.9000000000002, 378.40000000000043, 109.79999999999987, 198.39999999999978, 109.09999999999962, 150.5999999999996, 360.39999999999986, 121.19999999999973, 189.0999999999995, 103.89999999999995, 246.79999999999944, 384.7, 265.09999999999957, 191.89999999999958, 340.4000000000009, 264.29999999999984, 389.2, 240.59999999999954, 348.0000000000007, 280.59999999999957, 371.99999999999994, 205.0999999999993, 355.0000000000001, 359.69999999999993, 255.90000000000003, 93.0999999999999, 342.40000000000003, 386.1, 214.4999999999993, 330.00000000000085, 273.0999999999995, 83.70000000000019, 256.09999999999934, 303.8000000000005, 307.0999999999999, 359.70000000000005, 98.39999999999912, 359.3000000000001, 201.69999999999936, 163.09999999999943, 237.89999999999978, 216.19999999999996, 87.69999999999996, 45.40000000000029, 366.70000000000044, 138.99999999999991, 381.10000000000036, 184.29999999999978, 286.2000000000004, 30.100000000000147, 249.69999999999965, 240.99999999999957, 234.39999999999955, 195.69999999999914, 249.2999999999995, 309.4, 233.69999999999976, 189.59999999999926, 351.5], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [176.6, 108.20000000000002, 84.79999999999998, 143.29999999999967, 20.000000000000014, 190.99999999999994, 20.000000000000014, 194.0, 199.1, 99.19999999999936, 170.29999999999995, -0.9999999999999992, 152.29999999999995, 139.09999999999974, 198.2, 140.89999999999986, 189.2, 129.4999999999997, 97.39999999999988, 165.79999999999993, 56.60000000000012, 84.50000000000009, 161.59999999999994, 127.9999999999996, 182.0, 158.0, 172.99999999999983, 190.09999999999997, 157.70000000000002, 44.00000000000016, 199.1, 121.69999999999968, 119.30000000000001, 162.49999999999997, 196.39999999999998, 61.399999999999984, 126.20000000000006, 191.0, 186.5, 20.000000000000014, -17.799999999999763, 136.09999999999988, 200.0, 186.49999999999991, 44.000000000000014, 184.7, 196.4, 154.99999999999991, 109.99999999999997, 45.20000000000009, 53.30000000000014, 124.39999999999954, 142.3999999999999, 147.19999999999985, 76.69999999999996, 192.8, 189.2, 190.1, 191.0, 177.5, 114.50000000000013, 24.500000000000096, 192.79999999999995, 155.3, 198.2, 29.0, 20.90000000000003, 146.0, 82.99999999999997, 20.90000000000003, 189.2, 200.0, 155.9, 200.0, 7.399999999999965, 4.699999999999969, 197.29999999999998, 164.59999999999997, 132.50000000000003, 175.69999999999985, 189.2, 169.39999999999998, 200.0, 104.89999999999984, 180.19999999999987, 198.2, 20.000000000000014, 87.8, 137.0, 61.39999999999999, 88.09999999999988, 20.000000000000014, 134.89999999999998, 1.6999999999999693, 167.89999999999992, 186.5, 7.699999999999974, 105.49999999999997, 91.99999999999987, 91.0999999999999, 20.000000000000014, 83.89999999999998, 46.70000000000009, 199.1, 185.6, 199.1, 173.3, 75.7999999999995, 145.99999999999994, 44.90000000000004, 135.79999999999978, 194.6, 59.30000000000013, 188.0, 194.59999999999997, 194.6, 26.60000000000018, 200.0, 188.9, 151.09999999999982, 154.40000000000003, 123.20000000000007, 193.69999999999996, 173.3, 17.899999999999988, 180.2, 155.89999999999998, 199.1, 193.69999999999996, 149.0, 68.60000000000011, 161.3, 15.799999999999963, 62.29999999999999, 162.2, 171.2, 190.1, 194.0, 200.0, 9.499999999999964, 147.19999999999976, 177.79999999999998, 88.40000000000012, 184.7, 16.400000000000187, 41.300000000000146, 161.0, 82.09999999999968, 112.09999999999985, 187.7, 134.89999999999998, 162.19999999999987, 190.1, 161.6, 61.70000000000014, 22.699999999999985, 166.69999999999996, 173.6, -24.099999999999753, 192.8, 156.49999999999994, -9.400000000000011, 133.70000000000005, 84.20000000000005, 115.1, 82.10000000000008, 67.69999999999996, 20.000000000000014, 20.000000000000014, 25.400000000000006, 186.49999999999991, 180.2, 20.000000000000014, 119.00000000000013, 200.0, 181.0999999999999, 23.600000000000108, 142.69999999999996, 93.19999999999965, 185.0, 1.0999999999999865, 20.000000000000014, 66.79999999999998, 182.9, 30.800000000000075, 198.2, 43.400000000000084, 173.0, 175.69999999999987, 20.000000000000014, 149.0, 89.30000000000013, 149.59999999999994, 147.8, 171.2, 54.49999999999996, 161.59999999999997, 20.000000000000014, 181.1, 148.4], "policy_predator_policy_reward": [0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 4.0, 6.0, 8.0, 9.0, 0.0, 11.0, 0.0, 10.0, 9.0, 0.0, 0.0, 25.0, 0.0, 2.0, 0.0, 6.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 19.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 3.0, 18.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 11.0, 5.0, 0.0, 0.0, 9.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 15.0, 0.0, 0.0, 1.0, 15.0, 0.0, 12.0, 0.0, 0.0, 5.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 14.0, 0.0, 5.0, 1.0, 8.0, 0.0, 0.0, 6.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 8.0, 8.0, 0.0, 1.0, 8.0, 2.0, 13.0, 4.0, 0.0, 0.0, 0.0, 14.0, 0.0, 8.0, 1.0, 2.0, 5.0, 0.0, 1.0, 6.0, 0.0, 0.0, 0.0, 17.0, 20.0, 6.0, 6.0, 9.0, 9.0, 0.0, 0.0, 2.0, 5.0, 0.0, 5.0, 0.0, 0.0, 0.0, 5.0, 21.0, 0.0, 13.0, 0.0, 4.0, 10.0, 0.0, 8.0, 0.0, 14.0, 0.0, 9.0, 10.0, 21.0, 12.0, 0.0, 16.0, 8.0, 12.0, 19.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 18.0, 0.0, 0.0, 8.0, 9.0, 0.0, 0.0, 0.0, 0.0, 12.0, 9.0, 9.0, 0.0, 0.0, 0.0, 11.0, 12.0, 0.0, 8.0, 0.0, 8.0, 0.0, 13.0, 9.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 15.792805260246059, "mean_inference_ms": 34.30573750484979, "mean_action_processing_ms": 7.793812528418752, "mean_env_wait_ms": 10.493325639996383, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.03757452964782715, "StateBufferConnector_ms": 0.021609067916870117, "ViewRequirementAgentConnector_ms": 0.28158724308013916}, "num_episodes": 18, "episode_return_max": 389.2, "episode_return_min": 27.100000000000097, "episode_return_mean": 256.1429999999999, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1184000, "num_agent_steps_trained": 1184000, "num_env_steps_sampled": 296000, "num_env_steps_trained": 296000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 149.02591054396305, "num_env_steps_trained_throughput_per_sec": 149.02591054396305, "timesteps_total": 296000, "num_env_steps_sampled_lifetime": 296000, "num_agent_steps_sampled_lifetime": 1184000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1184000, "timers": {"training_iteration_time_ms": 26779.849, "restore_workers_time_ms": 0.026, "training_step_time_ms": 26779.763, "sample_time_ms": 4772.85, "learn_time_ms": 21964.592, "learn_throughput": 182.111, "synch_weights_time_ms": 35.538}, "counters": {"num_env_steps_sampled": 296000, "num_env_steps_trained": 296000, "num_agent_steps_sampled": 1184000, "num_agent_steps_trained": 1184000}, "done": false, "training_iteration": 74, "trial_id": "75ec3_00000", "date": "2024-08-13_02-55-40", "timestamp": 1723532140, "time_this_iter_s": 26.881932020187378, "time_total_s": 5794.12190079689, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b1bc6790>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 5794.12190079689, "iterations_since_restore": 74, "perf": {"cpu_util_percent": 88.41052631578947, "ram_util_percent": 83.13684210526314}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 13.234909715002807, "cur_kl_coeff": 0.04505081176757812, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.323511912835338, "policy_loss": -0.0024232298707362837, "vf_loss": 8.325148283236873, "vf_explained_var": 0.13281227126323356, "kl": 0.017466533374683166, "entropy": 1.0381847547475622, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 140805.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.17716907558213701, "cur_kl_coeff": 9.094947017729283e-14, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.13216844674140688, "policy_loss": -0.0003860002531418725, "vf_loss": 0.1325544471639515, "vf_explained_var": -0.07079450970604306, "kl": 0.0024736580341809832, "entropy": 0.24534893852693063, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 140805.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 300000, "num_env_steps_trained": 300000, "num_agent_steps_sampled": 1200000, "num_agent_steps_trained": 1200000}, "env_runners": {"episode_reward_max": 389.2, "episode_reward_min": 27.100000000000097, "episode_reward_mean": 261.45099999999985, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -24.099999999999753, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 21.0}, "policy_reward_mean": {"prey_policy": 127.09549999999999, "predator_policy": 3.63}, "custom_metrics": {}, "hist_stats": {"episode_reward": [329.20000000000005, 209.49999999999932, 136.29999999999947, 386.5000000000002, 232.69999999999956, 351.40000000000043, 155.1999999999999, 177.69999999999897, 297.6000000000003, 269.4999999999998, 379.3, 371.5, 138.9999999999999, 364.1000000000001, 227.1999999999993, 185.89999999999944, 103.89999999999992, 389.2, 355.90000000000003, 27.100000000000097, 362.90000000000015, 323.2000000000006, 370.59999999999997, 309.9000000000002, 378.40000000000043, 109.79999999999987, 198.39999999999978, 109.09999999999962, 150.5999999999996, 360.39999999999986, 121.19999999999973, 189.0999999999995, 103.89999999999995, 246.79999999999944, 384.7, 265.09999999999957, 191.89999999999958, 340.4000000000009, 264.29999999999984, 389.2, 240.59999999999954, 348.0000000000007, 280.59999999999957, 371.99999999999994, 205.0999999999993, 355.0000000000001, 359.69999999999993, 255.90000000000003, 93.0999999999999, 342.40000000000003, 386.1, 214.4999999999993, 330.00000000000085, 273.0999999999995, 83.70000000000019, 256.09999999999934, 303.8000000000005, 307.0999999999999, 359.70000000000005, 98.39999999999912, 359.3000000000001, 201.69999999999936, 163.09999999999943, 237.89999999999978, 216.19999999999996, 87.69999999999996, 45.40000000000029, 366.70000000000044, 138.99999999999991, 381.10000000000036, 184.29999999999978, 286.2000000000004, 30.100000000000147, 249.69999999999965, 240.99999999999957, 234.39999999999955, 195.69999999999914, 249.2999999999995, 309.4, 233.69999999999976, 189.59999999999926, 351.5, 298.9000000000001, 377.5000000000003, 326.2000000000002, 149.19999999999914, 310.4000000000003, 200.99999999999972, 257.7999999999995, 153.99999999999932, 322.6, 287.50000000000006, 359.40000000000003, 365.9999999999999, 366.6999999999998, 281.1999999999996, 368.5000000000005, 369.4999999999999, 364.00000000000006, 308.1999999999997], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [126.20000000000006, 191.0, 186.5, 20.000000000000014, -17.799999999999763, 136.09999999999988, 200.0, 186.49999999999991, 44.000000000000014, 184.7, 196.4, 154.99999999999991, 109.99999999999997, 45.20000000000009, 53.30000000000014, 124.39999999999954, 142.3999999999999, 147.19999999999985, 76.69999999999996, 192.8, 189.2, 190.1, 191.0, 177.5, 114.50000000000013, 24.500000000000096, 192.79999999999995, 155.3, 198.2, 29.0, 20.90000000000003, 146.0, 82.99999999999997, 20.90000000000003, 189.2, 200.0, 155.9, 200.0, 7.399999999999965, 4.699999999999969, 197.29999999999998, 164.59999999999997, 132.50000000000003, 175.69999999999985, 189.2, 169.39999999999998, 200.0, 104.89999999999984, 180.19999999999987, 198.2, 20.000000000000014, 87.8, 137.0, 61.39999999999999, 88.09999999999988, 20.000000000000014, 134.89999999999998, 1.6999999999999693, 167.89999999999992, 186.5, 7.699999999999974, 105.49999999999997, 91.99999999999987, 91.0999999999999, 20.000000000000014, 83.89999999999998, 46.70000000000009, 199.1, 185.6, 199.1, 173.3, 75.7999999999995, 145.99999999999994, 44.90000000000004, 135.79999999999978, 194.6, 59.30000000000013, 188.0, 194.59999999999997, 194.6, 26.60000000000018, 200.0, 188.9, 151.09999999999982, 154.40000000000003, 123.20000000000007, 193.69999999999996, 173.3, 17.899999999999988, 180.2, 155.89999999999998, 199.1, 193.69999999999996, 149.0, 68.60000000000011, 161.3, 15.799999999999963, 62.29999999999999, 162.2, 171.2, 190.1, 194.0, 200.0, 9.499999999999964, 147.19999999999976, 177.79999999999998, 88.40000000000012, 184.7, 16.400000000000187, 41.300000000000146, 161.0, 82.09999999999968, 112.09999999999985, 187.7, 134.89999999999998, 162.19999999999987, 190.1, 161.6, 61.70000000000014, 22.699999999999985, 166.69999999999996, 173.6, -24.099999999999753, 192.8, 156.49999999999994, -9.400000000000011, 133.70000000000005, 84.20000000000005, 115.1, 82.10000000000008, 67.69999999999996, 20.000000000000014, 20.000000000000014, 25.400000000000006, 186.49999999999991, 180.2, 20.000000000000014, 119.00000000000013, 200.0, 181.0999999999999, 23.600000000000108, 142.69999999999996, 93.19999999999965, 185.0, 1.0999999999999865, 20.000000000000014, 66.79999999999998, 182.9, 30.800000000000075, 198.2, 43.400000000000084, 173.0, 175.69999999999987, 20.000000000000014, 149.0, 89.30000000000013, 149.59999999999994, 147.8, 171.2, 54.49999999999996, 161.59999999999997, 20.000000000000014, 181.1, 148.4, 95.6000000000001, 188.29999999999998, 181.99999999999991, 195.5, 175.7, 150.4999999999999, 76.69999999999978, 69.50000000000017, 110.29999999999995, 175.1, 55.10000000000005, 140.89999999999998, 199.1, 58.69999999999998, 115.0999999999998, 23.89999999999997, 182.0, 140.59999999999997, 128.89999999999998, 158.60000000000002, 175.1, 179.29999999999998, 167.9, 190.10000000000002, 171.19999999999985, 195.49999999999997, 188.29999999999998, 92.9000000000001, 181.99999999999994, 186.49999999999991, 185.59999999999994, 179.89999999999995, 159.49999999999997, 195.5, 136.99999999999994, 171.19999999999993], "policy_predator_policy_reward": [12.0, 0.0, 0.0, 3.0, 18.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 11.0, 5.0, 0.0, 0.0, 9.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 15.0, 0.0, 0.0, 1.0, 15.0, 0.0, 12.0, 0.0, 0.0, 5.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 14.0, 0.0, 5.0, 1.0, 8.0, 0.0, 0.0, 6.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 8.0, 8.0, 0.0, 1.0, 8.0, 2.0, 13.0, 4.0, 0.0, 0.0, 0.0, 14.0, 0.0, 8.0, 1.0, 2.0, 5.0, 0.0, 1.0, 6.0, 0.0, 0.0, 0.0, 17.0, 20.0, 6.0, 6.0, 9.0, 9.0, 0.0, 0.0, 2.0, 5.0, 0.0, 5.0, 0.0, 0.0, 0.0, 5.0, 21.0, 0.0, 13.0, 0.0, 4.0, 10.0, 0.0, 8.0, 0.0, 14.0, 0.0, 9.0, 10.0, 21.0, 12.0, 0.0, 16.0, 8.0, 12.0, 19.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 18.0, 0.0, 0.0, 8.0, 9.0, 0.0, 0.0, 0.0, 0.0, 12.0, 9.0, 9.0, 0.0, 0.0, 0.0, 11.0, 12.0, 0.0, 8.0, 0.0, 8.0, 0.0, 13.0, 9.0, 6.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 18.0, 7.0, 0.0, 5.0, 0.0, 0.0, 10.0, 5.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 9.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 15.617233918511948, "mean_inference_ms": 33.937337193435525, "mean_action_processing_ms": 7.704459837059355, "mean_env_wait_ms": 10.369934746872131, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.03633463382720947, "StateBufferConnector_ms": 0.011642813682556152, "ViewRequirementAgentConnector_ms": 0.2835909128189087}, "num_episodes": 18, "episode_return_max": 389.2, "episode_return_min": 27.100000000000097, "episode_return_mean": 261.45099999999985, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1200000, "num_agent_steps_trained": 1200000, "num_env_steps_sampled": 300000, "num_env_steps_trained": 300000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 146.69556343486724, "num_env_steps_trained_throughput_per_sec": 146.69556343486724, "timesteps_total": 300000, "num_env_steps_sampled_lifetime": 300000, "num_agent_steps_sampled_lifetime": 1200000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1200000, "timers": {"training_iteration_time_ms": 27032.473, "restore_workers_time_ms": 0.026, "training_step_time_ms": 27032.386, "sample_time_ms": 4700.518, "learn_time_ms": 22292.116, "learn_throughput": 179.436, "synch_weights_time_ms": 32.808}, "counters": {"num_env_steps_sampled": 300000, "num_env_steps_trained": 300000, "num_agent_steps_sampled": 1200000, "num_agent_steps_trained": 1200000}, "done": false, "training_iteration": 75, "trial_id": "75ec3_00000", "date": "2024-08-13_02-56-07", "timestamp": 1723532167, "time_this_iter_s": 27.338329792022705, "time_total_s": 5821.460230588913, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2084160>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 5821.460230588913, "iterations_since_restore": 75, "perf": {"cpu_util_percent": 86.4923076923077, "ram_util_percent": 83.08974358974359}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 12.931957669705941, "cur_kl_coeff": 0.04505081176757812, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.112441570292074, "policy_loss": -0.001727444562992012, "vf_loss": 8.113866970021888, "vf_explained_var": 0.20861337475045016, "kl": 0.00670449542304675, "entropy": 1.0965241839015294, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 142695.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.35032895420377375, "cur_kl_coeff": 4.5474735088646414e-14, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.25656615489965706, "policy_loss": -0.0005761570247905279, "vf_loss": 0.2571423118102497, "vf_explained_var": 0.019869820150748764, "kl": 0.001992124230147105, "entropy": 0.29113614295840895, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 142695.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 304000, "num_env_steps_trained": 304000, "num_agent_steps_sampled": 1216000, "num_agent_steps_trained": 1216000}, "env_runners": {"episode_reward_max": 389.2, "episode_reward_min": 30.100000000000147, "episode_reward_mean": 264.63299999999987, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -24.099999999999753, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 21.0}, "policy_reward_mean": {"prey_policy": 128.58649999999997, "predator_policy": 3.73}, "custom_metrics": {}, "hist_stats": {"episode_reward": [370.59999999999997, 309.9000000000002, 378.40000000000043, 109.79999999999987, 198.39999999999978, 109.09999999999962, 150.5999999999996, 360.39999999999986, 121.19999999999973, 189.0999999999995, 103.89999999999995, 246.79999999999944, 384.7, 265.09999999999957, 191.89999999999958, 340.4000000000009, 264.29999999999984, 389.2, 240.59999999999954, 348.0000000000007, 280.59999999999957, 371.99999999999994, 205.0999999999993, 355.0000000000001, 359.69999999999993, 255.90000000000003, 93.0999999999999, 342.40000000000003, 386.1, 214.4999999999993, 330.00000000000085, 273.0999999999995, 83.70000000000019, 256.09999999999934, 303.8000000000005, 307.0999999999999, 359.70000000000005, 98.39999999999912, 359.3000000000001, 201.69999999999936, 163.09999999999943, 237.89999999999978, 216.19999999999996, 87.69999999999996, 45.40000000000029, 366.70000000000044, 138.99999999999991, 381.10000000000036, 184.29999999999978, 286.2000000000004, 30.100000000000147, 249.69999999999965, 240.99999999999957, 234.39999999999955, 195.69999999999914, 249.2999999999995, 309.4, 233.69999999999976, 189.59999999999926, 351.5, 298.9000000000001, 377.5000000000003, 326.2000000000002, 149.19999999999914, 310.4000000000003, 200.99999999999972, 257.7999999999995, 153.99999999999932, 322.6, 287.50000000000006, 359.40000000000003, 365.9999999999999, 366.6999999999998, 281.1999999999996, 368.5000000000005, 369.4999999999999, 364.00000000000006, 308.1999999999997, 34.0000000000001, 332.0, 151.89999999999998, 210.99999999999912, 270.30000000000007, 376.6, 284.89999999999964, 374.80000000000007, 376.8, 371.00000000000017, 379.30000000000035, 329.6, 292.0, 339.3, 318.1, 182.30000000000013, 350.8, 189.39999999999935, 329.7999999999999, 197.89999999999938, 196.59999999999948, 204.59999999999965], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [189.2, 169.39999999999998, 200.0, 104.89999999999984, 180.19999999999987, 198.2, 20.000000000000014, 87.8, 137.0, 61.39999999999999, 88.09999999999988, 20.000000000000014, 134.89999999999998, 1.6999999999999693, 167.89999999999992, 186.5, 7.699999999999974, 105.49999999999997, 91.99999999999987, 91.0999999999999, 20.000000000000014, 83.89999999999998, 46.70000000000009, 199.1, 185.6, 199.1, 173.3, 75.7999999999995, 145.99999999999994, 44.90000000000004, 135.79999999999978, 194.6, 59.30000000000013, 188.0, 194.59999999999997, 194.6, 26.60000000000018, 200.0, 188.9, 151.09999999999982, 154.40000000000003, 123.20000000000007, 193.69999999999996, 173.3, 17.899999999999988, 180.2, 155.89999999999998, 199.1, 193.69999999999996, 149.0, 68.60000000000011, 161.3, 15.799999999999963, 62.29999999999999, 162.2, 171.2, 190.1, 194.0, 200.0, 9.499999999999964, 147.19999999999976, 177.79999999999998, 88.40000000000012, 184.7, 16.400000000000187, 41.300000000000146, 161.0, 82.09999999999968, 112.09999999999985, 187.7, 134.89999999999998, 162.19999999999987, 190.1, 161.6, 61.70000000000014, 22.699999999999985, 166.69999999999996, 173.6, -24.099999999999753, 192.8, 156.49999999999994, -9.400000000000011, 133.70000000000005, 84.20000000000005, 115.1, 82.10000000000008, 67.69999999999996, 20.000000000000014, 20.000000000000014, 25.400000000000006, 186.49999999999991, 180.2, 20.000000000000014, 119.00000000000013, 200.0, 181.0999999999999, 23.600000000000108, 142.69999999999996, 93.19999999999965, 185.0, 1.0999999999999865, 20.000000000000014, 66.79999999999998, 182.9, 30.800000000000075, 198.2, 43.400000000000084, 173.0, 175.69999999999987, 20.000000000000014, 149.0, 89.30000000000013, 149.59999999999994, 147.8, 171.2, 54.49999999999996, 161.59999999999997, 20.000000000000014, 181.1, 148.4, 95.6000000000001, 188.29999999999998, 181.99999999999991, 195.5, 175.7, 150.4999999999999, 76.69999999999978, 69.50000000000017, 110.29999999999995, 175.1, 55.10000000000005, 140.89999999999998, 199.1, 58.69999999999998, 115.0999999999998, 23.89999999999997, 182.0, 140.59999999999997, 128.89999999999998, 158.60000000000002, 175.1, 179.29999999999998, 167.9, 190.10000000000002, 171.19999999999985, 195.49999999999997, 188.29999999999998, 92.9000000000001, 181.99999999999994, 186.49999999999991, 185.59999999999994, 179.89999999999995, 159.49999999999997, 195.5, 136.99999999999994, 171.19999999999993, 27.20000000000004, -5.1999999999999265, 157.39999999999998, 167.6, 53.29999999999996, 95.6, 156.8, 54.20000000000021, 105.5, 153.79999999999998, 181.1, 195.5, 157.99999999999991, 113.8999999999999, 170.29999999999998, 195.5, 199.1, 169.7, 176.59999999999985, 193.4, 192.8, 186.49999999999991, 183.8, 144.8, 109.99999999999955, 182.0, 164.6, 163.7, 161.0, 139.10000000000002, 94.70000000000002, 83.6, 161.3, 177.5, 20.900000000000013, 168.49999999999997, 190.09999999999994, 139.7, 20.000000000000014, 170.9, 151.39999999999995, 45.20000000000011, 18.20000000000011, 169.4], "policy_predator_policy_reward": [12.0, 0.0, 0.0, 5.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 14.0, 0.0, 5.0, 1.0, 8.0, 0.0, 0.0, 6.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 8.0, 8.0, 0.0, 1.0, 8.0, 2.0, 13.0, 4.0, 0.0, 0.0, 0.0, 14.0, 0.0, 8.0, 1.0, 2.0, 5.0, 0.0, 1.0, 6.0, 0.0, 0.0, 0.0, 17.0, 20.0, 6.0, 6.0, 9.0, 9.0, 0.0, 0.0, 2.0, 5.0, 0.0, 5.0, 0.0, 0.0, 0.0, 5.0, 21.0, 0.0, 13.0, 0.0, 4.0, 10.0, 0.0, 8.0, 0.0, 14.0, 0.0, 9.0, 10.0, 21.0, 12.0, 0.0, 16.0, 8.0, 12.0, 19.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 18.0, 0.0, 0.0, 8.0, 9.0, 0.0, 0.0, 0.0, 0.0, 12.0, 9.0, 9.0, 0.0, 0.0, 0.0, 11.0, 12.0, 0.0, 8.0, 0.0, 8.0, 0.0, 13.0, 9.0, 6.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 18.0, 7.0, 0.0, 5.0, 0.0, 0.0, 10.0, 5.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 9.0, 0.0, 0.0, 0.0, 12.0, 0.0, 7.0, 0.0, 0.0, 3.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 13.0, 0.0, 0.0, 9.0, 0.0, 8.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 4.0, 7.0, 8.0, 10.0, 0.0, 4.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 5.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 15.7280015795926, "mean_inference_ms": 33.472859885143954, "mean_action_processing_ms": 7.321722751070013, "mean_env_wait_ms": 10.233207441259587, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.034717440605163574, "StateBufferConnector_ms": 0.01219332218170166, "ViewRequirementAgentConnector_ms": 0.27830934524536133}, "num_episodes": 22, "episode_return_max": 389.2, "episode_return_min": 30.100000000000147, "episode_return_mean": 264.63299999999987, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1216000, "num_agent_steps_trained": 1216000, "num_env_steps_sampled": 304000, "num_env_steps_trained": 304000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 151.05797157911965, "num_env_steps_trained_throughput_per_sec": 151.05797157911965, "timesteps_total": 304000, "num_env_steps_sampled_lifetime": 304000, "num_agent_steps_sampled_lifetime": 1216000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1216000, "timers": {"training_iteration_time_ms": 27270.317, "restore_workers_time_ms": 0.024, "training_step_time_ms": 27270.231, "sample_time_ms": 4647.916, "learn_time_ms": 22589.131, "learn_throughput": 177.076, "synch_weights_time_ms": 25.76}, "counters": {"num_env_steps_sampled": 304000, "num_env_steps_trained": 304000, "num_agent_steps_sampled": 1216000, "num_agent_steps_trained": 1216000}, "done": false, "training_iteration": 76, "trial_id": "75ec3_00000", "date": "2024-08-13_02-56-34", "timestamp": 1723532194, "time_this_iter_s": 26.545578002929688, "time_total_s": 5848.005808591843, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b1bbbaf0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 5848.005808591843, "iterations_since_restore": 76, "perf": {"cpu_util_percent": 85.3054054054054, "ram_util_percent": 83.37837837837837}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 15.87391773818662, "cur_kl_coeff": 0.04505081176757812, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.770591186846374, "policy_loss": -0.0015642090183165338, "vf_loss": 7.771688509996606, "vf_explained_var": 0.19461380271684556, "kl": 0.010363665414668197, "entropy": 1.0933778533229122, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 144585.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.1622205178169583, "cur_kl_coeff": 2.2737367544323207e-14, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.07897207187488675, "policy_loss": -4.5203975347614794e-05, "vf_loss": 0.07901727597138483, "vf_explained_var": -0.16001693136477596, "kl": 0.0021295919233349186, "entropy": 0.2525929924593401, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 144585.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 308000, "num_env_steps_trained": 308000, "num_agent_steps_sampled": 1232000, "num_agent_steps_trained": 1232000}, "env_runners": {"episode_reward_max": 394.6, "episode_reward_min": 30.100000000000147, "episode_reward_mean": 271.7459999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -24.099999999999753, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 34.0}, "policy_reward_mean": {"prey_policy": 132.083, "predator_policy": 3.79}, "custom_metrics": {}, "hist_stats": {"episode_reward": [240.59999999999954, 348.0000000000007, 280.59999999999957, 371.99999999999994, 205.0999999999993, 355.0000000000001, 359.69999999999993, 255.90000000000003, 93.0999999999999, 342.40000000000003, 386.1, 214.4999999999993, 330.00000000000085, 273.0999999999995, 83.70000000000019, 256.09999999999934, 303.8000000000005, 307.0999999999999, 359.70000000000005, 98.39999999999912, 359.3000000000001, 201.69999999999936, 163.09999999999943, 237.89999999999978, 216.19999999999996, 87.69999999999996, 45.40000000000029, 366.70000000000044, 138.99999999999991, 381.10000000000036, 184.29999999999978, 286.2000000000004, 30.100000000000147, 249.69999999999965, 240.99999999999957, 234.39999999999955, 195.69999999999914, 249.2999999999995, 309.4, 233.69999999999976, 189.59999999999926, 351.5, 298.9000000000001, 377.5000000000003, 326.2000000000002, 149.19999999999914, 310.4000000000003, 200.99999999999972, 257.7999999999995, 153.99999999999932, 322.6, 287.50000000000006, 359.40000000000003, 365.9999999999999, 366.6999999999998, 281.1999999999996, 368.5000000000005, 369.4999999999999, 364.00000000000006, 308.1999999999997, 34.0000000000001, 332.0, 151.89999999999998, 210.99999999999912, 270.30000000000007, 376.6, 284.89999999999964, 374.80000000000007, 376.8, 371.00000000000017, 379.30000000000035, 329.6, 292.0, 339.3, 318.1, 182.30000000000013, 350.8, 189.39999999999935, 329.7999999999999, 197.89999999999938, 196.59999999999948, 204.59999999999965, 352.7000000000004, 373.5, 183.99999999999943, 210.99999999999926, 325.9000000000002, 333.4000000000001, 351.500000000001, 186.29999999999941, 300.69999999999993, 340.8000000000005, 335.2, 394.6, 221.89999999999995, 314.5, 309.9999999999997, 182.19999999999908, 160.59999999999934, 316.30000000000007], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [26.60000000000018, 200.0, 188.9, 151.09999999999982, 154.40000000000003, 123.20000000000007, 193.69999999999996, 173.3, 17.899999999999988, 180.2, 155.89999999999998, 199.1, 193.69999999999996, 149.0, 68.60000000000011, 161.3, 15.799999999999963, 62.29999999999999, 162.2, 171.2, 190.1, 194.0, 200.0, 9.499999999999964, 147.19999999999976, 177.79999999999998, 88.40000000000012, 184.7, 16.400000000000187, 41.300000000000146, 161.0, 82.09999999999968, 112.09999999999985, 187.7, 134.89999999999998, 162.19999999999987, 190.1, 161.6, 61.70000000000014, 22.699999999999985, 166.69999999999996, 173.6, -24.099999999999753, 192.8, 156.49999999999994, -9.400000000000011, 133.70000000000005, 84.20000000000005, 115.1, 82.10000000000008, 67.69999999999996, 20.000000000000014, 20.000000000000014, 25.400000000000006, 186.49999999999991, 180.2, 20.000000000000014, 119.00000000000013, 200.0, 181.0999999999999, 23.600000000000108, 142.69999999999996, 93.19999999999965, 185.0, 1.0999999999999865, 20.000000000000014, 66.79999999999998, 182.9, 30.800000000000075, 198.2, 43.400000000000084, 173.0, 175.69999999999987, 20.000000000000014, 149.0, 89.30000000000013, 149.59999999999994, 147.8, 171.2, 54.49999999999996, 161.59999999999997, 20.000000000000014, 181.1, 148.4, 95.6000000000001, 188.29999999999998, 181.99999999999991, 195.5, 175.7, 150.4999999999999, 76.69999999999978, 69.50000000000017, 110.29999999999995, 175.1, 55.10000000000005, 140.89999999999998, 199.1, 58.69999999999998, 115.0999999999998, 23.89999999999997, 182.0, 140.59999999999997, 128.89999999999998, 158.60000000000002, 175.1, 179.29999999999998, 167.9, 190.10000000000002, 171.19999999999985, 195.49999999999997, 188.29999999999998, 92.9000000000001, 181.99999999999994, 186.49999999999991, 185.59999999999994, 179.89999999999995, 159.49999999999997, 195.5, 136.99999999999994, 171.19999999999993, 27.20000000000004, -5.1999999999999265, 157.39999999999998, 167.6, 53.29999999999996, 95.6, 156.8, 54.20000000000021, 105.5, 153.79999999999998, 181.1, 195.5, 157.99999999999991, 113.8999999999999, 170.29999999999998, 195.5, 199.1, 169.7, 176.59999999999985, 193.4, 192.8, 186.49999999999991, 183.8, 144.8, 109.99999999999955, 182.0, 164.6, 163.7, 161.0, 139.10000000000002, 94.70000000000002, 83.6, 161.3, 177.5, 20.900000000000013, 168.49999999999997, 190.09999999999994, 139.7, 20.000000000000014, 170.9, 151.39999999999995, 45.20000000000011, 18.20000000000011, 169.4, 152.0, 184.6999999999999, 173.3, 189.2, 20.000000000000014, 164.0, 79.40000000000003, 131.59999999999962, 148.69999999999996, 171.2, 195.5, 137.89999999999998, 200.0, 147.49999999999974, 165.8, 18.500000000000004, 113.60000000000002, 181.1, 148.39999999999986, 175.39999999999998, 199.1, 136.1, 197.3, 197.29999999999998, 170.29999999999995, 11.59999999999998, 175.7, 138.79999999999993, 168.5, 132.4999999999997, 116.29999999999951, 65.89999999999993, 129.7999999999998, 30.799999999999997, 182.0, 134.29999999999998], "policy_predator_policy_reward": [0.0, 14.0, 0.0, 8.0, 1.0, 2.0, 5.0, 0.0, 1.0, 6.0, 0.0, 0.0, 0.0, 17.0, 20.0, 6.0, 6.0, 9.0, 9.0, 0.0, 0.0, 2.0, 5.0, 0.0, 5.0, 0.0, 0.0, 0.0, 5.0, 21.0, 0.0, 13.0, 0.0, 4.0, 10.0, 0.0, 8.0, 0.0, 14.0, 0.0, 9.0, 10.0, 21.0, 12.0, 0.0, 16.0, 8.0, 12.0, 19.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 18.0, 0.0, 0.0, 8.0, 9.0, 0.0, 0.0, 0.0, 0.0, 12.0, 9.0, 9.0, 0.0, 0.0, 0.0, 11.0, 12.0, 0.0, 8.0, 0.0, 8.0, 0.0, 13.0, 9.0, 6.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 18.0, 7.0, 0.0, 5.0, 0.0, 0.0, 10.0, 5.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 9.0, 0.0, 0.0, 0.0, 12.0, 0.0, 7.0, 0.0, 0.0, 3.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 13.0, 0.0, 0.0, 9.0, 0.0, 8.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 4.0, 7.0, 8.0, 10.0, 0.0, 4.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 5.0, 12.0, 6.0, 10.0, 1.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 4.0, 0.0, 2.0, 0.0, 6.0, 0.0, 7.0, 10.0, 0.0, 0.0, 0.0, 0.0, 34.0, 6.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 15.245384085615761, "mean_inference_ms": 33.182379033621565, "mean_action_processing_ms": 7.5326637886007, "mean_env_wait_ms": 10.08580963323458, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.032442688941955566, "StateBufferConnector_ms": 0.010373234748840332, "ViewRequirementAgentConnector_ms": 0.28320419788360596}, "num_episodes": 18, "episode_return_max": 394.6, "episode_return_min": 30.100000000000147, "episode_return_mean": 271.7459999999999, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1232000, "num_agent_steps_trained": 1232000, "num_env_steps_sampled": 308000, "num_env_steps_trained": 308000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 150.23769882329316, "num_env_steps_trained_throughput_per_sec": 150.23769882329316, "timesteps_total": 308000, "num_env_steps_sampled_lifetime": 308000, "num_agent_steps_sampled_lifetime": 1232000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1232000, "timers": {"training_iteration_time_ms": 27447.847, "restore_workers_time_ms": 0.023, "training_step_time_ms": 27447.766, "sample_time_ms": 4374.7, "learn_time_ms": 23038.941, "learn_throughput": 173.619, "synch_weights_time_ms": 27.254}, "counters": {"num_env_steps_sampled": 308000, "num_env_steps_trained": 308000, "num_agent_steps_sampled": 1232000, "num_agent_steps_trained": 1232000}, "done": false, "training_iteration": 77, "trial_id": "75ec3_00000", "date": "2024-08-13_02-57-01", "timestamp": 1723532221, "time_this_iter_s": 26.68358302116394, "time_total_s": 5874.689391613007, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b1bb5f70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 5874.689391613007, "iterations_since_restore": 77, "perf": {"cpu_util_percent": 84.66842105263157, "ram_util_percent": 82.85000000000002}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 21.956904303554506, "cur_kl_coeff": 0.04505081176757812, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.130562508800042, "policy_loss": -0.0008379986746207116, "vf_loss": 7.130284614663906, "vf_explained_var": 0.41527884085342365, "kl": 0.024769909313926617, "entropy": 1.077980924094165, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 146475.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.3894517543208268, "cur_kl_coeff": 1.1368683772161604e-14, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.5908164746073818, "policy_loss": -0.000336601062820702, "vf_loss": 0.591153077376149, "vf_explained_var": 0.0033445735772450764, "kl": 0.0011984675519660455, "entropy": 0.2500875551706899, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 146475.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 312000, "num_env_steps_trained": 312000, "num_agent_steps_sampled": 1248000, "num_agent_steps_trained": 1248000}, "env_runners": {"episode_reward_max": 394.6, "episode_reward_min": -87.30000000000098, "episode_reward_mean": 272.48499999999984, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -229.9000000000004, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 119.0}, "policy_reward_mean": {"prey_policy": 131.99749999999997, "predator_policy": 4.245}, "custom_metrics": {}, "hist_stats": {"episode_reward": [237.89999999999978, 216.19999999999996, 87.69999999999996, 45.40000000000029, 366.70000000000044, 138.99999999999991, 381.10000000000036, 184.29999999999978, 286.2000000000004, 30.100000000000147, 249.69999999999965, 240.99999999999957, 234.39999999999955, 195.69999999999914, 249.2999999999995, 309.4, 233.69999999999976, 189.59999999999926, 351.5, 298.9000000000001, 377.5000000000003, 326.2000000000002, 149.19999999999914, 310.4000000000003, 200.99999999999972, 257.7999999999995, 153.99999999999932, 322.6, 287.50000000000006, 359.40000000000003, 365.9999999999999, 366.6999999999998, 281.1999999999996, 368.5000000000005, 369.4999999999999, 364.00000000000006, 308.1999999999997, 34.0000000000001, 332.0, 151.89999999999998, 210.99999999999912, 270.30000000000007, 376.6, 284.89999999999964, 374.80000000000007, 376.8, 371.00000000000017, 379.30000000000035, 329.6, 292.0, 339.3, 318.1, 182.30000000000013, 350.8, 189.39999999999935, 329.7999999999999, 197.89999999999938, 196.59999999999948, 204.59999999999965, 352.7000000000004, 373.5, 183.99999999999943, 210.99999999999926, 325.9000000000002, 333.4000000000001, 351.500000000001, 186.29999999999941, 300.69999999999993, 340.8000000000005, 335.2, 394.6, 221.89999999999995, 314.5, 309.9999999999997, 182.19999999999908, 160.59999999999934, 316.30000000000007, 369.4000000000003, 356.0000000000001, 237.99999999999935, 274.1999999999999, 263.19999999999953, 240.09999999999988, 234.39999999999966, -87.30000000000098, 340.59999999999997, 230.79999999999941, 339.90000000000003, 367.79999999999995, 134.19999999999968, 201.8, 289.10000000000025, 325.0, 255.09999999999974, 337.90000000000003, 335.19999999999993, 305.5, 195.6999999999998, 362.19999999999993, 354.09999999999997], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [133.70000000000005, 84.20000000000005, 115.1, 82.10000000000008, 67.69999999999996, 20.000000000000014, 20.000000000000014, 25.400000000000006, 186.49999999999991, 180.2, 20.000000000000014, 119.00000000000013, 200.0, 181.0999999999999, 23.600000000000108, 142.69999999999996, 93.19999999999965, 185.0, 1.0999999999999865, 20.000000000000014, 66.79999999999998, 182.9, 30.800000000000075, 198.2, 43.400000000000084, 173.0, 175.69999999999987, 20.000000000000014, 149.0, 89.30000000000013, 149.59999999999994, 147.8, 171.2, 54.49999999999996, 161.59999999999997, 20.000000000000014, 181.1, 148.4, 95.6000000000001, 188.29999999999998, 181.99999999999991, 195.5, 175.7, 150.4999999999999, 76.69999999999978, 69.50000000000017, 110.29999999999995, 175.1, 55.10000000000005, 140.89999999999998, 199.1, 58.69999999999998, 115.0999999999998, 23.89999999999997, 182.0, 140.59999999999997, 128.89999999999998, 158.60000000000002, 175.1, 179.29999999999998, 167.9, 190.10000000000002, 171.19999999999985, 195.49999999999997, 188.29999999999998, 92.9000000000001, 181.99999999999994, 186.49999999999991, 185.59999999999994, 179.89999999999995, 159.49999999999997, 195.5, 136.99999999999994, 171.19999999999993, 27.20000000000004, -5.1999999999999265, 157.39999999999998, 167.6, 53.29999999999996, 95.6, 156.8, 54.20000000000021, 105.5, 153.79999999999998, 181.1, 195.5, 157.99999999999991, 113.8999999999999, 170.29999999999998, 195.5, 199.1, 169.7, 176.59999999999985, 193.4, 192.8, 186.49999999999991, 183.8, 144.8, 109.99999999999955, 182.0, 164.6, 163.7, 161.0, 139.10000000000002, 94.70000000000002, 83.6, 161.3, 177.5, 20.900000000000013, 168.49999999999997, 190.09999999999994, 139.7, 20.000000000000014, 170.9, 151.39999999999995, 45.20000000000011, 18.20000000000011, 169.4, 152.0, 184.6999999999999, 173.3, 189.2, 20.000000000000014, 164.0, 79.40000000000003, 131.59999999999962, 148.69999999999996, 171.2, 195.5, 137.89999999999998, 200.0, 147.49999999999974, 165.8, 18.500000000000004, 113.60000000000002, 181.1, 148.39999999999986, 175.39999999999998, 199.1, 136.1, 197.3, 197.29999999999998, 170.29999999999995, 11.59999999999998, 175.7, 138.79999999999993, 168.5, 132.4999999999997, 116.29999999999951, 65.89999999999993, 129.7999999999998, 30.799999999999997, 182.0, 134.29999999999998, 170.29999999999993, 199.1, 145.70000000000002, 197.29999999999998, 197.0, 32.0, 157.40000000000003, 99.80000000000001, 196.4, 66.79999999999995, 101.60000000000008, 123.49999999999999, 162.20000000000002, 63.199999999999974, -229.9000000000004, 23.60000000000001, 200.0, 140.60000000000002, 78.49999999999997, 152.29999999999976, 141.8, 190.1, 189.2, 170.6, 108.19999999999997, 20.000000000000014, 171.2, -54.40000000000029, 193.7, 94.39999999999971, 108.50000000000003, 177.49999999999997, 93.80000000000007, 161.3, 146.0, 191.9, 167.3, 155.89999999999998, 164.0, 141.5, 137.0, 58.69999999999998, 179.3, 182.9, 169.39999999999998, 175.69999999999985], "policy_predator_policy_reward": [8.0, 12.0, 19.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 18.0, 0.0, 0.0, 8.0, 9.0, 0.0, 0.0, 0.0, 0.0, 12.0, 9.0, 9.0, 0.0, 0.0, 0.0, 11.0, 12.0, 0.0, 8.0, 0.0, 8.0, 0.0, 13.0, 9.0, 6.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 18.0, 7.0, 0.0, 5.0, 0.0, 0.0, 10.0, 5.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 9.0, 0.0, 0.0, 0.0, 12.0, 0.0, 7.0, 0.0, 0.0, 3.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 13.0, 0.0, 0.0, 9.0, 0.0, 8.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 4.0, 7.0, 8.0, 10.0, 0.0, 4.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 5.0, 12.0, 6.0, 10.0, 1.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 4.0, 0.0, 2.0, 0.0, 6.0, 0.0, 7.0, 10.0, 0.0, 0.0, 0.0, 0.0, 34.0, 6.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13.0, 8.0, 1.0, 7.0, 10.0, 0.0, 0.0, 3.0, 12.0, 0.0, 9.0, 119.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 8.0, 0.0, 6.0, 20.0, 65.0, 0.0, 1.0, 14.0, 25.0, 0.0, 0.0, 0.0, 0.0, 7.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 15.044014122705336, "mean_inference_ms": 32.725720213622104, "mean_action_processing_ms": 7.4110753787877055, "mean_env_wait_ms": 9.972059969592381, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.02967691421508789, "StateBufferConnector_ms": 0.006872415542602539, "ViewRequirementAgentConnector_ms": 0.2730358839035034}, "num_episodes": 23, "episode_return_max": 394.6, "episode_return_min": -87.30000000000098, "episode_return_mean": 272.48499999999984, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1248000, "num_agent_steps_trained": 1248000, "num_env_steps_sampled": 312000, "num_env_steps_trained": 312000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 141.08752686857815, "num_env_steps_trained_throughput_per_sec": 141.08752686857815, "timesteps_total": 312000, "num_env_steps_sampled_lifetime": 312000, "num_agent_steps_sampled_lifetime": 1248000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1248000, "timers": {"training_iteration_time_ms": 27627.721, "restore_workers_time_ms": 0.023, "training_step_time_ms": 27627.642, "sample_time_ms": 4047.418, "learn_time_ms": 23548.518, "learn_throughput": 169.862, "synch_weights_time_ms": 26.848}, "counters": {"num_env_steps_sampled": 312000, "num_env_steps_trained": 312000, "num_agent_steps_sampled": 1248000, "num_agent_steps_trained": 1248000}, "done": false, "training_iteration": 78, "trial_id": "75ec3_00000", "date": "2024-08-13_02-57-29", "timestamp": 1723532249, "time_this_iter_s": 28.424445867538452, "time_total_s": 5903.113837480545, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2058940>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 5903.113837480545, "iterations_since_restore": 78, "perf": {"cpu_util_percent": 85.0375, "ram_util_percent": 83.35499999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 17.330735131420155, "cur_kl_coeff": 0.0675762176513672, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.157508447687462, "policy_loss": -0.003280623704281256, "vf_loss": 7.159406597904427, "vf_explained_var": 0.17405252371515548, "kl": 0.02045774738969865, "entropy": 1.0506314502822027, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 148365.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.23156309701433336, "cur_kl_coeff": 5.684341886080802e-15, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.18905736152378338, "policy_loss": 2.0648666445619214e-05, "vf_loss": 0.1890367130034113, "vf_explained_var": 0.03296789662547843, "kl": 0.002291759862085216, "entropy": 0.2224278971079796, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 148365.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 316000, "num_env_steps_trained": 316000, "num_agent_steps_sampled": 1264000, "num_agent_steps_trained": 1264000}, "env_runners": {"episode_reward_max": 394.6, "episode_reward_min": -87.30000000000098, "episode_reward_mean": 283.8289999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -229.9000000000004, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 119.0}, "policy_reward_mean": {"prey_policy": 137.97949999999997, "predator_policy": 3.935}, "custom_metrics": {}, "hist_stats": {"episode_reward": [351.5, 298.9000000000001, 377.5000000000003, 326.2000000000002, 149.19999999999914, 310.4000000000003, 200.99999999999972, 257.7999999999995, 153.99999999999932, 322.6, 287.50000000000006, 359.40000000000003, 365.9999999999999, 366.6999999999998, 281.1999999999996, 368.5000000000005, 369.4999999999999, 364.00000000000006, 308.1999999999997, 34.0000000000001, 332.0, 151.89999999999998, 210.99999999999912, 270.30000000000007, 376.6, 284.89999999999964, 374.80000000000007, 376.8, 371.00000000000017, 379.30000000000035, 329.6, 292.0, 339.3, 318.1, 182.30000000000013, 350.8, 189.39999999999935, 329.7999999999999, 197.89999999999938, 196.59999999999948, 204.59999999999965, 352.7000000000004, 373.5, 183.99999999999943, 210.99999999999926, 325.9000000000002, 333.4000000000001, 351.500000000001, 186.29999999999941, 300.69999999999993, 340.8000000000005, 335.2, 394.6, 221.89999999999995, 314.5, 309.9999999999997, 182.19999999999908, 160.59999999999934, 316.30000000000007, 369.4000000000003, 356.0000000000001, 237.99999999999935, 274.1999999999999, 263.19999999999953, 240.09999999999988, 234.39999999999966, -87.30000000000098, 340.59999999999997, 230.79999999999941, 339.90000000000003, 367.79999999999995, 134.19999999999968, 201.8, 289.10000000000025, 325.0, 255.09999999999974, 337.90000000000003, 335.19999999999993, 305.5, 195.6999999999998, 362.19999999999993, 354.09999999999997, 183.09999999999923, 340.6000000000002, 285.70000000000005, 322.39999999999986, 193.19999999999933, 61.10000000000025, 273.9999999999998, 325.09999999999985, 263.1999999999998, 272.19999999999953, 320.80000000000007, 335.20000000000044, 335.2, 351.90000000000003, 243.3999999999999, 324.70000000000084, 265.89999999999975, 314.09999999999957], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [181.1, 148.4, 95.6000000000001, 188.29999999999998, 181.99999999999991, 195.5, 175.7, 150.4999999999999, 76.69999999999978, 69.50000000000017, 110.29999999999995, 175.1, 55.10000000000005, 140.89999999999998, 199.1, 58.69999999999998, 115.0999999999998, 23.89999999999997, 182.0, 140.59999999999997, 128.89999999999998, 158.60000000000002, 175.1, 179.29999999999998, 167.9, 190.10000000000002, 171.19999999999985, 195.49999999999997, 188.29999999999998, 92.9000000000001, 181.99999999999994, 186.49999999999991, 185.59999999999994, 179.89999999999995, 159.49999999999997, 195.5, 136.99999999999994, 171.19999999999993, 27.20000000000004, -5.1999999999999265, 157.39999999999998, 167.6, 53.29999999999996, 95.6, 156.8, 54.20000000000021, 105.5, 153.79999999999998, 181.1, 195.5, 157.99999999999991, 113.8999999999999, 170.29999999999998, 195.5, 199.1, 169.7, 176.59999999999985, 193.4, 192.8, 186.49999999999991, 183.8, 144.8, 109.99999999999955, 182.0, 164.6, 163.7, 161.0, 139.10000000000002, 94.70000000000002, 83.6, 161.3, 177.5, 20.900000000000013, 168.49999999999997, 190.09999999999994, 139.7, 20.000000000000014, 170.9, 151.39999999999995, 45.20000000000011, 18.20000000000011, 169.4, 152.0, 184.6999999999999, 173.3, 189.2, 20.000000000000014, 164.0, 79.40000000000003, 131.59999999999962, 148.69999999999996, 171.2, 195.5, 137.89999999999998, 200.0, 147.49999999999974, 165.8, 18.500000000000004, 113.60000000000002, 181.1, 148.39999999999986, 175.39999999999998, 199.1, 136.1, 197.3, 197.29999999999998, 170.29999999999995, 11.59999999999998, 175.7, 138.79999999999993, 168.5, 132.4999999999997, 116.29999999999951, 65.89999999999993, 129.7999999999998, 30.799999999999997, 182.0, 134.29999999999998, 170.29999999999993, 199.1, 145.70000000000002, 197.29999999999998, 197.0, 32.0, 157.40000000000003, 99.80000000000001, 196.4, 66.79999999999995, 101.60000000000008, 123.49999999999999, 162.20000000000002, 63.199999999999974, -229.9000000000004, 23.60000000000001, 200.0, 140.60000000000002, 78.49999999999997, 152.29999999999976, 141.8, 190.1, 189.2, 170.6, 108.19999999999997, 20.000000000000014, 171.2, -54.40000000000029, 193.7, 94.39999999999971, 108.50000000000003, 177.49999999999997, 93.80000000000007, 161.3, 146.0, 191.9, 167.3, 155.89999999999998, 164.0, 141.5, 137.0, 58.69999999999998, 179.3, 182.9, 169.39999999999998, 175.69999999999985, 20.000000000000014, 154.09999999999988, 169.39999999999992, 171.19999999999996, 89.29999999999981, 187.39999999999992, 139.40000000000003, 182.0, 181.99999999999997, 3.1999999999999633, 37.70000000000007, 7.399999999999968, 91.99999999999997, 181.99999999999994, 126.50000000000003, 176.59999999999985, 150.50000000000006, 112.6999999999999, 125.29999999999995, 146.89999999999986, 137.0, 183.7999999999999, 167.5999999999999, 167.59999999999985, 152.29999999999995, 182.89999999999992, 149.00000000000003, 191.89999999999995, 155.9, 87.49999999999999, 182.89999999999998, 138.79999999999978, 142.39999999999998, 123.50000000000009, 135.1999999999996, 176.89999999999995], "policy_predator_policy_reward": [13.0, 9.0, 6.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 18.0, 7.0, 0.0, 5.0, 0.0, 0.0, 10.0, 5.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 9.0, 0.0, 0.0, 0.0, 12.0, 0.0, 7.0, 0.0, 0.0, 3.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 13.0, 0.0, 0.0, 9.0, 0.0, 8.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 4.0, 7.0, 8.0, 10.0, 0.0, 4.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 5.0, 12.0, 6.0, 10.0, 1.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 4.0, 0.0, 2.0, 0.0, 6.0, 0.0, 7.0, 10.0, 0.0, 0.0, 0.0, 0.0, 34.0, 6.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13.0, 8.0, 1.0, 7.0, 10.0, 0.0, 0.0, 3.0, 12.0, 0.0, 9.0, 119.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 8.0, 0.0, 6.0, 20.0, 65.0, 0.0, 1.0, 14.0, 25.0, 0.0, 0.0, 0.0, 0.0, 7.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 9.0, 0.0, 0.0, 0.0, 5.0, 4.0, 1.0, 0.0, 0.0, 8.0, 10.0, 6.0, 0.0, 0.0, 11.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.885041306888757, "mean_inference_ms": 32.3930292942752, "mean_action_processing_ms": 7.330594316878875, "mean_env_wait_ms": 9.861341647838794, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.010740995407104492, "StateBufferConnector_ms": 0.006848812103271484, "ViewRequirementAgentConnector_ms": 0.27036285400390625}, "num_episodes": 18, "episode_return_max": 394.6, "episode_return_min": -87.30000000000098, "episode_return_mean": 283.8289999999999, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1264000, "num_agent_steps_trained": 1264000, "num_env_steps_sampled": 316000, "num_env_steps_trained": 316000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 145.80526934519528, "num_env_steps_trained_throughput_per_sec": 145.80526934519528, "timesteps_total": 316000, "num_env_steps_sampled_lifetime": 316000, "num_agent_steps_sampled_lifetime": 1264000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1264000, "timers": {"training_iteration_time_ms": 27321.88, "restore_workers_time_ms": 0.023, "training_step_time_ms": 27321.802, "sample_time_ms": 3789.904, "learn_time_ms": 23501.199, "learn_throughput": 170.204, "synch_weights_time_ms": 26.273}, "counters": {"num_env_steps_sampled": 316000, "num_env_steps_trained": 316000, "num_agent_steps_sampled": 1264000, "num_agent_steps_trained": 1264000}, "done": false, "training_iteration": 79, "trial_id": "75ec3_00000", "date": "2024-08-13_02-57-57", "timestamp": 1723532277, "time_this_iter_s": 27.493362188339233, "time_total_s": 5930.607199668884, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b1bc1430>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 5930.607199668884, "iterations_since_restore": 79, "perf": {"cpu_util_percent": 86.01052631578948, "ram_util_percent": 83.22631578947369}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 15.216522836622106, "cur_kl_coeff": 0.10136432647705075, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.394064642891052, "policy_loss": -0.00299977693785593, "vf_loss": 6.394927853629703, "vf_explained_var": 0.1952617212893471, "kl": 0.021078086231228615, "entropy": 1.0278769988231558, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 150255.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.26251618733146675, "cur_kl_coeff": 2.842170943040401e-15, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.22892008274005204, "policy_loss": -0.0009373366036920478, "vf_loss": 0.22985741941654986, "vf_explained_var": 0.04151576148769843, "kl": 0.041530167057524485, "entropy": 0.4063465070945245, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 150255.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 320000, "num_env_steps_trained": 320000, "num_agent_steps_sampled": 1280000, "num_agent_steps_trained": 1280000}, "env_runners": {"episode_reward_max": 394.6, "episode_reward_min": -87.30000000000098, "episode_reward_mean": 282.6019999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -229.9000000000004, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 119.0}, "policy_reward_mean": {"prey_policy": 137.29099999999994, "predator_policy": 4.01}, "custom_metrics": {}, "hist_stats": {"episode_reward": [210.99999999999912, 270.30000000000007, 376.6, 284.89999999999964, 374.80000000000007, 376.8, 371.00000000000017, 379.30000000000035, 329.6, 292.0, 339.3, 318.1, 182.30000000000013, 350.8, 189.39999999999935, 329.7999999999999, 197.89999999999938, 196.59999999999948, 204.59999999999965, 352.7000000000004, 373.5, 183.99999999999943, 210.99999999999926, 325.9000000000002, 333.4000000000001, 351.500000000001, 186.29999999999941, 300.69999999999993, 340.8000000000005, 335.2, 394.6, 221.89999999999995, 314.5, 309.9999999999997, 182.19999999999908, 160.59999999999934, 316.30000000000007, 369.4000000000003, 356.0000000000001, 237.99999999999935, 274.1999999999999, 263.19999999999953, 240.09999999999988, 234.39999999999966, -87.30000000000098, 340.59999999999997, 230.79999999999941, 339.90000000000003, 367.79999999999995, 134.19999999999968, 201.8, 289.10000000000025, 325.0, 255.09999999999974, 337.90000000000003, 335.19999999999993, 305.5, 195.6999999999998, 362.19999999999993, 354.09999999999997, 183.09999999999923, 340.6000000000002, 285.70000000000005, 322.39999999999986, 193.19999999999933, 61.10000000000025, 273.9999999999998, 325.09999999999985, 263.1999999999998, 272.19999999999953, 320.80000000000007, 335.20000000000044, 335.2, 351.90000000000003, 243.3999999999999, 324.70000000000084, 265.89999999999975, 314.09999999999957, 290.1999999999996, 278.4999999999997, 354.1, 320.6999999999998, 273.3000000000002, 325.0000000000001, 283.0000000000001, 346.49999999999994, 256.89999999999964, 217.29999999999993, 293.1, 266.7999999999996, 373.00000000000006, 351.20000000000005, 282.49999999999955, 286.7000000000005, 74.50000000000016, 384.5000000000002, 341.70000000000005, 215.69999999999962, 195.39999999999938, 204.69999999999922], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [156.8, 54.20000000000021, 105.5, 153.79999999999998, 181.1, 195.5, 157.99999999999991, 113.8999999999999, 170.29999999999998, 195.5, 199.1, 169.7, 176.59999999999985, 193.4, 192.8, 186.49999999999991, 183.8, 144.8, 109.99999999999955, 182.0, 164.6, 163.7, 161.0, 139.10000000000002, 94.70000000000002, 83.6, 161.3, 177.5, 20.900000000000013, 168.49999999999997, 190.09999999999994, 139.7, 20.000000000000014, 170.9, 151.39999999999995, 45.20000000000011, 18.20000000000011, 169.4, 152.0, 184.6999999999999, 173.3, 189.2, 20.000000000000014, 164.0, 79.40000000000003, 131.59999999999962, 148.69999999999996, 171.2, 195.5, 137.89999999999998, 200.0, 147.49999999999974, 165.8, 18.500000000000004, 113.60000000000002, 181.1, 148.39999999999986, 175.39999999999998, 199.1, 136.1, 197.3, 197.29999999999998, 170.29999999999995, 11.59999999999998, 175.7, 138.79999999999993, 168.5, 132.4999999999997, 116.29999999999951, 65.89999999999993, 129.7999999999998, 30.799999999999997, 182.0, 134.29999999999998, 170.29999999999993, 199.1, 145.70000000000002, 197.29999999999998, 197.0, 32.0, 157.40000000000003, 99.80000000000001, 196.4, 66.79999999999995, 101.60000000000008, 123.49999999999999, 162.20000000000002, 63.199999999999974, -229.9000000000004, 23.60000000000001, 200.0, 140.60000000000002, 78.49999999999997, 152.29999999999976, 141.8, 190.1, 189.2, 170.6, 108.19999999999997, 20.000000000000014, 171.2, -54.40000000000029, 193.7, 94.39999999999971, 108.50000000000003, 177.49999999999997, 93.80000000000007, 161.3, 146.0, 191.9, 167.3, 155.89999999999998, 164.0, 141.5, 137.0, 58.69999999999998, 179.3, 182.9, 169.39999999999998, 175.69999999999985, 20.000000000000014, 154.09999999999988, 169.39999999999992, 171.19999999999996, 89.29999999999981, 187.39999999999992, 139.40000000000003, 182.0, 181.99999999999997, 3.1999999999999633, 37.70000000000007, 7.399999999999968, 91.99999999999997, 181.99999999999994, 126.50000000000003, 176.59999999999985, 150.50000000000006, 112.6999999999999, 125.29999999999995, 146.89999999999986, 137.0, 183.7999999999999, 167.5999999999999, 167.59999999999985, 152.29999999999995, 182.89999999999992, 149.00000000000003, 191.89999999999995, 155.9, 87.49999999999999, 182.89999999999998, 138.79999999999978, 142.39999999999998, 123.50000000000009, 135.1999999999996, 176.89999999999995, 102.79999999999967, 187.4, 118.1, 151.3999999999997, 166.1, 176.0, 143.29999999999998, 163.39999999999998, 142.39999999999992, 122.89999999999998, 148.69999999999985, 170.29999999999993, 140.59999999999997, 142.39999999999998, 200.0, 135.50000000000003, 182.89999999999995, 74.00000000000003, 132.49999999999997, 84.80000000000001, 112.40000000000002, 157.7, 155.89999999999984, 110.89999999999998, 181.09999999999997, 191.9, 150.1999999999998, 200.0, 193.69999999999996, 81.80000000000007, 169.09999999999997, 113.59999999999985, 45.50000000000004, 20.000000000000014, 189.19999999999996, 194.29999999999998, 154.39999999999998, 179.3, 56.000000000000014, 142.69999999999996, 20.000000000000014, 157.4, 20.000000000000014, 184.69999999999993], "policy_predator_policy_reward": [0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 13.0, 0.0, 0.0, 9.0, 0.0, 8.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 4.0, 7.0, 8.0, 10.0, 0.0, 4.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 5.0, 12.0, 6.0, 10.0, 1.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 4.0, 0.0, 2.0, 0.0, 6.0, 0.0, 7.0, 10.0, 0.0, 0.0, 0.0, 0.0, 34.0, 6.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13.0, 8.0, 1.0, 7.0, 10.0, 0.0, 0.0, 3.0, 12.0, 0.0, 9.0, 119.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 8.0, 0.0, 6.0, 20.0, 65.0, 0.0, 1.0, 14.0, 25.0, 0.0, 0.0, 0.0, 0.0, 7.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 9.0, 0.0, 0.0, 0.0, 5.0, 4.0, 1.0, 0.0, 0.0, 8.0, 10.0, 6.0, 0.0, 0.0, 11.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 9.0, 0.0, 11.0, 1.0, 9.0, 5.0, 0.0, 8.0, 0.0, 6.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 7.0, 4.0, 0.0, 4.0, 5.0, 1.0, 0.0, 8.0, 0.0, 17.0, 0.0, 13.0, 5.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.998549764416753, "mean_inference_ms": 31.971008989667045, "mean_action_processing_ms": 6.97204133669352, "mean_env_wait_ms": 9.739888930170002, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0107421875, "StateBufferConnector_ms": 0.006728053092956543, "ViewRequirementAgentConnector_ms": 0.26281213760375977}, "num_episodes": 22, "episode_return_max": 394.6, "episode_return_min": -87.30000000000098, "episode_return_mean": 282.6019999999999, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1280000, "num_agent_steps_trained": 1280000, "num_env_steps_sampled": 320000, "num_env_steps_trained": 320000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 137.38262583925194, "num_env_steps_trained_throughput_per_sec": 137.38262583925194, "timesteps_total": 320000, "num_env_steps_sampled_lifetime": 320000, "num_agent_steps_sampled_lifetime": 1280000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1280000, "timers": {"training_iteration_time_ms": 27401.683, "restore_workers_time_ms": 0.023, "training_step_time_ms": 27401.607, "sample_time_ms": 3572.515, "learn_time_ms": 23798.276, "learn_throughput": 168.079, "synch_weights_time_ms": 25.877}, "counters": {"num_env_steps_sampled": 320000, "num_env_steps_trained": 320000, "num_agent_steps_sampled": 1280000, "num_agent_steps_trained": 1280000}, "done": false, "training_iteration": 80, "trial_id": "75ec3_00000", "date": "2024-08-13_02-58-26", "timestamp": 1723532306, "time_this_iter_s": 29.1663601398468, "time_total_s": 5959.773559808731, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b226fb80>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 5959.773559808731, "iterations_since_restore": 80, "perf": {"cpu_util_percent": 85.94523809523811, "ram_util_percent": 83.19999999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 14.634338435704116, "cur_kl_coeff": 0.15204648971557616, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.920180903036128, "policy_loss": -0.007027671492114052, "vf_loss": 7.922947194084289, "vf_explained_var": 0.15655730555927944, "kl": 0.02802679783992831, "entropy": 1.0048093735225616, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 152145.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.3308982968093857, "cur_kl_coeff": 4.2632564145606e-15, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.21198264324554691, "policy_loss": -0.0003590460588278436, "vf_loss": 0.21234168894890765, "vf_explained_var": -0.0048553041049412314, "kl": 0.006801494511521084, "entropy": 0.8937818411481444, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 152145.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 324000, "num_env_steps_trained": 324000, "num_agent_steps_sampled": 1296000, "num_agent_steps_trained": 1296000}, "env_runners": {"episode_reward_max": 394.6, "episode_reward_min": -87.30000000000098, "episode_reward_mean": 272.22199999999987, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -229.9000000000004, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 119.0}, "policy_reward_mean": {"prey_policy": 131.99599999999998, "predator_policy": 4.115}, "custom_metrics": {}, "hist_stats": {"episode_reward": [204.59999999999965, 352.7000000000004, 373.5, 183.99999999999943, 210.99999999999926, 325.9000000000002, 333.4000000000001, 351.500000000001, 186.29999999999941, 300.69999999999993, 340.8000000000005, 335.2, 394.6, 221.89999999999995, 314.5, 309.9999999999997, 182.19999999999908, 160.59999999999934, 316.30000000000007, 369.4000000000003, 356.0000000000001, 237.99999999999935, 274.1999999999999, 263.19999999999953, 240.09999999999988, 234.39999999999966, -87.30000000000098, 340.59999999999997, 230.79999999999941, 339.90000000000003, 367.79999999999995, 134.19999999999968, 201.8, 289.10000000000025, 325.0, 255.09999999999974, 337.90000000000003, 335.19999999999993, 305.5, 195.6999999999998, 362.19999999999993, 354.09999999999997, 183.09999999999923, 340.6000000000002, 285.70000000000005, 322.39999999999986, 193.19999999999933, 61.10000000000025, 273.9999999999998, 325.09999999999985, 263.1999999999998, 272.19999999999953, 320.80000000000007, 335.20000000000044, 335.2, 351.90000000000003, 243.3999999999999, 324.70000000000084, 265.89999999999975, 314.09999999999957, 290.1999999999996, 278.4999999999997, 354.1, 320.6999999999998, 273.3000000000002, 325.0000000000001, 283.0000000000001, 346.49999999999994, 256.89999999999964, 217.29999999999993, 293.1, 266.7999999999996, 373.00000000000006, 351.20000000000005, 282.49999999999955, 286.7000000000005, 74.50000000000016, 384.5000000000002, 341.70000000000005, 215.69999999999962, 195.39999999999938, 204.69999999999922, 339.6000000000003, 288.59999999999957, 255.09999999999974, 197.89999999999978, 286.5999999999999, 165.99999999999972, 330.70000000000005, 132.8999999999995, 268.0, 232.09999999999917, 337.3000000000004, 195.69999999999956, 282.9000000000002, 191.1999999999992, 298.29999999999995, 163.3999999999996, 184.1999999999993, 181.99999999999903], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [18.20000000000011, 169.4, 152.0, 184.6999999999999, 173.3, 189.2, 20.000000000000014, 164.0, 79.40000000000003, 131.59999999999962, 148.69999999999996, 171.2, 195.5, 137.89999999999998, 200.0, 147.49999999999974, 165.8, 18.500000000000004, 113.60000000000002, 181.1, 148.39999999999986, 175.39999999999998, 199.1, 136.1, 197.3, 197.29999999999998, 170.29999999999995, 11.59999999999998, 175.7, 138.79999999999993, 168.5, 132.4999999999997, 116.29999999999951, 65.89999999999993, 129.7999999999998, 30.799999999999997, 182.0, 134.29999999999998, 170.29999999999993, 199.1, 145.70000000000002, 197.29999999999998, 197.0, 32.0, 157.40000000000003, 99.80000000000001, 196.4, 66.79999999999995, 101.60000000000008, 123.49999999999999, 162.20000000000002, 63.199999999999974, -229.9000000000004, 23.60000000000001, 200.0, 140.60000000000002, 78.49999999999997, 152.29999999999976, 141.8, 190.1, 189.2, 170.6, 108.19999999999997, 20.000000000000014, 171.2, -54.40000000000029, 193.7, 94.39999999999971, 108.50000000000003, 177.49999999999997, 93.80000000000007, 161.3, 146.0, 191.9, 167.3, 155.89999999999998, 164.0, 141.5, 137.0, 58.69999999999998, 179.3, 182.9, 169.39999999999998, 175.69999999999985, 20.000000000000014, 154.09999999999988, 169.39999999999992, 171.19999999999996, 89.29999999999981, 187.39999999999992, 139.40000000000003, 182.0, 181.99999999999997, 3.1999999999999633, 37.70000000000007, 7.399999999999968, 91.99999999999997, 181.99999999999994, 126.50000000000003, 176.59999999999985, 150.50000000000006, 112.6999999999999, 125.29999999999995, 146.89999999999986, 137.0, 183.7999999999999, 167.5999999999999, 167.59999999999985, 152.29999999999995, 182.89999999999992, 149.00000000000003, 191.89999999999995, 155.9, 87.49999999999999, 182.89999999999998, 138.79999999999978, 142.39999999999998, 123.50000000000009, 135.1999999999996, 176.89999999999995, 102.79999999999967, 187.4, 118.1, 151.3999999999997, 166.1, 176.0, 143.29999999999998, 163.39999999999998, 142.39999999999992, 122.89999999999998, 148.69999999999985, 170.29999999999993, 140.59999999999997, 142.39999999999998, 200.0, 135.50000000000003, 182.89999999999995, 74.00000000000003, 132.49999999999997, 84.80000000000001, 112.40000000000002, 157.7, 155.89999999999984, 110.89999999999998, 181.09999999999997, 191.9, 150.1999999999998, 200.0, 193.69999999999996, 81.80000000000007, 169.09999999999997, 113.59999999999985, 45.50000000000004, 20.000000000000014, 189.19999999999996, 194.29999999999998, 154.39999999999998, 179.3, 56.000000000000014, 142.69999999999996, 20.000000000000014, 157.4, 20.000000000000014, 184.69999999999993, 163.9999999999999, 170.59999999999994, 113.59999999999977, 166.99999999999997, 105.50000000000006, 149.5999999999999, 139.09999999999994, 42.80000000000006, 117.19999999999996, 169.4, 58.700000000000024, 107.29999999999995, 190.10000000000002, 140.6, 31.700000000000095, 93.19999999999999, 137.0, 118.99999999999999, 80.59999999999974, 144.49999999999972, 145.99999999999997, 179.2999999999999, 56.89999999999997, 138.79999999999995, 94.10000000000005, 153.79999999999995, 41.600000000000165, 149.59999999999982, 118.99999999999996, 179.29999999999998, 18.79999999999997, 140.6, 13.699999999999964, 162.49999999999991, 160.9999999999998, 20.000000000000014], "policy_predator_policy_reward": [5.0, 12.0, 6.0, 10.0, 1.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 4.0, 0.0, 2.0, 0.0, 6.0, 0.0, 7.0, 10.0, 0.0, 0.0, 0.0, 0.0, 34.0, 6.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13.0, 8.0, 1.0, 7.0, 10.0, 0.0, 0.0, 3.0, 12.0, 0.0, 9.0, 119.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 8.0, 0.0, 6.0, 20.0, 65.0, 0.0, 1.0, 14.0, 25.0, 0.0, 0.0, 0.0, 0.0, 7.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 9.0, 0.0, 0.0, 0.0, 5.0, 4.0, 1.0, 0.0, 0.0, 8.0, 10.0, 6.0, 0.0, 0.0, 11.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 9.0, 0.0, 11.0, 1.0, 9.0, 5.0, 0.0, 8.0, 0.0, 6.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 7.0, 4.0, 0.0, 4.0, 5.0, 1.0, 0.0, 8.0, 0.0, 17.0, 0.0, 13.0, 5.0, 0.0, 0.0, 0.0, 5.0, 8.0, 0.0, 0.0, 0.0, 11.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 12.0, 0.0, 2.0, 5.0, 12.0, 0.0, 0.0, 0.0, 13.0, 22.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 3.0, 5.0, 1.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.547476024735136, "mean_inference_ms": 31.71036323684693, "mean_action_processing_ms": 7.175462335967437, "mean_env_wait_ms": 9.605635455882918, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.009360790252685547, "StateBufferConnector_ms": 0.0062236785888671875, "ViewRequirementAgentConnector_ms": 0.26325345039367676}, "num_episodes": 18, "episode_return_max": 394.6, "episode_return_min": -87.30000000000098, "episode_return_mean": 272.22199999999987, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1296000, "num_agent_steps_trained": 1296000, "num_env_steps_sampled": 324000, "num_env_steps_trained": 324000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 146.62990487191666, "num_env_steps_trained_throughput_per_sec": 146.62990487191666, "timesteps_total": 324000, "num_env_steps_sampled_lifetime": 324000, "num_agent_steps_sampled_lifetime": 1296000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1296000, "timers": {"training_iteration_time_ms": 27431.297, "restore_workers_time_ms": 0.023, "training_step_time_ms": 27431.22, "sample_time_ms": 3516.56, "learn_time_ms": 23883.95, "learn_throughput": 167.476, "synch_weights_time_ms": 25.812}, "counters": {"num_env_steps_sampled": 324000, "num_env_steps_trained": 324000, "num_agent_steps_sampled": 1296000, "num_agent_steps_trained": 1296000}, "done": false, "training_iteration": 81, "trial_id": "75ec3_00000", "date": "2024-08-13_02-58-54", "timestamp": 1723532334, "time_this_iter_s": 27.376050233840942, "time_total_s": 5987.149610042572, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b20588b0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 5987.149610042572, "iterations_since_restore": 81, "perf": {"cpu_util_percent": 86.56052631578947, "ram_util_percent": 83.26315789473684}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 13.46777941376444, "cur_kl_coeff": 0.22806973457336432, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.317412001998337, "policy_loss": -0.0026870618905088612, "vf_loss": 7.3179432228128745, "vf_explained_var": 0.2816990091687157, "kl": 0.009452530832886559, "entropy": 1.0013466409905247, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 154035.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5888616798652543, "cur_kl_coeff": 4.2632564145606e-15, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.6509290383764045, "policy_loss": -0.0018001156982290682, "vf_loss": 0.6527291526121122, "vf_explained_var": 0.06562804106682066, "kl": 0.009890525495438288, "entropy": 0.8047041467888646, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 154035.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 328000, "num_env_steps_trained": 328000, "num_agent_steps_sampled": 1312000, "num_agent_steps_trained": 1312000}, "env_runners": {"episode_reward_max": 384.5000000000002, "episode_reward_min": -87.30000000000098, "episode_reward_mean": 266.13199999999983, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -229.9000000000004, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 119.0}, "policy_reward_mean": {"prey_policy": 128.77099999999993, "predator_policy": 4.295}, "custom_metrics": {}, "hist_stats": {"episode_reward": [263.19999999999953, 240.09999999999988, 234.39999999999966, -87.30000000000098, 340.59999999999997, 230.79999999999941, 339.90000000000003, 367.79999999999995, 134.19999999999968, 201.8, 289.10000000000025, 325.0, 255.09999999999974, 337.90000000000003, 335.19999999999993, 305.5, 195.6999999999998, 362.19999999999993, 354.09999999999997, 183.09999999999923, 340.6000000000002, 285.70000000000005, 322.39999999999986, 193.19999999999933, 61.10000000000025, 273.9999999999998, 325.09999999999985, 263.1999999999998, 272.19999999999953, 320.80000000000007, 335.20000000000044, 335.2, 351.90000000000003, 243.3999999999999, 324.70000000000084, 265.89999999999975, 314.09999999999957, 290.1999999999996, 278.4999999999997, 354.1, 320.6999999999998, 273.3000000000002, 325.0000000000001, 283.0000000000001, 346.49999999999994, 256.89999999999964, 217.29999999999993, 293.1, 266.7999999999996, 373.00000000000006, 351.20000000000005, 282.49999999999955, 286.7000000000005, 74.50000000000016, 384.5000000000002, 341.70000000000005, 215.69999999999962, 195.39999999999938, 204.69999999999922, 339.6000000000003, 288.59999999999957, 255.09999999999974, 197.89999999999978, 286.5999999999999, 165.99999999999972, 330.70000000000005, 132.8999999999995, 268.0, 232.09999999999917, 337.3000000000004, 195.69999999999956, 282.9000000000002, 191.1999999999992, 298.29999999999995, 163.3999999999996, 184.1999999999993, 181.99999999999903, 246.99999999999957, 331.4, 257.19999999999993, 281.9999999999997, 273.0999999999998, 212.89999999999918, 264.49999999999955, 261.8999999999999, 221.29999999999964, 337.1999999999999, 333.20000000000005, 316.30000000000103, 201.79999999999967, 258.79999999999967, 198.4999999999992, 187.8999999999992, 166.19999999999993, 253.09999999999965, 340.60000000000025, 350.19999999999993, 313.59999999999974, 128.4999999999994, 291.10000000000036], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [196.4, 66.79999999999995, 101.60000000000008, 123.49999999999999, 162.20000000000002, 63.199999999999974, -229.9000000000004, 23.60000000000001, 200.0, 140.60000000000002, 78.49999999999997, 152.29999999999976, 141.8, 190.1, 189.2, 170.6, 108.19999999999997, 20.000000000000014, 171.2, -54.40000000000029, 193.7, 94.39999999999971, 108.50000000000003, 177.49999999999997, 93.80000000000007, 161.3, 146.0, 191.9, 167.3, 155.89999999999998, 164.0, 141.5, 137.0, 58.69999999999998, 179.3, 182.9, 169.39999999999998, 175.69999999999985, 20.000000000000014, 154.09999999999988, 169.39999999999992, 171.19999999999996, 89.29999999999981, 187.39999999999992, 139.40000000000003, 182.0, 181.99999999999997, 3.1999999999999633, 37.70000000000007, 7.399999999999968, 91.99999999999997, 181.99999999999994, 126.50000000000003, 176.59999999999985, 150.50000000000006, 112.6999999999999, 125.29999999999995, 146.89999999999986, 137.0, 183.7999999999999, 167.5999999999999, 167.59999999999985, 152.29999999999995, 182.89999999999992, 149.00000000000003, 191.89999999999995, 155.9, 87.49999999999999, 182.89999999999998, 138.79999999999978, 142.39999999999998, 123.50000000000009, 135.1999999999996, 176.89999999999995, 102.79999999999967, 187.4, 118.1, 151.3999999999997, 166.1, 176.0, 143.29999999999998, 163.39999999999998, 142.39999999999992, 122.89999999999998, 148.69999999999985, 170.29999999999993, 140.59999999999997, 142.39999999999998, 200.0, 135.50000000000003, 182.89999999999995, 74.00000000000003, 132.49999999999997, 84.80000000000001, 112.40000000000002, 157.7, 155.89999999999984, 110.89999999999998, 181.09999999999997, 191.9, 150.1999999999998, 200.0, 193.69999999999996, 81.80000000000007, 169.09999999999997, 113.59999999999985, 45.50000000000004, 20.000000000000014, 189.19999999999996, 194.29999999999998, 154.39999999999998, 179.3, 56.000000000000014, 142.69999999999996, 20.000000000000014, 157.4, 20.000000000000014, 184.69999999999993, 163.9999999999999, 170.59999999999994, 113.59999999999977, 166.99999999999997, 105.50000000000006, 149.5999999999999, 139.09999999999994, 42.80000000000006, 117.19999999999996, 169.4, 58.700000000000024, 107.29999999999995, 190.10000000000002, 140.6, 31.700000000000095, 93.19999999999999, 137.0, 118.99999999999999, 80.59999999999974, 144.49999999999972, 145.99999999999997, 179.2999999999999, 56.89999999999997, 138.79999999999995, 94.10000000000005, 153.79999999999995, 41.600000000000165, 149.59999999999982, 118.99999999999996, 179.29999999999998, 18.79999999999997, 140.6, 13.699999999999964, 162.49999999999991, 160.9999999999998, 20.000000000000014, 83.9, 163.09999999999997, 156.8, 149.6, 99.19999999999999, 146.0, 166.09999999999988, 110.89999999999982, 118.09999999999957, 154.99999999999972, 75.8000000000001, 133.09999999999962, 114.7999999999999, 139.69999999999996, 95.00000000000003, 155.90000000000003, 133.39999999999995, 74.89999999999996, 157.9999999999999, 162.2, 130.39999999999995, 192.79999999999998, 190.09999999999994, 126.19999999999966, 56.00000000000006, 135.79999999999995, 74.0, 180.79999999999998, 86.60000000000014, 98.89999999999978, -0.9999999999999917, 173.89999999999992, 118.69999999999999, 30.500000000000107, 128.8999999999998, 114.19999999999987, 180.19999999999993, 160.3999999999999, 174.19999999999993, 157.99999999999997, 148.69999999999982, 164.89999999999995, 99.49999999999983, 20.000000000000014, 137.89999999999992, 153.1999999999999], "policy_predator_policy_reward": [0.0, 0.0, 3.0, 12.0, 0.0, 9.0, 119.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 8.0, 0.0, 6.0, 20.0, 65.0, 0.0, 1.0, 14.0, 25.0, 0.0, 0.0, 0.0, 0.0, 7.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 9.0, 0.0, 0.0, 0.0, 5.0, 4.0, 1.0, 0.0, 0.0, 8.0, 10.0, 6.0, 0.0, 0.0, 11.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 9.0, 0.0, 11.0, 1.0, 9.0, 5.0, 0.0, 8.0, 0.0, 6.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 7.0, 4.0, 0.0, 4.0, 5.0, 1.0, 0.0, 8.0, 0.0, 17.0, 0.0, 13.0, 5.0, 0.0, 0.0, 0.0, 5.0, 8.0, 0.0, 0.0, 0.0, 11.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 12.0, 0.0, 2.0, 5.0, 12.0, 0.0, 0.0, 0.0, 13.0, 22.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 3.0, 5.0, 1.0, 0.0, 0.0, 0.0, 13.0, 12.0, 12.0, 0.0, 5.0, 0.0, 0.0, 0.0, 1.0, 3.0, 0.0, 10.0, 0.0, 11.0, 7.0, 6.0, 0.0, 17.0, 10.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 4.0, 6.0, 7.0, 7.0, 8.0, 17.0, 0.0, 0.0, 10.0, 0.0, 0.0, 7.0, 11.0, 0.0, 0.0, 1.0, 8.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.637809303168867, "mean_inference_ms": 31.88748940550108, "mean_action_processing_ms": 7.365859024324456, "mean_env_wait_ms": 8.376906363981265, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.009798645973205566, "StateBufferConnector_ms": 0.006671428680419922, "ViewRequirementAgentConnector_ms": 0.282328724861145}, "num_episodes": 23, "episode_return_max": 384.5000000000002, "episode_return_min": -87.30000000000098, "episode_return_mean": 266.13199999999983, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1312000, "num_agent_steps_trained": 1312000, "num_env_steps_sampled": 328000, "num_env_steps_trained": 328000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 140.84327509345385, "num_env_steps_trained_throughput_per_sec": 140.84327509345385, "timesteps_total": 328000, "num_env_steps_sampled_lifetime": 328000, "num_agent_steps_sampled_lifetime": 1312000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1312000, "timers": {"training_iteration_time_ms": 27648.766, "restore_workers_time_ms": 0.02, "training_step_time_ms": 27648.698, "sample_time_ms": 3538.538, "learn_time_ms": 24079.554, "learn_throughput": 166.116, "synch_weights_time_ms": 26.076}, "counters": {"num_env_steps_sampled": 328000, "num_env_steps_trained": 328000, "num_agent_steps_sampled": 1312000, "num_agent_steps_trained": 1312000}, "done": false, "training_iteration": 82, "trial_id": "75ec3_00000", "date": "2024-08-13_02-59-22", "timestamp": 1723532362, "time_this_iter_s": 28.4568829536438, "time_total_s": 6015.606492996216, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b1bb5040>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 6015.606492996216, "iterations_since_restore": 82, "perf": {"cpu_util_percent": 86.77317073170732, "ram_util_percent": 83.0048780487805}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 13.445471616491439, "cur_kl_coeff": 0.22806973457336432, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.412157459612246, "policy_loss": 0.0021305494488428824, "vf_loss": 6.404509137925648, "vf_explained_var": 0.483020567452466, "kl": 0.024193344827423902, "entropy": 1.0231824773644644, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 155925.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.38038146816805085, "cur_kl_coeff": 4.2632564145606e-15, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.2576037208672869, "policy_loss": -0.0011418510531444872, "vf_loss": 0.25874557131445575, "vf_explained_var": 0.014582578877292612, "kl": 0.012446153676216664, "entropy": 0.6917193926831402, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 155925.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 332000, "num_env_steps_trained": 332000, "num_agent_steps_sampled": 1328000, "num_agent_steps_trained": 1328000}, "env_runners": {"episode_reward_max": 384.5000000000002, "episode_reward_min": 61.10000000000025, "episode_reward_mean": 269.2899999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -17.79999999999974, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 23.0}, "policy_reward_mean": {"prey_policy": 131.28499999999997, "predator_policy": 3.36}, "custom_metrics": {}, "hist_stats": {"episode_reward": [354.09999999999997, 183.09999999999923, 340.6000000000002, 285.70000000000005, 322.39999999999986, 193.19999999999933, 61.10000000000025, 273.9999999999998, 325.09999999999985, 263.1999999999998, 272.19999999999953, 320.80000000000007, 335.20000000000044, 335.2, 351.90000000000003, 243.3999999999999, 324.70000000000084, 265.89999999999975, 314.09999999999957, 290.1999999999996, 278.4999999999997, 354.1, 320.6999999999998, 273.3000000000002, 325.0000000000001, 283.0000000000001, 346.49999999999994, 256.89999999999964, 217.29999999999993, 293.1, 266.7999999999996, 373.00000000000006, 351.20000000000005, 282.49999999999955, 286.7000000000005, 74.50000000000016, 384.5000000000002, 341.70000000000005, 215.69999999999962, 195.39999999999938, 204.69999999999922, 339.6000000000003, 288.59999999999957, 255.09999999999974, 197.89999999999978, 286.5999999999999, 165.99999999999972, 330.70000000000005, 132.8999999999995, 268.0, 232.09999999999917, 337.3000000000004, 195.69999999999956, 282.9000000000002, 191.1999999999992, 298.29999999999995, 163.3999999999996, 184.1999999999993, 181.99999999999903, 246.99999999999957, 331.4, 257.19999999999993, 281.9999999999997, 273.0999999999998, 212.89999999999918, 264.49999999999955, 261.8999999999999, 221.29999999999964, 337.1999999999999, 333.20000000000005, 316.30000000000103, 201.79999999999967, 258.79999999999967, 198.4999999999992, 187.8999999999992, 166.19999999999993, 253.09999999999965, 340.60000000000025, 350.19999999999993, 313.59999999999974, 128.4999999999994, 291.10000000000036, 235.2999999999994, 235.29999999999956, 331.19999999999993, 298.20000000000005, 294.6999999999998, 319.89999999999964, 292.90000000000026, 144.90000000000003, 202.39999999999935, 376.6, 262.49999999999994, 268.5999999999997, 349.40000000000015, 365.79999999999995, 192.0999999999993, 351.0000000000001, 324.59999999999997, 141.5999999999998], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [169.39999999999998, 175.69999999999985, 20.000000000000014, 154.09999999999988, 169.39999999999992, 171.19999999999996, 89.29999999999981, 187.39999999999992, 139.40000000000003, 182.0, 181.99999999999997, 3.1999999999999633, 37.70000000000007, 7.399999999999968, 91.99999999999997, 181.99999999999994, 126.50000000000003, 176.59999999999985, 150.50000000000006, 112.6999999999999, 125.29999999999995, 146.89999999999986, 137.0, 183.7999999999999, 167.5999999999999, 167.59999999999985, 152.29999999999995, 182.89999999999992, 149.00000000000003, 191.89999999999995, 155.9, 87.49999999999999, 182.89999999999998, 138.79999999999978, 142.39999999999998, 123.50000000000009, 135.1999999999996, 176.89999999999995, 102.79999999999967, 187.4, 118.1, 151.3999999999997, 166.1, 176.0, 143.29999999999998, 163.39999999999998, 142.39999999999992, 122.89999999999998, 148.69999999999985, 170.29999999999993, 140.59999999999997, 142.39999999999998, 200.0, 135.50000000000003, 182.89999999999995, 74.00000000000003, 132.49999999999997, 84.80000000000001, 112.40000000000002, 157.7, 155.89999999999984, 110.89999999999998, 181.09999999999997, 191.9, 150.1999999999998, 200.0, 193.69999999999996, 81.80000000000007, 169.09999999999997, 113.59999999999985, 45.50000000000004, 20.000000000000014, 189.19999999999996, 194.29999999999998, 154.39999999999998, 179.3, 56.000000000000014, 142.69999999999996, 20.000000000000014, 157.4, 20.000000000000014, 184.69999999999993, 163.9999999999999, 170.59999999999994, 113.59999999999977, 166.99999999999997, 105.50000000000006, 149.5999999999999, 139.09999999999994, 42.80000000000006, 117.19999999999996, 169.4, 58.700000000000024, 107.29999999999995, 190.10000000000002, 140.6, 31.700000000000095, 93.19999999999999, 137.0, 118.99999999999999, 80.59999999999974, 144.49999999999972, 145.99999999999997, 179.2999999999999, 56.89999999999997, 138.79999999999995, 94.10000000000005, 153.79999999999995, 41.600000000000165, 149.59999999999982, 118.99999999999996, 179.29999999999998, 18.79999999999997, 140.6, 13.699999999999964, 162.49999999999991, 160.9999999999998, 20.000000000000014, 83.9, 163.09999999999997, 156.8, 149.6, 99.19999999999999, 146.0, 166.09999999999988, 110.89999999999982, 118.09999999999957, 154.99999999999972, 75.8000000000001, 133.09999999999962, 114.7999999999999, 139.69999999999996, 95.00000000000003, 155.90000000000003, 133.39999999999995, 74.89999999999996, 157.9999999999999, 162.2, 130.39999999999995, 192.79999999999998, 190.09999999999994, 126.19999999999966, 56.00000000000006, 135.79999999999995, 74.0, 180.79999999999998, 86.60000000000014, 98.89999999999978, -0.9999999999999917, 173.89999999999992, 118.69999999999999, 30.500000000000107, 128.8999999999998, 114.19999999999987, 180.19999999999993, 160.3999999999999, 174.19999999999993, 157.99999999999997, 148.69999999999982, 164.89999999999995, 99.49999999999983, 20.000000000000014, 137.89999999999992, 153.1999999999999, 162.1999999999998, 73.10000000000005, 60.50000000000008, 174.79999999999995, 160.09999999999997, 157.1, 175.6999999999999, 117.50000000000003, 186.49999999999991, 108.19999999999985, 131.6000000000001, 188.29999999999993, 118.09999999999978, 174.8, 36.499999999999964, 97.40000000000003, 157.39999999999998, 38.00000000000014, 170.29999999999998, 197.3, 125.29999999999995, 120.19999999999993, 181.10000000000002, 84.49999999999999, 172.39999999999992, 169.99999999999997, 185.6, 180.19999999999993, -17.79999999999974, 191.89999999999995, 186.49999999999997, 153.50000000000003, 151.7, 164.89999999999998, 86.89999999999998, 49.700000000000045], "policy_predator_policy_reward": [0.0, 9.0, 9.0, 0.0, 0.0, 0.0, 5.0, 4.0, 1.0, 0.0, 0.0, 8.0, 10.0, 6.0, 0.0, 0.0, 11.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 9.0, 0.0, 11.0, 1.0, 9.0, 5.0, 0.0, 8.0, 0.0, 6.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 7.0, 4.0, 0.0, 4.0, 5.0, 1.0, 0.0, 8.0, 0.0, 17.0, 0.0, 13.0, 5.0, 0.0, 0.0, 0.0, 5.0, 8.0, 0.0, 0.0, 0.0, 11.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 12.0, 0.0, 2.0, 5.0, 12.0, 0.0, 0.0, 0.0, 13.0, 22.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 3.0, 5.0, 1.0, 0.0, 0.0, 0.0, 13.0, 12.0, 12.0, 0.0, 5.0, 0.0, 0.0, 0.0, 1.0, 3.0, 0.0, 10.0, 0.0, 11.0, 7.0, 6.0, 0.0, 17.0, 10.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 4.0, 6.0, 7.0, 7.0, 8.0, 17.0, 0.0, 0.0, 10.0, 0.0, 0.0, 7.0, 11.0, 0.0, 0.0, 1.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 14.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 7.0, 0.0, 9.0, 0.0, 0.0, 17.0, 0.0, 3.0, 0.0, 7.0, 0.0, 0.0, 18.0, 0.0, 0.0, 11.0, 8.0, 0.0, 0.0, 5.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.228650210202339, "mean_inference_ms": 31.02206421707995, "mean_action_processing_ms": 7.000569656100006, "mean_env_wait_ms": 9.403324118904788, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007618069648742676, "StateBufferConnector_ms": 0.0067348480224609375, "ViewRequirementAgentConnector_ms": 0.3212500810623169}, "num_episodes": 18, "episode_return_max": 384.5000000000002, "episode_return_min": 61.10000000000025, "episode_return_mean": 269.2899999999998, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1328000, "num_agent_steps_trained": 1328000, "num_env_steps_sampled": 332000, "num_env_steps_trained": 332000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 134.71952049236833, "num_env_steps_trained_throughput_per_sec": 134.71952049236833, "timesteps_total": 332000, "num_env_steps_sampled_lifetime": 332000, "num_agent_steps_sampled_lifetime": 1328000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1328000, "timers": {"training_iteration_time_ms": 27748.487, "restore_workers_time_ms": 0.02, "training_step_time_ms": 27748.42, "sample_time_ms": 3547.908, "learn_time_ms": 24169.081, "learn_throughput": 165.501, "synch_weights_time_ms": 27.033}, "counters": {"num_env_steps_sampled": 332000, "num_env_steps_trained": 332000, "num_agent_steps_sampled": 1328000, "num_agent_steps_trained": 1328000}, "done": false, "training_iteration": 83, "trial_id": "75ec3_00000", "date": "2024-08-13_02-59-52", "timestamp": 1723532392, "time_this_iter_s": 29.76656985282898, "time_total_s": 6045.373062849045, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b226f670>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 6045.373062849045, "iterations_since_restore": 83, "perf": {"cpu_util_percent": 87.6690476190476, "ram_util_percent": 83.28809523809524}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 15.168682036198005, "cur_kl_coeff": 0.3421046018600463, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.818825850663361, "policy_loss": -0.008543190761671338, "vf_loss": 7.822516577584403, "vf_explained_var": 0.04530656479653858, "kl": 0.014184186786143246, "entropy": 1.0500910125081502, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 157815.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4299869171506356, "cur_kl_coeff": 4.2632564145606e-15, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.32002913999967475, "policy_loss": -0.0013329802896512092, "vf_loss": 0.32136212087940996, "vf_explained_var": 0.01061365560249046, "kl": 0.005033943630126686, "entropy": 0.7860314368886292, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 157815.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 336000, "num_env_steps_trained": 336000, "num_agent_steps_sampled": 1344000, "num_agent_steps_trained": 1344000}, "env_runners": {"episode_reward_max": 384.5000000000002, "episode_reward_min": 74.50000000000016, "episode_reward_mean": 254.27299999999977, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -17.79999999999974, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 23.0}, "policy_reward_mean": {"prey_policy": 123.57649999999995, "predator_policy": 3.56}, "custom_metrics": {}, "hist_stats": {"episode_reward": [314.09999999999957, 290.1999999999996, 278.4999999999997, 354.1, 320.6999999999998, 273.3000000000002, 325.0000000000001, 283.0000000000001, 346.49999999999994, 256.89999999999964, 217.29999999999993, 293.1, 266.7999999999996, 373.00000000000006, 351.20000000000005, 282.49999999999955, 286.7000000000005, 74.50000000000016, 384.5000000000002, 341.70000000000005, 215.69999999999962, 195.39999999999938, 204.69999999999922, 339.6000000000003, 288.59999999999957, 255.09999999999974, 197.89999999999978, 286.5999999999999, 165.99999999999972, 330.70000000000005, 132.8999999999995, 268.0, 232.09999999999917, 337.3000000000004, 195.69999999999956, 282.9000000000002, 191.1999999999992, 298.29999999999995, 163.3999999999996, 184.1999999999993, 181.99999999999903, 246.99999999999957, 331.4, 257.19999999999993, 281.9999999999997, 273.0999999999998, 212.89999999999918, 264.49999999999955, 261.8999999999999, 221.29999999999964, 337.1999999999999, 333.20000000000005, 316.30000000000103, 201.79999999999967, 258.79999999999967, 198.4999999999992, 187.8999999999992, 166.19999999999993, 253.09999999999965, 340.60000000000025, 350.19999999999993, 313.59999999999974, 128.4999999999994, 291.10000000000036, 235.2999999999994, 235.29999999999956, 331.19999999999993, 298.20000000000005, 294.6999999999998, 319.89999999999964, 292.90000000000026, 144.90000000000003, 202.39999999999935, 376.6, 262.49999999999994, 268.5999999999997, 349.40000000000015, 365.79999999999995, 192.0999999999993, 351.0000000000001, 324.59999999999997, 141.5999999999998, 198.19999999999976, 208.59999999999994, 235.5999999999995, 301.89999999999986, 220.899999999999, 124.79999999999927, 229.8999999999996, 86.29999999999998, 119.39999999999964, 221.4999999999996, 285.70000000000084, 206.4999999999998, 212.79999999999967, 225.3999999999998, 268.59999999999957, 144.39999999999935, 134.39999999999947, 125.19999999999955], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [135.1999999999996, 176.89999999999995, 102.79999999999967, 187.4, 118.1, 151.3999999999997, 166.1, 176.0, 143.29999999999998, 163.39999999999998, 142.39999999999992, 122.89999999999998, 148.69999999999985, 170.29999999999993, 140.59999999999997, 142.39999999999998, 200.0, 135.50000000000003, 182.89999999999995, 74.00000000000003, 132.49999999999997, 84.80000000000001, 112.40000000000002, 157.7, 155.89999999999984, 110.89999999999998, 181.09999999999997, 191.9, 150.1999999999998, 200.0, 193.69999999999996, 81.80000000000007, 169.09999999999997, 113.59999999999985, 45.50000000000004, 20.000000000000014, 189.19999999999996, 194.29999999999998, 154.39999999999998, 179.3, 56.000000000000014, 142.69999999999996, 20.000000000000014, 157.4, 20.000000000000014, 184.69999999999993, 163.9999999999999, 170.59999999999994, 113.59999999999977, 166.99999999999997, 105.50000000000006, 149.5999999999999, 139.09999999999994, 42.80000000000006, 117.19999999999996, 169.4, 58.700000000000024, 107.29999999999995, 190.10000000000002, 140.6, 31.700000000000095, 93.19999999999999, 137.0, 118.99999999999999, 80.59999999999974, 144.49999999999972, 145.99999999999997, 179.2999999999999, 56.89999999999997, 138.79999999999995, 94.10000000000005, 153.79999999999995, 41.600000000000165, 149.59999999999982, 118.99999999999996, 179.29999999999998, 18.79999999999997, 140.6, 13.699999999999964, 162.49999999999991, 160.9999999999998, 20.000000000000014, 83.9, 163.09999999999997, 156.8, 149.6, 99.19999999999999, 146.0, 166.09999999999988, 110.89999999999982, 118.09999999999957, 154.99999999999972, 75.8000000000001, 133.09999999999962, 114.7999999999999, 139.69999999999996, 95.00000000000003, 155.90000000000003, 133.39999999999995, 74.89999999999996, 157.9999999999999, 162.2, 130.39999999999995, 192.79999999999998, 190.09999999999994, 126.19999999999966, 56.00000000000006, 135.79999999999995, 74.0, 180.79999999999998, 86.60000000000014, 98.89999999999978, -0.9999999999999917, 173.89999999999992, 118.69999999999999, 30.500000000000107, 128.8999999999998, 114.19999999999987, 180.19999999999993, 160.3999999999999, 174.19999999999993, 157.99999999999997, 148.69999999999982, 164.89999999999995, 99.49999999999983, 20.000000000000014, 137.89999999999992, 153.1999999999999, 162.1999999999998, 73.10000000000005, 60.50000000000008, 174.79999999999995, 160.09999999999997, 157.1, 175.6999999999999, 117.50000000000003, 186.49999999999991, 108.19999999999985, 131.6000000000001, 188.29999999999993, 118.09999999999978, 174.8, 36.499999999999964, 97.40000000000003, 157.39999999999998, 38.00000000000014, 170.29999999999998, 197.3, 125.29999999999995, 120.19999999999993, 181.10000000000002, 84.49999999999999, 172.39999999999992, 169.99999999999997, 185.6, 180.19999999999993, -17.79999999999974, 191.89999999999995, 186.49999999999997, 153.50000000000003, 151.7, 164.89999999999998, 86.89999999999998, 49.700000000000045, 79.70000000000003, 108.49999999999986, 107.59999999999998, 80.0, 50.60000000000013, 182.0, 191.0, 110.89999999999961, 139.6999999999998, 81.20000000000002, 25.400000000000006, 73.39999999999998, 168.49999999999994, 61.4, 59.30000000000002, 20.000000000000014, 49.70000000000009, 61.70000000000014, 116.3, 99.20000000000009, 145.09999999999965, 131.59999999999974, 74.00000000000006, 132.50000000000003, 128.89999999999998, 83.90000000000006, 93.5, 122.89999999999989, 113.59999999999945, 154.99999999999977, 117.1999999999998, 27.20000000000011, 23.900000000000077, 87.49999999999966, 27.200000000000003, 91.99999999999979], "policy_predator_policy_reward": [0.0, 2.0, 0.0, 0.0, 9.0, 0.0, 11.0, 1.0, 9.0, 5.0, 0.0, 8.0, 0.0, 6.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 7.0, 4.0, 0.0, 4.0, 5.0, 1.0, 0.0, 8.0, 0.0, 17.0, 0.0, 13.0, 5.0, 0.0, 0.0, 0.0, 5.0, 8.0, 0.0, 0.0, 0.0, 11.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 12.0, 0.0, 2.0, 5.0, 12.0, 0.0, 0.0, 0.0, 13.0, 22.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 3.0, 5.0, 1.0, 0.0, 0.0, 0.0, 13.0, 12.0, 12.0, 0.0, 5.0, 0.0, 0.0, 0.0, 1.0, 3.0, 0.0, 10.0, 0.0, 11.0, 7.0, 6.0, 0.0, 17.0, 10.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 4.0, 6.0, 7.0, 7.0, 8.0, 17.0, 0.0, 0.0, 10.0, 0.0, 0.0, 7.0, 11.0, 0.0, 0.0, 1.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 14.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 7.0, 0.0, 9.0, 0.0, 0.0, 17.0, 0.0, 3.0, 0.0, 7.0, 0.0, 0.0, 18.0, 0.0, 0.0, 11.0, 8.0, 0.0, 0.0, 5.0, 5.0, 5.0, 8.0, 13.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 17.0, 9.0, 0.0, 0.0, 1.0, 6.0, 0.0, 8.0, 0.0, 6.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 2.0, 7.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.089716000988519, "mean_inference_ms": 30.73167756834083, "mean_action_processing_ms": 6.929861319349377, "mean_env_wait_ms": 9.305869724467053, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00782930850982666, "StateBufferConnector_ms": 0.006951570510864258, "ViewRequirementAgentConnector_ms": 0.30795109272003174}, "num_episodes": 18, "episode_return_max": 384.5000000000002, "episode_return_min": 74.50000000000016, "episode_return_mean": 254.27299999999977, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1344000, "num_agent_steps_trained": 1344000, "num_env_steps_sampled": 336000, "num_env_steps_trained": 336000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 130.71631070635624, "num_env_steps_trained_throughput_per_sec": 130.71631070635624, "timesteps_total": 336000, "num_env_steps_sampled_lifetime": 336000, "num_agent_steps_sampled_lifetime": 1344000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1344000, "timers": {"training_iteration_time_ms": 28124.452, "restore_workers_time_ms": 0.019, "training_step_time_ms": 28124.384, "sample_time_ms": 3596.182, "learn_time_ms": 24496.715, "learn_throughput": 163.287, "synch_weights_time_ms": 26.509}, "counters": {"num_env_steps_sampled": 336000, "num_env_steps_trained": 336000, "num_agent_steps_sampled": 1344000, "num_agent_steps_trained": 1344000}, "done": false, "training_iteration": 84, "trial_id": "75ec3_00000", "date": "2024-08-13_03-00-23", "timestamp": 1723532423, "time_this_iter_s": 30.64668297767639, "time_total_s": 6076.019745826721, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b23dfa60>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 6076.019745826721, "iterations_since_restore": 84, "perf": {"cpu_util_percent": 87.56976744186046, "ram_util_percent": 83.03488372093024}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 12.630674473507694, "cur_kl_coeff": 0.3421046018600463, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.185347931725638, "policy_loss": 0.0007586953459337117, "vf_loss": 7.183379064287458, "vf_explained_var": 0.31084250079260933, "kl": 0.003537455560633738, "entropy": 1.070214897678012, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 159705.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.39888462277434805, "cur_kl_coeff": 4.2632564145606e-15, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.2709816535313924, "policy_loss": -0.0017354515754425574, "vf_loss": 0.27271710358037754, "vf_explained_var": 0.035957722184519286, "kl": 0.012102520133958738, "entropy": 0.5812621653079987, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 159705.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 340000, "num_env_steps_trained": 340000, "num_agent_steps_sampled": 1360000, "num_agent_steps_trained": 1360000}, "env_runners": {"episode_reward_max": 377.5, "episode_reward_min": 86.29999999999998, "episode_reward_mean": 246.6099999999997, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -17.79999999999974, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 199.1, "predator_policy": 41.0}, "policy_reward_mean": {"prey_policy": 119.92999999999995, "predator_policy": 3.375}, "custom_metrics": {}, "hist_stats": {"episode_reward": [204.69999999999922, 339.6000000000003, 288.59999999999957, 255.09999999999974, 197.89999999999978, 286.5999999999999, 165.99999999999972, 330.70000000000005, 132.8999999999995, 268.0, 232.09999999999917, 337.3000000000004, 195.69999999999956, 282.9000000000002, 191.1999999999992, 298.29999999999995, 163.3999999999996, 184.1999999999993, 181.99999999999903, 246.99999999999957, 331.4, 257.19999999999993, 281.9999999999997, 273.0999999999998, 212.89999999999918, 264.49999999999955, 261.8999999999999, 221.29999999999964, 337.1999999999999, 333.20000000000005, 316.30000000000103, 201.79999999999967, 258.79999999999967, 198.4999999999992, 187.8999999999992, 166.19999999999993, 253.09999999999965, 340.60000000000025, 350.19999999999993, 313.59999999999974, 128.4999999999994, 291.10000000000036, 235.2999999999994, 235.29999999999956, 331.19999999999993, 298.20000000000005, 294.6999999999998, 319.89999999999964, 292.90000000000026, 144.90000000000003, 202.39999999999935, 376.6, 262.49999999999994, 268.5999999999997, 349.40000000000015, 365.79999999999995, 192.0999999999993, 351.0000000000001, 324.59999999999997, 141.5999999999998, 198.19999999999976, 208.59999999999994, 235.5999999999995, 301.89999999999986, 220.899999999999, 124.79999999999927, 229.8999999999996, 86.29999999999998, 119.39999999999964, 221.4999999999996, 285.70000000000084, 206.4999999999998, 212.79999999999967, 225.3999999999998, 268.59999999999957, 144.39999999999935, 134.39999999999947, 125.19999999999955, 256.0999999999998, 293.0, 289.89999999999986, 318.10000000000014, 326.20000000000005, 204.6999999999995, 238.8999999999994, 279.7999999999997, 290.19999999999993, 377.5, 330.70000000000016, 310.3999999999998, 165.89999999999932, 192.29999999999959, 150.90000000000006, 315.0000000000001, 265.89999999999986, 149.79999999999896, 212.79999999999976, 187.59999999999957, 208.79999999999924, 193.89999999999947], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 184.69999999999993, 163.9999999999999, 170.59999999999994, 113.59999999999977, 166.99999999999997, 105.50000000000006, 149.5999999999999, 139.09999999999994, 42.80000000000006, 117.19999999999996, 169.4, 58.700000000000024, 107.29999999999995, 190.10000000000002, 140.6, 31.700000000000095, 93.19999999999999, 137.0, 118.99999999999999, 80.59999999999974, 144.49999999999972, 145.99999999999997, 179.2999999999999, 56.89999999999997, 138.79999999999995, 94.10000000000005, 153.79999999999995, 41.600000000000165, 149.59999999999982, 118.99999999999996, 179.29999999999998, 18.79999999999997, 140.6, 13.699999999999964, 162.49999999999991, 160.9999999999998, 20.000000000000014, 83.9, 163.09999999999997, 156.8, 149.6, 99.19999999999999, 146.0, 166.09999999999988, 110.89999999999982, 118.09999999999957, 154.99999999999972, 75.8000000000001, 133.09999999999962, 114.7999999999999, 139.69999999999996, 95.00000000000003, 155.90000000000003, 133.39999999999995, 74.89999999999996, 157.9999999999999, 162.2, 130.39999999999995, 192.79999999999998, 190.09999999999994, 126.19999999999966, 56.00000000000006, 135.79999999999995, 74.0, 180.79999999999998, 86.60000000000014, 98.89999999999978, -0.9999999999999917, 173.89999999999992, 118.69999999999999, 30.500000000000107, 128.8999999999998, 114.19999999999987, 180.19999999999993, 160.3999999999999, 174.19999999999993, 157.99999999999997, 148.69999999999982, 164.89999999999995, 99.49999999999983, 20.000000000000014, 137.89999999999992, 153.1999999999999, 162.1999999999998, 73.10000000000005, 60.50000000000008, 174.79999999999995, 160.09999999999997, 157.1, 175.6999999999999, 117.50000000000003, 186.49999999999991, 108.19999999999985, 131.6000000000001, 188.29999999999993, 118.09999999999978, 174.8, 36.499999999999964, 97.40000000000003, 157.39999999999998, 38.00000000000014, 170.29999999999998, 197.3, 125.29999999999995, 120.19999999999993, 181.10000000000002, 84.49999999999999, 172.39999999999992, 169.99999999999997, 185.6, 180.19999999999993, -17.79999999999974, 191.89999999999995, 186.49999999999997, 153.50000000000003, 151.7, 164.89999999999998, 86.89999999999998, 49.700000000000045, 79.70000000000003, 108.49999999999986, 107.59999999999998, 80.0, 50.60000000000013, 182.0, 191.0, 110.89999999999961, 139.6999999999998, 81.20000000000002, 25.400000000000006, 73.39999999999998, 168.49999999999994, 61.4, 59.30000000000002, 20.000000000000014, 49.70000000000009, 61.70000000000014, 116.3, 99.20000000000009, 145.09999999999965, 131.59999999999974, 74.00000000000006, 132.50000000000003, 128.89999999999998, 83.90000000000006, 93.5, 122.89999999999989, 113.59999999999945, 154.99999999999977, 117.1999999999998, 27.20000000000011, 23.900000000000077, 87.49999999999966, 27.200000000000003, 91.99999999999979, 124.1, 127.99999999999989, 127.69999999999992, 161.3, 174.79999999999998, 109.09999999999978, 132.49999999999972, 185.60000000000002, 166.70000000000002, 159.49999999999997, 89.29999999999976, 115.39999999999989, 162.19999999999982, 67.69999999999997, 163.1, 100.70000000000002, 100.99999999999994, 189.19999999999996, 199.1, 178.4, 171.19999999999985, 159.49999999999983, 179.59999999999997, 123.80000000000001, 23.89999999999997, 136.99999999999986, 29.29999999999996, 154.99999999999994, -1.3000000000002654, 108.19999999999996, 154.6999999999999, 152.3, 163.09999999999994, 102.79999999999995, 82.09999999999945, 67.69999999999985, 146.89999999999998, 65.9, 145.10000000000008, 42.5000000000001, 56.30000000000015, 150.49999999999994, 165.79999999999998, 28.1], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 5.0, 8.0, 0.0, 0.0, 0.0, 11.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 12.0, 0.0, 2.0, 5.0, 12.0, 0.0, 0.0, 0.0, 13.0, 22.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 3.0, 5.0, 1.0, 0.0, 0.0, 0.0, 13.0, 12.0, 12.0, 0.0, 5.0, 0.0, 0.0, 0.0, 1.0, 3.0, 0.0, 10.0, 0.0, 11.0, 7.0, 6.0, 0.0, 17.0, 10.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 4.0, 6.0, 7.0, 7.0, 8.0, 17.0, 0.0, 0.0, 10.0, 0.0, 0.0, 7.0, 11.0, 0.0, 0.0, 1.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 14.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 7.0, 0.0, 9.0, 0.0, 0.0, 17.0, 0.0, 3.0, 0.0, 7.0, 0.0, 0.0, 18.0, 0.0, 0.0, 11.0, 8.0, 0.0, 0.0, 5.0, 5.0, 5.0, 8.0, 13.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 17.0, 9.0, 0.0, 0.0, 1.0, 6.0, 0.0, 8.0, 0.0, 6.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 2.0, 7.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 6.0, 0.0, 4.0, 4.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 4.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 5.0, 8.0, 0.0, 3.0, 41.0, 7.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 13.92116080683305, "mean_inference_ms": 30.403670930332865, "mean_action_processing_ms": 6.861011803696538, "mean_env_wait_ms": 9.163343004103906, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.008062958717346191, "StateBufferConnector_ms": 0.0072716474533081055, "ViewRequirementAgentConnector_ms": 0.30464303493499756}, "num_episodes": 22, "episode_return_max": 377.5, "episode_return_min": 86.29999999999998, "episode_return_mean": 246.6099999999997, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1360000, "num_agent_steps_trained": 1360000, "num_env_steps_sampled": 340000, "num_env_steps_trained": 340000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 129.44346668919778, "num_env_steps_trained_throughput_per_sec": 129.44346668919778, "timesteps_total": 340000, "num_env_steps_sampled_lifetime": 340000, "num_agent_steps_sampled_lifetime": 1360000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1360000, "timers": {"training_iteration_time_ms": 28487.869, "restore_workers_time_ms": 0.02, "training_step_time_ms": 28487.802, "sample_time_ms": 3664.004, "learn_time_ms": 24791.868, "learn_throughput": 161.343, "synch_weights_time_ms": 27.162}, "counters": {"num_env_steps_sampled": 340000, "num_env_steps_trained": 340000, "num_agent_steps_sampled": 1360000, "num_agent_steps_trained": 1360000}, "done": false, "training_iteration": 85, "trial_id": "75ec3_00000", "date": "2024-08-13_03-00-54", "timestamp": 1723532454, "time_this_iter_s": 30.98256492614746, "time_total_s": 6107.002310752869, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b1bbbc10>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 6107.002310752869, "iterations_since_restore": 85, "perf": {"cpu_util_percent": 88.45348837209302, "ram_util_percent": 83.21395348837208}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 20.055796289412434, "cur_kl_coeff": 0.17105230093002316, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.139176054858657, "policy_loss": 0.000834282940110714, "vf_loss": 7.136608891764646, "vf_explained_var": 0.6423799175434012, "kl": 0.010130677600174318, "entropy": 1.0586211998311301, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 161595.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5028537366677214, "cur_kl_coeff": 4.2632564145606e-15, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.4141698140237067, "policy_loss": -0.0010219157860668563, "vf_loss": 0.4151917301118374, "vf_explained_var": 0.036712503590911785, "kl": 0.005395286156933208, "entropy": 0.5584757033163908, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 161595.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 344000, "num_env_steps_trained": 344000, "num_agent_steps_sampled": 1376000, "num_agent_steps_trained": 1376000}, "env_runners": {"episode_reward_max": 377.5, "episode_reward_min": 78.59999999999982, "episode_reward_mean": 249.08499999999978, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -17.79999999999974, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 199.1, "predator_policy": 41.0}, "policy_reward_mean": {"prey_policy": 121.07749999999994, "predator_policy": 3.465}, "custom_metrics": {}, "hist_stats": {"episode_reward": [181.99999999999903, 246.99999999999957, 331.4, 257.19999999999993, 281.9999999999997, 273.0999999999998, 212.89999999999918, 264.49999999999955, 261.8999999999999, 221.29999999999964, 337.1999999999999, 333.20000000000005, 316.30000000000103, 201.79999999999967, 258.79999999999967, 198.4999999999992, 187.8999999999992, 166.19999999999993, 253.09999999999965, 340.60000000000025, 350.19999999999993, 313.59999999999974, 128.4999999999994, 291.10000000000036, 235.2999999999994, 235.29999999999956, 331.19999999999993, 298.20000000000005, 294.6999999999998, 319.89999999999964, 292.90000000000026, 144.90000000000003, 202.39999999999935, 376.6, 262.49999999999994, 268.5999999999997, 349.40000000000015, 365.79999999999995, 192.0999999999993, 351.0000000000001, 324.59999999999997, 141.5999999999998, 198.19999999999976, 208.59999999999994, 235.5999999999995, 301.89999999999986, 220.899999999999, 124.79999999999927, 229.8999999999996, 86.29999999999998, 119.39999999999964, 221.4999999999996, 285.70000000000084, 206.4999999999998, 212.79999999999967, 225.3999999999998, 268.59999999999957, 144.39999999999935, 134.39999999999947, 125.19999999999955, 256.0999999999998, 293.0, 289.89999999999986, 318.10000000000014, 326.20000000000005, 204.6999999999995, 238.8999999999994, 279.7999999999997, 290.19999999999993, 377.5, 330.70000000000016, 310.3999999999998, 165.89999999999932, 192.29999999999959, 150.90000000000006, 315.0000000000001, 265.89999999999986, 149.79999999999896, 212.79999999999976, 187.59999999999957, 208.79999999999924, 193.89999999999947, 250.49999999999977, 335.4, 262.69999999999976, 186.5999999999993, 330.8999999999999, 263.9999999999999, 236.19999999999976, 219.0999999999995, 204.99999999999923, 301.9000000000001, 166.99999999999898, 202.19999999999925, 295.60000000000076, 78.59999999999982, 304.5999999999997, 364.40000000000003, 303.29999999999984, 294.69999999999993], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [160.9999999999998, 20.000000000000014, 83.9, 163.09999999999997, 156.8, 149.6, 99.19999999999999, 146.0, 166.09999999999988, 110.89999999999982, 118.09999999999957, 154.99999999999972, 75.8000000000001, 133.09999999999962, 114.7999999999999, 139.69999999999996, 95.00000000000003, 155.90000000000003, 133.39999999999995, 74.89999999999996, 157.9999999999999, 162.2, 130.39999999999995, 192.79999999999998, 190.09999999999994, 126.19999999999966, 56.00000000000006, 135.79999999999995, 74.0, 180.79999999999998, 86.60000000000014, 98.89999999999978, -0.9999999999999917, 173.89999999999992, 118.69999999999999, 30.500000000000107, 128.8999999999998, 114.19999999999987, 180.19999999999993, 160.3999999999999, 174.19999999999993, 157.99999999999997, 148.69999999999982, 164.89999999999995, 99.49999999999983, 20.000000000000014, 137.89999999999992, 153.1999999999999, 162.1999999999998, 73.10000000000005, 60.50000000000008, 174.79999999999995, 160.09999999999997, 157.1, 175.6999999999999, 117.50000000000003, 186.49999999999991, 108.19999999999985, 131.6000000000001, 188.29999999999993, 118.09999999999978, 174.8, 36.499999999999964, 97.40000000000003, 157.39999999999998, 38.00000000000014, 170.29999999999998, 197.3, 125.29999999999995, 120.19999999999993, 181.10000000000002, 84.49999999999999, 172.39999999999992, 169.99999999999997, 185.6, 180.19999999999993, -17.79999999999974, 191.89999999999995, 186.49999999999997, 153.50000000000003, 151.7, 164.89999999999998, 86.89999999999998, 49.700000000000045, 79.70000000000003, 108.49999999999986, 107.59999999999998, 80.0, 50.60000000000013, 182.0, 191.0, 110.89999999999961, 139.6999999999998, 81.20000000000002, 25.400000000000006, 73.39999999999998, 168.49999999999994, 61.4, 59.30000000000002, 20.000000000000014, 49.70000000000009, 61.70000000000014, 116.3, 99.20000000000009, 145.09999999999965, 131.59999999999974, 74.00000000000006, 132.50000000000003, 128.89999999999998, 83.90000000000006, 93.5, 122.89999999999989, 113.59999999999945, 154.99999999999977, 117.1999999999998, 27.20000000000011, 23.900000000000077, 87.49999999999966, 27.200000000000003, 91.99999999999979, 124.1, 127.99999999999989, 127.69999999999992, 161.3, 174.79999999999998, 109.09999999999978, 132.49999999999972, 185.60000000000002, 166.70000000000002, 159.49999999999997, 89.29999999999976, 115.39999999999989, 162.19999999999982, 67.69999999999997, 163.1, 100.70000000000002, 100.99999999999994, 189.19999999999996, 199.1, 178.4, 171.19999999999985, 159.49999999999983, 179.59999999999997, 123.80000000000001, 23.89999999999997, 136.99999999999986, 29.29999999999996, 154.99999999999994, -1.3000000000002654, 108.19999999999996, 154.6999999999999, 152.3, 163.09999999999994, 102.79999999999995, 82.09999999999945, 67.69999999999985, 146.89999999999998, 65.9, 145.10000000000008, 42.5000000000001, 56.30000000000015, 150.49999999999994, 165.79999999999998, 28.1, 136.39999999999995, 100.0999999999998, 190.1, 137.29999999999995, 148.6999999999999, 98.00000000000003, 169.99999999999994, 11.599999999999964, 137.8999999999999, 185.0, 112.69999999999985, 146.3, 117.19999999999978, 118.99999999999994, 88.39999999999964, 130.69999999999987, 181.99999999999994, 20.000000000000014, 122.59999999999998, 179.29999999999998, 9.499999999999964, 150.4999999999997, 52.700000000000095, 141.49999999999977, 104.59999999999968, 190.99999999999994, 44.60000000000012, 20.000000000000014, 162.19999999999996, 133.4000000000001, 170.89999999999998, 186.49999999999991, 119.30000000000001, 163.99999999999997, 161.29999999999998, 124.39999999999995], "policy_predator_policy_reward": [1.0, 0.0, 0.0, 0.0, 13.0, 12.0, 12.0, 0.0, 5.0, 0.0, 0.0, 0.0, 1.0, 3.0, 0.0, 10.0, 0.0, 11.0, 7.0, 6.0, 0.0, 17.0, 10.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 4.0, 6.0, 7.0, 7.0, 8.0, 17.0, 0.0, 0.0, 10.0, 0.0, 0.0, 7.0, 11.0, 0.0, 0.0, 1.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 14.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 7.0, 0.0, 9.0, 0.0, 0.0, 17.0, 0.0, 3.0, 0.0, 7.0, 0.0, 0.0, 18.0, 0.0, 0.0, 11.0, 8.0, 0.0, 0.0, 5.0, 5.0, 5.0, 8.0, 13.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 17.0, 9.0, 0.0, 0.0, 1.0, 6.0, 0.0, 8.0, 0.0, 6.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 2.0, 7.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 6.0, 0.0, 4.0, 4.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 4.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 5.0, 8.0, 0.0, 3.0, 41.0, 7.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 14.0, 1.0, 7.0, 10.0, 6.0, 4.0, 1.0, 0.0, 8.0, 4.0, 1.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 5.0, 2.0, 2.0, 6.0, 0.0, 0.0, 14.0, 0.0, 0.0, 9.0, 0.0, 7.0, 9.0, 11.0, 9.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 13.79006088684294, "mean_inference_ms": 30.130597299085185, "mean_action_processing_ms": 6.794057115769449, "mean_env_wait_ms": 9.07068900627504, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.008273839950561523, "StateBufferConnector_ms": 0.007793426513671875, "ViewRequirementAgentConnector_ms": 0.32747113704681396}, "num_episodes": 18, "episode_return_max": 377.5, "episode_return_min": 78.59999999999982, "episode_return_mean": 249.08499999999978, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1376000, "num_agent_steps_trained": 1376000, "num_env_steps_sampled": 344000, "num_env_steps_trained": 344000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 131.15406453267568, "num_env_steps_trained_throughput_per_sec": 131.15406453267568, "timesteps_total": 344000, "num_env_steps_sampled_lifetime": 344000, "num_agent_steps_sampled_lifetime": 1376000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1376000, "timers": {"training_iteration_time_ms": 28889.726, "restore_workers_time_ms": 0.02, "training_step_time_ms": 28889.659, "sample_time_ms": 3673.299, "learn_time_ms": 25185.636, "learn_throughput": 158.821, "synch_weights_time_ms": 25.909}, "counters": {"num_env_steps_sampled": 344000, "num_env_steps_trained": 344000, "num_agent_steps_sampled": 1376000, "num_agent_steps_trained": 1376000}, "done": false, "training_iteration": 86, "trial_id": "75ec3_00000", "date": "2024-08-13_03-01-24", "timestamp": 1723532484, "time_this_iter_s": 30.57072377204895, "time_total_s": 6137.573034524918, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2058940>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 6137.573034524918, "iterations_since_restore": 86, "perf": {"cpu_util_percent": 87.40227272727272, "ram_util_percent": 83.10681818181818}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 15.385400656732932, "cur_kl_coeff": 0.17105230093002316, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.785428113029116, "policy_loss": -0.005089078318061573, "vf_loss": 7.788642520753164, "vf_explained_var": 0.2593933537208214, "kl": 0.010959434158099149, "entropy": 1.0494109352429708, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 163485.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6566622642218751, "cur_kl_coeff": 4.2632564145606e-15, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.5749564427074301, "policy_loss": -0.0015409693484091096, "vf_loss": 0.5764974108527577, "vf_explained_var": 0.009487976125939183, "kl": 0.0036241121791509936, "entropy": 0.5588223022600961, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 163485.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 348000, "num_env_steps_trained": 348000, "num_agent_steps_sampled": 1392000, "num_agent_steps_trained": 1392000}, "env_runners": {"episode_reward_max": 377.5, "episode_reward_min": 74.20000000000005, "episode_reward_mean": 238.1999999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -17.79999999999974, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 199.1, "predator_policy": 41.0}, "policy_reward_mean": {"prey_policy": 115.77499999999995, "predator_policy": 3.325}, "custom_metrics": {}, "hist_stats": {"episode_reward": [291.10000000000036, 235.2999999999994, 235.29999999999956, 331.19999999999993, 298.20000000000005, 294.6999999999998, 319.89999999999964, 292.90000000000026, 144.90000000000003, 202.39999999999935, 376.6, 262.49999999999994, 268.5999999999997, 349.40000000000015, 365.79999999999995, 192.0999999999993, 351.0000000000001, 324.59999999999997, 141.5999999999998, 198.19999999999976, 208.59999999999994, 235.5999999999995, 301.89999999999986, 220.899999999999, 124.79999999999927, 229.8999999999996, 86.29999999999998, 119.39999999999964, 221.4999999999996, 285.70000000000084, 206.4999999999998, 212.79999999999967, 225.3999999999998, 268.59999999999957, 144.39999999999935, 134.39999999999947, 125.19999999999955, 256.0999999999998, 293.0, 289.89999999999986, 318.10000000000014, 326.20000000000005, 204.6999999999995, 238.8999999999994, 279.7999999999997, 290.19999999999993, 377.5, 330.70000000000016, 310.3999999999998, 165.89999999999932, 192.29999999999959, 150.90000000000006, 315.0000000000001, 265.89999999999986, 149.79999999999896, 212.79999999999976, 187.59999999999957, 208.79999999999924, 193.89999999999947, 250.49999999999977, 335.4, 262.69999999999976, 186.5999999999993, 330.8999999999999, 263.9999999999999, 236.19999999999976, 219.0999999999995, 204.99999999999923, 301.9000000000001, 166.99999999999898, 202.19999999999925, 295.60000000000076, 78.59999999999982, 304.5999999999997, 364.40000000000003, 303.29999999999984, 294.69999999999993, 311.19999999999993, 222.39999999999955, 165.9999999999998, 281.0, 364.00000000000034, 159.1999999999993, 166.09999999999968, 252.39999999999952, 125.20000000000003, 193.4999999999995, 222.3999999999999, 170.49999999999937, 238.89999999999958, 211.89999999999944, 145.29999999999922, 189.89999999999924, 219.49999999999955, 192.8999999999994, 221.79999999999947, 236.59999999999923, 74.20000000000005, 138.0999999999996, 327.70000000000005], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [137.89999999999992, 153.1999999999999, 162.1999999999998, 73.10000000000005, 60.50000000000008, 174.79999999999995, 160.09999999999997, 157.1, 175.6999999999999, 117.50000000000003, 186.49999999999991, 108.19999999999985, 131.6000000000001, 188.29999999999993, 118.09999999999978, 174.8, 36.499999999999964, 97.40000000000003, 157.39999999999998, 38.00000000000014, 170.29999999999998, 197.3, 125.29999999999995, 120.19999999999993, 181.10000000000002, 84.49999999999999, 172.39999999999992, 169.99999999999997, 185.6, 180.19999999999993, -17.79999999999974, 191.89999999999995, 186.49999999999997, 153.50000000000003, 151.7, 164.89999999999998, 86.89999999999998, 49.700000000000045, 79.70000000000003, 108.49999999999986, 107.59999999999998, 80.0, 50.60000000000013, 182.0, 191.0, 110.89999999999961, 139.6999999999998, 81.20000000000002, 25.400000000000006, 73.39999999999998, 168.49999999999994, 61.4, 59.30000000000002, 20.000000000000014, 49.70000000000009, 61.70000000000014, 116.3, 99.20000000000009, 145.09999999999965, 131.59999999999974, 74.00000000000006, 132.50000000000003, 128.89999999999998, 83.90000000000006, 93.5, 122.89999999999989, 113.59999999999945, 154.99999999999977, 117.1999999999998, 27.20000000000011, 23.900000000000077, 87.49999999999966, 27.200000000000003, 91.99999999999979, 124.1, 127.99999999999989, 127.69999999999992, 161.3, 174.79999999999998, 109.09999999999978, 132.49999999999972, 185.60000000000002, 166.70000000000002, 159.49999999999997, 89.29999999999976, 115.39999999999989, 162.19999999999982, 67.69999999999997, 163.1, 100.70000000000002, 100.99999999999994, 189.19999999999996, 199.1, 178.4, 171.19999999999985, 159.49999999999983, 179.59999999999997, 123.80000000000001, 23.89999999999997, 136.99999999999986, 29.29999999999996, 154.99999999999994, -1.3000000000002654, 108.19999999999996, 154.6999999999999, 152.3, 163.09999999999994, 102.79999999999995, 82.09999999999945, 67.69999999999985, 146.89999999999998, 65.9, 145.10000000000008, 42.5000000000001, 56.30000000000015, 150.49999999999994, 165.79999999999998, 28.1, 136.39999999999995, 100.0999999999998, 190.1, 137.29999999999995, 148.6999999999999, 98.00000000000003, 169.99999999999994, 11.599999999999964, 137.8999999999999, 185.0, 112.69999999999985, 146.3, 117.19999999999978, 118.99999999999994, 88.39999999999964, 130.69999999999987, 181.99999999999994, 20.000000000000014, 122.59999999999998, 179.29999999999998, 9.499999999999964, 150.4999999999997, 52.700000000000095, 141.49999999999977, 104.59999999999968, 190.99999999999994, 44.60000000000012, 20.000000000000014, 162.19999999999996, 133.4000000000001, 170.89999999999998, 186.49999999999991, 119.30000000000001, 163.99999999999997, 161.29999999999998, 124.39999999999995, 170.29999999999998, 128.89999999999992, 128.0, 70.40000000000009, 118.1, 47.89999999999997, 125.29999999999998, 154.69999999999996, 183.7999999999999, 180.1999999999999, 28.69999999999998, 96.49999999999979, 70.39999999999998, 73.69999999999985, 185.59999999999997, 66.8, 45.19999999999999, 77.00000000000003, 25.999999999999964, 147.49999999999994, 152.3, 64.10000000000001, 48.79999999999997, 121.69999999999975, 176.59999999999997, 62.30000000000005, 93.80000000000007, 118.10000000000002, 125.29999999999984, 20.000000000000014, 15.799999999999962, 172.09999999999994, 40.399999999999984, 172.09999999999994, 20.000000000000014, 167.89999999999998, 59.600000000000115, 162.19999999999987, 55.70000000000018, 173.89999999999992, 32.60000000000002, 32.599999999999994, -4.299999999999841, 124.39999999999989, 190.99999999999997, 130.7], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 14.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 7.0, 0.0, 9.0, 0.0, 0.0, 17.0, 0.0, 3.0, 0.0, 7.0, 0.0, 0.0, 18.0, 0.0, 0.0, 11.0, 8.0, 0.0, 0.0, 5.0, 5.0, 5.0, 8.0, 13.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 17.0, 9.0, 0.0, 0.0, 1.0, 6.0, 0.0, 8.0, 0.0, 6.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 2.0, 7.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 6.0, 0.0, 4.0, 4.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 4.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 5.0, 8.0, 0.0, 3.0, 41.0, 7.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 14.0, 1.0, 7.0, 10.0, 6.0, 4.0, 1.0, 0.0, 8.0, 4.0, 1.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 5.0, 2.0, 2.0, 6.0, 0.0, 0.0, 14.0, 0.0, 0.0, 9.0, 0.0, 7.0, 9.0, 11.0, 9.0, 0.0, 10.0, 2.0, 0.0, 24.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 3.0, 31.0, 10.0, 12.0, 0.0, 0.0, 1.0, 2.0, 13.0, 7.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 7.0, 0.0, 5.0, 0.0, 0.0, 7.0, 0.0, 0.0, 9.0, 6.0, 12.0, 6.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 13.633337238918335, "mean_inference_ms": 29.777276082312934, "mean_action_processing_ms": 6.698179169288708, "mean_env_wait_ms": 8.980585500676165, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.008377552032470703, "StateBufferConnector_ms": 0.013359904289245605, "ViewRequirementAgentConnector_ms": 0.330630898475647}, "num_episodes": 23, "episode_return_max": 377.5, "episode_return_min": 74.20000000000005, "episode_return_mean": 238.1999999999998, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1392000, "num_agent_steps_trained": 1392000, "num_env_steps_sampled": 348000, "num_env_steps_trained": 348000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 132.68881528754144, "num_env_steps_trained_throughput_per_sec": 132.68881528754144, "timesteps_total": 348000, "num_env_steps_sampled_lifetime": 348000, "num_agent_steps_sampled_lifetime": 1392000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1392000, "timers": {"training_iteration_time_ms": 29241.85, "restore_workers_time_ms": 0.02, "training_step_time_ms": 29241.783, "sample_time_ms": 3828.746, "learn_time_ms": 25384.601, "learn_throughput": 157.576, "synch_weights_time_ms": 23.573}, "counters": {"num_env_steps_sampled": 348000, "num_env_steps_trained": 348000, "num_agent_steps_sampled": 1392000, "num_agent_steps_trained": 1392000}, "done": false, "training_iteration": 87, "trial_id": "75ec3_00000", "date": "2024-08-13_03-01-54", "timestamp": 1723532514, "time_this_iter_s": 30.19986605644226, "time_total_s": 6167.77290058136, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b23dfa60>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 6167.77290058136, "iterations_since_restore": 87, "perf": {"cpu_util_percent": 88.46190476190476, "ram_util_percent": 83.0}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 13.718317666160997, "cur_kl_coeff": 0.17105230093002316, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.093822748698885, "policy_loss": -0.0014111032822814883, "vf_loss": 8.09481096368618, "vf_explained_var": 0.2222397825389943, "kl": 0.002472199259199182, "entropy": 1.047563120549318, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 165375.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.37041952259710464, "cur_kl_coeff": 2.1316282072803e-15, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.23876032051901339, "policy_loss": -0.0004044357049106448, "vf_loss": 0.23916475544314061, "vf_explained_var": 0.022898752222616205, "kl": 0.0028164156638628922, "entropy": 0.6497719912617295, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 165375.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 352000, "num_env_steps_trained": 352000, "num_agent_steps_sampled": 1408000, "num_agent_steps_trained": 1408000}, "env_runners": {"episode_reward_max": 377.5, "episode_reward_min": 74.20000000000005, "episode_reward_mean": 227.03699999999972, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -4.299999999999841, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 199.1, "predator_policy": 41.0}, "policy_reward_mean": {"prey_policy": 110.14849999999996, "predator_policy": 3.37}, "custom_metrics": {}, "hist_stats": {"episode_reward": [141.5999999999998, 198.19999999999976, 208.59999999999994, 235.5999999999995, 301.89999999999986, 220.899999999999, 124.79999999999927, 229.8999999999996, 86.29999999999998, 119.39999999999964, 221.4999999999996, 285.70000000000084, 206.4999999999998, 212.79999999999967, 225.3999999999998, 268.59999999999957, 144.39999999999935, 134.39999999999947, 125.19999999999955, 256.0999999999998, 293.0, 289.89999999999986, 318.10000000000014, 326.20000000000005, 204.6999999999995, 238.8999999999994, 279.7999999999997, 290.19999999999993, 377.5, 330.70000000000016, 310.3999999999998, 165.89999999999932, 192.29999999999959, 150.90000000000006, 315.0000000000001, 265.89999999999986, 149.79999999999896, 212.79999999999976, 187.59999999999957, 208.79999999999924, 193.89999999999947, 250.49999999999977, 335.4, 262.69999999999976, 186.5999999999993, 330.8999999999999, 263.9999999999999, 236.19999999999976, 219.0999999999995, 204.99999999999923, 301.9000000000001, 166.99999999999898, 202.19999999999925, 295.60000000000076, 78.59999999999982, 304.5999999999997, 364.40000000000003, 303.29999999999984, 294.69999999999993, 311.19999999999993, 222.39999999999955, 165.9999999999998, 281.0, 364.00000000000034, 159.1999999999993, 166.09999999999968, 252.39999999999952, 125.20000000000003, 193.4999999999995, 222.3999999999999, 170.49999999999937, 238.89999999999958, 211.89999999999944, 145.29999999999922, 189.89999999999924, 219.49999999999955, 192.8999999999994, 221.79999999999947, 236.59999999999923, 74.20000000000005, 138.0999999999996, 327.70000000000005, 176.8999999999993, 222.59999999999954, 220.89999999999932, 213.2999999999996, 189.09999999999937, 223.39999999999938, 136.59999999999994, 251.99999999999977, 122.99999999999989, 174.0999999999993, 246.8999999999994, 243.5999999999996, 296.5000000000013, 260.4999999999996, 234.4000000000001, 185.49999999999946, 293.79999999999995, 327.0999999999998], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [86.89999999999998, 49.700000000000045, 79.70000000000003, 108.49999999999986, 107.59999999999998, 80.0, 50.60000000000013, 182.0, 191.0, 110.89999999999961, 139.6999999999998, 81.20000000000002, 25.400000000000006, 73.39999999999998, 168.49999999999994, 61.4, 59.30000000000002, 20.000000000000014, 49.70000000000009, 61.70000000000014, 116.3, 99.20000000000009, 145.09999999999965, 131.59999999999974, 74.00000000000006, 132.50000000000003, 128.89999999999998, 83.90000000000006, 93.5, 122.89999999999989, 113.59999999999945, 154.99999999999977, 117.1999999999998, 27.20000000000011, 23.900000000000077, 87.49999999999966, 27.200000000000003, 91.99999999999979, 124.1, 127.99999999999989, 127.69999999999992, 161.3, 174.79999999999998, 109.09999999999978, 132.49999999999972, 185.60000000000002, 166.70000000000002, 159.49999999999997, 89.29999999999976, 115.39999999999989, 162.19999999999982, 67.69999999999997, 163.1, 100.70000000000002, 100.99999999999994, 189.19999999999996, 199.1, 178.4, 171.19999999999985, 159.49999999999983, 179.59999999999997, 123.80000000000001, 23.89999999999997, 136.99999999999986, 29.29999999999996, 154.99999999999994, -1.3000000000002654, 108.19999999999996, 154.6999999999999, 152.3, 163.09999999999994, 102.79999999999995, 82.09999999999945, 67.69999999999985, 146.89999999999998, 65.9, 145.10000000000008, 42.5000000000001, 56.30000000000015, 150.49999999999994, 165.79999999999998, 28.1, 136.39999999999995, 100.0999999999998, 190.1, 137.29999999999995, 148.6999999999999, 98.00000000000003, 169.99999999999994, 11.599999999999964, 137.8999999999999, 185.0, 112.69999999999985, 146.3, 117.19999999999978, 118.99999999999994, 88.39999999999964, 130.69999999999987, 181.99999999999994, 20.000000000000014, 122.59999999999998, 179.29999999999998, 9.499999999999964, 150.4999999999997, 52.700000000000095, 141.49999999999977, 104.59999999999968, 190.99999999999994, 44.60000000000012, 20.000000000000014, 162.19999999999996, 133.4000000000001, 170.89999999999998, 186.49999999999991, 119.30000000000001, 163.99999999999997, 161.29999999999998, 124.39999999999995, 170.29999999999998, 128.89999999999992, 128.0, 70.40000000000009, 118.1, 47.89999999999997, 125.29999999999998, 154.69999999999996, 183.7999999999999, 180.1999999999999, 28.69999999999998, 96.49999999999979, 70.39999999999998, 73.69999999999985, 185.59999999999997, 66.8, 45.19999999999999, 77.00000000000003, 25.999999999999964, 147.49999999999994, 152.3, 64.10000000000001, 48.79999999999997, 121.69999999999975, 176.59999999999997, 62.30000000000005, 93.80000000000007, 118.10000000000002, 125.29999999999984, 20.000000000000014, 15.799999999999962, 172.09999999999994, 40.399999999999984, 172.09999999999994, 20.000000000000014, 167.89999999999998, 59.600000000000115, 162.19999999999987, 55.70000000000018, 173.89999999999992, 32.60000000000002, 32.599999999999994, -4.299999999999841, 124.39999999999989, 190.99999999999997, 130.7, 22.100000000000062, 138.8, 147.19999999999993, 61.400000000000055, 117.19999999999993, 103.69999999999943, 77.6000000000002, 124.69999999999997, 23.600000000000048, 159.49999999999986, 81.2000000000001, 132.1999999999999, 47.000000000000014, 86.6, 101.89999999999995, 139.0999999999999, 83.89999999999996, 31.10000000000009, 20.000000000000014, 154.0999999999999, 156.79999999999987, 88.09999999999991, 61.10000000000011, 159.49999999999994, 137.89999999999966, 158.5999999999999, 153.19999999999987, 107.30000000000007, 111.79999999999993, 122.60000000000008, 9.200000000000086, 161.29999999999987, 139.69999999999965, 154.1, 149.59999999999982, 177.49999999999986], "policy_predator_policy_reward": [0.0, 5.0, 5.0, 5.0, 8.0, 13.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 17.0, 9.0, 0.0, 0.0, 1.0, 6.0, 0.0, 8.0, 0.0, 6.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 2.0, 7.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 6.0, 0.0, 4.0, 4.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 4.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 5.0, 8.0, 0.0, 3.0, 41.0, 7.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 14.0, 1.0, 7.0, 10.0, 6.0, 4.0, 1.0, 0.0, 8.0, 4.0, 1.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 5.0, 2.0, 2.0, 6.0, 0.0, 0.0, 14.0, 0.0, 0.0, 9.0, 0.0, 7.0, 9.0, 11.0, 9.0, 0.0, 10.0, 2.0, 0.0, 24.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 3.0, 31.0, 10.0, 12.0, 0.0, 0.0, 1.0, 2.0, 13.0, 7.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 7.0, 0.0, 5.0, 0.0, 0.0, 7.0, 0.0, 0.0, 9.0, 6.0, 12.0, 6.0, 0.0, 0.0, 16.0, 5.0, 9.0, 0.0, 0.0, 11.0, 0.0, 0.0, 6.0, 0.0, 10.0, 0.0, 3.0, 8.0, 3.0, 0.0, 8.0, 0.0, 0.0, 1.0, 1.0, 13.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 12.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 13.509652892782618, "mean_inference_ms": 29.520609419353015, "mean_action_processing_ms": 6.634966429922509, "mean_env_wait_ms": 8.892823592134597, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.008627176284790039, "StateBufferConnector_ms": 0.013523101806640625, "ViewRequirementAgentConnector_ms": 0.31268310546875}, "num_episodes": 18, "episode_return_max": 377.5, "episode_return_min": 74.20000000000005, "episode_return_mean": 227.03699999999972, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1408000, "num_agent_steps_trained": 1408000, "num_env_steps_sampled": 352000, "num_env_steps_trained": 352000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 128.74541248215252, "num_env_steps_trained_throughput_per_sec": 128.74541248215252, "timesteps_total": 352000, "num_env_steps_sampled_lifetime": 352000, "num_agent_steps_sampled_lifetime": 1408000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1408000, "timers": {"training_iteration_time_ms": 29513.637, "restore_workers_time_ms": 0.02, "training_step_time_ms": 29513.571, "sample_time_ms": 3939.164, "learn_time_ms": 25544.779, "learn_throughput": 156.588, "synch_weights_time_ms": 24.59}, "counters": {"num_env_steps_sampled": 352000, "num_env_steps_trained": 352000, "num_agent_steps_sampled": 1408000, "num_agent_steps_trained": 1408000}, "done": false, "training_iteration": 88, "trial_id": "75ec3_00000", "date": "2024-08-13_03-02-26", "timestamp": 1723532546, "time_this_iter_s": 31.161618947982788, "time_total_s": 6198.934519529343, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b209c4c0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 6198.934519529343, "iterations_since_restore": 88, "perf": {"cpu_util_percent": 87.99545454545455, "ram_util_percent": 83.19090909090907}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 9.25202638891639, "cur_kl_coeff": 0.08552615046501158, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.30767466201984, "policy_loss": -0.007107887434447923, "vf_loss": 7.312489228021531, "vf_explained_var": 0.1937547648079181, "kl": 0.026814079693699255, "entropy": 1.0206264160297536, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 167265.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.21738791845581204, "cur_kl_coeff": 1.06581410364015e-15, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.12879732928913895, "policy_loss": -0.0016856140040708756, "vf_loss": 0.13048294318800488, "vf_explained_var": -0.08301830641807072, "kl": 0.00829961953425833, "entropy": 0.5120622841927109, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 167265.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 356000, "num_env_steps_trained": 356000, "num_agent_steps_sampled": 1424000, "num_agent_steps_trained": 1424000}, "env_runners": {"episode_reward_max": 377.5, "episode_reward_min": 74.20000000000005, "episode_reward_mean": 241.73299999999978, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -4.299999999999841, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 199.1, "predator_policy": 41.0}, "policy_reward_mean": {"prey_policy": 117.80149999999995, "predator_policy": 3.065}, "custom_metrics": {}, "hist_stats": {"episode_reward": [318.10000000000014, 326.20000000000005, 204.6999999999995, 238.8999999999994, 279.7999999999997, 290.19999999999993, 377.5, 330.70000000000016, 310.3999999999998, 165.89999999999932, 192.29999999999959, 150.90000000000006, 315.0000000000001, 265.89999999999986, 149.79999999999896, 212.79999999999976, 187.59999999999957, 208.79999999999924, 193.89999999999947, 250.49999999999977, 335.4, 262.69999999999976, 186.5999999999993, 330.8999999999999, 263.9999999999999, 236.19999999999976, 219.0999999999995, 204.99999999999923, 301.9000000000001, 166.99999999999898, 202.19999999999925, 295.60000000000076, 78.59999999999982, 304.5999999999997, 364.40000000000003, 303.29999999999984, 294.69999999999993, 311.19999999999993, 222.39999999999955, 165.9999999999998, 281.0, 364.00000000000034, 159.1999999999993, 166.09999999999968, 252.39999999999952, 125.20000000000003, 193.4999999999995, 222.3999999999999, 170.49999999999937, 238.89999999999958, 211.89999999999944, 145.29999999999922, 189.89999999999924, 219.49999999999955, 192.8999999999994, 221.79999999999947, 236.59999999999923, 74.20000000000005, 138.0999999999996, 327.70000000000005, 176.8999999999993, 222.59999999999954, 220.89999999999932, 213.2999999999996, 189.09999999999937, 223.39999999999938, 136.59999999999994, 251.99999999999977, 122.99999999999989, 174.0999999999993, 246.8999999999994, 243.5999999999996, 296.5000000000013, 260.4999999999996, 234.4000000000001, 185.49999999999946, 293.79999999999995, 327.0999999999998, 155.19999999999922, 357.69999999999993, 326.200000000001, 307.29999999999984, 196.29999999999936, 320.79999999999984, 346.30000000000007, 265.0999999999999, 319.0000000000001, 300.2999999999998, 313.70000000000056, 194.79999999999953, 341.5000000000003, 281.1999999999995, 184.89999999999995, 138.99999999999946, 348.4999999999999, 317.6000000000002, 283.9, 289.29999999999984, 108.00000000000013, 303.7], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [132.49999999999972, 185.60000000000002, 166.70000000000002, 159.49999999999997, 89.29999999999976, 115.39999999999989, 162.19999999999982, 67.69999999999997, 163.1, 100.70000000000002, 100.99999999999994, 189.19999999999996, 199.1, 178.4, 171.19999999999985, 159.49999999999983, 179.59999999999997, 123.80000000000001, 23.89999999999997, 136.99999999999986, 29.29999999999996, 154.99999999999994, -1.3000000000002654, 108.19999999999996, 154.6999999999999, 152.3, 163.09999999999994, 102.79999999999995, 82.09999999999945, 67.69999999999985, 146.89999999999998, 65.9, 145.10000000000008, 42.5000000000001, 56.30000000000015, 150.49999999999994, 165.79999999999998, 28.1, 136.39999999999995, 100.0999999999998, 190.1, 137.29999999999995, 148.6999999999999, 98.00000000000003, 169.99999999999994, 11.599999999999964, 137.8999999999999, 185.0, 112.69999999999985, 146.3, 117.19999999999978, 118.99999999999994, 88.39999999999964, 130.69999999999987, 181.99999999999994, 20.000000000000014, 122.59999999999998, 179.29999999999998, 9.499999999999964, 150.4999999999997, 52.700000000000095, 141.49999999999977, 104.59999999999968, 190.99999999999994, 44.60000000000012, 20.000000000000014, 162.19999999999996, 133.4000000000001, 170.89999999999998, 186.49999999999991, 119.30000000000001, 163.99999999999997, 161.29999999999998, 124.39999999999995, 170.29999999999998, 128.89999999999992, 128.0, 70.40000000000009, 118.1, 47.89999999999997, 125.29999999999998, 154.69999999999996, 183.7999999999999, 180.1999999999999, 28.69999999999998, 96.49999999999979, 70.39999999999998, 73.69999999999985, 185.59999999999997, 66.8, 45.19999999999999, 77.00000000000003, 25.999999999999964, 147.49999999999994, 152.3, 64.10000000000001, 48.79999999999997, 121.69999999999975, 176.59999999999997, 62.30000000000005, 93.80000000000007, 118.10000000000002, 125.29999999999984, 20.000000000000014, 15.799999999999962, 172.09999999999994, 40.399999999999984, 172.09999999999994, 20.000000000000014, 167.89999999999998, 59.600000000000115, 162.19999999999987, 55.70000000000018, 173.89999999999992, 32.60000000000002, 32.599999999999994, -4.299999999999841, 124.39999999999989, 190.99999999999997, 130.7, 22.100000000000062, 138.8, 147.19999999999993, 61.400000000000055, 117.19999999999993, 103.69999999999943, 77.6000000000002, 124.69999999999997, 23.600000000000048, 159.49999999999986, 81.2000000000001, 132.1999999999999, 47.000000000000014, 86.6, 101.89999999999995, 139.0999999999999, 83.89999999999996, 31.10000000000009, 20.000000000000014, 154.0999999999999, 156.79999999999987, 88.09999999999991, 61.10000000000011, 159.49999999999994, 137.89999999999966, 158.5999999999999, 153.19999999999987, 107.30000000000007, 111.79999999999993, 122.60000000000008, 9.200000000000086, 161.29999999999987, 139.69999999999965, 154.1, 149.59999999999982, 177.49999999999986, 108.1999999999997, 47.00000000000015, 196.4, 161.29999999999993, 137.89999999999975, 188.3, 174.79999999999984, 132.50000000000003, 22.700000000000095, 158.59999999999985, 134.29999999999973, 186.49999999999991, 169.39999999999992, 173.89999999999986, 112.39999999999995, 139.69999999999993, 149.5999999999998, 169.4, 149.59999999999988, 142.69999999999996, 157.3999999999999, 143.29999999999995, 114.49999999999964, 71.29999999999998, 179.2999999999999, 162.1999999999999, 107.2999999999996, 173.89999999999986, 109.10000000000005, 75.79999999999993, 20.000000000000014, 118.99999999999989, 167.59999999999997, 173.89999999999998, 158.29999999999993, 152.3, 160.39999999999986, 123.49999999999993, 131.60000000000005, 157.6999999999999, 27.50000000000005, 69.50000000000017, 179.2999999999999, 124.39999999999989], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 4.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 5.0, 8.0, 0.0, 3.0, 41.0, 7.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 14.0, 1.0, 7.0, 10.0, 6.0, 4.0, 1.0, 0.0, 8.0, 4.0, 1.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 5.0, 2.0, 2.0, 6.0, 0.0, 0.0, 14.0, 0.0, 0.0, 9.0, 0.0, 7.0, 9.0, 11.0, 9.0, 0.0, 10.0, 2.0, 0.0, 24.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 3.0, 31.0, 10.0, 12.0, 0.0, 0.0, 1.0, 2.0, 13.0, 7.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 7.0, 0.0, 5.0, 0.0, 0.0, 7.0, 0.0, 0.0, 9.0, 6.0, 12.0, 6.0, 0.0, 0.0, 16.0, 5.0, 9.0, 0.0, 0.0, 11.0, 0.0, 0.0, 6.0, 0.0, 10.0, 0.0, 3.0, 8.0, 3.0, 0.0, 8.0, 0.0, 0.0, 1.0, 1.0, 13.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 15.0, 0.0, 0.0, 0.0, 3.0, 0.0, 13.0, 0.0, 0.0, 8.0, 0.0, 4.0, 9.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 13.634820035585319, "mean_inference_ms": 29.19250558508289, "mean_action_processing_ms": 6.324110650853895, "mean_env_wait_ms": 8.79984789527261, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.010634541511535645, "StateBufferConnector_ms": 0.013576745986938477, "ViewRequirementAgentConnector_ms": 0.3291795253753662}, "num_episodes": 22, "episode_return_max": 377.5, "episode_return_min": 74.20000000000005, "episode_return_mean": 241.73299999999978, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1424000, "num_agent_steps_trained": 1424000, "num_env_steps_sampled": 356000, "num_env_steps_trained": 356000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 130.4487464633232, "num_env_steps_trained_throughput_per_sec": 130.4487464633232, "timesteps_total": 356000, "num_env_steps_sampled_lifetime": 356000, "num_agent_steps_sampled_lifetime": 1424000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1424000, "timers": {"training_iteration_time_ms": 29836.591, "restore_workers_time_ms": 0.021, "training_step_time_ms": 29836.521, "sample_time_ms": 4145.627, "learn_time_ms": 25660.344, "learn_throughput": 155.883, "synch_weights_time_ms": 25.432}, "counters": {"num_env_steps_sampled": 356000, "num_env_steps_trained": 356000, "num_agent_steps_sampled": 1424000, "num_agent_steps_trained": 1424000}, "done": false, "training_iteration": 89, "trial_id": "75ec3_00000", "date": "2024-08-13_03-02-57", "timestamp": 1723532577, "time_this_iter_s": 30.7354838848114, "time_total_s": 6229.670003414154, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b206b160>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 6229.670003414154, "iterations_since_restore": 89, "perf": {"cpu_util_percent": 87.7159090909091, "ram_util_percent": 83.25681818181819}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 13.82820281080468, "cur_kl_coeff": 0.1282892256975174, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.572900105531884, "policy_loss": -0.011049669045738127, "vf_loss": 8.58071314115373, "vf_explained_var": 0.2458462455600658, "kl": 0.025229250846318326, "entropy": 1.0304190787373397, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 169155.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6207833076891287, "cur_kl_coeff": 1.06581410364015e-15, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.86129198332943, "policy_loss": -0.002067561814482644, "vf_loss": 1.8633595480805352, "vf_explained_var": 9.93601228824999e-05, "kl": 0.006000605333873733, "entropy": 0.4078479853572038, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 169155.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 360000, "num_env_steps_trained": 360000, "num_agent_steps_sampled": 1440000, "num_agent_steps_trained": 1440000}, "env_runners": {"episode_reward_max": 364.40000000000003, "episode_reward_min": 67.10000000000025, "episode_reward_mean": 240.48199999999974, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -141.7000000000003, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 196.4, "predator_policy": 64.0}, "policy_reward_mean": {"prey_policy": 116.18599999999995, "predator_policy": 4.055}, "custom_metrics": {}, "hist_stats": {"episode_reward": [193.89999999999947, 250.49999999999977, 335.4, 262.69999999999976, 186.5999999999993, 330.8999999999999, 263.9999999999999, 236.19999999999976, 219.0999999999995, 204.99999999999923, 301.9000000000001, 166.99999999999898, 202.19999999999925, 295.60000000000076, 78.59999999999982, 304.5999999999997, 364.40000000000003, 303.29999999999984, 294.69999999999993, 311.19999999999993, 222.39999999999955, 165.9999999999998, 281.0, 364.00000000000034, 159.1999999999993, 166.09999999999968, 252.39999999999952, 125.20000000000003, 193.4999999999995, 222.3999999999999, 170.49999999999937, 238.89999999999958, 211.89999999999944, 145.29999999999922, 189.89999999999924, 219.49999999999955, 192.8999999999994, 221.79999999999947, 236.59999999999923, 74.20000000000005, 138.0999999999996, 327.70000000000005, 176.8999999999993, 222.59999999999954, 220.89999999999932, 213.2999999999996, 189.09999999999937, 223.39999999999938, 136.59999999999994, 251.99999999999977, 122.99999999999989, 174.0999999999993, 246.8999999999994, 243.5999999999996, 296.5000000000013, 260.4999999999996, 234.4000000000001, 185.49999999999946, 293.79999999999995, 327.0999999999998, 155.19999999999922, 357.69999999999993, 326.200000000001, 307.29999999999984, 196.29999999999936, 320.79999999999984, 346.30000000000007, 265.0999999999999, 319.0000000000001, 300.2999999999998, 313.70000000000056, 194.79999999999953, 341.5000000000003, 281.1999999999995, 184.89999999999995, 138.99999999999946, 348.4999999999999, 317.6000000000002, 283.9, 289.29999999999984, 108.00000000000013, 303.7, 192.1999999999991, 256.6999999999998, 67.10000000000025, 303.7000000000003, 145.3999999999996, 287.5999999999997, 318.9000000000003, 109.79999999999963, 328.30000000000024, 314.6, 299.9999999999999, 251.4999999999995, 300.79999999999995, 119.89999999999972, 272.29999999999995, 219.79999999999944, 322.60000000000025, 289.19999999999993], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [165.79999999999998, 28.1, 136.39999999999995, 100.0999999999998, 190.1, 137.29999999999995, 148.6999999999999, 98.00000000000003, 169.99999999999994, 11.599999999999964, 137.8999999999999, 185.0, 112.69999999999985, 146.3, 117.19999999999978, 118.99999999999994, 88.39999999999964, 130.69999999999987, 181.99999999999994, 20.000000000000014, 122.59999999999998, 179.29999999999998, 9.499999999999964, 150.4999999999997, 52.700000000000095, 141.49999999999977, 104.59999999999968, 190.99999999999994, 44.60000000000012, 20.000000000000014, 162.19999999999996, 133.4000000000001, 170.89999999999998, 186.49999999999991, 119.30000000000001, 163.99999999999997, 161.29999999999998, 124.39999999999995, 170.29999999999998, 128.89999999999992, 128.0, 70.40000000000009, 118.1, 47.89999999999997, 125.29999999999998, 154.69999999999996, 183.7999999999999, 180.1999999999999, 28.69999999999998, 96.49999999999979, 70.39999999999998, 73.69999999999985, 185.59999999999997, 66.8, 45.19999999999999, 77.00000000000003, 25.999999999999964, 147.49999999999994, 152.3, 64.10000000000001, 48.79999999999997, 121.69999999999975, 176.59999999999997, 62.30000000000005, 93.80000000000007, 118.10000000000002, 125.29999999999984, 20.000000000000014, 15.799999999999962, 172.09999999999994, 40.399999999999984, 172.09999999999994, 20.000000000000014, 167.89999999999998, 59.600000000000115, 162.19999999999987, 55.70000000000018, 173.89999999999992, 32.60000000000002, 32.599999999999994, -4.299999999999841, 124.39999999999989, 190.99999999999997, 130.7, 22.100000000000062, 138.8, 147.19999999999993, 61.400000000000055, 117.19999999999993, 103.69999999999943, 77.6000000000002, 124.69999999999997, 23.600000000000048, 159.49999999999986, 81.2000000000001, 132.1999999999999, 47.000000000000014, 86.6, 101.89999999999995, 139.0999999999999, 83.89999999999996, 31.10000000000009, 20.000000000000014, 154.0999999999999, 156.79999999999987, 88.09999999999991, 61.10000000000011, 159.49999999999994, 137.89999999999966, 158.5999999999999, 153.19999999999987, 107.30000000000007, 111.79999999999993, 122.60000000000008, 9.200000000000086, 161.29999999999987, 139.69999999999965, 154.1, 149.59999999999982, 177.49999999999986, 108.1999999999997, 47.00000000000015, 196.4, 161.29999999999993, 137.89999999999975, 188.3, 174.79999999999984, 132.50000000000003, 22.700000000000095, 158.59999999999985, 134.29999999999973, 186.49999999999991, 169.39999999999992, 173.89999999999986, 112.39999999999995, 139.69999999999993, 149.5999999999998, 169.4, 149.59999999999988, 142.69999999999996, 157.3999999999999, 143.29999999999995, 114.49999999999964, 71.29999999999998, 179.2999999999999, 162.1999999999999, 107.2999999999996, 173.89999999999986, 109.10000000000005, 75.79999999999993, 20.000000000000014, 118.99999999999989, 167.59999999999997, 173.89999999999998, 158.29999999999993, 152.3, 160.39999999999986, 123.49999999999993, 131.60000000000005, 157.6999999999999, 27.50000000000005, 69.50000000000017, 179.2999999999999, 124.39999999999989, 65.90000000000005, 122.29999999999961, 118.10000000000005, 119.60000000000002, -141.7000000000003, 84.79999999999991, 135.1999999999999, 168.49999999999983, 136.0999999999999, -27.699999999999847, 139.39999999999995, 135.2, 176.89999999999995, 130.9999999999999, 20.000000000000014, 78.80000000000001, 165.79999999999984, 159.49999999999997, 133.0999999999998, 177.49999999999986, 130.7, 164.29999999999995, 106.09999999999995, 136.39999999999964, 185.29999999999993, 114.5, 62.30000000000022, 56.599999999999966, 172.99999999999991, 86.3000000000001, 116.59999999999994, 75.19999999999987, 154.39999999999992, 159.19999999999987, 110.29999999999981, 173.9], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 14.0, 1.0, 7.0, 10.0, 6.0, 4.0, 1.0, 0.0, 8.0, 4.0, 1.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 5.0, 2.0, 2.0, 6.0, 0.0, 0.0, 14.0, 0.0, 0.0, 9.0, 0.0, 7.0, 9.0, 11.0, 9.0, 0.0, 10.0, 2.0, 0.0, 24.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 3.0, 31.0, 10.0, 12.0, 0.0, 0.0, 1.0, 2.0, 13.0, 7.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 7.0, 0.0, 5.0, 0.0, 0.0, 7.0, 0.0, 0.0, 9.0, 6.0, 12.0, 6.0, 0.0, 0.0, 16.0, 5.0, 9.0, 0.0, 0.0, 11.0, 0.0, 0.0, 6.0, 0.0, 10.0, 0.0, 3.0, 8.0, 3.0, 0.0, 8.0, 0.0, 0.0, 1.0, 1.0, 13.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 15.0, 0.0, 0.0, 0.0, 3.0, 0.0, 13.0, 0.0, 0.0, 8.0, 0.0, 4.0, 9.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 4.0, 0.0, 0.0, 19.0, 64.0, 60.0, 0.0, 0.0, 15.0, 22.0, 0.0, 13.0, 10.0, 1.0, 0.0, 11.0, 0.0, 3.0, 4.0, 0.0, 5.0, 0.0, 0.0, 9.0, 0.0, 1.0, 0.0, 1.0, 0.0, 13.0, 8.0, 20.0, 0.0, 9.0, 0.0, 5.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 13.252268215865461, "mean_inference_ms": 29.005614711121098, "mean_action_processing_ms": 6.515211476643555, "mean_env_wait_ms": 8.691647814566746, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.010997176170349121, "StateBufferConnector_ms": 0.017678380012512207, "ViewRequirementAgentConnector_ms": 0.4073374271392822}, "num_episodes": 18, "episode_return_max": 364.40000000000003, "episode_return_min": 67.10000000000025, "episode_return_mean": 240.48199999999974, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1440000, "num_agent_steps_trained": 1440000, "num_env_steps_sampled": 360000, "num_env_steps_trained": 360000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 128.02878479201536, "num_env_steps_trained_throughput_per_sec": 128.02878479201536, "timesteps_total": 360000, "num_env_steps_sampled_lifetime": 360000, "num_agent_steps_sampled_lifetime": 1440000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1440000, "timers": {"training_iteration_time_ms": 30049.314, "restore_workers_time_ms": 0.023, "training_step_time_ms": 30049.239, "sample_time_ms": 4414.371, "learn_time_ms": 25601.093, "learn_throughput": 156.243, "synch_weights_time_ms": 27.36}, "counters": {"num_env_steps_sampled": 360000, "num_env_steps_trained": 360000, "num_agent_steps_sampled": 1440000, "num_agent_steps_trained": 1440000}, "done": false, "training_iteration": 90, "trial_id": "75ec3_00000", "date": "2024-08-13_03-03-28", "timestamp": 1723532608, "time_this_iter_s": 31.379943132400513, "time_total_s": 6261.049946546555, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b1bbbb80>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 6261.049946546555, "iterations_since_restore": 90, "perf": {"cpu_util_percent": 87.04318181818182, "ram_util_percent": 83.2840909090909}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 16.287166564016747, "cur_kl_coeff": 0.1924338385462761, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.908581869185917, "policy_loss": -0.003411716137761398, "vf_loss": 6.9107421900229475, "vf_explained_var": 0.569731429928825, "kl": 0.006502950906414482, "entropy": 1.034451362411812, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 171045.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.2688912967594449, "cur_kl_coeff": 1.06581410364015e-15, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.15220556998398727, "policy_loss": -1.8026295275718132e-05, "vf_loss": 0.1522235961759059, "vf_explained_var": 0.01138718320579125, "kl": 0.0021753974131450975, "entropy": 0.3646565949159955, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 171045.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 364000, "num_env_steps_trained": 364000, "num_agent_steps_sampled": 1456000, "num_agent_steps_trained": 1456000}, "env_runners": {"episode_reward_max": 364.00000000000034, "episode_reward_min": 10.100000000000156, "episode_reward_mean": 232.11399999999986, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -141.7000000000003, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 196.4, "predator_policy": 64.0}, "policy_reward_mean": {"prey_policy": 111.57199999999993, "predator_policy": 4.485}, "custom_metrics": {}, "hist_stats": {"episode_reward": [364.00000000000034, 159.1999999999993, 166.09999999999968, 252.39999999999952, 125.20000000000003, 193.4999999999995, 222.3999999999999, 170.49999999999937, 238.89999999999958, 211.89999999999944, 145.29999999999922, 189.89999999999924, 219.49999999999955, 192.8999999999994, 221.79999999999947, 236.59999999999923, 74.20000000000005, 138.0999999999996, 327.70000000000005, 176.8999999999993, 222.59999999999954, 220.89999999999932, 213.2999999999996, 189.09999999999937, 223.39999999999938, 136.59999999999994, 251.99999999999977, 122.99999999999989, 174.0999999999993, 246.8999999999994, 243.5999999999996, 296.5000000000013, 260.4999999999996, 234.4000000000001, 185.49999999999946, 293.79999999999995, 327.0999999999998, 155.19999999999922, 357.69999999999993, 326.200000000001, 307.29999999999984, 196.29999999999936, 320.79999999999984, 346.30000000000007, 265.0999999999999, 319.0000000000001, 300.2999999999998, 313.70000000000056, 194.79999999999953, 341.5000000000003, 281.1999999999995, 184.89999999999995, 138.99999999999946, 348.4999999999999, 317.6000000000002, 283.9, 289.29999999999984, 108.00000000000013, 303.7, 192.1999999999991, 256.6999999999998, 67.10000000000025, 303.7000000000003, 145.3999999999996, 287.5999999999997, 318.9000000000003, 109.79999999999963, 328.30000000000024, 314.6, 299.9999999999999, 251.4999999999995, 300.79999999999995, 119.89999999999972, 272.29999999999995, 219.79999999999944, 322.60000000000025, 289.19999999999993, 242.49999999999991, 281.4999999999997, 282.10000000000036, 230.99999999999955, 191.59999999999937, 260.4999999999994, 169.59999999999965, 233.2999999999997, 10.100000000000156, 161.49999999999986, 177.69999999999936, 322.0, 309.99999999999994, 296.5000000000007, 201.3999999999995, 168.6, 287.99999999999983, 250.79999999999976, 207.8999999999999, 199.19999999999968, 53.89999999999999, 147.9999999999992, 252.69999999999962], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [183.7999999999999, 180.1999999999999, 28.69999999999998, 96.49999999999979, 70.39999999999998, 73.69999999999985, 185.59999999999997, 66.8, 45.19999999999999, 77.00000000000003, 25.999999999999964, 147.49999999999994, 152.3, 64.10000000000001, 48.79999999999997, 121.69999999999975, 176.59999999999997, 62.30000000000005, 93.80000000000007, 118.10000000000002, 125.29999999999984, 20.000000000000014, 15.799999999999962, 172.09999999999994, 40.399999999999984, 172.09999999999994, 20.000000000000014, 167.89999999999998, 59.600000000000115, 162.19999999999987, 55.70000000000018, 173.89999999999992, 32.60000000000002, 32.599999999999994, -4.299999999999841, 124.39999999999989, 190.99999999999997, 130.7, 22.100000000000062, 138.8, 147.19999999999993, 61.400000000000055, 117.19999999999993, 103.69999999999943, 77.6000000000002, 124.69999999999997, 23.600000000000048, 159.49999999999986, 81.2000000000001, 132.1999999999999, 47.000000000000014, 86.6, 101.89999999999995, 139.0999999999999, 83.89999999999996, 31.10000000000009, 20.000000000000014, 154.0999999999999, 156.79999999999987, 88.09999999999991, 61.10000000000011, 159.49999999999994, 137.89999999999966, 158.5999999999999, 153.19999999999987, 107.30000000000007, 111.79999999999993, 122.60000000000008, 9.200000000000086, 161.29999999999987, 139.69999999999965, 154.1, 149.59999999999982, 177.49999999999986, 108.1999999999997, 47.00000000000015, 196.4, 161.29999999999993, 137.89999999999975, 188.3, 174.79999999999984, 132.50000000000003, 22.700000000000095, 158.59999999999985, 134.29999999999973, 186.49999999999991, 169.39999999999992, 173.89999999999986, 112.39999999999995, 139.69999999999993, 149.5999999999998, 169.4, 149.59999999999988, 142.69999999999996, 157.3999999999999, 143.29999999999995, 114.49999999999964, 71.29999999999998, 179.2999999999999, 162.1999999999999, 107.2999999999996, 173.89999999999986, 109.10000000000005, 75.79999999999993, 20.000000000000014, 118.99999999999989, 167.59999999999997, 173.89999999999998, 158.29999999999993, 152.3, 160.39999999999986, 123.49999999999993, 131.60000000000005, 157.6999999999999, 27.50000000000005, 69.50000000000017, 179.2999999999999, 124.39999999999989, 65.90000000000005, 122.29999999999961, 118.10000000000005, 119.60000000000002, -141.7000000000003, 84.79999999999991, 135.1999999999999, 168.49999999999983, 136.0999999999999, -27.699999999999847, 139.39999999999995, 135.2, 176.89999999999995, 130.9999999999999, 20.000000000000014, 78.80000000000001, 165.79999999999984, 159.49999999999997, 133.0999999999998, 177.49999999999986, 130.7, 164.29999999999995, 106.09999999999995, 136.39999999999964, 185.29999999999993, 114.5, 62.30000000000022, 56.599999999999966, 172.99999999999991, 86.3000000000001, 116.59999999999994, 75.19999999999987, 154.39999999999992, 159.19999999999987, 110.29999999999981, 173.9, 129.80000000000004, 112.69999999999987, 101.00000000000009, 177.49999999999994, 185.6, 96.49999999999989, 65.00000000000001, 157.99999999999994, 20.000000000000014, 164.59999999999997, 182.9, 77.59999999999926, 77.59999999999975, 91.99999999999997, 115.6999999999999, 110.59999999999997, -2.199999999999905, -45.69999999999977, 23.30000000000012, 111.20000000000005, 157.69999999999996, 20.000000000000014, 182.89999999999992, 136.0999999999999, 184.7, 125.29999999999997, 132.50000000000003, 163.99999999999977, 111.4999999999999, 59.900000000000084, 94.69999999999999, 59.89999999999999, 146.3, 130.6999999999999, 127.09999999999985, 106.69999999999999, 98.59999999999997, 107.29999999999998, 122.00000000000006, 72.19999999999975, 46.99999999999999, -36.09999999999984, 20.000000000000014, 127.99999999999977, 76.10000000000001, 155.59999999999997], "policy_predator_policy_reward": [0.0, 0.0, 3.0, 31.0, 10.0, 12.0, 0.0, 0.0, 1.0, 2.0, 13.0, 7.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 7.0, 0.0, 5.0, 0.0, 0.0, 7.0, 0.0, 0.0, 9.0, 6.0, 12.0, 6.0, 0.0, 0.0, 16.0, 5.0, 9.0, 0.0, 0.0, 11.0, 0.0, 0.0, 6.0, 0.0, 10.0, 0.0, 3.0, 8.0, 3.0, 0.0, 8.0, 0.0, 0.0, 1.0, 1.0, 13.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 15.0, 0.0, 0.0, 0.0, 3.0, 0.0, 13.0, 0.0, 0.0, 8.0, 0.0, 4.0, 9.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 4.0, 0.0, 0.0, 19.0, 64.0, 60.0, 0.0, 0.0, 15.0, 22.0, 0.0, 13.0, 10.0, 1.0, 0.0, 11.0, 0.0, 3.0, 4.0, 0.0, 5.0, 0.0, 0.0, 9.0, 0.0, 1.0, 0.0, 1.0, 0.0, 13.0, 8.0, 20.0, 0.0, 9.0, 0.0, 5.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 8.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 17.0, 41.0, 15.0, 12.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 1.0, 29.0, 6.0, 8.0, 11.0, 0.0, 11.0, 6.0, 0.0, 2.0, 0.0, 5.0, 15.0, 28.0, 0.0, 0.0, 11.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 13.360907936910614, "mean_inference_ms": 29.2269062190074, "mean_action_processing_ms": 6.700140089537092, "mean_env_wait_ms": 7.602841626323253, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.020920872688293457, "StateBufferConnector_ms": 0.01670384407043457, "ViewRequirementAgentConnector_ms": 0.4526851177215576}, "num_episodes": 23, "episode_return_max": 364.00000000000034, "episode_return_min": 10.100000000000156, "episode_return_mean": 232.11399999999986, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1456000, "num_agent_steps_trained": 1456000, "num_env_steps_sampled": 364000, "num_env_steps_trained": 364000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 123.4668046250804, "num_env_steps_trained_throughput_per_sec": 123.4668046250804, "timesteps_total": 364000, "num_env_steps_sampled_lifetime": 364000, "num_agent_steps_sampled_lifetime": 1456000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1456000, "timers": {"training_iteration_time_ms": 30561.095, "restore_workers_time_ms": 0.023, "training_step_time_ms": 30561.019, "sample_time_ms": 4670.376, "learn_time_ms": 25853.215, "learn_throughput": 154.72, "synch_weights_time_ms": 28.953}, "counters": {"num_env_steps_sampled": 364000, "num_env_steps_trained": 364000, "num_agent_steps_sampled": 1456000, "num_agent_steps_trained": 1456000}, "done": false, "training_iteration": 91, "trial_id": "75ec3_00000", "date": "2024-08-13_03-04-01", "timestamp": 1723532641, "time_this_iter_s": 32.54285907745361, "time_total_s": 6293.592805624008, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b209c280>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 6293.592805624008, "iterations_since_restore": 91, "perf": {"cpu_util_percent": 88.21956521739129, "ram_util_percent": 83.25}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 13.367759968931713, "cur_kl_coeff": 0.1924338385462761, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.485598165017588, "policy_loss": -0.0034031496367234954, "vf_loss": 7.486660004166699, "vf_explained_var": 0.42947632418107734, "kl": 0.012166766453396143, "entropy": 1.035357360928147, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 172935.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.34638204761145136, "cur_kl_coeff": 5.32907051820075e-16, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.5601435649647284, "policy_loss": -0.0006382534834778025, "vf_loss": 0.5607818189298823, "vf_explained_var": 0.0027167620797636646, "kl": 0.0029622175776634354, "entropy": 0.26702650964417785, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 172935.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 368000, "num_env_steps_trained": 368000, "num_agent_steps_sampled": 1472000, "num_agent_steps_trained": 1472000}, "env_runners": {"episode_reward_max": 357.69999999999993, "episode_reward_min": 10.100000000000156, "episode_reward_mean": 242.37199999999982, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -141.7000000000003, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 197.29999999999998, "predator_policy": 64.0}, "policy_reward_mean": {"prey_policy": 116.90599999999995, "predator_policy": 4.28}, "custom_metrics": {}, "hist_stats": {"episode_reward": [327.70000000000005, 176.8999999999993, 222.59999999999954, 220.89999999999932, 213.2999999999996, 189.09999999999937, 223.39999999999938, 136.59999999999994, 251.99999999999977, 122.99999999999989, 174.0999999999993, 246.8999999999994, 243.5999999999996, 296.5000000000013, 260.4999999999996, 234.4000000000001, 185.49999999999946, 293.79999999999995, 327.0999999999998, 155.19999999999922, 357.69999999999993, 326.200000000001, 307.29999999999984, 196.29999999999936, 320.79999999999984, 346.30000000000007, 265.0999999999999, 319.0000000000001, 300.2999999999998, 313.70000000000056, 194.79999999999953, 341.5000000000003, 281.1999999999995, 184.89999999999995, 138.99999999999946, 348.4999999999999, 317.6000000000002, 283.9, 289.29999999999984, 108.00000000000013, 303.7, 192.1999999999991, 256.6999999999998, 67.10000000000025, 303.7000000000003, 145.3999999999996, 287.5999999999997, 318.9000000000003, 109.79999999999963, 328.30000000000024, 314.6, 299.9999999999999, 251.4999999999995, 300.79999999999995, 119.89999999999972, 272.29999999999995, 219.79999999999944, 322.60000000000025, 289.19999999999993, 242.49999999999991, 281.4999999999997, 282.10000000000036, 230.99999999999955, 191.59999999999937, 260.4999999999994, 169.59999999999965, 233.2999999999997, 10.100000000000156, 161.49999999999986, 177.69999999999936, 322.0, 309.99999999999994, 296.5000000000007, 201.3999999999995, 168.6, 287.99999999999983, 250.79999999999976, 207.8999999999999, 199.19999999999968, 53.89999999999999, 147.9999999999992, 252.69999999999962, 325.0000000000002, 209.49999999999955, 323.5000000000004, 309.0999999999998, 248.49999999999957, 282.10000000000065, 355.90000000000003, 312.7, 105.99999999999986, 181.39999999999924, 169.89999999999938, 183.0999999999995, 229.8999999999992, 198.39999999999918, 317.2000000000002, 238.89999999999964, 256.8999999999991, 300.1999999999997], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [190.99999999999997, 130.7, 22.100000000000062, 138.8, 147.19999999999993, 61.400000000000055, 117.19999999999993, 103.69999999999943, 77.6000000000002, 124.69999999999997, 23.600000000000048, 159.49999999999986, 81.2000000000001, 132.1999999999999, 47.000000000000014, 86.6, 101.89999999999995, 139.0999999999999, 83.89999999999996, 31.10000000000009, 20.000000000000014, 154.0999999999999, 156.79999999999987, 88.09999999999991, 61.10000000000011, 159.49999999999994, 137.89999999999966, 158.5999999999999, 153.19999999999987, 107.30000000000007, 111.79999999999993, 122.60000000000008, 9.200000000000086, 161.29999999999987, 139.69999999999965, 154.1, 149.59999999999982, 177.49999999999986, 108.1999999999997, 47.00000000000015, 196.4, 161.29999999999993, 137.89999999999975, 188.3, 174.79999999999984, 132.50000000000003, 22.700000000000095, 158.59999999999985, 134.29999999999973, 186.49999999999991, 169.39999999999992, 173.89999999999986, 112.39999999999995, 139.69999999999993, 149.5999999999998, 169.4, 149.59999999999988, 142.69999999999996, 157.3999999999999, 143.29999999999995, 114.49999999999964, 71.29999999999998, 179.2999999999999, 162.1999999999999, 107.2999999999996, 173.89999999999986, 109.10000000000005, 75.79999999999993, 20.000000000000014, 118.99999999999989, 167.59999999999997, 173.89999999999998, 158.29999999999993, 152.3, 160.39999999999986, 123.49999999999993, 131.60000000000005, 157.6999999999999, 27.50000000000005, 69.50000000000017, 179.2999999999999, 124.39999999999989, 65.90000000000005, 122.29999999999961, 118.10000000000005, 119.60000000000002, -141.7000000000003, 84.79999999999991, 135.1999999999999, 168.49999999999983, 136.0999999999999, -27.699999999999847, 139.39999999999995, 135.2, 176.89999999999995, 130.9999999999999, 20.000000000000014, 78.80000000000001, 165.79999999999984, 159.49999999999997, 133.0999999999998, 177.49999999999986, 130.7, 164.29999999999995, 106.09999999999995, 136.39999999999964, 185.29999999999993, 114.5, 62.30000000000022, 56.599999999999966, 172.99999999999991, 86.3000000000001, 116.59999999999994, 75.19999999999987, 154.39999999999992, 159.19999999999987, 110.29999999999981, 173.9, 129.80000000000004, 112.69999999999987, 101.00000000000009, 177.49999999999994, 185.6, 96.49999999999989, 65.00000000000001, 157.99999999999994, 20.000000000000014, 164.59999999999997, 182.9, 77.59999999999926, 77.59999999999975, 91.99999999999997, 115.6999999999999, 110.59999999999997, -2.199999999999905, -45.69999999999977, 23.30000000000012, 111.20000000000005, 157.69999999999996, 20.000000000000014, 182.89999999999992, 136.0999999999999, 184.7, 125.29999999999997, 132.50000000000003, 163.99999999999977, 111.4999999999999, 59.900000000000084, 94.69999999999999, 59.89999999999999, 146.3, 130.6999999999999, 127.09999999999985, 106.69999999999999, 98.59999999999997, 107.29999999999998, 122.00000000000006, 72.19999999999975, 46.99999999999999, -36.09999999999984, 20.000000000000014, 127.99999999999977, 76.10000000000001, 155.59999999999997, 172.09999999999994, 146.8999999999999, 20.000000000000096, 177.49999999999997, 197.29999999999998, 126.19999999999979, 179.29999999999998, 129.79999999999984, 66.80000000000004, 175.69999999999987, 155.89999999999984, 126.19999999999965, 159.49999999999986, 196.39999999999998, 176.59999999999994, 136.09999999999997, -28.29999999999977, 104.29999999999998, 157.39999999999995, 20.000000000000014, 163.09999999999994, -5.200000000000021, 43.400000000000034, 130.69999999999976, 64.10000000000021, 156.79999999999993, 146.89999999999972, 51.499999999999964, 154.1, 163.09999999999997, 100.99999999999999, 137.89999999999986, 190.99999999999994, 65.90000000000008, 144.19999999999993, 151.99999999999983], "policy_predator_policy_reward": [6.0, 0.0, 0.0, 16.0, 5.0, 9.0, 0.0, 0.0, 11.0, 0.0, 0.0, 6.0, 0.0, 10.0, 0.0, 3.0, 8.0, 3.0, 0.0, 8.0, 0.0, 0.0, 1.0, 1.0, 13.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 15.0, 0.0, 0.0, 0.0, 3.0, 0.0, 13.0, 0.0, 0.0, 8.0, 0.0, 4.0, 9.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 4.0, 0.0, 0.0, 19.0, 64.0, 60.0, 0.0, 0.0, 15.0, 22.0, 0.0, 13.0, 10.0, 1.0, 0.0, 11.0, 0.0, 3.0, 4.0, 0.0, 5.0, 0.0, 0.0, 9.0, 0.0, 1.0, 0.0, 1.0, 0.0, 13.0, 8.0, 20.0, 0.0, 9.0, 0.0, 5.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 8.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 17.0, 41.0, 15.0, 12.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 1.0, 29.0, 6.0, 8.0, 11.0, 0.0, 11.0, 6.0, 0.0, 2.0, 0.0, 5.0, 15.0, 28.0, 0.0, 0.0, 11.0, 10.0, 0.0, 6.0, 8.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 23.0, 0.0, 4.0, 12.0, 0.0, 9.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 13.02428899761349, "mean_inference_ms": 28.525575854889095, "mean_action_processing_ms": 6.385732860546845, "mean_env_wait_ms": 8.538878683234362, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.04561591148376465, "StateBufferConnector_ms": 0.023875832557678223, "ViewRequirementAgentConnector_ms": 0.6050115823745728}, "num_episodes": 18, "episode_return_max": 357.69999999999993, "episode_return_min": 10.100000000000156, "episode_return_mean": 242.37199999999982, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1472000, "num_agent_steps_trained": 1472000, "num_env_steps_sampled": 368000, "num_env_steps_trained": 368000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 81.39044822981887, "num_env_steps_trained_throughput_per_sec": 81.39044822981887, "timesteps_total": 368000, "num_env_steps_sampled_lifetime": 368000, "num_agent_steps_sampled_lifetime": 1472000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1472000, "timers": {"training_iteration_time_ms": 32635.641, "restore_workers_time_ms": 0.024, "training_step_time_ms": 32635.562, "sample_time_ms": 5823.554, "learn_time_ms": 26769.808, "learn_throughput": 149.422, "synch_weights_time_ms": 33.358}, "counters": {"num_env_steps_sampled": 368000, "num_env_steps_trained": 368000, "num_agent_steps_sampled": 1472000, "num_agent_steps_trained": 1472000}, "done": false, "training_iteration": 92, "trial_id": "75ec3_00000", "date": "2024-08-13_03-04-50", "timestamp": 1723532690, "time_this_iter_s": 49.29811716079712, "time_total_s": 6342.890922784805, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b209c550>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 6342.890922784805, "iterations_since_restore": 92, "perf": {"cpu_util_percent": 94.51739130434783, "ram_util_percent": 83.13768115942028}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 13.503634799788237, "cur_kl_coeff": 0.1924338385462761, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.472662686040162, "policy_loss": -0.005622780197866694, "vf_loss": 7.475428293874024, "vf_explained_var": 0.2720912013104353, "kl": 0.01484754228312252, "entropy": 1.0463435384331556, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 174825.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.24663605454264495, "cur_kl_coeff": 2.664535259100375e-16, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.2584159433053284, "policy_loss": -0.0004755795308728776, "vf_loss": 0.2588915217214476, "vf_explained_var": 0.006651792229798736, "kl": 0.0010683875876325354, "entropy": 0.24116876022052514, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 174825.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 372000, "num_env_steps_trained": 372000, "num_agent_steps_sampled": 1488000, "num_agent_steps_trained": 1488000}, "env_runners": {"episode_reward_max": 382.9000000000001, "episode_reward_min": 10.100000000000156, "episode_reward_mean": 245.69999999999982, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -141.7000000000003, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 197.29999999999998, "predator_policy": 64.0}, "policy_reward_mean": {"prey_policy": 118.38499999999993, "predator_policy": 4.465}, "custom_metrics": {}, "hist_stats": {"episode_reward": [327.0999999999998, 155.19999999999922, 357.69999999999993, 326.200000000001, 307.29999999999984, 196.29999999999936, 320.79999999999984, 346.30000000000007, 265.0999999999999, 319.0000000000001, 300.2999999999998, 313.70000000000056, 194.79999999999953, 341.5000000000003, 281.1999999999995, 184.89999999999995, 138.99999999999946, 348.4999999999999, 317.6000000000002, 283.9, 289.29999999999984, 108.00000000000013, 303.7, 192.1999999999991, 256.6999999999998, 67.10000000000025, 303.7000000000003, 145.3999999999996, 287.5999999999997, 318.9000000000003, 109.79999999999963, 328.30000000000024, 314.6, 299.9999999999999, 251.4999999999995, 300.79999999999995, 119.89999999999972, 272.29999999999995, 219.79999999999944, 322.60000000000025, 289.19999999999993, 242.49999999999991, 281.4999999999997, 282.10000000000036, 230.99999999999955, 191.59999999999937, 260.4999999999994, 169.59999999999965, 233.2999999999997, 10.100000000000156, 161.49999999999986, 177.69999999999936, 322.0, 309.99999999999994, 296.5000000000007, 201.3999999999995, 168.6, 287.99999999999983, 250.79999999999976, 207.8999999999999, 199.19999999999968, 53.89999999999999, 147.9999999999992, 252.69999999999962, 325.0000000000002, 209.49999999999955, 323.5000000000004, 309.0999999999998, 248.49999999999957, 282.10000000000065, 355.90000000000003, 312.7, 105.99999999999986, 181.39999999999924, 169.89999999999938, 183.0999999999995, 229.8999999999992, 198.39999999999918, 317.2000000000002, 238.89999999999964, 256.8999999999991, 300.1999999999997, 272.0999999999999, 325.8999999999999, 179.9, 382.9000000000001, 364.0000000000006, 215.19999999999942, 311.4000000000001, 205.59999999999928, 208.59999999999982, 97.10000000000005, 227.59999999999977, 181.09999999999988, 238.89999999999938, 147.09999999999965, 262.49999999999994, 166.6999999999995, 275.79999999999967, 291.2000000000006], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [149.59999999999982, 177.49999999999986, 108.1999999999997, 47.00000000000015, 196.4, 161.29999999999993, 137.89999999999975, 188.3, 174.79999999999984, 132.50000000000003, 22.700000000000095, 158.59999999999985, 134.29999999999973, 186.49999999999991, 169.39999999999992, 173.89999999999986, 112.39999999999995, 139.69999999999993, 149.5999999999998, 169.4, 149.59999999999988, 142.69999999999996, 157.3999999999999, 143.29999999999995, 114.49999999999964, 71.29999999999998, 179.2999999999999, 162.1999999999999, 107.2999999999996, 173.89999999999986, 109.10000000000005, 75.79999999999993, 20.000000000000014, 118.99999999999989, 167.59999999999997, 173.89999999999998, 158.29999999999993, 152.3, 160.39999999999986, 123.49999999999993, 131.60000000000005, 157.6999999999999, 27.50000000000005, 69.50000000000017, 179.2999999999999, 124.39999999999989, 65.90000000000005, 122.29999999999961, 118.10000000000005, 119.60000000000002, -141.7000000000003, 84.79999999999991, 135.1999999999999, 168.49999999999983, 136.0999999999999, -27.699999999999847, 139.39999999999995, 135.2, 176.89999999999995, 130.9999999999999, 20.000000000000014, 78.80000000000001, 165.79999999999984, 159.49999999999997, 133.0999999999998, 177.49999999999986, 130.7, 164.29999999999995, 106.09999999999995, 136.39999999999964, 185.29999999999993, 114.5, 62.30000000000022, 56.599999999999966, 172.99999999999991, 86.3000000000001, 116.59999999999994, 75.19999999999987, 154.39999999999992, 159.19999999999987, 110.29999999999981, 173.9, 129.80000000000004, 112.69999999999987, 101.00000000000009, 177.49999999999994, 185.6, 96.49999999999989, 65.00000000000001, 157.99999999999994, 20.000000000000014, 164.59999999999997, 182.9, 77.59999999999926, 77.59999999999975, 91.99999999999997, 115.6999999999999, 110.59999999999997, -2.199999999999905, -45.69999999999977, 23.30000000000012, 111.20000000000005, 157.69999999999996, 20.000000000000014, 182.89999999999992, 136.0999999999999, 184.7, 125.29999999999997, 132.50000000000003, 163.99999999999977, 111.4999999999999, 59.900000000000084, 94.69999999999999, 59.89999999999999, 146.3, 130.6999999999999, 127.09999999999985, 106.69999999999999, 98.59999999999997, 107.29999999999998, 122.00000000000006, 72.19999999999975, 46.99999999999999, -36.09999999999984, 20.000000000000014, 127.99999999999977, 76.10000000000001, 155.59999999999997, 172.09999999999994, 146.8999999999999, 20.000000000000096, 177.49999999999997, 197.29999999999998, 126.19999999999979, 179.29999999999998, 129.79999999999984, 66.80000000000004, 175.69999999999987, 155.89999999999984, 126.19999999999965, 159.49999999999986, 196.39999999999998, 176.59999999999994, 136.09999999999997, -28.29999999999977, 104.29999999999998, 157.39999999999995, 20.000000000000014, 163.09999999999994, -5.200000000000021, 43.400000000000034, 130.69999999999976, 64.10000000000021, 156.79999999999993, 146.89999999999972, 51.499999999999964, 154.1, 163.09999999999997, 100.99999999999999, 137.89999999999986, 190.99999999999994, 65.90000000000008, 144.19999999999993, 151.99999999999983, 120.49999999999997, 140.59999999999997, 161.29999999999987, 158.59999999999994, 171.19999999999993, -43.300000000000466, 190.99999999999994, 191.9, 192.79999999999995, 171.19999999999987, 83.00000000000009, 117.19999999999972, 141.49999999999997, 158.89999999999998, 165.7999999999999, 39.80000000000007, 118.99999999999999, 77.60000000000014, 48.49999999999997, 41.60000000000014, 91.09999999999997, 120.49999999999989, 77.29999999999995, 102.79999999999993, 115.39999999999989, 123.49999999999989, 124.40000000000003, 22.70000000000001, 94.09999999999995, 151.4, 25.400000000000006, 140.3, 132.5, 143.29999999999995, 112.39999999999993, 165.79999999999987], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 15.0, 0.0, 0.0, 0.0, 3.0, 0.0, 13.0, 0.0, 0.0, 8.0, 0.0, 4.0, 9.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 4.0, 0.0, 0.0, 19.0, 64.0, 60.0, 0.0, 0.0, 15.0, 22.0, 0.0, 13.0, 10.0, 1.0, 0.0, 11.0, 0.0, 3.0, 4.0, 0.0, 5.0, 0.0, 0.0, 9.0, 0.0, 1.0, 0.0, 1.0, 0.0, 13.0, 8.0, 20.0, 0.0, 9.0, 0.0, 5.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 8.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 17.0, 41.0, 15.0, 12.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 1.0, 29.0, 6.0, 8.0, 11.0, 0.0, 11.0, 6.0, 0.0, 2.0, 0.0, 5.0, 15.0, 28.0, 0.0, 0.0, 11.0, 10.0, 0.0, 6.0, 8.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 23.0, 0.0, 4.0, 12.0, 0.0, 9.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 10.0, 1.0, 0.0, 6.0, 0.0, 52.0, 0.0, 0.0, 0.0, 0.0, 15.0, 0.0, 3.0, 8.0, 0.0, 0.0, 12.0, 0.0, 0.0, 7.0, 0.0, 16.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 16.0, 0.0, 1.0, 0.0, 0.0, 0.0, 13.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 12.929689739518128, "mean_inference_ms": 28.33901754901244, "mean_action_processing_ms": 6.335651912725507, "mean_env_wait_ms": 8.466840791041399, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.04665708541870117, "StateBufferConnector_ms": 0.01890850067138672, "ViewRequirementAgentConnector_ms": 0.6208318471908569}, "num_episodes": 18, "episode_return_max": 382.9000000000001, "episode_return_min": 10.100000000000156, "episode_return_mean": 245.69999999999982, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1488000, "num_agent_steps_trained": 1488000, "num_env_steps_sampled": 372000, "num_env_steps_trained": 372000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 116.59496681638217, "num_env_steps_trained_throughput_per_sec": 116.59496681638217, "timesteps_total": 372000, "num_env_steps_sampled_lifetime": 372000, "num_agent_steps_sampled_lifetime": 1488000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1488000, "timers": {"training_iteration_time_ms": 33097.193, "restore_workers_time_ms": 0.032, "training_step_time_ms": 33097.095, "sample_time_ms": 5940.272, "learn_time_ms": 27111.178, "learn_throughput": 147.541, "synch_weights_time_ms": 36.79}, "counters": {"num_env_steps_sampled": 372000, "num_env_steps_trained": 372000, "num_agent_steps_sampled": 1488000, "num_agent_steps_trained": 1488000}, "done": false, "training_iteration": 93, "trial_id": "75ec3_00000", "date": "2024-08-13_03-05-25", "timestamp": 1723532725, "time_this_iter_s": 34.39162802696228, "time_total_s": 6377.282550811768, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b1bbbf70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 6377.282550811768, "iterations_since_restore": 93, "perf": {"cpu_util_percent": 89.76122448979592, "ram_util_percent": 83.29591836734694}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 14.042852949181562, "cur_kl_coeff": 0.1924338385462761, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.617639029215253, "policy_loss": -0.002384129566726861, "vf_loss": 7.618500607102005, "vf_explained_var": 0.43761026670062353, "kl": 0.007912113203352571, "entropy": 1.0008221443368013, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 176715.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4808201261485616, "cur_kl_coeff": 1.3322676295501876e-16, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.7133882941865416, "policy_loss": -0.0010640677492129345, "vf_loss": 0.7144523634402841, "vf_explained_var": 0.018624815802094796, "kl": 0.001103426194733485, "entropy": 0.2623292305639812, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 176715.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 376000, "num_env_steps_trained": 376000, "num_agent_steps_sampled": 1504000, "num_agent_steps_trained": 1504000}, "env_runners": {"episode_reward_max": 382.9000000000001, "episode_reward_min": 10.100000000000156, "episode_reward_mean": 238.09799999999981, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -141.7000000000003, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 197.29999999999998, "predator_policy": 64.0}, "policy_reward_mean": {"prey_policy": 114.19399999999995, "predator_policy": 4.855}, "custom_metrics": {}, "hist_stats": {"episode_reward": [303.7, 192.1999999999991, 256.6999999999998, 67.10000000000025, 303.7000000000003, 145.3999999999996, 287.5999999999997, 318.9000000000003, 109.79999999999963, 328.30000000000024, 314.6, 299.9999999999999, 251.4999999999995, 300.79999999999995, 119.89999999999972, 272.29999999999995, 219.79999999999944, 322.60000000000025, 289.19999999999993, 242.49999999999991, 281.4999999999997, 282.10000000000036, 230.99999999999955, 191.59999999999937, 260.4999999999994, 169.59999999999965, 233.2999999999997, 10.100000000000156, 161.49999999999986, 177.69999999999936, 322.0, 309.99999999999994, 296.5000000000007, 201.3999999999995, 168.6, 287.99999999999983, 250.79999999999976, 207.8999999999999, 199.19999999999968, 53.89999999999999, 147.9999999999992, 252.69999999999962, 325.0000000000002, 209.49999999999955, 323.5000000000004, 309.0999999999998, 248.49999999999957, 282.10000000000065, 355.90000000000003, 312.7, 105.99999999999986, 181.39999999999924, 169.89999999999938, 183.0999999999995, 229.8999999999992, 198.39999999999918, 317.2000000000002, 238.89999999999964, 256.8999999999991, 300.1999999999997, 272.0999999999999, 325.8999999999999, 179.9, 382.9000000000001, 364.0000000000006, 215.19999999999942, 311.4000000000001, 205.59999999999928, 208.59999999999982, 97.10000000000005, 227.59999999999977, 181.09999999999988, 238.89999999999938, 147.09999999999965, 262.49999999999994, 166.6999999999995, 275.79999999999967, 291.2000000000006, 81.20000000000017, 210.19999999999936, 274.89999999999935, 195.4999999999992, 229.8999999999997, 142.29999999999941, 321.5000000000002, 292.0999999999999, 327.10000000000014, 269.4999999999998, 321.8999999999998, 327.3000000000004, 342.39999999999986, 359.29999999999984, 335.30000000000035, 40.80000000000021, 246.09999999999954, 48.200000000000244, 295.5999999999999, 240.19999999999945, 227.1999999999995, 134.9999999999993], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [179.2999999999999, 124.39999999999989, 65.90000000000005, 122.29999999999961, 118.10000000000005, 119.60000000000002, -141.7000000000003, 84.79999999999991, 135.1999999999999, 168.49999999999983, 136.0999999999999, -27.699999999999847, 139.39999999999995, 135.2, 176.89999999999995, 130.9999999999999, 20.000000000000014, 78.80000000000001, 165.79999999999984, 159.49999999999997, 133.0999999999998, 177.49999999999986, 130.7, 164.29999999999995, 106.09999999999995, 136.39999999999964, 185.29999999999993, 114.5, 62.30000000000022, 56.599999999999966, 172.99999999999991, 86.3000000000001, 116.59999999999994, 75.19999999999987, 154.39999999999992, 159.19999999999987, 110.29999999999981, 173.9, 129.80000000000004, 112.69999999999987, 101.00000000000009, 177.49999999999994, 185.6, 96.49999999999989, 65.00000000000001, 157.99999999999994, 20.000000000000014, 164.59999999999997, 182.9, 77.59999999999926, 77.59999999999975, 91.99999999999997, 115.6999999999999, 110.59999999999997, -2.199999999999905, -45.69999999999977, 23.30000000000012, 111.20000000000005, 157.69999999999996, 20.000000000000014, 182.89999999999992, 136.0999999999999, 184.7, 125.29999999999997, 132.50000000000003, 163.99999999999977, 111.4999999999999, 59.900000000000084, 94.69999999999999, 59.89999999999999, 146.3, 130.6999999999999, 127.09999999999985, 106.69999999999999, 98.59999999999997, 107.29999999999998, 122.00000000000006, 72.19999999999975, 46.99999999999999, -36.09999999999984, 20.000000000000014, 127.99999999999977, 76.10000000000001, 155.59999999999997, 172.09999999999994, 146.8999999999999, 20.000000000000096, 177.49999999999997, 197.29999999999998, 126.19999999999979, 179.29999999999998, 129.79999999999984, 66.80000000000004, 175.69999999999987, 155.89999999999984, 126.19999999999965, 159.49999999999986, 196.39999999999998, 176.59999999999994, 136.09999999999997, -28.29999999999977, 104.29999999999998, 157.39999999999995, 20.000000000000014, 163.09999999999994, -5.200000000000021, 43.400000000000034, 130.69999999999976, 64.10000000000021, 156.79999999999993, 146.89999999999972, 51.499999999999964, 154.1, 163.09999999999997, 100.99999999999999, 137.89999999999986, 190.99999999999994, 65.90000000000008, 144.19999999999993, 151.99999999999983, 120.49999999999997, 140.59999999999997, 161.29999999999987, 158.59999999999994, 171.19999999999993, -43.300000000000466, 190.99999999999994, 191.9, 192.79999999999995, 171.19999999999987, 83.00000000000009, 117.19999999999972, 141.49999999999997, 158.89999999999998, 165.7999999999999, 39.80000000000007, 118.99999999999999, 77.60000000000014, 48.49999999999997, 41.60000000000014, 91.09999999999997, 120.49999999999989, 77.29999999999995, 102.79999999999993, 115.39999999999989, 123.49999999999989, 124.40000000000003, 22.70000000000001, 94.09999999999995, 151.4, 25.400000000000006, 140.3, 132.5, 143.29999999999995, 112.39999999999993, 165.79999999999987, 62.30000000000022, 17.899999999999977, 162.19999999999987, 35.000000000000135, 96.49999999999982, 178.39999999999992, 143.89999999999995, 41.60000000000016, 171.2, 49.70000000000006, 75.79999999999998, 60.500000000000085, 170.00000000000003, 150.49999999999977, 139.69999999999993, 139.39999999999998, 188.29999999999993, 138.7999999999999, 117.49999999999969, 137.0, 143.29999999999984, 170.59999999999997, 153.49999999999994, 162.79999999999993, 163.0999999999999, 179.29999999999998, 185.59999999999997, 172.70000000000005, 168.7999999999999, 153.5, 20.000000000000014, 15.799999999999967, 181.09999999999988, 55.99999999999999, 48.50000000000012, -31.300000000000036, 134.3, 161.2999999999998, 80.89999999999972, 152.2999999999999, 56.90000000000012, 170.29999999999998, 20.000000000000014, 103.99999999999983], "policy_predator_policy_reward": [0.0, 0.0, 4.0, 0.0, 0.0, 19.0, 64.0, 60.0, 0.0, 0.0, 15.0, 22.0, 0.0, 13.0, 10.0, 1.0, 0.0, 11.0, 0.0, 3.0, 4.0, 0.0, 5.0, 0.0, 0.0, 9.0, 0.0, 1.0, 0.0, 1.0, 0.0, 13.0, 8.0, 20.0, 0.0, 9.0, 0.0, 5.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 8.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 17.0, 41.0, 15.0, 12.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 1.0, 29.0, 6.0, 8.0, 11.0, 0.0, 11.0, 6.0, 0.0, 2.0, 0.0, 5.0, 15.0, 28.0, 0.0, 0.0, 11.0, 10.0, 0.0, 6.0, 8.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 23.0, 0.0, 4.0, 12.0, 0.0, 9.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 10.0, 1.0, 0.0, 6.0, 0.0, 52.0, 0.0, 0.0, 0.0, 0.0, 15.0, 0.0, 3.0, 8.0, 0.0, 0.0, 12.0, 0.0, 0.0, 7.0, 0.0, 16.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 16.0, 0.0, 1.0, 0.0, 0.0, 0.0, 13.0, 1.0, 0.0, 7.0, 6.0, 0.0, 0.0, 1.0, 9.0, 9.0, 0.0, 6.0, 0.0, 0.0, 1.0, 13.0, 0.0, 0.0, 0.0, 15.0, 0.0, 0.0, 8.0, 0.0, 11.0, 0.0, 0.0, 0.0, 1.0, 13.0, 0.0, 0.0, 5.0, 4.0, 5.0, 31.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 11.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 12.812301981986643, "mean_inference_ms": 28.12703587980873, "mean_action_processing_ms": 6.2879260931253675, "mean_env_wait_ms": 8.358733776285993, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.04742908477783203, "StateBufferConnector_ms": 0.019071340560913086, "ViewRequirementAgentConnector_ms": 0.6368942260742188}, "num_episodes": 22, "episode_return_max": 382.9000000000001, "episode_return_min": 10.100000000000156, "episode_return_mean": 238.09799999999981, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1504000, "num_agent_steps_trained": 1504000, "num_env_steps_sampled": 376000, "num_env_steps_trained": 376000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 119.1600019094333, "num_env_steps_trained_throughput_per_sec": 119.1600019094333, "timesteps_total": 376000, "num_env_steps_sampled_lifetime": 376000, "num_agent_steps_sampled_lifetime": 1504000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1504000, "timers": {"training_iteration_time_ms": 33393.963, "restore_workers_time_ms": 0.033, "training_step_time_ms": 33393.865, "sample_time_ms": 5981.793, "learn_time_ms": 27366.606, "learn_throughput": 146.164, "synch_weights_time_ms": 37.088}, "counters": {"num_env_steps_sampled": 376000, "num_env_steps_trained": 376000, "num_agent_steps_sampled": 1504000, "num_agent_steps_trained": 1504000}, "done": false, "training_iteration": 94, "trial_id": "75ec3_00000", "date": "2024-08-13_03-05-58", "timestamp": 1723532758, "time_this_iter_s": 33.65387296676636, "time_total_s": 6410.936423778534, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b206be50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 6410.936423778534, "iterations_since_restore": 94, "perf": {"cpu_util_percent": 89.12978723404254, "ram_util_percent": 83.26170212765959}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 10.60815248438921, "cur_kl_coeff": 0.1924338385462761, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.08082235856031, "policy_loss": -0.00400750680885736, "vf_loss": 7.083868179876338, "vf_explained_var": 0.36070104011152154, "kl": 0.004997567917307871, "entropy": 1.0075457678585455, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 178605.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.21031026788469817, "cur_kl_coeff": 6.661338147750938e-17, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.15792025878394722, "policy_loss": -0.0002212656674187177, "vf_loss": 0.15814152434492906, "vf_explained_var": 0.005459806464967273, "kl": 0.0018973114611367538, "entropy": 0.3169058705054263, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 178605.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 380000, "num_env_steps_trained": 380000, "num_agent_steps_sampled": 1520000, "num_agent_steps_trained": 1520000}, "env_runners": {"episode_reward_max": 382.9000000000001, "episode_reward_min": 10.100000000000156, "episode_reward_mean": 237.66599999999977, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -45.69999999999977, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 197.29999999999998, "predator_policy": 52.0}, "policy_reward_mean": {"prey_policy": 115.13299999999995, "predator_policy": 3.7}, "custom_metrics": {}, "hist_stats": {"episode_reward": [289.19999999999993, 242.49999999999991, 281.4999999999997, 282.10000000000036, 230.99999999999955, 191.59999999999937, 260.4999999999994, 169.59999999999965, 233.2999999999997, 10.100000000000156, 161.49999999999986, 177.69999999999936, 322.0, 309.99999999999994, 296.5000000000007, 201.3999999999995, 168.6, 287.99999999999983, 250.79999999999976, 207.8999999999999, 199.19999999999968, 53.89999999999999, 147.9999999999992, 252.69999999999962, 325.0000000000002, 209.49999999999955, 323.5000000000004, 309.0999999999998, 248.49999999999957, 282.10000000000065, 355.90000000000003, 312.7, 105.99999999999986, 181.39999999999924, 169.89999999999938, 183.0999999999995, 229.8999999999992, 198.39999999999918, 317.2000000000002, 238.89999999999964, 256.8999999999991, 300.1999999999997, 272.0999999999999, 325.8999999999999, 179.9, 382.9000000000001, 364.0000000000006, 215.19999999999942, 311.4000000000001, 205.59999999999928, 208.59999999999982, 97.10000000000005, 227.59999999999977, 181.09999999999988, 238.89999999999938, 147.09999999999965, 262.49999999999994, 166.6999999999995, 275.79999999999967, 291.2000000000006, 81.20000000000017, 210.19999999999936, 274.89999999999935, 195.4999999999992, 229.8999999999997, 142.29999999999941, 321.5000000000002, 292.0999999999999, 327.10000000000014, 269.4999999999998, 321.8999999999998, 327.3000000000004, 342.39999999999986, 359.29999999999984, 335.30000000000035, 40.80000000000021, 246.09999999999954, 48.200000000000244, 295.5999999999999, 240.19999999999945, 227.1999999999995, 134.9999999999993, 113.49999999999946, 363.79999999999984, 228.09999999999923, 133.59999999999997, 225.79999999999987, 330.7000000000007, 326.30000000000007, 108.20000000000002, 246.99999999999972, 208.2999999999992, 345.1, 187.89999999999975, 172.79999999999902, 323.50000000000017, 227.1999999999991, 332.30000000000047, 203.79999999999973, 293.7999999999999], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [110.29999999999981, 173.9, 129.80000000000004, 112.69999999999987, 101.00000000000009, 177.49999999999994, 185.6, 96.49999999999989, 65.00000000000001, 157.99999999999994, 20.000000000000014, 164.59999999999997, 182.9, 77.59999999999926, 77.59999999999975, 91.99999999999997, 115.6999999999999, 110.59999999999997, -2.199999999999905, -45.69999999999977, 23.30000000000012, 111.20000000000005, 157.69999999999996, 20.000000000000014, 182.89999999999992, 136.0999999999999, 184.7, 125.29999999999997, 132.50000000000003, 163.99999999999977, 111.4999999999999, 59.900000000000084, 94.69999999999999, 59.89999999999999, 146.3, 130.6999999999999, 127.09999999999985, 106.69999999999999, 98.59999999999997, 107.29999999999998, 122.00000000000006, 72.19999999999975, 46.99999999999999, -36.09999999999984, 20.000000000000014, 127.99999999999977, 76.10000000000001, 155.59999999999997, 172.09999999999994, 146.8999999999999, 20.000000000000096, 177.49999999999997, 197.29999999999998, 126.19999999999979, 179.29999999999998, 129.79999999999984, 66.80000000000004, 175.69999999999987, 155.89999999999984, 126.19999999999965, 159.49999999999986, 196.39999999999998, 176.59999999999994, 136.09999999999997, -28.29999999999977, 104.29999999999998, 157.39999999999995, 20.000000000000014, 163.09999999999994, -5.200000000000021, 43.400000000000034, 130.69999999999976, 64.10000000000021, 156.79999999999993, 146.89999999999972, 51.499999999999964, 154.1, 163.09999999999997, 100.99999999999999, 137.89999999999986, 190.99999999999994, 65.90000000000008, 144.19999999999993, 151.99999999999983, 120.49999999999997, 140.59999999999997, 161.29999999999987, 158.59999999999994, 171.19999999999993, -43.300000000000466, 190.99999999999994, 191.9, 192.79999999999995, 171.19999999999987, 83.00000000000009, 117.19999999999972, 141.49999999999997, 158.89999999999998, 165.7999999999999, 39.80000000000007, 118.99999999999999, 77.60000000000014, 48.49999999999997, 41.60000000000014, 91.09999999999997, 120.49999999999989, 77.29999999999995, 102.79999999999993, 115.39999999999989, 123.49999999999989, 124.40000000000003, 22.70000000000001, 94.09999999999995, 151.4, 25.400000000000006, 140.3, 132.5, 143.29999999999995, 112.39999999999993, 165.79999999999987, 62.30000000000022, 17.899999999999977, 162.19999999999987, 35.000000000000135, 96.49999999999982, 178.39999999999992, 143.89999999999995, 41.60000000000016, 171.2, 49.70000000000006, 75.79999999999998, 60.500000000000085, 170.00000000000003, 150.49999999999977, 139.69999999999993, 139.39999999999998, 188.29999999999993, 138.7999999999999, 117.49999999999969, 137.0, 143.29999999999984, 170.59999999999997, 153.49999999999994, 162.79999999999993, 163.0999999999999, 179.29999999999998, 185.59999999999997, 172.70000000000005, 168.7999999999999, 153.5, 20.000000000000014, 15.799999999999967, 181.09999999999988, 55.99999999999999, 48.50000000000012, -31.300000000000036, 134.3, 161.2999999999998, 80.89999999999972, 152.2999999999999, 56.90000000000012, 170.29999999999998, 20.000000000000014, 103.99999999999983, 63.2000000000001, 44.300000000000026, 187.09999999999994, 175.6999999999999, 148.70000000000002, 79.40000000000005, 89.29999999999995, 44.300000000000075, 95.6, 114.2, 190.10000000000002, 140.59999999999965, 166.7, 146.59999999999997, 38.60000000000015, 68.59999999999997, 163.99999999999994, 82.99999999999997, 20.000000000000014, 188.29999999999993, 163.09999999999997, 173.0, 64.40000000000018, 111.50000000000001, 26.300000000000004, 144.4999999999997, 174.79999999999998, 148.6999999999999, 108.19999999999953, 118.99999999999957, 165.79999999999995, 165.49999999999986, 125.29999999999997, 78.49999999999997, 175.69999999999993, 118.09999999999974], "policy_predator_policy_reward": [0.0, 5.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 8.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 17.0, 41.0, 15.0, 12.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 1.0, 29.0, 6.0, 8.0, 11.0, 0.0, 11.0, 6.0, 0.0, 2.0, 0.0, 5.0, 15.0, 28.0, 0.0, 0.0, 11.0, 10.0, 0.0, 6.0, 8.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 23.0, 0.0, 4.0, 12.0, 0.0, 9.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 10.0, 1.0, 0.0, 6.0, 0.0, 52.0, 0.0, 0.0, 0.0, 0.0, 15.0, 0.0, 3.0, 8.0, 0.0, 0.0, 12.0, 0.0, 0.0, 7.0, 0.0, 16.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 16.0, 0.0, 1.0, 0.0, 0.0, 0.0, 13.0, 1.0, 0.0, 7.0, 6.0, 0.0, 0.0, 1.0, 9.0, 9.0, 0.0, 6.0, 0.0, 0.0, 1.0, 13.0, 0.0, 0.0, 0.0, 15.0, 0.0, 0.0, 8.0, 0.0, 11.0, 0.0, 0.0, 0.0, 1.0, 13.0, 0.0, 0.0, 5.0, 4.0, 5.0, 31.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 11.0, 0.0, 6.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 4.0, 9.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 12.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 12.71957861546838, "mean_inference_ms": 27.94334661599019, "mean_action_processing_ms": 6.239246519153534, "mean_env_wait_ms": 8.288959837570316, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.048362135887145996, "StateBufferConnector_ms": 0.01738715171813965, "ViewRequirementAgentConnector_ms": 0.5897552967071533}, "num_episodes": 18, "episode_return_max": 382.9000000000001, "episode_return_min": 10.100000000000156, "episode_return_mean": 237.66599999999977, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1520000, "num_agent_steps_trained": 1520000, "num_env_steps_sampled": 380000, "num_env_steps_trained": 380000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 118.27802747614598, "num_env_steps_trained_throughput_per_sec": 118.27802747614598, "timesteps_total": 380000, "num_env_steps_sampled_lifetime": 380000, "num_agent_steps_sampled_lifetime": 1520000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1520000, "timers": {"training_iteration_time_ms": 33685.673, "restore_workers_time_ms": 0.033, "training_step_time_ms": 33685.575, "sample_time_ms": 6020.568, "learn_time_ms": 27620.436, "learn_throughput": 144.82, "synch_weights_time_ms": 36.112}, "counters": {"num_env_steps_sampled": 380000, "num_env_steps_trained": 380000, "num_agent_steps_sampled": 1520000, "num_agent_steps_trained": 1520000}, "done": false, "training_iteration": 95, "trial_id": "75ec3_00000", "date": "2024-08-13_03-06-32", "timestamp": 1723532792, "time_this_iter_s": 33.884685039520264, "time_total_s": 6444.821108818054, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b223a280>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 6444.821108818054, "iterations_since_restore": 95, "perf": {"cpu_util_percent": 88.38541666666667, "ram_util_percent": 83.10208333333334}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 10.96654776300072, "cur_kl_coeff": 0.09621691927313805, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.881887082700376, "policy_loss": -0.004484644249603941, "vf_loss": 6.884708250893487, "vf_explained_var": 0.4253695446032065, "kl": 0.01728896282511622, "entropy": 0.986723016431092, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 180495.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5851836847565162, "cur_kl_coeff": 3.330669073875469e-17, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.7414846246046994, "policy_loss": -0.0004711579957671424, "vf_loss": 0.7419557840499298, "vf_explained_var": 0.009020967142922538, "kl": 0.002474286413374369, "entropy": 0.3610926254401131, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 180495.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 384000, "num_env_steps_trained": 384000, "num_agent_steps_sampled": 1536000, "num_agent_steps_trained": 1536000}, "env_runners": {"episode_reward_max": 382.9000000000001, "episode_reward_min": 40.80000000000021, "episode_reward_mean": 250.60999999999981, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -43.300000000000466, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 197.29999999999998, "predator_policy": 52.0}, "policy_reward_mean": {"prey_policy": 122.14999999999992, "predator_policy": 3.155}, "custom_metrics": {}, "hist_stats": {"episode_reward": [252.69999999999962, 325.0000000000002, 209.49999999999955, 323.5000000000004, 309.0999999999998, 248.49999999999957, 282.10000000000065, 355.90000000000003, 312.7, 105.99999999999986, 181.39999999999924, 169.89999999999938, 183.0999999999995, 229.8999999999992, 198.39999999999918, 317.2000000000002, 238.89999999999964, 256.8999999999991, 300.1999999999997, 272.0999999999999, 325.8999999999999, 179.9, 382.9000000000001, 364.0000000000006, 215.19999999999942, 311.4000000000001, 205.59999999999928, 208.59999999999982, 97.10000000000005, 227.59999999999977, 181.09999999999988, 238.89999999999938, 147.09999999999965, 262.49999999999994, 166.6999999999995, 275.79999999999967, 291.2000000000006, 81.20000000000017, 210.19999999999936, 274.89999999999935, 195.4999999999992, 229.8999999999997, 142.29999999999941, 321.5000000000002, 292.0999999999999, 327.10000000000014, 269.4999999999998, 321.8999999999998, 327.3000000000004, 342.39999999999986, 359.29999999999984, 335.30000000000035, 40.80000000000021, 246.09999999999954, 48.200000000000244, 295.5999999999999, 240.19999999999945, 227.1999999999995, 134.9999999999993, 113.49999999999946, 363.79999999999984, 228.09999999999923, 133.59999999999997, 225.79999999999987, 330.7000000000007, 326.30000000000007, 108.20000000000002, 246.99999999999972, 208.2999999999992, 345.1, 187.89999999999975, 172.79999999999902, 323.50000000000017, 227.1999999999991, 332.30000000000047, 203.79999999999973, 293.7999999999999, 226.9999999999992, 316.0000000000002, 281.6000000000002, 252.1999999999994, 329.3000000000001, 293.1999999999998, 300.1, 302.8000000000004, 312.4000000000001, 200.8999999999992, 338.80000000000007, 258.69999999999993, 298.99999999999994, 209.89999999999924, 295.3000000000001, 215.49999999999923, 250.49999999999957, 290.1000000000013, 181.29999999999944, 302.0000000000001, 302.99999999999966, 321.4, 190.2999999999996], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [76.10000000000001, 155.59999999999997, 172.09999999999994, 146.8999999999999, 20.000000000000096, 177.49999999999997, 197.29999999999998, 126.19999999999979, 179.29999999999998, 129.79999999999984, 66.80000000000004, 175.69999999999987, 155.89999999999984, 126.19999999999965, 159.49999999999986, 196.39999999999998, 176.59999999999994, 136.09999999999997, -28.29999999999977, 104.29999999999998, 157.39999999999995, 20.000000000000014, 163.09999999999994, -5.200000000000021, 43.400000000000034, 130.69999999999976, 64.10000000000021, 156.79999999999993, 146.89999999999972, 51.499999999999964, 154.1, 163.09999999999997, 100.99999999999999, 137.89999999999986, 190.99999999999994, 65.90000000000008, 144.19999999999993, 151.99999999999983, 120.49999999999997, 140.59999999999997, 161.29999999999987, 158.59999999999994, 171.19999999999993, -43.300000000000466, 190.99999999999994, 191.9, 192.79999999999995, 171.19999999999987, 83.00000000000009, 117.19999999999972, 141.49999999999997, 158.89999999999998, 165.7999999999999, 39.80000000000007, 118.99999999999999, 77.60000000000014, 48.49999999999997, 41.60000000000014, 91.09999999999997, 120.49999999999989, 77.29999999999995, 102.79999999999993, 115.39999999999989, 123.49999999999989, 124.40000000000003, 22.70000000000001, 94.09999999999995, 151.4, 25.400000000000006, 140.3, 132.5, 143.29999999999995, 112.39999999999993, 165.79999999999987, 62.30000000000022, 17.899999999999977, 162.19999999999987, 35.000000000000135, 96.49999999999982, 178.39999999999992, 143.89999999999995, 41.60000000000016, 171.2, 49.70000000000006, 75.79999999999998, 60.500000000000085, 170.00000000000003, 150.49999999999977, 139.69999999999993, 139.39999999999998, 188.29999999999993, 138.7999999999999, 117.49999999999969, 137.0, 143.29999999999984, 170.59999999999997, 153.49999999999994, 162.79999999999993, 163.0999999999999, 179.29999999999998, 185.59999999999997, 172.70000000000005, 168.7999999999999, 153.5, 20.000000000000014, 15.799999999999967, 181.09999999999988, 55.99999999999999, 48.50000000000012, -31.300000000000036, 134.3, 161.2999999999998, 80.89999999999972, 152.2999999999999, 56.90000000000012, 170.29999999999998, 20.000000000000014, 103.99999999999983, 63.2000000000001, 44.300000000000026, 187.09999999999994, 175.6999999999999, 148.70000000000002, 79.40000000000005, 89.29999999999995, 44.300000000000075, 95.6, 114.2, 190.10000000000002, 140.59999999999965, 166.7, 146.59999999999997, 38.60000000000015, 68.59999999999997, 163.99999999999994, 82.99999999999997, 20.000000000000014, 188.29999999999993, 163.09999999999997, 173.0, 64.40000000000018, 111.50000000000001, 26.300000000000004, 144.4999999999997, 174.79999999999998, 148.6999999999999, 108.19999999999953, 118.99999999999957, 165.79999999999995, 165.49999999999986, 125.29999999999997, 78.49999999999997, 175.69999999999993, 118.09999999999974, 131.59999999999997, 94.3999999999995, 131.8999999999997, 178.1, 88.09999999999991, 186.49999999999991, 59.30000000000015, 191.89999999999995, 178.39999999999992, 146.89999999999992, 151.70000000000002, 129.4999999999997, 182.9, 117.19999999999997, 174.79999999999987, 128.00000000000003, 165.19999999999993, 138.19999999999985, 124.09999999999957, 75.79999999999967, 155.89999999999998, 182.89999999999998, 143.29999999999993, 115.39999999999998, 114.49999999999999, 174.5, 10.699999999999948, 189.19999999999993, 123.1999999999999, 148.09999999999994, 20.000000000000014, 195.49999999999997, 110.30000000000007, 126.19999999999996, 133.3999999999997, 151.6999999999999, 20.000000000000014, 161.3, 132.49999999999997, 156.49999999999994, 137.2999999999999, 157.69999999999982, 170.29999999999998, 145.1, 111.79999999999976, 78.50000000000004], "policy_predator_policy_reward": [11.0, 10.0, 0.0, 6.0, 8.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 23.0, 0.0, 4.0, 12.0, 0.0, 9.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 10.0, 1.0, 0.0, 6.0, 0.0, 52.0, 0.0, 0.0, 0.0, 0.0, 15.0, 0.0, 3.0, 8.0, 0.0, 0.0, 12.0, 0.0, 0.0, 7.0, 0.0, 16.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 16.0, 0.0, 1.0, 0.0, 0.0, 0.0, 13.0, 1.0, 0.0, 7.0, 6.0, 0.0, 0.0, 1.0, 9.0, 9.0, 0.0, 6.0, 0.0, 0.0, 1.0, 13.0, 0.0, 0.0, 0.0, 15.0, 0.0, 0.0, 8.0, 0.0, 11.0, 0.0, 0.0, 0.0, 1.0, 13.0, 0.0, 0.0, 5.0, 4.0, 5.0, 31.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 11.0, 0.0, 6.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 4.0, 9.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 12.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 6.0, 7.0, 0.0, 1.0, 0.0, 1.0, 3.0, 8.0, 4.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 10.0, 12.0, 12.0, 0.0, 0.0, 6.0, 8.0, 5.0, 0.0, 0.0, 0.0, 13.0, 0.0, 0.0, 8.0, 6.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 12.60645823806852, "mean_inference_ms": 27.69519590604249, "mean_action_processing_ms": 6.166768067074298, "mean_env_wait_ms": 8.22128709106207, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.038617491722106934, "StateBufferConnector_ms": 0.04121804237365723, "ViewRequirementAgentConnector_ms": 0.5291517972946167}, "num_episodes": 23, "episode_return_max": 382.9000000000001, "episode_return_min": 40.80000000000021, "episode_return_mean": 250.60999999999981, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1536000, "num_agent_steps_trained": 1536000, "num_env_steps_sampled": 384000, "num_env_steps_trained": 384000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 128.89912529044187, "num_env_steps_trained_throughput_per_sec": 128.89912529044187, "timesteps_total": 384000, "num_env_steps_sampled_lifetime": 384000, "num_agent_steps_sampled_lifetime": 1536000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1536000, "timers": {"training_iteration_time_ms": 33739.027, "restore_workers_time_ms": 0.033, "training_step_time_ms": 33738.929, "sample_time_ms": 6058.212, "learn_time_ms": 27635.456, "learn_throughput": 144.742, "synch_weights_time_ms": 36.691}, "counters": {"num_env_steps_sampled": 384000, "num_env_steps_trained": 384000, "num_agent_steps_sampled": 1536000, "num_agent_steps_trained": 1536000}, "done": false, "training_iteration": 96, "trial_id": "75ec3_00000", "date": "2024-08-13_03-07-03", "timestamp": 1723532823, "time_this_iter_s": 31.113549947738647, "time_total_s": 6475.934658765793, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b223a820>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 6475.934658765793, "iterations_since_restore": 96, "perf": {"cpu_util_percent": 88.09545454545454, "ram_util_percent": 83.11363636363636}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 10.274636814833949, "cur_kl_coeff": 0.09621691927313805, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.260251646445543, "policy_loss": -0.006475131028016448, "vf_loss": 8.263729428235816, "vf_explained_var": 0.038100097765998236, "kl": 0.031151971820126283, "entropy": 1.0210792489468106, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 182385.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.222718269810593, "cur_kl_coeff": 1.6653345369377344e-17, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.07979569634701071, "policy_loss": 0.00025219992640866803, "vf_loss": 0.07954349664468614, "vf_explained_var": -0.06011877107241797, "kl": 0.0007729266868276382, "entropy": 0.3688028280066435, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 182385.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 388000, "num_env_steps_trained": 388000, "num_agent_steps_sampled": 1552000, "num_agent_steps_trained": 1552000}, "env_runners": {"episode_reward_max": 382.9000000000001, "episode_reward_min": 40.80000000000021, "episode_reward_mean": 248.7389999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -43.300000000000466, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 195.49999999999997, "predator_policy": 52.0}, "policy_reward_mean": {"prey_policy": 121.04449999999993, "predator_policy": 3.325}, "custom_metrics": {}, "hist_stats": {"episode_reward": [300.1999999999997, 272.0999999999999, 325.8999999999999, 179.9, 382.9000000000001, 364.0000000000006, 215.19999999999942, 311.4000000000001, 205.59999999999928, 208.59999999999982, 97.10000000000005, 227.59999999999977, 181.09999999999988, 238.89999999999938, 147.09999999999965, 262.49999999999994, 166.6999999999995, 275.79999999999967, 291.2000000000006, 81.20000000000017, 210.19999999999936, 274.89999999999935, 195.4999999999992, 229.8999999999997, 142.29999999999941, 321.5000000000002, 292.0999999999999, 327.10000000000014, 269.4999999999998, 321.8999999999998, 327.3000000000004, 342.39999999999986, 359.29999999999984, 335.30000000000035, 40.80000000000021, 246.09999999999954, 48.200000000000244, 295.5999999999999, 240.19999999999945, 227.1999999999995, 134.9999999999993, 113.49999999999946, 363.79999999999984, 228.09999999999923, 133.59999999999997, 225.79999999999987, 330.7000000000007, 326.30000000000007, 108.20000000000002, 246.99999999999972, 208.2999999999992, 345.1, 187.89999999999975, 172.79999999999902, 323.50000000000017, 227.1999999999991, 332.30000000000047, 203.79999999999973, 293.7999999999999, 226.9999999999992, 316.0000000000002, 281.6000000000002, 252.1999999999994, 329.3000000000001, 293.1999999999998, 300.1, 302.8000000000004, 312.4000000000001, 200.8999999999992, 338.80000000000007, 258.69999999999993, 298.99999999999994, 209.89999999999924, 295.3000000000001, 215.49999999999923, 250.49999999999957, 290.1000000000013, 181.29999999999944, 302.0000000000001, 302.99999999999966, 321.4, 190.2999999999996, 213.79999999999933, 91.39999999999952, 250.4999999999996, 270.5000000000004, 234.99999999999943, 294.29999999999967, 262.2999999999996, 295.4999999999998, 198.39999999999947, 260.6999999999994, 216.39999999999895, 259.2999999999996, 163.0999999999995, 267.4999999999998, 286.6, 310.9000000000001, 153.4999999999999, 283.8999999999997], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [144.19999999999993, 151.99999999999983, 120.49999999999997, 140.59999999999997, 161.29999999999987, 158.59999999999994, 171.19999999999993, -43.300000000000466, 190.99999999999994, 191.9, 192.79999999999995, 171.19999999999987, 83.00000000000009, 117.19999999999972, 141.49999999999997, 158.89999999999998, 165.7999999999999, 39.80000000000007, 118.99999999999999, 77.60000000000014, 48.49999999999997, 41.60000000000014, 91.09999999999997, 120.49999999999989, 77.29999999999995, 102.79999999999993, 115.39999999999989, 123.49999999999989, 124.40000000000003, 22.70000000000001, 94.09999999999995, 151.4, 25.400000000000006, 140.3, 132.5, 143.29999999999995, 112.39999999999993, 165.79999999999987, 62.30000000000022, 17.899999999999977, 162.19999999999987, 35.000000000000135, 96.49999999999982, 178.39999999999992, 143.89999999999995, 41.60000000000016, 171.2, 49.70000000000006, 75.79999999999998, 60.500000000000085, 170.00000000000003, 150.49999999999977, 139.69999999999993, 139.39999999999998, 188.29999999999993, 138.7999999999999, 117.49999999999969, 137.0, 143.29999999999984, 170.59999999999997, 153.49999999999994, 162.79999999999993, 163.0999999999999, 179.29999999999998, 185.59999999999997, 172.70000000000005, 168.7999999999999, 153.5, 20.000000000000014, 15.799999999999967, 181.09999999999988, 55.99999999999999, 48.50000000000012, -31.300000000000036, 134.3, 161.2999999999998, 80.89999999999972, 152.2999999999999, 56.90000000000012, 170.29999999999998, 20.000000000000014, 103.99999999999983, 63.2000000000001, 44.300000000000026, 187.09999999999994, 175.6999999999999, 148.70000000000002, 79.40000000000005, 89.29999999999995, 44.300000000000075, 95.6, 114.2, 190.10000000000002, 140.59999999999965, 166.7, 146.59999999999997, 38.60000000000015, 68.59999999999997, 163.99999999999994, 82.99999999999997, 20.000000000000014, 188.29999999999993, 163.09999999999997, 173.0, 64.40000000000018, 111.50000000000001, 26.300000000000004, 144.4999999999997, 174.79999999999998, 148.6999999999999, 108.19999999999953, 118.99999999999957, 165.79999999999995, 165.49999999999986, 125.29999999999997, 78.49999999999997, 175.69999999999993, 118.09999999999974, 131.59999999999997, 94.3999999999995, 131.8999999999997, 178.1, 88.09999999999991, 186.49999999999991, 59.30000000000015, 191.89999999999995, 178.39999999999992, 146.89999999999992, 151.70000000000002, 129.4999999999997, 182.9, 117.19999999999997, 174.79999999999987, 128.00000000000003, 165.19999999999993, 138.19999999999985, 124.09999999999957, 75.79999999999967, 155.89999999999998, 182.89999999999998, 143.29999999999993, 115.39999999999998, 114.49999999999999, 174.5, 10.699999999999948, 189.19999999999993, 123.1999999999999, 148.09999999999994, 20.000000000000014, 195.49999999999997, 110.30000000000007, 126.19999999999996, 133.3999999999997, 151.6999999999999, 20.000000000000014, 161.3, 132.49999999999997, 156.49999999999994, 137.2999999999999, 157.69999999999982, 170.29999999999998, 145.1, 111.79999999999976, 78.50000000000004, 157.70000000000002, 52.10000000000016, 33.50000000000016, 53.90000000000006, 4.700000000000093, 192.79999999999995, 132.19999999999985, 134.29999999999959, 46.099999999999994, 182.8999999999999, 98.60000000000007, 193.7, 118.09999999999982, 144.19999999999976, 147.19999999999987, 134.29999999999978, 57.8000000000001, 131.5999999999999, 128.2999999999998, 124.3999999999996, 70.39999999999972, 145.99999999999991, 91.0999999999999, 153.19999999999976, 87.49999999999989, 65.60000000000007, 139.39999999999984, 127.09999999999998, 136.9999999999998, 140.59999999999994, 144.19999999999987, 166.6999999999998, 79.09999999999994, 70.39999999999992, 181.99999999999991, 101.89999999999998], "policy_predator_policy_reward": [0.0, 4.0, 10.0, 1.0, 0.0, 6.0, 0.0, 52.0, 0.0, 0.0, 0.0, 0.0, 15.0, 0.0, 3.0, 8.0, 0.0, 0.0, 12.0, 0.0, 0.0, 7.0, 0.0, 16.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 16.0, 0.0, 1.0, 0.0, 0.0, 0.0, 13.0, 1.0, 0.0, 7.0, 6.0, 0.0, 0.0, 1.0, 9.0, 9.0, 0.0, 6.0, 0.0, 0.0, 1.0, 13.0, 0.0, 0.0, 0.0, 15.0, 0.0, 0.0, 8.0, 0.0, 11.0, 0.0, 0.0, 0.0, 1.0, 13.0, 0.0, 0.0, 5.0, 4.0, 5.0, 31.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 11.0, 0.0, 6.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 4.0, 9.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 12.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 6.0, 7.0, 0.0, 1.0, 0.0, 1.0, 3.0, 8.0, 4.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 10.0, 12.0, 12.0, 0.0, 0.0, 6.0, 8.0, 5.0, 0.0, 0.0, 0.0, 13.0, 0.0, 0.0, 8.0, 6.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 4.0, 26.0, 27.0, 0.0, 4.0, 0.0, 6.0, 2.0, 0.0, 0.0, 0.0, 9.0, 5.0, 0.0, 9.0, 0.0, 8.0, 0.0, 0.0, 15.0, 0.0, 0.0, 10.0, 0.0, 1.0, 9.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 12.506052303634949, "mean_inference_ms": 27.4876593583174, "mean_action_processing_ms": 6.115783622013428, "mean_env_wait_ms": 8.149761083249421, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.013923406600952148, "StateBufferConnector_ms": 0.042508721351623535, "ViewRequirementAgentConnector_ms": 0.37173330783843994}, "num_episodes": 18, "episode_return_max": 382.9000000000001, "episode_return_min": 40.80000000000021, "episode_return_mean": 248.7389999999998, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1552000, "num_agent_steps_trained": 1552000, "num_env_steps_sampled": 388000, "num_env_steps_trained": 388000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 131.77283071171453, "num_env_steps_trained_throughput_per_sec": 131.77283071171453, "timesteps_total": 388000, "num_env_steps_sampled_lifetime": 388000, "num_agent_steps_sampled_lifetime": 1552000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1552000, "timers": {"training_iteration_time_ms": 33759.982, "restore_workers_time_ms": 0.033, "training_step_time_ms": 33759.883, "sample_time_ms": 5963.204, "learn_time_ms": 27750.845, "learn_throughput": 144.14, "synch_weights_time_ms": 37.191}, "counters": {"num_env_steps_sampled": 388000, "num_env_steps_trained": 388000, "num_agent_steps_sampled": 1552000, "num_agent_steps_trained": 1552000}, "done": false, "training_iteration": 97, "trial_id": "75ec3_00000", "date": "2024-08-13_03-07-34", "timestamp": 1723532854, "time_this_iter_s": 30.42383909225464, "time_total_s": 6506.3584978580475, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b206be50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 6506.3584978580475, "iterations_since_restore": 97, "perf": {"cpu_util_percent": 88.36046511627909, "ram_util_percent": 83.19302325581394}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 9.52655718302916, "cur_kl_coeff": 0.14432537890970704, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.3965590416439, "policy_loss": -0.0020372300657626025, "vf_loss": 6.39708804428262, "vf_explained_var": 0.43487886344944987, "kl": 0.01045013810422706, "entropy": 0.9945842901865641, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 184275.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4565981678901211, "cur_kl_coeff": 8.326672684688672e-18, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.8364329476993551, "policy_loss": -0.0007085323449539603, "vf_loss": 0.837141478802792, "vf_explained_var": 0.011333368663434628, "kl": 0.0029190184922039857, "entropy": 0.2906945509175775, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 184275.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 392000, "num_env_steps_trained": 392000, "num_agent_steps_sampled": 1568000, "num_agent_steps_trained": 1568000}, "env_runners": {"episode_reward_max": 368.8999999999999, "episode_reward_min": 40.80000000000021, "episode_reward_mean": 255.40099999999984, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -31.300000000000036, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 195.49999999999997, "predator_policy": 31.0}, "policy_reward_mean": {"prey_policy": 124.60549999999994, "predator_policy": 3.095}, "custom_metrics": {}, "hist_stats": {"episode_reward": [195.4999999999992, 229.8999999999997, 142.29999999999941, 321.5000000000002, 292.0999999999999, 327.10000000000014, 269.4999999999998, 321.8999999999998, 327.3000000000004, 342.39999999999986, 359.29999999999984, 335.30000000000035, 40.80000000000021, 246.09999999999954, 48.200000000000244, 295.5999999999999, 240.19999999999945, 227.1999999999995, 134.9999999999993, 113.49999999999946, 363.79999999999984, 228.09999999999923, 133.59999999999997, 225.79999999999987, 330.7000000000007, 326.30000000000007, 108.20000000000002, 246.99999999999972, 208.2999999999992, 345.1, 187.89999999999975, 172.79999999999902, 323.50000000000017, 227.1999999999991, 332.30000000000047, 203.79999999999973, 293.7999999999999, 226.9999999999992, 316.0000000000002, 281.6000000000002, 252.1999999999994, 329.3000000000001, 293.1999999999998, 300.1, 302.8000000000004, 312.4000000000001, 200.8999999999992, 338.80000000000007, 258.69999999999993, 298.99999999999994, 209.89999999999924, 295.3000000000001, 215.49999999999923, 250.49999999999957, 290.1000000000013, 181.29999999999944, 302.0000000000001, 302.99999999999966, 321.4, 190.2999999999996, 213.79999999999933, 91.39999999999952, 250.4999999999996, 270.5000000000004, 234.99999999999943, 294.29999999999967, 262.2999999999996, 295.4999999999998, 198.39999999999947, 260.6999999999994, 216.39999999999895, 259.2999999999996, 163.0999999999995, 267.4999999999998, 286.6, 310.9000000000001, 153.4999999999999, 283.8999999999997, 189.3999999999995, 295.3, 278.2999999999996, 149.7999999999996, 301.29999999999984, 348.19999999999993, 267.99999999999983, 336.10000000000014, 178.5999999999993, 244.1, 210.99999999999957, 368.8999999999999, 262.6999999999998, 237.49999999999966, 349.6, 319.7, 334.49999999999983, 359.6000000000002, 253.29999999999987, 209.1999999999993, 173.8999999999997, 217.29999999999964], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [143.89999999999995, 41.60000000000016, 171.2, 49.70000000000006, 75.79999999999998, 60.500000000000085, 170.00000000000003, 150.49999999999977, 139.69999999999993, 139.39999999999998, 188.29999999999993, 138.7999999999999, 117.49999999999969, 137.0, 143.29999999999984, 170.59999999999997, 153.49999999999994, 162.79999999999993, 163.0999999999999, 179.29999999999998, 185.59999999999997, 172.70000000000005, 168.7999999999999, 153.5, 20.000000000000014, 15.799999999999967, 181.09999999999988, 55.99999999999999, 48.50000000000012, -31.300000000000036, 134.3, 161.2999999999998, 80.89999999999972, 152.2999999999999, 56.90000000000012, 170.29999999999998, 20.000000000000014, 103.99999999999983, 63.2000000000001, 44.300000000000026, 187.09999999999994, 175.6999999999999, 148.70000000000002, 79.40000000000005, 89.29999999999995, 44.300000000000075, 95.6, 114.2, 190.10000000000002, 140.59999999999965, 166.7, 146.59999999999997, 38.60000000000015, 68.59999999999997, 163.99999999999994, 82.99999999999997, 20.000000000000014, 188.29999999999993, 163.09999999999997, 173.0, 64.40000000000018, 111.50000000000001, 26.300000000000004, 144.4999999999997, 174.79999999999998, 148.6999999999999, 108.19999999999953, 118.99999999999957, 165.79999999999995, 165.49999999999986, 125.29999999999997, 78.49999999999997, 175.69999999999993, 118.09999999999974, 131.59999999999997, 94.3999999999995, 131.8999999999997, 178.1, 88.09999999999991, 186.49999999999991, 59.30000000000015, 191.89999999999995, 178.39999999999992, 146.89999999999992, 151.70000000000002, 129.4999999999997, 182.9, 117.19999999999997, 174.79999999999987, 128.00000000000003, 165.19999999999993, 138.19999999999985, 124.09999999999957, 75.79999999999967, 155.89999999999998, 182.89999999999998, 143.29999999999993, 115.39999999999998, 114.49999999999999, 174.5, 10.699999999999948, 189.19999999999993, 123.1999999999999, 148.09999999999994, 20.000000000000014, 195.49999999999997, 110.30000000000007, 126.19999999999996, 133.3999999999997, 151.6999999999999, 20.000000000000014, 161.3, 132.49999999999997, 156.49999999999994, 137.2999999999999, 157.69999999999982, 170.29999999999998, 145.1, 111.79999999999976, 78.50000000000004, 157.70000000000002, 52.10000000000016, 33.50000000000016, 53.90000000000006, 4.700000000000093, 192.79999999999995, 132.19999999999985, 134.29999999999959, 46.099999999999994, 182.8999999999999, 98.60000000000007, 193.7, 118.09999999999982, 144.19999999999976, 147.19999999999987, 134.29999999999978, 57.8000000000001, 131.5999999999999, 128.2999999999998, 124.3999999999996, 70.39999999999972, 145.99999999999991, 91.0999999999999, 153.19999999999976, 87.49999999999989, 65.60000000000007, 139.39999999999984, 127.09999999999998, 136.9999999999998, 140.59999999999994, 144.19999999999987, 166.6999999999998, 79.09999999999994, 70.39999999999992, 181.99999999999991, 101.89999999999998, 113.6, 75.79999999999987, 141.2, 130.09999999999997, 112.40000000000009, 161.89999999999998, 113.60000000000005, 36.20000000000008, 162.20000000000005, 127.09999999999998, 149.5999999999999, 185.59999999999997, 153.19999999999985, 111.79999999999998, 155.89999999999972, 171.2, 36.19999999999999, 142.3999999999998, 113.30000000000003, 120.79999999999995, 118.99999999999999, 91.9999999999997, 176.59999999999997, 185.29999999999995, 160.99999999999991, 94.69999999999989, 190.7, 30.80000000000019, 175.70000000000002, 173.89999999999995, 165.8, 152.89999999999992, 144.49999999999997, 182.00000000000003, 170.8999999999999, 184.7, 141.49999999999994, 111.80000000000001, 48.80000000000019, 160.4, 71.29999999999981, 101.59999999999994, 166.4, 35.900000000000055], "policy_predator_policy_reward": [1.0, 9.0, 9.0, 0.0, 6.0, 0.0, 0.0, 1.0, 13.0, 0.0, 0.0, 0.0, 15.0, 0.0, 0.0, 8.0, 0.0, 11.0, 0.0, 0.0, 0.0, 1.0, 13.0, 0.0, 0.0, 5.0, 4.0, 5.0, 31.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 11.0, 0.0, 6.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 4.0, 9.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 12.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 6.0, 7.0, 0.0, 1.0, 0.0, 1.0, 3.0, 8.0, 4.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 10.0, 12.0, 12.0, 0.0, 0.0, 6.0, 8.0, 5.0, 0.0, 0.0, 0.0, 13.0, 0.0, 0.0, 8.0, 6.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 4.0, 26.0, 27.0, 0.0, 4.0, 0.0, 6.0, 2.0, 0.0, 0.0, 0.0, 9.0, 5.0, 0.0, 9.0, 0.0, 8.0, 0.0, 0.0, 15.0, 0.0, 0.0, 10.0, 0.0, 1.0, 9.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 12.0, 4.0, 9.0, 3.0, 0.0, 2.0, 7.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 7.0, 0.0, 0.0, 7.0, 1.0, 15.0, 0.0, 0.0, 0.0, 1.0, 8.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 7.0, 8.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 12.629246608959402, "mean_inference_ms": 27.20939207849949, "mean_action_processing_ms": 5.839804071115464, "mean_env_wait_ms": 8.074949216295641, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.014688372611999512, "StateBufferConnector_ms": 0.0422818660736084, "ViewRequirementAgentConnector_ms": 0.376078724861145}, "num_episodes": 22, "episode_return_max": 368.8999999999999, "episode_return_min": 40.80000000000021, "episode_return_mean": 255.40099999999984, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1568000, "num_agent_steps_trained": 1568000, "num_env_steps_sampled": 392000, "num_env_steps_trained": 392000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 130.5223733449625, "num_env_steps_trained_throughput_per_sec": 130.5223733449625, "timesteps_total": 392000, "num_env_steps_sampled_lifetime": 392000, "num_agent_steps_sampled_lifetime": 1568000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1568000, "timers": {"training_iteration_time_ms": 33717.684, "restore_workers_time_ms": 0.033, "training_step_time_ms": 33717.585, "sample_time_ms": 5933.282, "learn_time_ms": 27737.131, "learn_throughput": 144.211, "synch_weights_time_ms": 38.585}, "counters": {"num_env_steps_sampled": 392000, "num_env_steps_trained": 392000, "num_agent_steps_sampled": 1568000, "num_agent_steps_trained": 1568000}, "done": false, "training_iteration": 98, "trial_id": "75ec3_00000", "date": "2024-08-13_03-08-05", "timestamp": 1723532885, "time_this_iter_s": 30.706258296966553, "time_total_s": 6537.064756155014, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b226f670>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 6537.064756155014, "iterations_since_restore": 98, "perf": {"cpu_util_percent": 87.88372093023256, "ram_util_percent": 83.29767441860467}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 10.976406602096306, "cur_kl_coeff": 0.14432537890970704, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.9768427185280615, "policy_loss": -0.0030368416373021704, "vf_loss": 7.978098145742265, "vf_explained_var": 0.1410737846894239, "kl": 0.01234301812713173, "entropy": 0.98963538392511, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 186165.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.37535184928605325, "cur_kl_coeff": 4.163336342344336e-18, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.5947228657032447, "policy_loss": -0.00035959371998807584, "vf_loss": 0.5950824620941328, "vf_explained_var": 0.009784532539428226, "kl": 0.0013016011728477347, "entropy": 0.28059423908039377, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 186165.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 396000, "num_env_steps_trained": 396000, "num_agent_steps_sampled": 1584000, "num_agent_steps_trained": 1584000}, "env_runners": {"episode_reward_max": 368.8999999999999, "episode_reward_min": 91.39999999999952, "episode_reward_mean": 249.04399999999976, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -31.599999999999937, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 195.49999999999997, "predator_policy": 30.0}, "policy_reward_mean": {"prey_policy": 121.12699999999994, "predator_policy": 3.395}, "custom_metrics": {}, "hist_stats": {"episode_reward": [134.9999999999993, 113.49999999999946, 363.79999999999984, 228.09999999999923, 133.59999999999997, 225.79999999999987, 330.7000000000007, 326.30000000000007, 108.20000000000002, 246.99999999999972, 208.2999999999992, 345.1, 187.89999999999975, 172.79999999999902, 323.50000000000017, 227.1999999999991, 332.30000000000047, 203.79999999999973, 293.7999999999999, 226.9999999999992, 316.0000000000002, 281.6000000000002, 252.1999999999994, 329.3000000000001, 293.1999999999998, 300.1, 302.8000000000004, 312.4000000000001, 200.8999999999992, 338.80000000000007, 258.69999999999993, 298.99999999999994, 209.89999999999924, 295.3000000000001, 215.49999999999923, 250.49999999999957, 290.1000000000013, 181.29999999999944, 302.0000000000001, 302.99999999999966, 321.4, 190.2999999999996, 213.79999999999933, 91.39999999999952, 250.4999999999996, 270.5000000000004, 234.99999999999943, 294.29999999999967, 262.2999999999996, 295.4999999999998, 198.39999999999947, 260.6999999999994, 216.39999999999895, 259.2999999999996, 163.0999999999995, 267.4999999999998, 286.6, 310.9000000000001, 153.4999999999999, 283.8999999999997, 189.3999999999995, 295.3, 278.2999999999996, 149.7999999999996, 301.29999999999984, 348.19999999999993, 267.99999999999983, 336.10000000000014, 178.5999999999993, 244.1, 210.99999999999957, 368.8999999999999, 262.6999999999998, 237.49999999999966, 349.6, 319.7, 334.49999999999983, 359.6000000000002, 253.29999999999987, 209.1999999999993, 173.8999999999997, 217.29999999999964, 106.99999999999932, 163.49999999999997, 258.0999999999997, 174.9999999999994, 244.69999999999956, 286.60000000000025, 259.5999999999997, 209.19999999999928, 188.29999999999941, 169.1999999999998, 203.19999999999948, 213.69999999999916, 227.19999999999956, 237.89999999999966, 241.99999999999932, 246.9999999999994, 352.6, 141.69999999999982], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 103.99999999999983, 63.2000000000001, 44.300000000000026, 187.09999999999994, 175.6999999999999, 148.70000000000002, 79.40000000000005, 89.29999999999995, 44.300000000000075, 95.6, 114.2, 190.10000000000002, 140.59999999999965, 166.7, 146.59999999999997, 38.60000000000015, 68.59999999999997, 163.99999999999994, 82.99999999999997, 20.000000000000014, 188.29999999999993, 163.09999999999997, 173.0, 64.40000000000018, 111.50000000000001, 26.300000000000004, 144.4999999999997, 174.79999999999998, 148.6999999999999, 108.19999999999953, 118.99999999999957, 165.79999999999995, 165.49999999999986, 125.29999999999997, 78.49999999999997, 175.69999999999993, 118.09999999999974, 131.59999999999997, 94.3999999999995, 131.8999999999997, 178.1, 88.09999999999991, 186.49999999999991, 59.30000000000015, 191.89999999999995, 178.39999999999992, 146.89999999999992, 151.70000000000002, 129.4999999999997, 182.9, 117.19999999999997, 174.79999999999987, 128.00000000000003, 165.19999999999993, 138.19999999999985, 124.09999999999957, 75.79999999999967, 155.89999999999998, 182.89999999999998, 143.29999999999993, 115.39999999999998, 114.49999999999999, 174.5, 10.699999999999948, 189.19999999999993, 123.1999999999999, 148.09999999999994, 20.000000000000014, 195.49999999999997, 110.30000000000007, 126.19999999999996, 133.3999999999997, 151.6999999999999, 20.000000000000014, 161.3, 132.49999999999997, 156.49999999999994, 137.2999999999999, 157.69999999999982, 170.29999999999998, 145.1, 111.79999999999976, 78.50000000000004, 157.70000000000002, 52.10000000000016, 33.50000000000016, 53.90000000000006, 4.700000000000093, 192.79999999999995, 132.19999999999985, 134.29999999999959, 46.099999999999994, 182.8999999999999, 98.60000000000007, 193.7, 118.09999999999982, 144.19999999999976, 147.19999999999987, 134.29999999999978, 57.8000000000001, 131.5999999999999, 128.2999999999998, 124.3999999999996, 70.39999999999972, 145.99999999999991, 91.0999999999999, 153.19999999999976, 87.49999999999989, 65.60000000000007, 139.39999999999984, 127.09999999999998, 136.9999999999998, 140.59999999999994, 144.19999999999987, 166.6999999999998, 79.09999999999994, 70.39999999999992, 181.99999999999991, 101.89999999999998, 113.6, 75.79999999999987, 141.2, 130.09999999999997, 112.40000000000009, 161.89999999999998, 113.60000000000005, 36.20000000000008, 162.20000000000005, 127.09999999999998, 149.5999999999999, 185.59999999999997, 153.19999999999985, 111.79999999999998, 155.89999999999972, 171.2, 36.19999999999999, 142.3999999999998, 113.30000000000003, 120.79999999999995, 118.99999999999999, 91.9999999999997, 176.59999999999997, 185.29999999999995, 160.99999999999991, 94.69999999999989, 190.7, 30.80000000000019, 175.70000000000002, 173.89999999999995, 165.8, 152.89999999999992, 144.49999999999997, 182.00000000000003, 170.8999999999999, 184.7, 141.49999999999994, 111.80000000000001, 48.80000000000019, 160.4, 71.29999999999981, 101.59999999999994, 166.4, 35.900000000000055, 32.300000000000075, 67.69999999999982, 59.60000000000011, 92.9, 148.09999999999994, 100.99999999999972, 49.700000000000045, 125.2999999999999, 136.0999999999997, 71.6, 190.1, 96.49999999999963, 134.2999999999998, 125.29999999999987, 98.29999999999941, 110.8999999999999, 28.100000000000108, 144.19999999999996, 49.99999999999998, 117.19999999999995, -31.599999999999937, 174.79999999999995, 129.79999999999967, 74.90000000000002, 91.10000000000005, 136.0999999999998, 108.80000000000003, 100.09999999999968, 134.29999999999973, 91.69999999999987, 189.19999999999993, 57.8000000000001, 158.6, 190.99999999999994, 84.7999999999999, 56.90000000000001], "policy_predator_policy_reward": [11.0, 0.0, 6.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 4.0, 9.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 12.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 6.0, 7.0, 0.0, 1.0, 0.0, 1.0, 3.0, 8.0, 4.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 10.0, 12.0, 12.0, 0.0, 0.0, 6.0, 8.0, 5.0, 0.0, 0.0, 0.0, 13.0, 0.0, 0.0, 8.0, 6.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 4.0, 26.0, 27.0, 0.0, 4.0, 0.0, 6.0, 2.0, 0.0, 0.0, 0.0, 9.0, 5.0, 0.0, 9.0, 0.0, 8.0, 0.0, 0.0, 15.0, 0.0, 0.0, 10.0, 0.0, 1.0, 9.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 12.0, 4.0, 9.0, 3.0, 0.0, 2.0, 7.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 7.0, 0.0, 0.0, 7.0, 1.0, 15.0, 0.0, 0.0, 0.0, 1.0, 8.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 7.0, 8.0, 7.0, 0.0, 2.0, 9.0, 3.0, 6.0, 0.0, 0.0, 11.0, 26.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 12.0, 2.0, 0.0, 30.0, 30.0, 9.0, 0.0, 0.0, 0.0, 22.0, 7.0, 10.0, 6.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 12.28956108300587, "mean_inference_ms": 27.053837824348985, "mean_action_processing_ms": 6.01582865105533, "mean_env_wait_ms": 7.982356377206352, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01432490348815918, "StateBufferConnector_ms": 0.0441056489944458, "ViewRequirementAgentConnector_ms": 0.4014688730239868}, "num_episodes": 18, "episode_return_max": 368.8999999999999, "episode_return_min": 91.39999999999952, "episode_return_mean": 249.04399999999976, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1584000, "num_agent_steps_trained": 1584000, "num_env_steps_sampled": 396000, "num_env_steps_trained": 396000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 123.80686881878071, "num_env_steps_trained_throughput_per_sec": 123.80686881878071, "timesteps_total": 396000, "num_env_steps_sampled_lifetime": 396000, "num_agent_steps_sampled_lifetime": 1584000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1584000, "timers": {"training_iteration_time_ms": 33882.184, "restore_workers_time_ms": 0.032, "training_step_time_ms": 33882.087, "sample_time_ms": 5877.127, "learn_time_ms": 27958.283, "learn_throughput": 143.07, "synch_weights_time_ms": 38.266}, "counters": {"num_env_steps_sampled": 396000, "num_env_steps_trained": 396000, "num_agent_steps_sampled": 1584000, "num_agent_steps_trained": 1584000}, "done": false, "training_iteration": 99, "trial_id": "75ec3_00000", "date": "2024-08-13_03-08-37", "timestamp": 1723532917, "time_this_iter_s": 32.37847590446472, "time_total_s": 6569.443232059479, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b221c040>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 6569.443232059479, "iterations_since_restore": 99, "perf": {"cpu_util_percent": 87.68043478260869, "ram_util_percent": 83.1608695652174}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 8.063624440851035, "cur_kl_coeff": 0.14432537890970704, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.0523752782710645, "policy_loss": -0.009277037217000884, "vf_loss": 7.057741182821768, "vf_explained_var": 0.31196823180037203, "kl": 0.02709938750254522, "entropy": 0.9965583186300974, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 188055.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6649954445896641, "cur_kl_coeff": 2.081668171172168e-18, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.4016837608877313, "policy_loss": -0.0008690351812494179, "vf_loss": 1.4025527976808094, "vf_explained_var": 0.01375937439777233, "kl": 0.0021258508105505463, "entropy": 0.24009244576017694, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 188055.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 400000, "num_env_steps_trained": 400000, "num_agent_steps_sampled": 1600000, "num_agent_steps_trained": 1600000}, "env_runners": {"episode_reward_max": 368.8999999999999, "episode_reward_min": 91.39999999999952, "episode_reward_mean": 253.14099999999976, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -31.599999999999937, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 195.49999999999997, "predator_policy": 30.0}, "policy_reward_mean": {"prey_policy": 122.11549999999994, "predator_policy": 4.455}, "custom_metrics": {}, "hist_stats": {"episode_reward": [329.3000000000001, 293.1999999999998, 300.1, 302.8000000000004, 312.4000000000001, 200.8999999999992, 338.80000000000007, 258.69999999999993, 298.99999999999994, 209.89999999999924, 295.3000000000001, 215.49999999999923, 250.49999999999957, 290.1000000000013, 181.29999999999944, 302.0000000000001, 302.99999999999966, 321.4, 190.2999999999996, 213.79999999999933, 91.39999999999952, 250.4999999999996, 270.5000000000004, 234.99999999999943, 294.29999999999967, 262.2999999999996, 295.4999999999998, 198.39999999999947, 260.6999999999994, 216.39999999999895, 259.2999999999996, 163.0999999999995, 267.4999999999998, 286.6, 310.9000000000001, 153.4999999999999, 283.8999999999997, 189.3999999999995, 295.3, 278.2999999999996, 149.7999999999996, 301.29999999999984, 348.19999999999993, 267.99999999999983, 336.10000000000014, 178.5999999999993, 244.1, 210.99999999999957, 368.8999999999999, 262.6999999999998, 237.49999999999966, 349.6, 319.7, 334.49999999999983, 359.6000000000002, 253.29999999999987, 209.1999999999993, 173.8999999999997, 217.29999999999964, 106.99999999999932, 163.49999999999997, 258.0999999999997, 174.9999999999994, 244.69999999999956, 286.60000000000025, 259.5999999999997, 209.19999999999928, 188.29999999999941, 169.1999999999998, 203.19999999999948, 213.69999999999916, 227.19999999999956, 237.89999999999966, 241.99999999999932, 246.9999999999994, 352.6, 141.69999999999982, 289.10000000000025, 285.7000000000003, 305.60000000000025, 294.69999999999993, 274.39999999999986, 156.2, 252.09999999999977, 349.2000000000004, 234.99999999999955, 252.8999999999995, 251.49999999999966, 282.09999999999934, 238.99999999999952, 175.8999999999997, 242.29999999999953, 288.5999999999999, 269.79999999999995, 203.59999999999934, 278.5, 249.69999999999945, 295.4999999999999, 221.69999999999956, 300.09999999999985], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [178.39999999999992, 146.89999999999992, 151.70000000000002, 129.4999999999997, 182.9, 117.19999999999997, 174.79999999999987, 128.00000000000003, 165.19999999999993, 138.19999999999985, 124.09999999999957, 75.79999999999967, 155.89999999999998, 182.89999999999998, 143.29999999999993, 115.39999999999998, 114.49999999999999, 174.5, 10.699999999999948, 189.19999999999993, 123.1999999999999, 148.09999999999994, 20.000000000000014, 195.49999999999997, 110.30000000000007, 126.19999999999996, 133.3999999999997, 151.6999999999999, 20.000000000000014, 161.3, 132.49999999999997, 156.49999999999994, 137.2999999999999, 157.69999999999982, 170.29999999999998, 145.1, 111.79999999999976, 78.50000000000004, 157.70000000000002, 52.10000000000016, 33.50000000000016, 53.90000000000006, 4.700000000000093, 192.79999999999995, 132.19999999999985, 134.29999999999959, 46.099999999999994, 182.8999999999999, 98.60000000000007, 193.7, 118.09999999999982, 144.19999999999976, 147.19999999999987, 134.29999999999978, 57.8000000000001, 131.5999999999999, 128.2999999999998, 124.3999999999996, 70.39999999999972, 145.99999999999991, 91.0999999999999, 153.19999999999976, 87.49999999999989, 65.60000000000007, 139.39999999999984, 127.09999999999998, 136.9999999999998, 140.59999999999994, 144.19999999999987, 166.6999999999998, 79.09999999999994, 70.39999999999992, 181.99999999999991, 101.89999999999998, 113.6, 75.79999999999987, 141.2, 130.09999999999997, 112.40000000000009, 161.89999999999998, 113.60000000000005, 36.20000000000008, 162.20000000000005, 127.09999999999998, 149.5999999999999, 185.59999999999997, 153.19999999999985, 111.79999999999998, 155.89999999999972, 171.2, 36.19999999999999, 142.3999999999998, 113.30000000000003, 120.79999999999995, 118.99999999999999, 91.9999999999997, 176.59999999999997, 185.29999999999995, 160.99999999999991, 94.69999999999989, 190.7, 30.80000000000019, 175.70000000000002, 173.89999999999995, 165.8, 152.89999999999992, 144.49999999999997, 182.00000000000003, 170.8999999999999, 184.7, 141.49999999999994, 111.80000000000001, 48.80000000000019, 160.4, 71.29999999999981, 101.59999999999994, 166.4, 35.900000000000055, 32.300000000000075, 67.69999999999982, 59.60000000000011, 92.9, 148.09999999999994, 100.99999999999972, 49.700000000000045, 125.2999999999999, 136.0999999999997, 71.6, 190.1, 96.49999999999963, 134.2999999999998, 125.29999999999987, 98.29999999999941, 110.8999999999999, 28.100000000000108, 144.19999999999996, 49.99999999999998, 117.19999999999995, -31.599999999999937, 174.79999999999995, 129.79999999999967, 74.90000000000002, 91.10000000000005, 136.0999999999998, 108.80000000000003, 100.09999999999968, 134.29999999999973, 91.69999999999987, 189.19999999999993, 57.8000000000001, 158.6, 190.99999999999994, 84.7999999999999, 56.90000000000001, 121.40000000000002, 157.69999999999985, 138.79999999999993, 128.9, 110.60000000000002, 151.99999999999983, 149.6, 145.1, 121.99999999999991, 127.39999999999978, 44.90000000000008, 80.29999999999997, 166.09999999999997, 70.99999999999999, 183.19999999999993, 163.9999999999999, 115.39999999999986, 113.6, 153.19999999999993, 79.69999999999989, 164.8999999999999, 86.60000000000004, 144.2000000000001, 137.8999999999998, 52.40000000000006, 167.59999999999994, 53.300000000000054, 95.59999999999997, 183.79999999999995, 57.49999999999999, 99.2, 175.4, 187.39999999999998, 73.39999999999992, 107.00000000000004, 77.60000000000008, 166.7, 102.79999999999987, 108.20000000000005, 141.49999999999963, 181.7, 99.8000000000001, 50.60000000000011, 154.1, 109.1, 190.99999999999994], "policy_predator_policy_reward": [1.0, 3.0, 8.0, 4.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 10.0, 12.0, 12.0, 0.0, 0.0, 6.0, 8.0, 5.0, 0.0, 0.0, 0.0, 13.0, 0.0, 0.0, 8.0, 6.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 4.0, 26.0, 27.0, 0.0, 4.0, 0.0, 6.0, 2.0, 0.0, 0.0, 0.0, 9.0, 5.0, 0.0, 9.0, 0.0, 8.0, 0.0, 0.0, 15.0, 0.0, 0.0, 10.0, 0.0, 1.0, 9.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 12.0, 4.0, 9.0, 3.0, 0.0, 2.0, 7.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 7.0, 0.0, 0.0, 7.0, 1.0, 15.0, 0.0, 0.0, 0.0, 1.0, 8.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 7.0, 8.0, 7.0, 0.0, 2.0, 9.0, 3.0, 6.0, 0.0, 0.0, 11.0, 26.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 12.0, 2.0, 0.0, 30.0, 30.0, 9.0, 0.0, 0.0, 0.0, 22.0, 7.0, 10.0, 6.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 10.0, 9.0, 9.0, 20.0, 23.0, 0.0, 0.0, 25.0, 0.0, 22.0, 9.0, 15.0, 0.0, 0.0, 2.0, 0.0, 6.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 14.0, 27.0, 0.0, 1.0, 0.0, 8.0, 6.0, 8.0, 1.0, 6.0, 13.0, 9.0, 0.0, 0.0, 0.0, 13.0, 1.0, 8.0, 9.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 12.393683368868373, "mean_inference_ms": 27.264288775289305, "mean_action_processing_ms": 6.187721910860883, "mean_env_wait_ms": 7.000012246877043, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.011720776557922363, "StateBufferConnector_ms": 0.06018352508544922, "ViewRequirementAgentConnector_ms": 0.3699226379394531}, "num_episodes": 23, "episode_return_max": 368.8999999999999, "episode_return_min": 91.39999999999952, "episode_return_mean": 253.14099999999976, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1600000, "num_agent_steps_trained": 1600000, "num_env_steps_sampled": 400000, "num_env_steps_trained": 400000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 121.18122006068054, "num_env_steps_trained_throughput_per_sec": 121.18122006068054, "timesteps_total": 400000, "num_env_steps_sampled_lifetime": 400000, "num_agent_steps_sampled_lifetime": 1600000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1600000, "timers": {"training_iteration_time_ms": 34058.726, "restore_workers_time_ms": 0.03, "training_step_time_ms": 34058.633, "sample_time_ms": 5692.684, "learn_time_ms": 28322.058, "learn_throughput": 141.233, "synch_weights_time_ms": 37.361}, "counters": {"num_env_steps_sampled": 400000, "num_env_steps_trained": 400000, "num_agent_steps_sampled": 1600000, "num_agent_steps_trained": 1600000}, "done": false, "training_iteration": 100, "trial_id": "75ec3_00000", "date": "2024-08-13_03-09-10", "timestamp": 1723532950, "time_this_iter_s": 33.10188102722168, "time_total_s": 6602.5451130867, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b221c940>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 6602.5451130867, "iterations_since_restore": 100, "perf": {"cpu_util_percent": 87.69782608695651, "ram_util_percent": 82.78260869565219}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 14.113266824982153, "cur_kl_coeff": 0.21648806836456067, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.7265754023557, "policy_loss": -0.010474761651715549, "vf_loss": 8.733093563463322, "vf_explained_var": 0.1823292530087567, "kl": 0.01827613742005122, "entropy": 0.9864952616590671, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 189945.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.3047621544992561, "cur_kl_coeff": 1.040834085586084e-18, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.3308271798586089, "policy_loss": 0.00010109069811367484, "vf_loss": 0.3307260904976083, "vf_explained_var": 0.02641582694003191, "kl": 0.0010649010646715334, "entropy": 0.2273074739824527, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 189945.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 404000, "num_env_steps_trained": 404000, "num_agent_steps_sampled": 1616000, "num_agent_steps_trained": 1616000}, "env_runners": {"episode_reward_max": 368.8999999999999, "episode_reward_min": 91.39999999999952, "episode_reward_mean": 239.85599999999968, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -31.599999999999937, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 193.7, "predator_policy": 30.0}, "policy_reward_mean": {"prey_policy": 115.32799999999992, "predator_policy": 4.6}, "custom_metrics": {}, "hist_stats": {"episode_reward": [190.2999999999996, 213.79999999999933, 91.39999999999952, 250.4999999999996, 270.5000000000004, 234.99999999999943, 294.29999999999967, 262.2999999999996, 295.4999999999998, 198.39999999999947, 260.6999999999994, 216.39999999999895, 259.2999999999996, 163.0999999999995, 267.4999999999998, 286.6, 310.9000000000001, 153.4999999999999, 283.8999999999997, 189.3999999999995, 295.3, 278.2999999999996, 149.7999999999996, 301.29999999999984, 348.19999999999993, 267.99999999999983, 336.10000000000014, 178.5999999999993, 244.1, 210.99999999999957, 368.8999999999999, 262.6999999999998, 237.49999999999966, 349.6, 319.7, 334.49999999999983, 359.6000000000002, 253.29999999999987, 209.1999999999993, 173.8999999999997, 217.29999999999964, 106.99999999999932, 163.49999999999997, 258.0999999999997, 174.9999999999994, 244.69999999999956, 286.60000000000025, 259.5999999999997, 209.19999999999928, 188.29999999999941, 169.1999999999998, 203.19999999999948, 213.69999999999916, 227.19999999999956, 237.89999999999966, 241.99999999999932, 246.9999999999994, 352.6, 141.69999999999982, 289.10000000000025, 285.7000000000003, 305.60000000000025, 294.69999999999993, 274.39999999999986, 156.2, 252.09999999999977, 349.2000000000004, 234.99999999999955, 252.8999999999995, 251.49999999999966, 282.09999999999934, 238.99999999999952, 175.8999999999997, 242.29999999999953, 288.5999999999999, 269.79999999999995, 203.59999999999934, 278.5, 249.69999999999945, 295.4999999999999, 221.69999999999956, 300.09999999999985, 229.19999999999956, 197.79999999999959, 286.60000000000014, 175.69999999999933, 172.49999999999974, 241.59999999999945, 212.79999999999944, 236.09999999999957, 222.4999999999997, 120.09999999999971, 199.19999999999968, 213.79999999999956, 191.3999999999993, 215.49999999999955, 111.99999999999915, 205.59999999999954, 237.9999999999994, 205.29999999999947], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [111.79999999999976, 78.50000000000004, 157.70000000000002, 52.10000000000016, 33.50000000000016, 53.90000000000006, 4.700000000000093, 192.79999999999995, 132.19999999999985, 134.29999999999959, 46.099999999999994, 182.8999999999999, 98.60000000000007, 193.7, 118.09999999999982, 144.19999999999976, 147.19999999999987, 134.29999999999978, 57.8000000000001, 131.5999999999999, 128.2999999999998, 124.3999999999996, 70.39999999999972, 145.99999999999991, 91.0999999999999, 153.19999999999976, 87.49999999999989, 65.60000000000007, 139.39999999999984, 127.09999999999998, 136.9999999999998, 140.59999999999994, 144.19999999999987, 166.6999999999998, 79.09999999999994, 70.39999999999992, 181.99999999999991, 101.89999999999998, 113.6, 75.79999999999987, 141.2, 130.09999999999997, 112.40000000000009, 161.89999999999998, 113.60000000000005, 36.20000000000008, 162.20000000000005, 127.09999999999998, 149.5999999999999, 185.59999999999997, 153.19999999999985, 111.79999999999998, 155.89999999999972, 171.2, 36.19999999999999, 142.3999999999998, 113.30000000000003, 120.79999999999995, 118.99999999999999, 91.9999999999997, 176.59999999999997, 185.29999999999995, 160.99999999999991, 94.69999999999989, 190.7, 30.80000000000019, 175.70000000000002, 173.89999999999995, 165.8, 152.89999999999992, 144.49999999999997, 182.00000000000003, 170.8999999999999, 184.7, 141.49999999999994, 111.80000000000001, 48.80000000000019, 160.4, 71.29999999999981, 101.59999999999994, 166.4, 35.900000000000055, 32.300000000000075, 67.69999999999982, 59.60000000000011, 92.9, 148.09999999999994, 100.99999999999972, 49.700000000000045, 125.2999999999999, 136.0999999999997, 71.6, 190.1, 96.49999999999963, 134.2999999999998, 125.29999999999987, 98.29999999999941, 110.8999999999999, 28.100000000000108, 144.19999999999996, 49.99999999999998, 117.19999999999995, -31.599999999999937, 174.79999999999995, 129.79999999999967, 74.90000000000002, 91.10000000000005, 136.0999999999998, 108.80000000000003, 100.09999999999968, 134.29999999999973, 91.69999999999987, 189.19999999999993, 57.8000000000001, 158.6, 190.99999999999994, 84.7999999999999, 56.90000000000001, 121.40000000000002, 157.69999999999985, 138.79999999999993, 128.9, 110.60000000000002, 151.99999999999983, 149.6, 145.1, 121.99999999999991, 127.39999999999978, 44.90000000000008, 80.29999999999997, 166.09999999999997, 70.99999999999999, 183.19999999999993, 163.9999999999999, 115.39999999999986, 113.6, 153.19999999999993, 79.69999999999989, 164.8999999999999, 86.60000000000004, 144.2000000000001, 137.8999999999998, 52.40000000000006, 167.59999999999994, 53.300000000000054, 95.59999999999997, 183.79999999999995, 57.49999999999999, 99.2, 175.4, 187.39999999999998, 73.39999999999992, 107.00000000000004, 77.60000000000008, 166.7, 102.79999999999987, 108.20000000000005, 141.49999999999963, 181.7, 99.8000000000001, 50.60000000000011, 154.1, 109.1, 190.99999999999994, 45.80000000000004, 157.39999999999992, 47.00000000000005, 129.8000000000001, 187.39999999999992, 99.1999999999999, 37.09999999999997, 119.59999999999968, 147.79999999999998, 7.700000000000099, 161.2999999999998, 80.30000000000001, 134.2999999999999, 78.4999999999996, 106.69999999999985, 118.39999999999992, 139.39999999999992, 73.10000000000002, 60.499999999999986, 59.600000000000065, 126.1999999999999, 68.00000000000003, 91.40000000000009, 109.39999999999965, 94.09999999999977, 89.29999999999974, 82.99999999999977, 132.49999999999986, 37.999999999999986, 73.99999999999956, 104.59999999999991, 100.99999999999963, 67.70000000000007, 161.29999999999984, 102.79999999999995, 96.4999999999998], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 4.0, 0.0, 4.0, 26.0, 27.0, 0.0, 4.0, 0.0, 6.0, 2.0, 0.0, 0.0, 0.0, 9.0, 5.0, 0.0, 9.0, 0.0, 8.0, 0.0, 0.0, 15.0, 0.0, 0.0, 10.0, 0.0, 1.0, 9.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 12.0, 4.0, 9.0, 3.0, 0.0, 2.0, 7.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 7.0, 0.0, 0.0, 7.0, 1.0, 15.0, 0.0, 0.0, 0.0, 1.0, 8.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 7.0, 8.0, 7.0, 0.0, 2.0, 9.0, 3.0, 6.0, 0.0, 0.0, 11.0, 26.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 12.0, 2.0, 0.0, 30.0, 30.0, 9.0, 0.0, 0.0, 0.0, 22.0, 7.0, 10.0, 6.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 10.0, 9.0, 9.0, 20.0, 23.0, 0.0, 0.0, 25.0, 0.0, 22.0, 9.0, 15.0, 0.0, 0.0, 2.0, 0.0, 6.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 14.0, 27.0, 0.0, 1.0, 0.0, 8.0, 6.0, 8.0, 1.0, 6.0, 13.0, 9.0, 0.0, 0.0, 0.0, 13.0, 1.0, 8.0, 9.0, 0.0, 0.0, 16.0, 10.0, 11.0, 10.0, 0.0, 0.0, 9.0, 10.0, 0.0, 17.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 1.0, 9.0, 0.0, 0.0, 0.0, 5.0, 2.0, 11.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 3.0, 0.0, 6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 12.08316428792295, "mean_inference_ms": 26.6124678672979, "mean_action_processing_ms": 5.901688952791215, "mean_env_wait_ms": 7.849298731052361, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0117950439453125, "StateBufferConnector_ms": 0.03664374351501465, "ViewRequirementAgentConnector_ms": 0.38676881790161133}, "num_episodes": 18, "episode_return_max": 368.8999999999999, "episode_return_min": 91.39999999999952, "episode_return_mean": 239.85599999999968, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1616000, "num_agent_steps_trained": 1616000, "num_env_steps_sampled": 404000, "num_env_steps_trained": 404000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 116.8161788206312, "num_env_steps_trained_throughput_per_sec": 116.8161788206312, "timesteps_total": 404000, "num_env_steps_sampled_lifetime": 404000, "num_agent_steps_sampled_lifetime": 1616000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1616000, "timers": {"training_iteration_time_ms": 34243.178, "restore_workers_time_ms": 0.039, "training_step_time_ms": 34243.066, "sample_time_ms": 5563.926, "learn_time_ms": 28639.094, "learn_throughput": 139.669, "synch_weights_time_ms": 35.64}, "counters": {"num_env_steps_sampled": 404000, "num_env_steps_trained": 404000, "num_agent_steps_sampled": 1616000, "num_agent_steps_trained": 1616000}, "done": false, "training_iteration": 101, "trial_id": "75ec3_00000", "date": "2024-08-13_03-09-45", "timestamp": 1723532985, "time_this_iter_s": 34.29895496368408, "time_total_s": 6636.8440680503845, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b226f670>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 6636.8440680503845, "iterations_since_restore": 101, "perf": {"cpu_util_percent": 88.45102040816326, "ram_util_percent": 83.2265306122449}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 8.528960910360649, "cur_kl_coeff": 0.21648806836456067, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.296088085225019, "policy_loss": -0.003148991099888922, "vf_loss": 7.298332331420252, "vf_explained_var": 0.3496581127719274, "kl": 0.0041792234348398665, "entropy": 0.9911045573691212, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 191835.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4950258347585245, "cur_kl_coeff": 5.20417042793042e-19, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.7853153594271847, "policy_loss": 8.757817608220552e-05, "vf_loss": 0.7852277809823001, "vf_explained_var": 0.05340651888695974, "kl": 0.0007059114917267577, "entropy": 0.2514849895759234, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 191835.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 408000, "num_env_steps_trained": 408000, "num_agent_steps_sampled": 1632000, "num_agent_steps_trained": 1632000}, "env_runners": {"episode_reward_max": 377.5000000000001, "episode_reward_min": 106.99999999999932, "episode_reward_mean": 244.17999999999975, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -40.899999999999764, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 192.79999999999995, "predator_policy": 30.0}, "policy_reward_mean": {"prey_policy": 117.28999999999992, "predator_policy": 4.8}, "custom_metrics": {}, "hist_stats": {"episode_reward": [283.8999999999997, 189.3999999999995, 295.3, 278.2999999999996, 149.7999999999996, 301.29999999999984, 348.19999999999993, 267.99999999999983, 336.10000000000014, 178.5999999999993, 244.1, 210.99999999999957, 368.8999999999999, 262.6999999999998, 237.49999999999966, 349.6, 319.7, 334.49999999999983, 359.6000000000002, 253.29999999999987, 209.1999999999993, 173.8999999999997, 217.29999999999964, 106.99999999999932, 163.49999999999997, 258.0999999999997, 174.9999999999994, 244.69999999999956, 286.60000000000025, 259.5999999999997, 209.19999999999928, 188.29999999999941, 169.1999999999998, 203.19999999999948, 213.69999999999916, 227.19999999999956, 237.89999999999966, 241.99999999999932, 246.9999999999994, 352.6, 141.69999999999982, 289.10000000000025, 285.7000000000003, 305.60000000000025, 294.69999999999993, 274.39999999999986, 156.2, 252.09999999999977, 349.2000000000004, 234.99999999999955, 252.8999999999995, 251.49999999999966, 282.09999999999934, 238.99999999999952, 175.8999999999997, 242.29999999999953, 288.5999999999999, 269.79999999999995, 203.59999999999934, 278.5, 249.69999999999945, 295.4999999999999, 221.69999999999956, 300.09999999999985, 229.19999999999956, 197.79999999999959, 286.60000000000014, 175.69999999999933, 172.49999999999974, 241.59999999999945, 212.79999999999944, 236.09999999999957, 222.4999999999997, 120.09999999999971, 199.19999999999968, 213.79999999999956, 191.3999999999993, 215.49999999999955, 111.99999999999915, 205.59999999999954, 237.9999999999994, 205.29999999999947, 190.99999999999963, 200.2999999999997, 126.8999999999997, 317.5999999999998, 214.5999999999996, 341.9, 237.09999999999985, 281.1999999999998, 246.99999999999983, 317.7999999999997, 377.5000000000001, 282.9999999999999, 327.1, 308.20000000000016, 213.69999999999956, 166.49999999999903, 242.5, 258.4999999999997], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [181.99999999999991, 101.89999999999998, 113.6, 75.79999999999987, 141.2, 130.09999999999997, 112.40000000000009, 161.89999999999998, 113.60000000000005, 36.20000000000008, 162.20000000000005, 127.09999999999998, 149.5999999999999, 185.59999999999997, 153.19999999999985, 111.79999999999998, 155.89999999999972, 171.2, 36.19999999999999, 142.3999999999998, 113.30000000000003, 120.79999999999995, 118.99999999999999, 91.9999999999997, 176.59999999999997, 185.29999999999995, 160.99999999999991, 94.69999999999989, 190.7, 30.80000000000019, 175.70000000000002, 173.89999999999995, 165.8, 152.89999999999992, 144.49999999999997, 182.00000000000003, 170.8999999999999, 184.7, 141.49999999999994, 111.80000000000001, 48.80000000000019, 160.4, 71.29999999999981, 101.59999999999994, 166.4, 35.900000000000055, 32.300000000000075, 67.69999999999982, 59.60000000000011, 92.9, 148.09999999999994, 100.99999999999972, 49.700000000000045, 125.2999999999999, 136.0999999999997, 71.6, 190.1, 96.49999999999963, 134.2999999999998, 125.29999999999987, 98.29999999999941, 110.8999999999999, 28.100000000000108, 144.19999999999996, 49.99999999999998, 117.19999999999995, -31.599999999999937, 174.79999999999995, 129.79999999999967, 74.90000000000002, 91.10000000000005, 136.0999999999998, 108.80000000000003, 100.09999999999968, 134.29999999999973, 91.69999999999987, 189.19999999999993, 57.8000000000001, 158.6, 190.99999999999994, 84.7999999999999, 56.90000000000001, 121.40000000000002, 157.69999999999985, 138.79999999999993, 128.9, 110.60000000000002, 151.99999999999983, 149.6, 145.1, 121.99999999999991, 127.39999999999978, 44.90000000000008, 80.29999999999997, 166.09999999999997, 70.99999999999999, 183.19999999999993, 163.9999999999999, 115.39999999999986, 113.6, 153.19999999999993, 79.69999999999989, 164.8999999999999, 86.60000000000004, 144.2000000000001, 137.8999999999998, 52.40000000000006, 167.59999999999994, 53.300000000000054, 95.59999999999997, 183.79999999999995, 57.49999999999999, 99.2, 175.4, 187.39999999999998, 73.39999999999992, 107.00000000000004, 77.60000000000008, 166.7, 102.79999999999987, 108.20000000000005, 141.49999999999963, 181.7, 99.8000000000001, 50.60000000000011, 154.1, 109.1, 190.99999999999994, 45.80000000000004, 157.39999999999992, 47.00000000000005, 129.8000000000001, 187.39999999999992, 99.1999999999999, 37.09999999999997, 119.59999999999968, 147.79999999999998, 7.700000000000099, 161.2999999999998, 80.30000000000001, 134.2999999999999, 78.4999999999996, 106.69999999999985, 118.39999999999992, 139.39999999999992, 73.10000000000002, 60.499999999999986, 59.600000000000065, 126.1999999999999, 68.00000000000003, 91.40000000000009, 109.39999999999965, 94.09999999999977, 89.29999999999974, 82.99999999999977, 132.49999999999986, 37.999999999999986, 73.99999999999956, 104.59999999999991, 100.99999999999963, 67.70000000000007, 161.29999999999984, 102.79999999999995, 96.4999999999998, 82.70000000000007, 98.29999999999994, 100.99999999999977, 95.29999999999994, 138.79999999999998, -40.899999999999764, 157.9999999999999, 143.59999999999994, 101.90000000000005, 112.69999999999993, 175.69999999999996, 159.2, 129.8, 98.30000000000004, 127.09999999999991, 127.1, 95.89999999999993, 142.09999999999994, 121.6999999999999, 181.10000000000002, 184.7, 192.79999999999995, 134.29999999999993, 139.69999999999993, 148.7, 178.39999999999998, 147.79999999999998, 160.39999999999992, 112.69999999999993, 91.99999999999973, 5.000000000000075, 141.49999999999963, 133.4, 109.09999999999998, 88.39999999999984, 151.09999999999985], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 0.0, 24.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 12.0, 4.0, 9.0, 3.0, 0.0, 2.0, 7.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 7.0, 0.0, 0.0, 7.0, 1.0, 15.0, 0.0, 0.0, 0.0, 1.0, 8.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 7.0, 8.0, 7.0, 0.0, 2.0, 9.0, 3.0, 6.0, 0.0, 0.0, 11.0, 26.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 12.0, 2.0, 0.0, 30.0, 30.0, 9.0, 0.0, 0.0, 0.0, 22.0, 7.0, 10.0, 6.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 10.0, 9.0, 9.0, 20.0, 23.0, 0.0, 0.0, 25.0, 0.0, 22.0, 9.0, 15.0, 0.0, 0.0, 2.0, 0.0, 6.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 14.0, 27.0, 0.0, 1.0, 0.0, 8.0, 6.0, 8.0, 1.0, 6.0, 13.0, 9.0, 0.0, 0.0, 0.0, 13.0, 1.0, 8.0, 9.0, 0.0, 0.0, 16.0, 10.0, 11.0, 10.0, 0.0, 0.0, 9.0, 10.0, 0.0, 17.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 1.0, 9.0, 0.0, 0.0, 0.0, 5.0, 2.0, 11.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 3.0, 0.0, 6.0, 10.0, 0.0, 4.0, 0.0, 29.0, 0.0, 5.0, 11.0, 0.0, 0.0, 7.0, 0.0, 9.0, 0.0, 19.0, 8.0, 2.0, 7.0, 6.0, 9.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 13.0, 7.0, 0.0, 0.0, 0.0, 19.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 11.99253126252247, "mean_inference_ms": 26.425342059653584, "mean_action_processing_ms": 5.855448483660379, "mean_env_wait_ms": 7.784818569018378, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.011893630027770996, "StateBufferConnector_ms": 0.043332815170288086, "ViewRequirementAgentConnector_ms": 0.4186108112335205}, "num_episodes": 18, "episode_return_max": 377.5000000000001, "episode_return_min": 106.99999999999932, "episode_return_mean": 244.17999999999975, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1632000, "num_agent_steps_trained": 1632000, "num_env_steps_sampled": 408000, "num_env_steps_trained": 408000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 6.548865262508624, "num_env_steps_trained_throughput_per_sec": 6.548865262508624, "timesteps_total": 408000, "num_env_steps_sampled_lifetime": 408000, "num_agent_steps_sampled_lifetime": 1632000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1632000, "timers": {"training_iteration_time_ms": 90407.879, "restore_workers_time_ms": 0.039, "training_step_time_ms": 90407.77, "sample_time_ms": 4492.43, "learn_time_ms": 85880.736, "learn_throughput": 46.576, "synch_weights_time_ms": 30.706}, "counters": {"num_env_steps_sampled": 408000, "num_env_steps_trained": 408000, "num_agent_steps_sampled": 1632000, "num_agent_steps_trained": 1632000}, "done": false, "training_iteration": 102, "trial_id": "75ec3_00000", "date": "2024-08-13_03-19-56", "timestamp": 1723533596, "time_this_iter_s": 610.9256579875946, "time_total_s": 7247.769726037979, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b23df9d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 7247.769726037979, "iterations_since_restore": 102, "perf": {"cpu_util_percent": 91.89636363636365, "ram_util_percent": 83.16545454545455}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 13.668028518888686, "cur_kl_coeff": 0.10824403418228033, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.7939415374130165, "policy_loss": -0.010985899499553458, "vf_loss": 7.802444538742146, "vf_explained_var": 0.5028758569684609, "kl": 0.022938053072193147, "entropy": 0.9713066387744177, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 193725.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.2571950953227108, "cur_kl_coeff": 2.60208521396521e-19, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.19524849729474497, "policy_loss": -0.0006784788863831964, "vf_loss": 0.1959269759804503, "vf_explained_var": 0.024709869661028422, "kl": 0.002981232003962032, "entropy": 0.21667972436499974, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 193725.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 412000, "num_env_steps_trained": 412000, "num_agent_steps_sampled": 1648000, "num_agent_steps_trained": 1648000}, "env_runners": {"episode_reward_max": 377.5000000000001, "episode_reward_min": 94.99999999999932, "episode_reward_mean": 236.91599999999974, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -40.899999999999764, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 199.1, "predator_policy": 30.0}, "policy_reward_mean": {"prey_policy": 113.30299999999993, "predator_policy": 5.155}, "custom_metrics": {}, "hist_stats": {"episode_reward": [217.29999999999964, 106.99999999999932, 163.49999999999997, 258.0999999999997, 174.9999999999994, 244.69999999999956, 286.60000000000025, 259.5999999999997, 209.19999999999928, 188.29999999999941, 169.1999999999998, 203.19999999999948, 213.69999999999916, 227.19999999999956, 237.89999999999966, 241.99999999999932, 246.9999999999994, 352.6, 141.69999999999982, 289.10000000000025, 285.7000000000003, 305.60000000000025, 294.69999999999993, 274.39999999999986, 156.2, 252.09999999999977, 349.2000000000004, 234.99999999999955, 252.8999999999995, 251.49999999999966, 282.09999999999934, 238.99999999999952, 175.8999999999997, 242.29999999999953, 288.5999999999999, 269.79999999999995, 203.59999999999934, 278.5, 249.69999999999945, 295.4999999999999, 221.69999999999956, 300.09999999999985, 229.19999999999956, 197.79999999999959, 286.60000000000014, 175.69999999999933, 172.49999999999974, 241.59999999999945, 212.79999999999944, 236.09999999999957, 222.4999999999997, 120.09999999999971, 199.19999999999968, 213.79999999999956, 191.3999999999993, 215.49999999999955, 111.99999999999915, 205.59999999999954, 237.9999999999994, 205.29999999999947, 190.99999999999963, 200.2999999999997, 126.8999999999997, 317.5999999999998, 214.5999999999996, 341.9, 237.09999999999985, 281.1999999999998, 246.99999999999983, 317.7999999999997, 377.5000000000001, 282.9999999999999, 327.1, 308.20000000000016, 213.69999999999956, 166.49999999999903, 242.5, 258.4999999999997, 265.09999999999957, 124.39999999999995, 223.79999999999933, 213.69999999999965, 326.2000000000003, 294.8000000000002, 94.99999999999932, 298.79999999999995, 334.29999999999984, 345.8999999999998, 98.49999999999997, 196.99999999999932, 296.6, 330.6999999999997, 215.69999999999965, 195.6999999999994, 275.7999999999997, 144.4999999999988, 353.2000000000005, 248.5999999999998, 145.4999999999999, 202.6999999999995], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [166.4, 35.900000000000055, 32.300000000000075, 67.69999999999982, 59.60000000000011, 92.9, 148.09999999999994, 100.99999999999972, 49.700000000000045, 125.2999999999999, 136.0999999999997, 71.6, 190.1, 96.49999999999963, 134.2999999999998, 125.29999999999987, 98.29999999999941, 110.8999999999999, 28.100000000000108, 144.19999999999996, 49.99999999999998, 117.19999999999995, -31.599999999999937, 174.79999999999995, 129.79999999999967, 74.90000000000002, 91.10000000000005, 136.0999999999998, 108.80000000000003, 100.09999999999968, 134.29999999999973, 91.69999999999987, 189.19999999999993, 57.8000000000001, 158.6, 190.99999999999994, 84.7999999999999, 56.90000000000001, 121.40000000000002, 157.69999999999985, 138.79999999999993, 128.9, 110.60000000000002, 151.99999999999983, 149.6, 145.1, 121.99999999999991, 127.39999999999978, 44.90000000000008, 80.29999999999997, 166.09999999999997, 70.99999999999999, 183.19999999999993, 163.9999999999999, 115.39999999999986, 113.6, 153.19999999999993, 79.69999999999989, 164.8999999999999, 86.60000000000004, 144.2000000000001, 137.8999999999998, 52.40000000000006, 167.59999999999994, 53.300000000000054, 95.59999999999997, 183.79999999999995, 57.49999999999999, 99.2, 175.4, 187.39999999999998, 73.39999999999992, 107.00000000000004, 77.60000000000008, 166.7, 102.79999999999987, 108.20000000000005, 141.49999999999963, 181.7, 99.8000000000001, 50.60000000000011, 154.1, 109.1, 190.99999999999994, 45.80000000000004, 157.39999999999992, 47.00000000000005, 129.8000000000001, 187.39999999999992, 99.1999999999999, 37.09999999999997, 119.59999999999968, 147.79999999999998, 7.700000000000099, 161.2999999999998, 80.30000000000001, 134.2999999999999, 78.4999999999996, 106.69999999999985, 118.39999999999992, 139.39999999999992, 73.10000000000002, 60.499999999999986, 59.600000000000065, 126.1999999999999, 68.00000000000003, 91.40000000000009, 109.39999999999965, 94.09999999999977, 89.29999999999974, 82.99999999999977, 132.49999999999986, 37.999999999999986, 73.99999999999956, 104.59999999999991, 100.99999999999963, 67.70000000000007, 161.29999999999984, 102.79999999999995, 96.4999999999998, 82.70000000000007, 98.29999999999994, 100.99999999999977, 95.29999999999994, 138.79999999999998, -40.899999999999764, 157.9999999999999, 143.59999999999994, 101.90000000000005, 112.69999999999993, 175.69999999999996, 159.2, 129.8, 98.30000000000004, 127.09999999999991, 127.1, 95.89999999999993, 142.09999999999994, 121.6999999999999, 181.10000000000002, 184.7, 192.79999999999995, 134.29999999999993, 139.69999999999993, 148.7, 178.39999999999998, 147.79999999999998, 160.39999999999992, 112.69999999999993, 91.99999999999973, 5.000000000000075, 141.49999999999963, 133.4, 109.09999999999998, 88.39999999999984, 151.09999999999985, 124.99999999999983, 127.09999999999974, 29.899999999999984, 84.49999999999997, 49.100000000000115, 166.69999999999987, 144.19999999999993, 69.49999999999997, 182.8999999999999, 143.29999999999998, 159.4999999999998, 131.29999999999995, 1.0999999999999723, 80.89999999999966, 111.19999999999999, 176.59999999999994, 199.1, 135.1999999999999, 172.69999999999985, 168.19999999999987, 78.49999999999997, 20.000000000000014, 115.39999999999978, 56.600000000000165, 133.9999999999999, 149.60000000000002, 158.59999999999985, 172.10000000000002, 64.40000000000003, 143.2999999999998, 47.90000000000021, 147.8, 132.49999999999966, 143.29999999999995, 40.40000000000018, 91.09999999999943, 180.19999999999993, 172.99999999999983, 104.90000000000006, 121.69999999999989, 15.500000000000155, 95.00000000000009, 47.000000000000114, 145.7], "policy_predator_policy_reward": [7.0, 8.0, 7.0, 0.0, 2.0, 9.0, 3.0, 6.0, 0.0, 0.0, 11.0, 26.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 12.0, 2.0, 0.0, 30.0, 30.0, 9.0, 0.0, 0.0, 0.0, 22.0, 7.0, 10.0, 6.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 10.0, 9.0, 9.0, 20.0, 23.0, 0.0, 0.0, 25.0, 0.0, 22.0, 9.0, 15.0, 0.0, 0.0, 2.0, 0.0, 6.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 14.0, 27.0, 0.0, 1.0, 0.0, 8.0, 6.0, 8.0, 1.0, 6.0, 13.0, 9.0, 0.0, 0.0, 0.0, 13.0, 1.0, 8.0, 9.0, 0.0, 0.0, 16.0, 10.0, 11.0, 10.0, 0.0, 0.0, 9.0, 10.0, 0.0, 17.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 1.0, 9.0, 0.0, 0.0, 0.0, 5.0, 2.0, 11.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 3.0, 0.0, 6.0, 10.0, 0.0, 4.0, 0.0, 29.0, 0.0, 5.0, 11.0, 0.0, 0.0, 7.0, 0.0, 9.0, 0.0, 19.0, 8.0, 2.0, 7.0, 6.0, 9.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 13.0, 7.0, 0.0, 0.0, 0.0, 19.0, 3.0, 10.0, 0.0, 10.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 13.0, 0.0, 11.0, 0.0, 0.0, 0.0, 4.0, 1.0, 0.0, 0.0, 5.0, 20.0, 13.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 0.0, 22.0, 17.0, 18.0, 10.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 11.882058135363504, "mean_inference_ms": 26.214676330301618, "mean_action_processing_ms": 5.810582248557306, "mean_env_wait_ms": 7.690144393018709, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.009008646011352539, "StateBufferConnector_ms": 0.04289042949676514, "ViewRequirementAgentConnector_ms": 0.38058364391326904}, "num_episodes": 22, "episode_return_max": 377.5000000000001, "episode_return_min": 94.99999999999932, "episode_return_mean": 236.91599999999974, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1648000, "num_agent_steps_trained": 1648000, "num_env_steps_sampled": 412000, "num_env_steps_trained": 412000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 202.99729628796328, "num_env_steps_trained_throughput_per_sec": 202.99729628796328, "timesteps_total": 412000, "num_env_steps_sampled_lifetime": 412000, "num_agent_steps_sampled_lifetime": 1648000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1648000, "timers": {"training_iteration_time_ms": 88947.664, "restore_workers_time_ms": 0.031, "training_step_time_ms": 88947.575, "sample_time_ms": 4485.817, "learn_time_ms": 84432.031, "learn_throughput": 47.375, "synch_weights_time_ms": 25.741}, "counters": {"num_env_steps_sampled": 412000, "num_env_steps_trained": 412000, "num_agent_steps_sampled": 1648000, "num_agent_steps_trained": 1648000}, "done": false, "training_iteration": 103, "trial_id": "75ec3_00000", "date": "2024-08-13_03-20-16", "timestamp": 1723533616, "time_this_iter_s": 19.762871980667114, "time_total_s": 7267.532598018646, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b23f01f0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 7267.532598018646, "iterations_since_restore": 103, "perf": {"cpu_util_percent": 89.49285714285715, "ram_util_percent": 83.64285714285714}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 9.823663330425031, "cur_kl_coeff": 0.16236605127342046, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.38861143626864, "policy_loss": -0.01793556822397347, "vf_loss": 7.401588363748379, "vf_explained_var": 0.17370744719707146, "kl": 0.030539892870841533, "entropy": 1.003610319466818, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 195615.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5069242648139753, "cur_kl_coeff": 1.301042606982605e-19, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.249418059984843, "policy_loss": -0.000755586274702437, "vf_loss": 1.2501736420487601, "vf_explained_var": 0.006211104594841205, "kl": 0.001751874730965112, "entropy": 0.19210821157567715, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 195615.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 416000, "num_env_steps_trained": 416000, "num_agent_steps_sampled": 1664000, "num_agent_steps_trained": 1664000}, "env_runners": {"episode_reward_max": 377.5000000000001, "episode_reward_min": 94.99999999999932, "episode_reward_mean": 241.77899999999968, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -40.899999999999764, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 199.1, "predator_policy": 46.0}, "policy_reward_mean": {"prey_policy": 115.79449999999996, "predator_policy": 5.095}, "custom_metrics": {}, "hist_stats": {"episode_reward": [141.69999999999982, 289.10000000000025, 285.7000000000003, 305.60000000000025, 294.69999999999993, 274.39999999999986, 156.2, 252.09999999999977, 349.2000000000004, 234.99999999999955, 252.8999999999995, 251.49999999999966, 282.09999999999934, 238.99999999999952, 175.8999999999997, 242.29999999999953, 288.5999999999999, 269.79999999999995, 203.59999999999934, 278.5, 249.69999999999945, 295.4999999999999, 221.69999999999956, 300.09999999999985, 229.19999999999956, 197.79999999999959, 286.60000000000014, 175.69999999999933, 172.49999999999974, 241.59999999999945, 212.79999999999944, 236.09999999999957, 222.4999999999997, 120.09999999999971, 199.19999999999968, 213.79999999999956, 191.3999999999993, 215.49999999999955, 111.99999999999915, 205.59999999999954, 237.9999999999994, 205.29999999999947, 190.99999999999963, 200.2999999999997, 126.8999999999997, 317.5999999999998, 214.5999999999996, 341.9, 237.09999999999985, 281.1999999999998, 246.99999999999983, 317.7999999999997, 377.5000000000001, 282.9999999999999, 327.1, 308.20000000000016, 213.69999999999956, 166.49999999999903, 242.5, 258.4999999999997, 265.09999999999957, 124.39999999999995, 223.79999999999933, 213.69999999999965, 326.2000000000003, 294.8000000000002, 94.99999999999932, 298.79999999999995, 334.29999999999984, 345.8999999999998, 98.49999999999997, 196.99999999999932, 296.6, 330.6999999999997, 215.69999999999965, 195.6999999999994, 275.7999999999997, 144.4999999999988, 353.2000000000005, 248.5999999999998, 145.4999999999999, 202.6999999999995, 249.69999999999942, 223.09999999999957, 158.59999999999954, 254.39999999999972, 215.79999999999953, 288.2999999999997, 294.1, 148.79999999999944, 352.29999999999995, 167.79999999999964, 204.69999999999948, 277.19999999999993, 299.2000000000005, 288.9999999999999, 257.99999999999955, 327.10000000000014, 195.9999999999992, 284.29999999999995], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [84.7999999999999, 56.90000000000001, 121.40000000000002, 157.69999999999985, 138.79999999999993, 128.9, 110.60000000000002, 151.99999999999983, 149.6, 145.1, 121.99999999999991, 127.39999999999978, 44.90000000000008, 80.29999999999997, 166.09999999999997, 70.99999999999999, 183.19999999999993, 163.9999999999999, 115.39999999999986, 113.6, 153.19999999999993, 79.69999999999989, 164.8999999999999, 86.60000000000004, 144.2000000000001, 137.8999999999998, 52.40000000000006, 167.59999999999994, 53.300000000000054, 95.59999999999997, 183.79999999999995, 57.49999999999999, 99.2, 175.4, 187.39999999999998, 73.39999999999992, 107.00000000000004, 77.60000000000008, 166.7, 102.79999999999987, 108.20000000000005, 141.49999999999963, 181.7, 99.8000000000001, 50.60000000000011, 154.1, 109.1, 190.99999999999994, 45.80000000000004, 157.39999999999992, 47.00000000000005, 129.8000000000001, 187.39999999999992, 99.1999999999999, 37.09999999999997, 119.59999999999968, 147.79999999999998, 7.700000000000099, 161.2999999999998, 80.30000000000001, 134.2999999999999, 78.4999999999996, 106.69999999999985, 118.39999999999992, 139.39999999999992, 73.10000000000002, 60.499999999999986, 59.600000000000065, 126.1999999999999, 68.00000000000003, 91.40000000000009, 109.39999999999965, 94.09999999999977, 89.29999999999974, 82.99999999999977, 132.49999999999986, 37.999999999999986, 73.99999999999956, 104.59999999999991, 100.99999999999963, 67.70000000000007, 161.29999999999984, 102.79999999999995, 96.4999999999998, 82.70000000000007, 98.29999999999994, 100.99999999999977, 95.29999999999994, 138.79999999999998, -40.899999999999764, 157.9999999999999, 143.59999999999994, 101.90000000000005, 112.69999999999993, 175.69999999999996, 159.2, 129.8, 98.30000000000004, 127.09999999999991, 127.1, 95.89999999999993, 142.09999999999994, 121.6999999999999, 181.10000000000002, 184.7, 192.79999999999995, 134.29999999999993, 139.69999999999993, 148.7, 178.39999999999998, 147.79999999999998, 160.39999999999992, 112.69999999999993, 91.99999999999973, 5.000000000000075, 141.49999999999963, 133.4, 109.09999999999998, 88.39999999999984, 151.09999999999985, 124.99999999999983, 127.09999999999974, 29.899999999999984, 84.49999999999997, 49.100000000000115, 166.69999999999987, 144.19999999999993, 69.49999999999997, 182.8999999999999, 143.29999999999998, 159.4999999999998, 131.29999999999995, 1.0999999999999723, 80.89999999999966, 111.19999999999999, 176.59999999999994, 199.1, 135.1999999999999, 172.69999999999985, 168.19999999999987, 78.49999999999997, 20.000000000000014, 115.39999999999978, 56.600000000000165, 133.9999999999999, 149.60000000000002, 158.59999999999985, 172.10000000000002, 64.40000000000003, 143.2999999999998, 47.90000000000021, 147.8, 132.49999999999966, 143.29999999999995, 40.40000000000018, 91.09999999999943, 180.19999999999993, 172.99999999999983, 104.90000000000006, 121.69999999999989, 15.500000000000155, 95.00000000000009, 47.000000000000114, 145.7, 90.19999999999985, 159.49999999999983, 115.99999999999991, 82.10000000000008, 143.8999999999998, -40.300000000000026, 120.19999999999999, 126.19999999999976, 142.39999999999986, 70.40000000000006, 152.29999999999998, 130.99999999999977, 126.79999999999986, 146.29999999999995, 66.79999999999986, 59.00000000000008, 168.49999999999991, 183.79999999999993, 73.40000000000009, 76.40000000000003, 154.0999999999999, 50.599999999999966, 135.5, 130.7, 163.09999999999982, 136.09999999999994, 144.19999999999987, 138.79999999999995, 175.69999999999996, 74.3000000000001, 147.79999999999995, 179.2999999999999, 20.000000000000014, 172.99999999999991, 188.29999999999998, 80.00000000000003], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 10.0, 9.0, 9.0, 20.0, 23.0, 0.0, 0.0, 25.0, 0.0, 22.0, 9.0, 15.0, 0.0, 0.0, 2.0, 0.0, 6.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 14.0, 27.0, 0.0, 1.0, 0.0, 8.0, 6.0, 8.0, 1.0, 6.0, 13.0, 9.0, 0.0, 0.0, 0.0, 13.0, 1.0, 8.0, 9.0, 0.0, 0.0, 16.0, 10.0, 11.0, 10.0, 0.0, 0.0, 9.0, 10.0, 0.0, 17.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 1.0, 9.0, 0.0, 0.0, 0.0, 5.0, 2.0, 11.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 3.0, 0.0, 6.0, 10.0, 0.0, 4.0, 0.0, 29.0, 0.0, 5.0, 11.0, 0.0, 0.0, 7.0, 0.0, 9.0, 0.0, 19.0, 8.0, 2.0, 7.0, 6.0, 9.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 13.0, 7.0, 0.0, 0.0, 0.0, 19.0, 3.0, 10.0, 0.0, 10.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 13.0, 0.0, 11.0, 0.0, 0.0, 0.0, 4.0, 1.0, 0.0, 0.0, 5.0, 20.0, 13.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 0.0, 22.0, 17.0, 18.0, 10.0, 0.0, 0.0, 0.0, 0.0, 25.0, 46.0, 9.0, 8.0, 0.0, 3.0, 0.0, 5.0, 0.0, 0.0, 21.0, 0.0, 23.0, 0.0, 0.0, 18.0, 0.0, 0.0, 0.0, 8.0, 3.0, 0.0, 0.0, 6.0, 0.0, 0.0, 8.0, 0.0, 0.0, 3.0, 0.0, 13.0, 3.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 11.792880870660492, "mean_inference_ms": 26.029882404459272, "mean_action_processing_ms": 5.765508149285084, "mean_env_wait_ms": 7.627686979991835, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006984353065490723, "StateBufferConnector_ms": 0.040274858474731445, "ViewRequirementAgentConnector_ms": 0.32334184646606445}, "num_episodes": 18, "episode_return_max": 377.5000000000001, "episode_return_min": 94.99999999999932, "episode_return_mean": 241.77899999999968, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1664000, "num_agent_steps_trained": 1664000, "num_env_steps_sampled": 416000, "num_env_steps_trained": 416000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 4.08964437613137, "num_env_steps_trained_throughput_per_sec": 4.08964437613137, "timesteps_total": 416000, "num_env_steps_sampled_lifetime": 416000, "num_agent_steps_sampled_lifetime": 1664000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1664000, "timers": {"training_iteration_time_ms": 183398.849, "restore_workers_time_ms": 0.031, "training_step_time_ms": 183398.759, "sample_time_ms": 4262.7, "learn_time_ms": 179100.867, "learn_throughput": 22.334, "synch_weights_time_ms": 25.668}, "counters": {"num_env_steps_sampled": 416000, "num_env_steps_trained": 416000, "num_agent_steps_sampled": 1664000, "num_agent_steps_trained": 1664000}, "done": false, "training_iteration": 104, "trial_id": "75ec3_00000", "date": "2024-08-13_03-36-34", "timestamp": 1723534594, "time_this_iter_s": 978.1161396503448, "time_total_s": 8245.648737668991, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b1ad45e0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 8245.648737668991, "iterations_since_restore": 104, "perf": {"cpu_util_percent": 89.54571428571428, "ram_util_percent": 83.00857142857143}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 11.954558197594194, "cur_kl_coeff": 0.2435490769101306, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.721542653078755, "policy_loss": -0.006091535279142951, "vf_loss": 7.7249663257094285, "vf_explained_var": -0.017078047107767176, "kl": 0.010954070945868453, "entropy": 1.006665722402946, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 197505.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.21370533508539358, "cur_kl_coeff": 6.505213034913025e-20, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.15349428489331216, "policy_loss": 7.560084396529765e-05, "vf_loss": 0.15341868398922973, "vf_explained_var": 0.002456924114277754, "kl": 0.0011921419575168025, "entropy": 0.2116961546754711, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 197505.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 420000, "num_env_steps_trained": 420000, "num_agent_steps_sampled": 1680000, "num_agent_steps_trained": 1680000}, "env_runners": {"episode_reward_max": 377.5000000000001, "episode_reward_min": 94.99999999999932, "episode_reward_mean": 242.5379999999997, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -40.899999999999764, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 199.1, "predator_policy": 46.0}, "policy_reward_mean": {"prey_policy": 117.07399999999994, "predator_policy": 4.195}, "custom_metrics": {}, "hist_stats": {"episode_reward": [300.09999999999985, 229.19999999999956, 197.79999999999959, 286.60000000000014, 175.69999999999933, 172.49999999999974, 241.59999999999945, 212.79999999999944, 236.09999999999957, 222.4999999999997, 120.09999999999971, 199.19999999999968, 213.79999999999956, 191.3999999999993, 215.49999999999955, 111.99999999999915, 205.59999999999954, 237.9999999999994, 205.29999999999947, 190.99999999999963, 200.2999999999997, 126.8999999999997, 317.5999999999998, 214.5999999999996, 341.9, 237.09999999999985, 281.1999999999998, 246.99999999999983, 317.7999999999997, 377.5000000000001, 282.9999999999999, 327.1, 308.20000000000016, 213.69999999999956, 166.49999999999903, 242.5, 258.4999999999997, 265.09999999999957, 124.39999999999995, 223.79999999999933, 213.69999999999965, 326.2000000000003, 294.8000000000002, 94.99999999999932, 298.79999999999995, 334.29999999999984, 345.8999999999998, 98.49999999999997, 196.99999999999932, 296.6, 330.6999999999997, 215.69999999999965, 195.6999999999994, 275.7999999999997, 144.4999999999988, 353.2000000000005, 248.5999999999998, 145.4999999999999, 202.6999999999995, 249.69999999999942, 223.09999999999957, 158.59999999999954, 254.39999999999972, 215.79999999999953, 288.2999999999997, 294.1, 148.79999999999944, 352.29999999999995, 167.79999999999964, 204.69999999999948, 277.19999999999993, 299.2000000000005, 288.9999999999999, 257.99999999999955, 327.10000000000014, 195.9999999999992, 284.29999999999995, 261.8999999999996, 232.3999999999996, 323.50000000000045, 227.29999999999953, 160.59999999999945, 244.7999999999996, 246.99999999999943, 312.69999999999993, 236.89999999999938, 246.0999999999996, 352.3000000000003, 138.39999999999915, 143.49999999999972, 301.9000000000001, 334.2999999999999, 254.19999999999965, 270.39999999999986, 222.69999999999945, 245.69999999999968, 273.0999999999998, 287.4000000000003, 266.79999999999967, 326.79999999999984], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [109.1, 190.99999999999994, 45.80000000000004, 157.39999999999992, 47.00000000000005, 129.8000000000001, 187.39999999999992, 99.1999999999999, 37.09999999999997, 119.59999999999968, 147.79999999999998, 7.700000000000099, 161.2999999999998, 80.30000000000001, 134.2999999999999, 78.4999999999996, 106.69999999999985, 118.39999999999992, 139.39999999999992, 73.10000000000002, 60.499999999999986, 59.600000000000065, 126.1999999999999, 68.00000000000003, 91.40000000000009, 109.39999999999965, 94.09999999999977, 89.29999999999974, 82.99999999999977, 132.49999999999986, 37.999999999999986, 73.99999999999956, 104.59999999999991, 100.99999999999963, 67.70000000000007, 161.29999999999984, 102.79999999999995, 96.4999999999998, 82.70000000000007, 98.29999999999994, 100.99999999999977, 95.29999999999994, 138.79999999999998, -40.899999999999764, 157.9999999999999, 143.59999999999994, 101.90000000000005, 112.69999999999993, 175.69999999999996, 159.2, 129.8, 98.30000000000004, 127.09999999999991, 127.1, 95.89999999999993, 142.09999999999994, 121.6999999999999, 181.10000000000002, 184.7, 192.79999999999995, 134.29999999999993, 139.69999999999993, 148.7, 178.39999999999998, 147.79999999999998, 160.39999999999992, 112.69999999999993, 91.99999999999973, 5.000000000000075, 141.49999999999963, 133.4, 109.09999999999998, 88.39999999999984, 151.09999999999985, 124.99999999999983, 127.09999999999974, 29.899999999999984, 84.49999999999997, 49.100000000000115, 166.69999999999987, 144.19999999999993, 69.49999999999997, 182.8999999999999, 143.29999999999998, 159.4999999999998, 131.29999999999995, 1.0999999999999723, 80.89999999999966, 111.19999999999999, 176.59999999999994, 199.1, 135.1999999999999, 172.69999999999985, 168.19999999999987, 78.49999999999997, 20.000000000000014, 115.39999999999978, 56.600000000000165, 133.9999999999999, 149.60000000000002, 158.59999999999985, 172.10000000000002, 64.40000000000003, 143.2999999999998, 47.90000000000021, 147.8, 132.49999999999966, 143.29999999999995, 40.40000000000018, 91.09999999999943, 180.19999999999993, 172.99999999999983, 104.90000000000006, 121.69999999999989, 15.500000000000155, 95.00000000000009, 47.000000000000114, 145.7, 90.19999999999985, 159.49999999999983, 115.99999999999991, 82.10000000000008, 143.8999999999998, -40.300000000000026, 120.19999999999999, 126.19999999999976, 142.39999999999986, 70.40000000000006, 152.29999999999998, 130.99999999999977, 126.79999999999986, 146.29999999999995, 66.79999999999986, 59.00000000000008, 168.49999999999991, 183.79999999999993, 73.40000000000009, 76.40000000000003, 154.0999999999999, 50.599999999999966, 135.5, 130.7, 163.09999999999982, 136.09999999999994, 144.19999999999987, 138.79999999999995, 175.69999999999996, 74.3000000000001, 147.79999999999995, 179.2999999999999, 20.000000000000014, 172.99999999999991, 188.29999999999998, 80.00000000000003, 183.79999999999998, 67.09999999999988, 126.79999999999991, 104.59999999999972, 182.8999999999999, 140.59999999999997, 83.90000000000009, 139.39999999999992, 70.4000000000001, 90.1999999999999, 135.49999999999986, 98.29999999999984, 136.99999999999966, 92.0, 162.1999999999998, 150.4999999999997, 174.49999999999986, 61.39999999999996, 127.99999999999983, 118.09999999999994, 172.0999999999999, 180.19999999999996, 65.00000000000014, 61.400000000000055, 52.40000000000009, 91.10000000000001, 166.6999999999999, 126.20000000000003, 195.49999999999997, 138.79999999999987, 106.39999999999988, 147.8, 165.79999999999995, 104.6, 136.0999999999997, 86.60000000000007, 117.50000000000004, 126.19999999999982, 122.2999999999999, 126.79999999999991, 112.69999999999973, 160.7, 110.00000000000009, 156.7999999999999, 163.1, 151.69999999999987], "policy_predator_policy_reward": [0.0, 0.0, 16.0, 10.0, 11.0, 10.0, 0.0, 0.0, 9.0, 10.0, 0.0, 17.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 1.0, 9.0, 0.0, 0.0, 0.0, 5.0, 2.0, 11.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 3.0, 0.0, 6.0, 10.0, 0.0, 4.0, 0.0, 29.0, 0.0, 5.0, 11.0, 0.0, 0.0, 7.0, 0.0, 9.0, 0.0, 19.0, 8.0, 2.0, 7.0, 6.0, 9.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 13.0, 7.0, 0.0, 0.0, 0.0, 19.0, 3.0, 10.0, 0.0, 10.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 13.0, 0.0, 11.0, 0.0, 0.0, 0.0, 4.0, 1.0, 0.0, 0.0, 5.0, 20.0, 13.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 0.0, 22.0, 17.0, 18.0, 10.0, 0.0, 0.0, 0.0, 0.0, 25.0, 46.0, 9.0, 8.0, 0.0, 3.0, 0.0, 5.0, 0.0, 0.0, 21.0, 0.0, 23.0, 0.0, 0.0, 18.0, 0.0, 0.0, 0.0, 8.0, 3.0, 0.0, 0.0, 6.0, 0.0, 0.0, 8.0, 0.0, 0.0, 3.0, 0.0, 13.0, 3.0, 11.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 11.0, 0.0, 18.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 3.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 13.0, 11.0, 7.0, 7.0, 0.0, 0.0, 0.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 11.684203800140692, "mean_inference_ms": 25.78514076002695, "mean_action_processing_ms": 5.700113513934496, "mean_env_wait_ms": 7.566318633926635, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006060123443603516, "StateBufferConnector_ms": 0.0477597713470459, "ViewRequirementAgentConnector_ms": 0.3538755178451538}, "num_episodes": 23, "episode_return_max": 377.5000000000001, "episode_return_min": 94.99999999999932, "episode_return_mean": 242.5379999999997, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1680000, "num_agent_steps_trained": 1680000, "num_env_steps_sampled": 420000, "num_env_steps_trained": 420000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 168.88060616978936, "num_env_steps_trained_throughput_per_sec": 168.88060616978936, "timesteps_total": 420000, "num_env_steps_sampled_lifetime": 420000, "num_agent_steps_sampled_lifetime": 1680000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1680000, "timers": {"training_iteration_time_ms": 182385.524, "restore_workers_time_ms": 0.031, "training_step_time_ms": 182385.435, "sample_time_ms": 4235.183, "learn_time_ms": 178115.864, "learn_throughput": 22.457, "synch_weights_time_ms": 24.943}, "counters": {"num_env_steps_sampled": 420000, "num_env_steps_trained": 420000, "num_agent_steps_sampled": 1680000, "num_agent_steps_trained": 1680000}, "done": false, "training_iteration": 105, "trial_id": "75ec3_00000", "date": "2024-08-13_03-36-58", "timestamp": 1723534618, "time_this_iter_s": 23.765560150146484, "time_total_s": 8269.414297819138, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b226f8b0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 8269.414297819138, "iterations_since_restore": 105, "perf": {"cpu_util_percent": 96.94848484848485, "ram_util_percent": 83.52424242424242}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 12.531126185731281, "cur_kl_coeff": 0.2435490769101306, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.893634717931192, "policy_loss": -0.0019100503848185615, "vf_loss": 6.894578641306156, "vf_explained_var": 0.2308453601504129, "kl": 0.003966858257150786, "entropy": 1.035183304453653, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 199395.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.34664934269058956, "cur_kl_coeff": 3.2526065174565126e-20, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.30787980536777504, "policy_loss": -0.00017060810606433916, "vf_loss": 0.30805041295569885, "vf_explained_var": 0.004431608934251089, "kl": 0.0012562640223117794, "entropy": 0.17478644689397208, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 199395.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 424000, "num_env_steps_trained": 424000, "num_agent_steps_sampled": 1696000, "num_agent_steps_trained": 1696000}, "env_runners": {"episode_reward_max": 377.5000000000001, "episode_reward_min": 94.99999999999932, "episode_reward_mean": 251.96499999999975, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -40.899999999999764, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 199.1, "predator_policy": 46.0}, "policy_reward_mean": {"prey_policy": 121.99249999999992, "predator_policy": 3.99}, "custom_metrics": {}, "hist_stats": {"episode_reward": [205.29999999999947, 190.99999999999963, 200.2999999999997, 126.8999999999997, 317.5999999999998, 214.5999999999996, 341.9, 237.09999999999985, 281.1999999999998, 246.99999999999983, 317.7999999999997, 377.5000000000001, 282.9999999999999, 327.1, 308.20000000000016, 213.69999999999956, 166.49999999999903, 242.5, 258.4999999999997, 265.09999999999957, 124.39999999999995, 223.79999999999933, 213.69999999999965, 326.2000000000003, 294.8000000000002, 94.99999999999932, 298.79999999999995, 334.29999999999984, 345.8999999999998, 98.49999999999997, 196.99999999999932, 296.6, 330.6999999999997, 215.69999999999965, 195.6999999999994, 275.7999999999997, 144.4999999999988, 353.2000000000005, 248.5999999999998, 145.4999999999999, 202.6999999999995, 249.69999999999942, 223.09999999999957, 158.59999999999954, 254.39999999999972, 215.79999999999953, 288.2999999999997, 294.1, 148.79999999999944, 352.29999999999995, 167.79999999999964, 204.69999999999948, 277.19999999999993, 299.2000000000005, 288.9999999999999, 257.99999999999955, 327.10000000000014, 195.9999999999992, 284.29999999999995, 261.8999999999996, 232.3999999999996, 323.50000000000045, 227.29999999999953, 160.59999999999945, 244.7999999999996, 246.99999999999943, 312.69999999999993, 236.89999999999938, 246.0999999999996, 352.3000000000003, 138.39999999999915, 143.49999999999972, 301.9000000000001, 334.2999999999999, 254.19999999999965, 270.39999999999986, 222.69999999999945, 245.69999999999968, 273.0999999999998, 287.4000000000003, 266.79999999999967, 326.79999999999984, 243.39999999999984, 227.2999999999993, 236.79999999999959, 305.50000000000006, 344.69999999999993, 214.39999999999975, 292.4000000000001, 147.39999999999964, 269.49999999999994, 344.79999999999995, 149.39999999999935, 264.9999999999998, 297.3999999999998, 308.2000000000003, 292.4999999999999, 228.99999999999932, 264.99999999999955, 280.5000000000008], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [102.79999999999995, 96.4999999999998, 82.70000000000007, 98.29999999999994, 100.99999999999977, 95.29999999999994, 138.79999999999998, -40.899999999999764, 157.9999999999999, 143.59999999999994, 101.90000000000005, 112.69999999999993, 175.69999999999996, 159.2, 129.8, 98.30000000000004, 127.09999999999991, 127.1, 95.89999999999993, 142.09999999999994, 121.6999999999999, 181.10000000000002, 184.7, 192.79999999999995, 134.29999999999993, 139.69999999999993, 148.7, 178.39999999999998, 147.79999999999998, 160.39999999999992, 112.69999999999993, 91.99999999999973, 5.000000000000075, 141.49999999999963, 133.4, 109.09999999999998, 88.39999999999984, 151.09999999999985, 124.99999999999983, 127.09999999999974, 29.899999999999984, 84.49999999999997, 49.100000000000115, 166.69999999999987, 144.19999999999993, 69.49999999999997, 182.8999999999999, 143.29999999999998, 159.4999999999998, 131.29999999999995, 1.0999999999999723, 80.89999999999966, 111.19999999999999, 176.59999999999994, 199.1, 135.1999999999999, 172.69999999999985, 168.19999999999987, 78.49999999999997, 20.000000000000014, 115.39999999999978, 56.600000000000165, 133.9999999999999, 149.60000000000002, 158.59999999999985, 172.10000000000002, 64.40000000000003, 143.2999999999998, 47.90000000000021, 147.8, 132.49999999999966, 143.29999999999995, 40.40000000000018, 91.09999999999943, 180.19999999999993, 172.99999999999983, 104.90000000000006, 121.69999999999989, 15.500000000000155, 95.00000000000009, 47.000000000000114, 145.7, 90.19999999999985, 159.49999999999983, 115.99999999999991, 82.10000000000008, 143.8999999999998, -40.300000000000026, 120.19999999999999, 126.19999999999976, 142.39999999999986, 70.40000000000006, 152.29999999999998, 130.99999999999977, 126.79999999999986, 146.29999999999995, 66.79999999999986, 59.00000000000008, 168.49999999999991, 183.79999999999993, 73.40000000000009, 76.40000000000003, 154.0999999999999, 50.599999999999966, 135.5, 130.7, 163.09999999999982, 136.09999999999994, 144.19999999999987, 138.79999999999995, 175.69999999999996, 74.3000000000001, 147.79999999999995, 179.2999999999999, 20.000000000000014, 172.99999999999991, 188.29999999999998, 80.00000000000003, 183.79999999999998, 67.09999999999988, 126.79999999999991, 104.59999999999972, 182.8999999999999, 140.59999999999997, 83.90000000000009, 139.39999999999992, 70.4000000000001, 90.1999999999999, 135.49999999999986, 98.29999999999984, 136.99999999999966, 92.0, 162.1999999999998, 150.4999999999997, 174.49999999999986, 61.39999999999996, 127.99999999999983, 118.09999999999994, 172.0999999999999, 180.19999999999996, 65.00000000000014, 61.400000000000055, 52.40000000000009, 91.10000000000001, 166.6999999999999, 126.20000000000003, 195.49999999999997, 138.79999999999987, 106.39999999999988, 147.8, 165.79999999999995, 104.6, 136.0999999999997, 86.60000000000007, 117.50000000000004, 126.19999999999982, 122.2999999999999, 126.79999999999991, 112.69999999999973, 160.7, 110.00000000000009, 156.7999999999999, 163.1, 151.69999999999987, 117.20000000000002, 126.19999999999999, 141.49999999999972, 72.80000000000015, 147.79999999999984, 82.99999999999997, 166.69999999999987, 138.7999999999996, 168.79999999999998, 173.89999999999998, 97.99999999999999, 115.39999999999998, 135.19999999999996, 150.2, 43.39999999999998, 92.00000000000009, 165.79999999999993, 103.69999999999993, 193.7, 145.09999999999994, 15.799999999999963, 131.59999999999985, 170.3, 85.70000000000006, 126.19999999999979, 171.19999999999982, 146.89999999999992, 161.29999999999998, 96.80000000000004, 184.69999999999996, 154.0999999999998, 74.89999999999968, 198.2, 66.80000000000007, 93.79999999999995, 157.6999999999998], "policy_predator_policy_reward": [0.0, 6.0, 10.0, 0.0, 4.0, 0.0, 29.0, 0.0, 5.0, 11.0, 0.0, 0.0, 7.0, 0.0, 9.0, 0.0, 19.0, 8.0, 2.0, 7.0, 6.0, 9.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 13.0, 7.0, 0.0, 0.0, 0.0, 19.0, 3.0, 10.0, 0.0, 10.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 13.0, 0.0, 11.0, 0.0, 0.0, 0.0, 4.0, 1.0, 0.0, 0.0, 5.0, 20.0, 13.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 0.0, 22.0, 17.0, 18.0, 10.0, 0.0, 0.0, 0.0, 0.0, 25.0, 46.0, 9.0, 8.0, 0.0, 3.0, 0.0, 5.0, 0.0, 0.0, 21.0, 0.0, 23.0, 0.0, 0.0, 18.0, 0.0, 0.0, 0.0, 8.0, 3.0, 0.0, 0.0, 6.0, 0.0, 0.0, 8.0, 0.0, 0.0, 3.0, 0.0, 13.0, 3.0, 11.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 11.0, 0.0, 18.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 3.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 13.0, 11.0, 7.0, 7.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 3.0, 10.0, 6.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 7.0, 0.0, 12.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 2.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 14.0, 15.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 11.595918472441461, "mean_inference_ms": 25.599946642570114, "mean_action_processing_ms": 5.655810937084812, "mean_env_wait_ms": 7.505291081618534, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005375266075134277, "StateBufferConnector_ms": 0.0390779972076416, "ViewRequirementAgentConnector_ms": 0.3239915370941162}, "num_episodes": 18, "episode_return_max": 377.5000000000001, "episode_return_min": 94.99999999999932, "episode_return_mean": 251.96499999999975, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1696000, "num_agent_steps_trained": 1696000, "num_env_steps_sampled": 424000, "num_env_steps_trained": 424000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 246.40235819456618, "num_env_steps_trained_throughput_per_sec": 246.40235819456618, "timesteps_total": 424000, "num_env_steps_sampled_lifetime": 424000, "num_agent_steps_sampled_lifetime": 1696000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1696000, "timers": {"training_iteration_time_ms": 180905.683, "restore_workers_time_ms": 0.03, "training_step_time_ms": 180905.596, "sample_time_ms": 4011.222, "learn_time_ms": 176860.906, "learn_throughput": 22.617, "synch_weights_time_ms": 23.957}, "counters": {"num_env_steps_sampled": 424000, "num_env_steps_trained": 424000, "num_agent_steps_sampled": 1696000, "num_agent_steps_trained": 1696000}, "done": false, "training_iteration": 106, "trial_id": "75ec3_00000", "date": "2024-08-13_03-37-14", "timestamp": 1723534634, "time_this_iter_s": 16.32043433189392, "time_total_s": 8285.734732151031, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b23f0280>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 8285.734732151031, "iterations_since_restore": 106, "perf": {"cpu_util_percent": 81.5304347826087, "ram_util_percent": 83.40869565217392}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 9.876591589148083, "cur_kl_coeff": 0.1217745384550653, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.300791524200843, "policy_loss": -0.010672981956007856, "vf_loss": 7.30862418835756, "vf_explained_var": 0.16785809624762763, "kl": 0.023324443327719567, "entropy": 1.0040325143349864, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 201285.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6787395184396436, "cur_kl_coeff": 1.6263032587282563e-20, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.9902139148384175, "policy_loss": -0.0010692268295864028, "vf_loss": 0.991283142345923, "vf_explained_var": 0.03334339172751815, "kl": 0.001215624285502402, "entropy": 0.1964179030171147, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 201285.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 428000, "num_env_steps_trained": 428000, "num_agent_steps_sampled": 1712000, "num_agent_steps_trained": 1712000}, "env_runners": {"episode_reward_max": 353.2000000000005, "episode_reward_min": 94.99999999999932, "episode_reward_mean": 257.3979999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -40.300000000000026, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 199.1, "predator_policy": 46.0}, "policy_reward_mean": {"prey_policy": 124.93399999999994, "predator_policy": 3.765}, "custom_metrics": {}, "hist_stats": {"episode_reward": [213.69999999999965, 326.2000000000003, 294.8000000000002, 94.99999999999932, 298.79999999999995, 334.29999999999984, 345.8999999999998, 98.49999999999997, 196.99999999999932, 296.6, 330.6999999999997, 215.69999999999965, 195.6999999999994, 275.7999999999997, 144.4999999999988, 353.2000000000005, 248.5999999999998, 145.4999999999999, 202.6999999999995, 249.69999999999942, 223.09999999999957, 158.59999999999954, 254.39999999999972, 215.79999999999953, 288.2999999999997, 294.1, 148.79999999999944, 352.29999999999995, 167.79999999999964, 204.69999999999948, 277.19999999999993, 299.2000000000005, 288.9999999999999, 257.99999999999955, 327.10000000000014, 195.9999999999992, 284.29999999999995, 261.8999999999996, 232.3999999999996, 323.50000000000045, 227.29999999999953, 160.59999999999945, 244.7999999999996, 246.99999999999943, 312.69999999999993, 236.89999999999938, 246.0999999999996, 352.3000000000003, 138.39999999999915, 143.49999999999972, 301.9000000000001, 334.2999999999999, 254.19999999999965, 270.39999999999986, 222.69999999999945, 245.69999999999968, 273.0999999999998, 287.4000000000003, 266.79999999999967, 326.79999999999984, 243.39999999999984, 227.2999999999993, 236.79999999999959, 305.50000000000006, 344.69999999999993, 214.39999999999975, 292.4000000000001, 147.39999999999964, 269.49999999999994, 344.79999999999995, 149.39999999999935, 264.9999999999998, 297.3999999999998, 308.2000000000003, 292.4999999999999, 228.99999999999932, 264.99999999999955, 280.5000000000008, 263.69999999999976, 300.9999999999999, 297.5000000000001, 252.3999999999998, 272.60000000000014, 254.1999999999997, 266.5999999999999, 306.3999999999996, 258.7999999999996, 272.20000000000005, 320.59999999999997, 295.60000000000036, 349.60000000000014, 237.0999999999996, 296.6, 231.89999999999952, 316.10000000000036, 287.50000000000017, 275.89999999999975, 169.39999999999938, 260.39999999999986, 228.19999999999962], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [144.19999999999993, 69.49999999999997, 182.8999999999999, 143.29999999999998, 159.4999999999998, 131.29999999999995, 1.0999999999999723, 80.89999999999966, 111.19999999999999, 176.59999999999994, 199.1, 135.1999999999999, 172.69999999999985, 168.19999999999987, 78.49999999999997, 20.000000000000014, 115.39999999999978, 56.600000000000165, 133.9999999999999, 149.60000000000002, 158.59999999999985, 172.10000000000002, 64.40000000000003, 143.2999999999998, 47.90000000000021, 147.8, 132.49999999999966, 143.29999999999995, 40.40000000000018, 91.09999999999943, 180.19999999999993, 172.99999999999983, 104.90000000000006, 121.69999999999989, 15.500000000000155, 95.00000000000009, 47.000000000000114, 145.7, 90.19999999999985, 159.49999999999983, 115.99999999999991, 82.10000000000008, 143.8999999999998, -40.300000000000026, 120.19999999999999, 126.19999999999976, 142.39999999999986, 70.40000000000006, 152.29999999999998, 130.99999999999977, 126.79999999999986, 146.29999999999995, 66.79999999999986, 59.00000000000008, 168.49999999999991, 183.79999999999993, 73.40000000000009, 76.40000000000003, 154.0999999999999, 50.599999999999966, 135.5, 130.7, 163.09999999999982, 136.09999999999994, 144.19999999999987, 138.79999999999995, 175.69999999999996, 74.3000000000001, 147.79999999999995, 179.2999999999999, 20.000000000000014, 172.99999999999991, 188.29999999999998, 80.00000000000003, 183.79999999999998, 67.09999999999988, 126.79999999999991, 104.59999999999972, 182.8999999999999, 140.59999999999997, 83.90000000000009, 139.39999999999992, 70.4000000000001, 90.1999999999999, 135.49999999999986, 98.29999999999984, 136.99999999999966, 92.0, 162.1999999999998, 150.4999999999997, 174.49999999999986, 61.39999999999996, 127.99999999999983, 118.09999999999994, 172.0999999999999, 180.19999999999996, 65.00000000000014, 61.400000000000055, 52.40000000000009, 91.10000000000001, 166.6999999999999, 126.20000000000003, 195.49999999999997, 138.79999999999987, 106.39999999999988, 147.8, 165.79999999999995, 104.6, 136.0999999999997, 86.60000000000007, 117.50000000000004, 126.19999999999982, 122.2999999999999, 126.79999999999991, 112.69999999999973, 160.7, 110.00000000000009, 156.7999999999999, 163.1, 151.69999999999987, 117.20000000000002, 126.19999999999999, 141.49999999999972, 72.80000000000015, 147.79999999999984, 82.99999999999997, 166.69999999999987, 138.7999999999996, 168.79999999999998, 173.89999999999998, 97.99999999999999, 115.39999999999998, 135.19999999999996, 150.2, 43.39999999999998, 92.00000000000009, 165.79999999999993, 103.69999999999993, 193.7, 145.09999999999994, 15.799999999999963, 131.59999999999985, 170.3, 85.70000000000006, 126.19999999999979, 171.19999999999982, 146.89999999999992, 161.29999999999998, 96.80000000000004, 184.69999999999996, 154.0999999999998, 74.89999999999968, 198.2, 66.80000000000007, 93.79999999999995, 157.6999999999998, 99.49999999999977, 159.19999999999987, 139.70000000000002, 161.29999999999995, 139.7, 144.79999999999998, 147.79999999999998, 104.59999999999982, 112.39999999999964, 153.19999999999996, 149.5999999999999, 77.5999999999998, 179.3, 86.2999999999998, 185.59999999999994, 120.79999999999983, 115.39999999999988, 115.39999999999972, 140.60000000000002, 131.60000000000002, 122.9, 175.7, 169.39999999999998, 126.19999999999992, 190.1, 159.4999999999998, 74.90000000000003, 162.20000000000005, 152.0, 131.6, 70.39999999999966, 153.5, 148.09999999999985, 163.99999999999977, 141.1999999999999, 131.29999999999987, 181.99999999999997, 89.8999999999999, 24.79999999999997, 134.59999999999982, 126.19999999999999, 129.20000000000005, 116.89999999999989, 98.30000000000001], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 13.0, 0.0, 11.0, 0.0, 0.0, 0.0, 4.0, 1.0, 0.0, 0.0, 5.0, 20.0, 13.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 0.0, 22.0, 17.0, 18.0, 10.0, 0.0, 0.0, 0.0, 0.0, 25.0, 46.0, 9.0, 8.0, 0.0, 3.0, 0.0, 5.0, 0.0, 0.0, 21.0, 0.0, 23.0, 0.0, 0.0, 18.0, 0.0, 0.0, 0.0, 8.0, 3.0, 0.0, 0.0, 6.0, 0.0, 0.0, 8.0, 0.0, 0.0, 3.0, 0.0, 13.0, 3.0, 11.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 11.0, 0.0, 18.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 3.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 13.0, 11.0, 7.0, 7.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 3.0, 10.0, 6.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 7.0, 0.0, 12.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 2.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 14.0, 15.0, 2.0, 3.0, 0.0, 0.0, 10.0, 3.0, 0.0, 0.0, 7.0, 0.0, 0.0, 27.0, 0.0, 1.0, 0.0, 0.0, 15.0, 13.0, 0.0, 0.0, 17.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13.0, 0.0, 8.0, 2.0, 2.0, 14.0, 1.0, 4.0, 0.0, 5.0, 5.0, 5.0, 0.0, 13.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 11.71092796941043, "mean_inference_ms": 25.34647136915095, "mean_action_processing_ms": 5.4056601911784465, "mean_env_wait_ms": 7.442690358540732, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004710674285888672, "StateBufferConnector_ms": 0.02325296401977539, "ViewRequirementAgentConnector_ms": 0.2533944845199585}, "num_episodes": 22, "episode_return_max": 353.2000000000005, "episode_return_min": 94.99999999999932, "episode_return_mean": 257.3979999999998, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1712000, "num_agent_steps_trained": 1712000, "num_env_steps_sampled": 428000, "num_env_steps_trained": 428000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 3.9044404712396648, "num_env_steps_trained_throughput_per_sec": 3.9044404712396648, "timesteps_total": 428000, "num_env_steps_sampled_lifetime": 428000, "num_agent_steps_sampled_lifetime": 1712000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1712000, "timers": {"training_iteration_time_ms": 280317.613, "restore_workers_time_ms": 0.029, "training_step_time_ms": 280317.528, "sample_time_ms": 3831.237, "learn_time_ms": 276452.608, "learn_throughput": 14.469, "synch_weights_time_ms": 23.754}, "counters": {"num_env_steps_sampled": 428000, "num_env_steps_trained": 428000, "num_agent_steps_sampled": 1712000, "num_agent_steps_trained": 1712000}, "done": false, "training_iteration": 107, "trial_id": "75ec3_00000", "date": "2024-08-13_03-54-19", "timestamp": 1723535659, "time_this_iter_s": 1024.578975200653, "time_total_s": 9310.313707351685, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b223a0d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 9310.313707351685, "iterations_since_restore": 107, "perf": {"cpu_util_percent": 91.22894736842105, "ram_util_percent": 82.4078947368421}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 12.371734599934683, "cur_kl_coeff": 0.18266180768259807, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.143872962174592, "policy_loss": -0.011156493088688761, "vf_loss": 8.151480253915938, "vf_explained_var": 0.3762164843145502, "kl": 0.019430445755517587, "entropy": 1.0505482155809958, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 203175.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.27245313136508226, "cur_kl_coeff": 8.131516293641281e-21, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.08022888328919493, "policy_loss": -0.0002391383835365848, "vf_loss": 0.08046802176339996, "vf_explained_var": -0.07947678439831607, "kl": 0.0007731275569365433, "entropy": 0.22695064302632417, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 203175.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 432000, "num_env_steps_trained": 432000, "num_agent_steps_sampled": 1728000, "num_agent_steps_trained": 1728000}, "env_runners": {"episode_reward_max": 366.7000000000002, "episode_reward_min": 83.50000000000011, "episode_reward_mean": 258.1339999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -40.300000000000026, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 198.2, "predator_policy": 46.0}, "policy_reward_mean": {"prey_policy": 125.67199999999991, "predator_policy": 3.395}, "custom_metrics": {}, "hist_stats": {"episode_reward": [202.6999999999995, 249.69999999999942, 223.09999999999957, 158.59999999999954, 254.39999999999972, 215.79999999999953, 288.2999999999997, 294.1, 148.79999999999944, 352.29999999999995, 167.79999999999964, 204.69999999999948, 277.19999999999993, 299.2000000000005, 288.9999999999999, 257.99999999999955, 327.10000000000014, 195.9999999999992, 284.29999999999995, 261.8999999999996, 232.3999999999996, 323.50000000000045, 227.29999999999953, 160.59999999999945, 244.7999999999996, 246.99999999999943, 312.69999999999993, 236.89999999999938, 246.0999999999996, 352.3000000000003, 138.39999999999915, 143.49999999999972, 301.9000000000001, 334.2999999999999, 254.19999999999965, 270.39999999999986, 222.69999999999945, 245.69999999999968, 273.0999999999998, 287.4000000000003, 266.79999999999967, 326.79999999999984, 243.39999999999984, 227.2999999999993, 236.79999999999959, 305.50000000000006, 344.69999999999993, 214.39999999999975, 292.4000000000001, 147.39999999999964, 269.49999999999994, 344.79999999999995, 149.39999999999935, 264.9999999999998, 297.3999999999998, 308.2000000000003, 292.4999999999999, 228.99999999999932, 264.99999999999955, 280.5000000000008, 263.69999999999976, 300.9999999999999, 297.5000000000001, 252.3999999999998, 272.60000000000014, 254.1999999999997, 266.5999999999999, 306.3999999999996, 258.7999999999996, 272.20000000000005, 320.59999999999997, 295.60000000000036, 349.60000000000014, 237.0999999999996, 296.6, 231.89999999999952, 316.10000000000036, 287.50000000000017, 275.89999999999975, 169.39999999999938, 260.39999999999986, 228.19999999999962, 321.4999999999998, 241.19999999999976, 132.99999999999898, 263.1999999999996, 112.30000000000024, 83.50000000000011, 290.1999999999998, 271.9999999999993, 331.60000000000076, 271.2999999999996, 366.7000000000002, 287.4999999999998, 307.7000000000003, 221.79999999999978, 242.79999999999953, 278.20000000000044, 298.29999999999995, 161.29999999999995], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [47.000000000000114, 145.7, 90.19999999999985, 159.49999999999983, 115.99999999999991, 82.10000000000008, 143.8999999999998, -40.300000000000026, 120.19999999999999, 126.19999999999976, 142.39999999999986, 70.40000000000006, 152.29999999999998, 130.99999999999977, 126.79999999999986, 146.29999999999995, 66.79999999999986, 59.00000000000008, 168.49999999999991, 183.79999999999993, 73.40000000000009, 76.40000000000003, 154.0999999999999, 50.599999999999966, 135.5, 130.7, 163.09999999999982, 136.09999999999994, 144.19999999999987, 138.79999999999995, 175.69999999999996, 74.3000000000001, 147.79999999999995, 179.2999999999999, 20.000000000000014, 172.99999999999991, 188.29999999999998, 80.00000000000003, 183.79999999999998, 67.09999999999988, 126.79999999999991, 104.59999999999972, 182.8999999999999, 140.59999999999997, 83.90000000000009, 139.39999999999992, 70.4000000000001, 90.1999999999999, 135.49999999999986, 98.29999999999984, 136.99999999999966, 92.0, 162.1999999999998, 150.4999999999997, 174.49999999999986, 61.39999999999996, 127.99999999999983, 118.09999999999994, 172.0999999999999, 180.19999999999996, 65.00000000000014, 61.400000000000055, 52.40000000000009, 91.10000000000001, 166.6999999999999, 126.20000000000003, 195.49999999999997, 138.79999999999987, 106.39999999999988, 147.8, 165.79999999999995, 104.6, 136.0999999999997, 86.60000000000007, 117.50000000000004, 126.19999999999982, 122.2999999999999, 126.79999999999991, 112.69999999999973, 160.7, 110.00000000000009, 156.7999999999999, 163.1, 151.69999999999987, 117.20000000000002, 126.19999999999999, 141.49999999999972, 72.80000000000015, 147.79999999999984, 82.99999999999997, 166.69999999999987, 138.7999999999996, 168.79999999999998, 173.89999999999998, 97.99999999999999, 115.39999999999998, 135.19999999999996, 150.2, 43.39999999999998, 92.00000000000009, 165.79999999999993, 103.69999999999993, 193.7, 145.09999999999994, 15.799999999999963, 131.59999999999985, 170.3, 85.70000000000006, 126.19999999999979, 171.19999999999982, 146.89999999999992, 161.29999999999998, 96.80000000000004, 184.69999999999996, 154.0999999999998, 74.89999999999968, 198.2, 66.80000000000007, 93.79999999999995, 157.6999999999998, 99.49999999999977, 159.19999999999987, 139.70000000000002, 161.29999999999995, 139.7, 144.79999999999998, 147.79999999999998, 104.59999999999982, 112.39999999999964, 153.19999999999996, 149.5999999999999, 77.5999999999998, 179.3, 86.2999999999998, 185.59999999999994, 120.79999999999983, 115.39999999999988, 115.39999999999972, 140.60000000000002, 131.60000000000002, 122.9, 175.7, 169.39999999999998, 126.19999999999992, 190.1, 159.4999999999998, 74.90000000000003, 162.20000000000005, 152.0, 131.6, 70.39999999999966, 153.5, 148.09999999999985, 163.99999999999977, 141.1999999999999, 131.29999999999987, 181.99999999999997, 89.8999999999999, 24.79999999999997, 134.59999999999982, 126.19999999999999, 129.20000000000005, 116.89999999999989, 98.30000000000001, 133.40000000000003, 172.0999999999999, 103.99999999999999, 135.19999999999985, 100.99999999999986, 20.000000000000014, 166.69999999999982, 96.49999999999994, 36.199999999999974, 73.10000000000011, 24.500000000000007, 55.99999999999998, 118.99999999999966, 171.19999999999987, 130.69999999999965, 140.29999999999984, 154.99999999999972, 176.5999999999999, 135.19999999999982, 136.09999999999988, 195.5, 171.19999999999985, 139.69999999999968, 147.7999999999997, 168.49999999999997, 132.19999999999985, 141.49999999999991, 80.30000000000001, 64.7000000000001, 166.09999999999997, 119.89999999999962, 152.29999999999993, 148.69999999999982, 149.5999999999998, 121.39999999999998, 26.900000000000126], "policy_predator_policy_reward": [10.0, 0.0, 0.0, 0.0, 0.0, 25.0, 46.0, 9.0, 8.0, 0.0, 3.0, 0.0, 5.0, 0.0, 0.0, 21.0, 0.0, 23.0, 0.0, 0.0, 18.0, 0.0, 0.0, 0.0, 8.0, 3.0, 0.0, 0.0, 6.0, 0.0, 0.0, 8.0, 0.0, 0.0, 3.0, 0.0, 13.0, 3.0, 11.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 11.0, 0.0, 18.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 3.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 13.0, 11.0, 7.0, 7.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 3.0, 10.0, 6.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 7.0, 0.0, 12.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 2.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 14.0, 15.0, 2.0, 3.0, 0.0, 0.0, 10.0, 3.0, 0.0, 0.0, 7.0, 0.0, 0.0, 27.0, 0.0, 1.0, 0.0, 0.0, 15.0, 13.0, 0.0, 0.0, 17.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13.0, 0.0, 8.0, 2.0, 2.0, 14.0, 1.0, 4.0, 0.0, 5.0, 5.0, 5.0, 0.0, 13.0, 0.0, 7.0, 9.0, 0.0, 2.0, 12.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 3.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 7.0, 5.0, 6.0, 0.0, 0.0, 0.0, 13.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 11.400968731367696, "mean_inference_ms": 25.199363022759442, "mean_action_processing_ms": 5.566879454138261, "mean_env_wait_ms": 7.360916883850851, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00480198860168457, "StateBufferConnector_ms": 0.023048758506774902, "ViewRequirementAgentConnector_ms": 0.23267018795013428}, "num_episodes": 18, "episode_return_max": 366.7000000000002, "episode_return_min": 83.50000000000011, "episode_return_mean": 258.1339999999998, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1728000, "num_agent_steps_trained": 1728000, "num_env_steps_sampled": 432000, "num_env_steps_trained": 432000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 207.3378845495434, "num_env_steps_trained_throughput_per_sec": 207.3378845495434, "timesteps_total": 432000, "num_env_steps_sampled_lifetime": 432000, "num_agent_steps_sampled_lifetime": 1728000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1728000, "timers": {"training_iteration_time_ms": 279182.224, "restore_workers_time_ms": 0.029, "training_step_time_ms": 279182.138, "sample_time_ms": 3704.075, "learn_time_ms": 275447.052, "learn_throughput": 14.522, "synch_weights_time_ms": 21.375}, "counters": {"num_env_steps_sampled": 432000, "num_env_steps_trained": 432000, "num_agent_steps_sampled": 1728000, "num_agent_steps_trained": 1728000}, "done": false, "training_iteration": 108, "trial_id": "75ec3_00000", "date": "2024-08-13_03-54-38", "timestamp": 1723535678, "time_this_iter_s": 19.35412096977234, "time_total_s": 9329.667828321457, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b226f8b0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 9329.667828321457, "iterations_since_restore": 108, "perf": {"cpu_util_percent": 87.61851851851851, "ram_util_percent": 81.88518518518521}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 8.324036933394966, "cur_kl_coeff": 0.18266180768259807, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.476477442090474, "policy_loss": -0.009492599446247653, "vf_loss": 6.481857284667, "vf_explained_var": 0.22866484642659546, "kl": 0.022515692733931385, "entropy": 1.0239460926522654, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 205065.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.23155388191401485, "cur_kl_coeff": 4.065758146820641e-21, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.18823122776374615, "policy_loss": -0.00014119799983091456, "vf_loss": 0.18837242577626573, "vf_explained_var": -0.017142157232950605, "kl": 0.0018007311978842696, "entropy": 0.17889143248241415, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 205065.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 436000, "num_env_steps_trained": 436000, "num_agent_steps_sampled": 1744000, "num_agent_steps_trained": 1744000}, "env_runners": {"episode_reward_max": 366.7000000000002, "episode_reward_min": 83.50000000000011, "episode_reward_mean": 265.4979999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 15.799999999999963, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 198.2, "predator_policy": 27.0}, "policy_reward_mean": {"prey_policy": 130.0039999999999, "predator_policy": 2.745}, "custom_metrics": {}, "hist_stats": {"episode_reward": [284.29999999999995, 261.8999999999996, 232.3999999999996, 323.50000000000045, 227.29999999999953, 160.59999999999945, 244.7999999999996, 246.99999999999943, 312.69999999999993, 236.89999999999938, 246.0999999999996, 352.3000000000003, 138.39999999999915, 143.49999999999972, 301.9000000000001, 334.2999999999999, 254.19999999999965, 270.39999999999986, 222.69999999999945, 245.69999999999968, 273.0999999999998, 287.4000000000003, 266.79999999999967, 326.79999999999984, 243.39999999999984, 227.2999999999993, 236.79999999999959, 305.50000000000006, 344.69999999999993, 214.39999999999975, 292.4000000000001, 147.39999999999964, 269.49999999999994, 344.79999999999995, 149.39999999999935, 264.9999999999998, 297.3999999999998, 308.2000000000003, 292.4999999999999, 228.99999999999932, 264.99999999999955, 280.5000000000008, 263.69999999999976, 300.9999999999999, 297.5000000000001, 252.3999999999998, 272.60000000000014, 254.1999999999997, 266.5999999999999, 306.3999999999996, 258.7999999999996, 272.20000000000005, 320.59999999999997, 295.60000000000036, 349.60000000000014, 237.0999999999996, 296.6, 231.89999999999952, 316.10000000000036, 287.50000000000017, 275.89999999999975, 169.39999999999938, 260.39999999999986, 228.19999999999962, 321.4999999999998, 241.19999999999976, 132.99999999999898, 263.1999999999996, 112.30000000000024, 83.50000000000011, 290.1999999999998, 271.9999999999993, 331.60000000000076, 271.2999999999996, 366.7000000000002, 287.4999999999998, 307.7000000000003, 221.79999999999978, 242.79999999999953, 278.20000000000044, 298.29999999999995, 161.29999999999995, 149.79999999999993, 224.09999999999982, 327.09999999999997, 352.20000000000005, 218.49999999999946, 280.60000000000014, 333.4000000000001, 311.89999999999986, 289.30000000000007, 347.8000000000001, 248.7999999999997, 328.9000000000008, 321.70000000000016, 343.3000000000005, 168.6999999999997, 321.7000000000002, 228.69999999999985, 346.700000000001], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [188.29999999999998, 80.00000000000003, 183.79999999999998, 67.09999999999988, 126.79999999999991, 104.59999999999972, 182.8999999999999, 140.59999999999997, 83.90000000000009, 139.39999999999992, 70.4000000000001, 90.1999999999999, 135.49999999999986, 98.29999999999984, 136.99999999999966, 92.0, 162.1999999999998, 150.4999999999997, 174.49999999999986, 61.39999999999996, 127.99999999999983, 118.09999999999994, 172.0999999999999, 180.19999999999996, 65.00000000000014, 61.400000000000055, 52.40000000000009, 91.10000000000001, 166.6999999999999, 126.20000000000003, 195.49999999999997, 138.79999999999987, 106.39999999999988, 147.8, 165.79999999999995, 104.6, 136.0999999999997, 86.60000000000007, 117.50000000000004, 126.19999999999982, 122.2999999999999, 126.79999999999991, 112.69999999999973, 160.7, 110.00000000000009, 156.7999999999999, 163.1, 151.69999999999987, 117.20000000000002, 126.19999999999999, 141.49999999999972, 72.80000000000015, 147.79999999999984, 82.99999999999997, 166.69999999999987, 138.7999999999996, 168.79999999999998, 173.89999999999998, 97.99999999999999, 115.39999999999998, 135.19999999999996, 150.2, 43.39999999999998, 92.00000000000009, 165.79999999999993, 103.69999999999993, 193.7, 145.09999999999994, 15.799999999999963, 131.59999999999985, 170.3, 85.70000000000006, 126.19999999999979, 171.19999999999982, 146.89999999999992, 161.29999999999998, 96.80000000000004, 184.69999999999996, 154.0999999999998, 74.89999999999968, 198.2, 66.80000000000007, 93.79999999999995, 157.6999999999998, 99.49999999999977, 159.19999999999987, 139.70000000000002, 161.29999999999995, 139.7, 144.79999999999998, 147.79999999999998, 104.59999999999982, 112.39999999999964, 153.19999999999996, 149.5999999999999, 77.5999999999998, 179.3, 86.2999999999998, 185.59999999999994, 120.79999999999983, 115.39999999999988, 115.39999999999972, 140.60000000000002, 131.60000000000002, 122.9, 175.7, 169.39999999999998, 126.19999999999992, 190.1, 159.4999999999998, 74.90000000000003, 162.20000000000005, 152.0, 131.6, 70.39999999999966, 153.5, 148.09999999999985, 163.99999999999977, 141.1999999999999, 131.29999999999987, 181.99999999999997, 89.8999999999999, 24.79999999999997, 134.59999999999982, 126.19999999999999, 129.20000000000005, 116.89999999999989, 98.30000000000001, 133.40000000000003, 172.0999999999999, 103.99999999999999, 135.19999999999985, 100.99999999999986, 20.000000000000014, 166.69999999999982, 96.49999999999994, 36.199999999999974, 73.10000000000011, 24.500000000000007, 55.99999999999998, 118.99999999999966, 171.19999999999987, 130.69999999999965, 140.29999999999984, 154.99999999999972, 176.5999999999999, 135.19999999999982, 136.09999999999988, 195.5, 171.19999999999985, 139.69999999999968, 147.7999999999997, 168.49999999999997, 132.19999999999985, 141.49999999999991, 80.30000000000001, 64.7000000000001, 166.09999999999997, 119.89999999999962, 152.29999999999993, 148.69999999999982, 149.5999999999998, 121.39999999999998, 26.900000000000126, 51.49999999999999, 98.29999999999998, 100.39999999999998, 121.6999999999998, 137.0, 190.10000000000002, 178.4, 159.79999999999995, 59.59999999999997, 155.89999999999984, 119.89999999999989, 145.70000000000002, 138.7999999999998, 194.6, 109.99999999999994, 191.89999999999998, 115.39999999999995, 173.8999999999999, 149.6, 198.2, 150.49999999999994, 98.30000000000003, 182.89999999999992, 145.9999999999998, 136.99999999999986, 184.6999999999999, 173.9, 169.3999999999998, 104.59999999999997, 49.1000000000001, 161.29999999999993, 160.39999999999995, 120.79999999999994, 101.8999999999999, 175.6999999999999, 169.99999999999986], "policy_predator_policy_reward": [13.0, 3.0, 11.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 11.0, 0.0, 18.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 3.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 13.0, 11.0, 7.0, 7.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 3.0, 10.0, 6.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 7.0, 0.0, 12.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 2.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 14.0, 15.0, 2.0, 3.0, 0.0, 0.0, 10.0, 3.0, 0.0, 0.0, 7.0, 0.0, 0.0, 27.0, 0.0, 1.0, 0.0, 0.0, 15.0, 13.0, 0.0, 0.0, 17.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13.0, 0.0, 8.0, 2.0, 2.0, 14.0, 1.0, 4.0, 0.0, 5.0, 5.0, 5.0, 0.0, 13.0, 0.0, 7.0, 9.0, 0.0, 2.0, 12.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 3.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 7.0, 5.0, 6.0, 0.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 6.0, 8.0, 0.0, 3.0, 0.0, 15.0, 0.0, 0.0, 5.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 15.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 11.314086805668142, "mean_inference_ms": 25.01397730518348, "mean_action_processing_ms": 5.523452552435947, "mean_env_wait_ms": 7.301853748863996, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005307316780090332, "StateBufferConnector_ms": 0.022911548614501953, "ViewRequirementAgentConnector_ms": 0.2161719799041748}, "num_episodes": 18, "episode_return_max": 366.7000000000002, "episode_return_min": 83.50000000000011, "episode_return_mean": 265.4979999999999, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1744000, "num_agent_steps_trained": 1744000, "num_env_steps_sampled": 436000, "num_env_steps_trained": 436000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 264.3255697893864, "num_env_steps_trained_throughput_per_sec": 264.3255697893864, "timesteps_total": 436000, "num_env_steps_sampled_lifetime": 436000, "num_agent_steps_sampled_lifetime": 1744000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1744000, "timers": {"training_iteration_time_ms": 277464.67, "restore_workers_time_ms": 0.028, "training_step_time_ms": 277464.587, "sample_time_ms": 3399.515, "learn_time_ms": 274034.17, "learn_throughput": 14.597, "synch_weights_time_ms": 21.039}, "counters": {"num_env_steps_sampled": 436000, "num_env_steps_trained": 436000, "num_agent_steps_sampled": 1744000, "num_agent_steps_trained": 1744000}, "done": false, "training_iteration": 109, "trial_id": "75ec3_00000", "date": "2024-08-13_03-54-53", "timestamp": 1723535693, "time_this_iter_s": 15.199596166610718, "time_total_s": 9344.867424488068, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b245ff70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 9344.867424488068, "iterations_since_restore": 109, "perf": {"cpu_util_percent": 80.00454545454545, "ram_util_percent": 79.82272727272729}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 8.367688926218678, "cur_kl_coeff": 0.27399271152389687, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.2915517431087595, "policy_loss": -0.0044799998929852215, "vf_loss": 6.292127438953945, "vf_explained_var": 0.5113093699412371, "kl": 0.014249681702135917, "entropy": 1.0312510844260927, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 206955.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6057158001181152, "cur_kl_coeff": 2.0328790734103204e-21, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.743118281213064, "policy_loss": -0.0004538896693182843, "vf_loss": 0.7435721709141656, "vf_explained_var": 0.011256828320720209, "kl": 0.0012263290882541186, "entropy": 0.21070685118594498, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 206955.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 440000, "num_env_steps_trained": 440000, "num_agent_steps_sampled": 1760000, "num_agent_steps_trained": 1760000}, "env_runners": {"episode_reward_max": 377.5000000000001, "episode_reward_min": 83.50000000000011, "episode_reward_mean": 277.62599999999986, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 7.399999999999965, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 199.1, "predator_policy": 27.0}, "policy_reward_mean": {"prey_policy": 135.93799999999993, "predator_policy": 2.875}, "custom_metrics": {}, "hist_stats": {"episode_reward": [326.79999999999984, 243.39999999999984, 227.2999999999993, 236.79999999999959, 305.50000000000006, 344.69999999999993, 214.39999999999975, 292.4000000000001, 147.39999999999964, 269.49999999999994, 344.79999999999995, 149.39999999999935, 264.9999999999998, 297.3999999999998, 308.2000000000003, 292.4999999999999, 228.99999999999932, 264.99999999999955, 280.5000000000008, 263.69999999999976, 300.9999999999999, 297.5000000000001, 252.3999999999998, 272.60000000000014, 254.1999999999997, 266.5999999999999, 306.3999999999996, 258.7999999999996, 272.20000000000005, 320.59999999999997, 295.60000000000036, 349.60000000000014, 237.0999999999996, 296.6, 231.89999999999952, 316.10000000000036, 287.50000000000017, 275.89999999999975, 169.39999999999938, 260.39999999999986, 228.19999999999962, 321.4999999999998, 241.19999999999976, 132.99999999999898, 263.1999999999996, 112.30000000000024, 83.50000000000011, 290.1999999999998, 271.9999999999993, 331.60000000000076, 271.2999999999996, 366.7000000000002, 287.4999999999998, 307.7000000000003, 221.79999999999978, 242.79999999999953, 278.20000000000044, 298.29999999999995, 161.29999999999995, 149.79999999999993, 224.09999999999982, 327.09999999999997, 352.20000000000005, 218.49999999999946, 280.60000000000014, 333.4000000000001, 311.89999999999986, 289.30000000000007, 347.8000000000001, 248.7999999999997, 328.9000000000008, 321.70000000000016, 343.3000000000005, 168.6999999999997, 321.7000000000002, 228.69999999999985, 346.700000000001, 308.29999999999995, 252.79999999999964, 275.89999999999964, 348.9, 312.5000000000001, 291.0, 333.60000000000014, 261.3999999999993, 325.2999999999999, 304.6, 344.00000000000045, 311.0999999999998, 327.09999999999997, 373.9, 305.9, 153.09999999999957, 278.30000000000007, 336.1000000000002, 360.8000000000003, 272.60000000000025, 326.19999999999993, 377.5000000000001, 300.09999999999985], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [163.1, 151.69999999999987, 117.20000000000002, 126.19999999999999, 141.49999999999972, 72.80000000000015, 147.79999999999984, 82.99999999999997, 166.69999999999987, 138.7999999999996, 168.79999999999998, 173.89999999999998, 97.99999999999999, 115.39999999999998, 135.19999999999996, 150.2, 43.39999999999998, 92.00000000000009, 165.79999999999993, 103.69999999999993, 193.7, 145.09999999999994, 15.799999999999963, 131.59999999999985, 170.3, 85.70000000000006, 126.19999999999979, 171.19999999999982, 146.89999999999992, 161.29999999999998, 96.80000000000004, 184.69999999999996, 154.0999999999998, 74.89999999999968, 198.2, 66.80000000000007, 93.79999999999995, 157.6999999999998, 99.49999999999977, 159.19999999999987, 139.70000000000002, 161.29999999999995, 139.7, 144.79999999999998, 147.79999999999998, 104.59999999999982, 112.39999999999964, 153.19999999999996, 149.5999999999999, 77.5999999999998, 179.3, 86.2999999999998, 185.59999999999994, 120.79999999999983, 115.39999999999988, 115.39999999999972, 140.60000000000002, 131.60000000000002, 122.9, 175.7, 169.39999999999998, 126.19999999999992, 190.1, 159.4999999999998, 74.90000000000003, 162.20000000000005, 152.0, 131.6, 70.39999999999966, 153.5, 148.09999999999985, 163.99999999999977, 141.1999999999999, 131.29999999999987, 181.99999999999997, 89.8999999999999, 24.79999999999997, 134.59999999999982, 126.19999999999999, 129.20000000000005, 116.89999999999989, 98.30000000000001, 133.40000000000003, 172.0999999999999, 103.99999999999999, 135.19999999999985, 100.99999999999986, 20.000000000000014, 166.69999999999982, 96.49999999999994, 36.199999999999974, 73.10000000000011, 24.500000000000007, 55.99999999999998, 118.99999999999966, 171.19999999999987, 130.69999999999965, 140.29999999999984, 154.99999999999972, 176.5999999999999, 135.19999999999982, 136.09999999999988, 195.5, 171.19999999999985, 139.69999999999968, 147.7999999999997, 168.49999999999997, 132.19999999999985, 141.49999999999991, 80.30000000000001, 64.7000000000001, 166.09999999999997, 119.89999999999962, 152.29999999999993, 148.69999999999982, 149.5999999999998, 121.39999999999998, 26.900000000000126, 51.49999999999999, 98.29999999999998, 100.39999999999998, 121.6999999999998, 137.0, 190.10000000000002, 178.4, 159.79999999999995, 59.59999999999997, 155.89999999999984, 119.89999999999989, 145.70000000000002, 138.7999999999998, 194.6, 109.99999999999994, 191.89999999999998, 115.39999999999995, 173.8999999999999, 149.6, 198.2, 150.49999999999994, 98.30000000000003, 182.89999999999992, 145.9999999999998, 136.99999999999986, 184.6999999999999, 173.9, 169.3999999999998, 104.59999999999997, 49.1000000000001, 161.29999999999993, 160.39999999999995, 120.79999999999994, 101.8999999999999, 175.6999999999999, 169.99999999999986, 184.70000000000002, 119.59999999999997, 82.09999999999982, 163.6999999999999, 181.1, 81.8000000000001, 187.4, 153.49999999999997, 174.79999999999993, 127.69999999999987, 147.79999999999995, 132.2, 158.5999999999998, 167.0, 99.2000000000001, 153.19999999999993, 167.5999999999999, 157.70000000000002, 179.2999999999999, 125.29999999999978, 142.39999999999986, 191.59999999999997, 149.9, 153.19999999999987, 157.99999999999986, 160.09999999999997, 186.49999999999997, 187.4, 139.7, 156.2, 139.7, 7.399999999999965, 155.60000000000002, 121.69999999999976, 169.39999999999986, 166.7, 146.29999999999993, 195.5, 115.09999999999977, 150.49999999999974, 118.1, 199.1, 189.19999999999993, 188.3, 106.40000000000003, 193.7], "policy_predator_policy_reward": [0.0, 12.0, 0.0, 0.0, 3.0, 10.0, 6.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 7.0, 0.0, 12.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 2.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 14.0, 15.0, 2.0, 3.0, 0.0, 0.0, 10.0, 3.0, 0.0, 0.0, 7.0, 0.0, 0.0, 27.0, 0.0, 1.0, 0.0, 0.0, 15.0, 13.0, 0.0, 0.0, 17.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13.0, 0.0, 8.0, 2.0, 2.0, 14.0, 1.0, 4.0, 0.0, 5.0, 5.0, 5.0, 0.0, 13.0, 0.0, 7.0, 9.0, 0.0, 2.0, 12.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 3.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 7.0, 5.0, 6.0, 0.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 6.0, 8.0, 0.0, 3.0, 0.0, 15.0, 0.0, 0.0, 5.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 15.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 1.0, 0.0, 4.0, 7.0, 0.0, 7.0, 6.0, 0.0, 8.0, 3.0, 7.0, 6.0, 5.0, 5.0, 3.0, 6.0, 3.0, 0.0, 0.0, 0.0, 0.0, 9.0, 1.0, 8.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 6.0, 0.0, 1.0, 0.0, 0.0, 8.0, 11.0, 4.0, 3.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 11.206994313415603, "mean_inference_ms": 24.76847157255742, "mean_action_processing_ms": 5.460306326277107, "mean_env_wait_ms": 7.242956536285406, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.009963035583496094, "StateBufferConnector_ms": 0.007361412048339844, "ViewRequirementAgentConnector_ms": 0.20354080200195312}, "num_episodes": 23, "episode_return_max": 377.5000000000001, "episode_return_min": 83.50000000000011, "episode_return_mean": 277.62599999999986, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1760000, "num_agent_steps_trained": 1760000, "num_env_steps_sampled": 440000, "num_env_steps_trained": 440000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 250.60463171803, "num_env_steps_trained_throughput_per_sec": 250.60463171803, "timesteps_total": 440000, "num_env_steps_sampled_lifetime": 440000, "num_agent_steps_sampled_lifetime": 1760000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1760000, "timers": {"training_iteration_time_ms": 275759.968, "restore_workers_time_ms": 0.028, "training_step_time_ms": 275759.885, "sample_time_ms": 3215.225, "learn_time_ms": 272514.485, "learn_throughput": 14.678, "synch_weights_time_ms": 20.012}, "counters": {"num_env_steps_sampled": 440000, "num_env_steps_trained": 440000, "num_agent_steps_sampled": 1760000, "num_agent_steps_trained": 1760000}, "done": false, "training_iteration": 110, "trial_id": "75ec3_00000", "date": "2024-08-13_03-55-09", "timestamp": 1723535709, "time_this_iter_s": 16.022810220718384, "time_total_s": 9360.890234708786, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b223a8b0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 9360.890234708786, "iterations_since_restore": 110, "perf": {"cpu_util_percent": 79.19090909090909, "ram_util_percent": 80.02272727272727}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 10.528163179424073, "cur_kl_coeff": 0.27399271152389687, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.691365911847069, "policy_loss": -0.013109409333226425, "vf_loss": 7.700559120581894, "vf_explained_var": 0.33568870882508617, "kl": 0.014293003508190289, "entropy": 1.05268828818407, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 208845.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.31587702519009037, "cur_kl_coeff": 1.0164395367051602e-21, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.18214510511311274, "policy_loss": 5.6227829267896675e-06, "vf_loss": 0.18213948218679182, "vf_explained_var": 0.0019594585454022445, "kl": 0.0014033569442683433, "entropy": 0.26420752807426706, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 208845.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 444000, "num_env_steps_trained": 444000, "num_agent_steps_sampled": 1776000, "num_agent_steps_trained": 1776000}, "env_runners": {"episode_reward_max": 377.5000000000001, "episode_reward_min": 83.50000000000011, "episode_reward_mean": 276.92499999999995, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 7.399999999999965, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 199.1, "predator_policy": 27.0}, "policy_reward_mean": {"prey_policy": 135.32749999999993, "predator_policy": 3.135}, "custom_metrics": {}, "hist_stats": {"episode_reward": [280.5000000000008, 263.69999999999976, 300.9999999999999, 297.5000000000001, 252.3999999999998, 272.60000000000014, 254.1999999999997, 266.5999999999999, 306.3999999999996, 258.7999999999996, 272.20000000000005, 320.59999999999997, 295.60000000000036, 349.60000000000014, 237.0999999999996, 296.6, 231.89999999999952, 316.10000000000036, 287.50000000000017, 275.89999999999975, 169.39999999999938, 260.39999999999986, 228.19999999999962, 321.4999999999998, 241.19999999999976, 132.99999999999898, 263.1999999999996, 112.30000000000024, 83.50000000000011, 290.1999999999998, 271.9999999999993, 331.60000000000076, 271.2999999999996, 366.7000000000002, 287.4999999999998, 307.7000000000003, 221.79999999999978, 242.79999999999953, 278.20000000000044, 298.29999999999995, 161.29999999999995, 149.79999999999993, 224.09999999999982, 327.09999999999997, 352.20000000000005, 218.49999999999946, 280.60000000000014, 333.4000000000001, 311.89999999999986, 289.30000000000007, 347.8000000000001, 248.7999999999997, 328.9000000000008, 321.70000000000016, 343.3000000000005, 168.6999999999997, 321.7000000000002, 228.69999999999985, 346.700000000001, 308.29999999999995, 252.79999999999964, 275.89999999999964, 348.9, 312.5000000000001, 291.0, 333.60000000000014, 261.3999999999993, 325.2999999999999, 304.6, 344.00000000000045, 311.0999999999998, 327.09999999999997, 373.9, 305.9, 153.09999999999957, 278.30000000000007, 336.1000000000002, 360.8000000000003, 272.60000000000025, 326.19999999999993, 377.5000000000001, 300.09999999999985, 317.8999999999995, 262.49999999999955, 245.79999999999944, 198.79999999999947, 369.40000000000003, 283.9000000000001, 369.4000000000002, 282.4999999999997, 233.49999999999937, 254.69999999999973, 242.89999999999918, 283.2999999999997, 143.49999999999997, 263.29999999999984, 307.5000000000004, 247.89999999999952, 119.39999999999989, 263.1999999999996], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [93.79999999999995, 157.6999999999998, 99.49999999999977, 159.19999999999987, 139.70000000000002, 161.29999999999995, 139.7, 144.79999999999998, 147.79999999999998, 104.59999999999982, 112.39999999999964, 153.19999999999996, 149.5999999999999, 77.5999999999998, 179.3, 86.2999999999998, 185.59999999999994, 120.79999999999983, 115.39999999999988, 115.39999999999972, 140.60000000000002, 131.60000000000002, 122.9, 175.7, 169.39999999999998, 126.19999999999992, 190.1, 159.4999999999998, 74.90000000000003, 162.20000000000005, 152.0, 131.6, 70.39999999999966, 153.5, 148.09999999999985, 163.99999999999977, 141.1999999999999, 131.29999999999987, 181.99999999999997, 89.8999999999999, 24.79999999999997, 134.59999999999982, 126.19999999999999, 129.20000000000005, 116.89999999999989, 98.30000000000001, 133.40000000000003, 172.0999999999999, 103.99999999999999, 135.19999999999985, 100.99999999999986, 20.000000000000014, 166.69999999999982, 96.49999999999994, 36.199999999999974, 73.10000000000011, 24.500000000000007, 55.99999999999998, 118.99999999999966, 171.19999999999987, 130.69999999999965, 140.29999999999984, 154.99999999999972, 176.5999999999999, 135.19999999999982, 136.09999999999988, 195.5, 171.19999999999985, 139.69999999999968, 147.7999999999997, 168.49999999999997, 132.19999999999985, 141.49999999999991, 80.30000000000001, 64.7000000000001, 166.09999999999997, 119.89999999999962, 152.29999999999993, 148.69999999999982, 149.5999999999998, 121.39999999999998, 26.900000000000126, 51.49999999999999, 98.29999999999998, 100.39999999999998, 121.6999999999998, 137.0, 190.10000000000002, 178.4, 159.79999999999995, 59.59999999999997, 155.89999999999984, 119.89999999999989, 145.70000000000002, 138.7999999999998, 194.6, 109.99999999999994, 191.89999999999998, 115.39999999999995, 173.8999999999999, 149.6, 198.2, 150.49999999999994, 98.30000000000003, 182.89999999999992, 145.9999999999998, 136.99999999999986, 184.6999999999999, 173.9, 169.3999999999998, 104.59999999999997, 49.1000000000001, 161.29999999999993, 160.39999999999995, 120.79999999999994, 101.8999999999999, 175.6999999999999, 169.99999999999986, 184.70000000000002, 119.59999999999997, 82.09999999999982, 163.6999999999999, 181.1, 81.8000000000001, 187.4, 153.49999999999997, 174.79999999999993, 127.69999999999987, 147.79999999999995, 132.2, 158.5999999999998, 167.0, 99.2000000000001, 153.19999999999993, 167.5999999999999, 157.70000000000002, 179.2999999999999, 125.29999999999978, 142.39999999999986, 191.59999999999997, 149.9, 153.19999999999987, 157.99999999999986, 160.09999999999997, 186.49999999999997, 187.4, 139.7, 156.2, 139.7, 7.399999999999965, 155.60000000000002, 121.69999999999976, 169.39999999999986, 166.7, 146.29999999999993, 195.5, 115.09999999999977, 150.49999999999974, 118.1, 199.1, 189.19999999999993, 188.3, 106.40000000000003, 193.7, 186.19999999999996, 130.69999999999965, 133.99999999999994, 108.49999999999966, 110.89999999999972, 122.89999999999975, 119.59999999999987, 72.2000000000001, 179.29999999999998, 190.09999999999994, 126.19999999999975, 157.69999999999987, 175.69999999999996, 193.7, 107.89999999999999, 158.6, 102.79999999999977, 130.69999999999982, 142.39999999999986, 101.29999999999995, 73.69999999999997, 162.1999999999998, 160.3999999999999, 119.8999999999995, 63.19999999999997, 80.29999999999998, 79.10000000000004, 180.19999999999993, 167.5999999999999, 125.89999999999998, 97.39999999999978, 150.49999999999983, 43.400000000000134, 37.999999999999986, 85.69999999999996, 177.49999999999991], "policy_predator_policy_reward": [14.0, 15.0, 2.0, 3.0, 0.0, 0.0, 10.0, 3.0, 0.0, 0.0, 7.0, 0.0, 0.0, 27.0, 0.0, 1.0, 0.0, 0.0, 15.0, 13.0, 0.0, 0.0, 17.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13.0, 0.0, 8.0, 2.0, 2.0, 14.0, 1.0, 4.0, 0.0, 5.0, 5.0, 5.0, 0.0, 13.0, 0.0, 7.0, 9.0, 0.0, 2.0, 12.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 3.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 7.0, 5.0, 6.0, 0.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 6.0, 8.0, 0.0, 3.0, 0.0, 15.0, 0.0, 0.0, 5.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 15.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 1.0, 0.0, 4.0, 7.0, 0.0, 7.0, 6.0, 0.0, 8.0, 3.0, 7.0, 6.0, 5.0, 5.0, 3.0, 6.0, 3.0, 0.0, 0.0, 0.0, 0.0, 9.0, 1.0, 8.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 6.0, 0.0, 1.0, 0.0, 0.0, 8.0, 11.0, 4.0, 3.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 6.0, 14.0, 8.0, 4.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 10.0, 0.0, 0.0, 0.0, 11.0, 7.0, 0.0, 3.0, 0.0, 0.0, 0.0, 4.0, 0.0, 1.0, 13.0, 0.0, 0.0, 17.0, 21.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 11.123036941713826, "mean_inference_ms": 24.589219853452597, "mean_action_processing_ms": 5.418210692450518, "mean_env_wait_ms": 7.185886436348526, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.009923696517944336, "StateBufferConnector_ms": 0.0072667598724365234, "ViewRequirementAgentConnector_ms": 0.18165647983551025}, "num_episodes": 18, "episode_return_max": 377.5000000000001, "episode_return_min": 83.50000000000011, "episode_return_mean": 276.92499999999995, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1776000, "num_agent_steps_trained": 1776000, "num_env_steps_sampled": 444000, "num_env_steps_trained": 444000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 237.1808758759124, "num_env_steps_trained_throughput_per_sec": 237.1808758759124, "timesteps_total": 444000, "num_env_steps_sampled_lifetime": 444000, "num_agent_steps_sampled_lifetime": 1776000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1776000, "timers": {"training_iteration_time_ms": 274022.256, "restore_workers_time_ms": 0.018, "training_step_time_ms": 274022.194, "sample_time_ms": 3056.552, "learn_time_ms": 270935.181, "learn_throughput": 14.764, "synch_weights_time_ms": 20.176}, "counters": {"num_env_steps_sampled": 444000, "num_env_steps_trained": 444000, "num_agent_steps_sampled": 1776000, "num_agent_steps_trained": 1776000}, "done": false, "training_iteration": 111, "trial_id": "75ec3_00000", "date": "2024-08-13_03-55-26", "timestamp": 1723535726, "time_this_iter_s": 16.957584857940674, "time_total_s": 9377.847819566727, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b221c700>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 9377.847819566727, "iterations_since_restore": 111, "perf": {"cpu_util_percent": 79.75, "ram_util_percent": 80.06666666666666}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 8.000134182638591, "cur_kl_coeff": 0.27399271152389687, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.401699385945759, "policy_loss": -0.0042870207325057695, "vf_loss": 5.404707275244294, "vf_explained_var": 0.3872941670594392, "kl": 0.004668482572743393, "entropy": 1.0342512544500764, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 210735.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.24880009715164464, "cur_kl_coeff": 5.082197683525801e-22, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.21387115390133604, "policy_loss": -0.0005958039106594192, "vf_loss": 0.21446695767155793, "vf_explained_var": 0.09874291542976621, "kl": 0.0024597883301487955, "entropy": 0.20026505754265206, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 210735.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 448000, "num_env_steps_trained": 448000, "num_agent_steps_sampled": 1792000, "num_agent_steps_trained": 1792000}, "env_runners": {"episode_reward_max": 397.29999999999995, "episode_reward_min": 83.50000000000011, "episode_reward_mean": 282.91599999999994, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 7.399999999999965, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 21.0}, "policy_reward_mean": {"prey_policy": 138.69799999999992, "predator_policy": 2.76}, "custom_metrics": {}, "hist_stats": {"episode_reward": [228.19999999999962, 321.4999999999998, 241.19999999999976, 132.99999999999898, 263.1999999999996, 112.30000000000024, 83.50000000000011, 290.1999999999998, 271.9999999999993, 331.60000000000076, 271.2999999999996, 366.7000000000002, 287.4999999999998, 307.7000000000003, 221.79999999999978, 242.79999999999953, 278.20000000000044, 298.29999999999995, 161.29999999999995, 149.79999999999993, 224.09999999999982, 327.09999999999997, 352.20000000000005, 218.49999999999946, 280.60000000000014, 333.4000000000001, 311.89999999999986, 289.30000000000007, 347.8000000000001, 248.7999999999997, 328.9000000000008, 321.70000000000016, 343.3000000000005, 168.6999999999997, 321.7000000000002, 228.69999999999985, 346.700000000001, 308.29999999999995, 252.79999999999964, 275.89999999999964, 348.9, 312.5000000000001, 291.0, 333.60000000000014, 261.3999999999993, 325.2999999999999, 304.6, 344.00000000000045, 311.0999999999998, 327.09999999999997, 373.9, 305.9, 153.09999999999957, 278.30000000000007, 336.1000000000002, 360.8000000000003, 272.60000000000025, 326.19999999999993, 377.5000000000001, 300.09999999999985, 317.8999999999995, 262.49999999999955, 245.79999999999944, 198.79999999999947, 369.40000000000003, 283.9000000000001, 369.4000000000002, 282.4999999999997, 233.49999999999937, 254.69999999999973, 242.89999999999918, 283.2999999999997, 143.49999999999997, 263.29999999999984, 307.5000000000004, 247.89999999999952, 119.39999999999989, 263.1999999999996, 304.6000000000001, 289.49999999999966, 397.29999999999995, 241.79999999999993, 283.8999999999999, 362.20000000000005, 317.2000000000004, 278.89999999999964, 302.1, 333.4000000000002, 252.89999999999986, 314.1000000000003, 183.1, 299.2, 291.29999999999984, 289.3000000000002, 265.19999999999993, 363.50000000000045, 280.1999999999998, 333.90000000000003, 307.29999999999984, 374.8000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [116.89999999999989, 98.30000000000001, 133.40000000000003, 172.0999999999999, 103.99999999999999, 135.19999999999985, 100.99999999999986, 20.000000000000014, 166.69999999999982, 96.49999999999994, 36.199999999999974, 73.10000000000011, 24.500000000000007, 55.99999999999998, 118.99999999999966, 171.19999999999987, 130.69999999999965, 140.29999999999984, 154.99999999999972, 176.5999999999999, 135.19999999999982, 136.09999999999988, 195.5, 171.19999999999985, 139.69999999999968, 147.7999999999997, 168.49999999999997, 132.19999999999985, 141.49999999999991, 80.30000000000001, 64.7000000000001, 166.09999999999997, 119.89999999999962, 152.29999999999993, 148.69999999999982, 149.5999999999998, 121.39999999999998, 26.900000000000126, 51.49999999999999, 98.29999999999998, 100.39999999999998, 121.6999999999998, 137.0, 190.10000000000002, 178.4, 159.79999999999995, 59.59999999999997, 155.89999999999984, 119.89999999999989, 145.70000000000002, 138.7999999999998, 194.6, 109.99999999999994, 191.89999999999998, 115.39999999999995, 173.8999999999999, 149.6, 198.2, 150.49999999999994, 98.30000000000003, 182.89999999999992, 145.9999999999998, 136.99999999999986, 184.6999999999999, 173.9, 169.3999999999998, 104.59999999999997, 49.1000000000001, 161.29999999999993, 160.39999999999995, 120.79999999999994, 101.8999999999999, 175.6999999999999, 169.99999999999986, 184.70000000000002, 119.59999999999997, 82.09999999999982, 163.6999999999999, 181.1, 81.8000000000001, 187.4, 153.49999999999997, 174.79999999999993, 127.69999999999987, 147.79999999999995, 132.2, 158.5999999999998, 167.0, 99.2000000000001, 153.19999999999993, 167.5999999999999, 157.70000000000002, 179.2999999999999, 125.29999999999978, 142.39999999999986, 191.59999999999997, 149.9, 153.19999999999987, 157.99999999999986, 160.09999999999997, 186.49999999999997, 187.4, 139.7, 156.2, 139.7, 7.399999999999965, 155.60000000000002, 121.69999999999976, 169.39999999999986, 166.7, 146.29999999999993, 195.5, 115.09999999999977, 150.49999999999974, 118.1, 199.1, 189.19999999999993, 188.3, 106.40000000000003, 193.7, 186.19999999999996, 130.69999999999965, 133.99999999999994, 108.49999999999966, 110.89999999999972, 122.89999999999975, 119.59999999999987, 72.2000000000001, 179.29999999999998, 190.09999999999994, 126.19999999999975, 157.69999999999987, 175.69999999999996, 193.7, 107.89999999999999, 158.6, 102.79999999999977, 130.69999999999982, 142.39999999999986, 101.29999999999995, 73.69999999999997, 162.1999999999998, 160.3999999999999, 119.8999999999995, 63.19999999999997, 80.29999999999998, 79.10000000000004, 180.19999999999993, 167.5999999999999, 125.89999999999998, 97.39999999999978, 150.49999999999983, 43.400000000000134, 37.999999999999986, 85.69999999999996, 177.49999999999991, 132.49999999999994, 163.09999999999997, 176.0, 105.50000000000006, 197.3, 200.0, 110.29999999999993, 123.50000000000006, 137.89999999999984, 145.99999999999994, 187.39999999999998, 174.79999999999998, 141.4999999999998, 175.69999999999996, 120.80000000000007, 151.09999999999994, 151.69999999999987, 142.40000000000003, 145.09999999999997, 188.29999999999993, 114.79999999999994, 118.1000000000001, 152.5999999999999, 150.49999999999994, 72.20000000000016, 110.90000000000003, 167.59999999999985, 131.59999999999974, 104.89999999999988, 178.39999999999995, 139.70000000000002, 149.5999999999999, 146.29999999999998, 110.89999999999996, 197.29999999999998, 159.19999999999987, 92.00000000000006, 183.2, 129.5, 187.39999999999992, 152.29999999999995, 155.00000000000003, 187.39999999999995, 187.39999999999998], "policy_predator_policy_reward": [13.0, 0.0, 7.0, 9.0, 0.0, 2.0, 12.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 3.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 7.0, 5.0, 6.0, 0.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 6.0, 8.0, 0.0, 3.0, 0.0, 15.0, 0.0, 0.0, 5.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 15.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 1.0, 0.0, 4.0, 7.0, 0.0, 7.0, 6.0, 0.0, 8.0, 3.0, 7.0, 6.0, 5.0, 5.0, 3.0, 6.0, 3.0, 0.0, 0.0, 0.0, 0.0, 9.0, 1.0, 8.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 6.0, 0.0, 1.0, 0.0, 0.0, 8.0, 11.0, 4.0, 3.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 6.0, 14.0, 8.0, 4.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 10.0, 0.0, 0.0, 0.0, 11.0, 7.0, 0.0, 3.0, 0.0, 0.0, 0.0, 4.0, 0.0, 1.0, 13.0, 0.0, 0.0, 17.0, 21.0, 0.0, 0.0, 3.0, 6.0, 0.0, 8.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 8.0, 0.0, 0.0, 0.0, 9.0, 11.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 8.0, 0.0, 0.0, 7.0, 0.0, 5.0, 4.0, 13.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 11.035823169609412, "mean_inference_ms": 24.416199882316114, "mean_action_processing_ms": 5.380753735489011, "mean_env_wait_ms": 7.107706439567169, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019018173217773438, "StateBufferConnector_ms": 0.013686180114746094, "ViewRequirementAgentConnector_ms": 0.4213021993637085}, "num_episodes": 22, "episode_return_max": 397.29999999999995, "episode_return_min": 83.50000000000011, "episode_return_mean": 282.91599999999994, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1792000, "num_agent_steps_trained": 1792000, "num_env_steps_sampled": 448000, "num_env_steps_trained": 448000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 86.22229196982668, "num_env_steps_trained_throughput_per_sec": 86.22229196982668, "timesteps_total": 448000, "num_env_steps_sampled_lifetime": 448000, "num_agent_steps_sampled_lifetime": 1792000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1792000, "timers": {"training_iteration_time_ms": 217583.183, "restore_workers_time_ms": 2.253, "training_step_time_ms": 217577.779, "sample_time_ms": 4336.213, "learn_time_ms": 213204.381, "learn_throughput": 18.761, "synch_weights_time_ms": 25.601}, "counters": {"num_env_steps_sampled": 448000, "num_env_steps_trained": 448000, "num_agent_steps_sampled": 1792000, "num_agent_steps_trained": 1792000}, "done": false, "training_iteration": 112, "trial_id": "75ec3_00000", "date": "2024-08-13_04-11-14", "timestamp": 1723536674, "time_this_iter_s": 46.78243708610535, "time_total_s": 9424.630256652832, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b206b5e0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 9424.630256652832, "iterations_since_restore": 112, "perf": {"cpu_util_percent": 87.16268656716417, "ram_util_percent": 84.4955223880597}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 8.374455622485074, "cur_kl_coeff": 0.13699635576194844, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.993448419419546, "policy_loss": -0.00035875016163108213, "vf_loss": 4.9925035271064315, "vf_explained_var": 0.41728512679458296, "kl": 0.009515953435483879, "entropy": 1.0393741062709263, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 212625.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.32795372422311514, "cur_kl_coeff": 2.5410988417629005e-22, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.21403927391680774, "policy_loss": -0.00017640786886057526, "vf_loss": 0.21421568131606494, "vf_explained_var": 0.03360929277838853, "kl": 0.0015173918697903215, "entropy": 0.1841145493917995, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 212625.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 452000, "num_env_steps_trained": 452000, "num_agent_steps_sampled": 1808000, "num_agent_steps_trained": 1808000}, "env_runners": {"episode_reward_max": 397.29999999999995, "episode_reward_min": 119.39999999999989, "episode_reward_mean": 296.06299999999993, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 7.399999999999965, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 21.0}, "policy_reward_mean": {"prey_policy": 145.04149999999993, "predator_policy": 2.99}, "custom_metrics": {}, "hist_stats": {"episode_reward": [161.29999999999995, 149.79999999999993, 224.09999999999982, 327.09999999999997, 352.20000000000005, 218.49999999999946, 280.60000000000014, 333.4000000000001, 311.89999999999986, 289.30000000000007, 347.8000000000001, 248.7999999999997, 328.9000000000008, 321.70000000000016, 343.3000000000005, 168.6999999999997, 321.7000000000002, 228.69999999999985, 346.700000000001, 308.29999999999995, 252.79999999999964, 275.89999999999964, 348.9, 312.5000000000001, 291.0, 333.60000000000014, 261.3999999999993, 325.2999999999999, 304.6, 344.00000000000045, 311.0999999999998, 327.09999999999997, 373.9, 305.9, 153.09999999999957, 278.30000000000007, 336.1000000000002, 360.8000000000003, 272.60000000000025, 326.19999999999993, 377.5000000000001, 300.09999999999985, 317.8999999999995, 262.49999999999955, 245.79999999999944, 198.79999999999947, 369.40000000000003, 283.9000000000001, 369.4000000000002, 282.4999999999997, 233.49999999999937, 254.69999999999973, 242.89999999999918, 283.2999999999997, 143.49999999999997, 263.29999999999984, 307.5000000000004, 247.89999999999952, 119.39999999999989, 263.1999999999996, 304.6000000000001, 289.49999999999966, 397.29999999999995, 241.79999999999993, 283.8999999999999, 362.20000000000005, 317.2000000000004, 278.89999999999964, 302.1, 333.4000000000002, 252.89999999999986, 314.1000000000003, 183.1, 299.2, 291.29999999999984, 289.3000000000002, 265.19999999999993, 363.50000000000045, 280.1999999999998, 333.90000000000003, 307.29999999999984, 374.8000000000003, 262.9999999999999, 287.5000000000001, 348.5999999999999, 349.2, 252.3999999999996, 376.30000000000007, 324.39999999999986, 331.59999999999997, 363.5999999999998, 328.90000000000055, 351.1, 239.7999999999994, 338.5000000000001, 356.79999999999995, 344.29999999999995, 343.2999999999999, 371.3, 295.0999999999998], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [121.39999999999998, 26.900000000000126, 51.49999999999999, 98.29999999999998, 100.39999999999998, 121.6999999999998, 137.0, 190.10000000000002, 178.4, 159.79999999999995, 59.59999999999997, 155.89999999999984, 119.89999999999989, 145.70000000000002, 138.7999999999998, 194.6, 109.99999999999994, 191.89999999999998, 115.39999999999995, 173.8999999999999, 149.6, 198.2, 150.49999999999994, 98.30000000000003, 182.89999999999992, 145.9999999999998, 136.99999999999986, 184.6999999999999, 173.9, 169.3999999999998, 104.59999999999997, 49.1000000000001, 161.29999999999993, 160.39999999999995, 120.79999999999994, 101.8999999999999, 175.6999999999999, 169.99999999999986, 184.70000000000002, 119.59999999999997, 82.09999999999982, 163.6999999999999, 181.1, 81.8000000000001, 187.4, 153.49999999999997, 174.79999999999993, 127.69999999999987, 147.79999999999995, 132.2, 158.5999999999998, 167.0, 99.2000000000001, 153.19999999999993, 167.5999999999999, 157.70000000000002, 179.2999999999999, 125.29999999999978, 142.39999999999986, 191.59999999999997, 149.9, 153.19999999999987, 157.99999999999986, 160.09999999999997, 186.49999999999997, 187.4, 139.7, 156.2, 139.7, 7.399999999999965, 155.60000000000002, 121.69999999999976, 169.39999999999986, 166.7, 146.29999999999993, 195.5, 115.09999999999977, 150.49999999999974, 118.1, 199.1, 189.19999999999993, 188.3, 106.40000000000003, 193.7, 186.19999999999996, 130.69999999999965, 133.99999999999994, 108.49999999999966, 110.89999999999972, 122.89999999999975, 119.59999999999987, 72.2000000000001, 179.29999999999998, 190.09999999999994, 126.19999999999975, 157.69999999999987, 175.69999999999996, 193.7, 107.89999999999999, 158.6, 102.79999999999977, 130.69999999999982, 142.39999999999986, 101.29999999999995, 73.69999999999997, 162.1999999999998, 160.3999999999999, 119.8999999999995, 63.19999999999997, 80.29999999999998, 79.10000000000004, 180.19999999999993, 167.5999999999999, 125.89999999999998, 97.39999999999978, 150.49999999999983, 43.400000000000134, 37.999999999999986, 85.69999999999996, 177.49999999999991, 132.49999999999994, 163.09999999999997, 176.0, 105.50000000000006, 197.3, 200.0, 110.29999999999993, 123.50000000000006, 137.89999999999984, 145.99999999999994, 187.39999999999998, 174.79999999999998, 141.4999999999998, 175.69999999999996, 120.80000000000007, 151.09999999999994, 151.69999999999987, 142.40000000000003, 145.09999999999997, 188.29999999999993, 114.79999999999994, 118.1000000000001, 152.5999999999999, 150.49999999999994, 72.20000000000016, 110.90000000000003, 167.59999999999985, 131.59999999999974, 104.89999999999988, 178.39999999999995, 139.70000000000002, 149.5999999999999, 146.29999999999998, 110.89999999999996, 197.29999999999998, 159.19999999999987, 92.00000000000006, 183.2, 129.5, 187.39999999999992, 152.29999999999995, 155.00000000000003, 187.39999999999995, 187.39999999999998, 179.29999999999995, 82.69999999999985, 116.29999999999994, 162.19999999999996, 168.5, 163.09999999999994, 149.0, 180.2, 185.6, 66.7999999999999, 191.0, 179.29999999999998, 130.7, 193.7, 170.0, 149.6, 171.19999999999982, 190.39999999999998, 168.5, 160.39999999999984, 157.39999999999995, 178.7, 66.79999999999995, 172.99999999999994, 166.69999999999996, 165.79999999999998, 193.7, 154.09999999999997, 188.3, 143.00000000000003, 163.99999999999994, 179.29999999999998, 194.6, 172.7, 173.3, 114.79999999999995], "policy_predator_policy_reward": [13.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 6.0, 8.0, 0.0, 3.0, 0.0, 15.0, 0.0, 0.0, 5.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 15.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 1.0, 0.0, 4.0, 7.0, 0.0, 7.0, 6.0, 0.0, 8.0, 3.0, 7.0, 6.0, 5.0, 5.0, 3.0, 6.0, 3.0, 0.0, 0.0, 0.0, 0.0, 9.0, 1.0, 8.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 6.0, 0.0, 1.0, 0.0, 0.0, 8.0, 11.0, 4.0, 3.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 6.0, 14.0, 8.0, 4.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 10.0, 0.0, 0.0, 0.0, 11.0, 7.0, 0.0, 3.0, 0.0, 0.0, 0.0, 4.0, 0.0, 1.0, 13.0, 0.0, 0.0, 17.0, 21.0, 0.0, 0.0, 3.0, 6.0, 0.0, 8.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 8.0, 0.0, 0.0, 0.0, 9.0, 11.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 8.0, 0.0, 0.0, 7.0, 0.0, 5.0, 4.0, 13.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 9.0, 0.0, 0.0, 17.0, 0.0, 20.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 2.0, 0.0, 0.0, 15.0, 0.0, 0.0, 0.0, 1.0, 5.0, 0.0, 9.0, 13.0, 0.0, 0.0, 0.0, 3.0, 1.0, 0.0, 7.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 10.968453062597955, "mean_inference_ms": 24.272373369041134, "mean_action_processing_ms": 5.3443458144503975, "mean_env_wait_ms": 7.057440965129551, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.02384352684020996, "StateBufferConnector_ms": 0.013742566108703613, "ViewRequirementAgentConnector_ms": 0.4514256715774536}, "num_episodes": 18, "episode_return_max": 397.29999999999995, "episode_return_min": 119.39999999999989, "episode_return_mean": 296.06299999999993, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1808000, "num_agent_steps_trained": 1808000, "num_env_steps_sampled": 452000, "num_env_steps_trained": 452000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 219.9253844213979, "num_env_steps_trained_throughput_per_sec": 219.9253844213979, "timesteps_total": 452000, "num_env_steps_sampled_lifetime": 452000, "num_agent_steps_sampled_lifetime": 1808000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1808000, "timers": {"training_iteration_time_ms": 217431.512, "restore_workers_time_ms": 2.253, "training_step_time_ms": 217426.108, "sample_time_ms": 4260.369, "learn_time_ms": 213128.841, "learn_throughput": 18.768, "synch_weights_time_ms": 25.152}, "counters": {"num_env_steps_sampled": 452000, "num_env_steps_trained": 452000, "num_agent_steps_sampled": 1808000, "num_agent_steps_trained": 1808000}, "done": false, "training_iteration": 113, "trial_id": "75ec3_00000", "date": "2024-08-13_04-26-50", "timestamp": 1723537610, "time_this_iter_s": 936.3818690776825, "time_total_s": 10361.012125730515, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b23df9d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 10361.012125730515, "iterations_since_restore": 113, "perf": {"cpu_util_percent": 88.5622641509434, "ram_util_percent": 85.13962264150945}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 7.850571606461964, "cur_kl_coeff": 0.13699635576194844, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.306026202408725, "policy_loss": -0.014481756133249118, "vf_loss": 7.317171908938696, "vf_explained_var": 0.16206283033209504, "kl": 0.02435141819595776, "entropy": 1.039156698360645, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 214515.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7351507326440205, "cur_kl_coeff": 1.2705494208814502e-22, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.8466856982972888, "policy_loss": -0.00018480224399359296, "vf_loss": 1.8468705025614884, "vf_explained_var": 0.022287825585673094, "kl": 0.0011301563039564206, "entropy": 0.17039187611647383, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 214515.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 456000, "num_env_steps_trained": 456000, "num_agent_steps_sampled": 1824000, "num_agent_steps_trained": 1824000}, "env_runners": {"episode_reward_max": 397.29999999999995, "episode_reward_min": 119.39999999999989, "episode_reward_mean": 294.3349999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 7.399999999999965, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 28.0}, "policy_reward_mean": {"prey_policy": 143.42749999999992, "predator_policy": 3.74}, "custom_metrics": {}, "hist_stats": {"episode_reward": [312.5000000000001, 291.0, 333.60000000000014, 261.3999999999993, 325.2999999999999, 304.6, 344.00000000000045, 311.0999999999998, 327.09999999999997, 373.9, 305.9, 153.09999999999957, 278.30000000000007, 336.1000000000002, 360.8000000000003, 272.60000000000025, 326.19999999999993, 377.5000000000001, 300.09999999999985, 317.8999999999995, 262.49999999999955, 245.79999999999944, 198.79999999999947, 369.40000000000003, 283.9000000000001, 369.4000000000002, 282.4999999999997, 233.49999999999937, 254.69999999999973, 242.89999999999918, 283.2999999999997, 143.49999999999997, 263.29999999999984, 307.5000000000004, 247.89999999999952, 119.39999999999989, 263.1999999999996, 304.6000000000001, 289.49999999999966, 397.29999999999995, 241.79999999999993, 283.8999999999999, 362.20000000000005, 317.2000000000004, 278.89999999999964, 302.1, 333.4000000000002, 252.89999999999986, 314.1000000000003, 183.1, 299.2, 291.29999999999984, 289.3000000000002, 265.19999999999993, 363.50000000000045, 280.1999999999998, 333.90000000000003, 307.29999999999984, 374.8000000000003, 262.9999999999999, 287.5000000000001, 348.5999999999999, 349.2, 252.3999999999996, 376.30000000000007, 324.39999999999986, 331.59999999999997, 363.5999999999998, 328.90000000000055, 351.1, 239.7999999999994, 338.5000000000001, 356.79999999999995, 344.29999999999995, 343.2999999999999, 371.3, 295.0999999999998, 281.1000000000002, 273.0999999999999, 317.20000000000033, 254.29999999999947, 359.3000000000002, 315.8999999999999, 195.39999999999947, 217.59999999999943, 269.29999999999995, 274.59999999999974, 282.8000000000003, 336.6999999999998, 277.3999999999999, 209.29999999999933, 355.00000000000045, 214.39999999999975, 293.8, 341.5999999999998, 161.79999999999964, 228.49999999999943, 354.8, 233.79999999999953, 269.89999999999975], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [174.79999999999993, 127.69999999999987, 147.79999999999995, 132.2, 158.5999999999998, 167.0, 99.2000000000001, 153.19999999999993, 167.5999999999999, 157.70000000000002, 179.2999999999999, 125.29999999999978, 142.39999999999986, 191.59999999999997, 149.9, 153.19999999999987, 157.99999999999986, 160.09999999999997, 186.49999999999997, 187.4, 139.7, 156.2, 139.7, 7.399999999999965, 155.60000000000002, 121.69999999999976, 169.39999999999986, 166.7, 146.29999999999993, 195.5, 115.09999999999977, 150.49999999999974, 118.1, 199.1, 189.19999999999993, 188.3, 106.40000000000003, 193.7, 186.19999999999996, 130.69999999999965, 133.99999999999994, 108.49999999999966, 110.89999999999972, 122.89999999999975, 119.59999999999987, 72.2000000000001, 179.29999999999998, 190.09999999999994, 126.19999999999975, 157.69999999999987, 175.69999999999996, 193.7, 107.89999999999999, 158.6, 102.79999999999977, 130.69999999999982, 142.39999999999986, 101.29999999999995, 73.69999999999997, 162.1999999999998, 160.3999999999999, 119.8999999999995, 63.19999999999997, 80.29999999999998, 79.10000000000004, 180.19999999999993, 167.5999999999999, 125.89999999999998, 97.39999999999978, 150.49999999999983, 43.400000000000134, 37.999999999999986, 85.69999999999996, 177.49999999999991, 132.49999999999994, 163.09999999999997, 176.0, 105.50000000000006, 197.3, 200.0, 110.29999999999993, 123.50000000000006, 137.89999999999984, 145.99999999999994, 187.39999999999998, 174.79999999999998, 141.4999999999998, 175.69999999999996, 120.80000000000007, 151.09999999999994, 151.69999999999987, 142.40000000000003, 145.09999999999997, 188.29999999999993, 114.79999999999994, 118.1000000000001, 152.5999999999999, 150.49999999999994, 72.20000000000016, 110.90000000000003, 167.59999999999985, 131.59999999999974, 104.89999999999988, 178.39999999999995, 139.70000000000002, 149.5999999999999, 146.29999999999998, 110.89999999999996, 197.29999999999998, 159.19999999999987, 92.00000000000006, 183.2, 129.5, 187.39999999999992, 152.29999999999995, 155.00000000000003, 187.39999999999995, 187.39999999999998, 179.29999999999995, 82.69999999999985, 116.29999999999994, 162.19999999999996, 168.5, 163.09999999999994, 149.0, 180.2, 185.6, 66.7999999999999, 191.0, 179.29999999999998, 130.7, 193.7, 170.0, 149.6, 171.19999999999982, 190.39999999999998, 168.5, 160.39999999999984, 157.39999999999995, 178.7, 66.79999999999995, 172.99999999999994, 166.69999999999996, 165.79999999999998, 193.7, 154.09999999999997, 188.3, 143.00000000000003, 163.99999999999994, 179.29999999999998, 194.6, 172.7, 173.3, 114.79999999999995, 167.59999999999994, 108.49999999999997, 123.79999999999995, 131.2999999999999, 187.4, 129.79999999999993, 122.89999999999984, 109.39999999999961, 166.39999999999995, 191.89999999999998, 121.10000000000002, 183.79999999999995, 70.39999999999993, 91.9999999999999, 66.79999999999997, 129.79999999999993, 161.89999999999998, 106.39999999999955, 146.8999999999999, 121.70000000000006, 145.9999999999999, 135.7999999999996, 175.1, 155.5999999999998, 155.59999999999997, 120.80000000000001, 87.4999999999996, 99.7999999999997, 181.9999999999999, 172.99999999999991, 31.40000000000007, 154.99999999999994, 200.0, 93.79999999999951, 194.59999999999997, 143.00000000000003, 94.99999999999999, 45.80000000000009, 80.29999999999993, 141.19999999999985, 168.5, 176.29999999999998, 82.39999999999989, 148.3999999999998, 88.40000000000003, 141.49999999999986], "policy_predator_policy_reward": [3.0, 7.0, 6.0, 5.0, 5.0, 3.0, 6.0, 3.0, 0.0, 0.0, 0.0, 0.0, 9.0, 1.0, 8.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 6.0, 0.0, 1.0, 0.0, 0.0, 8.0, 11.0, 4.0, 3.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 6.0, 14.0, 8.0, 4.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 10.0, 0.0, 0.0, 0.0, 11.0, 7.0, 0.0, 3.0, 0.0, 0.0, 0.0, 4.0, 0.0, 1.0, 13.0, 0.0, 0.0, 17.0, 21.0, 0.0, 0.0, 3.0, 6.0, 0.0, 8.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 8.0, 0.0, 0.0, 0.0, 9.0, 11.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 8.0, 0.0, 0.0, 7.0, 0.0, 5.0, 4.0, 13.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 9.0, 0.0, 0.0, 17.0, 0.0, 20.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 2.0, 0.0, 0.0, 15.0, 0.0, 0.0, 0.0, 1.0, 5.0, 0.0, 9.0, 13.0, 0.0, 0.0, 0.0, 3.0, 1.0, 0.0, 7.0, 0.0, 5.0, 4.0, 14.0, 0.0, 0.0, 17.0, 5.0, 0.0, 1.0, 0.0, 11.0, 15.0, 18.0, 3.0, 18.0, 0.0, 1.0, 6.0, 0.0, 0.0, 1.0, 5.0, 1.0, 1.0, 0.0, 7.0, 15.0, 0.0, 0.0, 28.0, 0.0, 0.0, 0.0, 4.0, 0.0, 8.0, 13.0, 0.0, 7.0, 0.0, 10.0, 3.0, 0.0, 22.0, 18.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 11.089402407210493, "mean_inference_ms": 24.515702646467386, "mean_action_processing_ms": 5.506785284280272, "mean_env_wait_ms": 6.21289300440264, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.046907663345336914, "StateBufferConnector_ms": 0.020766377449035645, "ViewRequirementAgentConnector_ms": 0.6247920989990234}, "num_episodes": 23, "episode_return_max": 397.29999999999995, "episode_return_min": 119.39999999999989, "episode_return_mean": 294.3349999999999, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1824000, "num_agent_steps_trained": 1824000, "num_env_steps_sampled": 456000, "num_env_steps_trained": 456000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 143.10342858418403, "num_env_steps_trained_throughput_per_sec": 143.10342858418403, "timesteps_total": 456000, "num_env_steps_sampled_lifetime": 456000, "num_agent_steps_sampled_lifetime": 1824000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1824000, "timers": {"training_iteration_time_ms": 122419.258, "restore_workers_time_ms": 2.566, "training_step_time_ms": 122412.958, "sample_time_ms": 5085.222, "learn_time_ms": 117294.279, "learn_throughput": 34.102, "synch_weights_time_ms": 26.925}, "counters": {"num_env_steps_sampled": 456000, "num_env_steps_trained": 456000, "num_agent_steps_sampled": 1824000, "num_agent_steps_trained": 1824000}, "done": false, "training_iteration": 114, "trial_id": "75ec3_00000", "date": "2024-08-13_04-27-19", "timestamp": 1723537639, "time_this_iter_s": 28.150949001312256, "time_total_s": 10389.163074731827, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b221c310>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 10389.163074731827, "iterations_since_restore": 114, "perf": {"cpu_util_percent": 88.05641025641025, "ram_util_percent": 83.76666666666667}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 10.073965080926028, "cur_kl_coeff": 0.2054945336429227, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.755730786399236, "policy_loss": -0.011867034597884095, "vf_loss": 6.764858284703007, "vf_explained_var": 0.3701018773689472, "kl": 0.013331375940692336, "entropy": 1.0459431790800953, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 216405.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.30815107987986673, "cur_kl_coeff": 6.352747104407251e-23, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.1874733095899934, "policy_loss": -0.0009104098353495516, "vf_loss": 0.18838371918659913, "vf_explained_var": 0.0009755493471862147, "kl": 0.0008639705741511678, "entropy": 0.18299212760080105, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 216405.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 460000, "num_env_steps_trained": 460000, "num_agent_steps_sampled": 1840000, "num_agent_steps_trained": 1840000}, "env_runners": {"episode_reward_max": 397.29999999999995, "episode_reward_min": 119.39999999999989, "episode_reward_mean": 287.0209999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 31.40000000000007, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 28.0}, "policy_reward_mean": {"prey_policy": 139.45549999999994, "predator_policy": 4.055}, "custom_metrics": {}, "hist_stats": {"episode_reward": [300.09999999999985, 317.8999999999995, 262.49999999999955, 245.79999999999944, 198.79999999999947, 369.40000000000003, 283.9000000000001, 369.4000000000002, 282.4999999999997, 233.49999999999937, 254.69999999999973, 242.89999999999918, 283.2999999999997, 143.49999999999997, 263.29999999999984, 307.5000000000004, 247.89999999999952, 119.39999999999989, 263.1999999999996, 304.6000000000001, 289.49999999999966, 397.29999999999995, 241.79999999999993, 283.8999999999999, 362.20000000000005, 317.2000000000004, 278.89999999999964, 302.1, 333.4000000000002, 252.89999999999986, 314.1000000000003, 183.1, 299.2, 291.29999999999984, 289.3000000000002, 265.19999999999993, 363.50000000000045, 280.1999999999998, 333.90000000000003, 307.29999999999984, 374.8000000000003, 262.9999999999999, 287.5000000000001, 348.5999999999999, 349.2, 252.3999999999996, 376.30000000000007, 324.39999999999986, 331.59999999999997, 363.5999999999998, 328.90000000000055, 351.1, 239.7999999999994, 338.5000000000001, 356.79999999999995, 344.29999999999995, 343.2999999999999, 371.3, 295.0999999999998, 281.1000000000002, 273.0999999999999, 317.20000000000033, 254.29999999999947, 359.3000000000002, 315.8999999999999, 195.39999999999947, 217.59999999999943, 269.29999999999995, 274.59999999999974, 282.8000000000003, 336.6999999999998, 277.3999999999999, 209.29999999999933, 355.00000000000045, 214.39999999999975, 293.8, 341.5999999999998, 161.79999999999964, 228.49999999999943, 354.8, 233.79999999999953, 269.89999999999975, 276.4000000000001, 308.4, 305.4000000000001, 259.5999999999995, 308.20000000000084, 296.79999999999995, 298.70000000000016, 292.0, 248.99999999999974, 291.9999999999998, 232.59999999999968, 253.19999999999996, 237.79999999999964, 278.4999999999998, 221.09999999999994, 202.29999999999907, 322.6000000000002, 228.9999999999992], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [106.40000000000003, 193.7, 186.19999999999996, 130.69999999999965, 133.99999999999994, 108.49999999999966, 110.89999999999972, 122.89999999999975, 119.59999999999987, 72.2000000000001, 179.29999999999998, 190.09999999999994, 126.19999999999975, 157.69999999999987, 175.69999999999996, 193.7, 107.89999999999999, 158.6, 102.79999999999977, 130.69999999999982, 142.39999999999986, 101.29999999999995, 73.69999999999997, 162.1999999999998, 160.3999999999999, 119.8999999999995, 63.19999999999997, 80.29999999999998, 79.10000000000004, 180.19999999999993, 167.5999999999999, 125.89999999999998, 97.39999999999978, 150.49999999999983, 43.400000000000134, 37.999999999999986, 85.69999999999996, 177.49999999999991, 132.49999999999994, 163.09999999999997, 176.0, 105.50000000000006, 197.3, 200.0, 110.29999999999993, 123.50000000000006, 137.89999999999984, 145.99999999999994, 187.39999999999998, 174.79999999999998, 141.4999999999998, 175.69999999999996, 120.80000000000007, 151.09999999999994, 151.69999999999987, 142.40000000000003, 145.09999999999997, 188.29999999999993, 114.79999999999994, 118.1000000000001, 152.5999999999999, 150.49999999999994, 72.20000000000016, 110.90000000000003, 167.59999999999985, 131.59999999999974, 104.89999999999988, 178.39999999999995, 139.70000000000002, 149.5999999999999, 146.29999999999998, 110.89999999999996, 197.29999999999998, 159.19999999999987, 92.00000000000006, 183.2, 129.5, 187.39999999999992, 152.29999999999995, 155.00000000000003, 187.39999999999995, 187.39999999999998, 179.29999999999995, 82.69999999999985, 116.29999999999994, 162.19999999999996, 168.5, 163.09999999999994, 149.0, 180.2, 185.6, 66.7999999999999, 191.0, 179.29999999999998, 130.7, 193.7, 170.0, 149.6, 171.19999999999982, 190.39999999999998, 168.5, 160.39999999999984, 157.39999999999995, 178.7, 66.79999999999995, 172.99999999999994, 166.69999999999996, 165.79999999999998, 193.7, 154.09999999999997, 188.3, 143.00000000000003, 163.99999999999994, 179.29999999999998, 194.6, 172.7, 173.3, 114.79999999999995, 167.59999999999994, 108.49999999999997, 123.79999999999995, 131.2999999999999, 187.4, 129.79999999999993, 122.89999999999984, 109.39999999999961, 166.39999999999995, 191.89999999999998, 121.10000000000002, 183.79999999999995, 70.39999999999993, 91.9999999999999, 66.79999999999997, 129.79999999999993, 161.89999999999998, 106.39999999999955, 146.8999999999999, 121.70000000000006, 145.9999999999999, 135.7999999999996, 175.1, 155.5999999999998, 155.59999999999997, 120.80000000000001, 87.4999999999996, 99.7999999999997, 181.9999999999999, 172.99999999999991, 31.40000000000007, 154.99999999999994, 200.0, 93.79999999999951, 194.59999999999997, 143.00000000000003, 94.99999999999999, 45.80000000000009, 80.29999999999993, 141.19999999999985, 168.5, 176.29999999999998, 82.39999999999989, 148.3999999999998, 88.40000000000003, 141.49999999999986, 100.70000000000007, 157.69999999999996, 178.39999999999986, 121.99999999999996, 130.39999999999998, 161.0, 62.300000000000026, 197.29999999999998, 119.89999999999975, 188.29999999999998, 118.70000000000005, 160.1, 93.79999999999993, 170.89999999999992, 120.80000000000005, 162.19999999999987, 136.09999999999982, 104.89999999999998, 147.79999999999998, 144.1999999999999, 138.79999999999987, 93.79999999999981, 127.1, 121.1, 58.400000000000134, 160.39999999999995, 131.59999999999985, 146.9, 154.09999999999994, 41.00000000000013, 113.59999999999994, 67.70000000000016, 155.89999999999995, 166.69999999999993, 130.69999999999965, 98.30000000000005], "policy_predator_policy_reward": [0.0, 0.0, 1.0, 0.0, 6.0, 14.0, 8.0, 4.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 10.0, 0.0, 0.0, 0.0, 11.0, 7.0, 0.0, 3.0, 0.0, 0.0, 0.0, 4.0, 0.0, 1.0, 13.0, 0.0, 0.0, 17.0, 21.0, 0.0, 0.0, 3.0, 6.0, 0.0, 8.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 8.0, 0.0, 0.0, 0.0, 9.0, 11.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 8.0, 0.0, 0.0, 7.0, 0.0, 5.0, 4.0, 13.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 9.0, 0.0, 0.0, 17.0, 0.0, 20.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 2.0, 0.0, 0.0, 15.0, 0.0, 0.0, 0.0, 1.0, 5.0, 0.0, 9.0, 13.0, 0.0, 0.0, 0.0, 3.0, 1.0, 0.0, 7.0, 0.0, 5.0, 4.0, 14.0, 0.0, 0.0, 17.0, 5.0, 0.0, 1.0, 0.0, 11.0, 15.0, 18.0, 3.0, 18.0, 0.0, 1.0, 6.0, 0.0, 0.0, 1.0, 5.0, 1.0, 1.0, 0.0, 7.0, 15.0, 0.0, 0.0, 28.0, 0.0, 0.0, 0.0, 4.0, 0.0, 8.0, 13.0, 0.0, 7.0, 0.0, 10.0, 3.0, 0.0, 22.0, 18.0, 11.0, 7.0, 0.0, 8.0, 0.0, 14.0, 0.0, 0.0, 0.0, 0.0, 0.0, 18.0, 17.0, 17.0, 0.0, 9.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 19.0, 0.0, 0.0, 0.0, 26.0, 11.0, 10.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 10.843637665976551, "mean_inference_ms": 23.99858377670973, "mean_action_processing_ms": 5.266347180675881, "mean_env_wait_ms": 6.966085144321712, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.04273724555969238, "StateBufferConnector_ms": 0.017047405242919922, "ViewRequirementAgentConnector_ms": 0.6549967527389526}, "num_episodes": 18, "episode_return_max": 397.29999999999995, "episode_return_min": 119.39999999999989, "episode_return_mean": 287.0209999999999, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1840000, "num_agent_steps_trained": 1840000, "num_env_steps_sampled": 460000, "num_env_steps_trained": 460000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 4.168834624714304, "num_env_steps_trained_throughput_per_sec": 4.168834624714304, "timesteps_total": 460000, "num_env_steps_sampled_lifetime": 460000, "num_agent_steps_sampled_lifetime": 1840000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1840000, "timers": {"training_iteration_time_ms": 216000.797, "restore_workers_time_ms": 2.566, "training_step_time_ms": 215994.497, "sample_time_ms": 5243.721, "learn_time_ms": 210714.217, "learn_throughput": 18.983, "synch_weights_time_ms": 29.3}, "counters": {"num_env_steps_sampled": 460000, "num_env_steps_trained": 460000, "num_agent_steps_sampled": 1840000, "num_agent_steps_trained": 1840000}, "done": false, "training_iteration": 115, "trial_id": "75ec3_00000", "date": "2024-08-13_04-43-19", "timestamp": 1723538599, "time_this_iter_s": 959.7376842498779, "time_total_s": 11348.900758981705, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b245f430>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 11348.900758981705, "iterations_since_restore": 115, "perf": {"cpu_util_percent": 87.7125, "ram_util_percent": 83.465625}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.6387679354065945, "cur_kl_coeff": 0.2054945336429227, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.436080414403683, "policy_loss": 2.127637244051411e-05, "vf_loss": 5.433959478549856, "vf_explained_var": 0.17643381231045596, "kl": 0.010217547277445532, "entropy": 1.0524462706197506, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 218295.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5567245507543838, "cur_kl_coeff": 3.1763735522036256e-23, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.8312168625139055, "policy_loss": -0.00030850853423573197, "vf_loss": 0.8315253704628617, "vf_explained_var": 0.005646774503919813, "kl": 0.0006639626662532668, "entropy": 0.15428039475723548, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 218295.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 464000, "num_env_steps_trained": 464000, "num_agent_steps_sampled": 1856000, "num_agent_steps_trained": 1856000}, "env_runners": {"episode_reward_max": 376.30000000000007, "episode_reward_min": 161.79999999999964, "episode_reward_mean": 298.56899999999996, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 31.40000000000007, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 28.0}, "policy_reward_mean": {"prey_policy": 145.02949999999993, "predator_policy": 4.255}, "custom_metrics": {}, "hist_stats": {"episode_reward": [241.79999999999993, 283.8999999999999, 362.20000000000005, 317.2000000000004, 278.89999999999964, 302.1, 333.4000000000002, 252.89999999999986, 314.1000000000003, 183.1, 299.2, 291.29999999999984, 289.3000000000002, 265.19999999999993, 363.50000000000045, 280.1999999999998, 333.90000000000003, 307.29999999999984, 374.8000000000003, 262.9999999999999, 287.5000000000001, 348.5999999999999, 349.2, 252.3999999999996, 376.30000000000007, 324.39999999999986, 331.59999999999997, 363.5999999999998, 328.90000000000055, 351.1, 239.7999999999994, 338.5000000000001, 356.79999999999995, 344.29999999999995, 343.2999999999999, 371.3, 295.0999999999998, 281.1000000000002, 273.0999999999999, 317.20000000000033, 254.29999999999947, 359.3000000000002, 315.8999999999999, 195.39999999999947, 217.59999999999943, 269.29999999999995, 274.59999999999974, 282.8000000000003, 336.6999999999998, 277.3999999999999, 209.29999999999933, 355.00000000000045, 214.39999999999975, 293.8, 341.5999999999998, 161.79999999999964, 228.49999999999943, 354.8, 233.79999999999953, 269.89999999999975, 276.4000000000001, 308.4, 305.4000000000001, 259.5999999999995, 308.20000000000084, 296.79999999999995, 298.70000000000016, 292.0, 248.99999999999974, 291.9999999999998, 232.59999999999968, 253.19999999999996, 237.79999999999964, 278.4999999999998, 221.09999999999994, 202.29999999999907, 322.6000000000002, 228.9999999999992, 323.50000000000006, 337.9000000000004, 324.0000000000001, 270.4999999999999, 326.20000000000095, 330.09999999999985, 305.7999999999999, 373.9, 324.7999999999997, 293.20000000000005, 313.4, 252.0999999999995, 347.79999999999995, 323.79999999999984, 355.5000000000002, 366.70000000000005, 298.6000000000001, 347.79999999999984, 319.8999999999997, 332.6000000000001, 370.0000000000001, 297.60000000000025], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [110.29999999999993, 123.50000000000006, 137.89999999999984, 145.99999999999994, 187.39999999999998, 174.79999999999998, 141.4999999999998, 175.69999999999996, 120.80000000000007, 151.09999999999994, 151.69999999999987, 142.40000000000003, 145.09999999999997, 188.29999999999993, 114.79999999999994, 118.1000000000001, 152.5999999999999, 150.49999999999994, 72.20000000000016, 110.90000000000003, 167.59999999999985, 131.59999999999974, 104.89999999999988, 178.39999999999995, 139.70000000000002, 149.5999999999999, 146.29999999999998, 110.89999999999996, 197.29999999999998, 159.19999999999987, 92.00000000000006, 183.2, 129.5, 187.39999999999992, 152.29999999999995, 155.00000000000003, 187.39999999999995, 187.39999999999998, 179.29999999999995, 82.69999999999985, 116.29999999999994, 162.19999999999996, 168.5, 163.09999999999994, 149.0, 180.2, 185.6, 66.7999999999999, 191.0, 179.29999999999998, 130.7, 193.7, 170.0, 149.6, 171.19999999999982, 190.39999999999998, 168.5, 160.39999999999984, 157.39999999999995, 178.7, 66.79999999999995, 172.99999999999994, 166.69999999999996, 165.79999999999998, 193.7, 154.09999999999997, 188.3, 143.00000000000003, 163.99999999999994, 179.29999999999998, 194.6, 172.7, 173.3, 114.79999999999995, 167.59999999999994, 108.49999999999997, 123.79999999999995, 131.2999999999999, 187.4, 129.79999999999993, 122.89999999999984, 109.39999999999961, 166.39999999999995, 191.89999999999998, 121.10000000000002, 183.79999999999995, 70.39999999999993, 91.9999999999999, 66.79999999999997, 129.79999999999993, 161.89999999999998, 106.39999999999955, 146.8999999999999, 121.70000000000006, 145.9999999999999, 135.7999999999996, 175.1, 155.5999999999998, 155.59999999999997, 120.80000000000001, 87.4999999999996, 99.7999999999997, 181.9999999999999, 172.99999999999991, 31.40000000000007, 154.99999999999994, 200.0, 93.79999999999951, 194.59999999999997, 143.00000000000003, 94.99999999999999, 45.80000000000009, 80.29999999999993, 141.19999999999985, 168.5, 176.29999999999998, 82.39999999999989, 148.3999999999998, 88.40000000000003, 141.49999999999986, 100.70000000000007, 157.69999999999996, 178.39999999999986, 121.99999999999996, 130.39999999999998, 161.0, 62.300000000000026, 197.29999999999998, 119.89999999999975, 188.29999999999998, 118.70000000000005, 160.1, 93.79999999999993, 170.89999999999992, 120.80000000000005, 162.19999999999987, 136.09999999999982, 104.89999999999998, 147.79999999999998, 144.1999999999999, 138.79999999999987, 93.79999999999981, 127.1, 121.1, 58.400000000000134, 160.39999999999995, 131.59999999999985, 146.9, 154.09999999999994, 41.00000000000013, 113.59999999999994, 67.70000000000016, 155.89999999999995, 166.69999999999993, 130.69999999999965, 98.30000000000005, 158.59999999999997, 164.89999999999995, 153.1999999999999, 184.7, 156.1999999999999, 159.8, 161.8999999999999, 104.59999999999988, 165.79999999999987, 160.3999999999998, 156.8, 161.29999999999995, 119.29999999999993, 174.5, 192.79999999999998, 181.1, 146.59999999999997, 171.20000000000002, 186.49999999999997, 103.69999999999996, 141.19999999999993, 138.1999999999999, 85.69999999999989, 148.39999999999984, 184.69999999999996, 163.1, 196.1, 103.70000000000005, 172.09999999999994, 169.39999999999998, 198.2, 168.49999999999986, 122.29999999999998, 167.3, 184.6999999999999, 163.10000000000002, 147.79999999999995, 163.10000000000002, 143.0, 176.59999999999997, 175.69999999999996, 188.3, 140.5999999999999, 139.99999999999997], "policy_predator_policy_reward": [0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 8.0, 0.0, 0.0, 0.0, 9.0, 11.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 8.0, 0.0, 0.0, 7.0, 0.0, 5.0, 4.0, 13.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 9.0, 0.0, 0.0, 17.0, 0.0, 20.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 2.0, 0.0, 0.0, 15.0, 0.0, 0.0, 0.0, 1.0, 5.0, 0.0, 9.0, 13.0, 0.0, 0.0, 0.0, 3.0, 1.0, 0.0, 7.0, 0.0, 5.0, 4.0, 14.0, 0.0, 0.0, 17.0, 5.0, 0.0, 1.0, 0.0, 11.0, 15.0, 18.0, 3.0, 18.0, 0.0, 1.0, 6.0, 0.0, 0.0, 1.0, 5.0, 1.0, 1.0, 0.0, 7.0, 15.0, 0.0, 0.0, 28.0, 0.0, 0.0, 0.0, 4.0, 0.0, 8.0, 13.0, 0.0, 7.0, 0.0, 10.0, 3.0, 0.0, 22.0, 18.0, 11.0, 7.0, 0.0, 8.0, 0.0, 14.0, 0.0, 0.0, 0.0, 0.0, 0.0, 18.0, 17.0, 17.0, 0.0, 9.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 19.0, 0.0, 0.0, 0.0, 26.0, 11.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 12.0, 12.0, 0.0, 0.0, 0.0, 7.0, 0.0, 3.0, 0.0, 13.0, 21.0, 13.0, 5.0, 0.0, 0.0, 8.0, 16.0, 8.0, 6.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 9.0, 0.0, 1.0, 12.0, 6.0, 0.0, 17.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 10.986764384215041, "mean_inference_ms": 23.849818086161655, "mean_action_processing_ms": 5.049031704076026, "mean_env_wait_ms": 6.924372381992032, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.07571768760681152, "StateBufferConnector_ms": 0.01921844482421875, "ViewRequirementAgentConnector_ms": 0.808205246925354}, "num_episodes": 22, "episode_return_max": 376.30000000000007, "episode_return_min": 161.79999999999964, "episode_return_mean": 298.56899999999996, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1856000, "num_agent_steps_trained": 1856000, "num_env_steps_sampled": 464000, "num_env_steps_trained": 464000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 145.37111388989118, "num_env_steps_trained_throughput_per_sec": 145.37111388989118, "timesteps_total": 464000, "num_env_steps_sampled_lifetime": 464000, "num_agent_steps_sampled_lifetime": 1856000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1856000, "timers": {"training_iteration_time_ms": 217129.015, "restore_workers_time_ms": 2.568, "training_step_time_ms": 217122.711, "sample_time_ms": 6033.157, "learn_time_ms": 211052.486, "learn_throughput": 18.953, "synch_weights_time_ms": 30.032}, "counters": {"num_env_steps_sampled": 464000, "num_env_steps_trained": 464000, "num_agent_steps_sampled": 1856000, "num_agent_steps_trained": 1856000}, "done": false, "training_iteration": 116, "trial_id": "75ec3_00000", "date": "2024-08-13_04-43-46", "timestamp": 1723538626, "time_this_iter_s": 27.60177707672119, "time_total_s": 11376.502536058426, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b23f0550>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 11376.502536058426, "iterations_since_restore": 116, "perf": {"cpu_util_percent": 92.66923076923075, "ram_util_percent": 83.8}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.783855003780789, "cur_kl_coeff": 0.2054945336429227, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.7751304184948955, "policy_loss": -0.006025962871080511, "vf_loss": 6.779766519990548, "vf_explained_var": 0.11210514827380105, "kl": 0.006763558265275052, "entropy": 1.0652862814999131, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 220185.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4833945390122829, "cur_kl_coeff": 1.5881867761018128e-23, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.626563645497201, "policy_loss": -0.0001980288446974502, "vf_loss": 0.6267616732923127, "vf_explained_var": 0.04521878784295743, "kl": 0.0008905828625485502, "entropy": 0.2145697443415879, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 220185.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 468000, "num_env_steps_trained": 468000, "num_agent_steps_sampled": 1872000, "num_agent_steps_trained": 1872000}, "env_runners": {"episode_reward_max": 376.30000000000007, "episode_reward_min": 161.79999999999964, "episode_reward_mean": 299.63399999999996, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 31.40000000000007, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 28.0}, "policy_reward_mean": {"prey_policy": 145.26199999999994, "predator_policy": 4.555}, "custom_metrics": {}, "hist_stats": {"episode_reward": [374.8000000000003, 262.9999999999999, 287.5000000000001, 348.5999999999999, 349.2, 252.3999999999996, 376.30000000000007, 324.39999999999986, 331.59999999999997, 363.5999999999998, 328.90000000000055, 351.1, 239.7999999999994, 338.5000000000001, 356.79999999999995, 344.29999999999995, 343.2999999999999, 371.3, 295.0999999999998, 281.1000000000002, 273.0999999999999, 317.20000000000033, 254.29999999999947, 359.3000000000002, 315.8999999999999, 195.39999999999947, 217.59999999999943, 269.29999999999995, 274.59999999999974, 282.8000000000003, 336.6999999999998, 277.3999999999999, 209.29999999999933, 355.00000000000045, 214.39999999999975, 293.8, 341.5999999999998, 161.79999999999964, 228.49999999999943, 354.8, 233.79999999999953, 269.89999999999975, 276.4000000000001, 308.4, 305.4000000000001, 259.5999999999995, 308.20000000000084, 296.79999999999995, 298.70000000000016, 292.0, 248.99999999999974, 291.9999999999998, 232.59999999999968, 253.19999999999996, 237.79999999999964, 278.4999999999998, 221.09999999999994, 202.29999999999907, 322.6000000000002, 228.9999999999992, 323.50000000000006, 337.9000000000004, 324.0000000000001, 270.4999999999999, 326.20000000000095, 330.09999999999985, 305.7999999999999, 373.9, 324.7999999999997, 293.20000000000005, 313.4, 252.0999999999995, 347.79999999999995, 323.79999999999984, 355.5000000000002, 366.70000000000005, 298.6000000000001, 347.79999999999984, 319.8999999999997, 332.6000000000001, 370.0000000000001, 297.60000000000025, 291.9000000000002, 271.69999999999993, 273.5999999999999, 345.19999999999993, 279.1, 349.5999999999999, 267.30000000000007, 336.40000000000066, 294.70000000000005, 302.8000000000003, 309.3000000000001, 311.3000000000004, 242.7999999999999, 304.49999999999994, 326.80000000000075, 283.2, 301.6000000000005, 314.1999999999999], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [187.39999999999995, 187.39999999999998, 179.29999999999995, 82.69999999999985, 116.29999999999994, 162.19999999999996, 168.5, 163.09999999999994, 149.0, 180.2, 185.6, 66.7999999999999, 191.0, 179.29999999999998, 130.7, 193.7, 170.0, 149.6, 171.19999999999982, 190.39999999999998, 168.5, 160.39999999999984, 157.39999999999995, 178.7, 66.79999999999995, 172.99999999999994, 166.69999999999996, 165.79999999999998, 193.7, 154.09999999999997, 188.3, 143.00000000000003, 163.99999999999994, 179.29999999999998, 194.6, 172.7, 173.3, 114.79999999999995, 167.59999999999994, 108.49999999999997, 123.79999999999995, 131.2999999999999, 187.4, 129.79999999999993, 122.89999999999984, 109.39999999999961, 166.39999999999995, 191.89999999999998, 121.10000000000002, 183.79999999999995, 70.39999999999993, 91.9999999999999, 66.79999999999997, 129.79999999999993, 161.89999999999998, 106.39999999999955, 146.8999999999999, 121.70000000000006, 145.9999999999999, 135.7999999999996, 175.1, 155.5999999999998, 155.59999999999997, 120.80000000000001, 87.4999999999996, 99.7999999999997, 181.9999999999999, 172.99999999999991, 31.40000000000007, 154.99999999999994, 200.0, 93.79999999999951, 194.59999999999997, 143.00000000000003, 94.99999999999999, 45.80000000000009, 80.29999999999993, 141.19999999999985, 168.5, 176.29999999999998, 82.39999999999989, 148.3999999999998, 88.40000000000003, 141.49999999999986, 100.70000000000007, 157.69999999999996, 178.39999999999986, 121.99999999999996, 130.39999999999998, 161.0, 62.300000000000026, 197.29999999999998, 119.89999999999975, 188.29999999999998, 118.70000000000005, 160.1, 93.79999999999993, 170.89999999999992, 120.80000000000005, 162.19999999999987, 136.09999999999982, 104.89999999999998, 147.79999999999998, 144.1999999999999, 138.79999999999987, 93.79999999999981, 127.1, 121.1, 58.400000000000134, 160.39999999999995, 131.59999999999985, 146.9, 154.09999999999994, 41.00000000000013, 113.59999999999994, 67.70000000000016, 155.89999999999995, 166.69999999999993, 130.69999999999965, 98.30000000000005, 158.59999999999997, 164.89999999999995, 153.1999999999999, 184.7, 156.1999999999999, 159.8, 161.8999999999999, 104.59999999999988, 165.79999999999987, 160.3999999999998, 156.8, 161.29999999999995, 119.29999999999993, 174.5, 192.79999999999998, 181.1, 146.59999999999997, 171.20000000000002, 186.49999999999997, 103.69999999999996, 141.19999999999993, 138.1999999999999, 85.69999999999989, 148.39999999999984, 184.69999999999996, 163.1, 196.1, 103.70000000000005, 172.09999999999994, 169.39999999999998, 198.2, 168.49999999999986, 122.29999999999998, 167.3, 184.6999999999999, 163.10000000000002, 147.79999999999995, 163.10000000000002, 143.0, 176.59999999999997, 175.69999999999996, 188.3, 140.5999999999999, 139.99999999999997, 173.89999999999984, 112.99999999999972, 141.2, 123.49999999999974, 139.10000000000002, 132.4999999999996, 153.49999999999997, 178.7, 133.0999999999999, 130.99999999999994, 144.79999999999998, 192.79999999999998, 138.79999999999973, 117.4999999999999, 184.69999999999996, 148.69999999999985, 172.99999999999991, 121.69999999999976, 171.19999999999993, 131.59999999999994, 122.29999999999997, 163.99999999999994, 174.7999999999999, 129.49999999999997, 119.89999999999992, 116.89999999999995, 163.09999999999994, 118.40000000000003, 159.7999999999999, 163.99999999999977, 166.09999999999997, 109.09999999999991, 127.39999999999992, 168.19999999999993, 148.39999999999992, 150.8], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 1.0, 9.0, 0.0, 0.0, 17.0, 0.0, 20.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 2.0, 0.0, 0.0, 15.0, 0.0, 0.0, 0.0, 1.0, 5.0, 0.0, 9.0, 13.0, 0.0, 0.0, 0.0, 3.0, 1.0, 0.0, 7.0, 0.0, 5.0, 4.0, 14.0, 0.0, 0.0, 17.0, 5.0, 0.0, 1.0, 0.0, 11.0, 15.0, 18.0, 3.0, 18.0, 0.0, 1.0, 6.0, 0.0, 0.0, 1.0, 5.0, 1.0, 1.0, 0.0, 7.0, 15.0, 0.0, 0.0, 28.0, 0.0, 0.0, 0.0, 4.0, 0.0, 8.0, 13.0, 0.0, 7.0, 0.0, 10.0, 3.0, 0.0, 22.0, 18.0, 11.0, 7.0, 0.0, 8.0, 0.0, 14.0, 0.0, 0.0, 0.0, 0.0, 0.0, 18.0, 17.0, 17.0, 0.0, 9.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 19.0, 0.0, 0.0, 0.0, 26.0, 11.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 12.0, 12.0, 0.0, 0.0, 0.0, 7.0, 0.0, 3.0, 0.0, 13.0, 21.0, 13.0, 5.0, 0.0, 0.0, 8.0, 16.0, 8.0, 6.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 9.0, 0.0, 1.0, 12.0, 6.0, 0.0, 17.0, 0.0, 0.0, 5.0, 7.0, 0.0, 0.0, 2.0, 11.0, 2.0, 7.0, 8.0, 7.0, 5.0, 0.0, 11.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 11.0, 12.0, 0.0, 7.0, 0.0, 6.0, 5.0, 18.0, 1.0, 2.0, 0.0, 8.0, 5.0, 1.0, 15.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 10.7226393318701, "mean_inference_ms": 23.765847571287505, "mean_action_processing_ms": 5.206120339706133, "mean_env_wait_ms": 6.85836113542654, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0672295093536377, "StateBufferConnector_ms": 0.013915777206420898, "ViewRequirementAgentConnector_ms": 0.5780832767486572}, "num_episodes": 18, "episode_return_max": 376.30000000000007, "episode_return_min": 161.79999999999964, "episode_return_mean": 299.63399999999996, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1872000, "num_agent_steps_trained": 1872000, "num_env_steps_sampled": 468000, "num_env_steps_trained": 468000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 220.67302235020517, "num_env_steps_trained_throughput_per_sec": 220.67302235020517, "timesteps_total": 468000, "num_env_steps_sampled_lifetime": 468000, "num_agent_steps_sampled_lifetime": 1872000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1872000, "timers": {"training_iteration_time_ms": 116494.194, "restore_workers_time_ms": 2.568, "training_step_time_ms": 116487.892, "sample_time_ms": 6204.869, "learn_time_ms": 110247.994, "learn_throughput": 36.282, "synch_weights_time_ms": 28.602}, "counters": {"num_env_steps_sampled": 468000, "num_env_steps_trained": 468000, "num_agent_steps_sampled": 1872000, "num_agent_steps_trained": 1872000}, "done": false, "training_iteration": 117, "trial_id": "75ec3_00000", "date": "2024-08-13_04-44-05", "timestamp": 1723538645, "time_this_iter_s": 18.17393684387207, "time_total_s": 11394.676472902298, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2409670>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 11394.676472902298, "iterations_since_restore": 117, "perf": {"cpu_util_percent": 80.27199999999999, "ram_util_percent": 83.72}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 6.1736035509715, "cur_kl_coeff": 0.2054945336429227, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.481319470632644, "policy_loss": 0.00038676674578772496, "vf_loss": 4.47948939434435, "vf_explained_var": 0.25062630069318903, "kl": 0.007023566743339085, "entropy": 1.0799862846495614, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 222075.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.31362242209059854, "cur_kl_coeff": 7.940933880509064e-24, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.1910409739763333, "policy_loss": 4.077233871809704e-05, "vf_loss": 0.1910002015168882, "vf_explained_var": 0.005177213432927611, "kl": 0.0013496313638878018, "entropy": 0.24889227387608676, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 222075.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 472000, "num_env_steps_trained": 472000, "num_agent_steps_sampled": 1888000, "num_agent_steps_trained": 1888000}, "env_runners": {"episode_reward_max": 373.9, "episode_reward_min": 161.79999999999964, "episode_reward_mean": 298.73599999999993, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 31.40000000000007, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 28.0}, "policy_reward_mean": {"prey_policy": 144.69799999999992, "predator_policy": 4.67}, "custom_metrics": {}, "hist_stats": {"episode_reward": [295.0999999999998, 281.1000000000002, 273.0999999999999, 317.20000000000033, 254.29999999999947, 359.3000000000002, 315.8999999999999, 195.39999999999947, 217.59999999999943, 269.29999999999995, 274.59999999999974, 282.8000000000003, 336.6999999999998, 277.3999999999999, 209.29999999999933, 355.00000000000045, 214.39999999999975, 293.8, 341.5999999999998, 161.79999999999964, 228.49999999999943, 354.8, 233.79999999999953, 269.89999999999975, 276.4000000000001, 308.4, 305.4000000000001, 259.5999999999995, 308.20000000000084, 296.79999999999995, 298.70000000000016, 292.0, 248.99999999999974, 291.9999999999998, 232.59999999999968, 253.19999999999996, 237.79999999999964, 278.4999999999998, 221.09999999999994, 202.29999999999907, 322.6000000000002, 228.9999999999992, 323.50000000000006, 337.9000000000004, 324.0000000000001, 270.4999999999999, 326.20000000000095, 330.09999999999985, 305.7999999999999, 373.9, 324.7999999999997, 293.20000000000005, 313.4, 252.0999999999995, 347.79999999999995, 323.79999999999984, 355.5000000000002, 366.70000000000005, 298.6000000000001, 347.79999999999984, 319.8999999999997, 332.6000000000001, 370.0000000000001, 297.60000000000025, 291.9000000000002, 271.69999999999993, 273.5999999999999, 345.19999999999993, 279.1, 349.5999999999999, 267.30000000000007, 336.40000000000066, 294.70000000000005, 302.8000000000003, 309.3000000000001, 311.3000000000004, 242.7999999999999, 304.49999999999994, 326.80000000000075, 283.2, 301.6000000000005, 314.1999999999999, 296.4999999999998, 346.2999999999999, 339.5000000000001, 373.1, 338.80000000000047, 358.60000000000014, 265.69999999999993, 314.8000000000002, 370.3, 343.30000000000064, 309.5999999999997, 326.79999999999995, 353.2000000000003, 293.2999999999998, 292.2999999999997, 315.7, 267.69999999999936, 350.09999999999997], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [173.3, 114.79999999999995, 167.59999999999994, 108.49999999999997, 123.79999999999995, 131.2999999999999, 187.4, 129.79999999999993, 122.89999999999984, 109.39999999999961, 166.39999999999995, 191.89999999999998, 121.10000000000002, 183.79999999999995, 70.39999999999993, 91.9999999999999, 66.79999999999997, 129.79999999999993, 161.89999999999998, 106.39999999999955, 146.8999999999999, 121.70000000000006, 145.9999999999999, 135.7999999999996, 175.1, 155.5999999999998, 155.59999999999997, 120.80000000000001, 87.4999999999996, 99.7999999999997, 181.9999999999999, 172.99999999999991, 31.40000000000007, 154.99999999999994, 200.0, 93.79999999999951, 194.59999999999997, 143.00000000000003, 94.99999999999999, 45.80000000000009, 80.29999999999993, 141.19999999999985, 168.5, 176.29999999999998, 82.39999999999989, 148.3999999999998, 88.40000000000003, 141.49999999999986, 100.70000000000007, 157.69999999999996, 178.39999999999986, 121.99999999999996, 130.39999999999998, 161.0, 62.300000000000026, 197.29999999999998, 119.89999999999975, 188.29999999999998, 118.70000000000005, 160.1, 93.79999999999993, 170.89999999999992, 120.80000000000005, 162.19999999999987, 136.09999999999982, 104.89999999999998, 147.79999999999998, 144.1999999999999, 138.79999999999987, 93.79999999999981, 127.1, 121.1, 58.400000000000134, 160.39999999999995, 131.59999999999985, 146.9, 154.09999999999994, 41.00000000000013, 113.59999999999994, 67.70000000000016, 155.89999999999995, 166.69999999999993, 130.69999999999965, 98.30000000000005, 158.59999999999997, 164.89999999999995, 153.1999999999999, 184.7, 156.1999999999999, 159.8, 161.8999999999999, 104.59999999999988, 165.79999999999987, 160.3999999999998, 156.8, 161.29999999999995, 119.29999999999993, 174.5, 192.79999999999998, 181.1, 146.59999999999997, 171.20000000000002, 186.49999999999997, 103.69999999999996, 141.19999999999993, 138.1999999999999, 85.69999999999989, 148.39999999999984, 184.69999999999996, 163.1, 196.1, 103.70000000000005, 172.09999999999994, 169.39999999999998, 198.2, 168.49999999999986, 122.29999999999998, 167.3, 184.6999999999999, 163.10000000000002, 147.79999999999995, 163.10000000000002, 143.0, 176.59999999999997, 175.69999999999996, 188.3, 140.5999999999999, 139.99999999999997, 173.89999999999984, 112.99999999999972, 141.2, 123.49999999999974, 139.10000000000002, 132.4999999999996, 153.49999999999997, 178.7, 133.0999999999999, 130.99999999999994, 144.79999999999998, 192.79999999999998, 138.79999999999973, 117.4999999999999, 184.69999999999996, 148.69999999999985, 172.99999999999991, 121.69999999999976, 171.19999999999993, 131.59999999999994, 122.29999999999997, 163.99999999999994, 174.7999999999999, 129.49999999999997, 119.89999999999992, 116.89999999999995, 163.09999999999994, 118.40000000000003, 159.7999999999999, 163.99999999999977, 166.09999999999997, 109.09999999999991, 127.39999999999992, 168.19999999999993, 148.39999999999992, 150.8, 123.20000000000003, 152.2999999999999, 150.49999999999994, 183.79999999999995, 161.29999999999998, 168.2, 191.89999999999998, 177.19999999999996, 181.09999999999994, 157.69999999999993, 186.49999999999997, 172.10000000000002, 136.1, 107.6, 146.89999999999998, 155.89999999999998, 189.20000000000002, 181.10000000000002, 174.79999999999987, 168.5, 136.40000000000003, 162.1999999999999, 182.89999999999998, 131.89999999999992, 190.09999999999994, 163.09999999999997, 175.39999999999998, 101.90000000000005, 184.70000000000002, 104.5999999999998, 137.0, 175.7, 120.80000000000007, 146.90000000000006, 163.4, 175.7], "policy_predator_policy_reward": [0.0, 7.0, 0.0, 5.0, 4.0, 14.0, 0.0, 0.0, 17.0, 5.0, 0.0, 1.0, 0.0, 11.0, 15.0, 18.0, 3.0, 18.0, 0.0, 1.0, 6.0, 0.0, 0.0, 1.0, 5.0, 1.0, 1.0, 0.0, 7.0, 15.0, 0.0, 0.0, 28.0, 0.0, 0.0, 0.0, 4.0, 0.0, 8.0, 13.0, 0.0, 7.0, 0.0, 10.0, 3.0, 0.0, 22.0, 18.0, 11.0, 7.0, 0.0, 8.0, 0.0, 14.0, 0.0, 0.0, 0.0, 0.0, 0.0, 18.0, 17.0, 17.0, 0.0, 9.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 19.0, 0.0, 0.0, 0.0, 26.0, 11.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 12.0, 12.0, 0.0, 0.0, 0.0, 7.0, 0.0, 3.0, 0.0, 13.0, 21.0, 13.0, 5.0, 0.0, 0.0, 8.0, 16.0, 8.0, 6.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 9.0, 0.0, 1.0, 12.0, 6.0, 0.0, 17.0, 0.0, 0.0, 5.0, 7.0, 0.0, 0.0, 2.0, 11.0, 2.0, 7.0, 8.0, 7.0, 5.0, 0.0, 11.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 11.0, 12.0, 0.0, 7.0, 0.0, 6.0, 5.0, 18.0, 1.0, 2.0, 0.0, 8.0, 5.0, 1.0, 15.0, 0.0, 5.0, 16.0, 3.0, 9.0, 10.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 11.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 4.0, 8.0, 0.0, 0.0, 4.0, 12.0, 3.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 11.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 10.662143062526605, "mean_inference_ms": 23.642648927037488, "mean_action_processing_ms": 5.174067883348138, "mean_env_wait_ms": 6.812585794058549, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.06248927116394043, "StateBufferConnector_ms": 0.013846516609191895, "ViewRequirementAgentConnector_ms": 0.5448116064071655}, "num_episodes": 18, "episode_return_max": 373.9, "episode_return_min": 161.79999999999964, "episode_return_mean": 298.73599999999993, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1888000, "num_agent_steps_trained": 1888000, "num_env_steps_sampled": 472000, "num_env_steps_trained": 472000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 241.126353282137, "num_env_steps_trained_throughput_per_sec": 241.126353282137, "timesteps_total": 472000, "num_env_steps_sampled_lifetime": 472000, "num_agent_steps_sampled_lifetime": 1888000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1888000, "timers": {"training_iteration_time_ms": 116223.855, "restore_workers_time_ms": 2.568, "training_step_time_ms": 116217.553, "sample_time_ms": 6133.053, "learn_time_ms": 110048.842, "learn_throughput": 36.347, "synch_weights_time_ms": 28.873}, "counters": {"num_env_steps_sampled": 472000, "num_env_steps_trained": 472000, "num_agent_steps_sampled": 1888000, "num_agent_steps_trained": 1888000}, "done": false, "training_iteration": 118, "trial_id": "75ec3_00000", "date": "2024-08-13_04-44-21", "timestamp": 1723538661, "time_this_iter_s": 16.636011600494385, "time_total_s": 11411.312484502792, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b245f430>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 11411.312484502792, "iterations_since_restore": 118, "perf": {"cpu_util_percent": 78.29166666666667, "ram_util_percent": 83.12083333333334}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 6.509224800584177, "cur_kl_coeff": 0.2054945336429227, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.121763211204892, "policy_loss": -0.016591075574979186, "vf_loss": 6.132591342926025, "vf_explained_var": 0.13310807038236547, "kl": 0.028044165472424238, "entropy": 1.04982995501271, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 223965.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7918020939365739, "cur_kl_coeff": 3.970466940254532e-24, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.546099211330767, "policy_loss": -0.0011213497846342979, "vf_loss": 1.5472205662853504, "vf_explained_var": 0.018144487766992477, "kl": 0.0031346789337660533, "entropy": 0.30893410374878577, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 223965.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 476000, "num_env_steps_trained": 476000, "num_agent_steps_sampled": 1904000, "num_agent_steps_trained": 1904000}, "env_runners": {"episode_reward_max": 373.9, "episode_reward_min": 173.29999999999941, "episode_reward_mean": 305.262, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 41.00000000000013, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 198.2, "predator_policy": 43.0}, "policy_reward_mean": {"prey_policy": 147.77599999999995, "predator_policy": 4.855}, "custom_metrics": {}, "hist_stats": {"episode_reward": [269.89999999999975, 276.4000000000001, 308.4, 305.4000000000001, 259.5999999999995, 308.20000000000084, 296.79999999999995, 298.70000000000016, 292.0, 248.99999999999974, 291.9999999999998, 232.59999999999968, 253.19999999999996, 237.79999999999964, 278.4999999999998, 221.09999999999994, 202.29999999999907, 322.6000000000002, 228.9999999999992, 323.50000000000006, 337.9000000000004, 324.0000000000001, 270.4999999999999, 326.20000000000095, 330.09999999999985, 305.7999999999999, 373.9, 324.7999999999997, 293.20000000000005, 313.4, 252.0999999999995, 347.79999999999995, 323.79999999999984, 355.5000000000002, 366.70000000000005, 298.6000000000001, 347.79999999999984, 319.8999999999997, 332.6000000000001, 370.0000000000001, 297.60000000000025, 291.9000000000002, 271.69999999999993, 273.5999999999999, 345.19999999999993, 279.1, 349.5999999999999, 267.30000000000007, 336.40000000000066, 294.70000000000005, 302.8000000000003, 309.3000000000001, 311.3000000000004, 242.7999999999999, 304.49999999999994, 326.80000000000075, 283.2, 301.6000000000005, 314.1999999999999, 296.4999999999998, 346.2999999999999, 339.5000000000001, 373.1, 338.80000000000047, 358.60000000000014, 265.69999999999993, 314.8000000000002, 370.3, 343.30000000000064, 309.5999999999997, 326.79999999999995, 353.2000000000003, 293.2999999999998, 292.2999999999997, 315.7, 267.69999999999936, 350.09999999999997, 312.6999999999996, 296.9999999999999, 312.70000000000005, 196.29999999999959, 342.1000000000005, 227.29999999999956, 368.49999999999994, 350.5, 321.30000000000075, 336.5999999999999, 317.8000000000003, 347.8000000000004, 173.29999999999941, 302.29999999999995, 308.1999999999999, 349.50000000000006, 252.29999999999947, 311.4, 335.89999999999986, 278.4000000000002, 311.4999999999999, 333.4000000000003, 308.5999999999997], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [88.40000000000003, 141.49999999999986, 100.70000000000007, 157.69999999999996, 178.39999999999986, 121.99999999999996, 130.39999999999998, 161.0, 62.300000000000026, 197.29999999999998, 119.89999999999975, 188.29999999999998, 118.70000000000005, 160.1, 93.79999999999993, 170.89999999999992, 120.80000000000005, 162.19999999999987, 136.09999999999982, 104.89999999999998, 147.79999999999998, 144.1999999999999, 138.79999999999987, 93.79999999999981, 127.1, 121.1, 58.400000000000134, 160.39999999999995, 131.59999999999985, 146.9, 154.09999999999994, 41.00000000000013, 113.59999999999994, 67.70000000000016, 155.89999999999995, 166.69999999999993, 130.69999999999965, 98.30000000000005, 158.59999999999997, 164.89999999999995, 153.1999999999999, 184.7, 156.1999999999999, 159.8, 161.8999999999999, 104.59999999999988, 165.79999999999987, 160.3999999999998, 156.8, 161.29999999999995, 119.29999999999993, 174.5, 192.79999999999998, 181.1, 146.59999999999997, 171.20000000000002, 186.49999999999997, 103.69999999999996, 141.19999999999993, 138.1999999999999, 85.69999999999989, 148.39999999999984, 184.69999999999996, 163.1, 196.1, 103.70000000000005, 172.09999999999994, 169.39999999999998, 198.2, 168.49999999999986, 122.29999999999998, 167.3, 184.6999999999999, 163.10000000000002, 147.79999999999995, 163.10000000000002, 143.0, 176.59999999999997, 175.69999999999996, 188.3, 140.5999999999999, 139.99999999999997, 173.89999999999984, 112.99999999999972, 141.2, 123.49999999999974, 139.10000000000002, 132.4999999999996, 153.49999999999997, 178.7, 133.0999999999999, 130.99999999999994, 144.79999999999998, 192.79999999999998, 138.79999999999973, 117.4999999999999, 184.69999999999996, 148.69999999999985, 172.99999999999991, 121.69999999999976, 171.19999999999993, 131.59999999999994, 122.29999999999997, 163.99999999999994, 174.7999999999999, 129.49999999999997, 119.89999999999992, 116.89999999999995, 163.09999999999994, 118.40000000000003, 159.7999999999999, 163.99999999999977, 166.09999999999997, 109.09999999999991, 127.39999999999992, 168.19999999999993, 148.39999999999992, 150.8, 123.20000000000003, 152.2999999999999, 150.49999999999994, 183.79999999999995, 161.29999999999998, 168.2, 191.89999999999998, 177.19999999999996, 181.09999999999994, 157.69999999999993, 186.49999999999997, 172.10000000000002, 136.1, 107.6, 146.89999999999998, 155.89999999999998, 189.20000000000002, 181.10000000000002, 174.79999999999987, 168.5, 136.40000000000003, 162.1999999999999, 182.89999999999998, 131.89999999999992, 190.09999999999994, 163.09999999999997, 175.39999999999998, 101.90000000000005, 184.70000000000002, 104.5999999999998, 137.0, 175.7, 120.80000000000007, 146.90000000000006, 163.4, 175.7, 180.19999999999996, 132.4999999999997, 78.79999999999998, 198.2, 176.59999999999994, 136.10000000000002, 51.200000000000074, 127.09999999999977, 172.99999999999997, 157.0999999999999, 78.19999999999987, 94.10000000000002, 189.19999999999996, 179.3, 163.10000000000002, 187.39999999999998, 171.19999999999993, 148.09999999999985, 196.39999999999998, 129.20000000000005, 177.49999999999994, 134.29999999999987, 192.79999999999995, 154.9999999999999, 92.29999999999987, 59.0000000000001, 123.79999999999998, 159.5, 146.90000000000003, 161.29999999999998, 171.2, 152.29999999999998, 140.89999999999986, 100.39999999999978, 149.00000000000003, 151.40000000000003, 158.29999999999978, 176.59999999999985, 139.40000000000006, 115.99999999999983, 157.69999999999993, 138.8, 158.59999999999997, 174.79999999999998, 159.7999999999999, 135.7999999999999], "policy_predator_policy_reward": [22.0, 18.0, 11.0, 7.0, 0.0, 8.0, 0.0, 14.0, 0.0, 0.0, 0.0, 0.0, 0.0, 18.0, 17.0, 17.0, 0.0, 9.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 19.0, 0.0, 0.0, 0.0, 26.0, 11.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 12.0, 12.0, 0.0, 0.0, 0.0, 7.0, 0.0, 3.0, 0.0, 13.0, 21.0, 13.0, 5.0, 0.0, 0.0, 8.0, 16.0, 8.0, 6.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 9.0, 0.0, 1.0, 12.0, 6.0, 0.0, 17.0, 0.0, 0.0, 5.0, 7.0, 0.0, 0.0, 2.0, 11.0, 2.0, 7.0, 8.0, 7.0, 5.0, 0.0, 11.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 11.0, 12.0, 0.0, 7.0, 0.0, 6.0, 5.0, 18.0, 1.0, 2.0, 0.0, 8.0, 5.0, 1.0, 15.0, 0.0, 5.0, 16.0, 3.0, 9.0, 10.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 11.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 4.0, 8.0, 0.0, 0.0, 4.0, 12.0, 3.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 20.0, 0.0, 0.0, 0.0, 6.0, 12.0, 12.0, 0.0, 12.0, 43.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 11.0, 0.0, 3.0, 3.0, 0.0, 0.0, 22.0, 0.0, 14.0, 5.0, 0.0, 0.0, 15.0, 11.0, 0.0, 11.0, 0.0, 11.0, 1.0, 0.0, 0.0, 23.0, 15.0, 0.0, 0.0, 0.0, 12.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 10.581123908757936, "mean_inference_ms": 23.460221623639082, "mean_action_processing_ms": 5.1241022864660195, "mean_env_wait_ms": 6.765816524255642, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.04273247718811035, "StateBufferConnector_ms": 0.010020017623901367, "ViewRequirementAgentConnector_ms": 0.41019535064697266}, "num_episodes": 23, "episode_return_max": 373.9, "episode_return_min": 173.29999999999941, "episode_return_mean": 305.262, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1904000, "num_agent_steps_trained": 1904000, "num_env_steps_sampled": 476000, "num_env_steps_trained": 476000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 214.75127304764013, "num_env_steps_trained_throughput_per_sec": 214.75127304764013, "timesteps_total": 476000, "num_env_steps_sampled_lifetime": 476000, "num_agent_steps_sampled_lifetime": 1904000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1904000, "timers": {"training_iteration_time_ms": 116573.189, "restore_workers_time_ms": 2.567, "training_step_time_ms": 116566.888, "sample_time_ms": 6137.851, "learn_time_ms": 110394.418, "learn_throughput": 36.234, "synch_weights_time_ms": 28.19}, "counters": {"num_env_steps_sampled": 476000, "num_env_steps_trained": 476000, "num_agent_steps_sampled": 1904000, "num_agent_steps_trained": 1904000}, "done": false, "training_iteration": 119, "trial_id": "75ec3_00000", "date": "2024-08-13_04-44-40", "timestamp": 1723538680, "time_this_iter_s": 18.672707080841064, "time_total_s": 11429.985191583633, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b24b5e50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 11429.985191583633, "iterations_since_restore": 119, "perf": {"cpu_util_percent": 78.27692307692305, "ram_util_percent": 83.54999999999998}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 6.4807182004054384, "cur_kl_coeff": 0.3082418004643842, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.110403472153598, "policy_loss": -0.014324213840959289, "vf_loss": 7.119423891753747, "vf_explained_var": 0.07451840301670094, "kl": 0.017206585402959686, "entropy": 1.0818866343725295, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 225855.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.29335250610377267, "cur_kl_coeff": 1.985233470127266e-24, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.12016757686429032, "policy_loss": -0.00011555445460582931, "vf_loss": 0.12028313149949388, "vf_explained_var": 0.0013275710363236685, "kl": 0.000515205820878166, "entropy": 0.30646781400240286, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 225855.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 480000, "num_env_steps_trained": 480000, "num_agent_steps_sampled": 1920000, "num_agent_steps_trained": 1920000}, "env_runners": {"episode_reward_max": 373.9, "episode_reward_min": 173.29999999999941, "episode_reward_mean": 309.233, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 51.200000000000074, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 198.2, "predator_policy": 43.0}, "policy_reward_mean": {"prey_policy": 150.26149999999996, "predator_policy": 4.355}, "custom_metrics": {}, "hist_stats": {"episode_reward": [270.4999999999999, 326.20000000000095, 330.09999999999985, 305.7999999999999, 373.9, 324.7999999999997, 293.20000000000005, 313.4, 252.0999999999995, 347.79999999999995, 323.79999999999984, 355.5000000000002, 366.70000000000005, 298.6000000000001, 347.79999999999984, 319.8999999999997, 332.6000000000001, 370.0000000000001, 297.60000000000025, 291.9000000000002, 271.69999999999993, 273.5999999999999, 345.19999999999993, 279.1, 349.5999999999999, 267.30000000000007, 336.40000000000066, 294.70000000000005, 302.8000000000003, 309.3000000000001, 311.3000000000004, 242.7999999999999, 304.49999999999994, 326.80000000000075, 283.2, 301.6000000000005, 314.1999999999999, 296.4999999999998, 346.2999999999999, 339.5000000000001, 373.1, 338.80000000000047, 358.60000000000014, 265.69999999999993, 314.8000000000002, 370.3, 343.30000000000064, 309.5999999999997, 326.79999999999995, 353.2000000000003, 293.2999999999998, 292.2999999999997, 315.7, 267.69999999999936, 350.09999999999997, 312.6999999999996, 296.9999999999999, 312.70000000000005, 196.29999999999959, 342.1000000000005, 227.29999999999956, 368.49999999999994, 350.5, 321.30000000000075, 336.5999999999999, 317.8000000000003, 347.8000000000004, 173.29999999999941, 302.29999999999995, 308.1999999999999, 349.50000000000006, 252.29999999999947, 311.4, 335.89999999999986, 278.4000000000002, 311.4999999999999, 333.4000000000003, 308.5999999999997, 327.1, 297.40000000000015, 301.0000000000002, 264.0999999999999, 319.9000000000003, 317.29999999999995, 348.79999999999995, 314.4000000000004, 210.10000000000005, 258.19999999999925, 367.0, 257.29999999999933, 332.70000000000005, 277.5999999999997, 190.99999999999923, 273.0999999999998, 334.70000000000016, 258.4999999999998, 252.49999999999963, 299.6999999999998, 355.9000000000001, 357.7000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [161.8999999999999, 104.59999999999988, 165.79999999999987, 160.3999999999998, 156.8, 161.29999999999995, 119.29999999999993, 174.5, 192.79999999999998, 181.1, 146.59999999999997, 171.20000000000002, 186.49999999999997, 103.69999999999996, 141.19999999999993, 138.1999999999999, 85.69999999999989, 148.39999999999984, 184.69999999999996, 163.1, 196.1, 103.70000000000005, 172.09999999999994, 169.39999999999998, 198.2, 168.49999999999986, 122.29999999999998, 167.3, 184.6999999999999, 163.10000000000002, 147.79999999999995, 163.10000000000002, 143.0, 176.59999999999997, 175.69999999999996, 188.3, 140.5999999999999, 139.99999999999997, 173.89999999999984, 112.99999999999972, 141.2, 123.49999999999974, 139.10000000000002, 132.4999999999996, 153.49999999999997, 178.7, 133.0999999999999, 130.99999999999994, 144.79999999999998, 192.79999999999998, 138.79999999999973, 117.4999999999999, 184.69999999999996, 148.69999999999985, 172.99999999999991, 121.69999999999976, 171.19999999999993, 131.59999999999994, 122.29999999999997, 163.99999999999994, 174.7999999999999, 129.49999999999997, 119.89999999999992, 116.89999999999995, 163.09999999999994, 118.40000000000003, 159.7999999999999, 163.99999999999977, 166.09999999999997, 109.09999999999991, 127.39999999999992, 168.19999999999993, 148.39999999999992, 150.8, 123.20000000000003, 152.2999999999999, 150.49999999999994, 183.79999999999995, 161.29999999999998, 168.2, 191.89999999999998, 177.19999999999996, 181.09999999999994, 157.69999999999993, 186.49999999999997, 172.10000000000002, 136.1, 107.6, 146.89999999999998, 155.89999999999998, 189.20000000000002, 181.10000000000002, 174.79999999999987, 168.5, 136.40000000000003, 162.1999999999999, 182.89999999999998, 131.89999999999992, 190.09999999999994, 163.09999999999997, 175.39999999999998, 101.90000000000005, 184.70000000000002, 104.5999999999998, 137.0, 175.7, 120.80000000000007, 146.90000000000006, 163.4, 175.7, 180.19999999999996, 132.4999999999997, 78.79999999999998, 198.2, 176.59999999999994, 136.10000000000002, 51.200000000000074, 127.09999999999977, 172.99999999999997, 157.0999999999999, 78.19999999999987, 94.10000000000002, 189.19999999999996, 179.3, 163.10000000000002, 187.39999999999998, 171.19999999999993, 148.09999999999985, 196.39999999999998, 129.20000000000005, 177.49999999999994, 134.29999999999987, 192.79999999999995, 154.9999999999999, 92.29999999999987, 59.0000000000001, 123.79999999999998, 159.5, 146.90000000000003, 161.29999999999998, 171.2, 152.29999999999998, 140.89999999999986, 100.39999999999978, 149.00000000000003, 151.40000000000003, 158.29999999999978, 176.59999999999985, 139.40000000000006, 115.99999999999983, 157.69999999999993, 138.8, 158.59999999999997, 174.79999999999998, 159.7999999999999, 135.7999999999999, 129.79999999999998, 197.29999999999998, 147.8, 131.59999999999985, 141.49999999999991, 159.49999999999983, 178.39999999999998, 85.69999999999993, 177.4999999999999, 142.3999999999999, 142.99999999999994, 170.2999999999999, 179.89999999999992, 158.89999999999995, 166.69999999999993, 142.69999999999987, 74.0, 127.1, 110.59999999999968, 140.59999999999985, 173.9, 181.1, 132.1999999999998, 118.09999999999981, 141.79999999999993, 182.89999999999995, 154.99999999999994, 122.5999999999997, 126.19999999999962, 63.80000000000003, 131.59999999999982, 141.50000000000006, 181.09999999999997, 146.59999999999985, 122.89999999999989, 119.6, 107.00000000000001, 123.49999999999972, 169.39999999999992, 128.29999999999973, 183.8, 172.0999999999999, 174.79999999999998, 182.89999999999995], "policy_predator_policy_reward": [0.0, 4.0, 0.0, 0.0, 0.0, 12.0, 12.0, 0.0, 0.0, 0.0, 7.0, 0.0, 3.0, 0.0, 13.0, 21.0, 13.0, 5.0, 0.0, 0.0, 8.0, 16.0, 8.0, 6.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 9.0, 0.0, 1.0, 12.0, 6.0, 0.0, 17.0, 0.0, 0.0, 5.0, 7.0, 0.0, 0.0, 2.0, 11.0, 2.0, 7.0, 8.0, 7.0, 5.0, 0.0, 11.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 11.0, 12.0, 0.0, 7.0, 0.0, 6.0, 5.0, 18.0, 1.0, 2.0, 0.0, 8.0, 5.0, 1.0, 15.0, 0.0, 5.0, 16.0, 3.0, 9.0, 10.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 11.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 4.0, 8.0, 0.0, 0.0, 4.0, 12.0, 3.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 20.0, 0.0, 0.0, 0.0, 6.0, 12.0, 12.0, 0.0, 12.0, 43.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 11.0, 0.0, 3.0, 3.0, 0.0, 0.0, 22.0, 0.0, 14.0, 5.0, 0.0, 0.0, 15.0, 11.0, 0.0, 11.0, 0.0, 11.0, 1.0, 0.0, 0.0, 23.0, 15.0, 0.0, 0.0, 0.0, 12.0, 1.0, 0.0, 0.0, 18.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 9.0, 1.0, 0.0, 5.0, 0.0, 9.0, 4.0, 3.0, 6.0, 6.0, 0.0, 7.0, 8.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 7.0, 16.0, 0.0, 22.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 10.697705723265688, "mean_inference_ms": 23.264865584665213, "mean_action_processing_ms": 4.907753097433219, "mean_env_wait_ms": 6.7196184405252275, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0324864387512207, "StateBufferConnector_ms": 0.010177373886108398, "ViewRequirementAgentConnector_ms": 0.2945972681045532}, "num_episodes": 22, "episode_return_max": 373.9, "episode_return_min": 173.29999999999941, "episode_return_mean": 309.233, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1920000, "num_agent_steps_trained": 1920000, "num_env_steps_sampled": 480000, "num_env_steps_trained": 480000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 210.01662636298747, "num_env_steps_trained_throughput_per_sec": 210.01662636298747, "timesteps_total": 480000, "num_env_steps_sampled_lifetime": 480000, "num_agent_steps_sampled_lifetime": 1920000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1920000, "timers": {"training_iteration_time_ms": 116881.661, "restore_workers_time_ms": 2.568, "training_step_time_ms": 116875.358, "sample_time_ms": 6197.291, "learn_time_ms": 110644.219, "learn_throughput": 36.152, "synch_weights_time_ms": 27.612}, "counters": {"num_env_steps_sampled": 480000, "num_env_steps_trained": 480000, "num_agent_steps_sampled": 1920000, "num_agent_steps_trained": 1920000}, "done": false, "training_iteration": 120, "trial_id": "75ec3_00000", "date": "2024-08-13_04-44-59", "timestamp": 1723538699, "time_this_iter_s": 19.08532977104187, "time_total_s": 11449.070521354675, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2417d30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 11449.070521354675, "iterations_since_restore": 120, "perf": {"cpu_util_percent": 79.72592592592594, "ram_util_percent": 83.54814814814814}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.101492625128024, "cur_kl_coeff": 0.3082418004643842, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.071439421618426, "policy_loss": -0.001362734726659717, "vf_loss": 5.070836668292051, "vf_explained_var": 0.1428437594383482, "kl": 0.006376453228290348, "entropy": 1.0771560352946086, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 227745.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.28126239674018017, "cur_kl_coeff": 9.92616735063633e-25, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.2076951618705477, "policy_loss": -0.00010361194748569417, "vf_loss": 0.20779877433789865, "vf_explained_var": 0.021872732311329513, "kl": 0.001748936442961668, "entropy": 0.34607629209914537, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 227745.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 484000, "num_env_steps_trained": 484000, "num_agent_steps_sampled": 1936000, "num_agent_steps_trained": 1936000}, "env_runners": {"episode_reward_max": 373.1, "episode_reward_min": 173.29999999999941, "episode_reward_mean": 309.691, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 51.200000000000074, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 198.2, "predator_policy": 43.0}, "policy_reward_mean": {"prey_policy": 150.90049999999997, "predator_policy": 3.945}, "custom_metrics": {}, "hist_stats": {"episode_reward": [297.60000000000025, 291.9000000000002, 271.69999999999993, 273.5999999999999, 345.19999999999993, 279.1, 349.5999999999999, 267.30000000000007, 336.40000000000066, 294.70000000000005, 302.8000000000003, 309.3000000000001, 311.3000000000004, 242.7999999999999, 304.49999999999994, 326.80000000000075, 283.2, 301.6000000000005, 314.1999999999999, 296.4999999999998, 346.2999999999999, 339.5000000000001, 373.1, 338.80000000000047, 358.60000000000014, 265.69999999999993, 314.8000000000002, 370.3, 343.30000000000064, 309.5999999999997, 326.79999999999995, 353.2000000000003, 293.2999999999998, 292.2999999999997, 315.7, 267.69999999999936, 350.09999999999997, 312.6999999999996, 296.9999999999999, 312.70000000000005, 196.29999999999959, 342.1000000000005, 227.29999999999956, 368.49999999999994, 350.5, 321.30000000000075, 336.5999999999999, 317.8000000000003, 347.8000000000004, 173.29999999999941, 302.29999999999995, 308.1999999999999, 349.50000000000006, 252.29999999999947, 311.4, 335.89999999999986, 278.4000000000002, 311.4999999999999, 333.4000000000003, 308.5999999999997, 327.1, 297.40000000000015, 301.0000000000002, 264.0999999999999, 319.9000000000003, 317.29999999999995, 348.79999999999995, 314.4000000000004, 210.10000000000005, 258.19999999999925, 367.0, 257.29999999999933, 332.70000000000005, 277.5999999999997, 190.99999999999923, 273.0999999999998, 334.70000000000016, 258.4999999999998, 252.49999999999963, 299.6999999999998, 355.9000000000001, 357.7000000000003, 310.89999999999975, 347.69999999999993, 300.4, 340.6000000000001, 334.1999999999998, 367.0, 359.1000000000003, 316.29999999999995, 330.69999999999993, 315.0999999999999, 311.7999999999999, 318.0999999999998, 331.60000000000036, 354.5, 323.99999999999994, 259.7999999999997, 322.59999999999997, 354.10000000000014], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [140.5999999999999, 139.99999999999997, 173.89999999999984, 112.99999999999972, 141.2, 123.49999999999974, 139.10000000000002, 132.4999999999996, 153.49999999999997, 178.7, 133.0999999999999, 130.99999999999994, 144.79999999999998, 192.79999999999998, 138.79999999999973, 117.4999999999999, 184.69999999999996, 148.69999999999985, 172.99999999999991, 121.69999999999976, 171.19999999999993, 131.59999999999994, 122.29999999999997, 163.99999999999994, 174.7999999999999, 129.49999999999997, 119.89999999999992, 116.89999999999995, 163.09999999999994, 118.40000000000003, 159.7999999999999, 163.99999999999977, 166.09999999999997, 109.09999999999991, 127.39999999999992, 168.19999999999993, 148.39999999999992, 150.8, 123.20000000000003, 152.2999999999999, 150.49999999999994, 183.79999999999995, 161.29999999999998, 168.2, 191.89999999999998, 177.19999999999996, 181.09999999999994, 157.69999999999993, 186.49999999999997, 172.10000000000002, 136.1, 107.6, 146.89999999999998, 155.89999999999998, 189.20000000000002, 181.10000000000002, 174.79999999999987, 168.5, 136.40000000000003, 162.1999999999999, 182.89999999999998, 131.89999999999992, 190.09999999999994, 163.09999999999997, 175.39999999999998, 101.90000000000005, 184.70000000000002, 104.5999999999998, 137.0, 175.7, 120.80000000000007, 146.90000000000006, 163.4, 175.7, 180.19999999999996, 132.4999999999997, 78.79999999999998, 198.2, 176.59999999999994, 136.10000000000002, 51.200000000000074, 127.09999999999977, 172.99999999999997, 157.0999999999999, 78.19999999999987, 94.10000000000002, 189.19999999999996, 179.3, 163.10000000000002, 187.39999999999998, 171.19999999999993, 148.09999999999985, 196.39999999999998, 129.20000000000005, 177.49999999999994, 134.29999999999987, 192.79999999999995, 154.9999999999999, 92.29999999999987, 59.0000000000001, 123.79999999999998, 159.5, 146.90000000000003, 161.29999999999998, 171.2, 152.29999999999998, 140.89999999999986, 100.39999999999978, 149.00000000000003, 151.40000000000003, 158.29999999999978, 176.59999999999985, 139.40000000000006, 115.99999999999983, 157.69999999999993, 138.8, 158.59999999999997, 174.79999999999998, 159.7999999999999, 135.7999999999999, 129.79999999999998, 197.29999999999998, 147.8, 131.59999999999985, 141.49999999999991, 159.49999999999983, 178.39999999999998, 85.69999999999993, 177.4999999999999, 142.3999999999999, 142.99999999999994, 170.2999999999999, 179.89999999999992, 158.89999999999995, 166.69999999999993, 142.69999999999987, 74.0, 127.1, 110.59999999999968, 140.59999999999985, 173.9, 181.1, 132.1999999999998, 118.09999999999981, 141.79999999999993, 182.89999999999995, 154.99999999999994, 122.5999999999997, 126.19999999999962, 63.80000000000003, 131.59999999999982, 141.50000000000006, 181.09999999999997, 146.59999999999985, 122.89999999999989, 119.6, 107.00000000000001, 123.49999999999972, 169.39999999999992, 128.29999999999973, 183.8, 172.0999999999999, 174.79999999999998, 182.89999999999995, 137.00000000000003, 167.8999999999999, 158.0, 184.7, 136.09999999999985, 155.3, 165.7999999999999, 174.8, 178.4, 150.80000000000004, 184.1, 170.89999999999998, 170.89999999999992, 183.19999999999993, 154.99999999999997, 161.3, 192.79999999999995, 128.90000000000003, 184.7, 115.39999999999978, 155.9, 155.9, 167.59999999999982, 150.49999999999994, 167.59999999999982, 163.99999999999994, 164.6, 182.9, 179.6, 142.39999999999986, 130.99999999999997, 120.80000000000007, 149.5999999999999, 172.99999999999997, 164.0, 190.09999999999994], "policy_predator_policy_reward": [17.0, 0.0, 0.0, 5.0, 7.0, 0.0, 0.0, 2.0, 11.0, 2.0, 7.0, 8.0, 7.0, 5.0, 0.0, 11.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 11.0, 12.0, 0.0, 7.0, 0.0, 6.0, 5.0, 18.0, 1.0, 2.0, 0.0, 8.0, 5.0, 1.0, 15.0, 0.0, 5.0, 16.0, 3.0, 9.0, 10.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 11.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 4.0, 8.0, 0.0, 0.0, 4.0, 12.0, 3.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 20.0, 0.0, 0.0, 0.0, 6.0, 12.0, 12.0, 0.0, 12.0, 43.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 11.0, 0.0, 3.0, 3.0, 0.0, 0.0, 22.0, 0.0, 14.0, 5.0, 0.0, 0.0, 15.0, 11.0, 0.0, 11.0, 0.0, 11.0, 1.0, 0.0, 0.0, 23.0, 15.0, 0.0, 0.0, 0.0, 12.0, 1.0, 0.0, 0.0, 18.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 9.0, 1.0, 0.0, 5.0, 0.0, 9.0, 4.0, 3.0, 6.0, 6.0, 0.0, 7.0, 8.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 7.0, 16.0, 0.0, 22.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 5.0, 7.0, 2.0, 0.0, 0.0, 5.0, 0.0, 12.0, 0.0, 4.0, 1.0, 0.0, 0.0, 9.0, 0.0, 3.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 2.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 10.429778867628507, "mean_inference_ms": 23.148579960915256, "mean_action_processing_ms": 5.054103985235794, "mean_env_wait_ms": 6.652018169391554, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.009342312812805176, "StateBufferConnector_ms": 0.00758206844329834, "ViewRequirementAgentConnector_ms": 0.18455421924591064}, "num_episodes": 18, "episode_return_max": 373.1, "episode_return_min": 173.29999999999941, "episode_return_mean": 309.691, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1936000, "num_agent_steps_trained": 1936000, "num_env_steps_sampled": 484000, "num_env_steps_trained": 484000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 214.31434567422914, "num_env_steps_trained_throughput_per_sec": 214.31434567422914, "timesteps_total": 484000, "num_env_steps_sampled_lifetime": 484000, "num_agent_steps_sampled_lifetime": 1936000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1936000, "timers": {"training_iteration_time_ms": 117061.602, "restore_workers_time_ms": 2.568, "training_step_time_ms": 117055.299, "sample_time_ms": 6105.383, "learn_time_ms": 110916.488, "learn_throughput": 36.063, "synch_weights_time_ms": 27.268}, "counters": {"num_env_steps_sampled": 484000, "num_env_steps_trained": 484000, "num_agent_steps_sampled": 1936000, "num_agent_steps_trained": 1936000}, "done": false, "training_iteration": 121, "trial_id": "75ec3_00000", "date": "2024-08-13_04-45-18", "timestamp": 1723538718, "time_this_iter_s": 18.70374584197998, "time_total_s": 11467.774267196655, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b24b5f70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 11467.774267196655, "iterations_since_restore": 121, "perf": {"cpu_util_percent": 78.68888888888888, "ram_util_percent": 83.32592592592592}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.332248082362786, "cur_kl_coeff": 0.3082418004643842, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.16600638457707, "policy_loss": -0.003191709480120273, "vf_loss": 5.1661523854291, "vf_explained_var": 0.1445485406451755, "kl": 0.009880935800888134, "entropy": 1.0642738119004265, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 229635.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6125454196598006, "cur_kl_coeff": 4.963083675318165e-25, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.770816038682978, "policy_loss": -0.0007869532573278303, "vf_loss": 0.7716029888107663, "vf_explained_var": 0.004619276838958579, "kl": 0.002017334323793669, "entropy": 0.3656479175759371, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 229635.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 488000, "num_env_steps_trained": 488000, "num_agent_steps_sampled": 1952000, "num_agent_steps_trained": 1952000}, "env_runners": {"episode_reward_max": 373.1, "episode_reward_min": 173.29999999999941, "episode_reward_mean": 315.846, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 51.200000000000074, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 198.2, "predator_policy": 43.0}, "policy_reward_mean": {"prey_policy": 154.28299999999996, "predator_policy": 3.64}, "custom_metrics": {}, "hist_stats": {"episode_reward": [314.1999999999999, 296.4999999999998, 346.2999999999999, 339.5000000000001, 373.1, 338.80000000000047, 358.60000000000014, 265.69999999999993, 314.8000000000002, 370.3, 343.30000000000064, 309.5999999999997, 326.79999999999995, 353.2000000000003, 293.2999999999998, 292.2999999999997, 315.7, 267.69999999999936, 350.09999999999997, 312.6999999999996, 296.9999999999999, 312.70000000000005, 196.29999999999959, 342.1000000000005, 227.29999999999956, 368.49999999999994, 350.5, 321.30000000000075, 336.5999999999999, 317.8000000000003, 347.8000000000004, 173.29999999999941, 302.29999999999995, 308.1999999999999, 349.50000000000006, 252.29999999999947, 311.4, 335.89999999999986, 278.4000000000002, 311.4999999999999, 333.4000000000003, 308.5999999999997, 327.1, 297.40000000000015, 301.0000000000002, 264.0999999999999, 319.9000000000003, 317.29999999999995, 348.79999999999995, 314.4000000000004, 210.10000000000005, 258.19999999999925, 367.0, 257.29999999999933, 332.70000000000005, 277.5999999999997, 190.99999999999923, 273.0999999999998, 334.70000000000016, 258.4999999999998, 252.49999999999963, 299.6999999999998, 355.9000000000001, 357.7000000000003, 310.89999999999975, 347.69999999999993, 300.4, 340.6000000000001, 334.1999999999998, 367.0, 359.1000000000003, 316.29999999999995, 330.69999999999993, 315.0999999999999, 311.7999999999999, 318.0999999999998, 331.60000000000036, 354.5, 323.99999999999994, 259.7999999999997, 322.59999999999997, 354.10000000000014, 306.1999999999999, 344.20000000000005, 355.9000000000003, 342.4000000000002, 299.99999999999994, 359.5000000000001, 360.4, 362.5, 331.19999999999993, 340.5999999999999, 311.70000000000016, 328.20000000000016, 316.5000000000002, 309.49999999999966, 362.20000000000016, 337.89999999999986, 301.19999999999993, 334.80000000000035], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [148.39999999999992, 150.8, 123.20000000000003, 152.2999999999999, 150.49999999999994, 183.79999999999995, 161.29999999999998, 168.2, 191.89999999999998, 177.19999999999996, 181.09999999999994, 157.69999999999993, 186.49999999999997, 172.10000000000002, 136.1, 107.6, 146.89999999999998, 155.89999999999998, 189.20000000000002, 181.10000000000002, 174.79999999999987, 168.5, 136.40000000000003, 162.1999999999999, 182.89999999999998, 131.89999999999992, 190.09999999999994, 163.09999999999997, 175.39999999999998, 101.90000000000005, 184.70000000000002, 104.5999999999998, 137.0, 175.7, 120.80000000000007, 146.90000000000006, 163.4, 175.7, 180.19999999999996, 132.4999999999997, 78.79999999999998, 198.2, 176.59999999999994, 136.10000000000002, 51.200000000000074, 127.09999999999977, 172.99999999999997, 157.0999999999999, 78.19999999999987, 94.10000000000002, 189.19999999999996, 179.3, 163.10000000000002, 187.39999999999998, 171.19999999999993, 148.09999999999985, 196.39999999999998, 129.20000000000005, 177.49999999999994, 134.29999999999987, 192.79999999999995, 154.9999999999999, 92.29999999999987, 59.0000000000001, 123.79999999999998, 159.5, 146.90000000000003, 161.29999999999998, 171.2, 152.29999999999998, 140.89999999999986, 100.39999999999978, 149.00000000000003, 151.40000000000003, 158.29999999999978, 176.59999999999985, 139.40000000000006, 115.99999999999983, 157.69999999999993, 138.8, 158.59999999999997, 174.79999999999998, 159.7999999999999, 135.7999999999999, 129.79999999999998, 197.29999999999998, 147.8, 131.59999999999985, 141.49999999999991, 159.49999999999983, 178.39999999999998, 85.69999999999993, 177.4999999999999, 142.3999999999999, 142.99999999999994, 170.2999999999999, 179.89999999999992, 158.89999999999995, 166.69999999999993, 142.69999999999987, 74.0, 127.1, 110.59999999999968, 140.59999999999985, 173.9, 181.1, 132.1999999999998, 118.09999999999981, 141.79999999999993, 182.89999999999995, 154.99999999999994, 122.5999999999997, 126.19999999999962, 63.80000000000003, 131.59999999999982, 141.50000000000006, 181.09999999999997, 146.59999999999985, 122.89999999999989, 119.6, 107.00000000000001, 123.49999999999972, 169.39999999999992, 128.29999999999973, 183.8, 172.0999999999999, 174.79999999999998, 182.89999999999995, 137.00000000000003, 167.8999999999999, 158.0, 184.7, 136.09999999999985, 155.3, 165.7999999999999, 174.8, 178.4, 150.80000000000004, 184.1, 170.89999999999998, 170.89999999999992, 183.19999999999993, 154.99999999999997, 161.3, 192.79999999999995, 128.90000000000003, 184.7, 115.39999999999978, 155.9, 155.9, 167.59999999999982, 150.49999999999994, 167.59999999999982, 163.99999999999994, 164.6, 182.9, 179.6, 142.39999999999986, 130.99999999999997, 120.80000000000007, 149.5999999999999, 172.99999999999997, 164.0, 190.09999999999994, 151.09999999999994, 145.09999999999997, 163.99999999999991, 180.19999999999993, 179.5999999999999, 167.29999999999993, 153.19999999999993, 189.19999999999996, 172.99999999999994, 122.0, 187.4, 172.09999999999982, 182.0, 178.4, 165.79999999999995, 193.69999999999996, 169.4, 141.79999999999998, 165.8, 174.79999999999998, 130.09999999999994, 176.5999999999999, 153.49999999999997, 160.7, 152.59999999999988, 155.89999999999998, 175.69999999999985, 117.80000000000004, 182.0, 180.19999999999996, 172.99999999999991, 164.89999999999992, 132.79999999999976, 160.39999999999995, 153.49999999999994, 179.29999999999998], "policy_predator_policy_reward": [15.0, 0.0, 5.0, 16.0, 3.0, 9.0, 10.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 11.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 4.0, 8.0, 0.0, 0.0, 4.0, 12.0, 3.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 20.0, 0.0, 0.0, 0.0, 6.0, 12.0, 12.0, 0.0, 12.0, 43.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 11.0, 0.0, 3.0, 3.0, 0.0, 0.0, 22.0, 0.0, 14.0, 5.0, 0.0, 0.0, 15.0, 11.0, 0.0, 11.0, 0.0, 11.0, 1.0, 0.0, 0.0, 23.0, 15.0, 0.0, 0.0, 0.0, 12.0, 1.0, 0.0, 0.0, 18.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 9.0, 1.0, 0.0, 5.0, 0.0, 9.0, 4.0, 3.0, 6.0, 6.0, 0.0, 7.0, 8.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 7.0, 16.0, 0.0, 22.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 5.0, 7.0, 2.0, 0.0, 0.0, 5.0, 0.0, 12.0, 0.0, 4.0, 1.0, 0.0, 0.0, 9.0, 0.0, 3.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 2.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 7.0, 2.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 7.0, 13.0, 0.0, 0.0, 5.0, 0.0, 14.0, 0.0, 8.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 5.0, 3.0, 0.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 10.359389927243862, "mean_inference_ms": 22.9973403879953, "mean_action_processing_ms": 5.018876364166604, "mean_env_wait_ms": 6.604567386740934, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00971376895904541, "StateBufferConnector_ms": 0.007667660713195801, "ViewRequirementAgentConnector_ms": 0.18739056587219238}, "num_episodes": 18, "episode_return_max": 373.1, "episode_return_min": 173.29999999999941, "episode_return_mean": 315.846, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1952000, "num_agent_steps_trained": 1952000, "num_env_steps_sampled": 488000, "num_env_steps_trained": 488000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 215.9570442422155, "num_env_steps_trained_throughput_per_sec": 215.9570442422155, "timesteps_total": 488000, "num_env_steps_sampled_lifetime": 488000, "num_agent_steps_sampled_lifetime": 1952000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1952000, "timers": {"training_iteration_time_ms": 114273.611, "restore_workers_time_ms": 0.332, "training_step_time_ms": 114272.651, "sample_time_ms": 4661.548, "learn_time_ms": 109583.735, "learn_throughput": 36.502, "synch_weights_time_ms": 22.358}, "counters": {"num_env_steps_sampled": 488000, "num_env_steps_trained": 488000, "num_agent_steps_sampled": 1952000, "num_agent_steps_trained": 1952000}, "done": false, "training_iteration": 122, "trial_id": "75ec3_00000", "date": "2024-08-13_04-45-37", "timestamp": 1723538737, "time_this_iter_s": 18.57748317718506, "time_total_s": 11486.35175037384, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b24099d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 11486.35175037384, "iterations_since_restore": 122, "perf": {"cpu_util_percent": 80.13846153846154, "ram_util_percent": 83.41153846153846}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.8427863399187725, "cur_kl_coeff": 0.3082418004643842, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.673556373863624, "policy_loss": -0.01105560257380444, "vf_loss": 4.6797800182665465, "vf_explained_var": 0.23544809064537128, "kl": 0.015675866941829174, "entropy": 1.054305193853126, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 231525.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.2070351809765848, "cur_kl_coeff": 2.4815418376590825e-25, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.108523528677505, "policy_loss": -0.00022020570603667428, "vf_loss": 0.10874373432133032, "vf_explained_var": -0.021922359517011693, "kl": 0.0012266557636084613, "entropy": 0.38202510458767097, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 231525.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 492000, "num_env_steps_trained": 492000, "num_agent_steps_sampled": 1968000, "num_agent_steps_trained": 1968000}, "env_runners": {"episode_reward_max": 375.70000000000005, "episode_reward_min": 173.29999999999941, "episode_reward_mean": 318.452, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 59.0000000000001, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 198.2, "predator_policy": 43.0}, "policy_reward_mean": {"prey_policy": 155.74099999999996, "predator_policy": 3.485}, "custom_metrics": {}, "hist_stats": {"episode_reward": [342.1000000000005, 227.29999999999956, 368.49999999999994, 350.5, 321.30000000000075, 336.5999999999999, 317.8000000000003, 347.8000000000004, 173.29999999999941, 302.29999999999995, 308.1999999999999, 349.50000000000006, 252.29999999999947, 311.4, 335.89999999999986, 278.4000000000002, 311.4999999999999, 333.4000000000003, 308.5999999999997, 327.1, 297.40000000000015, 301.0000000000002, 264.0999999999999, 319.9000000000003, 317.29999999999995, 348.79999999999995, 314.4000000000004, 210.10000000000005, 258.19999999999925, 367.0, 257.29999999999933, 332.70000000000005, 277.5999999999997, 190.99999999999923, 273.0999999999998, 334.70000000000016, 258.4999999999998, 252.49999999999963, 299.6999999999998, 355.9000000000001, 357.7000000000003, 310.89999999999975, 347.69999999999993, 300.4, 340.6000000000001, 334.1999999999998, 367.0, 359.1000000000003, 316.29999999999995, 330.69999999999993, 315.0999999999999, 311.7999999999999, 318.0999999999998, 331.60000000000036, 354.5, 323.99999999999994, 259.7999999999997, 322.59999999999997, 354.10000000000014, 306.1999999999999, 344.20000000000005, 355.9000000000003, 342.4000000000002, 299.99999999999994, 359.5000000000001, 360.4, 362.5, 331.19999999999993, 340.5999999999999, 311.70000000000016, 328.20000000000016, 316.5000000000002, 309.49999999999966, 362.20000000000016, 337.89999999999986, 301.19999999999993, 334.80000000000035, 340.4000000000002, 294.30000000000007, 351.5000000000002, 303.29999999999995, 287.50000000000034, 365.79999999999995, 354.7999999999999, 318.1, 308.49999999999966, 326.59999999999974, 347.79999999999995, 266.29999999999984, 352.3000000000004, 353.2, 277.69999999999993, 299.70000000000005, 352.29999999999984, 335.29999999999995, 355.9, 331.1000000000002, 315.80000000000007, 375.70000000000005, 335.1999999999998], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [172.99999999999997, 157.0999999999999, 78.19999999999987, 94.10000000000002, 189.19999999999996, 179.3, 163.10000000000002, 187.39999999999998, 171.19999999999993, 148.09999999999985, 196.39999999999998, 129.20000000000005, 177.49999999999994, 134.29999999999987, 192.79999999999995, 154.9999999999999, 92.29999999999987, 59.0000000000001, 123.79999999999998, 159.5, 146.90000000000003, 161.29999999999998, 171.2, 152.29999999999998, 140.89999999999986, 100.39999999999978, 149.00000000000003, 151.40000000000003, 158.29999999999978, 176.59999999999985, 139.40000000000006, 115.99999999999983, 157.69999999999993, 138.8, 158.59999999999997, 174.79999999999998, 159.7999999999999, 135.7999999999999, 129.79999999999998, 197.29999999999998, 147.8, 131.59999999999985, 141.49999999999991, 159.49999999999983, 178.39999999999998, 85.69999999999993, 177.4999999999999, 142.3999999999999, 142.99999999999994, 170.2999999999999, 179.89999999999992, 158.89999999999995, 166.69999999999993, 142.69999999999987, 74.0, 127.1, 110.59999999999968, 140.59999999999985, 173.9, 181.1, 132.1999999999998, 118.09999999999981, 141.79999999999993, 182.89999999999995, 154.99999999999994, 122.5999999999997, 126.19999999999962, 63.80000000000003, 131.59999999999982, 141.50000000000006, 181.09999999999997, 146.59999999999985, 122.89999999999989, 119.6, 107.00000000000001, 123.49999999999972, 169.39999999999992, 128.29999999999973, 183.8, 172.0999999999999, 174.79999999999998, 182.89999999999995, 137.00000000000003, 167.8999999999999, 158.0, 184.7, 136.09999999999985, 155.3, 165.7999999999999, 174.8, 178.4, 150.80000000000004, 184.1, 170.89999999999998, 170.89999999999992, 183.19999999999993, 154.99999999999997, 161.3, 192.79999999999995, 128.90000000000003, 184.7, 115.39999999999978, 155.9, 155.9, 167.59999999999982, 150.49999999999994, 167.59999999999982, 163.99999999999994, 164.6, 182.9, 179.6, 142.39999999999986, 130.99999999999997, 120.80000000000007, 149.5999999999999, 172.99999999999997, 164.0, 190.09999999999994, 151.09999999999994, 145.09999999999997, 163.99999999999991, 180.19999999999993, 179.5999999999999, 167.29999999999993, 153.19999999999993, 189.19999999999996, 172.99999999999994, 122.0, 187.4, 172.09999999999982, 182.0, 178.4, 165.79999999999995, 193.69999999999996, 169.4, 141.79999999999998, 165.8, 174.79999999999998, 130.09999999999994, 176.5999999999999, 153.49999999999997, 160.7, 152.59999999999988, 155.89999999999998, 175.69999999999985, 117.80000000000004, 182.0, 180.19999999999996, 172.99999999999991, 164.89999999999992, 132.79999999999976, 160.39999999999995, 153.49999999999994, 179.29999999999998, 168.49999999999991, 161.89999999999995, 168.49999999999997, 114.80000000000007, 174.79999999999995, 172.7, 148.69999999999993, 152.59999999999994, 155.89999999999986, 131.59999999999965, 179.3, 186.49999999999994, 171.19999999999993, 173.59999999999997, 137.0, 181.09999999999997, 141.49999999999977, 152.0, 154.7, 164.8999999999998, 173.89999999999995, 173.89999999999986, 151.70000000000002, 74.60000000000002, 174.79999999999998, 177.49999999999991, 160.39999999999998, 183.8, 102.50000000000003, 162.2, 152.6, 136.0999999999999, 192.79999999999998, 159.49999999999997, 172.09999999999997, 150.2, 182.89999999999995, 173.0, 142.09999999999977, 182.0, 140.59999999999997, 168.2, 177.49999999999997, 198.2, 190.99999999999994, 144.2], "policy_predator_policy_reward": [12.0, 0.0, 12.0, 43.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 11.0, 0.0, 3.0, 3.0, 0.0, 0.0, 22.0, 0.0, 14.0, 5.0, 0.0, 0.0, 15.0, 11.0, 0.0, 11.0, 0.0, 11.0, 1.0, 0.0, 0.0, 23.0, 15.0, 0.0, 0.0, 0.0, 12.0, 1.0, 0.0, 0.0, 18.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 9.0, 1.0, 0.0, 5.0, 0.0, 9.0, 4.0, 3.0, 6.0, 6.0, 0.0, 7.0, 8.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 7.0, 16.0, 0.0, 22.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 5.0, 7.0, 2.0, 0.0, 0.0, 5.0, 0.0, 12.0, 0.0, 4.0, 1.0, 0.0, 0.0, 9.0, 0.0, 3.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 2.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 7.0, 2.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 7.0, 13.0, 0.0, 0.0, 5.0, 0.0, 14.0, 0.0, 8.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 5.0, 3.0, 0.0, 2.0, 10.0, 0.0, 11.0, 0.0, 4.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 5.0, 10.0, 0.0, 7.0, 0.0, 0.0, 8.0, 32.0, 0.0, 0.0, 0.0, 9.0, 13.0, 0.0, 11.0, 0.0, 0.0, 0.0, 6.0, 7.0, 0.0, 0.0, 7.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 10.454069799659393, "mean_inference_ms": 23.18076578830772, "mean_action_processing_ms": 5.164906917559093, "mean_env_wait_ms": 5.819238703496082, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.009999513626098633, "StateBufferConnector_ms": 0.0076978206634521484, "ViewRequirementAgentConnector_ms": 0.18906891345977783}, "num_episodes": 23, "episode_return_max": 375.70000000000005, "episode_return_min": 173.29999999999941, "episode_return_mean": 318.452, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1968000, "num_agent_steps_trained": 1968000, "num_env_steps_sampled": 492000, "num_env_steps_trained": 492000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 204.55749000400758, "num_env_steps_trained_throughput_per_sec": 204.55749000400758, "timesteps_total": 492000, "num_env_steps_sampled_lifetime": 492000, "num_agent_steps_sampled_lifetime": 1968000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1968000, "timers": {"training_iteration_time_ms": 114410.253, "restore_workers_time_ms": 0.332, "training_step_time_ms": 114409.293, "sample_time_ms": 4517.683, "learn_time_ms": 109863.4, "learn_throughput": 36.409, "synch_weights_time_ms": 22.771}, "counters": {"num_env_steps_sampled": 492000, "num_env_steps_trained": 492000, "num_agent_steps_sampled": 1968000, "num_agent_steps_trained": 1968000}, "done": false, "training_iteration": 123, "trial_id": "75ec3_00000", "date": "2024-08-13_04-45-56", "timestamp": 1723538756, "time_this_iter_s": 19.607609033584595, "time_total_s": 11505.959359407425, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b223a1f0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 11505.959359407425, "iterations_since_restore": 123, "perf": {"cpu_util_percent": 80.93928571428572, "ram_util_percent": 83.4857142857143}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.203346619214961, "cur_kl_coeff": 0.3082418004643842, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.937457839143339, "policy_loss": -0.013172020289120536, "vf_loss": 4.944685376384271, "vf_explained_var": 0.20412328113954534, "kl": 0.019285161421925226, "entropy": 1.054243249048001, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 233415.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6386953416364218, "cur_kl_coeff": 1.2407709188295412e-25, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.0653576906395967, "policy_loss": -0.0015114118266239683, "vf_loss": 1.0668691031516544, "vf_explained_var": 0.02703207601945867, "kl": 0.0029379450746185574, "entropy": 0.37434310723864844, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 233415.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 496000, "num_env_steps_trained": 496000, "num_agent_steps_sampled": 1984000, "num_agent_steps_trained": 1984000}, "env_runners": {"episode_reward_max": 375.70000000000005, "episode_reward_min": 190.99999999999923, "episode_reward_mean": 321.633, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 63.80000000000003, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 198.2, "predator_policy": 32.0}, "policy_reward_mean": {"prey_policy": 157.71649999999997, "predator_policy": 3.1}, "custom_metrics": {}, "hist_stats": {"episode_reward": [308.5999999999997, 327.1, 297.40000000000015, 301.0000000000002, 264.0999999999999, 319.9000000000003, 317.29999999999995, 348.79999999999995, 314.4000000000004, 210.10000000000005, 258.19999999999925, 367.0, 257.29999999999933, 332.70000000000005, 277.5999999999997, 190.99999999999923, 273.0999999999998, 334.70000000000016, 258.4999999999998, 252.49999999999963, 299.6999999999998, 355.9000000000001, 357.7000000000003, 310.89999999999975, 347.69999999999993, 300.4, 340.6000000000001, 334.1999999999998, 367.0, 359.1000000000003, 316.29999999999995, 330.69999999999993, 315.0999999999999, 311.7999999999999, 318.0999999999998, 331.60000000000036, 354.5, 323.99999999999994, 259.7999999999997, 322.59999999999997, 354.10000000000014, 306.1999999999999, 344.20000000000005, 355.9000000000003, 342.4000000000002, 299.99999999999994, 359.5000000000001, 360.4, 362.5, 331.19999999999993, 340.5999999999999, 311.70000000000016, 328.20000000000016, 316.5000000000002, 309.49999999999966, 362.20000000000016, 337.89999999999986, 301.19999999999993, 334.80000000000035, 340.4000000000002, 294.30000000000007, 351.5000000000002, 303.29999999999995, 287.50000000000034, 365.79999999999995, 354.7999999999999, 318.1, 308.49999999999966, 326.59999999999974, 347.79999999999995, 266.29999999999984, 352.3000000000004, 353.2, 277.69999999999993, 299.70000000000005, 352.29999999999984, 335.29999999999995, 355.9, 331.1000000000002, 315.80000000000007, 375.70000000000005, 335.1999999999998, 350.7999999999999, 348.5999999999999, 321.79999999999995, 300.19999999999976, 360.4000000000002, 333.20000000000005, 344.19999999999993, 361.5000000000003, 328.80000000000007, 356.5, 273.29999999999984, 368.5, 299.1999999999998, 301.8999999999997, 374.5999999999999, 275.2999999999999, 282.09999999999985, 305.29999999999995], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [159.7999999999999, 135.7999999999999, 129.79999999999998, 197.29999999999998, 147.8, 131.59999999999985, 141.49999999999991, 159.49999999999983, 178.39999999999998, 85.69999999999993, 177.4999999999999, 142.3999999999999, 142.99999999999994, 170.2999999999999, 179.89999999999992, 158.89999999999995, 166.69999999999993, 142.69999999999987, 74.0, 127.1, 110.59999999999968, 140.59999999999985, 173.9, 181.1, 132.1999999999998, 118.09999999999981, 141.79999999999993, 182.89999999999995, 154.99999999999994, 122.5999999999997, 126.19999999999962, 63.80000000000003, 131.59999999999982, 141.50000000000006, 181.09999999999997, 146.59999999999985, 122.89999999999989, 119.6, 107.00000000000001, 123.49999999999972, 169.39999999999992, 128.29999999999973, 183.8, 172.0999999999999, 174.79999999999998, 182.89999999999995, 137.00000000000003, 167.8999999999999, 158.0, 184.7, 136.09999999999985, 155.3, 165.7999999999999, 174.8, 178.4, 150.80000000000004, 184.1, 170.89999999999998, 170.89999999999992, 183.19999999999993, 154.99999999999997, 161.3, 192.79999999999995, 128.90000000000003, 184.7, 115.39999999999978, 155.9, 155.9, 167.59999999999982, 150.49999999999994, 167.59999999999982, 163.99999999999994, 164.6, 182.9, 179.6, 142.39999999999986, 130.99999999999997, 120.80000000000007, 149.5999999999999, 172.99999999999997, 164.0, 190.09999999999994, 151.09999999999994, 145.09999999999997, 163.99999999999991, 180.19999999999993, 179.5999999999999, 167.29999999999993, 153.19999999999993, 189.19999999999996, 172.99999999999994, 122.0, 187.4, 172.09999999999982, 182.0, 178.4, 165.79999999999995, 193.69999999999996, 169.4, 141.79999999999998, 165.8, 174.79999999999998, 130.09999999999994, 176.5999999999999, 153.49999999999997, 160.7, 152.59999999999988, 155.89999999999998, 175.69999999999985, 117.80000000000004, 182.0, 180.19999999999996, 172.99999999999991, 164.89999999999992, 132.79999999999976, 160.39999999999995, 153.49999999999994, 179.29999999999998, 168.49999999999991, 161.89999999999995, 168.49999999999997, 114.80000000000007, 174.79999999999995, 172.7, 148.69999999999993, 152.59999999999994, 155.89999999999986, 131.59999999999965, 179.3, 186.49999999999994, 171.19999999999993, 173.59999999999997, 137.0, 181.09999999999997, 141.49999999999977, 152.0, 154.7, 164.8999999999998, 173.89999999999995, 173.89999999999986, 151.70000000000002, 74.60000000000002, 174.79999999999998, 177.49999999999991, 160.39999999999998, 183.8, 102.50000000000003, 162.2, 152.6, 136.0999999999999, 192.79999999999998, 159.49999999999997, 172.09999999999997, 150.2, 182.89999999999995, 173.0, 142.09999999999977, 182.0, 140.59999999999997, 168.2, 177.49999999999997, 198.2, 190.99999999999994, 144.2, 184.70000000000002, 163.10000000000002, 146.59999999999985, 188.0, 154.99999999999997, 156.79999999999993, 160.9999999999999, 123.19999999999992, 191.0, 169.39999999999992, 176.6, 137.59999999999994, 157.7, 186.49999999999997, 197.29999999999998, 156.19999999999993, 125.59999999999987, 198.2, 190.99999999999997, 159.5, 146.0, 119.30000000000007, 180.19999999999993, 188.3, 173.0, 117.19999999999993, 191.9, 110.00000000000001, 185.5999999999999, 187.99999999999997, 90.20000000000002, 157.09999999999994, 145.1, 137.00000000000003, 154.99999999999997, 140.29999999999998], "policy_predator_policy_reward": [12.0, 1.0, 0.0, 0.0, 18.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 9.0, 1.0, 0.0, 5.0, 0.0, 9.0, 4.0, 3.0, 6.0, 6.0, 0.0, 7.0, 8.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 7.0, 16.0, 0.0, 22.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 5.0, 7.0, 2.0, 0.0, 0.0, 5.0, 0.0, 12.0, 0.0, 4.0, 1.0, 0.0, 0.0, 9.0, 0.0, 3.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 2.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 7.0, 2.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 7.0, 13.0, 0.0, 0.0, 5.0, 0.0, 14.0, 0.0, 8.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 5.0, 3.0, 0.0, 2.0, 10.0, 0.0, 11.0, 0.0, 4.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 5.0, 10.0, 0.0, 7.0, 0.0, 0.0, 8.0, 32.0, 0.0, 0.0, 0.0, 9.0, 13.0, 0.0, 11.0, 0.0, 0.0, 0.0, 6.0, 7.0, 0.0, 0.0, 7.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 5.0, 9.0, 10.0, 0.0, 0.0, 16.0, 0.0, 0.0, 7.0, 12.0, 0.0, 0.0, 0.0, 8.0, 0.0, 5.0, 6.0, 0.0, 8.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 28.0, 0.0, 0.0, 0.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 10.925097643294263, "mean_inference_ms": 24.457274057084668, "mean_action_processing_ms": 5.294517850275239, "mean_env_wait_ms": 6.869733917066192, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007437348365783691, "StateBufferConnector_ms": 0.007942557334899902, "ViewRequirementAgentConnector_ms": 0.27104032039642334}, "num_episodes": 18, "episode_return_max": 375.70000000000005, "episode_return_min": 190.99999999999923, "episode_return_mean": 321.633, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1984000, "num_agent_steps_trained": 1984000, "num_env_steps_sampled": 496000, "num_env_steps_trained": 496000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 3.957527913774319, "num_env_steps_trained_throughput_per_sec": 3.957527913774319, "timesteps_total": 496000, "num_env_steps_sampled_lifetime": 496000, "num_agent_steps_sampled_lifetime": 1984000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1984000, "timers": {"training_iteration_time_ms": 212687.689, "restore_workers_time_ms": 0.018, "training_step_time_ms": 212687.626, "sample_time_ms": 102322.362, "learn_time_ms": 110339.611, "learn_throughput": 36.252, "synch_weights_time_ms": 20.138}, "counters": {"num_env_steps_sampled": 496000, "num_env_steps_trained": 496000, "num_agent_steps_sampled": 1984000, "num_agent_steps_trained": 1984000}, "done": false, "training_iteration": 124, "trial_id": "75ec3_00000", "date": "2024-08-13_05-02-47", "timestamp": 1723539767, "time_this_iter_s": 1010.7952101230621, "time_total_s": 12516.754569530487, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b24c18b0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 12516.754569530487, "iterations_since_restore": 124, "perf": {"cpu_util_percent": 91.95, "ram_util_percent": 83.1925}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 6.962366288837302, "cur_kl_coeff": 0.3082418004643842, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.935212261714632, "policy_loss": -0.01591506218771751, "vf_loss": 5.945156810901783, "vf_explained_var": 0.2743011529798861, "kl": 0.01936951232394069, "entropy": 1.010110689407934, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 235305.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.34633813280040626, "cur_kl_coeff": 6.203854594147706e-26, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.19023606366423704, "policy_loss": -0.0008155558483734254, "vf_loss": 0.19105161976281101, "vf_explained_var": 0.014196219835331831, "kl": 0.002503114207715178, "entropy": 0.3895882504326957, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 235305.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 500000, "num_env_steps_trained": 500000, "num_agent_steps_sampled": 2000000, "num_agent_steps_trained": 2000000}, "env_runners": {"episode_reward_max": 383.8000000000003, "episode_reward_min": 259.7999999999997, "episode_reward_mean": 326.56100000000004, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 74.60000000000002, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 198.2, "predator_policy": 32.0}, "policy_reward_mean": {"prey_policy": 160.21549999999996, "predator_policy": 3.065}, "custom_metrics": {}, "hist_stats": {"episode_reward": [357.7000000000003, 310.89999999999975, 347.69999999999993, 300.4, 340.6000000000001, 334.1999999999998, 367.0, 359.1000000000003, 316.29999999999995, 330.69999999999993, 315.0999999999999, 311.7999999999999, 318.0999999999998, 331.60000000000036, 354.5, 323.99999999999994, 259.7999999999997, 322.59999999999997, 354.10000000000014, 306.1999999999999, 344.20000000000005, 355.9000000000003, 342.4000000000002, 299.99999999999994, 359.5000000000001, 360.4, 362.5, 331.19999999999993, 340.5999999999999, 311.70000000000016, 328.20000000000016, 316.5000000000002, 309.49999999999966, 362.20000000000016, 337.89999999999986, 301.19999999999993, 334.80000000000035, 340.4000000000002, 294.30000000000007, 351.5000000000002, 303.29999999999995, 287.50000000000034, 365.79999999999995, 354.7999999999999, 318.1, 308.49999999999966, 326.59999999999974, 347.79999999999995, 266.29999999999984, 352.3000000000004, 353.2, 277.69999999999993, 299.70000000000005, 352.29999999999984, 335.29999999999995, 355.9, 331.1000000000002, 315.80000000000007, 375.70000000000005, 335.1999999999998, 350.7999999999999, 348.5999999999999, 321.79999999999995, 300.19999999999976, 360.4000000000002, 333.20000000000005, 344.19999999999993, 361.5000000000003, 328.80000000000007, 356.5, 273.29999999999984, 368.5, 299.1999999999998, 301.8999999999997, 374.5999999999999, 275.2999999999999, 282.09999999999985, 305.29999999999995, 327.19999999999993, 368.4, 347.0, 380.19999999999993, 338.79999999999984, 324.4000000000001, 272.0999999999998, 300.1999999999996, 322.60000000000025, 295.39999999999975, 294.7000000000003, 328.70000000000016, 322.7000000000002, 267.90000000000003, 278.49999999999994, 274.9, 278.2000000000001, 317.10000000000014, 348.7000000000001, 323.90000000000043, 383.8000000000003, 264.29999999999984], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [174.79999999999998, 182.89999999999995, 137.00000000000003, 167.8999999999999, 158.0, 184.7, 136.09999999999985, 155.3, 165.7999999999999, 174.8, 178.4, 150.80000000000004, 184.1, 170.89999999999998, 170.89999999999992, 183.19999999999993, 154.99999999999997, 161.3, 192.79999999999995, 128.90000000000003, 184.7, 115.39999999999978, 155.9, 155.9, 167.59999999999982, 150.49999999999994, 167.59999999999982, 163.99999999999994, 164.6, 182.9, 179.6, 142.39999999999986, 130.99999999999997, 120.80000000000007, 149.5999999999999, 172.99999999999997, 164.0, 190.09999999999994, 151.09999999999994, 145.09999999999997, 163.99999999999991, 180.19999999999993, 179.5999999999999, 167.29999999999993, 153.19999999999993, 189.19999999999996, 172.99999999999994, 122.0, 187.4, 172.09999999999982, 182.0, 178.4, 165.79999999999995, 193.69999999999996, 169.4, 141.79999999999998, 165.8, 174.79999999999998, 130.09999999999994, 176.5999999999999, 153.49999999999997, 160.7, 152.59999999999988, 155.89999999999998, 175.69999999999985, 117.80000000000004, 182.0, 180.19999999999996, 172.99999999999991, 164.89999999999992, 132.79999999999976, 160.39999999999995, 153.49999999999994, 179.29999999999998, 168.49999999999991, 161.89999999999995, 168.49999999999997, 114.80000000000007, 174.79999999999995, 172.7, 148.69999999999993, 152.59999999999994, 155.89999999999986, 131.59999999999965, 179.3, 186.49999999999994, 171.19999999999993, 173.59999999999997, 137.0, 181.09999999999997, 141.49999999999977, 152.0, 154.7, 164.8999999999998, 173.89999999999995, 173.89999999999986, 151.70000000000002, 74.60000000000002, 174.79999999999998, 177.49999999999991, 160.39999999999998, 183.8, 102.50000000000003, 162.2, 152.6, 136.0999999999999, 192.79999999999998, 159.49999999999997, 172.09999999999997, 150.2, 182.89999999999995, 173.0, 142.09999999999977, 182.0, 140.59999999999997, 168.2, 177.49999999999997, 198.2, 190.99999999999994, 144.2, 184.70000000000002, 163.10000000000002, 146.59999999999985, 188.0, 154.99999999999997, 156.79999999999993, 160.9999999999999, 123.19999999999992, 191.0, 169.39999999999992, 176.6, 137.59999999999994, 157.7, 186.49999999999997, 197.29999999999998, 156.19999999999993, 125.59999999999987, 198.2, 190.99999999999997, 159.5, 146.0, 119.30000000000007, 180.19999999999993, 188.3, 173.0, 117.19999999999993, 191.9, 110.00000000000001, 185.5999999999999, 187.99999999999997, 90.20000000000002, 157.09999999999994, 145.1, 137.00000000000003, 154.99999999999997, 140.29999999999998, 165.79999999999998, 157.39999999999995, 190.09999999999997, 173.29999999999998, 159.49999999999991, 183.5, 190.99999999999994, 189.19999999999996, 172.09999999999994, 166.69999999999987, 146.89999999999978, 177.49999999999994, 137.00000000000003, 106.09999999999994, 177.2, 118.99999999999999, 163.09999999999988, 159.49999999999997, 149.60000000000002, 135.79999999999984, 168.49999999999986, 126.19999999999987, 159.50000000000003, 156.19999999999993, 173.89999999999998, 135.79999999999995, 132.8, 127.09999999999997, 132.49999999999986, 145.99999999999997, 161.29999999999995, 113.59999999999997, 147.80000000000004, 124.39999999999999, 146.5999999999999, 156.49999999999991, 198.2, 150.4999999999999, 168.19999999999993, 148.69999999999985, 188.29999999999993, 195.5, 128.0, 119.29999999999981], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 6.0, 0.0, 5.0, 7.0, 2.0, 0.0, 0.0, 5.0, 0.0, 12.0, 0.0, 4.0, 1.0, 0.0, 0.0, 9.0, 0.0, 3.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 2.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 7.0, 2.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 7.0, 13.0, 0.0, 0.0, 5.0, 0.0, 14.0, 0.0, 8.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 5.0, 3.0, 0.0, 2.0, 10.0, 0.0, 11.0, 0.0, 4.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 5.0, 10.0, 0.0, 7.0, 0.0, 0.0, 8.0, 32.0, 0.0, 0.0, 0.0, 9.0, 13.0, 0.0, 11.0, 0.0, 0.0, 0.0, 6.0, 7.0, 0.0, 0.0, 7.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 5.0, 9.0, 10.0, 0.0, 0.0, 16.0, 0.0, 0.0, 7.0, 12.0, 0.0, 0.0, 0.0, 8.0, 0.0, 5.0, 6.0, 0.0, 8.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 28.0, 0.0, 0.0, 0.0, 10.0, 4.0, 0.0, 5.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 19.0, 10.0, 4.0, 0.0, 0.0, 0.0, 5.0, 5.0, 0.0, 0.0, 7.0, 6.0, 0.0, 13.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 14.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 5.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 11.904296031975123, "mean_inference_ms": 26.24371381475954, "mean_action_processing_ms": 5.790964637478843, "mean_env_wait_ms": 7.157693967202747, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007352113723754883, "StateBufferConnector_ms": 0.007700681686401367, "ViewRequirementAgentConnector_ms": 0.26486504077911377}, "num_episodes": 22, "episode_return_max": 383.8000000000003, "episode_return_min": 259.7999999999997, "episode_return_mean": 326.56100000000004, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2000000, "num_agent_steps_trained": 2000000, "num_env_steps_sampled": 500000, "num_env_steps_trained": 500000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 205.81759111356422, "num_env_steps_trained_throughput_per_sec": 205.81759111356422, "timesteps_total": 500000, "num_env_steps_sampled_lifetime": 500000, "num_agent_steps_sampled_lifetime": 2000000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2000000, "timers": {"training_iteration_time_ms": 118681.081, "restore_workers_time_ms": 0.018, "training_step_time_ms": 118681.018, "sample_time_ms": 101965.831, "learn_time_ms": 16691.16, "learn_throughput": 239.648, "synch_weights_time_ms": 18.596}, "counters": {"num_env_steps_sampled": 500000, "num_env_steps_trained": 500000, "num_agent_steps_sampled": 2000000, "num_agent_steps_trained": 2000000}, "done": false, "training_iteration": 125, "trial_id": "75ec3_00000", "date": "2024-08-13_05-03-07", "timestamp": 1723539787, "time_this_iter_s": 19.487298250198364, "time_total_s": 12536.241867780685, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b24c4670>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 12536.241867780685, "iterations_since_restore": 125, "perf": {"cpu_util_percent": 85.03571428571426, "ram_util_percent": 82.94285714285716}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.4879428430209085, "cur_kl_coeff": 0.3082418004643842, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.7654827848313346, "policy_loss": -0.006493495942078649, "vf_loss": 3.770203274772281, "vf_explained_var": 0.24693397930059482, "kl": 0.005752029917934433, "entropy": 1.0410401206798654, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 237195.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.2530359530466653, "cur_kl_coeff": 3.101927297073853e-26, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.17311982092639758, "policy_loss": -0.00025711743106878306, "vf_loss": 0.17337693809710256, "vf_explained_var": 0.018271207367932356, "kl": 0.0009829938603640915, "entropy": 0.43396533303475254, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 237195.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 504000, "num_env_steps_trained": 504000, "num_agent_steps_sampled": 2016000, "num_agent_steps_trained": 2016000}, "env_runners": {"episode_reward_max": 383.8000000000003, "episode_reward_min": 264.29999999999984, "episode_reward_mean": 327.46400000000006, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 74.60000000000002, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 198.2, "predator_policy": 32.0}, "policy_reward_mean": {"prey_policy": 160.57699999999994, "predator_policy": 3.155}, "custom_metrics": {}, "hist_stats": {"episode_reward": [354.10000000000014, 306.1999999999999, 344.20000000000005, 355.9000000000003, 342.4000000000002, 299.99999999999994, 359.5000000000001, 360.4, 362.5, 331.19999999999993, 340.5999999999999, 311.70000000000016, 328.20000000000016, 316.5000000000002, 309.49999999999966, 362.20000000000016, 337.89999999999986, 301.19999999999993, 334.80000000000035, 340.4000000000002, 294.30000000000007, 351.5000000000002, 303.29999999999995, 287.50000000000034, 365.79999999999995, 354.7999999999999, 318.1, 308.49999999999966, 326.59999999999974, 347.79999999999995, 266.29999999999984, 352.3000000000004, 353.2, 277.69999999999993, 299.70000000000005, 352.29999999999984, 335.29999999999995, 355.9, 331.1000000000002, 315.80000000000007, 375.70000000000005, 335.1999999999998, 350.7999999999999, 348.5999999999999, 321.79999999999995, 300.19999999999976, 360.4000000000002, 333.20000000000005, 344.19999999999993, 361.5000000000003, 328.80000000000007, 356.5, 273.29999999999984, 368.5, 299.1999999999998, 301.8999999999997, 374.5999999999999, 275.2999999999999, 282.09999999999985, 305.29999999999995, 327.19999999999993, 368.4, 347.0, 380.19999999999993, 338.79999999999984, 324.4000000000001, 272.0999999999998, 300.1999999999996, 322.60000000000025, 295.39999999999975, 294.7000000000003, 328.70000000000016, 322.7000000000002, 267.90000000000003, 278.49999999999994, 274.9, 278.2000000000001, 317.10000000000014, 348.7000000000001, 323.90000000000043, 383.8000000000003, 264.29999999999984, 322.19999999999993, 288.39999999999964, 318.5999999999998, 322.49999999999994, 371.19999999999993, 353.20000000000016, 340.20000000000016, 366.69999999999993, 301.1, 356.8000000000002, 307.9999999999999, 326.9999999999998, 350.4999999999999, 274.8999999999998, 331.19999999999993, 373.9, 379.19999999999993, 306.80000000000024], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [164.0, 190.09999999999994, 151.09999999999994, 145.09999999999997, 163.99999999999991, 180.19999999999993, 179.5999999999999, 167.29999999999993, 153.19999999999993, 189.19999999999996, 172.99999999999994, 122.0, 187.4, 172.09999999999982, 182.0, 178.4, 165.79999999999995, 193.69999999999996, 169.4, 141.79999999999998, 165.8, 174.79999999999998, 130.09999999999994, 176.5999999999999, 153.49999999999997, 160.7, 152.59999999999988, 155.89999999999998, 175.69999999999985, 117.80000000000004, 182.0, 180.19999999999996, 172.99999999999991, 164.89999999999992, 132.79999999999976, 160.39999999999995, 153.49999999999994, 179.29999999999998, 168.49999999999991, 161.89999999999995, 168.49999999999997, 114.80000000000007, 174.79999999999995, 172.7, 148.69999999999993, 152.59999999999994, 155.89999999999986, 131.59999999999965, 179.3, 186.49999999999994, 171.19999999999993, 173.59999999999997, 137.0, 181.09999999999997, 141.49999999999977, 152.0, 154.7, 164.8999999999998, 173.89999999999995, 173.89999999999986, 151.70000000000002, 74.60000000000002, 174.79999999999998, 177.49999999999991, 160.39999999999998, 183.8, 102.50000000000003, 162.2, 152.6, 136.0999999999999, 192.79999999999998, 159.49999999999997, 172.09999999999997, 150.2, 182.89999999999995, 173.0, 142.09999999999977, 182.0, 140.59999999999997, 168.2, 177.49999999999997, 198.2, 190.99999999999994, 144.2, 184.70000000000002, 163.10000000000002, 146.59999999999985, 188.0, 154.99999999999997, 156.79999999999993, 160.9999999999999, 123.19999999999992, 191.0, 169.39999999999992, 176.6, 137.59999999999994, 157.7, 186.49999999999997, 197.29999999999998, 156.19999999999993, 125.59999999999987, 198.2, 190.99999999999997, 159.5, 146.0, 119.30000000000007, 180.19999999999993, 188.3, 173.0, 117.19999999999993, 191.9, 110.00000000000001, 185.5999999999999, 187.99999999999997, 90.20000000000002, 157.09999999999994, 145.1, 137.00000000000003, 154.99999999999997, 140.29999999999998, 165.79999999999998, 157.39999999999995, 190.09999999999997, 173.29999999999998, 159.49999999999991, 183.5, 190.99999999999994, 189.19999999999996, 172.09999999999994, 166.69999999999987, 146.89999999999978, 177.49999999999994, 137.00000000000003, 106.09999999999994, 177.2, 118.99999999999999, 163.09999999999988, 159.49999999999997, 149.60000000000002, 135.79999999999984, 168.49999999999986, 126.19999999999987, 159.50000000000003, 156.19999999999993, 173.89999999999998, 135.79999999999995, 132.8, 127.09999999999997, 132.49999999999986, 145.99999999999997, 161.29999999999995, 113.59999999999997, 147.80000000000004, 124.39999999999999, 146.5999999999999, 156.49999999999991, 198.2, 150.4999999999999, 168.19999999999993, 148.69999999999985, 188.29999999999993, 195.5, 128.0, 119.29999999999981, 157.7, 153.5, 192.8, 95.59999999999997, 155.89999999999998, 151.7, 157.1, 151.39999999999992, 183.79999999999995, 187.4, 182.0, 162.19999999999996, 186.79999999999995, 151.39999999999998, 173.9, 192.79999999999998, 139.70000000000007, 157.39999999999986, 191.0, 165.79999999999995, 165.8, 141.20000000000002, 185.0, 136.99999999999983, 177.50000000000003, 172.99999999999994, 124.10000000000004, 132.8, 178.69999999999993, 141.50000000000003, 180.20000000000002, 193.69999999999996, 178.7, 195.49999999999997, 170.29999999999993, 126.49999999999989], "policy_predator_policy_reward": [0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 7.0, 2.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 7.0, 13.0, 0.0, 0.0, 5.0, 0.0, 14.0, 0.0, 8.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 5.0, 3.0, 0.0, 2.0, 10.0, 0.0, 11.0, 0.0, 4.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 5.0, 10.0, 0.0, 7.0, 0.0, 0.0, 8.0, 32.0, 0.0, 0.0, 0.0, 9.0, 13.0, 0.0, 11.0, 0.0, 0.0, 0.0, 6.0, 7.0, 0.0, 0.0, 7.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 5.0, 9.0, 10.0, 0.0, 0.0, 16.0, 0.0, 0.0, 7.0, 12.0, 0.0, 0.0, 0.0, 8.0, 0.0, 5.0, 6.0, 0.0, 8.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 28.0, 0.0, 0.0, 0.0, 10.0, 4.0, 0.0, 5.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 19.0, 10.0, 4.0, 0.0, 0.0, 0.0, 5.0, 5.0, 0.0, 0.0, 7.0, 6.0, 0.0, 13.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 14.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 5.0, 12.0, 11.0, 0.0, 0.0, 0.0, 11.0, 0.0, 14.0, 0.0, 0.0, 0.0, 0.0, 9.0, 2.0, 0.0, 0.0, 0.0, 3.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 5.0, 0.0, 0.0, 10.0, 8.0, 0.0, 11.0, 0.0, 0.0, 5.0, 0.0, 6.0, 4.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 12.542095924264554, "mean_inference_ms": 27.8661027710899, "mean_action_processing_ms": 6.109276381540403, "mean_env_wait_ms": 7.465604372605214, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007127523422241211, "StateBufferConnector_ms": 0.008542776107788086, "ViewRequirementAgentConnector_ms": 0.253432035446167}, "num_episodes": 18, "episode_return_max": 383.8000000000003, "episode_return_min": 264.29999999999984, "episode_return_mean": 327.46400000000006, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2016000, "num_agent_steps_trained": 2016000, "num_env_steps_sampled": 504000, "num_env_steps_trained": 504000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 206.70560005288993, "num_env_steps_trained_throughput_per_sec": 206.70560005288993, "timesteps_total": 504000, "num_env_steps_sampled_lifetime": 504000, "num_agent_steps_sampled_lifetime": 2016000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2016000, "timers": {"training_iteration_time_ms": 117864.621, "restore_workers_time_ms": 0.016, "training_step_time_ms": 117864.562, "sample_time_ms": 101271.169, "learn_time_ms": 16570.445, "learn_throughput": 241.394, "synch_weights_time_ms": 17.729}, "counters": {"num_env_steps_sampled": 504000, "num_env_steps_trained": 504000, "num_agent_steps_sampled": 2016000, "num_agent_steps_trained": 2016000}, "done": false, "training_iteration": 126, "trial_id": "75ec3_00000", "date": "2024-08-13_05-03-26", "timestamp": 1723539806, "time_this_iter_s": 19.397239208221436, "time_total_s": 12555.639106988907, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b245f430>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 12555.639106988907, "iterations_since_restore": 126, "perf": {"cpu_util_percent": 83.9222222222222, "ram_util_percent": 83.5925925925926}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.9440888993481478, "cur_kl_coeff": 0.3082418004643842, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.120256158662221, "policy_loss": -0.010096248528900403, "vf_loss": 4.124067034292473, "vf_explained_var": 0.09459370456675373, "kl": 0.020391014169647115, "entropy": 1.0383650287749275, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 239085.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4746804669637371, "cur_kl_coeff": 1.5509636485369265e-26, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.7406927838054284, "policy_loss": -0.00033447979481289627, "vf_loss": 0.7410272633903241, "vf_explained_var": 0.010386708268412837, "kl": 0.002392288926498599, "entropy": 0.3919432157877261, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 239085.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 508000, "num_env_steps_trained": 508000, "num_agent_steps_sampled": 2032000, "num_agent_steps_trained": 2032000}, "env_runners": {"episode_reward_max": 392.79999999999995, "episode_reward_min": 264.29999999999984, "episode_reward_mean": 329.67400000000004, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 74.60000000000002, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 32.0}, "policy_reward_mean": {"prey_policy": 161.62699999999998, "predator_policy": 3.21}, "custom_metrics": {}, "hist_stats": {"episode_reward": [334.80000000000035, 340.4000000000002, 294.30000000000007, 351.5000000000002, 303.29999999999995, 287.50000000000034, 365.79999999999995, 354.7999999999999, 318.1, 308.49999999999966, 326.59999999999974, 347.79999999999995, 266.29999999999984, 352.3000000000004, 353.2, 277.69999999999993, 299.70000000000005, 352.29999999999984, 335.29999999999995, 355.9, 331.1000000000002, 315.80000000000007, 375.70000000000005, 335.1999999999998, 350.7999999999999, 348.5999999999999, 321.79999999999995, 300.19999999999976, 360.4000000000002, 333.20000000000005, 344.19999999999993, 361.5000000000003, 328.80000000000007, 356.5, 273.29999999999984, 368.5, 299.1999999999998, 301.8999999999997, 374.5999999999999, 275.2999999999999, 282.09999999999985, 305.29999999999995, 327.19999999999993, 368.4, 347.0, 380.19999999999993, 338.79999999999984, 324.4000000000001, 272.0999999999998, 300.1999999999996, 322.60000000000025, 295.39999999999975, 294.7000000000003, 328.70000000000016, 322.7000000000002, 267.90000000000003, 278.49999999999994, 274.9, 278.2000000000001, 317.10000000000014, 348.7000000000001, 323.90000000000043, 383.8000000000003, 264.29999999999984, 322.19999999999993, 288.39999999999964, 318.5999999999998, 322.49999999999994, 371.19999999999993, 353.20000000000016, 340.20000000000016, 366.69999999999993, 301.1, 356.8000000000002, 307.9999999999999, 326.9999999999998, 350.4999999999999, 274.8999999999998, 331.19999999999993, 373.9, 379.19999999999993, 306.80000000000024, 338.9, 356.79999999999995, 346.9, 392.79999999999995, 375.20000000000005, 339.10000000000014, 302.30000000000064, 343.30000000000024, 318.1999999999999, 341.30000000000007, 369.4000000000005, 374.79999999999995, 309.0999999999999, 316.69999999999993, 374.80000000000024, 350.4999999999999, 356.29999999999995, 338.8000000000005], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [153.49999999999994, 179.29999999999998, 168.49999999999991, 161.89999999999995, 168.49999999999997, 114.80000000000007, 174.79999999999995, 172.7, 148.69999999999993, 152.59999999999994, 155.89999999999986, 131.59999999999965, 179.3, 186.49999999999994, 171.19999999999993, 173.59999999999997, 137.0, 181.09999999999997, 141.49999999999977, 152.0, 154.7, 164.8999999999998, 173.89999999999995, 173.89999999999986, 151.70000000000002, 74.60000000000002, 174.79999999999998, 177.49999999999991, 160.39999999999998, 183.8, 102.50000000000003, 162.2, 152.6, 136.0999999999999, 192.79999999999998, 159.49999999999997, 172.09999999999997, 150.2, 182.89999999999995, 173.0, 142.09999999999977, 182.0, 140.59999999999997, 168.2, 177.49999999999997, 198.2, 190.99999999999994, 144.2, 184.70000000000002, 163.10000000000002, 146.59999999999985, 188.0, 154.99999999999997, 156.79999999999993, 160.9999999999999, 123.19999999999992, 191.0, 169.39999999999992, 176.6, 137.59999999999994, 157.7, 186.49999999999997, 197.29999999999998, 156.19999999999993, 125.59999999999987, 198.2, 190.99999999999997, 159.5, 146.0, 119.30000000000007, 180.19999999999993, 188.3, 173.0, 117.19999999999993, 191.9, 110.00000000000001, 185.5999999999999, 187.99999999999997, 90.20000000000002, 157.09999999999994, 145.1, 137.00000000000003, 154.99999999999997, 140.29999999999998, 165.79999999999998, 157.39999999999995, 190.09999999999997, 173.29999999999998, 159.49999999999991, 183.5, 190.99999999999994, 189.19999999999996, 172.09999999999994, 166.69999999999987, 146.89999999999978, 177.49999999999994, 137.00000000000003, 106.09999999999994, 177.2, 118.99999999999999, 163.09999999999988, 159.49999999999997, 149.60000000000002, 135.79999999999984, 168.49999999999986, 126.19999999999987, 159.50000000000003, 156.19999999999993, 173.89999999999998, 135.79999999999995, 132.8, 127.09999999999997, 132.49999999999986, 145.99999999999997, 161.29999999999995, 113.59999999999997, 147.80000000000004, 124.39999999999999, 146.5999999999999, 156.49999999999991, 198.2, 150.4999999999999, 168.19999999999993, 148.69999999999985, 188.29999999999993, 195.5, 128.0, 119.29999999999981, 157.7, 153.5, 192.8, 95.59999999999997, 155.89999999999998, 151.7, 157.1, 151.39999999999992, 183.79999999999995, 187.4, 182.0, 162.19999999999996, 186.79999999999995, 151.39999999999998, 173.9, 192.79999999999998, 139.70000000000007, 157.39999999999986, 191.0, 165.79999999999995, 165.8, 141.20000000000002, 185.0, 136.99999999999983, 177.50000000000003, 172.99999999999994, 124.10000000000004, 132.8, 178.69999999999993, 141.50000000000003, 180.20000000000002, 193.69999999999996, 178.7, 195.49999999999997, 170.29999999999993, 126.49999999999989, 196.39999999999998, 129.5, 182.9, 164.9, 173.9, 173.0, 192.79999999999995, 200.0, 176.3, 191.89999999999998, 134.29999999999995, 192.8, 169.39999999999992, 101.89999999999984, 181.1, 162.19999999999993, 154.09999999999994, 151.09999999999997, 185.89999999999995, 145.40000000000003, 177.49999999999986, 191.9, 184.7, 190.1, 167.5999999999999, 141.5, 145.69999999999987, 164.0, 174.79999999999993, 200.0, 200.0, 150.4999999999999, 166.4, 182.89999999999995, 152.29999999999978, 186.49999999999997], "policy_predator_policy_reward": [0.0, 2.0, 10.0, 0.0, 11.0, 0.0, 4.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 5.0, 10.0, 0.0, 7.0, 0.0, 0.0, 8.0, 32.0, 0.0, 0.0, 0.0, 9.0, 13.0, 0.0, 11.0, 0.0, 0.0, 0.0, 6.0, 7.0, 0.0, 0.0, 7.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 5.0, 9.0, 10.0, 0.0, 0.0, 16.0, 0.0, 0.0, 7.0, 12.0, 0.0, 0.0, 0.0, 8.0, 0.0, 5.0, 6.0, 0.0, 8.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 28.0, 0.0, 0.0, 0.0, 10.0, 4.0, 0.0, 5.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 19.0, 10.0, 4.0, 0.0, 0.0, 0.0, 5.0, 5.0, 0.0, 0.0, 7.0, 6.0, 0.0, 13.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 14.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 5.0, 12.0, 11.0, 0.0, 0.0, 0.0, 11.0, 0.0, 14.0, 0.0, 0.0, 0.0, 0.0, 9.0, 2.0, 0.0, 0.0, 0.0, 3.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 5.0, 0.0, 0.0, 10.0, 8.0, 0.0, 11.0, 0.0, 0.0, 5.0, 0.0, 6.0, 4.0, 0.0, 13.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 12.0, 18.0, 13.0, 0.0, 0.0, 6.0, 7.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 13.17481671087868, "mean_inference_ms": 29.475714924815904, "mean_action_processing_ms": 6.425205417874229, "mean_env_wait_ms": 7.771282144267225, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006241559982299805, "StateBufferConnector_ms": 0.008384227752685547, "ViewRequirementAgentConnector_ms": 0.2513394355773926}, "num_episodes": 18, "episode_return_max": 392.79999999999995, "episode_return_min": 264.29999999999984, "episode_return_mean": 329.67400000000004, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2032000, "num_agent_steps_trained": 2032000, "num_env_steps_sampled": 508000, "num_env_steps_trained": 508000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 235.14745547294908, "num_env_steps_trained_throughput_per_sec": 235.14745547294908, "timesteps_total": 508000, "num_env_steps_sampled_lifetime": 508000, "num_agent_steps_sampled_lifetime": 2032000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2032000, "timers": {"training_iteration_time_ms": 117753.045, "restore_workers_time_ms": 0.016, "training_step_time_ms": 117752.985, "sample_time_ms": 101091.747, "learn_time_ms": 16637.698, "learn_throughput": 240.418, "synch_weights_time_ms": 18.019}, "counters": {"num_env_steps_sampled": 508000, "num_env_steps_trained": 508000, "num_agent_steps_sampled": 2032000, "num_agent_steps_trained": 2032000}, "done": false, "training_iteration": 127, "trial_id": "75ec3_00000", "date": "2024-08-13_05-03-43", "timestamp": 1723539823, "time_this_iter_s": 17.04747200012207, "time_total_s": 12572.686578989029, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b223a940>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 12572.686578989029, "iterations_since_restore": 127, "perf": {"cpu_util_percent": 82.83333333333333, "ram_util_percent": 83.5625}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.197616452861715, "cur_kl_coeff": 0.4623627006965761, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.415502420304313, "policy_loss": -0.00989726702226868, "vf_loss": 4.423290067879611, "vf_explained_var": 0.2596084013502434, "kl": 0.0045627046460765845, "entropy": 1.048731863624835, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 240975.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.33079932851411364, "cur_kl_coeff": 7.754818242684633e-27, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.23645404303278872, "policy_loss": -0.00020739919451809435, "vf_loss": 0.23666144197070035, "vf_explained_var": 0.022381811829471084, "kl": 0.0018108840692463385, "entropy": 0.4361228645478607, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 240975.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 512000, "num_env_steps_trained": 512000, "num_agent_steps_sampled": 2048000, "num_agent_steps_trained": 2048000}, "env_runners": {"episode_reward_max": 392.79999999999995, "episode_reward_min": 220.8999999999996, "episode_reward_mean": 330.89700000000005, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 41.90000000000008, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 39.0}, "policy_reward_mean": {"prey_policy": 161.91349999999994, "predator_policy": 3.535}, "custom_metrics": {}, "hist_stats": {"episode_reward": [335.1999999999998, 350.7999999999999, 348.5999999999999, 321.79999999999995, 300.19999999999976, 360.4000000000002, 333.20000000000005, 344.19999999999993, 361.5000000000003, 328.80000000000007, 356.5, 273.29999999999984, 368.5, 299.1999999999998, 301.8999999999997, 374.5999999999999, 275.2999999999999, 282.09999999999985, 305.29999999999995, 327.19999999999993, 368.4, 347.0, 380.19999999999993, 338.79999999999984, 324.4000000000001, 272.0999999999998, 300.1999999999996, 322.60000000000025, 295.39999999999975, 294.7000000000003, 328.70000000000016, 322.7000000000002, 267.90000000000003, 278.49999999999994, 274.9, 278.2000000000001, 317.10000000000014, 348.7000000000001, 323.90000000000043, 383.8000000000003, 264.29999999999984, 322.19999999999993, 288.39999999999964, 318.5999999999998, 322.49999999999994, 371.19999999999993, 353.20000000000016, 340.20000000000016, 366.69999999999993, 301.1, 356.8000000000002, 307.9999999999999, 326.9999999999998, 350.4999999999999, 274.8999999999998, 331.19999999999993, 373.9, 379.19999999999993, 306.80000000000024, 338.9, 356.79999999999995, 346.9, 392.79999999999995, 375.20000000000005, 339.10000000000014, 302.30000000000064, 343.30000000000024, 318.1999999999999, 341.30000000000007, 369.4000000000005, 374.79999999999995, 309.0999999999999, 316.69999999999993, 374.80000000000024, 350.4999999999999, 356.29999999999995, 338.8000000000005, 324.40000000000043, 340.5, 220.8999999999996, 267.69999999999993, 316.20000000000005, 373.90000000000015, 362.0000000000001, 330.1999999999999, 252.19999999999965, 335.80000000000035, 361.3000000000003, 375.70000000000056, 344.6, 353.20000000000005, 361.30000000000047, 360.4, 338.8000000000001, 337.9, 286.4999999999998, 340.60000000000025, 374.8000000000002, 360.5, 351.60000000000036], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [190.99999999999994, 144.2, 184.70000000000002, 163.10000000000002, 146.59999999999985, 188.0, 154.99999999999997, 156.79999999999993, 160.9999999999999, 123.19999999999992, 191.0, 169.39999999999992, 176.6, 137.59999999999994, 157.7, 186.49999999999997, 197.29999999999998, 156.19999999999993, 125.59999999999987, 198.2, 190.99999999999997, 159.5, 146.0, 119.30000000000007, 180.19999999999993, 188.3, 173.0, 117.19999999999993, 191.9, 110.00000000000001, 185.5999999999999, 187.99999999999997, 90.20000000000002, 157.09999999999994, 145.1, 137.00000000000003, 154.99999999999997, 140.29999999999998, 165.79999999999998, 157.39999999999995, 190.09999999999997, 173.29999999999998, 159.49999999999991, 183.5, 190.99999999999994, 189.19999999999996, 172.09999999999994, 166.69999999999987, 146.89999999999978, 177.49999999999994, 137.00000000000003, 106.09999999999994, 177.2, 118.99999999999999, 163.09999999999988, 159.49999999999997, 149.60000000000002, 135.79999999999984, 168.49999999999986, 126.19999999999987, 159.50000000000003, 156.19999999999993, 173.89999999999998, 135.79999999999995, 132.8, 127.09999999999997, 132.49999999999986, 145.99999999999997, 161.29999999999995, 113.59999999999997, 147.80000000000004, 124.39999999999999, 146.5999999999999, 156.49999999999991, 198.2, 150.4999999999999, 168.19999999999993, 148.69999999999985, 188.29999999999993, 195.5, 128.0, 119.29999999999981, 157.7, 153.5, 192.8, 95.59999999999997, 155.89999999999998, 151.7, 157.1, 151.39999999999992, 183.79999999999995, 187.4, 182.0, 162.19999999999996, 186.79999999999995, 151.39999999999998, 173.9, 192.79999999999998, 139.70000000000007, 157.39999999999986, 191.0, 165.79999999999995, 165.8, 141.20000000000002, 185.0, 136.99999999999983, 177.50000000000003, 172.99999999999994, 124.10000000000004, 132.8, 178.69999999999993, 141.50000000000003, 180.20000000000002, 193.69999999999996, 178.7, 195.49999999999997, 170.29999999999993, 126.49999999999989, 196.39999999999998, 129.5, 182.9, 164.9, 173.9, 173.0, 192.79999999999995, 200.0, 176.3, 191.89999999999998, 134.29999999999995, 192.8, 169.39999999999992, 101.89999999999984, 181.1, 162.19999999999993, 154.09999999999994, 151.09999999999997, 185.89999999999995, 145.40000000000003, 177.49999999999986, 191.9, 184.7, 190.1, 167.5999999999999, 141.5, 145.69999999999987, 164.0, 174.79999999999993, 200.0, 200.0, 150.4999999999999, 166.4, 182.89999999999995, 152.29999999999978, 186.49999999999997, 160.39999999999975, 163.99999999999997, 188.29999999999998, 129.2, 127.39999999999978, 54.50000000000002, 121.70000000000006, 145.99999999999994, 166.69999999999993, 123.50000000000001, 191.89999999999995, 181.99999999999997, 165.5, 186.49999999999994, 155.29999999999998, 158.89999999999992, 41.90000000000008, 155.2999999999998, 171.2, 158.59999999999988, 170.29999999999998, 181.99999999999994, 177.49999999999986, 198.2, 192.8, 144.7999999999999, 175.7, 177.49999999999991, 194.59999999999997, 166.6999999999998, 183.8, 176.60000000000002, 157.6999999999999, 181.09999999999997, 150.49999999999997, 178.39999999999998, 117.50000000000006, 164.0, 163.1, 177.49999999999991, 183.79999999999995, 190.99999999999994, 194.60000000000002, 152.9, 173.59999999999997, 169.99999999999983], "policy_predator_policy_reward": [0.0, 0.0, 3.0, 0.0, 5.0, 9.0, 10.0, 0.0, 0.0, 16.0, 0.0, 0.0, 7.0, 12.0, 0.0, 0.0, 0.0, 8.0, 0.0, 5.0, 6.0, 0.0, 8.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 28.0, 0.0, 0.0, 0.0, 10.0, 4.0, 0.0, 5.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 19.0, 10.0, 4.0, 0.0, 0.0, 0.0, 5.0, 5.0, 0.0, 0.0, 7.0, 6.0, 0.0, 13.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 14.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 5.0, 12.0, 11.0, 0.0, 0.0, 0.0, 11.0, 0.0, 14.0, 0.0, 0.0, 0.0, 0.0, 9.0, 2.0, 0.0, 0.0, 0.0, 3.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 5.0, 0.0, 0.0, 10.0, 8.0, 0.0, 11.0, 0.0, 0.0, 5.0, 0.0, 6.0, 4.0, 0.0, 13.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 12.0, 18.0, 13.0, 0.0, 0.0, 6.0, 7.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 17.0, 6.0, 0.0, 39.0, 0.0, 0.0, 13.0, 13.0, 0.0, 0.0, 0.0, 10.0, 8.0, 8.0, 23.0, 32.0, 0.0, 6.0, 9.0, 0.0, 0.0, 0.0, 6.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13.0, 1.0, 7.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 13.787664700251174, "mean_inference_ms": 31.720719391699753, "mean_action_processing_ms": 6.724394226567102, "mean_env_wait_ms": 8.247422320775653, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0056258440017700195, "StateBufferConnector_ms": 0.008156538009643555, "ViewRequirementAgentConnector_ms": 0.24886834621429443}, "num_episodes": 23, "episode_return_max": 392.79999999999995, "episode_return_min": 220.8999999999996, "episode_return_mean": 330.89700000000005, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2048000, "num_agent_steps_trained": 2048000, "num_env_steps_sampled": 512000, "num_env_steps_trained": 512000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 224.93806037457168, "num_env_steps_trained_throughput_per_sec": 224.93806037457168, "timesteps_total": 512000, "num_env_steps_sampled_lifetime": 512000, "num_agent_steps_sampled_lifetime": 2048000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2048000, "timers": {"training_iteration_time_ms": 117872.443, "restore_workers_time_ms": 0.016, "training_step_time_ms": 117872.37, "sample_time_ms": 101083.398, "learn_time_ms": 16765.433, "learn_throughput": 238.586, "synch_weights_time_ms": 18.135}, "counters": {"num_env_steps_sampled": 512000, "num_env_steps_trained": 512000, "num_agent_steps_sampled": 2048000, "num_agent_steps_trained": 2048000}, "done": false, "training_iteration": 128, "trial_id": "75ec3_00000", "date": "2024-08-13_05-04-01", "timestamp": 1723539841, "time_this_iter_s": 17.848564863204956, "time_total_s": 12590.535143852234, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b24170d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 12590.535143852234, "iterations_since_restore": 128, "perf": {"cpu_util_percent": 76.57600000000001, "ram_util_percent": 83.04799999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.7183400458128997, "cur_kl_coeff": 0.23118135034828804, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.494056913966224, "policy_loss": -0.0037117599364291268, "vf_loss": 2.4951769538657373, "vf_explained_var": 0.33082807988086077, "kl": 0.011210762958705068, "entropy": 1.0594555230998488, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 242865.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.45675537884728146, "cur_kl_coeff": 3.8774091213423164e-27, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.36160139642537587, "policy_loss": -0.0009478402011116188, "vf_loss": 0.3625492359568838, "vf_explained_var": 0.03479243684067297, "kl": 0.003086235525181417, "entropy": 0.3995646657767119, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 242865.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 516000, "num_env_steps_trained": 516000, "num_agent_steps_sampled": 2064000, "num_agent_steps_trained": 2064000}, "env_runners": {"episode_reward_max": 392.79999999999995, "episode_reward_min": 220.8999999999996, "episode_reward_mean": 336.42200000000014, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 41.90000000000008, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 39.0}, "policy_reward_mean": {"prey_policy": 164.831, "predator_policy": 3.38}, "custom_metrics": {}, "hist_stats": {"episode_reward": [380.19999999999993, 338.79999999999984, 324.4000000000001, 272.0999999999998, 300.1999999999996, 322.60000000000025, 295.39999999999975, 294.7000000000003, 328.70000000000016, 322.7000000000002, 267.90000000000003, 278.49999999999994, 274.9, 278.2000000000001, 317.10000000000014, 348.7000000000001, 323.90000000000043, 383.8000000000003, 264.29999999999984, 322.19999999999993, 288.39999999999964, 318.5999999999998, 322.49999999999994, 371.19999999999993, 353.20000000000016, 340.20000000000016, 366.69999999999993, 301.1, 356.8000000000002, 307.9999999999999, 326.9999999999998, 350.4999999999999, 274.8999999999998, 331.19999999999993, 373.9, 379.19999999999993, 306.80000000000024, 338.9, 356.79999999999995, 346.9, 392.79999999999995, 375.20000000000005, 339.10000000000014, 302.30000000000064, 343.30000000000024, 318.1999999999999, 341.30000000000007, 369.4000000000005, 374.79999999999995, 309.0999999999999, 316.69999999999993, 374.80000000000024, 350.4999999999999, 356.29999999999995, 338.8000000000005, 324.40000000000043, 340.5, 220.8999999999996, 267.69999999999993, 316.20000000000005, 373.90000000000015, 362.0000000000001, 330.1999999999999, 252.19999999999965, 335.80000000000035, 361.3000000000003, 375.70000000000056, 344.6, 353.20000000000005, 361.30000000000047, 360.4, 338.8000000000001, 337.9, 286.4999999999998, 340.60000000000025, 374.8000000000002, 360.5, 351.60000000000036, 352.5, 329.0999999999999, 358.1000000000002, 275.19999999999993, 353.1, 352.79999999999995, 352.29999999999995, 357.69999999999993, 377.1000000000005, 379.30000000000007, 375.70000000000005, 380.2, 373.0000000000002, 353.29999999999995, 352.10000000000036, 326.5, 358.19999999999993, 373.0, 378.4, 344.79999999999995, 334.8, 379.29999999999995], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [190.99999999999994, 189.19999999999996, 172.09999999999994, 166.69999999999987, 146.89999999999978, 177.49999999999994, 137.00000000000003, 106.09999999999994, 177.2, 118.99999999999999, 163.09999999999988, 159.49999999999997, 149.60000000000002, 135.79999999999984, 168.49999999999986, 126.19999999999987, 159.50000000000003, 156.19999999999993, 173.89999999999998, 135.79999999999995, 132.8, 127.09999999999997, 132.49999999999986, 145.99999999999997, 161.29999999999995, 113.59999999999997, 147.80000000000004, 124.39999999999999, 146.5999999999999, 156.49999999999991, 198.2, 150.4999999999999, 168.19999999999993, 148.69999999999985, 188.29999999999993, 195.5, 128.0, 119.29999999999981, 157.7, 153.5, 192.8, 95.59999999999997, 155.89999999999998, 151.7, 157.1, 151.39999999999992, 183.79999999999995, 187.4, 182.0, 162.19999999999996, 186.79999999999995, 151.39999999999998, 173.9, 192.79999999999998, 139.70000000000007, 157.39999999999986, 191.0, 165.79999999999995, 165.8, 141.20000000000002, 185.0, 136.99999999999983, 177.50000000000003, 172.99999999999994, 124.10000000000004, 132.8, 178.69999999999993, 141.50000000000003, 180.20000000000002, 193.69999999999996, 178.7, 195.49999999999997, 170.29999999999993, 126.49999999999989, 196.39999999999998, 129.5, 182.9, 164.9, 173.9, 173.0, 192.79999999999995, 200.0, 176.3, 191.89999999999998, 134.29999999999995, 192.8, 169.39999999999992, 101.89999999999984, 181.1, 162.19999999999993, 154.09999999999994, 151.09999999999997, 185.89999999999995, 145.40000000000003, 177.49999999999986, 191.9, 184.7, 190.1, 167.5999999999999, 141.5, 145.69999999999987, 164.0, 174.79999999999993, 200.0, 200.0, 150.4999999999999, 166.4, 182.89999999999995, 152.29999999999978, 186.49999999999997, 160.39999999999975, 163.99999999999997, 188.29999999999998, 129.2, 127.39999999999978, 54.50000000000002, 121.70000000000006, 145.99999999999994, 166.69999999999993, 123.50000000000001, 191.89999999999995, 181.99999999999997, 165.5, 186.49999999999994, 155.29999999999998, 158.89999999999992, 41.90000000000008, 155.2999999999998, 171.2, 158.59999999999988, 170.29999999999998, 181.99999999999994, 177.49999999999986, 198.2, 192.8, 144.7999999999999, 175.7, 177.49999999999991, 194.59999999999997, 166.6999999999998, 183.8, 176.60000000000002, 157.6999999999999, 181.09999999999997, 150.49999999999997, 178.39999999999998, 117.50000000000006, 164.0, 163.1, 177.49999999999991, 183.79999999999995, 190.99999999999994, 194.60000000000002, 152.9, 173.59999999999997, 169.99999999999983, 176.0, 168.5, 167.0, 148.10000000000002, 180.19999999999996, 170.9, 128.30000000000004, 134.90000000000003, 170.29999999999998, 177.8, 178.09999999999997, 163.7, 169.3999999999998, 182.9, 182.9, 174.8, 196.39999999999998, 178.6999999999999, 193.7, 185.6, 195.5, 180.2, 183.8, 196.4, 196.4, 176.5999999999999, 160.1, 180.2, 142.09999999999985, 200.0, 143.0, 171.5, 192.79999999999998, 148.4, 191.0, 182.0, 186.5, 191.9, 170.29999999999995, 168.5, 181.1, 151.7, 192.79999999999998, 186.5], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 19.0, 10.0, 4.0, 0.0, 0.0, 0.0, 5.0, 5.0, 0.0, 0.0, 7.0, 6.0, 0.0, 13.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 14.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 5.0, 12.0, 11.0, 0.0, 0.0, 0.0, 11.0, 0.0, 14.0, 0.0, 0.0, 0.0, 0.0, 9.0, 2.0, 0.0, 0.0, 0.0, 3.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 5.0, 0.0, 0.0, 10.0, 8.0, 0.0, 11.0, 0.0, 0.0, 5.0, 0.0, 6.0, 4.0, 0.0, 13.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 12.0, 18.0, 13.0, 0.0, 0.0, 6.0, 7.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 17.0, 6.0, 0.0, 39.0, 0.0, 0.0, 13.0, 13.0, 0.0, 0.0, 0.0, 10.0, 8.0, 8.0, 23.0, 32.0, 0.0, 6.0, 9.0, 0.0, 0.0, 0.0, 6.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13.0, 1.0, 7.0, 8.0, 0.0, 11.0, 3.0, 0.0, 7.0, 12.0, 0.0, 0.0, 5.0, 7.0, 4.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13.0, 0.0, 10.0, 0.0, 12.0, 9.0, 8.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 2.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 14.209319488249202, "mean_inference_ms": 31.106197154131916, "mean_action_processing_ms": 6.68122734018306, "mean_env_wait_ms": 8.192926870771911, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004573464393615723, "StateBufferConnector_ms": 0.005335688591003418, "ViewRequirementAgentConnector_ms": 0.15480077266693115}, "num_episodes": 22, "episode_return_max": 392.79999999999995, "episode_return_min": 220.8999999999996, "episode_return_mean": 336.42200000000014, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2064000, "num_agent_steps_trained": 2064000, "num_env_steps_sampled": 516000, "num_env_steps_trained": 516000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 203.40267181372943, "num_env_steps_trained_throughput_per_sec": 203.40267181372943, "timesteps_total": 516000, "num_env_steps_sampled_lifetime": 516000, "num_agent_steps_sampled_lifetime": 2064000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2064000, "timers": {"training_iteration_time_ms": 117976.365, "restore_workers_time_ms": 0.016, "training_step_time_ms": 117976.292, "sample_time_ms": 101165.566, "learn_time_ms": 16785.979, "learn_throughput": 238.294, "synch_weights_time_ms": 18.827}, "counters": {"num_env_steps_sampled": 516000, "num_env_steps_trained": 516000, "num_agent_steps_sampled": 2064000, "num_agent_steps_trained": 2064000}, "done": false, "training_iteration": 129, "trial_id": "75ec3_00000", "date": "2024-08-13_05-04-21", "timestamp": 1723539861, "time_this_iter_s": 19.718647956848145, "time_total_s": 12610.253791809082, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b24c4790>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 12610.253791809082, "iterations_since_restore": 129, "perf": {"cpu_util_percent": 81.59285714285713, "ram_util_percent": 83.46071428571429}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.9211790604250774, "cur_kl_coeff": 0.23118135034828804, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.386521088824701, "policy_loss": -0.013513657213287261, "vf_loss": 3.3958067105560708, "vf_explained_var": 0.23709848362302025, "kl": 0.018288821505603795, "entropy": 1.0488549919355483, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 244755.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.23191152385155123, "cur_kl_coeff": 1.9387045606711582e-27, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.10908270132821546, "policy_loss": -0.0003404494446441137, "vf_loss": 0.10942315058523996, "vf_explained_var": -0.13069013505385665, "kl": 0.0063721393472906205, "entropy": 0.5312547371816383, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 244755.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 520000, "num_env_steps_trained": 520000, "num_agent_steps_sampled": 2080000, "num_agent_steps_trained": 2080000}, "env_runners": {"episode_reward_max": 392.79999999999995, "episode_reward_min": 220.8999999999996, "episode_reward_mean": 341.85799999999995, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 41.90000000000008, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 39.0}, "policy_reward_mean": {"prey_policy": 167.69899999999996, "predator_policy": 3.23}, "custom_metrics": {}, "hist_stats": {"episode_reward": [264.29999999999984, 322.19999999999993, 288.39999999999964, 318.5999999999998, 322.49999999999994, 371.19999999999993, 353.20000000000016, 340.20000000000016, 366.69999999999993, 301.1, 356.8000000000002, 307.9999999999999, 326.9999999999998, 350.4999999999999, 274.8999999999998, 331.19999999999993, 373.9, 379.19999999999993, 306.80000000000024, 338.9, 356.79999999999995, 346.9, 392.79999999999995, 375.20000000000005, 339.10000000000014, 302.30000000000064, 343.30000000000024, 318.1999999999999, 341.30000000000007, 369.4000000000005, 374.79999999999995, 309.0999999999999, 316.69999999999993, 374.80000000000024, 350.4999999999999, 356.29999999999995, 338.8000000000005, 324.40000000000043, 340.5, 220.8999999999996, 267.69999999999993, 316.20000000000005, 373.90000000000015, 362.0000000000001, 330.1999999999999, 252.19999999999965, 335.80000000000035, 361.3000000000003, 375.70000000000056, 344.6, 353.20000000000005, 361.30000000000047, 360.4, 338.8000000000001, 337.9, 286.4999999999998, 340.60000000000025, 374.8000000000002, 360.5, 351.60000000000036, 352.5, 329.0999999999999, 358.1000000000002, 275.19999999999993, 353.1, 352.79999999999995, 352.29999999999995, 357.69999999999993, 377.1000000000005, 379.30000000000007, 375.70000000000005, 380.2, 373.0000000000002, 353.29999999999995, 352.10000000000036, 326.5, 358.19999999999993, 373.0, 378.4, 344.79999999999995, 334.8, 379.29999999999995, 335.9000000000001, 355.9, 340.3, 364.3999999999999, 346.2000000000003, 373.0, 335.2000000000002, 361.30000000000035, 373.0000000000001, 382.90000000000003, 346.0, 282.10000000000036, 318.5000000000001, 312.7000000000002, 336.1000000000001, 342.19999999999993, 350.2000000000002, 340.5], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [128.0, 119.29999999999981, 157.7, 153.5, 192.8, 95.59999999999997, 155.89999999999998, 151.7, 157.1, 151.39999999999992, 183.79999999999995, 187.4, 182.0, 162.19999999999996, 186.79999999999995, 151.39999999999998, 173.9, 192.79999999999998, 139.70000000000007, 157.39999999999986, 191.0, 165.79999999999995, 165.8, 141.20000000000002, 185.0, 136.99999999999983, 177.50000000000003, 172.99999999999994, 124.10000000000004, 132.8, 178.69999999999993, 141.50000000000003, 180.20000000000002, 193.69999999999996, 178.7, 195.49999999999997, 170.29999999999993, 126.49999999999989, 196.39999999999998, 129.5, 182.9, 164.9, 173.9, 173.0, 192.79999999999995, 200.0, 176.3, 191.89999999999998, 134.29999999999995, 192.8, 169.39999999999992, 101.89999999999984, 181.1, 162.19999999999993, 154.09999999999994, 151.09999999999997, 185.89999999999995, 145.40000000000003, 177.49999999999986, 191.9, 184.7, 190.1, 167.5999999999999, 141.5, 145.69999999999987, 164.0, 174.79999999999993, 200.0, 200.0, 150.4999999999999, 166.4, 182.89999999999995, 152.29999999999978, 186.49999999999997, 160.39999999999975, 163.99999999999997, 188.29999999999998, 129.2, 127.39999999999978, 54.50000000000002, 121.70000000000006, 145.99999999999994, 166.69999999999993, 123.50000000000001, 191.89999999999995, 181.99999999999997, 165.5, 186.49999999999994, 155.29999999999998, 158.89999999999992, 41.90000000000008, 155.2999999999998, 171.2, 158.59999999999988, 170.29999999999998, 181.99999999999994, 177.49999999999986, 198.2, 192.8, 144.7999999999999, 175.7, 177.49999999999991, 194.59999999999997, 166.6999999999998, 183.8, 176.60000000000002, 157.6999999999999, 181.09999999999997, 150.49999999999997, 178.39999999999998, 117.50000000000006, 164.0, 163.1, 177.49999999999991, 183.79999999999995, 190.99999999999994, 194.60000000000002, 152.9, 173.59999999999997, 169.99999999999983, 176.0, 168.5, 167.0, 148.10000000000002, 180.19999999999996, 170.9, 128.30000000000004, 134.90000000000003, 170.29999999999998, 177.8, 178.09999999999997, 163.7, 169.3999999999998, 182.9, 182.9, 174.8, 196.39999999999998, 178.6999999999999, 193.7, 185.6, 195.5, 180.2, 183.8, 196.4, 196.4, 176.5999999999999, 160.1, 180.2, 142.09999999999985, 200.0, 143.0, 171.5, 192.79999999999998, 148.4, 191.0, 182.0, 186.5, 191.9, 170.29999999999995, 168.5, 181.1, 151.7, 192.79999999999998, 186.5, 161.3, 161.6, 174.79999999999998, 181.1, 176.6, 157.7, 166.4, 190.99999999999997, 166.99999999999997, 171.19999999999993, 194.6, 178.4, 154.1, 181.09999999999994, 179.3, 181.9999999999999, 184.69999999999996, 188.29999999999995, 198.2, 184.69999999999996, 146.89999999999992, 199.1, 161.29999999999998, 120.79999999999984, 169.09999999999997, 142.39999999999998, 131.6, 169.1, 154.0999999999999, 181.99999999999997, 179.3, 152.89999999999998, 175.69999999999993, 168.5, 166.1, 169.39999999999998], "policy_predator_policy_reward": [5.0, 12.0, 11.0, 0.0, 0.0, 0.0, 11.0, 0.0, 14.0, 0.0, 0.0, 0.0, 0.0, 9.0, 2.0, 0.0, 0.0, 0.0, 3.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 5.0, 0.0, 0.0, 10.0, 8.0, 0.0, 11.0, 0.0, 0.0, 5.0, 0.0, 6.0, 4.0, 0.0, 13.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 12.0, 18.0, 13.0, 0.0, 0.0, 6.0, 7.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 17.0, 6.0, 0.0, 39.0, 0.0, 0.0, 13.0, 13.0, 0.0, 0.0, 0.0, 10.0, 8.0, 8.0, 23.0, 32.0, 0.0, 6.0, 9.0, 0.0, 0.0, 0.0, 6.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13.0, 1.0, 7.0, 8.0, 0.0, 11.0, 3.0, 0.0, 7.0, 12.0, 0.0, 0.0, 5.0, 7.0, 4.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13.0, 0.0, 10.0, 0.0, 12.0, 9.0, 8.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 2.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 7.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 12.0, 0.0, 0.0, 0.0, 0.0, 10.0, 6.0, 0.0, 5.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 13.583668204685752, "mean_inference_ms": 31.293308760130948, "mean_action_processing_ms": 6.629135026878682, "mean_env_wait_ms": 8.296587686594227, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004649758338928223, "StateBufferConnector_ms": 0.005577683448791504, "ViewRequirementAgentConnector_ms": 0.16396594047546387}, "num_episodes": 18, "episode_return_max": 392.79999999999995, "episode_return_min": 220.8999999999996, "episode_return_mean": 341.85799999999995, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2080000, "num_agent_steps_trained": 2080000, "num_env_steps_sampled": 520000, "num_env_steps_trained": 520000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 205.46474315345657, "num_env_steps_trained_throughput_per_sec": 205.46474315345657, "timesteps_total": 520000, "num_env_steps_sampled_lifetime": 520000, "num_agent_steps_sampled_lifetime": 2080000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2080000, "timers": {"training_iteration_time_ms": 118018.56, "restore_workers_time_ms": 0.016, "training_step_time_ms": 118018.488, "sample_time_ms": 101115.896, "learn_time_ms": 16877.434, "learn_throughput": 237.003, "synch_weights_time_ms": 19.32}, "counters": {"num_env_steps_sampled": 520000, "num_env_steps_trained": 520000, "num_agent_steps_sampled": 2080000, "num_agent_steps_trained": 2080000}, "done": false, "training_iteration": 130, "trial_id": "75ec3_00000", "date": "2024-08-13_05-04-40", "timestamp": 1723539880, "time_this_iter_s": 19.517886877059937, "time_total_s": 12629.771678686142, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b24f2670>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 12629.771678686142, "iterations_since_restore": 130, "perf": {"cpu_util_percent": 79.93214285714286, "ram_util_percent": 83.24285714285713}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.9603837491185576, "cur_kl_coeff": 0.23118135034828804, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.193005586553503, "policy_loss": -0.0030042091011261893, "vf_loss": 2.194768771923408, "vf_explained_var": 0.2632583358931163, "kl": 0.005368163904423927, "entropy": 1.0775775288147902, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 246645.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.3424543957428011, "cur_kl_coeff": 1.9387045606711582e-27, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.23000891170804463, "policy_loss": -0.0007599415181194821, "vf_loss": 0.23076885374736905, "vf_explained_var": 0.06053247133260051, "kl": 0.00476759876878074, "entropy": 0.6563481337809689, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 246645.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 524000, "num_env_steps_trained": 524000, "num_agent_steps_sampled": 2096000, "num_agent_steps_trained": 2096000}, "env_runners": {"episode_reward_max": 392.79999999999995, "episode_reward_min": 220.8999999999996, "episode_reward_mean": 347.298, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 41.90000000000008, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 39.0}, "policy_reward_mean": {"prey_policy": 170.384, "predator_policy": 3.265}, "custom_metrics": {}, "hist_stats": {"episode_reward": [306.80000000000024, 338.9, 356.79999999999995, 346.9, 392.79999999999995, 375.20000000000005, 339.10000000000014, 302.30000000000064, 343.30000000000024, 318.1999999999999, 341.30000000000007, 369.4000000000005, 374.79999999999995, 309.0999999999999, 316.69999999999993, 374.80000000000024, 350.4999999999999, 356.29999999999995, 338.8000000000005, 324.40000000000043, 340.5, 220.8999999999996, 267.69999999999993, 316.20000000000005, 373.90000000000015, 362.0000000000001, 330.1999999999999, 252.19999999999965, 335.80000000000035, 361.3000000000003, 375.70000000000056, 344.6, 353.20000000000005, 361.30000000000047, 360.4, 338.8000000000001, 337.9, 286.4999999999998, 340.60000000000025, 374.8000000000002, 360.5, 351.60000000000036, 352.5, 329.0999999999999, 358.1000000000002, 275.19999999999993, 353.1, 352.79999999999995, 352.29999999999995, 357.69999999999993, 377.1000000000005, 379.30000000000007, 375.70000000000005, 380.2, 373.0000000000002, 353.29999999999995, 352.10000000000036, 326.5, 358.19999999999993, 373.0, 378.4, 344.79999999999995, 334.8, 379.29999999999995, 335.9000000000001, 355.9, 340.3, 364.3999999999999, 346.2000000000003, 373.0, 335.2000000000002, 361.30000000000035, 373.0000000000001, 382.90000000000003, 346.0, 282.10000000000036, 318.5000000000001, 312.7000000000002, 336.1000000000001, 342.19999999999993, 350.2000000000002, 340.5, 391.9, 376.19999999999993, 332.1, 382.90000000000015, 349.1, 329.19999999999993, 340.60000000000014, 377.49999999999994, 385.5999999999999, 323.69999999999993, 353.4, 387.30000000000007, 381.1, 317.40000000000066, 373.9, 378.20000000000005, 378.20000000000005, 335.6], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [170.29999999999993, 126.49999999999989, 196.39999999999998, 129.5, 182.9, 164.9, 173.9, 173.0, 192.79999999999995, 200.0, 176.3, 191.89999999999998, 134.29999999999995, 192.8, 169.39999999999992, 101.89999999999984, 181.1, 162.19999999999993, 154.09999999999994, 151.09999999999997, 185.89999999999995, 145.40000000000003, 177.49999999999986, 191.9, 184.7, 190.1, 167.5999999999999, 141.5, 145.69999999999987, 164.0, 174.79999999999993, 200.0, 200.0, 150.4999999999999, 166.4, 182.89999999999995, 152.29999999999978, 186.49999999999997, 160.39999999999975, 163.99999999999997, 188.29999999999998, 129.2, 127.39999999999978, 54.50000000000002, 121.70000000000006, 145.99999999999994, 166.69999999999993, 123.50000000000001, 191.89999999999995, 181.99999999999997, 165.5, 186.49999999999994, 155.29999999999998, 158.89999999999992, 41.90000000000008, 155.2999999999998, 171.2, 158.59999999999988, 170.29999999999998, 181.99999999999994, 177.49999999999986, 198.2, 192.8, 144.7999999999999, 175.7, 177.49999999999991, 194.59999999999997, 166.6999999999998, 183.8, 176.60000000000002, 157.6999999999999, 181.09999999999997, 150.49999999999997, 178.39999999999998, 117.50000000000006, 164.0, 163.1, 177.49999999999991, 183.79999999999995, 190.99999999999994, 194.60000000000002, 152.9, 173.59999999999997, 169.99999999999983, 176.0, 168.5, 167.0, 148.10000000000002, 180.19999999999996, 170.9, 128.30000000000004, 134.90000000000003, 170.29999999999998, 177.8, 178.09999999999997, 163.7, 169.3999999999998, 182.9, 182.9, 174.8, 196.39999999999998, 178.6999999999999, 193.7, 185.6, 195.5, 180.2, 183.8, 196.4, 196.4, 176.5999999999999, 160.1, 180.2, 142.09999999999985, 200.0, 143.0, 171.5, 192.79999999999998, 148.4, 191.0, 182.0, 186.5, 191.9, 170.29999999999995, 168.5, 181.1, 151.7, 192.79999999999998, 186.5, 161.3, 161.6, 174.79999999999998, 181.1, 176.6, 157.7, 166.4, 190.99999999999997, 166.99999999999997, 171.19999999999993, 194.6, 178.4, 154.1, 181.09999999999994, 179.3, 181.9999999999999, 184.69999999999996, 188.29999999999995, 198.2, 184.69999999999996, 146.89999999999992, 199.1, 161.29999999999998, 120.79999999999984, 169.09999999999997, 142.39999999999998, 131.6, 169.1, 154.0999999999999, 181.99999999999997, 179.3, 152.89999999999998, 175.69999999999993, 168.5, 166.1, 169.39999999999998, 192.8, 199.1, 192.8, 181.39999999999995, 164.0, 157.1, 199.1, 183.79999999999993, 169.1, 170.0, 164.29999999999998, 155.9, 145.09999999999997, 195.5, 183.8, 193.7, 191.89999999999998, 193.7, 191.9, 96.80000000000001, 170.29999999999998, 175.1, 200.0, 182.29999999999998, 186.5, 194.6, 112.09999999999977, 188.29999999999998, 187.39999999999998, 186.49999999999997, 182.89999999999998, 194.29999999999998, 192.5, 184.69999999999996, 146.6, 173.0], "policy_predator_policy_reward": [6.0, 4.0, 0.0, 13.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 12.0, 18.0, 13.0, 0.0, 0.0, 6.0, 7.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 17.0, 6.0, 0.0, 39.0, 0.0, 0.0, 13.0, 13.0, 0.0, 0.0, 0.0, 10.0, 8.0, 8.0, 23.0, 32.0, 0.0, 6.0, 9.0, 0.0, 0.0, 0.0, 6.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13.0, 1.0, 7.0, 8.0, 0.0, 11.0, 3.0, 0.0, 7.0, 12.0, 0.0, 0.0, 5.0, 7.0, 4.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13.0, 0.0, 10.0, 0.0, 12.0, 9.0, 8.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 2.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 7.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 12.0, 0.0, 0.0, 0.0, 0.0, 10.0, 6.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 2.0, 4.0, 7.0, 0.0, 0.0, 10.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 18.0, 17.0, 8.0, 0.0, 4.0, 1.0, 0.0, 0.0, 6.0, 11.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 7.0, 9.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 13.495405614413617, "mean_inference_ms": 31.09555997763705, "mean_action_processing_ms": 6.585354383988278, "mean_env_wait_ms": 8.24070857601568, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00627899169921875, "StateBufferConnector_ms": 0.004310131072998047, "ViewRequirementAgentConnector_ms": 0.17351603507995605}, "num_episodes": 18, "episode_return_max": 392.79999999999995, "episode_return_min": 220.8999999999996, "episode_return_mean": 347.298, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2096000, "num_agent_steps_trained": 2096000, "num_env_steps_sampled": 524000, "num_env_steps_trained": 524000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 200.27184909153587, "num_env_steps_trained_throughput_per_sec": 200.27184909153587, "timesteps_total": 524000, "num_env_steps_sampled_lifetime": 524000, "num_agent_steps_sampled_lifetime": 2096000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2096000, "timers": {"training_iteration_time_ms": 118149.428, "restore_workers_time_ms": 0.016, "training_step_time_ms": 118149.356, "sample_time_ms": 101159.703, "learn_time_ms": 16965.185, "learn_throughput": 235.777, "synch_weights_time_ms": 18.674}, "counters": {"num_env_steps_sampled": 524000, "num_env_steps_trained": 524000, "num_agent_steps_sampled": 2096000, "num_agent_steps_trained": 2096000}, "done": false, "training_iteration": 131, "trial_id": "75ec3_00000", "date": "2024-08-13_05-05-00", "timestamp": 1723539900, "time_this_iter_s": 20.020007133483887, "time_total_s": 12649.791685819626, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2417c10>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 12649.791685819626, "iterations_since_restore": 131, "perf": {"cpu_util_percent": 79.96785714285714, "ram_util_percent": 83.325}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.8371115816333305, "cur_kl_coeff": 0.23118135034828804, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.6529234199927596, "policy_loss": -0.010072834512450432, "vf_loss": 2.658956673977867, "vf_explained_var": 0.3070967039418599, "kl": 0.017473652038721667, "entropy": 1.0727416741784919, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 248535.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.40550939278608117, "cur_kl_coeff": 9.693522803355791e-28, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.15594891146239306, "policy_loss": -3.0185359840591748e-05, "vf_loss": 0.15597909656057637, "vf_explained_var": 0.07257061452461928, "kl": 0.004985378324006108, "entropy": 0.5683566797820349, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 248535.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 528000, "num_env_steps_trained": 528000, "num_agent_steps_sampled": 2112000, "num_agent_steps_trained": 2112000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": 252.19999999999965, "episode_reward_mean": 354.58700000000005, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 41.90000000000008, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 32.0}, "policy_reward_mean": {"prey_policy": 174.49849999999998, "predator_policy": 2.795}, "custom_metrics": {}, "hist_stats": {"episode_reward": [316.20000000000005, 373.90000000000015, 362.0000000000001, 330.1999999999999, 252.19999999999965, 335.80000000000035, 361.3000000000003, 375.70000000000056, 344.6, 353.20000000000005, 361.30000000000047, 360.4, 338.8000000000001, 337.9, 286.4999999999998, 340.60000000000025, 374.8000000000002, 360.5, 351.60000000000036, 352.5, 329.0999999999999, 358.1000000000002, 275.19999999999993, 353.1, 352.79999999999995, 352.29999999999995, 357.69999999999993, 377.1000000000005, 379.30000000000007, 375.70000000000005, 380.2, 373.0000000000002, 353.29999999999995, 352.10000000000036, 326.5, 358.19999999999993, 373.0, 378.4, 344.79999999999995, 334.8, 379.29999999999995, 335.9000000000001, 355.9, 340.3, 364.3999999999999, 346.2000000000003, 373.0, 335.2000000000002, 361.30000000000035, 373.0000000000001, 382.90000000000003, 346.0, 282.10000000000036, 318.5000000000001, 312.7000000000002, 336.1000000000001, 342.19999999999993, 350.2000000000002, 340.5, 391.9, 376.19999999999993, 332.1, 382.90000000000015, 349.1, 329.19999999999993, 340.60000000000014, 377.49999999999994, 385.5999999999999, 323.69999999999993, 353.4, 387.30000000000007, 381.1, 317.40000000000066, 373.9, 378.20000000000005, 378.20000000000005, 335.6, 400.0, 361.5, 363.9, 375.69999999999993, 374.09999999999997, 368.50000000000017, 383.8, 372.0999999999999, 338.29999999999995, 380.20000000000005, 354.4, 371.2000000000007, 359.60000000000036, 345.9999999999999, 373.9, 400.0, 356.8000000000002, 360.39999999999986, 367.1000000000001, 376.6, 370.0, 356.79999999999995, 323.50000000000045], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [166.69999999999993, 123.50000000000001, 191.89999999999995, 181.99999999999997, 165.5, 186.49999999999994, 155.29999999999998, 158.89999999999992, 41.90000000000008, 155.2999999999998, 171.2, 158.59999999999988, 170.29999999999998, 181.99999999999994, 177.49999999999986, 198.2, 192.8, 144.7999999999999, 175.7, 177.49999999999991, 194.59999999999997, 166.6999999999998, 183.8, 176.60000000000002, 157.6999999999999, 181.09999999999997, 150.49999999999997, 178.39999999999998, 117.50000000000006, 164.0, 163.1, 177.49999999999991, 183.79999999999995, 190.99999999999994, 194.60000000000002, 152.9, 173.59999999999997, 169.99999999999983, 176.0, 168.5, 167.0, 148.10000000000002, 180.19999999999996, 170.9, 128.30000000000004, 134.90000000000003, 170.29999999999998, 177.8, 178.09999999999997, 163.7, 169.3999999999998, 182.9, 182.9, 174.8, 196.39999999999998, 178.6999999999999, 193.7, 185.6, 195.5, 180.2, 183.8, 196.4, 196.4, 176.5999999999999, 160.1, 180.2, 142.09999999999985, 200.0, 143.0, 171.5, 192.79999999999998, 148.4, 191.0, 182.0, 186.5, 191.9, 170.29999999999995, 168.5, 181.1, 151.7, 192.79999999999998, 186.5, 161.3, 161.6, 174.79999999999998, 181.1, 176.6, 157.7, 166.4, 190.99999999999997, 166.99999999999997, 171.19999999999993, 194.6, 178.4, 154.1, 181.09999999999994, 179.3, 181.9999999999999, 184.69999999999996, 188.29999999999995, 198.2, 184.69999999999996, 146.89999999999992, 199.1, 161.29999999999998, 120.79999999999984, 169.09999999999997, 142.39999999999998, 131.6, 169.1, 154.0999999999999, 181.99999999999997, 179.3, 152.89999999999998, 175.69999999999993, 168.5, 166.1, 169.39999999999998, 192.8, 199.1, 192.8, 181.39999999999995, 164.0, 157.1, 199.1, 183.79999999999993, 169.1, 170.0, 164.29999999999998, 155.9, 145.09999999999997, 195.5, 183.8, 193.7, 191.89999999999998, 193.7, 191.9, 96.80000000000001, 170.29999999999998, 175.1, 200.0, 182.29999999999998, 186.5, 194.6, 112.09999999999977, 188.29999999999998, 187.39999999999998, 186.49999999999997, 182.89999999999998, 194.29999999999998, 192.5, 184.69999999999996, 146.6, 173.0, 200.0, 200.0, 165.19999999999993, 188.3, 190.99999999999997, 155.9, 200.0, 175.69999999999993, 194.59999999999997, 171.5, 168.49999999999997, 200.0, 184.7, 199.1, 182.89999999999998, 189.20000000000002, 170.6, 151.70000000000002, 200.0, 180.2, 163.99999999999997, 187.4, 171.19999999999982, 200.0, 161.0, 185.5999999999999, 190.1, 155.90000000000003, 200.0, 173.9, 200.0, 200.0, 176.29999999999993, 171.49999999999994, 171.19999999999987, 189.19999999999996, 181.99999999999997, 178.1, 177.5, 199.1, 172.09999999999997, 191.9, 183.8, 172.99999999999994, 163.99999999999983, 159.49999999999997], "policy_predator_policy_reward": [13.0, 13.0, 0.0, 0.0, 0.0, 10.0, 8.0, 8.0, 23.0, 32.0, 0.0, 6.0, 9.0, 0.0, 0.0, 0.0, 6.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13.0, 1.0, 7.0, 8.0, 0.0, 11.0, 3.0, 0.0, 7.0, 12.0, 0.0, 0.0, 5.0, 7.0, 4.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13.0, 0.0, 10.0, 0.0, 12.0, 9.0, 8.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 2.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 7.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 12.0, 0.0, 0.0, 0.0, 0.0, 10.0, 6.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 2.0, 4.0, 7.0, 0.0, 0.0, 10.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 18.0, 17.0, 8.0, 0.0, 4.0, 1.0, 0.0, 0.0, 6.0, 11.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 7.0, 9.0, 0.0, 0.0, 0.0, 8.0, 9.0, 8.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 14.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 5.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 13.217343572247856, "mean_inference_ms": 31.539223928303446, "mean_action_processing_ms": 6.711411086194432, "mean_env_wait_ms": 7.492597088678649, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006529331207275391, "StateBufferConnector_ms": 0.004635930061340332, "ViewRequirementAgentConnector_ms": 0.1780259609222412}, "num_episodes": 23, "episode_return_max": 400.0, "episode_return_min": 252.19999999999965, "episode_return_mean": 354.58700000000005, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2112000, "num_agent_steps_trained": 2112000, "num_env_steps_sampled": 528000, "num_env_steps_trained": 528000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 195.05286408661914, "num_env_steps_trained_throughput_per_sec": 195.05286408661914, "timesteps_total": 528000, "num_env_steps_sampled_lifetime": 528000, "num_agent_steps_sampled_lifetime": 2112000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2112000, "timers": {"training_iteration_time_ms": 118347.934, "restore_workers_time_ms": 0.016, "training_step_time_ms": 118347.858, "sample_time_ms": 101224.431, "learn_time_ms": 17099.146, "learn_throughput": 233.93, "synch_weights_time_ms": 18.516}, "counters": {"num_env_steps_sampled": 528000, "num_env_steps_trained": 528000, "num_agent_steps_sampled": 2112000, "num_agent_steps_trained": 2112000}, "done": false, "training_iteration": 132, "trial_id": "75ec3_00000", "date": "2024-08-13_05-05-21", "timestamp": 1723539921, "time_this_iter_s": 20.580758094787598, "time_total_s": 12670.372443914413, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b1afee50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 12670.372443914413, "iterations_since_restore": 132, "perf": {"cpu_util_percent": 79.46551724137929, "ram_util_percent": 83.34137931034483}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.268359308630701, "cur_kl_coeff": 0.23118135034828804, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.817989215901289, "policy_loss": -0.010507896542795514, "vf_loss": 2.82568169497939, "vf_explained_var": 0.457822574446441, "kl": 0.012178352775031525, "entropy": 1.0487583754554628, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 250425.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.299472274451896, "cur_kl_coeff": 4.8467614016778955e-28, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.17831772828780154, "policy_loss": 9.870874380111379e-05, "vf_loss": 0.178219019107058, "vf_explained_var": 0.010341414919605961, "kl": 0.005775900123245566, "entropy": 0.6713004971938158, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 250425.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 532000, "num_env_steps_trained": 532000, "num_agent_steps_sampled": 2128000, "num_agent_steps_trained": 2128000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": 275.19999999999993, "episode_reward_mean": 355.9190000000001, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 96.80000000000001, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 18.0}, "policy_reward_mean": {"prey_policy": 175.37449999999998, "predator_policy": 2.585}, "custom_metrics": {}, "hist_stats": {"episode_reward": [351.60000000000036, 352.5, 329.0999999999999, 358.1000000000002, 275.19999999999993, 353.1, 352.79999999999995, 352.29999999999995, 357.69999999999993, 377.1000000000005, 379.30000000000007, 375.70000000000005, 380.2, 373.0000000000002, 353.29999999999995, 352.10000000000036, 326.5, 358.19999999999993, 373.0, 378.4, 344.79999999999995, 334.8, 379.29999999999995, 335.9000000000001, 355.9, 340.3, 364.3999999999999, 346.2000000000003, 373.0, 335.2000000000002, 361.30000000000035, 373.0000000000001, 382.90000000000003, 346.0, 282.10000000000036, 318.5000000000001, 312.7000000000002, 336.1000000000001, 342.19999999999993, 350.2000000000002, 340.5, 391.9, 376.19999999999993, 332.1, 382.90000000000015, 349.1, 329.19999999999993, 340.60000000000014, 377.49999999999994, 385.5999999999999, 323.69999999999993, 353.4, 387.30000000000007, 381.1, 317.40000000000066, 373.9, 378.20000000000005, 378.20000000000005, 335.6, 400.0, 361.5, 363.9, 375.69999999999993, 374.09999999999997, 368.50000000000017, 383.8, 372.0999999999999, 338.29999999999995, 380.20000000000005, 354.4, 371.2000000000007, 359.60000000000036, 345.9999999999999, 373.9, 400.0, 356.8000000000002, 360.39999999999986, 367.1000000000001, 376.6, 370.0, 356.79999999999995, 323.50000000000045, 351.4000000000001, 393.7000000000001, 337.40000000000015, 349.6, 307.29999999999984, 366.50000000000006, 347.9, 355.9, 363.6, 361.30000000000024, 351.9, 347.6000000000004, 342.6, 331.4, 385.9, 332.9000000000003, 325.79999999999984, 346.4000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [173.59999999999997, 169.99999999999983, 176.0, 168.5, 167.0, 148.10000000000002, 180.19999999999996, 170.9, 128.30000000000004, 134.90000000000003, 170.29999999999998, 177.8, 178.09999999999997, 163.7, 169.3999999999998, 182.9, 182.9, 174.8, 196.39999999999998, 178.6999999999999, 193.7, 185.6, 195.5, 180.2, 183.8, 196.4, 196.4, 176.5999999999999, 160.1, 180.2, 142.09999999999985, 200.0, 143.0, 171.5, 192.79999999999998, 148.4, 191.0, 182.0, 186.5, 191.9, 170.29999999999995, 168.5, 181.1, 151.7, 192.79999999999998, 186.5, 161.3, 161.6, 174.79999999999998, 181.1, 176.6, 157.7, 166.4, 190.99999999999997, 166.99999999999997, 171.19999999999993, 194.6, 178.4, 154.1, 181.09999999999994, 179.3, 181.9999999999999, 184.69999999999996, 188.29999999999995, 198.2, 184.69999999999996, 146.89999999999992, 199.1, 161.29999999999998, 120.79999999999984, 169.09999999999997, 142.39999999999998, 131.6, 169.1, 154.0999999999999, 181.99999999999997, 179.3, 152.89999999999998, 175.69999999999993, 168.5, 166.1, 169.39999999999998, 192.8, 199.1, 192.8, 181.39999999999995, 164.0, 157.1, 199.1, 183.79999999999993, 169.1, 170.0, 164.29999999999998, 155.9, 145.09999999999997, 195.5, 183.8, 193.7, 191.89999999999998, 193.7, 191.9, 96.80000000000001, 170.29999999999998, 175.1, 200.0, 182.29999999999998, 186.5, 194.6, 112.09999999999977, 188.29999999999998, 187.39999999999998, 186.49999999999997, 182.89999999999998, 194.29999999999998, 192.5, 184.69999999999996, 146.6, 173.0, 200.0, 200.0, 165.19999999999993, 188.3, 190.99999999999997, 155.9, 200.0, 175.69999999999993, 194.59999999999997, 171.5, 168.49999999999997, 200.0, 184.7, 199.1, 182.89999999999998, 189.20000000000002, 170.6, 151.70000000000002, 200.0, 180.2, 163.99999999999997, 187.4, 171.19999999999982, 200.0, 161.0, 185.5999999999999, 190.1, 155.90000000000003, 200.0, 173.9, 200.0, 200.0, 176.29999999999993, 171.49999999999994, 171.19999999999987, 189.19999999999996, 181.99999999999997, 178.1, 177.5, 199.1, 172.09999999999997, 191.9, 183.8, 172.99999999999994, 163.99999999999983, 159.49999999999997, 167.0, 175.39999999999998, 194.59999999999997, 199.1, 179.3, 142.09999999999994, 170.3, 170.29999999999998, 170.3, 136.9999999999999, 187.39999999999998, 169.1, 163.7, 180.2, 176.6, 179.3, 191.0, 170.6, 171.2, 190.09999999999994, 170.6, 173.29999999999998, 147.19999999999987, 190.4, 155.29999999999987, 179.29999999999995, 190.09999999999994, 131.30000000000004, 198.2, 184.7, 160.39999999999995, 165.49999999999997, 130.10000000000002, 184.7, 172.99999999999991, 166.39999999999995], "policy_predator_policy_reward": [1.0, 7.0, 8.0, 0.0, 11.0, 3.0, 0.0, 7.0, 12.0, 0.0, 0.0, 5.0, 7.0, 4.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13.0, 0.0, 10.0, 0.0, 12.0, 9.0, 8.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 2.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 7.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 12.0, 0.0, 0.0, 0.0, 0.0, 10.0, 6.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 2.0, 4.0, 7.0, 0.0, 0.0, 10.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 18.0, 17.0, 8.0, 0.0, 4.0, 1.0, 0.0, 0.0, 6.0, 11.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 7.0, 9.0, 0.0, 0.0, 0.0, 8.0, 9.0, 8.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 14.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 5.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 16.0, 0.0, 9.0, 0.0, 0.0, 0.0, 4.0, 6.0, 4.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 8.0, 0.0, 10.0, 0.0, 0.0, 8.0, 0.0, 10.0, 3.0, 0.0, 7.0, 0.0, 11.0, 0.0, 7.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 13.314910776851182, "mean_inference_ms": 30.66391489881499, "mean_action_processing_ms": 6.489991793333608, "mean_env_wait_ms": 8.127049751017699, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.008570671081542969, "StateBufferConnector_ms": 0.004954814910888672, "ViewRequirementAgentConnector_ms": 0.18827557563781738}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": 275.19999999999993, "episode_return_mean": 355.9190000000001, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2128000, "num_agent_steps_trained": 2128000, "num_env_steps_sampled": 532000, "num_env_steps_trained": 532000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 188.27691704664215, "num_env_steps_trained_throughput_per_sec": 188.27691704664215, "timesteps_total": 532000, "num_env_steps_sampled_lifetime": 532000, "num_agent_steps_sampled_lifetime": 2128000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2128000, "timers": {"training_iteration_time_ms": 118517.024, "restore_workers_time_ms": 0.016, "training_step_time_ms": 118516.948, "sample_time_ms": 101380.72, "learn_time_ms": 17110.071, "learn_throughput": 233.78, "synch_weights_time_ms": 21.128}, "counters": {"num_env_steps_sampled": 532000, "num_env_steps_trained": 532000, "num_agent_steps_sampled": 2128000, "num_agent_steps_trained": 2128000}, "done": false, "training_iteration": 133, "trial_id": "75ec3_00000", "date": "2024-08-13_05-05-42", "timestamp": 1723539942, "time_this_iter_s": 21.298853158950806, "time_total_s": 12691.671297073364, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b24c1670>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 12691.671297073364, "iterations_since_restore": 133, "perf": {"cpu_util_percent": 81.06333333333332, "ram_util_percent": 83.16000000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.2034891316026606, "cur_kl_coeff": 0.23118135034828804, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.0999597497402676, "policy_loss": 0.003692611125568864, "vf_loss": 1.0953941565499734, "vf_explained_var": 0.4484555462365428, "kl": 0.0037761832794931264, "entropy": 1.0595220901347973, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 252315.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.32664913072314844, "cur_kl_coeff": 4.8467614016778955e-28, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.17086946658947796, "policy_loss": -0.0004762857982386199, "vf_loss": 0.17134575235888994, "vf_explained_var": -0.03582955110010016, "kl": 0.00812977266236606, "entropy": 0.822941256200195, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 252315.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 536000, "num_env_steps_trained": 536000, "num_agent_steps_sampled": 2144000, "num_agent_steps_trained": 2144000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": 282.10000000000036, "episode_reward_mean": 359.6880000000001, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 96.80000000000001, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 18.0}, "policy_reward_mean": {"prey_policy": 177.509, "predator_policy": 2.335}, "custom_metrics": {}, "hist_stats": {"episode_reward": [379.29999999999995, 335.9000000000001, 355.9, 340.3, 364.3999999999999, 346.2000000000003, 373.0, 335.2000000000002, 361.30000000000035, 373.0000000000001, 382.90000000000003, 346.0, 282.10000000000036, 318.5000000000001, 312.7000000000002, 336.1000000000001, 342.19999999999993, 350.2000000000002, 340.5, 391.9, 376.19999999999993, 332.1, 382.90000000000015, 349.1, 329.19999999999993, 340.60000000000014, 377.49999999999994, 385.5999999999999, 323.69999999999993, 353.4, 387.30000000000007, 381.1, 317.40000000000066, 373.9, 378.20000000000005, 378.20000000000005, 335.6, 400.0, 361.5, 363.9, 375.69999999999993, 374.09999999999997, 368.50000000000017, 383.8, 372.0999999999999, 338.29999999999995, 380.20000000000005, 354.4, 371.2000000000007, 359.60000000000036, 345.9999999999999, 373.9, 400.0, 356.8000000000002, 360.39999999999986, 367.1000000000001, 376.6, 370.0, 356.79999999999995, 323.50000000000045, 351.4000000000001, 393.7000000000001, 337.40000000000015, 349.6, 307.29999999999984, 366.50000000000006, 347.9, 355.9, 363.6, 361.30000000000024, 351.9, 347.6000000000004, 342.6, 331.4, 385.9, 332.9000000000003, 325.79999999999984, 346.4000000000003, 340.6, 336.0, 378.4, 359.9000000000002, 380.5, 380.20000000000005, 354.90000000000003, 359.79999999999995, 390.1, 358.79999999999995, 375.70000000000005, 390.1, 383.79999999999995, 363.9, 379.5, 374.9, 370.29999999999995, 361.4, 383.80000000000007, 392.8, 356.6, 393.7], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [192.79999999999998, 186.5, 161.3, 161.6, 174.79999999999998, 181.1, 176.6, 157.7, 166.4, 190.99999999999997, 166.99999999999997, 171.19999999999993, 194.6, 178.4, 154.1, 181.09999999999994, 179.3, 181.9999999999999, 184.69999999999996, 188.29999999999995, 198.2, 184.69999999999996, 146.89999999999992, 199.1, 161.29999999999998, 120.79999999999984, 169.09999999999997, 142.39999999999998, 131.6, 169.1, 154.0999999999999, 181.99999999999997, 179.3, 152.89999999999998, 175.69999999999993, 168.5, 166.1, 169.39999999999998, 192.8, 199.1, 192.8, 181.39999999999995, 164.0, 157.1, 199.1, 183.79999999999993, 169.1, 170.0, 164.29999999999998, 155.9, 145.09999999999997, 195.5, 183.8, 193.7, 191.89999999999998, 193.7, 191.9, 96.80000000000001, 170.29999999999998, 175.1, 200.0, 182.29999999999998, 186.5, 194.6, 112.09999999999977, 188.29999999999998, 187.39999999999998, 186.49999999999997, 182.89999999999998, 194.29999999999998, 192.5, 184.69999999999996, 146.6, 173.0, 200.0, 200.0, 165.19999999999993, 188.3, 190.99999999999997, 155.9, 200.0, 175.69999999999993, 194.59999999999997, 171.5, 168.49999999999997, 200.0, 184.7, 199.1, 182.89999999999998, 189.20000000000002, 170.6, 151.70000000000002, 200.0, 180.2, 163.99999999999997, 187.4, 171.19999999999982, 200.0, 161.0, 185.5999999999999, 190.1, 155.90000000000003, 200.0, 173.9, 200.0, 200.0, 176.29999999999993, 171.49999999999994, 171.19999999999987, 189.19999999999996, 181.99999999999997, 178.1, 177.5, 199.1, 172.09999999999997, 191.9, 183.8, 172.99999999999994, 163.99999999999983, 159.49999999999997, 167.0, 175.39999999999998, 194.59999999999997, 199.1, 179.3, 142.09999999999994, 170.3, 170.29999999999998, 170.3, 136.9999999999999, 187.39999999999998, 169.1, 163.7, 180.2, 176.6, 179.3, 191.0, 170.6, 171.2, 190.09999999999994, 170.6, 173.29999999999998, 147.19999999999987, 190.4, 155.29999999999987, 179.29999999999995, 190.09999999999994, 131.30000000000004, 198.2, 184.7, 160.39999999999995, 165.49999999999997, 130.10000000000002, 184.7, 172.99999999999991, 166.39999999999995, 155.0, 185.6, 152.3, 178.7, 181.99999999999994, 196.39999999999998, 200.0, 152.89999999999998, 196.4, 181.1, 200.0, 180.2, 179.6, 170.3, 155.0, 192.8, 194.6, 195.5, 154.39999999999998, 196.39999999999998, 196.39999999999998, 179.3, 191.0, 199.1, 200.0, 183.8, 189.2, 169.7, 199.1, 172.4, 170.89999999999998, 200.0, 173.9, 196.4, 197.3, 151.10000000000002, 193.7, 190.1, 196.4, 196.4, 172.7, 176.9, 193.7, 200.0], "policy_predator_policy_reward": [0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 7.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 12.0, 0.0, 0.0, 0.0, 0.0, 10.0, 6.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 2.0, 4.0, 7.0, 0.0, 0.0, 10.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 18.0, 17.0, 8.0, 0.0, 4.0, 1.0, 0.0, 0.0, 6.0, 11.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 7.0, 9.0, 0.0, 0.0, 0.0, 8.0, 9.0, 8.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 14.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 5.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 16.0, 0.0, 9.0, 0.0, 0.0, 0.0, 4.0, 6.0, 4.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 8.0, 0.0, 10.0, 0.0, 0.0, 8.0, 0.0, 10.0, 3.0, 0.0, 7.0, 0.0, 11.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 7.0, 0.0, 3.0, 0.0, 0.0, 0.0, 5.0, 0.0, 12.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 8.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 13.207113643974662, "mean_inference_ms": 30.456494060240285, "mean_action_processing_ms": 6.442549795540798, "mean_env_wait_ms": 8.05576235913873, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.010909676551818848, "StateBufferConnector_ms": 0.009113430976867676, "ViewRequirementAgentConnector_ms": 0.2159961462020874}, "num_episodes": 22, "episode_return_max": 400.0, "episode_return_min": 282.10000000000036, "episode_return_mean": 359.6880000000001, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2144000, "num_agent_steps_trained": 2144000, "num_env_steps_sampled": 536000, "num_env_steps_trained": 536000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 179.93232671124332, "num_env_steps_trained_throughput_per_sec": 179.93232671124332, "timesteps_total": 536000, "num_env_steps_sampled_lifetime": 536000, "num_agent_steps_sampled_lifetime": 2144000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2144000, "timers": {"training_iteration_time_ms": 19666.885, "restore_workers_time_ms": 0.018, "training_step_time_ms": 19666.806, "sample_time_ms": 2890.141, "learn_time_ms": 16749.602, "learn_throughput": 238.812, "synch_weights_time_ms": 22.147}, "counters": {"num_env_steps_sampled": 536000, "num_env_steps_trained": 536000, "num_agent_steps_sampled": 2144000, "num_agent_steps_trained": 2144000}, "done": false, "training_iteration": 134, "trial_id": "75ec3_00000", "date": "2024-08-13_05-06-05", "timestamp": 1723539965, "time_this_iter_s": 22.300122261047363, "time_total_s": 12713.971419334412, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b24f24c0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 12713.971419334412, "iterations_since_restore": 134, "perf": {"cpu_util_percent": 82.88387096774194, "ram_util_percent": 83.40645161290321}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.258111264182146, "cur_kl_coeff": 0.11559067517414402, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.2175989677981724, "policy_loss": -0.005670479532311518, "vf_loss": 2.222360298368666, "vf_explained_var": 0.43851627836782464, "kl": 0.007865213869031041, "entropy": 1.0019734548513222, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 254205.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.29361075082271504, "cur_kl_coeff": 4.8467614016778955e-28, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.15129175325707783, "policy_loss": -0.0006008065388188081, "vf_loss": 0.15189255997581683, "vf_explained_var": -0.04665688985869998, "kl": 0.013479744561946179, "entropy": 0.9502869902464448, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 254205.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 540000, "num_env_steps_trained": 540000, "num_agent_steps_sampled": 2160000, "num_agent_steps_trained": 2160000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": 307.29999999999984, "episode_reward_mean": 361.97200000000004, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 96.80000000000001, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 19.0}, "policy_reward_mean": {"prey_policy": 178.481, "predator_policy": 2.505}, "custom_metrics": {}, "hist_stats": {"episode_reward": [340.5, 391.9, 376.19999999999993, 332.1, 382.90000000000015, 349.1, 329.19999999999993, 340.60000000000014, 377.49999999999994, 385.5999999999999, 323.69999999999993, 353.4, 387.30000000000007, 381.1, 317.40000000000066, 373.9, 378.20000000000005, 378.20000000000005, 335.6, 400.0, 361.5, 363.9, 375.69999999999993, 374.09999999999997, 368.50000000000017, 383.8, 372.0999999999999, 338.29999999999995, 380.20000000000005, 354.4, 371.2000000000007, 359.60000000000036, 345.9999999999999, 373.9, 400.0, 356.8000000000002, 360.39999999999986, 367.1000000000001, 376.6, 370.0, 356.79999999999995, 323.50000000000045, 351.4000000000001, 393.7000000000001, 337.40000000000015, 349.6, 307.29999999999984, 366.50000000000006, 347.9, 355.9, 363.6, 361.30000000000024, 351.9, 347.6000000000004, 342.6, 331.4, 385.9, 332.9000000000003, 325.79999999999984, 346.4000000000003, 340.6, 336.0, 378.4, 359.9000000000002, 380.5, 380.20000000000005, 354.90000000000003, 359.79999999999995, 390.1, 358.79999999999995, 375.70000000000005, 390.1, 383.79999999999995, 363.9, 379.5, 374.9, 370.29999999999995, 361.4, 383.80000000000007, 392.8, 356.6, 393.7, 350.5, 328.69999999999993, 320.8000000000006, 381.4000000000002, 353.9000000000001, 391.9, 391.9, 360.40000000000003, 389.9, 374.7999999999999, 332.50000000000006, 345.29999999999995, 355.4000000000001, 335.2000000000001, 341.7000000000003, 386.5000000000001, 366.0, 356.79999999999995], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [166.1, 169.39999999999998, 192.8, 199.1, 192.8, 181.39999999999995, 164.0, 157.1, 199.1, 183.79999999999993, 169.1, 170.0, 164.29999999999998, 155.9, 145.09999999999997, 195.5, 183.8, 193.7, 191.89999999999998, 193.7, 191.9, 96.80000000000001, 170.29999999999998, 175.1, 200.0, 182.29999999999998, 186.5, 194.6, 112.09999999999977, 188.29999999999998, 187.39999999999998, 186.49999999999997, 182.89999999999998, 194.29999999999998, 192.5, 184.69999999999996, 146.6, 173.0, 200.0, 200.0, 165.19999999999993, 188.3, 190.99999999999997, 155.9, 200.0, 175.69999999999993, 194.59999999999997, 171.5, 168.49999999999997, 200.0, 184.7, 199.1, 182.89999999999998, 189.20000000000002, 170.6, 151.70000000000002, 200.0, 180.2, 163.99999999999997, 187.4, 171.19999999999982, 200.0, 161.0, 185.5999999999999, 190.1, 155.90000000000003, 200.0, 173.9, 200.0, 200.0, 176.29999999999993, 171.49999999999994, 171.19999999999987, 189.19999999999996, 181.99999999999997, 178.1, 177.5, 199.1, 172.09999999999997, 191.9, 183.8, 172.99999999999994, 163.99999999999983, 159.49999999999997, 167.0, 175.39999999999998, 194.59999999999997, 199.1, 179.3, 142.09999999999994, 170.3, 170.29999999999998, 170.3, 136.9999999999999, 187.39999999999998, 169.1, 163.7, 180.2, 176.6, 179.3, 191.0, 170.6, 171.2, 190.09999999999994, 170.6, 173.29999999999998, 147.19999999999987, 190.4, 155.29999999999987, 179.29999999999995, 190.09999999999994, 131.30000000000004, 198.2, 184.7, 160.39999999999995, 165.49999999999997, 130.10000000000002, 184.7, 172.99999999999991, 166.39999999999995, 155.0, 185.6, 152.3, 178.7, 181.99999999999994, 196.39999999999998, 200.0, 152.89999999999998, 196.4, 181.1, 200.0, 180.2, 179.6, 170.3, 155.0, 192.8, 194.6, 195.5, 154.39999999999998, 196.39999999999998, 196.39999999999998, 179.3, 191.0, 199.1, 200.0, 183.8, 189.2, 169.7, 199.1, 172.4, 170.89999999999998, 200.0, 173.9, 196.4, 197.3, 151.10000000000002, 193.7, 190.1, 196.4, 196.4, 172.7, 176.9, 193.7, 200.0, 164.9, 185.6, 164.89999999999998, 153.8, 159.49999999999986, 161.29999999999998, 179.29999999999995, 199.1, 174.79999999999998, 169.1, 197.29999999999998, 194.6, 200.0, 191.9, 196.4, 164.0, 193.7, 195.2, 190.09999999999994, 184.69999999999996, 160.4, 172.1, 165.8, 168.49999999999991, 191.89999999999998, 147.5, 168.49999999999997, 166.69999999999996, 169.09999999999994, 161.6, 186.49999999999997, 200.0, 168.8, 189.2, 172.1, 151.7], "policy_predator_policy_reward": [5.0, 0.0, 0.0, 0.0, 0.0, 2.0, 4.0, 7.0, 0.0, 0.0, 10.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 18.0, 17.0, 8.0, 0.0, 4.0, 1.0, 0.0, 0.0, 6.0, 11.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 7.0, 9.0, 0.0, 0.0, 0.0, 8.0, 9.0, 8.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 14.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 5.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 16.0, 0.0, 9.0, 0.0, 0.0, 0.0, 4.0, 6.0, 4.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 8.0, 0.0, 10.0, 0.0, 0.0, 8.0, 0.0, 10.0, 3.0, 0.0, 7.0, 0.0, 11.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 7.0, 0.0, 3.0, 0.0, 0.0, 0.0, 5.0, 0.0, 12.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 8.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 3.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 5.0, 16.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 8.0, 14.0, 19.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 13.127306557933405, "mean_inference_ms": 30.278042798632697, "mean_action_processing_ms": 6.402477957153906, "mean_env_wait_ms": 8.004210443860437, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.011105060577392578, "StateBufferConnector_ms": 0.009390115737915039, "ViewRequirementAgentConnector_ms": 0.22079873085021973}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": 307.29999999999984, "episode_return_mean": 361.97200000000004, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2160000, "num_agent_steps_trained": 2160000, "num_env_steps_sampled": 540000, "num_env_steps_trained": 540000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 185.14438339183675, "num_env_steps_trained_throughput_per_sec": 185.14438339183675, "timesteps_total": 540000, "num_env_steps_sampled_lifetime": 540000, "num_agent_steps_sampled_lifetime": 2160000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2160000, "timers": {"training_iteration_time_ms": 19883.893, "restore_workers_time_ms": 0.018, "training_step_time_ms": 19883.814, "sample_time_ms": 2941.631, "learn_time_ms": 16915.6, "learn_throughput": 236.468, "synch_weights_time_ms": 22.11}, "counters": {"num_env_steps_sampled": 540000, "num_env_steps_trained": 540000, "num_agent_steps_sampled": 2160000, "num_agent_steps_trained": 2160000}, "done": false, "training_iteration": 135, "trial_id": "75ec3_00000", "date": "2024-08-13_05-06-27", "timestamp": 1723539987, "time_this_iter_s": 21.659557104110718, "time_total_s": 12735.630976438522, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b24c9d30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 12735.630976438522, "iterations_since_restore": 135, "perf": {"cpu_util_percent": 81.94516129032259, "ram_util_percent": 83.49354838709678}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.484297940718434, "cur_kl_coeff": 0.11559067517414402, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.9702587317852747, "policy_loss": -0.0032139175449542347, "vf_loss": 0.9720282175868907, "vf_explained_var": 0.36814207879323807, "kl": 0.012496101176959675, "entropy": 1.0240155091992131, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 256095.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.2857098127927178, "cur_kl_coeff": 4.8467614016778955e-28, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.23034383113737458, "policy_loss": 7.851306674262834e-05, "vf_loss": 0.23026531659690022, "vf_explained_var": 0.09499867094887628, "kl": 0.002989420220278087, "entropy": 0.8938772821552539, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 256095.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 544000, "num_env_steps_trained": 544000, "num_agent_steps_sampled": 2176000, "num_agent_steps_trained": 2176000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": 307.29999999999984, "episode_reward_mean": 362.05800000000005, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 130.10000000000002, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 20.0}, "policy_reward_mean": {"prey_policy": 178.51399999999998, "predator_policy": 2.515}, "custom_metrics": {}, "hist_stats": {"episode_reward": [335.6, 400.0, 361.5, 363.9, 375.69999999999993, 374.09999999999997, 368.50000000000017, 383.8, 372.0999999999999, 338.29999999999995, 380.20000000000005, 354.4, 371.2000000000007, 359.60000000000036, 345.9999999999999, 373.9, 400.0, 356.8000000000002, 360.39999999999986, 367.1000000000001, 376.6, 370.0, 356.79999999999995, 323.50000000000045, 351.4000000000001, 393.7000000000001, 337.40000000000015, 349.6, 307.29999999999984, 366.50000000000006, 347.9, 355.9, 363.6, 361.30000000000024, 351.9, 347.6000000000004, 342.6, 331.4, 385.9, 332.9000000000003, 325.79999999999984, 346.4000000000003, 340.6, 336.0, 378.4, 359.9000000000002, 380.5, 380.20000000000005, 354.90000000000003, 359.79999999999995, 390.1, 358.79999999999995, 375.70000000000005, 390.1, 383.79999999999995, 363.9, 379.5, 374.9, 370.29999999999995, 361.4, 383.80000000000007, 392.8, 356.6, 393.7, 350.5, 328.69999999999993, 320.8000000000006, 381.4000000000002, 353.9000000000001, 391.9, 391.9, 360.40000000000003, 389.9, 374.7999999999999, 332.50000000000006, 345.29999999999995, 355.4000000000001, 335.2000000000001, 341.7000000000003, 386.5000000000001, 366.0, 356.79999999999995, 362.1999999999999, 354.7, 398.2, 373.7, 373.70000000000005, 340.6, 349.6, 373.4, 393.29999999999995, 365.3, 309.80000000000007, 371.29999999999995, 393.7, 329.4, 395.5, 316.1, 349.1, 357.8], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [146.6, 173.0, 200.0, 200.0, 165.19999999999993, 188.3, 190.99999999999997, 155.9, 200.0, 175.69999999999993, 194.59999999999997, 171.5, 168.49999999999997, 200.0, 184.7, 199.1, 182.89999999999998, 189.20000000000002, 170.6, 151.70000000000002, 200.0, 180.2, 163.99999999999997, 187.4, 171.19999999999982, 200.0, 161.0, 185.5999999999999, 190.1, 155.90000000000003, 200.0, 173.9, 200.0, 200.0, 176.29999999999993, 171.49999999999994, 171.19999999999987, 189.19999999999996, 181.99999999999997, 178.1, 177.5, 199.1, 172.09999999999997, 191.9, 183.8, 172.99999999999994, 163.99999999999983, 159.49999999999997, 167.0, 175.39999999999998, 194.59999999999997, 199.1, 179.3, 142.09999999999994, 170.3, 170.29999999999998, 170.3, 136.9999999999999, 187.39999999999998, 169.1, 163.7, 180.2, 176.6, 179.3, 191.0, 170.6, 171.2, 190.09999999999994, 170.6, 173.29999999999998, 147.19999999999987, 190.4, 155.29999999999987, 179.29999999999995, 190.09999999999994, 131.30000000000004, 198.2, 184.7, 160.39999999999995, 165.49999999999997, 130.10000000000002, 184.7, 172.99999999999991, 166.39999999999995, 155.0, 185.6, 152.3, 178.7, 181.99999999999994, 196.39999999999998, 200.0, 152.89999999999998, 196.4, 181.1, 200.0, 180.2, 179.6, 170.3, 155.0, 192.8, 194.6, 195.5, 154.39999999999998, 196.39999999999998, 196.39999999999998, 179.3, 191.0, 199.1, 200.0, 183.8, 189.2, 169.7, 199.1, 172.4, 170.89999999999998, 200.0, 173.9, 196.4, 197.3, 151.10000000000002, 193.7, 190.1, 196.4, 196.4, 172.7, 176.9, 193.7, 200.0, 164.9, 185.6, 164.89999999999998, 153.8, 159.49999999999986, 161.29999999999998, 179.29999999999995, 199.1, 174.79999999999998, 169.1, 197.29999999999998, 194.6, 200.0, 191.9, 196.4, 164.0, 193.7, 195.2, 190.09999999999994, 184.69999999999996, 160.4, 172.1, 165.8, 168.49999999999991, 191.89999999999998, 147.5, 168.49999999999997, 166.69999999999996, 169.09999999999994, 161.6, 186.49999999999997, 200.0, 168.8, 189.2, 172.1, 151.7, 199.1, 163.10000000000002, 171.2, 174.5, 198.2, 200.0, 197.0, 175.7, 197.0, 175.7, 153.2, 187.4, 173.9, 175.7, 169.1, 197.3, 200.0, 191.29999999999998, 179.3, 179.0, 161.9, 137.89999999999998, 200.0, 158.3, 193.7, 200.0, 178.7, 130.7, 199.1, 196.39999999999998, 143.00000000000003, 163.1, 175.1, 161.0, 186.5, 158.3], "policy_predator_policy_reward": [7.0, 9.0, 0.0, 0.0, 0.0, 8.0, 9.0, 8.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 14.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 5.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 16.0, 0.0, 9.0, 0.0, 0.0, 0.0, 4.0, 6.0, 4.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 8.0, 0.0, 10.0, 0.0, 0.0, 8.0, 0.0, 10.0, 3.0, 0.0, 7.0, 0.0, 11.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 7.0, 0.0, 3.0, 0.0, 0.0, 0.0, 5.0, 0.0, 12.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 8.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 3.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 5.0, 16.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 8.0, 14.0, 19.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 2.0, 0.0, 7.0, 10.0, 0.0, 13.0, 0.0, 0.0, 0.0, 0.0, 20.0, 0.0, 0.0, 10.0, 0.0, 13.0, 0.0, 0.0, 13.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 13.04891137135025, "mean_inference_ms": 30.102789209482598, "mean_action_processing_ms": 6.363069467388293, "mean_env_wait_ms": 7.953441129363898, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.010329842567443848, "StateBufferConnector_ms": 0.011312603950500488, "ViewRequirementAgentConnector_ms": 0.22662687301635742}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": 307.29999999999984, "episode_return_mean": 362.05800000000005, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2176000, "num_agent_steps_trained": 2176000, "num_env_steps_sampled": 544000, "num_env_steps_trained": 544000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 182.83028734716603, "num_env_steps_trained_throughput_per_sec": 182.83028734716603, "timesteps_total": 544000, "num_env_steps_sampled_lifetime": 544000, "num_agent_steps_sampled_lifetime": 2176000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2176000, "timers": {"training_iteration_time_ms": 20136.595, "restore_workers_time_ms": 0.018, "training_step_time_ms": 20136.517, "sample_time_ms": 2950.711, "learn_time_ms": 17159.063, "learn_throughput": 233.113, "synch_weights_time_ms": 22.57}, "counters": {"num_env_steps_sampled": 544000, "num_env_steps_trained": 544000, "num_agent_steps_sampled": 2176000, "num_agent_steps_trained": 2176000}, "done": false, "training_iteration": 136, "trial_id": "75ec3_00000", "date": "2024-08-13_05-06-49", "timestamp": 1723540009, "time_this_iter_s": 21.931394815444946, "time_total_s": 12757.562371253967, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b24f2b80>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 12757.562371253967, "iterations_since_restore": 136, "perf": {"cpu_util_percent": 80.59354838709677, "ram_util_percent": 83.26451612903227}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.369162905752344, "cur_kl_coeff": 0.11559067517414402, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.850977213452102, "policy_loss": -0.01573347401479998, "vf_loss": 1.86415465521434, "vf_explained_var": 0.4501942155222413, "kl": 0.022112835173807268, "entropy": 1.010048502589029, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 257985.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.2624752631691831, "cur_kl_coeff": 2.4233807008389477e-28, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.13878423822452388, "policy_loss": -0.0007065681523825756, "vf_loss": 0.1394908062475561, "vf_explained_var": 0.015699996929320077, "kl": 0.03651577591397054, "entropy": 1.042372059096735, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 257985.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 548000, "num_env_steps_trained": 548000, "num_agent_steps_sampled": 2192000, "num_agent_steps_trained": 2192000}, "env_runners": {"episode_reward_max": 399.1, "episode_reward_min": 307.29999999999984, "episode_reward_mean": 361.64300000000003, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 130.10000000000002, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 20.0}, "policy_reward_mean": {"prey_policy": 178.35649999999995, "predator_policy": 2.465}, "custom_metrics": {}, "hist_stats": {"episode_reward": [323.50000000000045, 351.4000000000001, 393.7000000000001, 337.40000000000015, 349.6, 307.29999999999984, 366.50000000000006, 347.9, 355.9, 363.6, 361.30000000000024, 351.9, 347.6000000000004, 342.6, 331.4, 385.9, 332.9000000000003, 325.79999999999984, 346.4000000000003, 340.6, 336.0, 378.4, 359.9000000000002, 380.5, 380.20000000000005, 354.90000000000003, 359.79999999999995, 390.1, 358.79999999999995, 375.70000000000005, 390.1, 383.79999999999995, 363.9, 379.5, 374.9, 370.29999999999995, 361.4, 383.80000000000007, 392.8, 356.6, 393.7, 350.5, 328.69999999999993, 320.8000000000006, 381.4000000000002, 353.9000000000001, 391.9, 391.9, 360.40000000000003, 389.9, 374.7999999999999, 332.50000000000006, 345.29999999999995, 355.4000000000001, 335.2000000000001, 341.7000000000003, 386.5000000000001, 366.0, 356.79999999999995, 362.1999999999999, 354.7, 398.2, 373.7, 373.70000000000005, 340.6, 349.6, 373.4, 393.29999999999995, 365.3, 309.80000000000007, 371.29999999999995, 393.7, 329.4, 395.5, 316.1, 349.1, 357.8, 359.0, 337.0000000000002, 341.00000000000017, 397.1, 378.6, 358.6, 369.5, 369.4, 360.0, 358.6, 339.2, 363.99999999999994, 377.49999999999994, 359.9, 358.9, 379.3, 356.4, 372.1, 391.9, 350.50000000000006, 368.8, 399.1, 358.5999999999999], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [163.99999999999983, 159.49999999999997, 167.0, 175.39999999999998, 194.59999999999997, 199.1, 179.3, 142.09999999999994, 170.3, 170.29999999999998, 170.3, 136.9999999999999, 187.39999999999998, 169.1, 163.7, 180.2, 176.6, 179.3, 191.0, 170.6, 171.2, 190.09999999999994, 170.6, 173.29999999999998, 147.19999999999987, 190.4, 155.29999999999987, 179.29999999999995, 190.09999999999994, 131.30000000000004, 198.2, 184.7, 160.39999999999995, 165.49999999999997, 130.10000000000002, 184.7, 172.99999999999991, 166.39999999999995, 155.0, 185.6, 152.3, 178.7, 181.99999999999994, 196.39999999999998, 200.0, 152.89999999999998, 196.4, 181.1, 200.0, 180.2, 179.6, 170.3, 155.0, 192.8, 194.6, 195.5, 154.39999999999998, 196.39999999999998, 196.39999999999998, 179.3, 191.0, 199.1, 200.0, 183.8, 189.2, 169.7, 199.1, 172.4, 170.89999999999998, 200.0, 173.9, 196.4, 197.3, 151.10000000000002, 193.7, 190.1, 196.4, 196.4, 172.7, 176.9, 193.7, 200.0, 164.9, 185.6, 164.89999999999998, 153.8, 159.49999999999986, 161.29999999999998, 179.29999999999995, 199.1, 174.79999999999998, 169.1, 197.29999999999998, 194.6, 200.0, 191.9, 196.4, 164.0, 193.7, 195.2, 190.09999999999994, 184.69999999999996, 160.4, 172.1, 165.8, 168.49999999999991, 191.89999999999998, 147.5, 168.49999999999997, 166.69999999999996, 169.09999999999994, 161.6, 186.49999999999997, 200.0, 168.8, 189.2, 172.1, 151.7, 199.1, 163.10000000000002, 171.2, 174.5, 198.2, 200.0, 197.0, 175.7, 197.0, 175.7, 153.2, 187.4, 173.9, 175.7, 169.1, 197.3, 200.0, 191.29999999999998, 179.3, 179.0, 161.9, 137.89999999999998, 200.0, 158.3, 193.7, 200.0, 178.7, 130.7, 199.1, 196.39999999999998, 143.00000000000003, 163.1, 175.1, 161.0, 186.5, 158.3, 170.0, 167.0, 154.1, 182.89999999999992, 178.1, 155.89999999999978, 199.1, 197.0, 194.6, 176.0, 185.59999999999997, 173.00000000000003, 168.5, 182.0, 191.0, 178.4, 181.1, 176.9, 163.99999999999991, 194.6, 173.6, 158.60000000000002, 200.0, 164.00000000000003, 200.0, 177.50000000000003, 173.9, 176.0, 184.70000000000002, 162.2, 195.5, 183.8, 184.7, 169.70000000000002, 200.0, 172.1, 197.3, 194.6, 193.7, 156.8, 176.6, 189.2, 200.0, 199.1, 173.9, 184.7], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 16.0, 0.0, 9.0, 0.0, 0.0, 0.0, 4.0, 6.0, 4.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 8.0, 0.0, 10.0, 0.0, 0.0, 8.0, 0.0, 10.0, 3.0, 0.0, 7.0, 0.0, 11.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 7.0, 0.0, 3.0, 0.0, 0.0, 0.0, 5.0, 0.0, 12.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 8.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 3.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 5.0, 16.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 8.0, 14.0, 19.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 2.0, 0.0, 7.0, 10.0, 0.0, 13.0, 0.0, 0.0, 0.0, 0.0, 20.0, 0.0, 0.0, 10.0, 0.0, 13.0, 0.0, 0.0, 13.0, 15.0, 7.0, 0.0, 0.0, 7.0, 0.0, 1.0, 0.0, 8.0, 0.0, 0.0, 0.0, 8.0, 11.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 12.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 12.960272432586697, "mean_inference_ms": 30.31959613725664, "mean_action_processing_ms": 6.312271819068977, "mean_env_wait_ms": 7.897475613077608, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01546621322631836, "StateBufferConnector_ms": 0.011481046676635742, "ViewRequirementAgentConnector_ms": 0.29588043689727783}, "num_episodes": 23, "episode_return_max": 399.1, "episode_return_min": 307.29999999999984, "episode_return_mean": 361.64300000000003, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2192000, "num_agent_steps_trained": 2192000, "num_env_steps_sampled": 548000, "num_env_steps_trained": 548000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 4.243406578158307, "num_env_steps_trained_throughput_per_sec": 4.243406578158307, "timesteps_total": 548000, "num_env_steps_sampled_lifetime": 548000, "num_agent_steps_sampled_lifetime": 2192000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2192000, "timers": {"training_iteration_time_ms": 112699.422, "restore_workers_time_ms": 0.018, "training_step_time_ms": 112699.344, "sample_time_ms": 94494.65, "learn_time_ms": 18176.28, "learn_throughput": 220.067, "synch_weights_time_ms": 22.89}, "counters": {"num_env_steps_sampled": 548000, "num_env_steps_trained": 548000, "num_agent_steps_sampled": 2192000, "num_agent_steps_trained": 2192000}, "done": false, "training_iteration": 137, "trial_id": "75ec3_00000", "date": "2024-08-13_05-22-31", "timestamp": 1723540951, "time_this_iter_s": 942.8074150085449, "time_total_s": 13700.369786262512, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2409160>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 13700.369786262512, "iterations_since_restore": 137, "perf": {"cpu_util_percent": 97.44090909090909, "ram_util_percent": 83.56818181818181}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.590216644163485, "cur_kl_coeff": 0.17338601276121607, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.1826294443910084, "policy_loss": -0.002875799170163061, "vf_loss": 1.1836852417421089, "vf_explained_var": 0.3986036019981223, "kl": 0.010496834956397286, "entropy": 1.003473157447482, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 259875.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.3151404868998619, "cur_kl_coeff": 3.6350710512584234e-28, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.15647337582533952, "policy_loss": -0.0005873330720951633, "vf_loss": 0.1570607093185317, "vf_explained_var": -0.008926717282603027, "kl": 0.01952187428772105, "entropy": 0.9540812065361669, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 259875.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 552000, "num_env_steps_trained": 552000, "num_agent_steps_sampled": 2208000, "num_agent_steps_trained": 2208000}, "env_runners": {"episode_reward_max": 399.1, "episode_reward_min": 309.80000000000007, "episode_reward_mean": 366.1570000000001, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 130.7, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 20.0}, "policy_reward_mean": {"prey_policy": 180.63350000000003, "predator_policy": 2.445}, "custom_metrics": {}, "hist_stats": {"episode_reward": [359.9000000000002, 380.5, 380.20000000000005, 354.90000000000003, 359.79999999999995, 390.1, 358.79999999999995, 375.70000000000005, 390.1, 383.79999999999995, 363.9, 379.5, 374.9, 370.29999999999995, 361.4, 383.80000000000007, 392.8, 356.6, 393.7, 350.5, 328.69999999999993, 320.8000000000006, 381.4000000000002, 353.9000000000001, 391.9, 391.9, 360.40000000000003, 389.9, 374.7999999999999, 332.50000000000006, 345.29999999999995, 355.4000000000001, 335.2000000000001, 341.7000000000003, 386.5000000000001, 366.0, 356.79999999999995, 362.1999999999999, 354.7, 398.2, 373.7, 373.70000000000005, 340.6, 349.6, 373.4, 393.29999999999995, 365.3, 309.80000000000007, 371.29999999999995, 393.7, 329.4, 395.5, 316.1, 349.1, 357.8, 359.0, 337.0000000000002, 341.00000000000017, 397.1, 378.6, 358.6, 369.5, 369.4, 360.0, 358.6, 339.2, 363.99999999999994, 377.49999999999994, 359.9, 358.9, 379.3, 356.4, 372.1, 391.9, 350.50000000000006, 368.8, 399.1, 358.5999999999999, 382.0, 396.0, 352.4, 343.8, 374.5, 379.8, 388.29999999999995, 392.0, 371.8, 378.4, 386.1, 383.8, 349.60000000000014, 366.70000000000005, 369.0, 361.3, 364.0, 354.10000000000025, 339.8, 379.9, 359.9000000000001, 355.8], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [200.0, 152.89999999999998, 196.4, 181.1, 200.0, 180.2, 179.6, 170.3, 155.0, 192.8, 194.6, 195.5, 154.39999999999998, 196.39999999999998, 196.39999999999998, 179.3, 191.0, 199.1, 200.0, 183.8, 189.2, 169.7, 199.1, 172.4, 170.89999999999998, 200.0, 173.9, 196.4, 197.3, 151.10000000000002, 193.7, 190.1, 196.4, 196.4, 172.7, 176.9, 193.7, 200.0, 164.9, 185.6, 164.89999999999998, 153.8, 159.49999999999986, 161.29999999999998, 179.29999999999995, 199.1, 174.79999999999998, 169.1, 197.29999999999998, 194.6, 200.0, 191.9, 196.4, 164.0, 193.7, 195.2, 190.09999999999994, 184.69999999999996, 160.4, 172.1, 165.8, 168.49999999999991, 191.89999999999998, 147.5, 168.49999999999997, 166.69999999999996, 169.09999999999994, 161.6, 186.49999999999997, 200.0, 168.8, 189.2, 172.1, 151.7, 199.1, 163.10000000000002, 171.2, 174.5, 198.2, 200.0, 197.0, 175.7, 197.0, 175.7, 153.2, 187.4, 173.9, 175.7, 169.1, 197.3, 200.0, 191.29999999999998, 179.3, 179.0, 161.9, 137.89999999999998, 200.0, 158.3, 193.7, 200.0, 178.7, 130.7, 199.1, 196.39999999999998, 143.00000000000003, 163.1, 175.1, 161.0, 186.5, 158.3, 170.0, 167.0, 154.1, 182.89999999999992, 178.1, 155.89999999999978, 199.1, 197.0, 194.6, 176.0, 185.59999999999997, 173.00000000000003, 168.5, 182.0, 191.0, 178.4, 181.1, 176.9, 163.99999999999991, 194.6, 173.6, 158.60000000000002, 200.0, 164.00000000000003, 200.0, 177.50000000000003, 173.9, 176.0, 184.70000000000002, 162.2, 195.5, 183.8, 184.7, 169.70000000000002, 200.0, 172.1, 197.3, 194.6, 193.7, 156.8, 176.6, 189.2, 200.0, 199.1, 173.9, 184.7, 198.2, 183.7999999999999, 200.0, 194.0, 181.1, 158.3, 158.0, 165.8, 172.1, 196.4, 200.0, 177.8, 199.1, 189.19999999999996, 188.0, 200.0, 172.1, 193.7, 195.5, 182.9, 196.4, 187.7, 191.9, 191.9, 180.19999999999993, 169.4, 196.4, 170.3, 158.0, 200.0, 195.5, 165.8, 173.0, 182.0, 189.19999999999996, 164.89999999999995, 154.39999999999998, 172.4, 182.0, 191.9, 174.5, 178.39999999999998, 161.0, 180.8], "policy_predator_policy_reward": [0.0, 7.0, 0.0, 3.0, 0.0, 0.0, 0.0, 5.0, 0.0, 12.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 8.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 3.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 5.0, 16.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 8.0, 14.0, 19.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 2.0, 0.0, 7.0, 10.0, 0.0, 13.0, 0.0, 0.0, 0.0, 0.0, 20.0, 0.0, 0.0, 10.0, 0.0, 13.0, 0.0, 0.0, 13.0, 15.0, 7.0, 0.0, 0.0, 7.0, 0.0, 1.0, 0.0, 8.0, 0.0, 0.0, 0.0, 8.0, 11.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 12.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 7.0, 6.0, 12.0, 8.0, 0.0, 6.0, 0.0, 2.0, 0.0, 0.0, 0.0, 4.0, 6.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 4.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 8.0, 5.0, 0.0, 6.0, 7.0, 0.0, 0.0, 14.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 13.365292547625627, "mean_inference_ms": 30.066240577473426, "mean_action_processing_ms": 6.276373020052473, "mean_env_wait_ms": 7.684541787705843, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019117116928100586, "StateBufferConnector_ms": 0.011162281036376953, "ViewRequirementAgentConnector_ms": 0.32885921001434326}, "num_episodes": 22, "episode_return_max": 399.1, "episode_return_min": 309.80000000000007, "episode_return_mean": 366.1570000000001, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2208000, "num_agent_steps_trained": 2208000, "num_env_steps_sampled": 552000, "num_env_steps_trained": 552000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 225.06205492814425, "num_env_steps_trained_throughput_per_sec": 225.06205492814425, "timesteps_total": 552000, "num_env_steps_sampled_lifetime": 552000, "num_agent_steps_sampled_lifetime": 2208000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2208000, "timers": {"training_iteration_time_ms": 112698.43, "restore_workers_time_ms": 0.018, "training_step_time_ms": 112698.368, "sample_time_ms": 94644.585, "learn_time_ms": 18026.006, "learn_throughput": 221.902, "synch_weights_time_ms": 22.378}, "counters": {"num_env_steps_sampled": 552000, "num_env_steps_trained": 552000, "num_agent_steps_sampled": 2208000, "num_agent_steps_trained": 2208000}, "done": false, "training_iteration": 138, "trial_id": "75ec3_00000", "date": "2024-08-13_05-22-49", "timestamp": 1723540969, "time_this_iter_s": 17.823466300964355, "time_total_s": 13718.193252563477, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b24c4c10>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 13718.193252563477, "iterations_since_restore": 138, "perf": {"cpu_util_percent": 84.56153846153846, "ram_util_percent": 83.56923076923077}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.405969865344189, "cur_kl_coeff": 0.17338601276121607, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.2666121155811996, "policy_loss": -0.004031910143285083, "vf_loss": 1.2696928964090095, "vf_explained_var": 0.46322792525644657, "kl": 0.005485631393619734, "entropy": 1.0249978099865888, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 261765.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.2733377799736681, "cur_kl_coeff": 3.6350710512584234e-28, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.16552230713780594, "policy_loss": -0.0004814386275404739, "vf_loss": 0.16600374581991995, "vf_explained_var": 0.010983687197720563, "kl": 0.01951936730968868, "entropy": 1.117559704294911, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 261765.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 556000, "num_env_steps_trained": 556000, "num_agent_steps_sampled": 2224000, "num_agent_steps_trained": 2224000}, "env_runners": {"episode_reward_max": 399.1, "episode_reward_min": 300.3000000000001, "episode_reward_mean": 362.844, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 130.7, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 20.0}, "policy_reward_mean": {"prey_policy": 178.87699999999998, "predator_policy": 2.545}, "custom_metrics": {}, "hist_stats": {"episode_reward": [393.7, 350.5, 328.69999999999993, 320.8000000000006, 381.4000000000002, 353.9000000000001, 391.9, 391.9, 360.40000000000003, 389.9, 374.7999999999999, 332.50000000000006, 345.29999999999995, 355.4000000000001, 335.2000000000001, 341.7000000000003, 386.5000000000001, 366.0, 356.79999999999995, 362.1999999999999, 354.7, 398.2, 373.7, 373.70000000000005, 340.6, 349.6, 373.4, 393.29999999999995, 365.3, 309.80000000000007, 371.29999999999995, 393.7, 329.4, 395.5, 316.1, 349.1, 357.8, 359.0, 337.0000000000002, 341.00000000000017, 397.1, 378.6, 358.6, 369.5, 369.4, 360.0, 358.6, 339.2, 363.99999999999994, 377.49999999999994, 359.9, 358.9, 379.3, 356.4, 372.1, 391.9, 350.50000000000006, 368.8, 399.1, 358.5999999999999, 382.0, 396.0, 352.4, 343.8, 374.5, 379.8, 388.29999999999995, 392.0, 371.8, 378.4, 386.1, 383.8, 349.60000000000014, 366.70000000000005, 369.0, 361.3, 364.0, 354.10000000000025, 339.8, 379.9, 359.9000000000001, 355.8, 377.4, 360.29999999999995, 333.30000000000007, 375.1, 367.0, 383.8, 355.4, 306.4, 381.1, 332.5, 382.0, 355.1, 353.5, 352.30000000000007, 328.09999999999997, 391.0, 300.3000000000001, 351.1], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [193.7, 200.0, 164.9, 185.6, 164.89999999999998, 153.8, 159.49999999999986, 161.29999999999998, 179.29999999999995, 199.1, 174.79999999999998, 169.1, 197.29999999999998, 194.6, 200.0, 191.9, 196.4, 164.0, 193.7, 195.2, 190.09999999999994, 184.69999999999996, 160.4, 172.1, 165.8, 168.49999999999991, 191.89999999999998, 147.5, 168.49999999999997, 166.69999999999996, 169.09999999999994, 161.6, 186.49999999999997, 200.0, 168.8, 189.2, 172.1, 151.7, 199.1, 163.10000000000002, 171.2, 174.5, 198.2, 200.0, 197.0, 175.7, 197.0, 175.7, 153.2, 187.4, 173.9, 175.7, 169.1, 197.3, 200.0, 191.29999999999998, 179.3, 179.0, 161.9, 137.89999999999998, 200.0, 158.3, 193.7, 200.0, 178.7, 130.7, 199.1, 196.39999999999998, 143.00000000000003, 163.1, 175.1, 161.0, 186.5, 158.3, 170.0, 167.0, 154.1, 182.89999999999992, 178.1, 155.89999999999978, 199.1, 197.0, 194.6, 176.0, 185.59999999999997, 173.00000000000003, 168.5, 182.0, 191.0, 178.4, 181.1, 176.9, 163.99999999999991, 194.6, 173.6, 158.60000000000002, 200.0, 164.00000000000003, 200.0, 177.50000000000003, 173.9, 176.0, 184.70000000000002, 162.2, 195.5, 183.8, 184.7, 169.70000000000002, 200.0, 172.1, 197.3, 194.6, 193.7, 156.8, 176.6, 189.2, 200.0, 199.1, 173.9, 184.7, 198.2, 183.7999999999999, 200.0, 194.0, 181.1, 158.3, 158.0, 165.8, 172.1, 196.4, 200.0, 177.8, 199.1, 189.19999999999996, 188.0, 200.0, 172.1, 193.7, 195.5, 182.9, 196.4, 187.7, 191.9, 191.9, 180.19999999999993, 169.4, 196.4, 170.3, 158.0, 200.0, 195.5, 165.8, 173.0, 182.0, 189.19999999999996, 164.89999999999995, 154.39999999999998, 172.4, 182.0, 191.9, 174.5, 178.39999999999998, 161.0, 180.8, 187.4, 185.0, 183.8, 171.5, 193.7, 134.6, 187.4, 184.7, 168.5, 195.5, 190.1, 193.7, 161.0, 187.4, 143.29999999999995, 163.1, 194.6, 186.5, 166.7, 165.8, 191.9, 190.1, 181.1, 170.0, 171.5, 170.0, 168.5, 183.8, 162.8, 152.29999999999998, 192.8, 198.2, 132.5, 147.79999999999998, 155.0, 181.1], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 3.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 5.0, 16.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 8.0, 14.0, 19.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 2.0, 0.0, 7.0, 10.0, 0.0, 13.0, 0.0, 0.0, 0.0, 0.0, 20.0, 0.0, 0.0, 10.0, 0.0, 13.0, 0.0, 0.0, 13.0, 15.0, 7.0, 0.0, 0.0, 7.0, 0.0, 1.0, 0.0, 8.0, 0.0, 0.0, 0.0, 8.0, 11.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 12.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 7.0, 6.0, 12.0, 8.0, 0.0, 6.0, 0.0, 2.0, 0.0, 0.0, 0.0, 4.0, 6.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 4.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 8.0, 5.0, 0.0, 6.0, 7.0, 0.0, 0.0, 14.0, 5.0, 0.0, 0.0, 5.0, 0.0, 5.0, 3.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 12.0, 0.0, 0.0, 0.0, 6.0, 7.0, 0.0, 0.0, 10.0, 10.0, 15.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 12.790027944695257, "mean_inference_ms": 30.55406745819011, "mean_action_processing_ms": 6.231239198340754, "mean_env_wait_ms": 7.785578360029539, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01873040199279785, "StateBufferConnector_ms": 0.007134675979614258, "ViewRequirementAgentConnector_ms": 0.31537318229675293}, "num_episodes": 18, "episode_return_max": 399.1, "episode_return_min": 300.3000000000001, "episode_return_mean": 362.844, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2224000, "num_agent_steps_trained": 2224000, "num_env_steps_sampled": 556000, "num_env_steps_trained": 556000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 4.323754878673272, "num_env_steps_trained_throughput_per_sec": 4.323754878673272, "timesteps_total": 556000, "num_env_steps_sampled_lifetime": 556000, "num_agent_steps_sampled_lifetime": 2224000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2224000, "timers": {"training_iteration_time_ms": 203244.084, "restore_workers_time_ms": 0.018, "training_step_time_ms": 203243.795, "sample_time_ms": 94703.737, "learn_time_ms": 108512.461, "learn_throughput": 36.862, "synch_weights_time_ms": 22.244}, "counters": {"num_env_steps_sampled": 556000, "num_env_steps_trained": 556000, "num_agent_steps_sampled": 2224000, "num_agent_steps_trained": 2224000}, "done": false, "training_iteration": 139, "trial_id": "75ec3_00000", "date": "2024-08-13_05-38-15", "timestamp": 1723541895, "time_this_iter_s": 925.2241380214691, "time_total_s": 14643.417390584946, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b243fb80>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 14643.417390584946, "iterations_since_restore": 139, "perf": {"cpu_util_percent": 94.62, "ram_util_percent": 82.4625}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.5766686559669556, "cur_kl_coeff": 0.17338601276121607, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.6638073885650744, "policy_loss": -0.003814399900486466, "vf_loss": 0.6670498029737876, "vf_explained_var": 0.510625783318565, "kl": 0.0032989366135465275, "entropy": 1.040606312461631, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 263655.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.2732751693241495, "cur_kl_coeff": 3.6350710512584234e-28, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.19412397909416723, "policy_loss": -0.0007311189059345495, "vf_loss": 0.19485509785076371, "vf_explained_var": 0.0806174292135491, "kl": 0.04173514753337395, "entropy": 1.2292993373971768, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 263655.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 560000, "num_env_steps_trained": 560000, "num_agent_steps_sampled": 2240000, "num_agent_steps_trained": 2240000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": 300.3000000000001, "episode_reward_mean": 364.087, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 130.7, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 20.0}, "policy_reward_mean": {"prey_policy": 179.2685, "predator_policy": 2.775}, "custom_metrics": {}, "hist_stats": {"episode_reward": [356.79999999999995, 362.1999999999999, 354.7, 398.2, 373.7, 373.70000000000005, 340.6, 349.6, 373.4, 393.29999999999995, 365.3, 309.80000000000007, 371.29999999999995, 393.7, 329.4, 395.5, 316.1, 349.1, 357.8, 359.0, 337.0000000000002, 341.00000000000017, 397.1, 378.6, 358.6, 369.5, 369.4, 360.0, 358.6, 339.2, 363.99999999999994, 377.49999999999994, 359.9, 358.9, 379.3, 356.4, 372.1, 391.9, 350.50000000000006, 368.8, 399.1, 358.5999999999999, 382.0, 396.0, 352.4, 343.8, 374.5, 379.8, 388.29999999999995, 392.0, 371.8, 378.4, 386.1, 383.8, 349.60000000000014, 366.70000000000005, 369.0, 361.3, 364.0, 354.10000000000025, 339.8, 379.9, 359.9000000000001, 355.8, 377.4, 360.29999999999995, 333.30000000000007, 375.1, 367.0, 383.8, 355.4, 306.4, 381.1, 332.5, 382.0, 355.1, 353.5, 352.30000000000007, 328.09999999999997, 391.0, 300.3000000000001, 351.1, 371.2, 362.1, 378.4, 363.7, 388.0, 379.6, 377.1, 358.6, 321.9, 369.5, 346.29999999999995, 378.0, 360.0, 384.69999999999993, 354.1, 400.0, 376.6, 355.0], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [172.1, 151.7, 199.1, 163.10000000000002, 171.2, 174.5, 198.2, 200.0, 197.0, 175.7, 197.0, 175.7, 153.2, 187.4, 173.9, 175.7, 169.1, 197.3, 200.0, 191.29999999999998, 179.3, 179.0, 161.9, 137.89999999999998, 200.0, 158.3, 193.7, 200.0, 178.7, 130.7, 199.1, 196.39999999999998, 143.00000000000003, 163.1, 175.1, 161.0, 186.5, 158.3, 170.0, 167.0, 154.1, 182.89999999999992, 178.1, 155.89999999999978, 199.1, 197.0, 194.6, 176.0, 185.59999999999997, 173.00000000000003, 168.5, 182.0, 191.0, 178.4, 181.1, 176.9, 163.99999999999991, 194.6, 173.6, 158.60000000000002, 200.0, 164.00000000000003, 200.0, 177.50000000000003, 173.9, 176.0, 184.70000000000002, 162.2, 195.5, 183.8, 184.7, 169.70000000000002, 200.0, 172.1, 197.3, 194.6, 193.7, 156.8, 176.6, 189.2, 200.0, 199.1, 173.9, 184.7, 198.2, 183.7999999999999, 200.0, 194.0, 181.1, 158.3, 158.0, 165.8, 172.1, 196.4, 200.0, 177.8, 199.1, 189.19999999999996, 188.0, 200.0, 172.1, 193.7, 195.5, 182.9, 196.4, 187.7, 191.9, 191.9, 180.19999999999993, 169.4, 196.4, 170.3, 158.0, 200.0, 195.5, 165.8, 173.0, 182.0, 189.19999999999996, 164.89999999999995, 154.39999999999998, 172.4, 182.0, 191.9, 174.5, 178.39999999999998, 161.0, 180.8, 187.4, 185.0, 183.8, 171.5, 193.7, 134.6, 187.4, 184.7, 168.5, 195.5, 190.1, 193.7, 161.0, 187.4, 143.29999999999995, 163.1, 194.6, 186.5, 166.7, 165.8, 191.9, 190.1, 181.1, 170.0, 171.5, 170.0, 168.5, 183.8, 162.8, 152.29999999999998, 192.8, 198.2, 132.5, 147.79999999999998, 155.0, 181.1, 183.8, 187.4, 154.4, 193.7, 188.3, 190.1, 181.1, 176.6, 200.0, 179.0, 188.6, 185.0, 166.1, 200.0, 177.5, 181.1, 157.1, 141.8, 188.0, 177.5, 171.79999999999998, 162.5, 200.0, 167.0, 182.0, 167.0, 189.2, 195.5, 168.5, 185.6, 200.0, 200.0, 194.6, 173.0, 175.7, 179.3], "policy_predator_policy_reward": [14.0, 19.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 2.0, 0.0, 7.0, 10.0, 0.0, 13.0, 0.0, 0.0, 0.0, 0.0, 20.0, 0.0, 0.0, 10.0, 0.0, 13.0, 0.0, 0.0, 13.0, 15.0, 7.0, 0.0, 0.0, 7.0, 0.0, 1.0, 0.0, 8.0, 0.0, 0.0, 0.0, 8.0, 11.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 12.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 7.0, 6.0, 12.0, 8.0, 0.0, 6.0, 0.0, 2.0, 0.0, 0.0, 0.0, 4.0, 6.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 4.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 8.0, 5.0, 0.0, 6.0, 7.0, 0.0, 0.0, 14.0, 5.0, 0.0, 0.0, 5.0, 0.0, 5.0, 3.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 12.0, 0.0, 0.0, 0.0, 6.0, 7.0, 0.0, 0.0, 10.0, 10.0, 15.0, 0.0, 0.0, 0.0, 0.0, 14.0, 0.0, 0.0, 6.0, 0.0, 6.0, 3.0, 0.0, 6.0, 5.0, 6.0, 0.0, 0.0, 12.0, 11.0, 0.0, 4.0, 8.0, 4.0, 0.0, 11.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 12.71668278859127, "mean_inference_ms": 30.681976261103372, "mean_action_processing_ms": 6.194114627886638, "mean_env_wait_ms": 7.737880608639411, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.018770813941955566, "StateBufferConnector_ms": 0.010641932487487793, "ViewRequirementAgentConnector_ms": 0.3186001777648926}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": 300.3000000000001, "episode_return_mean": 364.087, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2240000, "num_agent_steps_trained": 2240000, "num_env_steps_sampled": 560000, "num_env_steps_trained": 560000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 208.29323416367313, "num_env_steps_trained_throughput_per_sec": 208.29323416367313, "timesteps_total": 560000, "num_env_steps_sampled_lifetime": 560000, "num_agent_steps_sampled_lifetime": 2240000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2240000, "timers": {"training_iteration_time_ms": 203217.647, "restore_workers_time_ms": 0.017, "training_step_time_ms": 203217.359, "sample_time_ms": 94798.982, "learn_time_ms": 108390.138, "learn_throughput": 36.904, "synch_weights_time_ms": 22.792}, "counters": {"num_env_steps_sampled": 560000, "num_env_steps_trained": 560000, "num_agent_steps_sampled": 2240000, "num_agent_steps_trained": 2240000}, "done": false, "training_iteration": 140, "trial_id": "75ec3_00000", "date": "2024-08-13_05-38-34", "timestamp": 1723541914, "time_this_iter_s": 19.264236211776733, "time_total_s": 14662.681626796722, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b24c4af0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 14662.681626796722, "iterations_since_restore": 140, "perf": {"cpu_util_percent": 86.41851851851854, "ram_util_percent": 82.41851851851852}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.1718359748995493, "cur_kl_coeff": 0.08669300638060803, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.6184001361635864, "policy_loss": -0.00407879623909673, "vf_loss": 0.6215605480014963, "vf_explained_var": 0.3791198745921806, "kl": 0.010593527602063736, "entropy": 1.0795719211063688, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 265545.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.2245833754416299, "cur_kl_coeff": 5.452606576887634e-28, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.1055935565037308, "policy_loss": -0.0004886411443332988, "vf_loss": 0.10608219805243795, "vf_explained_var": -0.061545016336693334, "kl": 0.012843222797241174, "entropy": 1.251585802325496, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 265545.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 564000, "num_env_steps_trained": 564000, "num_agent_steps_sampled": 2256000, "num_agent_steps_trained": 2256000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": 300.3000000000001, "episode_reward_mean": 365.62699999999995, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 132.5, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 15.0}, "policy_reward_mean": {"prey_policy": 180.25850000000003, "predator_policy": 2.555}, "custom_metrics": {}, "hist_stats": {"episode_reward": [378.6, 358.6, 369.5, 369.4, 360.0, 358.6, 339.2, 363.99999999999994, 377.49999999999994, 359.9, 358.9, 379.3, 356.4, 372.1, 391.9, 350.50000000000006, 368.8, 399.1, 358.5999999999999, 382.0, 396.0, 352.4, 343.8, 374.5, 379.8, 388.29999999999995, 392.0, 371.8, 378.4, 386.1, 383.8, 349.60000000000014, 366.70000000000005, 369.0, 361.3, 364.0, 354.10000000000025, 339.8, 379.9, 359.9000000000001, 355.8, 377.4, 360.29999999999995, 333.30000000000007, 375.1, 367.0, 383.8, 355.4, 306.4, 381.1, 332.5, 382.0, 355.1, 353.5, 352.30000000000007, 328.09999999999997, 391.0, 300.3000000000001, 351.1, 371.2, 362.1, 378.4, 363.7, 388.0, 379.6, 377.1, 358.6, 321.9, 369.5, 346.29999999999995, 378.0, 360.0, 384.69999999999993, 354.1, 400.0, 376.6, 355.0, 379.1, 368.5, 337.5, 361.9, 363.8, 360.4, 364.5, 379.2, 362.20000000000005, 378.6, 356.9, 328.0, 370.3, 391.9, 383.3, 383.79999999999995, 378.6, 355.79999999999995, 376.3, 366.69999999999993, 359.4, 368.1, 377.5], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [194.6, 176.0, 185.59999999999997, 173.00000000000003, 168.5, 182.0, 191.0, 178.4, 181.1, 176.9, 163.99999999999991, 194.6, 173.6, 158.60000000000002, 200.0, 164.00000000000003, 200.0, 177.50000000000003, 173.9, 176.0, 184.70000000000002, 162.2, 195.5, 183.8, 184.7, 169.70000000000002, 200.0, 172.1, 197.3, 194.6, 193.7, 156.8, 176.6, 189.2, 200.0, 199.1, 173.9, 184.7, 198.2, 183.7999999999999, 200.0, 194.0, 181.1, 158.3, 158.0, 165.8, 172.1, 196.4, 200.0, 177.8, 199.1, 189.19999999999996, 188.0, 200.0, 172.1, 193.7, 195.5, 182.9, 196.4, 187.7, 191.9, 191.9, 180.19999999999993, 169.4, 196.4, 170.3, 158.0, 200.0, 195.5, 165.8, 173.0, 182.0, 189.19999999999996, 164.89999999999995, 154.39999999999998, 172.4, 182.0, 191.9, 174.5, 178.39999999999998, 161.0, 180.8, 187.4, 185.0, 183.8, 171.5, 193.7, 134.6, 187.4, 184.7, 168.5, 195.5, 190.1, 193.7, 161.0, 187.4, 143.29999999999995, 163.1, 194.6, 186.5, 166.7, 165.8, 191.9, 190.1, 181.1, 170.0, 171.5, 170.0, 168.5, 183.8, 162.8, 152.29999999999998, 192.8, 198.2, 132.5, 147.79999999999998, 155.0, 181.1, 183.8, 187.4, 154.4, 193.7, 188.3, 190.1, 181.1, 176.6, 200.0, 179.0, 188.6, 185.0, 166.1, 200.0, 177.5, 181.1, 157.1, 141.8, 188.0, 177.5, 171.79999999999998, 162.5, 200.0, 167.0, 182.0, 167.0, 189.2, 195.5, 168.5, 185.6, 200.0, 200.0, 194.6, 173.0, 175.7, 179.3, 199.1, 170.0, 194.6, 173.9, 158.6, 176.9, 178.4, 177.5, 190.1, 163.7, 163.10000000000002, 197.29999999999998, 166.1, 187.4, 189.2, 185.0, 166.7, 195.5, 194.6, 176.0, 174.8, 178.1, 151.4, 167.6, 182.0, 179.3, 196.4, 195.5, 179.0, 197.3, 200.0, 183.8, 188.6, 182.0, 184.7, 157.1, 195.5, 174.8, 196.4, 170.29999999999998, 176.0, 169.4, 178.4, 187.7, 187.4, 190.1], "policy_predator_policy_reward": [8.0, 0.0, 0.0, 0.0, 8.0, 11.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 12.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 7.0, 6.0, 12.0, 8.0, 0.0, 6.0, 0.0, 2.0, 0.0, 0.0, 0.0, 4.0, 6.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 4.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 8.0, 5.0, 0.0, 6.0, 7.0, 0.0, 0.0, 14.0, 5.0, 0.0, 0.0, 5.0, 0.0, 5.0, 3.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 12.0, 0.0, 0.0, 0.0, 6.0, 7.0, 0.0, 0.0, 10.0, 10.0, 15.0, 0.0, 0.0, 0.0, 0.0, 14.0, 0.0, 0.0, 6.0, 0.0, 6.0, 3.0, 0.0, 6.0, 5.0, 6.0, 0.0, 0.0, 12.0, 11.0, 0.0, 4.0, 8.0, 4.0, 0.0, 11.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 2.0, 6.0, 0.0, 10.0, 0.0, 0.0, 0.0, 11.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 4.0, 0.0, 9.0, 9.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 8.0, 6.0, 8.0, 6.0, 0.0, 0.0, 0.0, 8.0, 6.0, 2.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 12.466306089049041, "mean_inference_ms": 31.55375320128638, "mean_action_processing_ms": 6.3164574839113845, "mean_env_wait_ms": 7.043600361030318, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.018181920051574707, "StateBufferConnector_ms": 0.008426547050476074, "ViewRequirementAgentConnector_ms": 0.31672728061676025}, "num_episodes": 23, "episode_return_max": 400.0, "episode_return_min": 300.3000000000001, "episode_return_mean": 365.62699999999995, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2256000, "num_agent_steps_trained": 2256000, "num_env_steps_sampled": 564000, "num_env_steps_trained": 564000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 228.30894907574373, "num_env_steps_trained_throughput_per_sec": 228.30894907574373, "timesteps_total": 564000, "num_env_steps_sampled_lifetime": 564000, "num_agent_steps_sampled_lifetime": 2256000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2256000, "timers": {"training_iteration_time_ms": 202972.374, "restore_workers_time_ms": 0.018, "training_step_time_ms": 202972.085, "sample_time_ms": 94834.294, "learn_time_ms": 108110.042, "learn_throughput": 36.999, "synch_weights_time_ms": 22.432}, "counters": {"num_env_steps_sampled": 564000, "num_env_steps_trained": 564000, "num_agent_steps_sampled": 2256000, "num_agent_steps_trained": 2256000}, "done": false, "training_iteration": 141, "trial_id": "75ec3_00000", "date": "2024-08-13_05-38-52", "timestamp": 1723541932, "time_this_iter_s": 17.619831085205078, "time_total_s": 14680.301457881927, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b24f2e50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 14680.301457881927, "iterations_since_restore": 141, "perf": {"cpu_util_percent": 80.868, "ram_util_percent": 80.708}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9332910647546804, "cur_kl_coeff": 0.08669300638060803, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.45765558882775376, "policy_loss": 0.001979517733564886, "vf_loss": 0.4551362576497788, "vf_explained_var": 0.23384030098637576, "kl": 0.006226743961776876, "entropy": 1.1450036107547699, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 267435.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.27775782185986087, "cur_kl_coeff": 5.452606576887634e-28, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.20776324749939026, "policy_loss": -0.00024301420956376998, "vf_loss": 0.20800626186836293, "vf_explained_var": 0.02891330507697252, "kl": 0.005551850360341051, "entropy": 1.274853186695664, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 267435.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 568000, "num_env_steps_trained": 568000, "num_agent_steps_sampled": 2272000, "num_agent_steps_trained": 2272000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": 300.3000000000001, "episode_reward_mean": 366.04999999999995, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 132.5, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 15.0}, "policy_reward_mean": {"prey_policy": 179.99, "predator_policy": 3.035}, "custom_metrics": {}, "hist_stats": {"episode_reward": [358.5999999999999, 382.0, 396.0, 352.4, 343.8, 374.5, 379.8, 388.29999999999995, 392.0, 371.8, 378.4, 386.1, 383.8, 349.60000000000014, 366.70000000000005, 369.0, 361.3, 364.0, 354.10000000000025, 339.8, 379.9, 359.9000000000001, 355.8, 377.4, 360.29999999999995, 333.30000000000007, 375.1, 367.0, 383.8, 355.4, 306.4, 381.1, 332.5, 382.0, 355.1, 353.5, 352.30000000000007, 328.09999999999997, 391.0, 300.3000000000001, 351.1, 371.2, 362.1, 378.4, 363.7, 388.0, 379.6, 377.1, 358.6, 321.9, 369.5, 346.29999999999995, 378.0, 360.0, 384.69999999999993, 354.1, 400.0, 376.6, 355.0, 379.1, 368.5, 337.5, 361.9, 363.8, 360.4, 364.5, 379.2, 362.20000000000005, 378.6, 356.9, 328.0, 370.3, 391.9, 383.3, 383.79999999999995, 378.6, 355.79999999999995, 376.3, 366.69999999999993, 359.4, 368.1, 377.5, 371.2, 352.4, 365.8, 366.1, 362.3, 351.4, 382.9, 357.4, 400.0, 364.5, 389.1, 354.5, 390.1, 390.1, 378.9, 346.2, 359.0, 372.7], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [173.9, 184.7, 198.2, 183.7999999999999, 200.0, 194.0, 181.1, 158.3, 158.0, 165.8, 172.1, 196.4, 200.0, 177.8, 199.1, 189.19999999999996, 188.0, 200.0, 172.1, 193.7, 195.5, 182.9, 196.4, 187.7, 191.9, 191.9, 180.19999999999993, 169.4, 196.4, 170.3, 158.0, 200.0, 195.5, 165.8, 173.0, 182.0, 189.19999999999996, 164.89999999999995, 154.39999999999998, 172.4, 182.0, 191.9, 174.5, 178.39999999999998, 161.0, 180.8, 187.4, 185.0, 183.8, 171.5, 193.7, 134.6, 187.4, 184.7, 168.5, 195.5, 190.1, 193.7, 161.0, 187.4, 143.29999999999995, 163.1, 194.6, 186.5, 166.7, 165.8, 191.9, 190.1, 181.1, 170.0, 171.5, 170.0, 168.5, 183.8, 162.8, 152.29999999999998, 192.8, 198.2, 132.5, 147.79999999999998, 155.0, 181.1, 183.8, 187.4, 154.4, 193.7, 188.3, 190.1, 181.1, 176.6, 200.0, 179.0, 188.6, 185.0, 166.1, 200.0, 177.5, 181.1, 157.1, 141.8, 188.0, 177.5, 171.79999999999998, 162.5, 200.0, 167.0, 182.0, 167.0, 189.2, 195.5, 168.5, 185.6, 200.0, 200.0, 194.6, 173.0, 175.7, 179.3, 199.1, 170.0, 194.6, 173.9, 158.6, 176.9, 178.4, 177.5, 190.1, 163.7, 163.10000000000002, 197.29999999999998, 166.1, 187.4, 189.2, 185.0, 166.7, 195.5, 194.6, 176.0, 174.8, 178.1, 151.4, 167.6, 182.0, 179.3, 196.4, 195.5, 179.0, 197.3, 200.0, 183.8, 188.6, 182.0, 184.7, 157.1, 195.5, 174.8, 196.4, 170.29999999999998, 176.0, 169.4, 178.4, 187.7, 187.4, 190.1, 162.20000000000002, 200.0, 179.0, 160.4, 191.9, 173.9, 181.1, 173.0, 188.3, 161.0, 176.0, 163.4, 187.4, 195.5, 155.0, 187.4, 200.0, 200.0, 176.0, 177.5, 200.0, 184.1, 171.5, 170.0, 196.4, 193.7, 190.1, 200.0, 194.0, 182.9, 171.2, 146.0, 182.0, 164.0, 194.6, 166.1], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 7.0, 6.0, 12.0, 8.0, 0.0, 6.0, 0.0, 2.0, 0.0, 0.0, 0.0, 4.0, 6.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 4.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 8.0, 5.0, 0.0, 6.0, 7.0, 0.0, 0.0, 14.0, 5.0, 0.0, 0.0, 5.0, 0.0, 5.0, 3.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 12.0, 0.0, 0.0, 0.0, 6.0, 7.0, 0.0, 0.0, 10.0, 10.0, 15.0, 0.0, 0.0, 0.0, 0.0, 14.0, 0.0, 0.0, 6.0, 0.0, 6.0, 3.0, 0.0, 6.0, 5.0, 6.0, 0.0, 0.0, 12.0, 11.0, 0.0, 4.0, 8.0, 4.0, 0.0, 11.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 2.0, 6.0, 0.0, 10.0, 0.0, 0.0, 0.0, 11.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 4.0, 0.0, 9.0, 9.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 8.0, 6.0, 8.0, 6.0, 0.0, 0.0, 0.0, 8.0, 6.0, 2.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 13.0, 0.0, 0.0, 3.0, 9.0, 0.0, 13.0, 0.0, 12.0, 0.0, 0.0, 15.0, 0.0, 0.0, 0.0, 8.0, 3.0, 5.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 14.0, 15.0, 6.0, 7.0, 7.0, 5.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 12.563038995859575, "mean_inference_ms": 30.737066923806815, "mean_action_processing_ms": 6.1120867752361425, "mean_env_wait_ms": 7.639618962478698, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01500558853149414, "StateBufferConnector_ms": 0.008715987205505371, "ViewRequirementAgentConnector_ms": 0.26781582832336426}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": 300.3000000000001, "episode_return_mean": 366.04999999999995, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2272000, "num_agent_steps_trained": 2272000, "num_env_steps_sampled": 568000, "num_env_steps_trained": 568000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 222.21555258906992, "num_env_steps_trained_throughput_per_sec": 222.21555258906992, "timesteps_total": 568000, "num_env_steps_sampled_lifetime": 568000, "num_agent_steps_sampled_lifetime": 2272000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2272000, "timers": {"training_iteration_time_ms": 202721.703, "restore_workers_time_ms": 0.02, "training_step_time_ms": 202721.411, "sample_time_ms": 94839.695, "learn_time_ms": 107847.917, "learn_throughput": 37.089, "synch_weights_time_ms": 28.434}, "counters": {"num_env_steps_sampled": 568000, "num_env_steps_trained": 568000, "num_agent_steps_sampled": 2272000, "num_agent_steps_trained": 2272000}, "done": false, "training_iteration": 142, "trial_id": "75ec3_00000", "date": "2024-08-13_05-39-10", "timestamp": 1723541950, "time_this_iter_s": 18.090182781219482, "time_total_s": 14698.391640663147, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b243fc10>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 14698.391640663147, "iterations_since_restore": 142, "perf": {"cpu_util_percent": 84.30000000000001, "ram_util_percent": 81.0576923076923}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.880684859002078, "cur_kl_coeff": 0.08669300638060803, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.7788548476013438, "policy_loss": -0.006199134157221548, "vf_loss": 0.7844964481771939, "vf_explained_var": 0.2952470570329636, "kl": 0.006431129389339781, "entropy": 1.1825104007014522, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 269325.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.21671448885093605, "cur_kl_coeff": 5.452606576887634e-28, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.20647136598687482, "policy_loss": -0.000452129819267799, "vf_loss": 0.20692349482823852, "vf_explained_var": 0.03927324061040525, "kl": 0.004814638067661012, "entropy": 1.2903580254978604, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 269325.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 572000, "num_env_steps_trained": 572000, "num_agent_steps_sampled": 2288000, "num_agent_steps_trained": 2288000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": 300.3000000000001, "episode_reward_mean": 365.661, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 132.5, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 27.0}, "policy_reward_mean": {"prey_policy": 179.6405, "predator_policy": 3.19}, "custom_metrics": {}, "hist_stats": {"episode_reward": [355.8, 377.4, 360.29999999999995, 333.30000000000007, 375.1, 367.0, 383.8, 355.4, 306.4, 381.1, 332.5, 382.0, 355.1, 353.5, 352.30000000000007, 328.09999999999997, 391.0, 300.3000000000001, 351.1, 371.2, 362.1, 378.4, 363.7, 388.0, 379.6, 377.1, 358.6, 321.9, 369.5, 346.29999999999995, 378.0, 360.0, 384.69999999999993, 354.1, 400.0, 376.6, 355.0, 379.1, 368.5, 337.5, 361.9, 363.8, 360.4, 364.5, 379.2, 362.20000000000005, 378.6, 356.9, 328.0, 370.3, 391.9, 383.3, 383.79999999999995, 378.6, 355.79999999999995, 376.3, 366.69999999999993, 359.4, 368.1, 377.5, 371.2, 352.4, 365.8, 366.1, 362.3, 351.4, 382.9, 357.4, 400.0, 364.5, 389.1, 354.5, 390.1, 390.1, 378.9, 346.2, 359.0, 372.7, 376.0, 380.7, 354.7, 391.9, 390.6, 334.0, 387.1, 354.9, 337.0, 366.70000000000005, 385.6, 370.3, 377.5, 373.0, 383.8, 331.59999999999997, 371.19999999999993, 343.3, 387.4, 362.2, 393.7, 339.7], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [161.0, 180.8, 187.4, 185.0, 183.8, 171.5, 193.7, 134.6, 187.4, 184.7, 168.5, 195.5, 190.1, 193.7, 161.0, 187.4, 143.29999999999995, 163.1, 194.6, 186.5, 166.7, 165.8, 191.9, 190.1, 181.1, 170.0, 171.5, 170.0, 168.5, 183.8, 162.8, 152.29999999999998, 192.8, 198.2, 132.5, 147.79999999999998, 155.0, 181.1, 183.8, 187.4, 154.4, 193.7, 188.3, 190.1, 181.1, 176.6, 200.0, 179.0, 188.6, 185.0, 166.1, 200.0, 177.5, 181.1, 157.1, 141.8, 188.0, 177.5, 171.79999999999998, 162.5, 200.0, 167.0, 182.0, 167.0, 189.2, 195.5, 168.5, 185.6, 200.0, 200.0, 194.6, 173.0, 175.7, 179.3, 199.1, 170.0, 194.6, 173.9, 158.6, 176.9, 178.4, 177.5, 190.1, 163.7, 163.10000000000002, 197.29999999999998, 166.1, 187.4, 189.2, 185.0, 166.7, 195.5, 194.6, 176.0, 174.8, 178.1, 151.4, 167.6, 182.0, 179.3, 196.4, 195.5, 179.0, 197.3, 200.0, 183.8, 188.6, 182.0, 184.7, 157.1, 195.5, 174.8, 196.4, 170.29999999999998, 176.0, 169.4, 178.4, 187.7, 187.4, 190.1, 162.20000000000002, 200.0, 179.0, 160.4, 191.9, 173.9, 181.1, 173.0, 188.3, 161.0, 176.0, 163.4, 187.4, 195.5, 155.0, 187.4, 200.0, 200.0, 176.0, 177.5, 200.0, 184.1, 171.5, 170.0, 196.4, 193.7, 190.1, 200.0, 194.0, 182.9, 171.2, 146.0, 182.0, 164.0, 194.6, 166.1, 179.0, 185.0, 184.7, 194.0, 183.5, 162.20000000000002, 195.5, 196.4, 194.0, 194.6, 164.0, 155.0, 181.1, 200.0, 182.9, 158.0, 149.0, 161.0, 171.2, 195.5, 190.1, 195.5, 198.2, 172.1, 186.5, 191.0, 181.1, 191.9, 183.8, 200.0, 143.3, 188.3, 182.89999999999995, 188.3, 155.0, 170.3, 200.0, 187.4, 173.0, 189.2, 200.0, 193.7, 148.70000000000002, 164.0], "policy_predator_policy_reward": [0.0, 14.0, 5.0, 0.0, 0.0, 5.0, 0.0, 5.0, 3.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 12.0, 0.0, 0.0, 0.0, 6.0, 7.0, 0.0, 0.0, 10.0, 10.0, 15.0, 0.0, 0.0, 0.0, 0.0, 14.0, 0.0, 0.0, 6.0, 0.0, 6.0, 3.0, 0.0, 6.0, 5.0, 6.0, 0.0, 0.0, 12.0, 11.0, 0.0, 4.0, 8.0, 4.0, 0.0, 11.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 2.0, 6.0, 0.0, 10.0, 0.0, 0.0, 0.0, 11.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 4.0, 0.0, 9.0, 9.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 8.0, 6.0, 8.0, 6.0, 0.0, 0.0, 0.0, 8.0, 6.0, 2.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 13.0, 0.0, 0.0, 3.0, 9.0, 0.0, 13.0, 0.0, 12.0, 0.0, 0.0, 15.0, 0.0, 0.0, 0.0, 8.0, 3.0, 5.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 14.0, 15.0, 6.0, 7.0, 7.0, 5.0, 7.0, 5.0, 2.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 2.0, 15.0, 0.0, 6.0, 0.0, 0.0, 14.0, 0.0, 27.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 15.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 12.468286166970607, "mean_inference_ms": 30.541816153059013, "mean_action_processing_ms": 6.070504329443867, "mean_env_wait_ms": 7.576899398727431, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.011448979377746582, "StateBufferConnector_ms": 0.009882092475891113, "ViewRequirementAgentConnector_ms": 0.2512131929397583}, "num_episodes": 22, "episode_return_max": 400.0, "episode_return_min": 300.3000000000001, "episode_return_mean": 365.661, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2288000, "num_agent_steps_trained": 2288000, "num_env_steps_sampled": 572000, "num_env_steps_trained": 572000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 236.61133381762556, "num_env_steps_trained_throughput_per_sec": 236.61133381762556, "timesteps_total": 572000, "num_env_steps_sampled_lifetime": 572000, "num_agent_steps_sampled_lifetime": 2288000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2288000, "timers": {"training_iteration_time_ms": 202287.709, "restore_workers_time_ms": 0.019, "training_step_time_ms": 202287.418, "sample_time_ms": 94681.461, "learn_time_ms": 107572.044, "learn_throughput": 37.184, "synch_weights_time_ms": 28.795}, "counters": {"num_env_steps_sampled": 572000, "num_env_steps_trained": 572000, "num_agent_steps_sampled": 2288000, "num_agent_steps_trained": 2288000}, "done": false, "training_iteration": 143, "trial_id": "75ec3_00000", "date": "2024-08-13_05-39-27", "timestamp": 1723541967, "time_this_iter_s": 16.96752691268921, "time_total_s": 14715.359167575836, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b24b73a0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 14715.359167575836, "iterations_since_restore": 143, "perf": {"cpu_util_percent": 82.99583333333334, "ram_util_percent": 81.2625}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.562201638409385, "cur_kl_coeff": 0.08669300638060803, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.3923386559181689, "policy_loss": -0.006233926471593794, "vf_loss": 0.39773184124271943, "vf_explained_var": 0.4200931199959346, "kl": 0.00969792258305349, "entropy": 1.2288255942561639, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 271215.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.2085296305231553, "cur_kl_coeff": 2.726303288443817e-28, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.11979667873629345, "policy_loss": -0.0010117246424434362, "vf_loss": 0.120808403096884, "vf_explained_var": -0.03833551952447841, "kl": 0.02641291106831724, "entropy": 1.2815609362390306, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 271215.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 576000, "num_env_steps_trained": 576000, "num_agent_steps_sampled": 2304000, "num_agent_steps_trained": 2304000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": 321.9, "episode_reward_mean": 369.508, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 141.8, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 27.0}, "policy_reward_mean": {"prey_policy": 181.63400000000001, "predator_policy": 3.12}, "custom_metrics": {}, "hist_stats": {"episode_reward": [351.1, 371.2, 362.1, 378.4, 363.7, 388.0, 379.6, 377.1, 358.6, 321.9, 369.5, 346.29999999999995, 378.0, 360.0, 384.69999999999993, 354.1, 400.0, 376.6, 355.0, 379.1, 368.5, 337.5, 361.9, 363.8, 360.4, 364.5, 379.2, 362.20000000000005, 378.6, 356.9, 328.0, 370.3, 391.9, 383.3, 383.79999999999995, 378.6, 355.79999999999995, 376.3, 366.69999999999993, 359.4, 368.1, 377.5, 371.2, 352.4, 365.8, 366.1, 362.3, 351.4, 382.9, 357.4, 400.0, 364.5, 389.1, 354.5, 390.1, 390.1, 378.9, 346.2, 359.0, 372.7, 376.0, 380.7, 354.7, 391.9, 390.6, 334.0, 387.1, 354.9, 337.0, 366.70000000000005, 385.6, 370.3, 377.5, 373.0, 383.8, 331.59999999999997, 371.19999999999993, 343.3, 387.4, 362.2, 393.7, 339.7, 370.3, 382.0, 378.4, 384.2, 382.0, 385.3, 376.5, 382.9, 372.69999999999993, 349.7, 388.3, 388.0, 374.69999999999993, 363.6, 361.1, 359.7, 390.1, 385.6], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [155.0, 181.1, 183.8, 187.4, 154.4, 193.7, 188.3, 190.1, 181.1, 176.6, 200.0, 179.0, 188.6, 185.0, 166.1, 200.0, 177.5, 181.1, 157.1, 141.8, 188.0, 177.5, 171.79999999999998, 162.5, 200.0, 167.0, 182.0, 167.0, 189.2, 195.5, 168.5, 185.6, 200.0, 200.0, 194.6, 173.0, 175.7, 179.3, 199.1, 170.0, 194.6, 173.9, 158.6, 176.9, 178.4, 177.5, 190.1, 163.7, 163.10000000000002, 197.29999999999998, 166.1, 187.4, 189.2, 185.0, 166.7, 195.5, 194.6, 176.0, 174.8, 178.1, 151.4, 167.6, 182.0, 179.3, 196.4, 195.5, 179.0, 197.3, 200.0, 183.8, 188.6, 182.0, 184.7, 157.1, 195.5, 174.8, 196.4, 170.29999999999998, 176.0, 169.4, 178.4, 187.7, 187.4, 190.1, 162.20000000000002, 200.0, 179.0, 160.4, 191.9, 173.9, 181.1, 173.0, 188.3, 161.0, 176.0, 163.4, 187.4, 195.5, 155.0, 187.4, 200.0, 200.0, 176.0, 177.5, 200.0, 184.1, 171.5, 170.0, 196.4, 193.7, 190.1, 200.0, 194.0, 182.9, 171.2, 146.0, 182.0, 164.0, 194.6, 166.1, 179.0, 185.0, 184.7, 194.0, 183.5, 162.20000000000002, 195.5, 196.4, 194.0, 194.6, 164.0, 155.0, 181.1, 200.0, 182.9, 158.0, 149.0, 161.0, 171.2, 195.5, 190.1, 195.5, 198.2, 172.1, 186.5, 191.0, 181.1, 191.9, 183.8, 200.0, 143.3, 188.3, 182.89999999999995, 188.3, 155.0, 170.3, 200.0, 187.4, 173.0, 189.2, 200.0, 193.7, 148.70000000000002, 164.0, 195.5, 174.8, 187.4, 194.6, 200.0, 178.4, 198.2, 179.0, 182.0, 200.0, 182.0, 197.3, 181.4, 190.1, 182.9, 200.0, 191.89999999999998, 174.8, 174.8, 170.89999999999998, 199.1, 189.2, 191.0, 194.0, 191.0, 175.69999999999996, 167.6, 185.0, 200.0, 142.1, 182.0, 169.7, 190.1, 200.0, 185.6, 200.0], "policy_predator_policy_reward": [15.0, 0.0, 0.0, 0.0, 0.0, 14.0, 0.0, 0.0, 6.0, 0.0, 6.0, 3.0, 0.0, 6.0, 5.0, 6.0, 0.0, 0.0, 12.0, 11.0, 0.0, 4.0, 8.0, 4.0, 0.0, 11.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 2.0, 6.0, 0.0, 10.0, 0.0, 0.0, 0.0, 11.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 4.0, 0.0, 9.0, 9.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 8.0, 6.0, 8.0, 6.0, 0.0, 0.0, 0.0, 8.0, 6.0, 2.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 13.0, 0.0, 0.0, 3.0, 9.0, 0.0, 13.0, 0.0, 12.0, 0.0, 0.0, 15.0, 0.0, 0.0, 0.0, 8.0, 3.0, 5.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 14.0, 15.0, 6.0, 7.0, 7.0, 5.0, 7.0, 5.0, 2.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 2.0, 15.0, 0.0, 6.0, 0.0, 0.0, 14.0, 0.0, 27.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 15.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 6.0, 5.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 3.0, 8.0, 0.0, 9.0, 2.0, 11.0, 8.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 12.397575428489263, "mean_inference_ms": 30.371091944394067, "mean_action_processing_ms": 6.0352440293108724, "mean_env_wait_ms": 7.531245671090952, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.010486483573913574, "StateBufferConnector_ms": 0.0106658935546875, "ViewRequirementAgentConnector_ms": 0.2470691204071045}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": 321.9, "episode_return_mean": 369.508, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2304000, "num_agent_steps_trained": 2304000, "num_env_steps_sampled": 576000, "num_env_steps_trained": 576000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 226.13152015668257, "num_env_steps_trained_throughput_per_sec": 226.13152015668257, "timesteps_total": 576000, "num_env_steps_sampled_lifetime": 576000, "num_agent_steps_sampled_lifetime": 2304000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2304000, "timers": {"training_iteration_time_ms": 201833.532, "restore_workers_time_ms": 0.019, "training_step_time_ms": 201833.241, "sample_time_ms": 94583.382, "learn_time_ms": 107216.318, "learn_throughput": 37.308, "synch_weights_time_ms": 28.302}, "counters": {"num_env_steps_sampled": 576000, "num_env_steps_trained": 576000, "num_agent_steps_sampled": 2304000, "num_agent_steps_trained": 2304000}, "done": false, "training_iteration": 144, "trial_id": "75ec3_00000", "date": "2024-08-13_05-39-45", "timestamp": 1723541985, "time_this_iter_s": 17.785494089126587, "time_total_s": 14733.144661664963, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b24f2e50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 14733.144661664963, "iterations_since_restore": 144, "perf": {"cpu_util_percent": 83.89200000000001, "ram_util_percent": 81.208}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.0010166161038256, "cur_kl_coeff": 0.08669300638060803, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.3527841215186984, "policy_loss": -0.0019438226246546028, "vf_loss": 0.35402228802137037, "vf_explained_var": 0.3240819731402019, "kl": 0.008139729907105394, "entropy": 1.248460130464463, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 273105.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.22189551513425257, "cur_kl_coeff": 4.089454932665724e-28, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.14022336373568842, "policy_loss": 0.00030664229105231624, "vf_loss": 0.13991672153698304, "vf_explained_var": 0.020302744517250667, "kl": 0.010595004346948779, "entropy": 1.32638272766083, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 273105.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 580000, "num_env_steps_trained": 580000, "num_agent_steps_sampled": 2320000, "num_agent_steps_trained": 2320000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": 328.0, "episode_reward_mean": 370.866, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 140.29999999999998, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 27.0}, "policy_reward_mean": {"prey_policy": 182.37800000000004, "predator_policy": 3.055}, "custom_metrics": {}, "hist_stats": {"episode_reward": [355.0, 379.1, 368.5, 337.5, 361.9, 363.8, 360.4, 364.5, 379.2, 362.20000000000005, 378.6, 356.9, 328.0, 370.3, 391.9, 383.3, 383.79999999999995, 378.6, 355.79999999999995, 376.3, 366.69999999999993, 359.4, 368.1, 377.5, 371.2, 352.4, 365.8, 366.1, 362.3, 351.4, 382.9, 357.4, 400.0, 364.5, 389.1, 354.5, 390.1, 390.1, 378.9, 346.2, 359.0, 372.7, 376.0, 380.7, 354.7, 391.9, 390.6, 334.0, 387.1, 354.9, 337.0, 366.70000000000005, 385.6, 370.3, 377.5, 373.0, 383.8, 331.59999999999997, 371.19999999999993, 343.3, 387.4, 362.2, 393.7, 339.7, 370.3, 382.0, 378.4, 384.2, 382.0, 385.3, 376.5, 382.9, 372.69999999999993, 349.7, 388.3, 388.0, 374.69999999999993, 363.6, 361.1, 359.7, 390.1, 385.6, 390.2, 369.0, 360.8, 389.2, 364.6, 380.4, 388.0, 354.80000000000007, 386.50000000000006, 382.9, 363.1, 398.2, 378.4, 353.20000000000005, 332.4, 393.5, 399.1, 372.4], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [175.7, 179.3, 199.1, 170.0, 194.6, 173.9, 158.6, 176.9, 178.4, 177.5, 190.1, 163.7, 163.10000000000002, 197.29999999999998, 166.1, 187.4, 189.2, 185.0, 166.7, 195.5, 194.6, 176.0, 174.8, 178.1, 151.4, 167.6, 182.0, 179.3, 196.4, 195.5, 179.0, 197.3, 200.0, 183.8, 188.6, 182.0, 184.7, 157.1, 195.5, 174.8, 196.4, 170.29999999999998, 176.0, 169.4, 178.4, 187.7, 187.4, 190.1, 162.20000000000002, 200.0, 179.0, 160.4, 191.9, 173.9, 181.1, 173.0, 188.3, 161.0, 176.0, 163.4, 187.4, 195.5, 155.0, 187.4, 200.0, 200.0, 176.0, 177.5, 200.0, 184.1, 171.5, 170.0, 196.4, 193.7, 190.1, 200.0, 194.0, 182.9, 171.2, 146.0, 182.0, 164.0, 194.6, 166.1, 179.0, 185.0, 184.7, 194.0, 183.5, 162.20000000000002, 195.5, 196.4, 194.0, 194.6, 164.0, 155.0, 181.1, 200.0, 182.9, 158.0, 149.0, 161.0, 171.2, 195.5, 190.1, 195.5, 198.2, 172.1, 186.5, 191.0, 181.1, 191.9, 183.8, 200.0, 143.3, 188.3, 182.89999999999995, 188.3, 155.0, 170.3, 200.0, 187.4, 173.0, 189.2, 200.0, 193.7, 148.70000000000002, 164.0, 195.5, 174.8, 187.4, 194.6, 200.0, 178.4, 198.2, 179.0, 182.0, 200.0, 182.0, 197.3, 181.4, 190.1, 182.9, 200.0, 191.89999999999998, 174.8, 174.8, 170.89999999999998, 199.1, 189.2, 191.0, 194.0, 191.0, 175.69999999999996, 167.6, 185.0, 200.0, 142.1, 182.0, 169.7, 190.1, 200.0, 185.6, 200.0, 199.1, 187.1, 167.0, 191.0, 177.2, 176.6, 190.1, 199.1, 188.0, 170.6, 188.3, 178.1, 200.0, 182.0, 140.29999999999998, 195.5, 200.0, 186.49999999999997, 198.2, 184.7, 170.3, 183.8, 198.2, 200.0, 200.0, 178.4, 200.0, 153.2, 143.3, 160.1, 197.0, 195.5, 200.0, 199.1, 197.3, 163.1], "policy_predator_policy_reward": [0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 2.0, 6.0, 0.0, 10.0, 0.0, 0.0, 0.0, 11.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 4.0, 0.0, 9.0, 9.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 8.0, 6.0, 8.0, 6.0, 0.0, 0.0, 0.0, 8.0, 6.0, 2.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 13.0, 0.0, 0.0, 3.0, 9.0, 0.0, 13.0, 0.0, 12.0, 0.0, 0.0, 15.0, 0.0, 0.0, 0.0, 8.0, 3.0, 5.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 14.0, 15.0, 6.0, 7.0, 7.0, 5.0, 7.0, 5.0, 2.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 2.0, 15.0, 0.0, 6.0, 0.0, 0.0, 14.0, 0.0, 27.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 15.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 6.0, 5.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 3.0, 8.0, 0.0, 9.0, 2.0, 11.0, 8.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 4.0, 7.0, 0.0, 7.0, 0.0, 0.0, 4.0, 2.0, 7.0, 7.0, 6.0, 0.0, 9.0, 10.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 23.0, 1.0, 0.0, 0.0, 0.0, 12.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 12.327157134252712, "mean_inference_ms": 30.20145840916673, "mean_action_processing_ms": 6.000316915326328, "mean_env_wait_ms": 7.486011319930778, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.010065197944641113, "StateBufferConnector_ms": 0.006661057472229004, "ViewRequirementAgentConnector_ms": 0.24433588981628418}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": 328.0, "episode_return_mean": 370.866, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2320000, "num_agent_steps_trained": 2320000, "num_env_steps_sampled": 580000, "num_env_steps_trained": 580000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 217.29565958382426, "num_env_steps_trained_throughput_per_sec": 217.29565958382426, "timesteps_total": 580000, "num_env_steps_sampled_lifetime": 580000, "num_agent_steps_sampled_lifetime": 2320000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2320000, "timers": {"training_iteration_time_ms": 201513.866, "restore_workers_time_ms": 0.019, "training_step_time_ms": 201513.575, "sample_time_ms": 94553.119, "learn_time_ms": 106927.018, "learn_throughput": 37.409, "synch_weights_time_ms": 27.924}, "counters": {"num_env_steps_sampled": 580000, "num_env_steps_trained": 580000, "num_agent_steps_sampled": 2320000, "num_agent_steps_trained": 2320000}, "done": false, "training_iteration": 145, "trial_id": "75ec3_00000", "date": "2024-08-13_05-40-03", "timestamp": 1723542003, "time_this_iter_s": 18.459941148757935, "time_total_s": 14751.60460281372, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b24b7ee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 14751.60460281372, "iterations_since_restore": 145, "perf": {"cpu_util_percent": 84.79615384615386, "ram_util_percent": 81.5923076923077}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.3246790244544626, "cur_kl_coeff": 0.08669300638060803, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.3734819889113568, "policy_loss": -0.0020315177948090923, "vf_loss": 0.37457595612341293, "vf_explained_var": 0.49183337596989185, "kl": 0.010814611951501572, "entropy": 1.2021863058761315, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 274995.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.26348013408560916, "cur_kl_coeff": 4.089454932665724e-28, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.1560630605176643, "policy_loss": -0.0016791700518557003, "vf_loss": 0.15774223009429603, "vf_explained_var": -0.04586949821502443, "kl": 0.022635148306646275, "entropy": 1.188145966630764, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 274995.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 584000, "num_env_steps_trained": 584000, "num_agent_steps_sampled": 2336000, "num_agent_steps_trained": 2336000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": 331.59999999999997, "episode_reward_mean": 373.85799999999995, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 140.29999999999998, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 27.0}, "policy_reward_mean": {"prey_policy": 184.06399999999996, "predator_policy": 2.865}, "custom_metrics": {}, "hist_stats": {"episode_reward": [377.5, 371.2, 352.4, 365.8, 366.1, 362.3, 351.4, 382.9, 357.4, 400.0, 364.5, 389.1, 354.5, 390.1, 390.1, 378.9, 346.2, 359.0, 372.7, 376.0, 380.7, 354.7, 391.9, 390.6, 334.0, 387.1, 354.9, 337.0, 366.70000000000005, 385.6, 370.3, 377.5, 373.0, 383.8, 331.59999999999997, 371.19999999999993, 343.3, 387.4, 362.2, 393.7, 339.7, 370.3, 382.0, 378.4, 384.2, 382.0, 385.3, 376.5, 382.9, 372.69999999999993, 349.7, 388.3, 388.0, 374.69999999999993, 363.6, 361.1, 359.7, 390.1, 385.6, 390.2, 369.0, 360.8, 389.2, 364.6, 380.4, 388.0, 354.80000000000007, 386.50000000000006, 382.9, 363.1, 398.2, 378.4, 353.20000000000005, 332.4, 393.5, 399.1, 372.4, 353.5, 384.2, 387.4, 383.8, 384.8, 367.8, 370.9, 364.6, 375.1, 380.2, 394.6, 387.4, 343.3, 396.0, 374.6, 360.0, 389.2, 391.9, 371.9, 394.2, 400.0, 381.7, 391.9], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [187.4, 190.1, 162.20000000000002, 200.0, 179.0, 160.4, 191.9, 173.9, 181.1, 173.0, 188.3, 161.0, 176.0, 163.4, 187.4, 195.5, 155.0, 187.4, 200.0, 200.0, 176.0, 177.5, 200.0, 184.1, 171.5, 170.0, 196.4, 193.7, 190.1, 200.0, 194.0, 182.9, 171.2, 146.0, 182.0, 164.0, 194.6, 166.1, 179.0, 185.0, 184.7, 194.0, 183.5, 162.20000000000002, 195.5, 196.4, 194.0, 194.6, 164.0, 155.0, 181.1, 200.0, 182.9, 158.0, 149.0, 161.0, 171.2, 195.5, 190.1, 195.5, 198.2, 172.1, 186.5, 191.0, 181.1, 191.9, 183.8, 200.0, 143.3, 188.3, 182.89999999999995, 188.3, 155.0, 170.3, 200.0, 187.4, 173.0, 189.2, 200.0, 193.7, 148.70000000000002, 164.0, 195.5, 174.8, 187.4, 194.6, 200.0, 178.4, 198.2, 179.0, 182.0, 200.0, 182.0, 197.3, 181.4, 190.1, 182.9, 200.0, 191.89999999999998, 174.8, 174.8, 170.89999999999998, 199.1, 189.2, 191.0, 194.0, 191.0, 175.69999999999996, 167.6, 185.0, 200.0, 142.1, 182.0, 169.7, 190.1, 200.0, 185.6, 200.0, 199.1, 187.1, 167.0, 191.0, 177.2, 176.6, 190.1, 199.1, 188.0, 170.6, 188.3, 178.1, 200.0, 182.0, 140.29999999999998, 195.5, 200.0, 186.49999999999997, 198.2, 184.7, 170.3, 183.8, 198.2, 200.0, 200.0, 178.4, 200.0, 153.2, 143.3, 160.1, 197.0, 195.5, 200.0, 199.1, 197.3, 163.1, 180.5, 164.0, 179.0, 198.2, 194.6, 192.8, 190.1, 193.7, 188.0, 192.8, 189.2, 170.6, 182.9, 176.0, 177.5, 181.1, 163.1, 200.0, 196.4, 183.8, 196.4, 198.2, 200.0, 187.4, 182.9, 160.4, 200.0, 194.0, 200.0, 173.6, 153.8, 189.2, 199.1, 190.1, 197.3, 194.6, 188.9, 182.0, 200.0, 192.2, 200.0, 200.0, 175.7, 200.0, 200.0, 191.9], "policy_predator_policy_reward": [0.0, 0.0, 9.0, 0.0, 0.0, 13.0, 0.0, 0.0, 3.0, 9.0, 0.0, 13.0, 0.0, 12.0, 0.0, 0.0, 15.0, 0.0, 0.0, 0.0, 8.0, 3.0, 5.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 14.0, 15.0, 6.0, 7.0, 7.0, 5.0, 7.0, 5.0, 2.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 2.0, 15.0, 0.0, 6.0, 0.0, 0.0, 14.0, 0.0, 27.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 15.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 6.0, 5.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 3.0, 8.0, 0.0, 9.0, 2.0, 11.0, 8.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 4.0, 7.0, 0.0, 7.0, 0.0, 0.0, 4.0, 2.0, 7.0, 7.0, 6.0, 0.0, 9.0, 10.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 23.0, 1.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 9.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 8.0, 0.0, 4.0, 8.0, 0.0, 6.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 12.0, 5.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 12.245656900828854, "mean_inference_ms": 29.972173865215904, "mean_action_processing_ms": 5.954594654669154, "mean_env_wait_ms": 7.435514482594214, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00972592830657959, "StateBufferConnector_ms": 0.006974220275878906, "ViewRequirementAgentConnector_ms": 0.21105217933654785}, "num_episodes": 23, "episode_return_max": 400.0, "episode_return_min": 331.59999999999997, "episode_return_mean": 373.85799999999995, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2336000, "num_agent_steps_trained": 2336000, "num_env_steps_sampled": 584000, "num_env_steps_trained": 584000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 209.6507481187596, "num_env_steps_trained_throughput_per_sec": 209.6507481187596, "timesteps_total": 584000, "num_env_steps_sampled_lifetime": 584000, "num_agent_steps_sampled_lifetime": 2336000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2336000, "timers": {"training_iteration_time_ms": 201233.98, "restore_workers_time_ms": 0.02, "training_step_time_ms": 201233.689, "sample_time_ms": 94460.68, "learn_time_ms": 106739.883, "learn_throughput": 37.474, "synch_weights_time_ms": 27.437}, "counters": {"num_env_steps_sampled": 584000, "num_env_steps_trained": 584000, "num_agent_steps_sampled": 2336000, "num_agent_steps_trained": 2336000}, "done": false, "training_iteration": 146, "trial_id": "75ec3_00000", "date": "2024-08-13_05-40-22", "timestamp": 1723542022, "time_this_iter_s": 19.165510892868042, "time_total_s": 14770.770113706589, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b24f25e0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 14770.770113706589, "iterations_since_restore": 146, "perf": {"cpu_util_percent": 83.61851851851853, "ram_util_percent": 81.78148148148148}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.2423251215112274, "cur_kl_coeff": 0.08669300638060803, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.4060260854899685, "policy_loss": -0.0029703148266192153, "vf_loss": 0.4082150476964969, "vf_explained_var": 0.30591817176531233, "kl": 0.009012880810306106, "entropy": 1.2106820315911027, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 276885.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.34489342817869134, "cur_kl_coeff": 6.13418239899859e-28, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.22098430201963143, "policy_loss": -0.0004919152177140984, "vf_loss": 0.2214762171236404, "vf_explained_var": 0.15474149509081764, "kl": 0.03737954928371805, "entropy": 1.2033390914952313, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 276885.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 588000, "num_env_steps_trained": 588000, "num_agent_steps_sampled": 2352000, "num_agent_steps_trained": 2352000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": 331.59999999999997, "episode_reward_mean": 375.1869999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 140.29999999999998, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 27.0}, "policy_reward_mean": {"prey_policy": 184.9535, "predator_policy": 2.64}, "custom_metrics": {}, "hist_stats": {"episode_reward": [391.9, 390.6, 334.0, 387.1, 354.9, 337.0, 366.70000000000005, 385.6, 370.3, 377.5, 373.0, 383.8, 331.59999999999997, 371.19999999999993, 343.3, 387.4, 362.2, 393.7, 339.7, 370.3, 382.0, 378.4, 384.2, 382.0, 385.3, 376.5, 382.9, 372.69999999999993, 349.7, 388.3, 388.0, 374.69999999999993, 363.6, 361.1, 359.7, 390.1, 385.6, 390.2, 369.0, 360.8, 389.2, 364.6, 380.4, 388.0, 354.80000000000007, 386.50000000000006, 382.9, 363.1, 398.2, 378.4, 353.20000000000005, 332.4, 393.5, 399.1, 372.4, 353.5, 384.2, 387.4, 383.8, 384.8, 367.8, 370.9, 364.6, 375.1, 380.2, 394.6, 387.4, 343.3, 396.0, 374.6, 360.0, 389.2, 391.9, 371.9, 394.2, 400.0, 381.7, 391.9, 377.4, 387.4, 370.4, 360.8, 378.0, 381.3, 373.9, 390.1, 378.1, 365.2, 353.7, 372.8, 372.6, 363.1, 399.1, 379.3, 374.8, 388.1, 395.5, 370.2, 383.2, 361.40000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [195.5, 196.4, 194.0, 194.6, 164.0, 155.0, 181.1, 200.0, 182.9, 158.0, 149.0, 161.0, 171.2, 195.5, 190.1, 195.5, 198.2, 172.1, 186.5, 191.0, 181.1, 191.9, 183.8, 200.0, 143.3, 188.3, 182.89999999999995, 188.3, 155.0, 170.3, 200.0, 187.4, 173.0, 189.2, 200.0, 193.7, 148.70000000000002, 164.0, 195.5, 174.8, 187.4, 194.6, 200.0, 178.4, 198.2, 179.0, 182.0, 200.0, 182.0, 197.3, 181.4, 190.1, 182.9, 200.0, 191.89999999999998, 174.8, 174.8, 170.89999999999998, 199.1, 189.2, 191.0, 194.0, 191.0, 175.69999999999996, 167.6, 185.0, 200.0, 142.1, 182.0, 169.7, 190.1, 200.0, 185.6, 200.0, 199.1, 187.1, 167.0, 191.0, 177.2, 176.6, 190.1, 199.1, 188.0, 170.6, 188.3, 178.1, 200.0, 182.0, 140.29999999999998, 195.5, 200.0, 186.49999999999997, 198.2, 184.7, 170.3, 183.8, 198.2, 200.0, 200.0, 178.4, 200.0, 153.2, 143.3, 160.1, 197.0, 195.5, 200.0, 199.1, 197.3, 163.1, 180.5, 164.0, 179.0, 198.2, 194.6, 192.8, 190.1, 193.7, 188.0, 192.8, 189.2, 170.6, 182.9, 176.0, 177.5, 181.1, 163.1, 200.0, 196.4, 183.8, 196.4, 198.2, 200.0, 187.4, 182.9, 160.4, 200.0, 194.0, 200.0, 173.6, 153.8, 189.2, 199.1, 190.1, 197.3, 194.6, 188.9, 182.0, 200.0, 192.2, 200.0, 200.0, 175.7, 200.0, 200.0, 191.9, 182.3, 187.1, 188.3, 199.1, 157.4, 200.0, 167.6, 183.2, 179.0, 197.0, 185.0, 191.3, 189.2, 184.7, 191.0, 199.1, 182.0, 190.1, 168.2, 185.0, 167.0, 166.7, 168.2, 194.6, 161.6, 200.0, 161.3, 192.8, 199.1, 200.0, 197.3, 182.0, 186.5, 188.3, 193.7, 193.4, 200.0, 195.5, 198.2, 158.0, 188.3, 191.9, 170.0, 178.4], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 2.0, 15.0, 0.0, 6.0, 0.0, 0.0, 14.0, 0.0, 27.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 15.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 6.0, 5.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 3.0, 8.0, 0.0, 9.0, 2.0, 11.0, 8.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 4.0, 7.0, 0.0, 7.0, 0.0, 0.0, 4.0, 2.0, 7.0, 7.0, 6.0, 0.0, 9.0, 10.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 23.0, 1.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 9.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 8.0, 0.0, 4.0, 8.0, 0.0, 6.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 12.0, 5.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 4.0, 4.0, 0.0, 0.0, 3.0, 10.0, 3.0, 7.0, 1.0, 1.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 12.0, 0.0, 11.0, 9.0, 0.0, 10.0, 7.0, 4.0, 2.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 7.0, 7.0, 0.0, 3.0, 7.0, 6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 12.627062836521223, "mean_inference_ms": 29.302711583950167, "mean_action_processing_ms": 5.9225636578633525, "mean_env_wait_ms": 7.2384252285627975, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.008191108703613281, "StateBufferConnector_ms": 0.005934476852416992, "ViewRequirementAgentConnector_ms": 0.19296228885650635}, "num_episodes": 22, "episode_return_max": 400.0, "episode_return_min": 331.59999999999997, "episode_return_mean": 375.1869999999999, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2352000, "num_agent_steps_trained": 2352000, "num_env_steps_sampled": 588000, "num_env_steps_trained": 588000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 146.68946332230072, "num_env_steps_trained_throughput_per_sec": 146.68946332230072, "timesteps_total": 588000, "num_env_steps_sampled_lifetime": 588000, "num_agent_steps_sampled_lifetime": 2352000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2352000, "timers": {"training_iteration_time_ms": 109696.941, "restore_workers_time_ms": 0.019, "training_step_time_ms": 109696.65, "sample_time_ms": 2951.512, "learn_time_ms": 106712.926, "learn_throughput": 37.484, "synch_weights_time_ms": 28.18}, "counters": {"num_env_steps_sampled": 588000, "num_env_steps_trained": 588000, "num_agent_steps_sampled": 2352000, "num_agent_steps_trained": 2352000}, "done": false, "training_iteration": 147, "trial_id": "75ec3_00000", "date": "2024-08-13_05-40-50", "timestamp": 1723542050, "time_this_iter_s": 27.32990527153015, "time_total_s": 14798.100018978119, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b24c4d30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 14798.100018978119, "iterations_since_restore": 147, "perf": {"cpu_util_percent": 90.41578947368421, "ram_util_percent": 83.50526315789473}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.462640580802998, "cur_kl_coeff": 0.08669300638060803, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.7031812891571059, "policy_loss": -0.005500195990686142, "vf_loss": 0.7078074415919011, "vf_explained_var": 0.3661122189943122, "kl": 0.010082073951040047, "entropy": 1.2259801179012924, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 278775.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.23207195461998698, "cur_kl_coeff": 9.201273598497877e-28, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.12202358794442955, "policy_loss": -0.0007148635083385719, "vf_loss": 0.12273845132454188, "vf_explained_var": 0.030144353865315675, "kl": 0.02033700103316637, "entropy": 1.2306849654389438, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 278775.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 592000, "num_env_steps_trained": 592000, "num_agent_steps_sampled": 2368000, "num_agent_steps_trained": 2368000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": 332.4, "episode_reward_mean": 375.9619999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 140.29999999999998, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 23.0}, "policy_reward_mean": {"prey_policy": 185.291, "predator_policy": 2.69}, "custom_metrics": {}, "hist_stats": {"episode_reward": [339.7, 370.3, 382.0, 378.4, 384.2, 382.0, 385.3, 376.5, 382.9, 372.69999999999993, 349.7, 388.3, 388.0, 374.69999999999993, 363.6, 361.1, 359.7, 390.1, 385.6, 390.2, 369.0, 360.8, 389.2, 364.6, 380.4, 388.0, 354.80000000000007, 386.50000000000006, 382.9, 363.1, 398.2, 378.4, 353.20000000000005, 332.4, 393.5, 399.1, 372.4, 353.5, 384.2, 387.4, 383.8, 384.8, 367.8, 370.9, 364.6, 375.1, 380.2, 394.6, 387.4, 343.3, 396.0, 374.6, 360.0, 389.2, 391.9, 371.9, 394.2, 400.0, 381.7, 391.9, 377.4, 387.4, 370.4, 360.8, 378.0, 381.3, 373.9, 390.1, 378.1, 365.2, 353.7, 372.8, 372.6, 363.1, 399.1, 379.3, 374.8, 388.1, 395.5, 370.2, 383.2, 361.40000000000003, 382.0, 373.7, 382.6, 343.5, 395.5, 373.0, 375.0, 370.9, 359.0, 374.7, 392.8, 365.4, 378.7, 362.6, 369.2, 394.2, 358.0, 368.5000000000005], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [148.70000000000002, 164.0, 195.5, 174.8, 187.4, 194.6, 200.0, 178.4, 198.2, 179.0, 182.0, 200.0, 182.0, 197.3, 181.4, 190.1, 182.9, 200.0, 191.89999999999998, 174.8, 174.8, 170.89999999999998, 199.1, 189.2, 191.0, 194.0, 191.0, 175.69999999999996, 167.6, 185.0, 200.0, 142.1, 182.0, 169.7, 190.1, 200.0, 185.6, 200.0, 199.1, 187.1, 167.0, 191.0, 177.2, 176.6, 190.1, 199.1, 188.0, 170.6, 188.3, 178.1, 200.0, 182.0, 140.29999999999998, 195.5, 200.0, 186.49999999999997, 198.2, 184.7, 170.3, 183.8, 198.2, 200.0, 200.0, 178.4, 200.0, 153.2, 143.3, 160.1, 197.0, 195.5, 200.0, 199.1, 197.3, 163.1, 180.5, 164.0, 179.0, 198.2, 194.6, 192.8, 190.1, 193.7, 188.0, 192.8, 189.2, 170.6, 182.9, 176.0, 177.5, 181.1, 163.1, 200.0, 196.4, 183.8, 196.4, 198.2, 200.0, 187.4, 182.9, 160.4, 200.0, 194.0, 200.0, 173.6, 153.8, 189.2, 199.1, 190.1, 197.3, 194.6, 188.9, 182.0, 200.0, 192.2, 200.0, 200.0, 175.7, 200.0, 200.0, 191.9, 182.3, 187.1, 188.3, 199.1, 157.4, 200.0, 167.6, 183.2, 179.0, 197.0, 185.0, 191.3, 189.2, 184.7, 191.0, 199.1, 182.0, 190.1, 168.2, 185.0, 167.0, 166.7, 168.2, 194.6, 161.6, 200.0, 161.3, 192.8, 199.1, 200.0, 197.3, 182.0, 186.5, 188.3, 193.7, 193.4, 200.0, 195.5, 198.2, 158.0, 188.3, 191.9, 170.0, 178.4, 186.5, 195.5, 182.6, 190.1, 185.6, 191.0, 160.4, 175.1, 195.5, 200.0, 173.0, 191.0, 167.0, 200.0, 178.39999999999998, 186.5, 176.0, 173.0, 185.0, 184.7, 199.1, 193.7, 166.4, 185.0, 175.7, 200.0, 179.0, 176.6, 183.5, 184.7, 193.1, 199.1, 173.0, 173.0, 175.6999999999999, 192.79999999999995], "policy_predator_policy_reward": [12.0, 15.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 6.0, 5.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 3.0, 8.0, 0.0, 9.0, 2.0, 11.0, 8.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 4.0, 7.0, 0.0, 7.0, 0.0, 0.0, 4.0, 2.0, 7.0, 7.0, 6.0, 0.0, 9.0, 10.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 23.0, 1.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 9.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 8.0, 0.0, 4.0, 8.0, 0.0, 6.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 12.0, 5.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 4.0, 4.0, 0.0, 0.0, 3.0, 10.0, 3.0, 7.0, 1.0, 1.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 12.0, 0.0, 11.0, 9.0, 0.0, 10.0, 7.0, 4.0, 2.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 7.0, 7.0, 0.0, 3.0, 7.0, 6.0, 0.0, 0.0, 0.0, 1.0, 3.0, 3.0, 8.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 8.0, 6.0, 0.0, 10.0, 0.0, 0.0, 5.0, 0.0, 0.0, 14.0, 0.0, 0.0, 3.0, 7.0, 0.0, 1.0, 0.0, 0.0, 2.0, 12.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 12.089426057520615, "mean_inference_ms": 29.62073960458625, "mean_action_processing_ms": 5.881637819013918, "mean_env_wait_ms": 7.334899996599011, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006589531898498535, "StateBufferConnector_ms": 0.006354689598083496, "ViewRequirementAgentConnector_ms": 0.18231940269470215}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": 332.4, "episode_return_mean": 375.9619999999999, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2368000, "num_agent_steps_trained": 2368000, "num_env_steps_sampled": 592000, "num_env_steps_trained": 592000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 191.84892365643216, "num_env_steps_trained_throughput_per_sec": 191.84892365643216, "timesteps_total": 592000, "num_env_steps_sampled_lifetime": 592000, "num_agent_steps_sampled_lifetime": 2368000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2368000, "timers": {"training_iteration_time_ms": 110004.628, "restore_workers_time_ms": 0.019, "training_step_time_ms": 110004.332, "sample_time_ms": 2871.04, "learn_time_ms": 107100.012, "learn_throughput": 37.348, "synch_weights_time_ms": 28.932}, "counters": {"num_env_steps_sampled": 592000, "num_env_steps_trained": 592000, "num_agent_steps_sampled": 2368000, "num_agent_steps_trained": 2368000}, "done": false, "training_iteration": 148, "trial_id": "75ec3_00000", "date": "2024-08-13_05-41-11", "timestamp": 1723542071, "time_this_iter_s": 20.929009199142456, "time_total_s": 14819.029028177261, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2497b80>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 14819.029028177261, "iterations_since_restore": 148, "perf": {"cpu_util_percent": 84.30666666666667, "ram_util_percent": 83.49333333333334}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8438218994982658, "cur_kl_coeff": 0.08669300638060803, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.31410738510103087, "policy_loss": -0.0018428842907909442, "vf_loss": 0.31540939417025865, "vf_explained_var": 0.36853472111086366, "kl": 0.006238966251282232, "entropy": 1.2380915658183829, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 280665.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.24532446070382047, "cur_kl_coeff": 1.3801910397746818e-27, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.13603394878658628, "policy_loss": -0.0006748245349006047, "vf_loss": 0.1367087729885329, "vf_explained_var": 0.006787446093937707, "kl": 0.015015480216630768, "entropy": 1.1263060776014178, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 280665.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 596000, "num_env_steps_trained": 596000, "num_agent_steps_sampled": 2384000, "num_agent_steps_trained": 2384000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": 332.4, "episode_reward_mean": 376.54799999999994, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 140.29999999999998, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 23.0}, "policy_reward_mean": {"prey_policy": 185.609, "predator_policy": 2.665}, "custom_metrics": {}, "hist_stats": {"episode_reward": [385.6, 390.2, 369.0, 360.8, 389.2, 364.6, 380.4, 388.0, 354.80000000000007, 386.50000000000006, 382.9, 363.1, 398.2, 378.4, 353.20000000000005, 332.4, 393.5, 399.1, 372.4, 353.5, 384.2, 387.4, 383.8, 384.8, 367.8, 370.9, 364.6, 375.1, 380.2, 394.6, 387.4, 343.3, 396.0, 374.6, 360.0, 389.2, 391.9, 371.9, 394.2, 400.0, 381.7, 391.9, 377.4, 387.4, 370.4, 360.8, 378.0, 381.3, 373.9, 390.1, 378.1, 365.2, 353.7, 372.8, 372.6, 363.1, 399.1, 379.3, 374.8, 388.1, 395.5, 370.2, 383.2, 361.40000000000003, 382.0, 373.7, 382.6, 343.5, 395.5, 373.0, 375.0, 370.9, 359.0, 374.7, 392.8, 365.4, 378.7, 362.6, 369.2, 394.2, 358.0, 368.5000000000005, 383.7, 376.5, 395.5, 367.0, 381.1, 386.2, 369.4, 370.0, 378.4, 389.0, 387.5, 393.7, 376.6, 361.0, 367.5, 349.6, 381.2, 373.9], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [185.6, 200.0, 199.1, 187.1, 167.0, 191.0, 177.2, 176.6, 190.1, 199.1, 188.0, 170.6, 188.3, 178.1, 200.0, 182.0, 140.29999999999998, 195.5, 200.0, 186.49999999999997, 198.2, 184.7, 170.3, 183.8, 198.2, 200.0, 200.0, 178.4, 200.0, 153.2, 143.3, 160.1, 197.0, 195.5, 200.0, 199.1, 197.3, 163.1, 180.5, 164.0, 179.0, 198.2, 194.6, 192.8, 190.1, 193.7, 188.0, 192.8, 189.2, 170.6, 182.9, 176.0, 177.5, 181.1, 163.1, 200.0, 196.4, 183.8, 196.4, 198.2, 200.0, 187.4, 182.9, 160.4, 200.0, 194.0, 200.0, 173.6, 153.8, 189.2, 199.1, 190.1, 197.3, 194.6, 188.9, 182.0, 200.0, 192.2, 200.0, 200.0, 175.7, 200.0, 200.0, 191.9, 182.3, 187.1, 188.3, 199.1, 157.4, 200.0, 167.6, 183.2, 179.0, 197.0, 185.0, 191.3, 189.2, 184.7, 191.0, 199.1, 182.0, 190.1, 168.2, 185.0, 167.0, 166.7, 168.2, 194.6, 161.6, 200.0, 161.3, 192.8, 199.1, 200.0, 197.3, 182.0, 186.5, 188.3, 193.7, 193.4, 200.0, 195.5, 198.2, 158.0, 188.3, 191.9, 170.0, 178.4, 186.5, 195.5, 182.6, 190.1, 185.6, 191.0, 160.4, 175.1, 195.5, 200.0, 173.0, 191.0, 167.0, 200.0, 178.39999999999998, 186.5, 176.0, 173.0, 185.0, 184.7, 199.1, 193.7, 166.4, 185.0, 175.7, 200.0, 179.0, 176.6, 183.5, 184.7, 193.1, 199.1, 173.0, 173.0, 175.6999999999999, 192.79999999999995, 200.0, 178.7, 179.0, 186.5, 200.0, 195.5, 185.0, 173.0, 188.3, 192.8, 183.2, 197.0, 171.2, 189.2, 194.0, 164.0, 184.7, 193.7, 195.5, 192.5, 195.5, 188.0, 200.0, 193.7, 191.0, 185.6, 172.7, 179.3, 158.0, 195.5, 179.6, 155.0, 187.1, 190.1, 190.1, 183.8], "policy_predator_policy_reward": [0.0, 0.0, 4.0, 0.0, 4.0, 7.0, 0.0, 7.0, 0.0, 0.0, 4.0, 2.0, 7.0, 7.0, 6.0, 0.0, 9.0, 10.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 23.0, 1.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 9.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 8.0, 0.0, 4.0, 8.0, 0.0, 6.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 12.0, 5.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 4.0, 4.0, 0.0, 0.0, 3.0, 10.0, 3.0, 7.0, 1.0, 1.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 12.0, 0.0, 11.0, 9.0, 0.0, 10.0, 7.0, 4.0, 2.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 7.0, 7.0, 0.0, 3.0, 7.0, 6.0, 0.0, 0.0, 0.0, 1.0, 3.0, 3.0, 8.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 8.0, 6.0, 0.0, 10.0, 0.0, 0.0, 5.0, 0.0, 0.0, 14.0, 0.0, 0.0, 3.0, 7.0, 0.0, 1.0, 0.0, 0.0, 2.0, 12.0, 0.0, 0.0, 0.0, 5.0, 0.0, 4.0, 7.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 9.0, 12.0, 0.0, 0.0, 0.0, 0.0, 1.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 6.0, 7.0, 7.0, 0.0, 15.0, 4.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 12.022009463945553, "mean_inference_ms": 29.458685262097088, "mean_action_processing_ms": 5.8481929941244974, "mean_env_wait_ms": 7.291985386589069, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007279515266418457, "StateBufferConnector_ms": 0.005617856979370117, "ViewRequirementAgentConnector_ms": 0.20107996463775635}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": 332.4, "episode_return_mean": 376.54799999999994, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2384000, "num_agent_steps_trained": 2384000, "num_env_steps_sampled": 596000, "num_env_steps_trained": 596000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 178.98723907934254, "num_env_steps_trained_throughput_per_sec": 178.98723907934254, "timesteps_total": 596000, "num_env_steps_sampled_lifetime": 596000, "num_agent_steps_sampled_lifetime": 2384000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2384000, "timers": {"training_iteration_time_ms": 19727.229, "restore_workers_time_ms": 0.02, "training_step_time_ms": 19727.158, "sample_time_ms": 2846.303, "learn_time_ms": 16846.979, "learn_throughput": 237.431, "synch_weights_time_ms": 29.276}, "counters": {"num_env_steps_sampled": 596000, "num_env_steps_trained": 596000, "num_agent_steps_sampled": 2384000, "num_agent_steps_trained": 2384000}, "done": false, "training_iteration": 149, "trial_id": "75ec3_00000", "date": "2024-08-13_05-41-33", "timestamp": 1723542093, "time_this_iter_s": 22.399930238723755, "time_total_s": 14841.428958415985, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2526790>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 14841.428958415985, "iterations_since_restore": 149, "perf": {"cpu_util_percent": 85.94193548387098, "ram_util_percent": 83.57096774193548}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8745726059432384, "cur_kl_coeff": 0.08669300638060803, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.40079083206737537, "policy_loss": -0.0027944819779977914, "vf_loss": 0.4030939461261455, "vf_explained_var": 0.3567333872040744, "kl": 0.0056679067060579815, "entropy": 1.2470350943545185, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 282555.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.23666816477678598, "cur_kl_coeff": 1.3801910397746818e-27, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.18001727487241465, "policy_loss": -0.0006831260508902016, "vf_loss": 0.18070040087122594, "vf_explained_var": -0.0034866791238229744, "kl": 0.01738738422826545, "entropy": 1.138911251605503, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 282555.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 600000, "num_env_steps_trained": 600000, "num_agent_steps_sampled": 2400000, "num_agent_steps_trained": 2400000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": 333.6, "episode_reward_mean": 375.974, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 150.5, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 18.0}, "policy_reward_mean": {"prey_policy": 185.22199999999998, "predator_policy": 2.765}, "custom_metrics": {}, "hist_stats": {"episode_reward": [384.8, 367.8, 370.9, 364.6, 375.1, 380.2, 394.6, 387.4, 343.3, 396.0, 374.6, 360.0, 389.2, 391.9, 371.9, 394.2, 400.0, 381.7, 391.9, 377.4, 387.4, 370.4, 360.8, 378.0, 381.3, 373.9, 390.1, 378.1, 365.2, 353.7, 372.8, 372.6, 363.1, 399.1, 379.3, 374.8, 388.1, 395.5, 370.2, 383.2, 361.40000000000003, 382.0, 373.7, 382.6, 343.5, 395.5, 373.0, 375.0, 370.9, 359.0, 374.7, 392.8, 365.4, 378.7, 362.6, 369.2, 394.2, 358.0, 368.5000000000005, 383.7, 376.5, 395.5, 367.0, 381.1, 386.2, 369.4, 370.0, 378.4, 389.0, 387.5, 393.7, 376.6, 361.0, 367.5, 349.6, 381.2, 373.9, 379.3, 353.2, 359.5, 399.1, 354.1, 390.1, 384.7, 374.4, 396.4, 382.4, 378.5, 363.1, 333.6, 361.2, 379.1, 386.5, 380.20000000000005, 386.5, 378.4, 375.3, 384.8, 365.0, 348.4], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [188.0, 192.8, 189.2, 170.6, 182.9, 176.0, 177.5, 181.1, 163.1, 200.0, 196.4, 183.8, 196.4, 198.2, 200.0, 187.4, 182.9, 160.4, 200.0, 194.0, 200.0, 173.6, 153.8, 189.2, 199.1, 190.1, 197.3, 194.6, 188.9, 182.0, 200.0, 192.2, 200.0, 200.0, 175.7, 200.0, 200.0, 191.9, 182.3, 187.1, 188.3, 199.1, 157.4, 200.0, 167.6, 183.2, 179.0, 197.0, 185.0, 191.3, 189.2, 184.7, 191.0, 199.1, 182.0, 190.1, 168.2, 185.0, 167.0, 166.7, 168.2, 194.6, 161.6, 200.0, 161.3, 192.8, 199.1, 200.0, 197.3, 182.0, 186.5, 188.3, 193.7, 193.4, 200.0, 195.5, 198.2, 158.0, 188.3, 191.9, 170.0, 178.4, 186.5, 195.5, 182.6, 190.1, 185.6, 191.0, 160.4, 175.1, 195.5, 200.0, 173.0, 191.0, 167.0, 200.0, 178.39999999999998, 186.5, 176.0, 173.0, 185.0, 184.7, 199.1, 193.7, 166.4, 185.0, 175.7, 200.0, 179.0, 176.6, 183.5, 184.7, 193.1, 199.1, 173.0, 173.0, 175.6999999999999, 192.79999999999995, 200.0, 178.7, 179.0, 186.5, 200.0, 195.5, 185.0, 173.0, 188.3, 192.8, 183.2, 197.0, 171.2, 189.2, 194.0, 164.0, 184.7, 193.7, 195.5, 192.5, 195.5, 188.0, 200.0, 193.7, 191.0, 185.6, 172.7, 179.3, 158.0, 195.5, 179.6, 155.0, 187.1, 190.1, 190.1, 183.8, 186.5, 192.8, 163.4, 171.8, 150.5, 200.0, 199.1, 200.0, 171.8, 167.3, 195.5, 194.6, 200.0, 184.7, 167.0, 196.4, 200.0, 196.4, 200.0, 175.4, 184.4, 190.1, 167.6, 186.5, 152.60000000000002, 161.0, 168.2, 179.0, 191.0, 187.1, 196.4, 190.1, 200.0, 180.2, 192.8, 193.7, 188.3, 190.1, 173.3, 191.0, 194.6, 186.2, 185.0, 167.0, 161.0, 169.4], "policy_predator_policy_reward": [0.0, 4.0, 8.0, 0.0, 4.0, 8.0, 0.0, 6.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 12.0, 5.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 4.0, 4.0, 0.0, 0.0, 3.0, 10.0, 3.0, 7.0, 1.0, 1.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 12.0, 0.0, 11.0, 9.0, 0.0, 10.0, 7.0, 4.0, 2.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 7.0, 7.0, 0.0, 3.0, 7.0, 6.0, 0.0, 0.0, 0.0, 1.0, 3.0, 3.0, 8.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 8.0, 6.0, 0.0, 10.0, 0.0, 0.0, 5.0, 0.0, 0.0, 14.0, 0.0, 0.0, 3.0, 7.0, 0.0, 1.0, 0.0, 0.0, 2.0, 12.0, 0.0, 0.0, 0.0, 5.0, 0.0, 4.0, 7.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 9.0, 12.0, 0.0, 0.0, 0.0, 0.0, 1.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 6.0, 7.0, 7.0, 0.0, 15.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 7.0, 9.0, 0.0, 0.0, 0.0, 0.0, 15.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 4.0, 9.0, 0.0, 3.0, 17.0, 14.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 8.0, 4.0, 0.0, 0.0, 13.0, 0.0, 18.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 11.788947577894191, "mean_inference_ms": 29.857343286830815, "mean_action_processing_ms": 5.964813772666583, "mean_env_wait_ms": 6.642424465394949, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007966041564941406, "StateBufferConnector_ms": 0.005619406700134277, "ViewRequirementAgentConnector_ms": 0.21005010604858398}, "num_episodes": 23, "episode_return_max": 400.0, "episode_return_min": 333.6, "episode_return_mean": 375.974, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2400000, "num_agent_steps_trained": 2400000, "num_env_steps_sampled": 600000, "num_env_steps_trained": 600000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 176.93155821354557, "num_env_steps_trained_throughput_per_sec": 176.93155821354557, "timesteps_total": 600000, "num_env_steps_sampled_lifetime": 600000, "num_agent_steps_sampled_lifetime": 2400000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2400000, "timers": {"training_iteration_time_ms": 20067.621, "restore_workers_time_ms": 0.02, "training_step_time_ms": 20067.548, "sample_time_ms": 2768.16, "learn_time_ms": 17265.764, "learn_throughput": 231.672, "synch_weights_time_ms": 29.081}, "counters": {"num_env_steps_sampled": 600000, "num_env_steps_trained": 600000, "num_agent_steps_sampled": 2400000, "num_agent_steps_trained": 2400000}, "done": false, "training_iteration": 150, "trial_id": "75ec3_00000", "date": "2024-08-13_05-41-56", "timestamp": 1723542116, "time_this_iter_s": 22.655534982681274, "time_total_s": 14864.084493398666, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b24c4d30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 14864.084493398666, "iterations_since_restore": 150, "perf": {"cpu_util_percent": 85.671875, "ram_util_percent": 83.49687499999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.986669460573682, "cur_kl_coeff": 0.08669300638060803, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.2504164098282148, "policy_loss": -0.0029279705260205208, "vf_loss": 0.2528591332257425, "vf_explained_var": 0.4281866956955541, "kl": 0.00559729978466121, "entropy": 1.2459938555798202, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 284445.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.2269690102715262, "cur_kl_coeff": 1.3801910397746818e-27, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.15497952670686774, "policy_loss": -0.0008501889657170054, "vf_loss": 0.1558297154127445, "vf_explained_var": 0.022615021719503654, "kl": 0.01919877120925032, "entropy": 1.1443115192746358, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 284445.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 604000, "num_env_steps_trained": 604000, "num_agent_steps_sampled": 2416000, "num_agent_steps_trained": 2416000}, "env_runners": {"episode_reward_max": 399.1, "episode_reward_min": 333.6, "episode_reward_mean": 376.05300000000005, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 149.6, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 18.0}, "policy_reward_mean": {"prey_policy": 185.0765, "predator_policy": 2.95}, "custom_metrics": {}, "hist_stats": {"episode_reward": [391.9, 377.4, 387.4, 370.4, 360.8, 378.0, 381.3, 373.9, 390.1, 378.1, 365.2, 353.7, 372.8, 372.6, 363.1, 399.1, 379.3, 374.8, 388.1, 395.5, 370.2, 383.2, 361.40000000000003, 382.0, 373.7, 382.6, 343.5, 395.5, 373.0, 375.0, 370.9, 359.0, 374.7, 392.8, 365.4, 378.7, 362.6, 369.2, 394.2, 358.0, 368.5000000000005, 383.7, 376.5, 395.5, 367.0, 381.1, 386.2, 369.4, 370.0, 378.4, 389.0, 387.5, 393.7, 376.6, 361.0, 367.5, 349.6, 381.2, 373.9, 379.3, 353.2, 359.5, 399.1, 354.1, 390.1, 384.7, 374.4, 396.4, 382.4, 378.5, 363.1, 333.6, 361.2, 379.1, 386.5, 380.20000000000005, 386.5, 378.4, 375.3, 384.8, 365.0, 348.4, 361.3, 362.5, 398.2, 398.2, 379.29999999999995, 397.3, 358.9, 364.2, 399.1, 365.5, 378.8, 379.7, 387.4, 352.9, 381.1, 396.0, 379.3, 396.4], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [200.0, 191.9, 182.3, 187.1, 188.3, 199.1, 157.4, 200.0, 167.6, 183.2, 179.0, 197.0, 185.0, 191.3, 189.2, 184.7, 191.0, 199.1, 182.0, 190.1, 168.2, 185.0, 167.0, 166.7, 168.2, 194.6, 161.6, 200.0, 161.3, 192.8, 199.1, 200.0, 197.3, 182.0, 186.5, 188.3, 193.7, 193.4, 200.0, 195.5, 198.2, 158.0, 188.3, 191.9, 170.0, 178.4, 186.5, 195.5, 182.6, 190.1, 185.6, 191.0, 160.4, 175.1, 195.5, 200.0, 173.0, 191.0, 167.0, 200.0, 178.39999999999998, 186.5, 176.0, 173.0, 185.0, 184.7, 199.1, 193.7, 166.4, 185.0, 175.7, 200.0, 179.0, 176.6, 183.5, 184.7, 193.1, 199.1, 173.0, 173.0, 175.6999999999999, 192.79999999999995, 200.0, 178.7, 179.0, 186.5, 200.0, 195.5, 185.0, 173.0, 188.3, 192.8, 183.2, 197.0, 171.2, 189.2, 194.0, 164.0, 184.7, 193.7, 195.5, 192.5, 195.5, 188.0, 200.0, 193.7, 191.0, 185.6, 172.7, 179.3, 158.0, 195.5, 179.6, 155.0, 187.1, 190.1, 190.1, 183.8, 186.5, 192.8, 163.4, 171.8, 150.5, 200.0, 199.1, 200.0, 171.8, 167.3, 195.5, 194.6, 200.0, 184.7, 167.0, 196.4, 200.0, 196.4, 200.0, 175.4, 184.4, 190.1, 167.6, 186.5, 152.60000000000002, 161.0, 168.2, 179.0, 191.0, 187.1, 196.4, 190.1, 200.0, 180.2, 192.8, 193.7, 188.3, 190.1, 173.3, 191.0, 194.6, 186.2, 185.0, 167.0, 161.0, 169.4, 173.9, 178.4, 186.5, 164.0, 200.0, 198.2, 198.2, 200.0, 193.7, 185.6, 200.0, 197.3, 170.0, 173.9, 171.2, 176.0, 199.1, 200.0, 186.5, 164.0, 195.5, 176.3, 175.7, 197.0, 187.4, 200.0, 188.3, 149.6, 172.1, 200.0, 194.0, 200.0, 186.5, 192.8, 196.4, 200.0], "policy_predator_policy_reward": [0.0, 0.0, 4.0, 4.0, 0.0, 0.0, 3.0, 10.0, 3.0, 7.0, 1.0, 1.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 12.0, 0.0, 11.0, 9.0, 0.0, 10.0, 7.0, 4.0, 2.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 7.0, 7.0, 0.0, 3.0, 7.0, 6.0, 0.0, 0.0, 0.0, 1.0, 3.0, 3.0, 8.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 8.0, 6.0, 0.0, 10.0, 0.0, 0.0, 5.0, 0.0, 0.0, 14.0, 0.0, 0.0, 3.0, 7.0, 0.0, 1.0, 0.0, 0.0, 2.0, 12.0, 0.0, 0.0, 0.0, 5.0, 0.0, 4.0, 7.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 9.0, 12.0, 0.0, 0.0, 0.0, 0.0, 1.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 6.0, 7.0, 7.0, 0.0, 15.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 7.0, 9.0, 0.0, 0.0, 0.0, 0.0, 15.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 4.0, 9.0, 0.0, 3.0, 17.0, 14.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 8.0, 4.0, 0.0, 0.0, 13.0, 0.0, 18.0, 4.0, 5.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 15.0, 0.0, 9.0, 8.0, 0.0, 0.0, 3.0, 12.0, 0.0, 7.0, 6.0, 1.0, 0.0, 0.0, 8.0, 7.0, 0.0, 9.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 11.88178819732759, "mean_inference_ms": 29.09807974619772, "mean_action_processing_ms": 5.774386405590901, "mean_env_wait_ms": 7.203970790631655, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.008295774459838867, "StateBufferConnector_ms": 0.005943894386291504, "ViewRequirementAgentConnector_ms": 0.22986245155334473}, "num_episodes": 18, "episode_return_max": 399.1, "episode_return_min": 333.6, "episode_return_mean": 376.05300000000005, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2416000, "num_agent_steps_trained": 2416000, "num_env_steps_sampled": 604000, "num_env_steps_trained": 604000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 167.42733670296678, "num_env_steps_trained_throughput_per_sec": 167.42733670296678, "timesteps_total": 604000, "num_env_steps_sampled_lifetime": 604000, "num_agent_steps_sampled_lifetime": 2416000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2416000, "timers": {"training_iteration_time_ms": 20704.705, "restore_workers_time_ms": 0.02, "training_step_time_ms": 20704.632, "sample_time_ms": 2754.238, "learn_time_ms": 17914.095, "learn_throughput": 223.288, "synch_weights_time_ms": 31.282}, "counters": {"num_env_steps_sampled": 604000, "num_env_steps_trained": 604000, "num_agent_steps_sampled": 2416000, "num_agent_steps_trained": 2416000}, "done": false, "training_iteration": 151, "trial_id": "75ec3_00000", "date": "2024-08-13_05-42-20", "timestamp": 1723542140, "time_this_iter_s": 23.96558904647827, "time_total_s": 14888.050082445145, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b243f790>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 14888.050082445145, "iterations_since_restore": 151, "perf": {"cpu_util_percent": 86.35882352941178, "ram_util_percent": 83.56176470588235}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7079570793206729, "cur_kl_coeff": 0.08669300638060803, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.37497218887850753, "policy_loss": -0.005641649605179077, "vf_loss": 0.3791614265554392, "vf_explained_var": 0.302448138358101, "kl": 0.01675352688967304, "entropy": 1.239443551043354, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 286335.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.35771821750495486, "cur_kl_coeff": 1.3801910397746818e-27, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.21692335168047558, "policy_loss": -0.0014553879104337837, "vf_loss": 0.21837873922659562, "vf_explained_var": 0.1028162007924741, "kl": 0.02087568564188726, "entropy": 1.1698818107130666, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 286335.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 608000, "num_env_steps_trained": 608000, "num_agent_steps_sampled": 2432000, "num_agent_steps_trained": 2432000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": 317.0, "episode_reward_mean": 375.746, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 143.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 19.0}, "policy_reward_mean": {"prey_policy": 184.94299999999998, "predator_policy": 2.93}, "custom_metrics": {}, "hist_stats": {"episode_reward": [361.40000000000003, 382.0, 373.7, 382.6, 343.5, 395.5, 373.0, 375.0, 370.9, 359.0, 374.7, 392.8, 365.4, 378.7, 362.6, 369.2, 394.2, 358.0, 368.5000000000005, 383.7, 376.5, 395.5, 367.0, 381.1, 386.2, 369.4, 370.0, 378.4, 389.0, 387.5, 393.7, 376.6, 361.0, 367.5, 349.6, 381.2, 373.9, 379.3, 353.2, 359.5, 399.1, 354.1, 390.1, 384.7, 374.4, 396.4, 382.4, 378.5, 363.1, 333.6, 361.2, 379.1, 386.5, 380.20000000000005, 386.5, 378.4, 375.3, 384.8, 365.0, 348.4, 361.3, 362.5, 398.2, 398.2, 379.29999999999995, 397.3, 358.9, 364.2, 399.1, 365.5, 378.8, 379.7, 387.4, 352.9, 381.1, 396.0, 379.3, 396.4, 400.0, 381.1, 393.3, 389.2, 389.2, 365.3, 368.5, 382.0, 364.6, 386.5, 360.4, 365.0, 389.3, 386.8, 392.0, 356.5, 368.0, 384.3, 367.6, 317.0, 393.7, 375.9], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [170.0, 178.4, 186.5, 195.5, 182.6, 190.1, 185.6, 191.0, 160.4, 175.1, 195.5, 200.0, 173.0, 191.0, 167.0, 200.0, 178.39999999999998, 186.5, 176.0, 173.0, 185.0, 184.7, 199.1, 193.7, 166.4, 185.0, 175.7, 200.0, 179.0, 176.6, 183.5, 184.7, 193.1, 199.1, 173.0, 173.0, 175.6999999999999, 192.79999999999995, 200.0, 178.7, 179.0, 186.5, 200.0, 195.5, 185.0, 173.0, 188.3, 192.8, 183.2, 197.0, 171.2, 189.2, 194.0, 164.0, 184.7, 193.7, 195.5, 192.5, 195.5, 188.0, 200.0, 193.7, 191.0, 185.6, 172.7, 179.3, 158.0, 195.5, 179.6, 155.0, 187.1, 190.1, 190.1, 183.8, 186.5, 192.8, 163.4, 171.8, 150.5, 200.0, 199.1, 200.0, 171.8, 167.3, 195.5, 194.6, 200.0, 184.7, 167.0, 196.4, 200.0, 196.4, 200.0, 175.4, 184.4, 190.1, 167.6, 186.5, 152.60000000000002, 161.0, 168.2, 179.0, 191.0, 187.1, 196.4, 190.1, 200.0, 180.2, 192.8, 193.7, 188.3, 190.1, 173.3, 191.0, 194.6, 186.2, 185.0, 167.0, 161.0, 169.4, 173.9, 178.4, 186.5, 164.0, 200.0, 198.2, 198.2, 200.0, 193.7, 185.6, 200.0, 197.3, 170.0, 173.9, 171.2, 176.0, 199.1, 200.0, 186.5, 164.0, 195.5, 176.3, 175.7, 197.0, 187.4, 200.0, 188.3, 149.6, 172.1, 200.0, 194.0, 200.0, 186.5, 192.8, 196.4, 200.0, 200.0, 200.0, 200.0, 181.1, 200.0, 191.3, 193.7, 195.5, 193.7, 195.5, 185.6, 172.7, 162.2, 197.3, 200.0, 182.0, 171.5, 181.1, 191.0, 195.5, 154.4, 191.0, 155.60000000000002, 196.4, 188.0, 197.3, 183.8, 200.0, 188.0, 200.0, 180.2, 161.3, 192.8, 168.2, 188.3, 194.0, 176.6, 191.0, 143.0, 155.0, 193.7, 200.0, 176.0, 191.9], "policy_predator_policy_reward": [7.0, 6.0, 0.0, 0.0, 0.0, 1.0, 3.0, 3.0, 8.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 8.0, 6.0, 0.0, 10.0, 0.0, 0.0, 5.0, 0.0, 0.0, 14.0, 0.0, 0.0, 3.0, 7.0, 0.0, 1.0, 0.0, 0.0, 2.0, 12.0, 0.0, 0.0, 0.0, 5.0, 0.0, 4.0, 7.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 9.0, 12.0, 0.0, 0.0, 0.0, 0.0, 1.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 6.0, 7.0, 7.0, 0.0, 15.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 7.0, 9.0, 0.0, 0.0, 0.0, 0.0, 15.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 4.0, 9.0, 0.0, 3.0, 17.0, 14.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 8.0, 4.0, 0.0, 0.0, 13.0, 0.0, 18.0, 4.0, 5.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 15.0, 0.0, 9.0, 8.0, 0.0, 0.0, 3.0, 12.0, 0.0, 7.0, 6.0, 1.0, 0.0, 0.0, 8.0, 7.0, 0.0, 9.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 9.0, 0.0, 0.0, 7.0, 5.0, 0.0, 0.0, 1.0, 14.0, 0.0, 13.0, 0.0, 4.0, 0.0, 3.0, 4.0, 0.0, 6.0, 9.0, 0.0, 7.0, 0.0, 2.0, 0.0, 0.0, 0.0, 19.0, 0.0, 0.0, 0.0, 8.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 11.798115884671041, "mean_inference_ms": 28.926482907497448, "mean_action_processing_ms": 5.7376853868593, "mean_env_wait_ms": 7.148665830466123, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.008109211921691895, "StateBufferConnector_ms": 0.006199836730957031, "ViewRequirementAgentConnector_ms": 0.2455439567565918}, "num_episodes": 22, "episode_return_max": 400.0, "episode_return_min": 317.0, "episode_return_mean": 375.746, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2432000, "num_agent_steps_trained": 2432000, "num_env_steps_sampled": 608000, "num_env_steps_trained": 608000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 164.39307674677767, "num_env_steps_trained_throughput_per_sec": 164.39307674677767, "timesteps_total": 608000, "num_env_steps_sampled_lifetime": 608000, "num_agent_steps_sampled_lifetime": 2432000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2432000, "timers": {"training_iteration_time_ms": 21337.842, "restore_workers_time_ms": 0.024, "training_step_time_ms": 21337.771, "sample_time_ms": 2836.292, "learn_time_ms": 18468.177, "learn_throughput": 216.589, "synch_weights_time_ms": 28.474}, "counters": {"num_env_steps_sampled": 608000, "num_env_steps_trained": 608000, "num_agent_steps_sampled": 2432000, "num_agent_steps_trained": 2432000}, "done": false, "training_iteration": 152, "trial_id": "75ec3_00000", "date": "2024-08-13_05-42-44", "timestamp": 1723542164, "time_this_iter_s": 24.421417951583862, "time_total_s": 14912.471500396729, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b243fd30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 14912.471500396729, "iterations_since_restore": 152, "perf": {"cpu_util_percent": 85.27714285714285, "ram_util_percent": 83.52}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.299168618078585, "cur_kl_coeff": 0.08669300638060803, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.32003050866945176, "policy_loss": -0.0013391884860567867, "vf_loss": 0.320772959066003, "vf_explained_var": 0.504050820182871, "kl": 0.006883356612806038, "entropy": 1.2473231011597568, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 288225.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.28057126214422246, "cur_kl_coeff": 2.0702865596620238e-27, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.14989515125514968, "policy_loss": -0.0005654098047189927, "vf_loss": 0.15046056064950084, "vf_explained_var": 0.0025643617072433392, "kl": 0.013032999323373857, "entropy": 1.1669552745011749, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 288225.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 612000, "num_env_steps_trained": 612000, "num_agent_steps_sampled": 2448000, "num_agent_steps_trained": 2448000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": 317.0, "episode_reward_mean": 377.19899999999996, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 143.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 19.0}, "policy_reward_mean": {"prey_policy": 185.7245, "predator_policy": 2.875}, "custom_metrics": {}, "hist_stats": {"episode_reward": [368.5000000000005, 383.7, 376.5, 395.5, 367.0, 381.1, 386.2, 369.4, 370.0, 378.4, 389.0, 387.5, 393.7, 376.6, 361.0, 367.5, 349.6, 381.2, 373.9, 379.3, 353.2, 359.5, 399.1, 354.1, 390.1, 384.7, 374.4, 396.4, 382.4, 378.5, 363.1, 333.6, 361.2, 379.1, 386.5, 380.20000000000005, 386.5, 378.4, 375.3, 384.8, 365.0, 348.4, 361.3, 362.5, 398.2, 398.2, 379.29999999999995, 397.3, 358.9, 364.2, 399.1, 365.5, 378.8, 379.7, 387.4, 352.9, 381.1, 396.0, 379.3, 396.4, 400.0, 381.1, 393.3, 389.2, 389.2, 365.3, 368.5, 382.0, 364.6, 386.5, 360.4, 365.0, 389.3, 386.8, 392.0, 356.5, 368.0, 384.3, 367.6, 317.0, 393.7, 375.9, 371.9, 381.3, 359.5, 393.7, 391.9, 358.1, 391.0, 391.0, 395.5, 353.7, 365.4, 394.6, 394.0, 393.7, 372.0, 373.6, 395.5, 381.1], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [175.6999999999999, 192.79999999999995, 200.0, 178.7, 179.0, 186.5, 200.0, 195.5, 185.0, 173.0, 188.3, 192.8, 183.2, 197.0, 171.2, 189.2, 194.0, 164.0, 184.7, 193.7, 195.5, 192.5, 195.5, 188.0, 200.0, 193.7, 191.0, 185.6, 172.7, 179.3, 158.0, 195.5, 179.6, 155.0, 187.1, 190.1, 190.1, 183.8, 186.5, 192.8, 163.4, 171.8, 150.5, 200.0, 199.1, 200.0, 171.8, 167.3, 195.5, 194.6, 200.0, 184.7, 167.0, 196.4, 200.0, 196.4, 200.0, 175.4, 184.4, 190.1, 167.6, 186.5, 152.60000000000002, 161.0, 168.2, 179.0, 191.0, 187.1, 196.4, 190.1, 200.0, 180.2, 192.8, 193.7, 188.3, 190.1, 173.3, 191.0, 194.6, 186.2, 185.0, 167.0, 161.0, 169.4, 173.9, 178.4, 186.5, 164.0, 200.0, 198.2, 198.2, 200.0, 193.7, 185.6, 200.0, 197.3, 170.0, 173.9, 171.2, 176.0, 199.1, 200.0, 186.5, 164.0, 195.5, 176.3, 175.7, 197.0, 187.4, 200.0, 188.3, 149.6, 172.1, 200.0, 194.0, 200.0, 186.5, 192.8, 196.4, 200.0, 200.0, 200.0, 200.0, 181.1, 200.0, 191.3, 193.7, 195.5, 193.7, 195.5, 185.6, 172.7, 162.2, 197.3, 200.0, 182.0, 171.5, 181.1, 191.0, 195.5, 154.4, 191.0, 155.60000000000002, 196.4, 188.0, 197.3, 183.8, 200.0, 188.0, 200.0, 180.2, 161.3, 192.8, 168.2, 188.3, 194.0, 176.6, 191.0, 143.0, 155.0, 193.7, 200.0, 176.0, 191.9, 192.8, 169.1, 197.3, 176.0, 175.1, 166.4, 197.29999999999998, 196.4, 191.9, 200.0, 172.7, 175.4, 197.3, 193.7, 195.5, 195.5, 195.5, 200.0, 185.6, 154.1, 187.4, 167.0, 194.6, 200.0, 191.0, 200.0, 200.0, 193.7, 173.0, 185.0, 179.3, 188.3, 195.5, 200.0, 199.1, 182.0], "policy_predator_policy_reward": [0.0, 0.0, 5.0, 0.0, 4.0, 7.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 9.0, 12.0, 0.0, 0.0, 0.0, 0.0, 1.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 6.0, 7.0, 7.0, 0.0, 15.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 7.0, 9.0, 0.0, 0.0, 0.0, 0.0, 15.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 4.0, 9.0, 0.0, 3.0, 17.0, 14.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 8.0, 4.0, 0.0, 0.0, 13.0, 0.0, 18.0, 4.0, 5.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 15.0, 0.0, 9.0, 8.0, 0.0, 0.0, 3.0, 12.0, 0.0, 7.0, 6.0, 1.0, 0.0, 0.0, 8.0, 7.0, 0.0, 9.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 9.0, 0.0, 0.0, 7.0, 5.0, 0.0, 0.0, 1.0, 14.0, 0.0, 13.0, 0.0, 4.0, 0.0, 3.0, 4.0, 0.0, 6.0, 9.0, 0.0, 7.0, 0.0, 2.0, 0.0, 0.0, 0.0, 19.0, 0.0, 0.0, 0.0, 8.0, 10.0, 0.0, 8.0, 0.0, 8.0, 10.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 2.0, 0.0, 11.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 14.0, 4.0, 2.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 11.736996127814141, "mean_inference_ms": 28.780210270584277, "mean_action_processing_ms": 5.706898901731788, "mean_env_wait_ms": 7.109062211392816, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.02172374725341797, "StateBufferConnector_ms": 0.005768537521362305, "ViewRequirementAgentConnector_ms": 0.2576751708984375}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": 317.0, "episode_return_mean": 377.19899999999996, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2448000, "num_agent_steps_trained": 2448000, "num_env_steps_sampled": 612000, "num_env_steps_trained": 612000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 156.6013912580828, "num_env_steps_trained_throughput_per_sec": 156.6013912580828, "timesteps_total": 612000, "num_env_steps_sampled_lifetime": 612000, "num_agent_steps_sampled_lifetime": 2448000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2448000, "timers": {"training_iteration_time_ms": 22201.562, "restore_workers_time_ms": 0.024, "training_step_time_ms": 22201.489, "sample_time_ms": 3032.76, "learn_time_ms": 19137.016, "learn_throughput": 209.019, "synch_weights_time_ms": 26.317}, "counters": {"num_env_steps_sampled": 612000, "num_env_steps_trained": 612000, "num_agent_steps_sampled": 2448000, "num_agent_steps_trained": 2448000}, "done": false, "training_iteration": 153, "trial_id": "75ec3_00000", "date": "2024-08-13_05-43-10", "timestamp": 1723542190, "time_this_iter_s": 25.633315086364746, "time_total_s": 14938.104815483093, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2568790>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 14938.104815483093, "iterations_since_restore": 153, "perf": {"cpu_util_percent": 86.74999999999999, "ram_util_percent": 83.48333333333332}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.0146790472997558, "cur_kl_coeff": 0.08669300638060803, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.29623314384223215, "policy_loss": -0.0015868604246024338, "vf_loss": 0.297507402443736, "vf_explained_var": 0.409654530867067, "kl": 0.003605850032583775, "entropy": 1.237279852357491, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 290115.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.26706579353305554, "cur_kl_coeff": 2.0702865596620238e-27, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.16286976742484266, "policy_loss": 9.474589701288591e-06, "vf_loss": 0.1628602926079852, "vf_explained_var": 0.0932153931370488, "kl": 0.004380720686564419, "entropy": 1.1565651353704867, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 290115.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 616000, "num_env_steps_trained": 616000, "num_agent_steps_sampled": 2464000, "num_agent_steps_trained": 2464000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": 317.0, "episode_reward_mean": 377.10400000000004, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 143.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 19.0}, "policy_reward_mean": {"prey_policy": 185.612, "predator_policy": 2.94}, "custom_metrics": {}, "hist_stats": {"episode_reward": [373.9, 379.3, 353.2, 359.5, 399.1, 354.1, 390.1, 384.7, 374.4, 396.4, 382.4, 378.5, 363.1, 333.6, 361.2, 379.1, 386.5, 380.20000000000005, 386.5, 378.4, 375.3, 384.8, 365.0, 348.4, 361.3, 362.5, 398.2, 398.2, 379.29999999999995, 397.3, 358.9, 364.2, 399.1, 365.5, 378.8, 379.7, 387.4, 352.9, 381.1, 396.0, 379.3, 396.4, 400.0, 381.1, 393.3, 389.2, 389.2, 365.3, 368.5, 382.0, 364.6, 386.5, 360.4, 365.0, 389.3, 386.8, 392.0, 356.5, 368.0, 384.3, 367.6, 317.0, 393.7, 375.9, 371.9, 381.3, 359.5, 393.7, 391.9, 358.1, 391.0, 391.0, 395.5, 353.7, 365.4, 394.6, 394.0, 393.7, 372.0, 373.6, 395.5, 381.1, 390.40000000000003, 395.5, 382.4, 372.5, 371.0, 379.3, 382.90000000000003, 345.7, 347.6, 364.6, 359.3, 396.0, 400.0, 396.40000000000003, 367.6, 375.90000000000003, 380.3, 365.5], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [190.1, 183.8, 186.5, 192.8, 163.4, 171.8, 150.5, 200.0, 199.1, 200.0, 171.8, 167.3, 195.5, 194.6, 200.0, 184.7, 167.0, 196.4, 200.0, 196.4, 200.0, 175.4, 184.4, 190.1, 167.6, 186.5, 152.60000000000002, 161.0, 168.2, 179.0, 191.0, 187.1, 196.4, 190.1, 200.0, 180.2, 192.8, 193.7, 188.3, 190.1, 173.3, 191.0, 194.6, 186.2, 185.0, 167.0, 161.0, 169.4, 173.9, 178.4, 186.5, 164.0, 200.0, 198.2, 198.2, 200.0, 193.7, 185.6, 200.0, 197.3, 170.0, 173.9, 171.2, 176.0, 199.1, 200.0, 186.5, 164.0, 195.5, 176.3, 175.7, 197.0, 187.4, 200.0, 188.3, 149.6, 172.1, 200.0, 194.0, 200.0, 186.5, 192.8, 196.4, 200.0, 200.0, 200.0, 200.0, 181.1, 200.0, 191.3, 193.7, 195.5, 193.7, 195.5, 185.6, 172.7, 162.2, 197.3, 200.0, 182.0, 171.5, 181.1, 191.0, 195.5, 154.4, 191.0, 155.60000000000002, 196.4, 188.0, 197.3, 183.8, 200.0, 188.0, 200.0, 180.2, 161.3, 192.8, 168.2, 188.3, 194.0, 176.6, 191.0, 143.0, 155.0, 193.7, 200.0, 176.0, 191.9, 192.8, 169.1, 197.3, 176.0, 175.1, 166.4, 197.29999999999998, 196.4, 191.9, 200.0, 172.7, 175.4, 197.3, 193.7, 195.5, 195.5, 195.5, 200.0, 185.6, 154.1, 187.4, 167.0, 194.6, 200.0, 191.0, 200.0, 200.0, 193.7, 173.0, 185.0, 179.3, 188.3, 195.5, 200.0, 199.1, 182.0, 190.1, 197.3, 200.0, 195.5, 175.4, 200.0, 174.5, 185.0, 195.5, 174.5, 189.2, 190.1, 200.0, 182.9, 180.2, 150.5, 156.2, 172.4, 169.4, 180.2, 162.8, 186.5, 200.0, 194.0, 200.0, 200.0, 199.1, 197.3, 188.29999999999998, 170.3, 167.9, 200.0, 188.3, 188.0, 186.5, 173.0], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 0.0, 11.0, 7.0, 9.0, 0.0, 0.0, 0.0, 0.0, 15.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 4.0, 9.0, 0.0, 3.0, 17.0, 14.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 8.0, 4.0, 0.0, 0.0, 13.0, 0.0, 18.0, 4.0, 5.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 15.0, 0.0, 9.0, 8.0, 0.0, 0.0, 3.0, 12.0, 0.0, 7.0, 6.0, 1.0, 0.0, 0.0, 8.0, 7.0, 0.0, 9.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 9.0, 0.0, 0.0, 7.0, 5.0, 0.0, 0.0, 1.0, 14.0, 0.0, 13.0, 0.0, 4.0, 0.0, 3.0, 4.0, 0.0, 6.0, 9.0, 0.0, 7.0, 0.0, 2.0, 0.0, 0.0, 0.0, 19.0, 0.0, 0.0, 0.0, 8.0, 10.0, 0.0, 8.0, 0.0, 8.0, 10.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 2.0, 0.0, 11.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 14.0, 4.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 7.0, 0.0, 12.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 8.0, 7.0, 8.0, 11.0, 0.0, 15.0, 10.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 8.0, 0.0, 4.0, 6.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 11.676713853962918, "mean_inference_ms": 28.636208449482652, "mean_action_processing_ms": 5.676516691585224, "mean_env_wait_ms": 7.069981553147461, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.021041393280029297, "StateBufferConnector_ms": 0.0058133602142333984, "ViewRequirementAgentConnector_ms": 0.2366774082183838}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": 317.0, "episode_return_mean": 377.10400000000004, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2464000, "num_agent_steps_trained": 2464000, "num_env_steps_sampled": 616000, "num_env_steps_trained": 616000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 159.6321434654795, "num_env_steps_trained_throughput_per_sec": 159.6321434654795, "timesteps_total": 616000, "num_env_steps_sampled_lifetime": 616000, "num_agent_steps_sampled_lifetime": 2464000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2464000, "timers": {"training_iteration_time_ms": 22938.441, "restore_workers_time_ms": 0.024, "training_step_time_ms": 22938.368, "sample_time_ms": 3106.486, "learn_time_ms": 19799.847, "learn_throughput": 202.022, "synch_weights_time_ms": 27.259}, "counters": {"num_env_steps_sampled": 616000, "num_env_steps_trained": 616000, "num_agent_steps_sampled": 2464000, "num_agent_steps_trained": 2464000}, "done": false, "training_iteration": 154, "trial_id": "75ec3_00000", "date": "2024-08-13_05-43-35", "timestamp": 1723542215, "time_this_iter_s": 25.132944107055664, "time_total_s": 14963.237759590149, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b243faf0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 14963.237759590149, "iterations_since_restore": 154, "perf": {"cpu_util_percent": 86.85428571428572, "ram_util_percent": 83.64285714285712}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.0096520843408094, "cur_kl_coeff": 0.04334650319030402, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.8736726212261058, "policy_loss": -0.002273263145859043, "vf_loss": 0.8756397351149529, "vf_explained_var": 0.3522260805601796, "kl": 0.007062879936101242, "entropy": 1.253930052184554, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 292005.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.2974778180665992, "cur_kl_coeff": 1.0351432798310119e-27, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.18890284112994632, "policy_loss": -0.0007415552784949935, "vf_loss": 0.18964439611873887, "vf_explained_var": 0.06327620486103037, "kl": 0.029596810857467987, "entropy": 1.1478165370446665, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 292005.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 620000, "num_env_steps_trained": 620000, "num_agent_steps_sampled": 2480000, "num_agent_steps_trained": 2480000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": 317.0, "episode_reward_mean": 377.643, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 143.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 19.0}, "policy_reward_mean": {"prey_policy": 185.9915, "predator_policy": 2.83}, "custom_metrics": {}, "hist_stats": {"episode_reward": [348.4, 361.3, 362.5, 398.2, 398.2, 379.29999999999995, 397.3, 358.9, 364.2, 399.1, 365.5, 378.8, 379.7, 387.4, 352.9, 381.1, 396.0, 379.3, 396.4, 400.0, 381.1, 393.3, 389.2, 389.2, 365.3, 368.5, 382.0, 364.6, 386.5, 360.4, 365.0, 389.3, 386.8, 392.0, 356.5, 368.0, 384.3, 367.6, 317.0, 393.7, 375.9, 371.9, 381.3, 359.5, 393.7, 391.9, 358.1, 391.0, 391.0, 395.5, 353.7, 365.4, 394.6, 394.0, 393.7, 372.0, 373.6, 395.5, 381.1, 390.40000000000003, 395.5, 382.4, 372.5, 371.0, 379.3, 382.90000000000003, 345.7, 347.6, 364.6, 359.3, 396.0, 400.0, 396.40000000000003, 367.6, 375.90000000000003, 380.3, 365.5, 398.2, 377.5, 366.8, 388.3, 373.9, 387.40000000000003, 375.9000000000001, 379.0, 374.1, 366.09999999999997, 367.1, 390.1, 358.0, 370.30000000000024, 378.0, 363.4, 388.3, 391.1, 361.5, 379.3, 381.20000000000005, 380.2, 377.5], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [161.0, 169.4, 173.9, 178.4, 186.5, 164.0, 200.0, 198.2, 198.2, 200.0, 193.7, 185.6, 200.0, 197.3, 170.0, 173.9, 171.2, 176.0, 199.1, 200.0, 186.5, 164.0, 195.5, 176.3, 175.7, 197.0, 187.4, 200.0, 188.3, 149.6, 172.1, 200.0, 194.0, 200.0, 186.5, 192.8, 196.4, 200.0, 200.0, 200.0, 200.0, 181.1, 200.0, 191.3, 193.7, 195.5, 193.7, 195.5, 185.6, 172.7, 162.2, 197.3, 200.0, 182.0, 171.5, 181.1, 191.0, 195.5, 154.4, 191.0, 155.60000000000002, 196.4, 188.0, 197.3, 183.8, 200.0, 188.0, 200.0, 180.2, 161.3, 192.8, 168.2, 188.3, 194.0, 176.6, 191.0, 143.0, 155.0, 193.7, 200.0, 176.0, 191.9, 192.8, 169.1, 197.3, 176.0, 175.1, 166.4, 197.29999999999998, 196.4, 191.9, 200.0, 172.7, 175.4, 197.3, 193.7, 195.5, 195.5, 195.5, 200.0, 185.6, 154.1, 187.4, 167.0, 194.6, 200.0, 191.0, 200.0, 200.0, 193.7, 173.0, 185.0, 179.3, 188.3, 195.5, 200.0, 199.1, 182.0, 190.1, 197.3, 200.0, 195.5, 175.4, 200.0, 174.5, 185.0, 195.5, 174.5, 189.2, 190.1, 200.0, 182.9, 180.2, 150.5, 156.2, 172.4, 169.4, 180.2, 162.8, 186.5, 200.0, 194.0, 200.0, 200.0, 199.1, 197.3, 188.29999999999998, 170.3, 167.9, 200.0, 188.3, 188.0, 186.5, 173.0, 198.2, 200.0, 195.5, 182.0, 177.2, 176.6, 189.2, 199.1, 190.1, 183.8, 198.2, 189.2, 173.29999999999998, 194.6, 191.0, 182.0, 175.1, 191.0, 184.7, 178.4, 181.1, 179.0, 190.1, 200.0, 158.0, 179.0, 192.8, 177.49999999999994, 176.0, 200.0, 189.20000000000002, 162.2, 194.59999999999997, 193.7, 200.0, 187.1, 174.5, 170.0, 182.0, 188.29999999999998, 178.1, 199.1, 198.2, 182.0, 191.9, 185.6], "policy_predator_policy_reward": [0.0, 18.0, 4.0, 5.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 15.0, 0.0, 9.0, 8.0, 0.0, 0.0, 3.0, 12.0, 0.0, 7.0, 6.0, 1.0, 0.0, 0.0, 8.0, 7.0, 0.0, 9.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 9.0, 0.0, 0.0, 7.0, 5.0, 0.0, 0.0, 1.0, 14.0, 0.0, 13.0, 0.0, 4.0, 0.0, 3.0, 4.0, 0.0, 6.0, 9.0, 0.0, 7.0, 0.0, 2.0, 0.0, 0.0, 0.0, 19.0, 0.0, 0.0, 0.0, 8.0, 10.0, 0.0, 8.0, 0.0, 8.0, 10.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 2.0, 0.0, 11.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 14.0, 4.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 7.0, 0.0, 12.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 8.0, 7.0, 8.0, 11.0, 0.0, 15.0, 10.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 8.0, 0.0, 4.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 6.0, 0.0, 0.0, 8.0, 0.0, 3.0, 0.0, 7.0, 0.0, 0.0, 9.0, 12.0, 0.0, 0.0, 0.0, 2.0, 12.0, 0.0, 0.0, 0.0, 4.0, 0.0, 10.0, 7.0, 0.0, 9.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 11.607933319485541, "mean_inference_ms": 28.442806535840035, "mean_action_processing_ms": 5.637035380888839, "mean_env_wait_ms": 7.026720476796436, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.02306663990020752, "StateBufferConnector_ms": 0.006207704544067383, "ViewRequirementAgentConnector_ms": 0.2595452070236206}, "num_episodes": 23, "episode_return_max": 400.0, "episode_return_min": 317.0, "episode_return_mean": 377.643, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2480000, "num_agent_steps_trained": 2480000, "num_env_steps_sampled": 620000, "num_env_steps_trained": 620000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 168.26481076089004, "num_env_steps_trained_throughput_per_sec": 168.26481076089004, "timesteps_total": 620000, "num_env_steps_sampled_lifetime": 620000, "num_agent_steps_sampled_lifetime": 2480000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2480000, "timers": {"training_iteration_time_ms": 23474.836, "restore_workers_time_ms": 0.024, "training_step_time_ms": 23474.762, "sample_time_ms": 3182.528, "learn_time_ms": 20259.782, "learn_throughput": 197.435, "synch_weights_time_ms": 27.846}, "counters": {"num_env_steps_sampled": 620000, "num_env_steps_trained": 620000, "num_agent_steps_sampled": 2480000, "num_agent_steps_trained": 2480000}, "done": false, "training_iteration": 155, "trial_id": "75ec3_00000", "date": "2024-08-13_05-43-59", "timestamp": 1723542239, "time_this_iter_s": 23.829236030578613, "time_total_s": 14987.066995620728, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b23f0430>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 14987.066995620728, "iterations_since_restore": 155, "perf": {"cpu_util_percent": 84.62058823529412, "ram_util_percent": 83.23529411764706}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9188906427807908, "cur_kl_coeff": 0.04334650319030402, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.5109788600788402, "policy_loss": -0.0033148933578992174, "vf_loss": 0.5137614152024663, "vf_explained_var": 0.262818811778669, "kl": 0.012280990727889745, "entropy": 1.2784723097685153, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 293895.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.26476800743017403, "cur_kl_coeff": 1.5527149197465171e-27, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.20081052862541385, "policy_loss": -0.0005183854976806928, "vf_loss": 0.20132891395446173, "vf_explained_var": 0.0413432224402352, "kl": 0.01790936686449084, "entropy": 1.175900173376477, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 293895.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 624000, "num_env_steps_trained": 624000, "num_agent_steps_sampled": 2496000, "num_agent_steps_trained": 2496000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": 317.0, "episode_reward_mean": 376.57, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 143.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 19.0}, "policy_reward_mean": {"prey_policy": 185.27, "predator_policy": 3.015}, "custom_metrics": {}, "hist_stats": {"episode_reward": [389.2, 389.2, 365.3, 368.5, 382.0, 364.6, 386.5, 360.4, 365.0, 389.3, 386.8, 392.0, 356.5, 368.0, 384.3, 367.6, 317.0, 393.7, 375.9, 371.9, 381.3, 359.5, 393.7, 391.9, 358.1, 391.0, 391.0, 395.5, 353.7, 365.4, 394.6, 394.0, 393.7, 372.0, 373.6, 395.5, 381.1, 390.40000000000003, 395.5, 382.4, 372.5, 371.0, 379.3, 382.90000000000003, 345.7, 347.6, 364.6, 359.3, 396.0, 400.0, 396.40000000000003, 367.6, 375.90000000000003, 380.3, 365.5, 398.2, 377.5, 366.8, 388.3, 373.9, 387.40000000000003, 375.9000000000001, 379.0, 374.1, 366.09999999999997, 367.1, 390.1, 358.0, 370.30000000000024, 378.0, 363.4, 388.3, 391.1, 361.5, 379.3, 381.20000000000005, 380.2, 377.5, 365.4, 396.2, 353.2, 389.7, 370.1, 379.3, 375.1, 360.3, 387.4, 383.9, 376.5, 389.20000000000005, 341.1, 361.2, 372.9, 390.1, 394.6, 362.8, 357.7, 363.8, 382.00000000000006, 399.1], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [193.7, 195.5, 193.7, 195.5, 185.6, 172.7, 162.2, 197.3, 200.0, 182.0, 171.5, 181.1, 191.0, 195.5, 154.4, 191.0, 155.60000000000002, 196.4, 188.0, 197.3, 183.8, 200.0, 188.0, 200.0, 180.2, 161.3, 192.8, 168.2, 188.3, 194.0, 176.6, 191.0, 143.0, 155.0, 193.7, 200.0, 176.0, 191.9, 192.8, 169.1, 197.3, 176.0, 175.1, 166.4, 197.29999999999998, 196.4, 191.9, 200.0, 172.7, 175.4, 197.3, 193.7, 195.5, 195.5, 195.5, 200.0, 185.6, 154.1, 187.4, 167.0, 194.6, 200.0, 191.0, 200.0, 200.0, 193.7, 173.0, 185.0, 179.3, 188.3, 195.5, 200.0, 199.1, 182.0, 190.1, 197.3, 200.0, 195.5, 175.4, 200.0, 174.5, 185.0, 195.5, 174.5, 189.2, 190.1, 200.0, 182.9, 180.2, 150.5, 156.2, 172.4, 169.4, 180.2, 162.8, 186.5, 200.0, 194.0, 200.0, 200.0, 199.1, 197.3, 188.29999999999998, 170.3, 167.9, 200.0, 188.3, 188.0, 186.5, 173.0, 198.2, 200.0, 195.5, 182.0, 177.2, 176.6, 189.2, 199.1, 190.1, 183.8, 198.2, 189.2, 173.29999999999998, 194.6, 191.0, 182.0, 175.1, 191.0, 184.7, 178.4, 181.1, 179.0, 190.1, 200.0, 158.0, 179.0, 192.8, 177.49999999999994, 176.0, 200.0, 189.20000000000002, 162.2, 194.59999999999997, 193.7, 200.0, 187.1, 174.5, 170.0, 182.0, 188.29999999999998, 178.1, 199.1, 198.2, 182.0, 191.9, 185.6, 165.2, 189.2, 197.0, 198.2, 173.0, 162.2, 188.6, 199.1, 188.0, 172.1, 170.3, 200.0, 191.0, 181.1, 173.0, 173.3, 195.5, 191.9, 188.0, 191.9, 176.0, 195.5, 191.9, 197.29999999999998, 160.4, 169.7, 170.0, 174.2, 170.0, 173.9, 199.1, 191.0, 197.3, 197.3, 180.2, 176.6, 173.3, 169.39999999999998, 183.8, 170.0, 187.4, 194.59999999999997, 200.0, 199.1], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 9.0, 0.0, 0.0, 7.0, 5.0, 0.0, 0.0, 1.0, 14.0, 0.0, 13.0, 0.0, 4.0, 0.0, 3.0, 4.0, 0.0, 6.0, 9.0, 0.0, 7.0, 0.0, 2.0, 0.0, 0.0, 0.0, 19.0, 0.0, 0.0, 0.0, 8.0, 10.0, 0.0, 8.0, 0.0, 8.0, 10.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 2.0, 0.0, 11.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 14.0, 4.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 7.0, 0.0, 12.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 8.0, 7.0, 8.0, 11.0, 0.0, 15.0, 10.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 8.0, 0.0, 4.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 6.0, 0.0, 0.0, 8.0, 0.0, 3.0, 0.0, 7.0, 0.0, 0.0, 9.0, 12.0, 0.0, 0.0, 0.0, 2.0, 12.0, 0.0, 0.0, 0.0, 4.0, 0.0, 10.0, 7.0, 0.0, 9.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 1.0, 18.0, 0.0, 0.0, 2.0, 0.0, 10.0, 9.0, 0.0, 3.0, 0.0, 8.0, 6.0, 0.0, 0.0, 4.0, 0.0, 0.0, 5.0, 0.0, 0.0, 11.0, 0.0, 8.0, 9.0, 14.0, 15.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 7.0, 8.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 11.975570931034548, "mean_inference_ms": 27.83424824438777, "mean_action_processing_ms": 5.6104337166139, "mean_env_wait_ms": 6.8458847045336, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.023637890815734863, "StateBufferConnector_ms": 0.006196260452270508, "ViewRequirementAgentConnector_ms": 0.2594207525253296}, "num_episodes": 22, "episode_return_max": 400.0, "episode_return_min": 317.0, "episode_return_mean": 376.57, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2496000, "num_agent_steps_trained": 2496000, "num_env_steps_sampled": 624000, "num_env_steps_trained": 624000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 159.7044334215715, "num_env_steps_trained_throughput_per_sec": 159.7044334215715, "timesteps_total": 624000, "num_env_steps_sampled_lifetime": 624000, "num_agent_steps_sampled_lifetime": 2496000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2496000, "timers": {"training_iteration_time_ms": 24071.529, "restore_workers_time_ms": 0.024, "training_step_time_ms": 24071.418, "sample_time_ms": 3252.501, "learn_time_ms": 20784.824, "learn_throughput": 192.448, "synch_weights_time_ms": 28.474}, "counters": {"num_env_steps_sampled": 624000, "num_env_steps_trained": 624000, "num_agent_steps_sampled": 2496000, "num_agent_steps_trained": 2496000}, "done": false, "training_iteration": 156, "trial_id": "75ec3_00000", "date": "2024-08-13_05-44-24", "timestamp": 1723542264, "time_this_iter_s": 25.091031789779663, "time_total_s": 15012.158027410507, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2568430>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 15012.158027410507, "iterations_since_restore": 156, "perf": {"cpu_util_percent": 84.7542857142857, "ram_util_percent": 83.42571428571428}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9286849500483305, "cur_kl_coeff": 0.04334650319030402, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.5374215625842452, "policy_loss": -0.0038982892539549284, "vf_loss": 0.5406599582857872, "vf_explained_var": 0.2725144199277989, "kl": 0.015223698014504163, "entropy": 1.2601499733470736, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 295785.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.28768823859749965, "cur_kl_coeff": 1.5527149197465171e-27, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.15396402306342252, "policy_loss": -0.0005084839287317461, "vf_loss": 0.15447250732272141, "vf_explained_var": 0.27401867259747137, "kl": 0.0196858570254139, "entropy": 1.2609216657265154, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 295785.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 628000, "num_env_steps_trained": 628000, "num_agent_steps_sampled": 2512000, "num_agent_steps_trained": 2512000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": 341.1, "episode_reward_mean": 377.08700000000005, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 150.5, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 18.0}, "policy_reward_mean": {"prey_policy": 185.5385, "predator_policy": 3.005}, "custom_metrics": {}, "hist_stats": {"episode_reward": [375.9, 371.9, 381.3, 359.5, 393.7, 391.9, 358.1, 391.0, 391.0, 395.5, 353.7, 365.4, 394.6, 394.0, 393.7, 372.0, 373.6, 395.5, 381.1, 390.40000000000003, 395.5, 382.4, 372.5, 371.0, 379.3, 382.90000000000003, 345.7, 347.6, 364.6, 359.3, 396.0, 400.0, 396.40000000000003, 367.6, 375.90000000000003, 380.3, 365.5, 398.2, 377.5, 366.8, 388.3, 373.9, 387.40000000000003, 375.9000000000001, 379.0, 374.1, 366.09999999999997, 367.1, 390.1, 358.0, 370.30000000000024, 378.0, 363.4, 388.3, 391.1, 361.5, 379.3, 381.20000000000005, 380.2, 377.5, 365.4, 396.2, 353.2, 389.7, 370.1, 379.3, 375.1, 360.3, 387.4, 383.9, 376.5, 389.20000000000005, 341.1, 361.2, 372.9, 390.1, 394.6, 362.8, 357.7, 363.8, 382.00000000000006, 399.1, 365.90000000000003, 385.6, 380.5, 354.8, 391.9, 392.8, 380.1, 387.4, 389.2, 347.7, 368.6, 355.7, 370.7, 400.0, 373.5, 366.8, 392.8, 373.59999999999997], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [176.0, 191.9, 192.8, 169.1, 197.3, 176.0, 175.1, 166.4, 197.29999999999998, 196.4, 191.9, 200.0, 172.7, 175.4, 197.3, 193.7, 195.5, 195.5, 195.5, 200.0, 185.6, 154.1, 187.4, 167.0, 194.6, 200.0, 191.0, 200.0, 200.0, 193.7, 173.0, 185.0, 179.3, 188.3, 195.5, 200.0, 199.1, 182.0, 190.1, 197.3, 200.0, 195.5, 175.4, 200.0, 174.5, 185.0, 195.5, 174.5, 189.2, 190.1, 200.0, 182.9, 180.2, 150.5, 156.2, 172.4, 169.4, 180.2, 162.8, 186.5, 200.0, 194.0, 200.0, 200.0, 199.1, 197.3, 188.29999999999998, 170.3, 167.9, 200.0, 188.3, 188.0, 186.5, 173.0, 198.2, 200.0, 195.5, 182.0, 177.2, 176.6, 189.2, 199.1, 190.1, 183.8, 198.2, 189.2, 173.29999999999998, 194.6, 191.0, 182.0, 175.1, 191.0, 184.7, 178.4, 181.1, 179.0, 190.1, 200.0, 158.0, 179.0, 192.8, 177.49999999999994, 176.0, 200.0, 189.20000000000002, 162.2, 194.59999999999997, 193.7, 200.0, 187.1, 174.5, 170.0, 182.0, 188.29999999999998, 178.1, 199.1, 198.2, 182.0, 191.9, 185.6, 165.2, 189.2, 197.0, 198.2, 173.0, 162.2, 188.6, 199.1, 188.0, 172.1, 170.3, 200.0, 191.0, 181.1, 173.0, 173.3, 195.5, 191.9, 188.0, 191.9, 176.0, 195.5, 191.9, 197.29999999999998, 160.4, 169.7, 170.0, 174.2, 170.0, 173.9, 199.1, 191.0, 197.3, 197.3, 180.2, 176.6, 173.3, 169.39999999999998, 183.8, 170.0, 187.4, 194.59999999999997, 200.0, 199.1, 166.1, 186.8, 200.0, 185.6, 188.29999999999998, 189.2, 159.8, 182.0, 198.2, 193.7, 200.0, 192.8, 193.7, 181.4, 200.0, 187.4, 190.1, 199.1, 153.5, 177.2, 169.1, 195.5, 169.7, 173.0, 170.9, 192.8, 200.0, 200.0, 195.5, 164.0, 164.3, 189.5, 200.0, 192.8, 177.5, 190.1], "policy_predator_policy_reward": [0.0, 8.0, 10.0, 0.0, 8.0, 0.0, 8.0, 10.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 2.0, 0.0, 11.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 14.0, 4.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 7.0, 0.0, 12.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 8.0, 7.0, 8.0, 11.0, 0.0, 15.0, 10.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 8.0, 0.0, 4.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 6.0, 0.0, 0.0, 8.0, 0.0, 3.0, 0.0, 7.0, 0.0, 0.0, 9.0, 12.0, 0.0, 0.0, 0.0, 2.0, 12.0, 0.0, 0.0, 0.0, 4.0, 0.0, 10.0, 7.0, 0.0, 9.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 1.0, 18.0, 0.0, 0.0, 2.0, 0.0, 10.0, 9.0, 0.0, 3.0, 0.0, 8.0, 6.0, 0.0, 0.0, 4.0, 0.0, 0.0, 5.0, 0.0, 0.0, 11.0, 0.0, 8.0, 9.0, 14.0, 15.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 7.0, 8.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 3.0, 0.0, 6.0, 7.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 7.0, 4.0, 0.0, 2.0, 11.0, 7.0, 0.0, 0.0, 0.0, 5.0, 9.0, 4.0, 9.0, 0.0, 0.0, 0.0, 6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 11.475927359948622, "mean_inference_ms": 28.149223132907167, "mean_action_processing_ms": 5.574539121748827, "mean_env_wait_ms": 6.940085188306637, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.023495793342590332, "StateBufferConnector_ms": 0.0061942338943481445, "ViewRequirementAgentConnector_ms": 0.25290608406066895}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": 341.1, "episode_return_mean": 377.08700000000005, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2512000, "num_agent_steps_trained": 2512000, "num_env_steps_sampled": 628000, "num_env_steps_trained": 628000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 167.38205770249797, "num_env_steps_trained_throughput_per_sec": 167.38205770249797, "timesteps_total": 628000, "num_env_steps_sampled_lifetime": 628000, "num_agent_steps_sampled_lifetime": 2512000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2512000, "timers": {"training_iteration_time_ms": 23734.422, "restore_workers_time_ms": 0.024, "training_step_time_ms": 23734.31, "sample_time_ms": 3314.054, "learn_time_ms": 20384.396, "learn_throughput": 196.229, "synch_weights_time_ms": 29.023}, "counters": {"num_env_steps_sampled": 628000, "num_env_steps_trained": 628000, "num_agent_steps_sampled": 2512000, "num_agent_steps_trained": 2512000}, "done": false, "training_iteration": 157, "trial_id": "75ec3_00000", "date": "2024-08-13_05-44-48", "timestamp": 1723542288, "time_this_iter_s": 24.01881217956543, "time_total_s": 15036.176839590073, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2495700>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 15036.176839590073, "iterations_since_restore": 157, "perf": {"cpu_util_percent": 84.38235294117646, "ram_util_percent": 83.43235294117646}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7951238754880492, "cur_kl_coeff": 0.04334650319030402, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.2449646436488601, "policy_loss": -0.0020979430832008205, "vf_loss": 0.24658757609403914, "vf_explained_var": 0.3535875262722136, "kl": 0.010958449318583691, "entropy": 1.3020848859554877, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 297675.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.41889474365130935, "cur_kl_coeff": 1.5527149197465171e-27, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.11233148245047285, "policy_loss": -0.0009134705852293385, "vf_loss": 0.11324495269914488, "vf_explained_var": 0.4183067112057297, "kl": 0.017588302054442867, "entropy": 1.212492545256539, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 297675.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 632000, "num_env_steps_trained": 632000, "num_agent_steps_sampled": 2528000, "num_agent_steps_trained": 2528000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": 341.1, "episode_reward_mean": 377.2900000000001, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 150.5, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 18.0}, "policy_reward_mean": {"prey_policy": 185.795, "predator_policy": 2.85}, "custom_metrics": {}, "hist_stats": {"episode_reward": [381.1, 390.40000000000003, 395.5, 382.4, 372.5, 371.0, 379.3, 382.90000000000003, 345.7, 347.6, 364.6, 359.3, 396.0, 400.0, 396.40000000000003, 367.6, 375.90000000000003, 380.3, 365.5, 398.2, 377.5, 366.8, 388.3, 373.9, 387.40000000000003, 375.9000000000001, 379.0, 374.1, 366.09999999999997, 367.1, 390.1, 358.0, 370.30000000000024, 378.0, 363.4, 388.3, 391.1, 361.5, 379.3, 381.20000000000005, 380.2, 377.5, 365.4, 396.2, 353.2, 389.7, 370.1, 379.3, 375.1, 360.3, 387.4, 383.9, 376.5, 389.20000000000005, 341.1, 361.2, 372.9, 390.1, 394.6, 362.8, 357.7, 363.8, 382.00000000000006, 399.1, 365.90000000000003, 385.6, 380.5, 354.8, 391.9, 392.8, 380.1, 387.4, 389.2, 347.7, 368.6, 355.7, 370.7, 400.0, 373.5, 366.8, 392.8, 373.59999999999997, 386.8, 382.0, 380.2, 386.2, 393.1, 391.5, 388.3, 371.3, 389.3, 373.4, 362.5, 377.6, 384.69999999999993, 389.2, 364.0, 396.4, 381.8, 374.29999999999995], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [199.1, 182.0, 190.1, 197.3, 200.0, 195.5, 175.4, 200.0, 174.5, 185.0, 195.5, 174.5, 189.2, 190.1, 200.0, 182.9, 180.2, 150.5, 156.2, 172.4, 169.4, 180.2, 162.8, 186.5, 200.0, 194.0, 200.0, 200.0, 199.1, 197.3, 188.29999999999998, 170.3, 167.9, 200.0, 188.3, 188.0, 186.5, 173.0, 198.2, 200.0, 195.5, 182.0, 177.2, 176.6, 189.2, 199.1, 190.1, 183.8, 198.2, 189.2, 173.29999999999998, 194.6, 191.0, 182.0, 175.1, 191.0, 184.7, 178.4, 181.1, 179.0, 190.1, 200.0, 158.0, 179.0, 192.8, 177.49999999999994, 176.0, 200.0, 189.20000000000002, 162.2, 194.59999999999997, 193.7, 200.0, 187.1, 174.5, 170.0, 182.0, 188.29999999999998, 178.1, 199.1, 198.2, 182.0, 191.9, 185.6, 165.2, 189.2, 197.0, 198.2, 173.0, 162.2, 188.6, 199.1, 188.0, 172.1, 170.3, 200.0, 191.0, 181.1, 173.0, 173.3, 195.5, 191.9, 188.0, 191.9, 176.0, 195.5, 191.9, 197.29999999999998, 160.4, 169.7, 170.0, 174.2, 170.0, 173.9, 199.1, 191.0, 197.3, 197.3, 180.2, 176.6, 173.3, 169.39999999999998, 183.8, 170.0, 187.4, 194.59999999999997, 200.0, 199.1, 166.1, 186.8, 200.0, 185.6, 188.29999999999998, 189.2, 159.8, 182.0, 198.2, 193.7, 200.0, 192.8, 193.7, 181.4, 200.0, 187.4, 190.1, 199.1, 153.5, 177.2, 169.1, 195.5, 169.7, 173.0, 170.9, 192.8, 200.0, 200.0, 195.5, 164.0, 164.3, 189.5, 200.0, 192.8, 177.5, 190.1, 192.8, 191.0, 200.0, 173.0, 198.2, 173.0, 180.2, 200.0, 200.0, 190.1, 191.3, 198.2, 197.3, 191.0, 185.6, 181.7, 199.1, 186.2, 177.2, 189.2, 162.2, 188.3, 194.6, 179.0, 184.69999999999996, 200.0, 199.1, 190.1, 173.0, 191.0, 200.0, 196.4, 197.0, 183.8, 190.1, 177.2], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 7.0, 0.0, 12.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 8.0, 7.0, 8.0, 11.0, 0.0, 15.0, 10.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 8.0, 0.0, 4.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 6.0, 0.0, 0.0, 8.0, 0.0, 3.0, 0.0, 7.0, 0.0, 0.0, 9.0, 12.0, 0.0, 0.0, 0.0, 2.0, 12.0, 0.0, 0.0, 0.0, 4.0, 0.0, 10.0, 7.0, 0.0, 9.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 1.0, 18.0, 0.0, 0.0, 2.0, 0.0, 10.0, 9.0, 0.0, 3.0, 0.0, 8.0, 6.0, 0.0, 0.0, 4.0, 0.0, 0.0, 5.0, 0.0, 0.0, 11.0, 0.0, 8.0, 9.0, 14.0, 15.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 7.0, 8.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 3.0, 0.0, 6.0, 7.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 7.0, 4.0, 0.0, 2.0, 11.0, 7.0, 0.0, 0.0, 0.0, 5.0, 9.0, 4.0, 9.0, 0.0, 0.0, 0.0, 6.0, 3.0, 0.0, 0.0, 9.0, 3.0, 6.0, 6.0, 0.0, 3.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 4.0, 0.0, 7.0, 6.0, 6.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 7.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 11.417414542766, "mean_inference_ms": 28.009019731472986, "mean_action_processing_ms": 5.545353894240411, "mean_env_wait_ms": 6.902534037907547, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.027103424072265625, "StateBufferConnector_ms": 0.00625455379486084, "ViewRequirementAgentConnector_ms": 0.24816691875457764}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": 341.1, "episode_return_mean": 377.2900000000001, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2528000, "num_agent_steps_trained": 2528000, "num_env_steps_sampled": 632000, "num_env_steps_trained": 632000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 165.5527237636256, "num_env_steps_trained_throughput_per_sec": 165.5527237636256, "timesteps_total": 632000, "num_env_steps_sampled_lifetime": 632000, "num_agent_steps_sampled_lifetime": 2528000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2528000, "timers": {"training_iteration_time_ms": 24065.597, "restore_workers_time_ms": 0.024, "training_step_time_ms": 24065.489, "sample_time_ms": 3336.176, "learn_time_ms": 20694.013, "learn_throughput": 193.293, "synch_weights_time_ms": 28.805}, "counters": {"num_env_steps_sampled": 632000, "num_env_steps_trained": 632000, "num_agent_steps_sampled": 2528000, "num_agent_steps_trained": 2528000}, "done": false, "training_iteration": 158, "trial_id": "75ec3_00000", "date": "2024-08-13_05-45-13", "timestamp": 1723542313, "time_this_iter_s": 24.223583936691284, "time_total_s": 15060.400423526764, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2497ee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 15060.400423526764, "iterations_since_restore": 158, "perf": {"cpu_util_percent": 85.32647058823531, "ram_util_percent": 83.33823529411765}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6792769949272197, "cur_kl_coeff": 0.04334650319030402, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.3403150645098076, "policy_loss": -0.0012435155796261612, "vf_loss": 0.34120556203594243, "vf_explained_var": 0.3373482101178043, "kl": 0.008144094140676008, "entropy": 1.2898003591431513, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 299565.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6307477397913183, "cur_kl_coeff": 1.5527149197465171e-27, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.22903615960545798, "policy_loss": -0.0006722768933743869, "vf_loss": 0.2297084367439821, "vf_explained_var": 0.19575218394319846, "kl": 0.009620680339247088, "entropy": 1.2005184384250136, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 299565.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 636000, "num_env_steps_trained": 636000, "num_agent_steps_sampled": 2544000, "num_agent_steps_trained": 2544000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": 341.1, "episode_reward_mean": 377.6549999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 146.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 18.0}, "policy_reward_mean": {"prey_policy": 185.9825, "predator_policy": 2.845}, "custom_metrics": {}, "hist_stats": {"episode_reward": [365.5, 398.2, 377.5, 366.8, 388.3, 373.9, 387.40000000000003, 375.9000000000001, 379.0, 374.1, 366.09999999999997, 367.1, 390.1, 358.0, 370.30000000000024, 378.0, 363.4, 388.3, 391.1, 361.5, 379.3, 381.20000000000005, 380.2, 377.5, 365.4, 396.2, 353.2, 389.7, 370.1, 379.3, 375.1, 360.3, 387.4, 383.9, 376.5, 389.20000000000005, 341.1, 361.2, 372.9, 390.1, 394.6, 362.8, 357.7, 363.8, 382.00000000000006, 399.1, 365.90000000000003, 385.6, 380.5, 354.8, 391.9, 392.8, 380.1, 387.4, 389.2, 347.7, 368.6, 355.7, 370.7, 400.0, 373.5, 366.8, 392.8, 373.59999999999997, 386.8, 382.0, 380.2, 386.2, 393.1, 391.5, 388.3, 371.3, 389.3, 373.4, 362.5, 377.6, 384.69999999999993, 389.2, 364.0, 396.4, 381.8, 374.29999999999995, 392.8, 374.8, 373.6, 377.9, 386.5, 377.4, 370.3, 388.29999999999995, 367.0, 383.2, 386.2, 368.1, 393.7, 363.1, 365.7, 374.6, 389.2, 392.6], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [186.5, 173.0, 198.2, 200.0, 195.5, 182.0, 177.2, 176.6, 189.2, 199.1, 190.1, 183.8, 198.2, 189.2, 173.29999999999998, 194.6, 191.0, 182.0, 175.1, 191.0, 184.7, 178.4, 181.1, 179.0, 190.1, 200.0, 158.0, 179.0, 192.8, 177.49999999999994, 176.0, 200.0, 189.20000000000002, 162.2, 194.59999999999997, 193.7, 200.0, 187.1, 174.5, 170.0, 182.0, 188.29999999999998, 178.1, 199.1, 198.2, 182.0, 191.9, 185.6, 165.2, 189.2, 197.0, 198.2, 173.0, 162.2, 188.6, 199.1, 188.0, 172.1, 170.3, 200.0, 191.0, 181.1, 173.0, 173.3, 195.5, 191.9, 188.0, 191.9, 176.0, 195.5, 191.9, 197.29999999999998, 160.4, 169.7, 170.0, 174.2, 170.0, 173.9, 199.1, 191.0, 197.3, 197.3, 180.2, 176.6, 173.3, 169.39999999999998, 183.8, 170.0, 187.4, 194.59999999999997, 200.0, 199.1, 166.1, 186.8, 200.0, 185.6, 188.29999999999998, 189.2, 159.8, 182.0, 198.2, 193.7, 200.0, 192.8, 193.7, 181.4, 200.0, 187.4, 190.1, 199.1, 153.5, 177.2, 169.1, 195.5, 169.7, 173.0, 170.9, 192.8, 200.0, 200.0, 195.5, 164.0, 164.3, 189.5, 200.0, 192.8, 177.5, 190.1, 192.8, 191.0, 200.0, 173.0, 198.2, 173.0, 180.2, 200.0, 200.0, 190.1, 191.3, 198.2, 197.3, 191.0, 185.6, 181.7, 199.1, 186.2, 177.2, 189.2, 162.2, 188.3, 194.6, 179.0, 184.69999999999996, 200.0, 199.1, 190.1, 173.0, 191.0, 200.0, 196.4, 197.0, 183.8, 190.1, 177.2, 200.0, 192.8, 183.8, 191.0, 178.4, 189.2, 193.7, 177.2, 200.0, 186.5, 172.4, 197.0, 182.3, 179.0, 188.3, 200.0, 191.0, 164.0, 189.2, 191.0, 180.2, 200.0, 182.0, 175.1, 200.0, 193.7, 146.0, 199.1, 177.2, 174.5, 169.1, 195.5, 191.9, 197.3, 191.6, 200.0], "policy_predator_policy_reward": [6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 6.0, 0.0, 0.0, 8.0, 0.0, 3.0, 0.0, 7.0, 0.0, 0.0, 9.0, 12.0, 0.0, 0.0, 0.0, 2.0, 12.0, 0.0, 0.0, 0.0, 4.0, 0.0, 10.0, 7.0, 0.0, 9.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 1.0, 18.0, 0.0, 0.0, 2.0, 0.0, 10.0, 9.0, 0.0, 3.0, 0.0, 8.0, 6.0, 0.0, 0.0, 4.0, 0.0, 0.0, 5.0, 0.0, 0.0, 11.0, 0.0, 8.0, 9.0, 14.0, 15.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 7.0, 8.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 3.0, 0.0, 6.0, 7.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 7.0, 4.0, 0.0, 2.0, 11.0, 7.0, 0.0, 0.0, 0.0, 5.0, 9.0, 4.0, 9.0, 0.0, 0.0, 0.0, 6.0, 3.0, 0.0, 0.0, 9.0, 3.0, 6.0, 6.0, 0.0, 3.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 4.0, 0.0, 7.0, 6.0, 6.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 8.0, 9.0, 0.0, 0.0, 0.0, 0.0, 12.0, 3.0, 0.0, 6.0, 0.0, 8.0, 3.0, 0.0, 0.0, 0.0, 18.0, 7.0, 7.0, 6.0, 4.0, 0.0, 0.0, 0.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 11.359698890368822, "mean_inference_ms": 27.870608042974172, "mean_action_processing_ms": 5.516513879469264, "mean_env_wait_ms": 6.865507755789289, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01858234405517578, "StateBufferConnector_ms": 0.006483316421508789, "ViewRequirementAgentConnector_ms": 0.25653016567230225}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": 341.1, "episode_return_mean": 377.6549999999999, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2544000, "num_agent_steps_trained": 2544000, "num_env_steps_sampled": 636000, "num_env_steps_trained": 636000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 160.91819235249517, "num_env_steps_trained_throughput_per_sec": 160.91819235249517, "timesteps_total": 636000, "num_env_steps_sampled_lifetime": 636000, "num_agent_steps_sampled_lifetime": 2544000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2544000, "timers": {"training_iteration_time_ms": 24316.536, "restore_workers_time_ms": 0.024, "training_step_time_ms": 24316.428, "sample_time_ms": 3360.638, "learn_time_ms": 20920.239, "learn_throughput": 191.202, "synch_weights_time_ms": 29.125}, "counters": {"num_env_steps_sampled": 636000, "num_env_steps_trained": 636000, "num_agent_steps_sampled": 2544000, "num_agent_steps_trained": 2544000}, "done": false, "training_iteration": 159, "trial_id": "75ec3_00000", "date": "2024-08-13_05-45-38", "timestamp": 1723542338, "time_this_iter_s": 24.911850929260254, "time_total_s": 15085.312274456024, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b24970d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 15085.312274456024, "iterations_since_restore": 159, "perf": {"cpu_util_percent": 84.57714285714286, "ram_util_percent": 83.27428571428572}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.0364656041538907, "cur_kl_coeff": 0.04334650319030402, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.4851015433126435, "policy_loss": -0.0052532498214748645, "vf_loss": 0.489690626242134, "vf_explained_var": 0.43125611023297383, "kl": 0.0153222494668077, "entropy": 1.2492449892891777, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 301455.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5223903318876942, "cur_kl_coeff": 1.5527149197465171e-27, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.2620811535015939, "policy_loss": -0.002035998372686288, "vf_loss": 0.26411715216266984, "vf_explained_var": 0.37860033471117577, "kl": 0.020324193161527514, "entropy": 1.1731796331506557, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 301455.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 640000, "num_env_steps_trained": 640000, "num_agent_steps_sampled": 2560000, "num_agent_steps_trained": 2560000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": 341.1, "episode_reward_mean": 377.78700000000003, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 146.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 18.0}, "policy_reward_mean": {"prey_policy": 185.98850000000002, "predator_policy": 2.905}, "custom_metrics": {}, "hist_stats": {"episode_reward": [389.7, 370.1, 379.3, 375.1, 360.3, 387.4, 383.9, 376.5, 389.20000000000005, 341.1, 361.2, 372.9, 390.1, 394.6, 362.8, 357.7, 363.8, 382.00000000000006, 399.1, 365.90000000000003, 385.6, 380.5, 354.8, 391.9, 392.8, 380.1, 387.4, 389.2, 347.7, 368.6, 355.7, 370.7, 400.0, 373.5, 366.8, 392.8, 373.59999999999997, 386.8, 382.0, 380.2, 386.2, 393.1, 391.5, 388.3, 371.3, 389.3, 373.4, 362.5, 377.6, 384.69999999999993, 389.2, 364.0, 396.4, 381.8, 374.29999999999995, 392.8, 374.8, 373.6, 377.9, 386.5, 377.4, 370.3, 388.29999999999995, 367.0, 383.2, 386.2, 368.1, 393.7, 363.1, 365.7, 374.6, 389.2, 392.6, 376.9, 393.5, 397.1, 374.6, 363.5, 380.7, 372.8, 388.3, 395.5, 396.4, 364.8, 388.3, 381.1, 376.4, 370.3, 376.6, 359.4, 355.7, 389.2, 357.0, 380.4, 376.8, 390.1, 372.8, 345.5, 371.8, 371.2], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [188.6, 199.1, 188.0, 172.1, 170.3, 200.0, 191.0, 181.1, 173.0, 173.3, 195.5, 191.9, 188.0, 191.9, 176.0, 195.5, 191.9, 197.29999999999998, 160.4, 169.7, 170.0, 174.2, 170.0, 173.9, 199.1, 191.0, 197.3, 197.3, 180.2, 176.6, 173.3, 169.39999999999998, 183.8, 170.0, 187.4, 194.59999999999997, 200.0, 199.1, 166.1, 186.8, 200.0, 185.6, 188.29999999999998, 189.2, 159.8, 182.0, 198.2, 193.7, 200.0, 192.8, 193.7, 181.4, 200.0, 187.4, 190.1, 199.1, 153.5, 177.2, 169.1, 195.5, 169.7, 173.0, 170.9, 192.8, 200.0, 200.0, 195.5, 164.0, 164.3, 189.5, 200.0, 192.8, 177.5, 190.1, 192.8, 191.0, 200.0, 173.0, 198.2, 173.0, 180.2, 200.0, 200.0, 190.1, 191.3, 198.2, 197.3, 191.0, 185.6, 181.7, 199.1, 186.2, 177.2, 189.2, 162.2, 188.3, 194.6, 179.0, 184.69999999999996, 200.0, 199.1, 190.1, 173.0, 191.0, 200.0, 196.4, 197.0, 183.8, 190.1, 177.2, 200.0, 192.8, 183.8, 191.0, 178.4, 189.2, 193.7, 177.2, 200.0, 186.5, 172.4, 197.0, 182.3, 179.0, 188.3, 200.0, 191.0, 164.0, 189.2, 191.0, 180.2, 200.0, 182.0, 175.1, 200.0, 193.7, 146.0, 199.1, 177.2, 174.5, 169.1, 195.5, 191.9, 197.3, 191.6, 200.0, 174.2, 193.7, 198.2, 191.3, 199.1, 197.0, 184.7, 188.9, 198.2, 158.3, 184.7, 194.0, 188.6, 174.2, 193.7, 194.6, 197.3, 198.2, 196.4, 200.0, 165.2, 185.6, 200.0, 188.3, 194.6, 186.5, 166.4, 200.0, 182.0, 188.3, 194.0, 173.6, 166.4, 179.0, 170.0, 175.7, 200.0, 189.2, 173.3, 175.7, 178.4, 194.0, 195.5, 173.3, 195.5, 194.6, 162.8, 200.0, 161.0, 168.5, 159.8, 200.0, 173.0, 189.2], "policy_predator_policy_reward": [0.0, 2.0, 0.0, 10.0, 9.0, 0.0, 3.0, 0.0, 8.0, 6.0, 0.0, 0.0, 4.0, 0.0, 0.0, 5.0, 0.0, 0.0, 11.0, 0.0, 8.0, 9.0, 14.0, 15.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 7.0, 8.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 3.0, 0.0, 6.0, 7.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 7.0, 4.0, 0.0, 2.0, 11.0, 7.0, 0.0, 0.0, 0.0, 5.0, 9.0, 4.0, 9.0, 0.0, 0.0, 0.0, 6.0, 3.0, 0.0, 0.0, 9.0, 3.0, 6.0, 6.0, 0.0, 3.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 4.0, 0.0, 7.0, 6.0, 6.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 8.0, 9.0, 0.0, 0.0, 0.0, 0.0, 12.0, 3.0, 0.0, 6.0, 0.0, 8.0, 3.0, 0.0, 0.0, 0.0, 18.0, 7.0, 7.0, 6.0, 4.0, 0.0, 0.0, 0.0, 1.0, 4.0, 5.0, 2.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 7.0, 0.0, 2.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 14.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 2.0, 7.0, 14.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 8.0, 0.0, 8.0, 0.0, 8.0, 0.0, 0.0, 10.0, 0.0, 8.0, 8.0, 8.0, 4.0, 0.0, 9.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 11.708438540474956, "mean_inference_ms": 27.227062164323385, "mean_action_processing_ms": 5.481480703000723, "mean_env_wait_ms": 6.685406381478244, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.02476799488067627, "StateBufferConnector_ms": 0.00629580020904541, "ViewRequirementAgentConnector_ms": 0.23548626899719238}, "num_episodes": 27, "episode_return_max": 400.0, "episode_return_min": 341.1, "episode_return_mean": 377.78700000000003, "episodes_this_iter": 27}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2560000, "num_agent_steps_trained": 2560000, "num_env_steps_sampled": 640000, "num_env_steps_trained": 640000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 159.66054228499397, "num_env_steps_trained_throughput_per_sec": 159.66054228499397, "timesteps_total": 640000, "num_env_steps_sampled_lifetime": 640000, "num_agent_steps_sampled_lifetime": 2560000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2560000, "timers": {"training_iteration_time_ms": 24561.09, "restore_workers_time_ms": 0.024, "training_step_time_ms": 24560.983, "sample_time_ms": 3396.765, "learn_time_ms": 21128.926, "learn_throughput": 189.314, "synch_weights_time_ms": 28.914}, "counters": {"num_env_steps_sampled": 640000, "num_env_steps_trained": 640000, "num_agent_steps_sampled": 2560000, "num_agent_steps_trained": 2560000}, "done": false, "training_iteration": 160, "trial_id": "75ec3_00000", "date": "2024-08-13_05-46-03", "timestamp": 1723542363, "time_this_iter_s": 25.1097629070282, "time_total_s": 15110.422037363052, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2495b80>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 15110.422037363052, "iterations_since_restore": 160, "perf": {"cpu_util_percent": 85.09166666666664, "ram_util_percent": 83.32499999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.1581821484855874, "cur_kl_coeff": 0.04334650319030402, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.7012604544148657, "policy_loss": -0.005716197278409723, "vf_loss": 0.7066600444928679, "vf_explained_var": 0.5540479811095687, "kl": 0.007304076673828857, "entropy": 1.238191224216784, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 303345.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.39352869235826704, "cur_kl_coeff": 2.329072379619776e-27, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.17153708986949087, "policy_loss": -0.0006826045369808241, "vf_loss": 0.17221969466960727, "vf_explained_var": 0.08449832667749395, "kl": 0.007920860480460928, "entropy": 1.133531888956746, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 303345.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 644000, "num_env_steps_trained": 644000, "num_agent_steps_sampled": 2576000, "num_agent_steps_trained": 2576000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": 327.5, "episode_reward_mean": 377.134, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 146.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 18.0}, "policy_reward_mean": {"prey_policy": 185.852, "predator_policy": 2.715}, "custom_metrics": {}, "hist_stats": {"episode_reward": [399.1, 365.90000000000003, 385.6, 380.5, 354.8, 391.9, 392.8, 380.1, 387.4, 389.2, 347.7, 368.6, 355.7, 370.7, 400.0, 373.5, 366.8, 392.8, 373.59999999999997, 386.8, 382.0, 380.2, 386.2, 393.1, 391.5, 388.3, 371.3, 389.3, 373.4, 362.5, 377.6, 384.69999999999993, 389.2, 364.0, 396.4, 381.8, 374.29999999999995, 392.8, 374.8, 373.6, 377.9, 386.5, 377.4, 370.3, 388.29999999999995, 367.0, 383.2, 386.2, 368.1, 393.7, 363.1, 365.7, 374.6, 389.2, 392.6, 376.9, 393.5, 397.1, 374.6, 363.5, 380.7, 372.8, 388.3, 395.5, 396.4, 364.8, 388.3, 381.1, 376.4, 370.3, 376.6, 359.4, 355.7, 389.2, 357.0, 380.4, 376.8, 390.1, 372.8, 345.5, 371.8, 371.2, 384.4, 382.9, 386.5, 378.40000000000003, 379.3, 359.2, 363.6, 392.8, 359.6, 352.3, 400.0, 373.5000000000001, 367.2, 339.8, 400.0, 359.5000000000001, 327.5, 365.9], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [200.0, 199.1, 166.1, 186.8, 200.0, 185.6, 188.29999999999998, 189.2, 159.8, 182.0, 198.2, 193.7, 200.0, 192.8, 193.7, 181.4, 200.0, 187.4, 190.1, 199.1, 153.5, 177.2, 169.1, 195.5, 169.7, 173.0, 170.9, 192.8, 200.0, 200.0, 195.5, 164.0, 164.3, 189.5, 200.0, 192.8, 177.5, 190.1, 192.8, 191.0, 200.0, 173.0, 198.2, 173.0, 180.2, 200.0, 200.0, 190.1, 191.3, 198.2, 197.3, 191.0, 185.6, 181.7, 199.1, 186.2, 177.2, 189.2, 162.2, 188.3, 194.6, 179.0, 184.69999999999996, 200.0, 199.1, 190.1, 173.0, 191.0, 200.0, 196.4, 197.0, 183.8, 190.1, 177.2, 200.0, 192.8, 183.8, 191.0, 178.4, 189.2, 193.7, 177.2, 200.0, 186.5, 172.4, 197.0, 182.3, 179.0, 188.3, 200.0, 191.0, 164.0, 189.2, 191.0, 180.2, 200.0, 182.0, 175.1, 200.0, 193.7, 146.0, 199.1, 177.2, 174.5, 169.1, 195.5, 191.9, 197.3, 191.6, 200.0, 174.2, 193.7, 198.2, 191.3, 199.1, 197.0, 184.7, 188.9, 198.2, 158.3, 184.7, 194.0, 188.6, 174.2, 193.7, 194.6, 197.3, 198.2, 196.4, 200.0, 165.2, 185.6, 200.0, 188.3, 194.6, 186.5, 166.4, 200.0, 182.0, 188.3, 194.0, 173.6, 166.4, 179.0, 170.0, 175.7, 200.0, 189.2, 173.3, 175.7, 178.4, 194.0, 195.5, 173.3, 195.5, 194.6, 162.8, 200.0, 161.0, 168.5, 159.8, 200.0, 173.0, 189.2, 181.1, 197.3, 182.9, 200.0, 200.0, 186.5, 189.2, 189.2, 193.7, 185.6, 168.2, 182.0, 185.0, 170.6, 192.8, 200.0, 170.0, 179.6, 181.1, 171.2, 200.0, 200.0, 188.0, 174.49999999999997, 185.0, 171.2, 161.9, 158.9, 200.0, 200.0, 174.79999999999998, 184.7, 154.7, 162.8, 173.3, 179.6], "policy_predator_policy_reward": [0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 3.0, 0.0, 6.0, 7.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 7.0, 4.0, 0.0, 2.0, 11.0, 7.0, 0.0, 0.0, 0.0, 5.0, 9.0, 4.0, 9.0, 0.0, 0.0, 0.0, 6.0, 3.0, 0.0, 0.0, 9.0, 3.0, 6.0, 6.0, 0.0, 3.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 4.0, 0.0, 7.0, 6.0, 6.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 8.0, 9.0, 0.0, 0.0, 0.0, 0.0, 12.0, 3.0, 0.0, 6.0, 0.0, 8.0, 3.0, 0.0, 0.0, 0.0, 18.0, 7.0, 7.0, 6.0, 4.0, 0.0, 0.0, 0.0, 1.0, 4.0, 5.0, 2.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 7.0, 0.0, 2.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 14.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 2.0, 7.0, 14.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 8.0, 0.0, 8.0, 0.0, 8.0, 0.0, 0.0, 10.0, 0.0, 8.0, 8.0, 8.0, 4.0, 0.0, 9.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 8.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 7.0, 4.0, 11.0, 0.0, 6.0, 13.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 8.0, 5.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 11.222193787503898, "mean_inference_ms": 27.535529168645827, "mean_action_processing_ms": 5.447090413835504, "mean_env_wait_ms": 6.777879695928416, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.027896404266357422, "StateBufferConnector_ms": 0.009519338607788086, "ViewRequirementAgentConnector_ms": 0.2522071599960327}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": 327.5, "episode_return_mean": 377.134, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2576000, "num_agent_steps_trained": 2576000, "num_env_steps_sampled": 644000, "num_env_steps_trained": 644000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 145.66924156766808, "num_env_steps_trained_throughput_per_sec": 145.66924156766808, "timesteps_total": 644000, "num_env_steps_sampled_lifetime": 644000, "num_agent_steps_sampled_lifetime": 2576000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2576000, "timers": {"training_iteration_time_ms": 24917.941, "restore_workers_time_ms": 0.024, "training_step_time_ms": 24917.833, "sample_time_ms": 3443.739, "learn_time_ms": 21439.441, "learn_throughput": 186.572, "synch_weights_time_ms": 28.217}, "counters": {"num_env_steps_sampled": 644000, "num_env_steps_trained": 644000, "num_agent_steps_sampled": 2576000, "num_agent_steps_trained": 2576000}, "done": false, "training_iteration": 161, "trial_id": "75ec3_00000", "date": "2024-08-13_05-46-30", "timestamp": 1723542390, "time_this_iter_s": 27.58227515220642, "time_total_s": 15138.004312515259, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2588b80>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 15138.004312515259, "iterations_since_restore": 161, "perf": {"cpu_util_percent": 89.5948717948718, "ram_util_percent": 83.35384615384613}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.12396280369746, "cur_kl_coeff": 0.04334650319030402, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.40247002367392826, "policy_loss": 0.00039496862344325534, "vf_loss": 0.40172533170423574, "vf_explained_var": 0.36438456452082074, "kl": 0.008068086082973025, "entropy": 1.2285287524026538, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 305235.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4403289379453454, "cur_kl_coeff": 2.329072379619776e-27, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.17814278971285574, "policy_loss": -0.0009027303164460199, "vf_loss": 0.17904551929203552, "vf_explained_var": 0.1941519631595208, "kl": 0.025406151211913253, "entropy": 1.0760625117039555, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 305235.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 648000, "num_env_steps_trained": 648000, "num_agent_steps_sampled": 2592000, "num_agent_steps_trained": 2592000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": 327.5, "episode_reward_mean": 376.43300000000005, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 146.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 18.0}, "policy_reward_mean": {"prey_policy": 185.6765, "predator_policy": 2.54}, "custom_metrics": {}, "hist_stats": {"episode_reward": [373.59999999999997, 386.8, 382.0, 380.2, 386.2, 393.1, 391.5, 388.3, 371.3, 389.3, 373.4, 362.5, 377.6, 384.69999999999993, 389.2, 364.0, 396.4, 381.8, 374.29999999999995, 392.8, 374.8, 373.6, 377.9, 386.5, 377.4, 370.3, 388.29999999999995, 367.0, 383.2, 386.2, 368.1, 393.7, 363.1, 365.7, 374.6, 389.2, 392.6, 376.9, 393.5, 397.1, 374.6, 363.5, 380.7, 372.8, 388.3, 395.5, 396.4, 364.8, 388.3, 381.1, 376.4, 370.3, 376.6, 359.4, 355.7, 389.2, 357.0, 380.4, 376.8, 390.1, 372.8, 345.5, 371.8, 371.2, 384.4, 382.9, 386.5, 378.40000000000003, 379.3, 359.2, 363.6, 392.8, 359.6, 352.3, 400.0, 373.5000000000001, 367.2, 339.8, 400.0, 359.5000000000001, 327.5, 365.9, 394.2, 381.4, 360.1, 374.80000000000007, 346.0, 360.0, 390.4, 370.9, 370.4, 388.8, 375.2, 368.0, 378.1, 389.2, 353.20000000000005, 387.4, 391.0, 353.9], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [177.5, 190.1, 192.8, 191.0, 200.0, 173.0, 198.2, 173.0, 180.2, 200.0, 200.0, 190.1, 191.3, 198.2, 197.3, 191.0, 185.6, 181.7, 199.1, 186.2, 177.2, 189.2, 162.2, 188.3, 194.6, 179.0, 184.69999999999996, 200.0, 199.1, 190.1, 173.0, 191.0, 200.0, 196.4, 197.0, 183.8, 190.1, 177.2, 200.0, 192.8, 183.8, 191.0, 178.4, 189.2, 193.7, 177.2, 200.0, 186.5, 172.4, 197.0, 182.3, 179.0, 188.3, 200.0, 191.0, 164.0, 189.2, 191.0, 180.2, 200.0, 182.0, 175.1, 200.0, 193.7, 146.0, 199.1, 177.2, 174.5, 169.1, 195.5, 191.9, 197.3, 191.6, 200.0, 174.2, 193.7, 198.2, 191.3, 199.1, 197.0, 184.7, 188.9, 198.2, 158.3, 184.7, 194.0, 188.6, 174.2, 193.7, 194.6, 197.3, 198.2, 196.4, 200.0, 165.2, 185.6, 200.0, 188.3, 194.6, 186.5, 166.4, 200.0, 182.0, 188.3, 194.0, 173.6, 166.4, 179.0, 170.0, 175.7, 200.0, 189.2, 173.3, 175.7, 178.4, 194.0, 195.5, 173.3, 195.5, 194.6, 162.8, 200.0, 161.0, 168.5, 159.8, 200.0, 173.0, 189.2, 181.1, 197.3, 182.9, 200.0, 200.0, 186.5, 189.2, 189.2, 193.7, 185.6, 168.2, 182.0, 185.0, 170.6, 192.8, 200.0, 170.0, 179.6, 181.1, 171.2, 200.0, 200.0, 188.0, 174.49999999999997, 185.0, 171.2, 161.9, 158.9, 200.0, 200.0, 174.79999999999998, 184.7, 154.7, 162.8, 173.3, 179.6, 194.0, 198.2, 187.4, 191.0, 177.5, 176.6, 186.5, 188.29999999999998, 164.0, 182.0, 182.0, 167.0, 187.4, 200.0, 180.2, 184.7, 188.0, 178.39999999999998, 194.0, 192.8, 179.0, 189.2, 182.9, 178.1, 182.0, 190.1, 194.6, 194.6, 162.2, 191.0, 200.0, 187.4, 197.3, 193.7, 182.9, 161.0], "policy_predator_policy_reward": [0.0, 6.0, 3.0, 0.0, 0.0, 9.0, 3.0, 6.0, 6.0, 0.0, 3.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 4.0, 0.0, 7.0, 6.0, 6.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 8.0, 9.0, 0.0, 0.0, 0.0, 0.0, 12.0, 3.0, 0.0, 6.0, 0.0, 8.0, 3.0, 0.0, 0.0, 0.0, 18.0, 7.0, 7.0, 6.0, 4.0, 0.0, 0.0, 0.0, 1.0, 4.0, 5.0, 2.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 7.0, 0.0, 2.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 14.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 2.0, 7.0, 14.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 8.0, 0.0, 8.0, 0.0, 8.0, 0.0, 0.0, 10.0, 0.0, 8.0, 8.0, 8.0, 4.0, 0.0, 9.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 8.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 7.0, 4.0, 11.0, 0.0, 6.0, 13.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 8.0, 5.0, 0.0, 2.0, 0.0, 3.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 3.0, 0.0, 6.0, 0.0, 0.0, 4.0, 2.0, 0.0, 7.0, 0.0, 7.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 11.167003639594627, "mean_inference_ms": 27.403398890474264, "mean_action_processing_ms": 5.419499007448545, "mean_env_wait_ms": 6.7424005154759, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.028948664665222168, "StateBufferConnector_ms": 0.00992739200592041, "ViewRequirementAgentConnector_ms": 0.26053881645202637}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": 327.5, "episode_return_mean": 376.43300000000005, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2592000, "num_agent_steps_trained": 2592000, "num_env_steps_sampled": 648000, "num_env_steps_trained": 648000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 154.80920931030917, "num_env_steps_trained_throughput_per_sec": 154.80920931030917, "timesteps_total": 648000, "num_env_steps_sampled_lifetime": 648000, "num_agent_steps_sampled_lifetime": 2592000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2592000, "timers": {"training_iteration_time_ms": 25068.574, "restore_workers_time_ms": 0.019, "training_step_time_ms": 25068.471, "sample_time_ms": 3348.573, "learn_time_ms": 21687.474, "learn_throughput": 184.438, "synch_weights_time_ms": 25.564}, "counters": {"num_env_steps_sampled": 648000, "num_env_steps_trained": 648000, "num_agent_steps_sampled": 2592000, "num_agent_steps_trained": 2592000}, "done": false, "training_iteration": 162, "trial_id": "75ec3_00000", "date": "2024-08-13_05-46-56", "timestamp": 1723542416, "time_this_iter_s": 25.89179229736328, "time_total_s": 15163.896104812622, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2526940>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 15163.896104812622, "iterations_since_restore": 162, "perf": {"cpu_util_percent": 87.375, "ram_util_percent": 82.95555555555556}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.549884124612682, "cur_kl_coeff": 0.04334650319030402, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.4486525206513415, "policy_loss": -0.0027633922448056557, "vf_loss": 0.4511427241086802, "vf_explained_var": 0.45389234190264705, "kl": 0.006302437518301034, "entropy": 1.181763553177869, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 307125.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4199689367874747, "cur_kl_coeff": 3.493608569429665e-27, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.16450513268281367, "policy_loss": -0.0006385505343257652, "vf_loss": 0.16514368350907085, "vf_explained_var": 0.0857358924610905, "kl": 0.011446862299775803, "entropy": 1.0296739886992823, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 307125.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 652000, "num_env_steps_trained": 652000, "num_agent_steps_sampled": 2608000, "num_agent_steps_trained": 2608000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": 327.5, "episode_reward_mean": 376.097, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 146.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 18.0}, "policy_reward_mean": {"prey_policy": 185.23850000000002, "predator_policy": 2.81}, "custom_metrics": {}, "hist_stats": {"episode_reward": [374.29999999999995, 392.8, 374.8, 373.6, 377.9, 386.5, 377.4, 370.3, 388.29999999999995, 367.0, 383.2, 386.2, 368.1, 393.7, 363.1, 365.7, 374.6, 389.2, 392.6, 376.9, 393.5, 397.1, 374.6, 363.5, 380.7, 372.8, 388.3, 395.5, 396.4, 364.8, 388.3, 381.1, 376.4, 370.3, 376.6, 359.4, 355.7, 389.2, 357.0, 380.4, 376.8, 390.1, 372.8, 345.5, 371.8, 371.2, 384.4, 382.9, 386.5, 378.40000000000003, 379.3, 359.2, 363.6, 392.8, 359.6, 352.3, 400.0, 373.5000000000001, 367.2, 339.8, 400.0, 359.5000000000001, 327.5, 365.9, 394.2, 381.4, 360.1, 374.80000000000007, 346.0, 360.0, 390.4, 370.9, 370.4, 388.8, 375.2, 368.0, 378.1, 389.2, 353.20000000000005, 387.4, 391.0, 353.9, 367.2, 364.4, 365.7, 376.6, 361.8, 394.6, 371.9, 382.5, 378.3, 400.0, 386.6, 362.7, 388.4, 383.9, 370.1, 385.4, 400.0, 398.2], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [190.1, 177.2, 200.0, 192.8, 183.8, 191.0, 178.4, 189.2, 193.7, 177.2, 200.0, 186.5, 172.4, 197.0, 182.3, 179.0, 188.3, 200.0, 191.0, 164.0, 189.2, 191.0, 180.2, 200.0, 182.0, 175.1, 200.0, 193.7, 146.0, 199.1, 177.2, 174.5, 169.1, 195.5, 191.9, 197.3, 191.6, 200.0, 174.2, 193.7, 198.2, 191.3, 199.1, 197.0, 184.7, 188.9, 198.2, 158.3, 184.7, 194.0, 188.6, 174.2, 193.7, 194.6, 197.3, 198.2, 196.4, 200.0, 165.2, 185.6, 200.0, 188.3, 194.6, 186.5, 166.4, 200.0, 182.0, 188.3, 194.0, 173.6, 166.4, 179.0, 170.0, 175.7, 200.0, 189.2, 173.3, 175.7, 178.4, 194.0, 195.5, 173.3, 195.5, 194.6, 162.8, 200.0, 161.0, 168.5, 159.8, 200.0, 173.0, 189.2, 181.1, 197.3, 182.9, 200.0, 200.0, 186.5, 189.2, 189.2, 193.7, 185.6, 168.2, 182.0, 185.0, 170.6, 192.8, 200.0, 170.0, 179.6, 181.1, 171.2, 200.0, 200.0, 188.0, 174.49999999999997, 185.0, 171.2, 161.9, 158.9, 200.0, 200.0, 174.79999999999998, 184.7, 154.7, 162.8, 173.3, 179.6, 194.0, 198.2, 187.4, 191.0, 177.5, 176.6, 186.5, 188.29999999999998, 164.0, 182.0, 182.0, 167.0, 187.4, 200.0, 180.2, 184.7, 188.0, 178.39999999999998, 194.0, 192.8, 179.0, 189.2, 182.9, 178.1, 182.0, 190.1, 194.6, 194.6, 162.2, 191.0, 200.0, 187.4, 197.3, 193.7, 182.9, 161.0, 158.0, 198.2, 179.0, 175.4, 178.7, 179.0, 167.3, 197.3, 168.2, 182.6, 194.6, 200.0, 162.2, 193.7, 185.0, 186.5, 193.7, 179.6, 200.0, 200.0, 184.4, 198.2, 163.4, 188.3, 184.4, 200.0, 196.4, 183.49999999999997, 161.3, 192.8, 188.9, 195.5, 200.0, 200.0, 198.2, 200.0], "policy_predator_policy_reward": [0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 8.0, 9.0, 0.0, 0.0, 0.0, 0.0, 12.0, 3.0, 0.0, 6.0, 0.0, 8.0, 3.0, 0.0, 0.0, 0.0, 18.0, 7.0, 7.0, 6.0, 4.0, 0.0, 0.0, 0.0, 1.0, 4.0, 5.0, 2.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 7.0, 0.0, 2.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 14.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 2.0, 7.0, 14.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 8.0, 0.0, 8.0, 0.0, 8.0, 0.0, 0.0, 10.0, 0.0, 8.0, 8.0, 8.0, 4.0, 0.0, 9.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 8.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 7.0, 4.0, 11.0, 0.0, 6.0, 13.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 8.0, 5.0, 0.0, 2.0, 0.0, 3.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 3.0, 0.0, 6.0, 0.0, 0.0, 4.0, 2.0, 0.0, 7.0, 0.0, 7.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 11.0, 0.0, 10.0, 8.0, 0.0, 5.0, 7.0, 10.0, 1.0, 0.0, 0.0, 4.0, 12.0, 5.0, 6.0, 5.0, 0.0, 0.0, 0.0, 0.0, 4.0, 4.0, 7.0, 0.0, 4.0, 0.0, 4.0, 8.0, 8.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 11.11278123786093, "mean_inference_ms": 27.27373645667314, "mean_action_processing_ms": 5.392357038769653, "mean_env_wait_ms": 6.707431820676586, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.02323746681213379, "StateBufferConnector_ms": 0.00989377498626709, "ViewRequirementAgentConnector_ms": 0.27499115467071533}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": 327.5, "episode_return_mean": 376.097, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2608000, "num_agent_steps_trained": 2608000, "num_env_steps_sampled": 652000, "num_env_steps_trained": 652000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 152.76711849985622, "num_env_steps_trained_throughput_per_sec": 152.76711849985622, "timesteps_total": 652000, "num_env_steps_sampled_lifetime": 652000, "num_agent_steps_sampled_lifetime": 2608000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2608000, "timers": {"training_iteration_time_ms": 25132.683, "restore_workers_time_ms": 0.019, "training_step_time_ms": 25132.581, "sample_time_ms": 3229.707, "learn_time_ms": 21871.301, "learn_throughput": 182.888, "synch_weights_time_ms": 25.099}, "counters": {"num_env_steps_sampled": 652000, "num_env_steps_trained": 652000, "num_agent_steps_sampled": 2608000, "num_agent_steps_trained": 2608000}, "done": false, "training_iteration": 163, "trial_id": "75ec3_00000", "date": "2024-08-13_05-47-23", "timestamp": 1723542443, "time_this_iter_s": 26.24786686897278, "time_total_s": 15190.143971681595, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b23f00d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 15190.143971681595, "iterations_since_restore": 163, "perf": {"cpu_util_percent": 88.66756756756759, "ram_util_percent": 83.3297297297297}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7549208175726039, "cur_kl_coeff": 0.04334650319030402, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.424739077644855, "policy_loss": -0.0011672901576039968, "vf_loss": 0.425655110348903, "vf_explained_var": 0.3480324841050244, "kl": 0.005796510042748938, "entropy": 1.2065278197091722, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 309015.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5625669103352323, "cur_kl_coeff": 3.493608569429665e-27, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.22207561398846487, "policy_loss": -0.00132397728462127, "vf_loss": 0.2233995920141097, "vf_explained_var": 0.21237572869926533, "kl": 0.017196803531182574, "entropy": 1.0840459661508994, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 309015.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 656000, "num_env_steps_trained": 656000, "num_agent_steps_sampled": 2624000, "num_agent_steps_trained": 2624000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": 327.5, "episode_reward_mean": 374.83, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 150.2, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 17.0}, "policy_reward_mean": {"prey_policy": 184.505, "predator_policy": 2.91}, "custom_metrics": {}, "hist_stats": {"episode_reward": [363.5, 380.7, 372.8, 388.3, 395.5, 396.4, 364.8, 388.3, 381.1, 376.4, 370.3, 376.6, 359.4, 355.7, 389.2, 357.0, 380.4, 376.8, 390.1, 372.8, 345.5, 371.8, 371.2, 384.4, 382.9, 386.5, 378.40000000000003, 379.3, 359.2, 363.6, 392.8, 359.6, 352.3, 400.0, 373.5000000000001, 367.2, 339.8, 400.0, 359.5000000000001, 327.5, 365.9, 394.2, 381.4, 360.1, 374.80000000000007, 346.0, 360.0, 390.4, 370.9, 370.4, 388.8, 375.2, 368.0, 378.1, 389.2, 353.20000000000005, 387.4, 391.0, 353.9, 367.2, 364.4, 365.7, 376.6, 361.8, 394.6, 371.9, 382.5, 378.3, 400.0, 386.6, 362.7, 388.4, 383.9, 370.1, 385.4, 400.0, 398.2, 376.9, 387.0, 377.2, 372.1, 361.3, 387.1, 369.4, 358.3, 363.3, 368.5, 359.6, 381.1, 387.1, 398.2, 377.5, 384.6, 381.1, 386.20000000000005, 342.5, 378.0, 340.1, 393.7, 383.9], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [198.2, 158.3, 184.7, 194.0, 188.6, 174.2, 193.7, 194.6, 197.3, 198.2, 196.4, 200.0, 165.2, 185.6, 200.0, 188.3, 194.6, 186.5, 166.4, 200.0, 182.0, 188.3, 194.0, 173.6, 166.4, 179.0, 170.0, 175.7, 200.0, 189.2, 173.3, 175.7, 178.4, 194.0, 195.5, 173.3, 195.5, 194.6, 162.8, 200.0, 161.0, 168.5, 159.8, 200.0, 173.0, 189.2, 181.1, 197.3, 182.9, 200.0, 200.0, 186.5, 189.2, 189.2, 193.7, 185.6, 168.2, 182.0, 185.0, 170.6, 192.8, 200.0, 170.0, 179.6, 181.1, 171.2, 200.0, 200.0, 188.0, 174.49999999999997, 185.0, 171.2, 161.9, 158.9, 200.0, 200.0, 174.79999999999998, 184.7, 154.7, 162.8, 173.3, 179.6, 194.0, 198.2, 187.4, 191.0, 177.5, 176.6, 186.5, 188.29999999999998, 164.0, 182.0, 182.0, 167.0, 187.4, 200.0, 180.2, 184.7, 188.0, 178.39999999999998, 194.0, 192.8, 179.0, 189.2, 182.9, 178.1, 182.0, 190.1, 194.6, 194.6, 162.2, 191.0, 200.0, 187.4, 197.3, 193.7, 182.9, 161.0, 158.0, 198.2, 179.0, 175.4, 178.7, 179.0, 167.3, 197.3, 168.2, 182.6, 194.6, 200.0, 162.2, 193.7, 185.0, 186.5, 193.7, 179.6, 200.0, 200.0, 184.4, 198.2, 163.4, 188.3, 184.4, 200.0, 196.4, 183.49999999999997, 161.3, 192.8, 188.9, 195.5, 200.0, 200.0, 198.2, 200.0, 182.0, 191.9, 194.0, 191.0, 182.0, 189.2, 190.1, 173.0, 175.7, 185.6, 181.1, 200.0, 178.4, 191.0, 150.2, 193.1, 175.1, 180.2, 194.6, 173.9, 150.2, 196.4, 189.2, 191.9, 200.0, 181.1, 199.1, 199.1, 191.9, 185.6, 185.0, 194.6, 175.1, 191.0, 198.2, 182.0, 159.5, 161.0, 176.0, 194.0, 167.0, 154.1, 193.7, 200.0, 194.0, 185.9], "policy_predator_policy_reward": [0.0, 7.0, 0.0, 2.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 14.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 2.0, 7.0, 14.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 8.0, 0.0, 8.0, 0.0, 8.0, 0.0, 0.0, 10.0, 0.0, 8.0, 8.0, 8.0, 4.0, 0.0, 9.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 8.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 7.0, 4.0, 11.0, 0.0, 6.0, 13.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 8.0, 5.0, 0.0, 2.0, 0.0, 3.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 3.0, 0.0, 6.0, 0.0, 0.0, 4.0, 2.0, 0.0, 7.0, 0.0, 7.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 11.0, 0.0, 10.0, 8.0, 0.0, 5.0, 7.0, 10.0, 1.0, 0.0, 0.0, 4.0, 12.0, 5.0, 6.0, 5.0, 0.0, 0.0, 0.0, 0.0, 4.0, 4.0, 7.0, 0.0, 4.0, 0.0, 4.0, 8.0, 8.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 2.0, 0.0, 6.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 15.0, 8.0, 0.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 9.0, 6.0, 0.0, 6.0, 5.0, 17.0, 0.0, 8.0, 6.0, 13.0, 0.0, 0.0, 2.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 11.046519761824266, "mean_inference_ms": 27.509175075865596, "mean_action_processing_ms": 5.503015551363595, "mean_env_wait_ms": 6.132858345014967, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.02574741840362549, "StateBufferConnector_ms": 0.009688019752502441, "ViewRequirementAgentConnector_ms": 0.29312121868133545}, "num_episodes": 23, "episode_return_max": 400.0, "episode_return_min": 327.5, "episode_return_mean": 374.83, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2624000, "num_agent_steps_trained": 2624000, "num_env_steps_sampled": 656000, "num_env_steps_trained": 656000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 157.61727313508905, "num_env_steps_trained_throughput_per_sec": 157.61727313508905, "timesteps_total": 656000, "num_env_steps_sampled_lifetime": 656000, "num_agent_steps_sampled_lifetime": 2624000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2624000, "timers": {"training_iteration_time_ms": 25164.714, "restore_workers_time_ms": 0.017, "training_step_time_ms": 25164.615, "sample_time_ms": 3247.05, "learn_time_ms": 21887.418, "learn_throughput": 182.753, "synch_weights_time_ms": 23.696}, "counters": {"num_env_steps_sampled": 656000, "num_env_steps_trained": 656000, "num_agent_steps_sampled": 2624000, "num_agent_steps_trained": 2624000}, "done": false, "training_iteration": 164, "trial_id": "75ec3_00000", "date": "2024-08-13_05-47-48", "timestamp": 1723542468, "time_this_iter_s": 25.428663969039917, "time_total_s": 15215.572635650635, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2568430>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 15215.572635650635, "iterations_since_restore": 164, "perf": {"cpu_util_percent": 86.9, "ram_util_percent": 83.39722222222221}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5306270299765168, "cur_kl_coeff": 0.04334650319030402, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.41468448123956075, "policy_loss": -0.0036821737846054097, "vf_loss": 0.4180890199664251, "vf_explained_var": 0.28251300362682846, "kl": 0.006404991472107092, "entropy": 1.1692440562147313, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 310905.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.3691540934756477, "cur_kl_coeff": 3.493608569429665e-27, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.22776338726912856, "policy_loss": -0.0002476176589471165, "vf_loss": 0.2280110048352514, "vf_explained_var": 0.14531900236215542, "kl": 0.018274404219787765, "entropy": 1.0797998175419197, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 310905.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 660000, "num_env_steps_trained": 660000, "num_agent_steps_sampled": 2640000, "num_agent_steps_trained": 2640000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": 327.5, "episode_reward_mean": 375.725, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 150.2, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 18.0}, "policy_reward_mean": {"prey_policy": 185.0075, "predator_policy": 2.855}, "custom_metrics": {}, "hist_stats": {"episode_reward": [371.2, 384.4, 382.9, 386.5, 378.40000000000003, 379.3, 359.2, 363.6, 392.8, 359.6, 352.3, 400.0, 373.5000000000001, 367.2, 339.8, 400.0, 359.5000000000001, 327.5, 365.9, 394.2, 381.4, 360.1, 374.80000000000007, 346.0, 360.0, 390.4, 370.9, 370.4, 388.8, 375.2, 368.0, 378.1, 389.2, 353.20000000000005, 387.4, 391.0, 353.9, 367.2, 364.4, 365.7, 376.6, 361.8, 394.6, 371.9, 382.5, 378.3, 400.0, 386.6, 362.7, 388.4, 383.9, 370.1, 385.4, 400.0, 398.2, 376.9, 387.0, 377.2, 372.1, 361.3, 387.1, 369.4, 358.3, 363.3, 368.5, 359.6, 381.1, 387.1, 398.2, 377.5, 384.6, 381.1, 386.20000000000005, 342.5, 378.0, 340.1, 393.7, 383.9, 363.8, 390.1, 352.9, 354.0, 388.1, 389.2, 390.1, 372.0, 381.8, 367.4, 386.4, 381.0, 399.1, 356.4, 383.0, 356.8, 392.8, 396.4, 385.6, 377.7, 389.3, 389.0], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [173.0, 189.2, 181.1, 197.3, 182.9, 200.0, 200.0, 186.5, 189.2, 189.2, 193.7, 185.6, 168.2, 182.0, 185.0, 170.6, 192.8, 200.0, 170.0, 179.6, 181.1, 171.2, 200.0, 200.0, 188.0, 174.49999999999997, 185.0, 171.2, 161.9, 158.9, 200.0, 200.0, 174.79999999999998, 184.7, 154.7, 162.8, 173.3, 179.6, 194.0, 198.2, 187.4, 191.0, 177.5, 176.6, 186.5, 188.29999999999998, 164.0, 182.0, 182.0, 167.0, 187.4, 200.0, 180.2, 184.7, 188.0, 178.39999999999998, 194.0, 192.8, 179.0, 189.2, 182.9, 178.1, 182.0, 190.1, 194.6, 194.6, 162.2, 191.0, 200.0, 187.4, 197.3, 193.7, 182.9, 161.0, 158.0, 198.2, 179.0, 175.4, 178.7, 179.0, 167.3, 197.3, 168.2, 182.6, 194.6, 200.0, 162.2, 193.7, 185.0, 186.5, 193.7, 179.6, 200.0, 200.0, 184.4, 198.2, 163.4, 188.3, 184.4, 200.0, 196.4, 183.49999999999997, 161.3, 192.8, 188.9, 195.5, 200.0, 200.0, 198.2, 200.0, 182.0, 191.9, 194.0, 191.0, 182.0, 189.2, 190.1, 173.0, 175.7, 185.6, 181.1, 200.0, 178.4, 191.0, 150.2, 193.1, 175.1, 180.2, 194.6, 173.9, 150.2, 196.4, 189.2, 191.9, 200.0, 181.1, 199.1, 199.1, 191.9, 185.6, 185.0, 194.6, 175.1, 191.0, 198.2, 182.0, 159.5, 161.0, 176.0, 194.0, 167.0, 154.1, 193.7, 200.0, 194.0, 185.9, 170.9, 191.9, 193.7, 196.4, 170.89999999999998, 164.0, 167.6, 172.4, 187.1, 200.0, 197.3, 191.9, 200.0, 190.1, 189.2, 177.8, 177.5, 197.3, 187.4, 170.0, 181.4, 200.0, 176.0, 197.0, 200.0, 199.1, 178.4, 167.0, 191.0, 176.0, 171.2, 176.6, 200.0, 192.8, 200.0, 196.4, 185.6, 200.0, 193.7, 176.0, 188.0, 197.3, 179.0, 200.0], "policy_predator_policy_reward": [0.0, 9.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 8.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 7.0, 4.0, 11.0, 0.0, 6.0, 13.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 8.0, 5.0, 0.0, 2.0, 0.0, 3.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 3.0, 0.0, 6.0, 0.0, 0.0, 4.0, 2.0, 0.0, 7.0, 0.0, 7.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 11.0, 0.0, 10.0, 8.0, 0.0, 5.0, 7.0, 10.0, 1.0, 0.0, 0.0, 4.0, 12.0, 5.0, 6.0, 5.0, 0.0, 0.0, 0.0, 0.0, 4.0, 4.0, 7.0, 0.0, 4.0, 0.0, 4.0, 8.0, 8.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 2.0, 0.0, 6.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 15.0, 8.0, 0.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 9.0, 6.0, 0.0, 6.0, 5.0, 17.0, 0.0, 8.0, 6.0, 13.0, 0.0, 0.0, 2.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 18.0, 14.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 4.0, 3.0, 0.0, 10.0, 5.0, 0.0, 8.0, 0.0, 0.0, 0.0, 8.0, 3.0, 8.0, 8.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 4.0, 0.0, 5.0, 5.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 10.982472620476262, "mean_inference_ms": 26.966381245543598, "mean_action_processing_ms": 5.328138926064607, "mean_env_wait_ms": 6.622972480348574, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.017577409744262695, "StateBufferConnector_ms": 0.009661436080932617, "ViewRequirementAgentConnector_ms": 0.3260326385498047}, "num_episodes": 22, "episode_return_max": 400.0, "episode_return_min": 327.5, "episode_return_mean": 375.725, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2640000, "num_agent_steps_trained": 2640000, "num_env_steps_sampled": 660000, "num_env_steps_trained": 660000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 149.66991860530592, "num_env_steps_trained_throughput_per_sec": 149.66991860530592, "timesteps_total": 660000, "num_env_steps_sampled_lifetime": 660000, "num_agent_steps_sampled_lifetime": 2640000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2640000, "timers": {"training_iteration_time_ms": 25460.057, "restore_workers_time_ms": 0.017, "training_step_time_ms": 25459.958, "sample_time_ms": 3280.001, "learn_time_ms": 22149.44, "learn_throughput": 180.591, "synch_weights_time_ms": 24.066}, "counters": {"num_env_steps_sampled": 660000, "num_env_steps_trained": 660000, "num_agent_steps_sampled": 2640000, "num_agent_steps_trained": 2640000}, "done": false, "training_iteration": 165, "trial_id": "75ec3_00000", "date": "2024-08-13_05-48-15", "timestamp": 1723542495, "time_this_iter_s": 26.793184995651245, "time_total_s": 15242.365820646286, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b1ae2d30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 15242.365820646286, "iterations_since_restore": 165, "perf": {"cpu_util_percent": 86.17105263157893, "ram_util_percent": 83.47105263157893}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5575078798310151, "cur_kl_coeff": 0.04334650319030402, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.26146226937481615, "policy_loss": -0.005241915847731646, "vf_loss": 0.2659034935150187, "vf_explained_var": 0.3763083724117784, "kl": 0.018471889405534764, "entropy": 1.0970120659580938, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 312795.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.3861230000617012, "cur_kl_coeff": 3.493608569429665e-27, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.14498600584095117, "policy_loss": -0.0016893049766107525, "vf_loss": 0.14667531011058524, "vf_explained_var": 0.09868839613344303, "kl": 0.013804351989361741, "entropy": 0.9680306911468506, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 312795.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 664000, "num_env_steps_trained": 664000, "num_agent_steps_sampled": 2656000, "num_agent_steps_trained": 2656000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": 340.1, "episode_reward_mean": 376.6139999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 150.2, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 18.0}, "policy_reward_mean": {"prey_policy": 185.357, "predator_policy": 2.95}, "custom_metrics": {}, "hist_stats": {"episode_reward": [365.9, 394.2, 381.4, 360.1, 374.80000000000007, 346.0, 360.0, 390.4, 370.9, 370.4, 388.8, 375.2, 368.0, 378.1, 389.2, 353.20000000000005, 387.4, 391.0, 353.9, 367.2, 364.4, 365.7, 376.6, 361.8, 394.6, 371.9, 382.5, 378.3, 400.0, 386.6, 362.7, 388.4, 383.9, 370.1, 385.4, 400.0, 398.2, 376.9, 387.0, 377.2, 372.1, 361.3, 387.1, 369.4, 358.3, 363.3, 368.5, 359.6, 381.1, 387.1, 398.2, 377.5, 384.6, 381.1, 386.20000000000005, 342.5, 378.0, 340.1, 393.7, 383.9, 363.8, 390.1, 352.9, 354.0, 388.1, 389.2, 390.1, 372.0, 381.8, 367.4, 386.4, 381.0, 399.1, 356.4, 383.0, 356.8, 392.8, 396.4, 385.6, 377.7, 389.3, 389.0, 378.6, 390.1, 397.3, 383.9, 379.7, 380.5, 369.7, 377.5, 360.1, 379.2, 348.9, 360.6, 363.1, 370.2, 369.9, 369.6, 392.2, 395.5], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [173.3, 179.6, 194.0, 198.2, 187.4, 191.0, 177.5, 176.6, 186.5, 188.29999999999998, 164.0, 182.0, 182.0, 167.0, 187.4, 200.0, 180.2, 184.7, 188.0, 178.39999999999998, 194.0, 192.8, 179.0, 189.2, 182.9, 178.1, 182.0, 190.1, 194.6, 194.6, 162.2, 191.0, 200.0, 187.4, 197.3, 193.7, 182.9, 161.0, 158.0, 198.2, 179.0, 175.4, 178.7, 179.0, 167.3, 197.3, 168.2, 182.6, 194.6, 200.0, 162.2, 193.7, 185.0, 186.5, 193.7, 179.6, 200.0, 200.0, 184.4, 198.2, 163.4, 188.3, 184.4, 200.0, 196.4, 183.49999999999997, 161.3, 192.8, 188.9, 195.5, 200.0, 200.0, 198.2, 200.0, 182.0, 191.9, 194.0, 191.0, 182.0, 189.2, 190.1, 173.0, 175.7, 185.6, 181.1, 200.0, 178.4, 191.0, 150.2, 193.1, 175.1, 180.2, 194.6, 173.9, 150.2, 196.4, 189.2, 191.9, 200.0, 181.1, 199.1, 199.1, 191.9, 185.6, 185.0, 194.6, 175.1, 191.0, 198.2, 182.0, 159.5, 161.0, 176.0, 194.0, 167.0, 154.1, 193.7, 200.0, 194.0, 185.9, 170.9, 191.9, 193.7, 196.4, 170.89999999999998, 164.0, 167.6, 172.4, 187.1, 200.0, 197.3, 191.9, 200.0, 190.1, 189.2, 177.8, 177.5, 197.3, 187.4, 170.0, 181.4, 200.0, 176.0, 197.0, 200.0, 199.1, 178.4, 167.0, 191.0, 176.0, 171.2, 176.6, 200.0, 192.8, 200.0, 196.4, 185.6, 200.0, 193.7, 176.0, 188.0, 197.3, 179.0, 200.0, 195.5, 169.1, 194.6, 195.5, 197.3, 200.0, 188.0, 191.9, 193.1, 182.6, 191.0, 186.5, 164.0, 193.7, 185.6, 191.9, 173.89999999999998, 177.2, 189.2, 185.0, 169.1, 171.8, 167.0, 182.6, 167.6, 186.5, 176.0, 183.2, 177.5, 181.4, 174.2, 187.4, 198.2, 191.0, 195.5, 200.0], "policy_predator_policy_reward": [8.0, 5.0, 0.0, 2.0, 0.0, 3.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 3.0, 0.0, 6.0, 0.0, 0.0, 4.0, 2.0, 0.0, 7.0, 0.0, 7.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 11.0, 0.0, 10.0, 8.0, 0.0, 5.0, 7.0, 10.0, 1.0, 0.0, 0.0, 4.0, 12.0, 5.0, 6.0, 5.0, 0.0, 0.0, 0.0, 0.0, 4.0, 4.0, 7.0, 0.0, 4.0, 0.0, 4.0, 8.0, 8.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 2.0, 0.0, 6.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 15.0, 8.0, 0.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 9.0, 6.0, 0.0, 6.0, 5.0, 17.0, 0.0, 8.0, 6.0, 13.0, 0.0, 0.0, 2.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 18.0, 14.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 4.0, 3.0, 0.0, 10.0, 5.0, 0.0, 8.0, 0.0, 0.0, 0.0, 8.0, 3.0, 8.0, 8.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 4.0, 0.0, 5.0, 5.0, 8.0, 6.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 4.0, 0.0, 0.0, 3.0, 0.0, 12.0, 0.0, 0.0, 9.0, 0.0, 0.0, 5.0, 8.0, 0.0, 0.0, 11.0, 0.0, 9.0, 11.0, 0.0, 11.0, 0.0, 0.0, 8.0, 3.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 10.931431721031002, "mean_inference_ms": 26.843769228293024, "mean_action_processing_ms": 5.302351224542181, "mean_env_wait_ms": 6.589455924002271, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019219636917114258, "StateBufferConnector_ms": 0.006476759910583496, "ViewRequirementAgentConnector_ms": 0.3261164426803589}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": 340.1, "episode_return_mean": 376.6139999999999, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2656000, "num_agent_steps_trained": 2656000, "num_env_steps_sampled": 664000, "num_env_steps_trained": 664000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 154.10688599158243, "num_env_steps_trained_throughput_per_sec": 154.10688599158243, "timesteps_total": 664000, "num_env_steps_sampled_lifetime": 664000, "num_agent_steps_sampled_lifetime": 2656000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2656000, "timers": {"training_iteration_time_ms": 25551.031, "restore_workers_time_ms": 0.017, "training_step_time_ms": 25550.967, "sample_time_ms": 3464.239, "learn_time_ms": 22057.214, "learn_throughput": 181.347, "synch_weights_time_ms": 24.026}, "counters": {"num_env_steps_sampled": 664000, "num_env_steps_trained": 664000, "num_agent_steps_sampled": 2656000, "num_agent_steps_trained": 2656000}, "done": false, "training_iteration": 166, "trial_id": "75ec3_00000", "date": "2024-08-13_05-48-41", "timestamp": 1723542521, "time_this_iter_s": 26.000717878341675, "time_total_s": 15268.366538524628, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b23f0160>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 15268.366538524628, "iterations_since_restore": 166, "perf": {"cpu_util_percent": 84.47567567567569, "ram_util_percent": 83.19459459459459}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.3259312215778563, "cur_kl_coeff": 0.04334650319030402, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.4647073729867953, "policy_loss": -0.005170783005216253, "vf_loss": 0.46944662822538585, "vf_explained_var": 0.46557540521419866, "kl": 0.009955249825746202, "entropy": 1.1472175830886477, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 314685.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4167846470026585, "cur_kl_coeff": 3.493608569429665e-27, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.18674282585738827, "policy_loss": -0.0005256457675603174, "vf_loss": 0.18726847129935525, "vf_explained_var": 0.20333844905807857, "kl": 0.01004115020466963, "entropy": 0.8927270131451743, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 314685.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 668000, "num_env_steps_trained": 668000, "num_agent_steps_sampled": 2672000, "num_agent_steps_trained": 2672000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": 340.1, "episode_reward_mean": 376.7859999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 150.2, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 18.0}, "policy_reward_mean": {"prey_policy": 185.213, "predator_policy": 3.18}, "custom_metrics": {}, "hist_stats": {"episode_reward": [353.9, 367.2, 364.4, 365.7, 376.6, 361.8, 394.6, 371.9, 382.5, 378.3, 400.0, 386.6, 362.7, 388.4, 383.9, 370.1, 385.4, 400.0, 398.2, 376.9, 387.0, 377.2, 372.1, 361.3, 387.1, 369.4, 358.3, 363.3, 368.5, 359.6, 381.1, 387.1, 398.2, 377.5, 384.6, 381.1, 386.20000000000005, 342.5, 378.0, 340.1, 393.7, 383.9, 363.8, 390.1, 352.9, 354.0, 388.1, 389.2, 390.1, 372.0, 381.8, 367.4, 386.4, 381.0, 399.1, 356.4, 383.0, 356.8, 392.8, 396.4, 385.6, 377.7, 389.3, 389.0, 378.6, 390.1, 397.3, 383.9, 379.7, 380.5, 369.7, 377.5, 360.1, 379.2, 348.9, 360.6, 363.1, 370.2, 369.9, 369.6, 392.2, 395.5, 367.5, 377.5, 379.7, 359.5, 382.0, 397.3, 394.6, 366.4000000000001, 364.2, 357.0, 369.5, 369.5, 353.2, 373.4, 382.6, 371.0, 399.1, 398.2], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [182.9, 161.0, 158.0, 198.2, 179.0, 175.4, 178.7, 179.0, 167.3, 197.3, 168.2, 182.6, 194.6, 200.0, 162.2, 193.7, 185.0, 186.5, 193.7, 179.6, 200.0, 200.0, 184.4, 198.2, 163.4, 188.3, 184.4, 200.0, 196.4, 183.49999999999997, 161.3, 192.8, 188.9, 195.5, 200.0, 200.0, 198.2, 200.0, 182.0, 191.9, 194.0, 191.0, 182.0, 189.2, 190.1, 173.0, 175.7, 185.6, 181.1, 200.0, 178.4, 191.0, 150.2, 193.1, 175.1, 180.2, 194.6, 173.9, 150.2, 196.4, 189.2, 191.9, 200.0, 181.1, 199.1, 199.1, 191.9, 185.6, 185.0, 194.6, 175.1, 191.0, 198.2, 182.0, 159.5, 161.0, 176.0, 194.0, 167.0, 154.1, 193.7, 200.0, 194.0, 185.9, 170.9, 191.9, 193.7, 196.4, 170.89999999999998, 164.0, 167.6, 172.4, 187.1, 200.0, 197.3, 191.9, 200.0, 190.1, 189.2, 177.8, 177.5, 197.3, 187.4, 170.0, 181.4, 200.0, 176.0, 197.0, 200.0, 199.1, 178.4, 167.0, 191.0, 176.0, 171.2, 176.6, 200.0, 192.8, 200.0, 196.4, 185.6, 200.0, 193.7, 176.0, 188.0, 197.3, 179.0, 200.0, 195.5, 169.1, 194.6, 195.5, 197.3, 200.0, 188.0, 191.9, 193.1, 182.6, 191.0, 186.5, 164.0, 193.7, 185.6, 191.9, 173.89999999999998, 177.2, 189.2, 185.0, 169.1, 171.8, 167.0, 182.6, 167.6, 186.5, 176.0, 183.2, 177.5, 181.4, 174.2, 187.4, 198.2, 191.0, 195.5, 200.0, 200.0, 153.5, 191.0, 186.5, 172.7, 200.0, 172.1, 187.4, 173.0, 200.0, 200.0, 197.3, 199.1, 195.5, 185.6, 174.79999999999998, 194.59999999999997, 161.6, 155.0, 179.0, 174.5, 191.0, 180.8, 184.7, 164.0, 171.2, 189.5, 176.9, 188.0, 188.6, 183.2, 177.79999999999998, 200.0, 199.1, 200.0, 198.2], "policy_predator_policy_reward": [0.0, 10.0, 0.0, 11.0, 0.0, 10.0, 8.0, 0.0, 5.0, 7.0, 10.0, 1.0, 0.0, 0.0, 4.0, 12.0, 5.0, 6.0, 5.0, 0.0, 0.0, 0.0, 0.0, 4.0, 4.0, 7.0, 0.0, 4.0, 0.0, 4.0, 8.0, 8.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 2.0, 0.0, 6.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 15.0, 8.0, 0.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 9.0, 6.0, 0.0, 6.0, 5.0, 17.0, 0.0, 8.0, 6.0, 13.0, 0.0, 0.0, 2.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 18.0, 14.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 4.0, 3.0, 0.0, 10.0, 5.0, 0.0, 8.0, 0.0, 0.0, 0.0, 8.0, 3.0, 8.0, 8.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 4.0, 0.0, 5.0, 5.0, 8.0, 6.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 4.0, 0.0, 0.0, 3.0, 0.0, 12.0, 0.0, 0.0, 9.0, 0.0, 0.0, 5.0, 8.0, 0.0, 0.0, 11.0, 0.0, 9.0, 11.0, 0.0, 11.0, 0.0, 0.0, 8.0, 3.0, 0.0, 0.0, 0.0, 7.0, 7.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 8.0, 8.0, 15.0, 0.0, 4.0, 4.0, 0.0, 4.0, 14.0, 7.0, 0.0, 4.0, 2.0, 5.0, 5.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 10.882285042268533, "mean_inference_ms": 26.72530186021525, "mean_action_processing_ms": 5.277271384219358, "mean_env_wait_ms": 6.5567491527612605, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.018060803413391113, "StateBufferConnector_ms": 0.007060647010803223, "ViewRequirementAgentConnector_ms": 0.36456573009490967}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": 340.1, "episode_return_mean": 376.7859999999999, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2672000, "num_agent_steps_trained": 2672000, "num_env_steps_sampled": 668000, "num_env_steps_trained": 668000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 154.71200100581333, "num_env_steps_trained_throughput_per_sec": 154.71200100581333, "timesteps_total": 668000, "num_env_steps_sampled_lifetime": 668000, "num_agent_steps_sampled_lifetime": 2672000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2672000, "timers": {"training_iteration_time_ms": 25746.737, "restore_workers_time_ms": 0.018, "training_step_time_ms": 25746.675, "sample_time_ms": 3719.422, "learn_time_ms": 21993.325, "learn_throughput": 181.873, "synch_weights_time_ms": 29.392}, "counters": {"num_env_steps_sampled": 668000, "num_env_steps_trained": 668000, "num_agent_steps_sampled": 2672000, "num_agent_steps_trained": 2672000}, "done": false, "training_iteration": 167, "trial_id": "75ec3_00000", "date": "2024-08-13_05-49-07", "timestamp": 1723542547, "time_this_iter_s": 25.922560930252075, "time_total_s": 15294.28909945488, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b23f0430>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 15294.28909945488, "iterations_since_restore": 167, "perf": {"cpu_util_percent": 84.58333333333334, "ram_util_percent": 82.99166666666667}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7025571073804582, "cur_kl_coeff": 0.04334650319030402, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.2633605727919121, "policy_loss": -0.0032570300889866693, "vf_loss": 0.2662676631145317, "vf_explained_var": 0.46207623377678886, "kl": 0.008073089274792139, "entropy": 1.1319279612056792, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 316575.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.3670938461506493, "cur_kl_coeff": 3.493608569429665e-27, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.10151946654089938, "policy_loss": -0.0004322481528602087, "vf_loss": 0.10195171450647875, "vf_explained_var": 0.004428236036704331, "kl": 0.012758533172067968, "entropy": 0.8553396000748589, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 316575.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 672000, "num_env_steps_trained": 672000, "num_agent_steps_sampled": 2688000, "num_agent_steps_trained": 2688000}, "env_runners": {"episode_reward_max": 399.1, "episode_reward_min": 340.1, "episode_reward_mean": 376.974, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 150.2, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 18.0}, "policy_reward_mean": {"prey_policy": 185.46200000000002, "predator_policy": 3.025}, "custom_metrics": {}, "hist_stats": {"episode_reward": [398.2, 376.9, 387.0, 377.2, 372.1, 361.3, 387.1, 369.4, 358.3, 363.3, 368.5, 359.6, 381.1, 387.1, 398.2, 377.5, 384.6, 381.1, 386.20000000000005, 342.5, 378.0, 340.1, 393.7, 383.9, 363.8, 390.1, 352.9, 354.0, 388.1, 389.2, 390.1, 372.0, 381.8, 367.4, 386.4, 381.0, 399.1, 356.4, 383.0, 356.8, 392.8, 396.4, 385.6, 377.7, 389.3, 389.0, 378.6, 390.1, 397.3, 383.9, 379.7, 380.5, 369.7, 377.5, 360.1, 379.2, 348.9, 360.6, 363.1, 370.2, 369.9, 369.6, 392.2, 395.5, 367.5, 377.5, 379.7, 359.5, 382.0, 397.3, 394.6, 366.4000000000001, 364.2, 357.0, 369.5, 369.5, 353.2, 373.4, 382.6, 371.0, 399.1, 398.2, 348.1, 391.3, 358.3, 389.3, 383.7, 372.7, 372.1, 389.5, 396.40000000000003, 390.8, 380.2, 381.3, 355.3, 388.2, 363.7, 387.9, 372.1, 391.9], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [198.2, 200.0, 182.0, 191.9, 194.0, 191.0, 182.0, 189.2, 190.1, 173.0, 175.7, 185.6, 181.1, 200.0, 178.4, 191.0, 150.2, 193.1, 175.1, 180.2, 194.6, 173.9, 150.2, 196.4, 189.2, 191.9, 200.0, 181.1, 199.1, 199.1, 191.9, 185.6, 185.0, 194.6, 175.1, 191.0, 198.2, 182.0, 159.5, 161.0, 176.0, 194.0, 167.0, 154.1, 193.7, 200.0, 194.0, 185.9, 170.9, 191.9, 193.7, 196.4, 170.89999999999998, 164.0, 167.6, 172.4, 187.1, 200.0, 197.3, 191.9, 200.0, 190.1, 189.2, 177.8, 177.5, 197.3, 187.4, 170.0, 181.4, 200.0, 176.0, 197.0, 200.0, 199.1, 178.4, 167.0, 191.0, 176.0, 171.2, 176.6, 200.0, 192.8, 200.0, 196.4, 185.6, 200.0, 193.7, 176.0, 188.0, 197.3, 179.0, 200.0, 195.5, 169.1, 194.6, 195.5, 197.3, 200.0, 188.0, 191.9, 193.1, 182.6, 191.0, 186.5, 164.0, 193.7, 185.6, 191.9, 173.89999999999998, 177.2, 189.2, 185.0, 169.1, 171.8, 167.0, 182.6, 167.6, 186.5, 176.0, 183.2, 177.5, 181.4, 174.2, 187.4, 198.2, 191.0, 195.5, 200.0, 200.0, 153.5, 191.0, 186.5, 172.7, 200.0, 172.1, 187.4, 173.0, 200.0, 200.0, 197.3, 199.1, 195.5, 185.6, 174.79999999999998, 194.59999999999997, 161.6, 155.0, 179.0, 174.5, 191.0, 180.8, 184.7, 164.0, 171.2, 189.5, 176.9, 188.0, 188.6, 183.2, 177.79999999999998, 200.0, 199.1, 200.0, 198.2, 156.5, 176.6, 200.0, 188.3, 176.3, 167.0, 197.3, 188.0, 185.0, 193.7, 191.6, 175.1, 200.0, 172.1, 186.5, 200.0, 199.1, 197.29999999999998, 197.0, 192.8, 188.3, 191.9, 200.0, 173.3, 159.5, 183.8, 200.0, 183.2, 155.9, 192.8, 194.0, 191.9, 183.2, 179.9, 191.9, 200.0], "policy_predator_policy_reward": [0.0, 0.0, 3.0, 0.0, 2.0, 0.0, 6.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 15.0, 8.0, 0.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 9.0, 6.0, 0.0, 6.0, 5.0, 17.0, 0.0, 8.0, 6.0, 13.0, 0.0, 0.0, 2.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 18.0, 14.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 4.0, 3.0, 0.0, 10.0, 5.0, 0.0, 8.0, 0.0, 0.0, 0.0, 8.0, 3.0, 8.0, 8.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 4.0, 0.0, 5.0, 5.0, 8.0, 6.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 4.0, 0.0, 0.0, 3.0, 0.0, 12.0, 0.0, 0.0, 9.0, 0.0, 0.0, 5.0, 8.0, 0.0, 0.0, 11.0, 0.0, 9.0, 11.0, 0.0, 11.0, 0.0, 0.0, 8.0, 3.0, 0.0, 0.0, 0.0, 7.0, 7.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 8.0, 8.0, 15.0, 0.0, 4.0, 4.0, 0.0, 4.0, 14.0, 7.0, 0.0, 4.0, 2.0, 5.0, 5.0, 0.0, 0.0, 0.0, 0.0, 7.0, 8.0, 0.0, 3.0, 0.0, 15.0, 0.0, 4.0, 5.0, 0.0, 5.0, 1.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 8.0, 8.0, 4.0, 5.0, 0.0, 6.0, 9.0, 0.0, 2.0, 4.0, 5.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 10.83480405754948, "mean_inference_ms": 26.611675269599345, "mean_action_processing_ms": 5.252929164865799, "mean_env_wait_ms": 6.524884266990539, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.016817450523376465, "StateBufferConnector_ms": 0.006927490234375, "ViewRequirementAgentConnector_ms": 0.38010382652282715}, "num_episodes": 18, "episode_return_max": 399.1, "episode_return_min": 340.1, "episode_return_mean": 376.974, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2688000, "num_agent_steps_trained": 2688000, "num_env_steps_sampled": 672000, "num_env_steps_trained": 672000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 153.67804807557567, "num_env_steps_trained_throughput_per_sec": 153.67804807557567, "timesteps_total": 672000, "num_env_steps_sampled_lifetime": 672000, "num_agent_steps_sampled_lifetime": 2688000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2688000, "timers": {"training_iteration_time_ms": 25933.433, "restore_workers_time_ms": 0.019, "training_step_time_ms": 25933.369, "sample_time_ms": 3997.184, "learn_time_ms": 21899.24, "learn_throughput": 182.655, "synch_weights_time_ms": 32.485}, "counters": {"num_env_steps_sampled": 672000, "num_env_steps_trained": 672000, "num_agent_steps_sampled": 2688000, "num_agent_steps_trained": 2688000}, "done": false, "training_iteration": 168, "trial_id": "75ec3_00000", "date": "2024-08-13_05-49-33", "timestamp": 1723542573, "time_this_iter_s": 26.100952863693237, "time_total_s": 15320.390052318573, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b24958b0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 15320.390052318573, "iterations_since_restore": 168, "perf": {"cpu_util_percent": 83.87297297297297, "ram_util_percent": 83.24054054054054}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.679082590302147, "cur_kl_coeff": 0.04334650319030402, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.3534750912733322, "policy_loss": -0.002316272038246983, "vf_loss": 0.3554026601707967, "vf_explained_var": 0.3100836163160031, "kl": 0.008967343456260107, "entropy": 1.118728683171449, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 318465.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.402338529870939, "cur_kl_coeff": 3.493608569429665e-27, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.20927220542555447, "policy_loss": -0.000610796847779836, "vf_loss": 0.20988300236110777, "vf_explained_var": 0.06112174369670727, "kl": 0.005562627742762612, "entropy": 0.7900519201679835, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 318465.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 676000, "num_env_steps_trained": 676000, "num_agent_steps_sampled": 2704000, "num_agent_steps_trained": 2704000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": 345.6, "episode_reward_mean": 378.1140000000001, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 150.5, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 15.0}, "policy_reward_mean": {"prey_policy": 186.107, "predator_policy": 2.95}, "custom_metrics": {}, "hist_stats": {"episode_reward": [354.0, 388.1, 389.2, 390.1, 372.0, 381.8, 367.4, 386.4, 381.0, 399.1, 356.4, 383.0, 356.8, 392.8, 396.4, 385.6, 377.7, 389.3, 389.0, 378.6, 390.1, 397.3, 383.9, 379.7, 380.5, 369.7, 377.5, 360.1, 379.2, 348.9, 360.6, 363.1, 370.2, 369.9, 369.6, 392.2, 395.5, 367.5, 377.5, 379.7, 359.5, 382.0, 397.3, 394.6, 366.4000000000001, 364.2, 357.0, 369.5, 369.5, 353.2, 373.4, 382.6, 371.0, 399.1, 398.2, 348.1, 391.3, 358.3, 389.3, 383.7, 372.7, 372.1, 389.5, 396.40000000000003, 390.8, 380.2, 381.3, 355.3, 388.2, 363.7, 387.9, 372.1, 391.9, 391.3, 367.6, 351.70000000000005, 379.3, 382.9, 399.1, 389.2, 387.4, 400.0, 368.5, 375.2, 380.2, 386.20000000000005, 394.0, 384.7, 389.2, 366.6, 385.5, 370.7, 373.2, 398.2, 386.0, 363.0, 345.6, 356.80000000000007, 397.3, 364.3], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [167.6, 172.4, 187.1, 200.0, 197.3, 191.9, 200.0, 190.1, 189.2, 177.8, 177.5, 197.3, 187.4, 170.0, 181.4, 200.0, 176.0, 197.0, 200.0, 199.1, 178.4, 167.0, 191.0, 176.0, 171.2, 176.6, 200.0, 192.8, 200.0, 196.4, 185.6, 200.0, 193.7, 176.0, 188.0, 197.3, 179.0, 200.0, 195.5, 169.1, 194.6, 195.5, 197.3, 200.0, 188.0, 191.9, 193.1, 182.6, 191.0, 186.5, 164.0, 193.7, 185.6, 191.9, 173.89999999999998, 177.2, 189.2, 185.0, 169.1, 171.8, 167.0, 182.6, 167.6, 186.5, 176.0, 183.2, 177.5, 181.4, 174.2, 187.4, 198.2, 191.0, 195.5, 200.0, 200.0, 153.5, 191.0, 186.5, 172.7, 200.0, 172.1, 187.4, 173.0, 200.0, 200.0, 197.3, 199.1, 195.5, 185.6, 174.79999999999998, 194.59999999999997, 161.6, 155.0, 179.0, 174.5, 191.0, 180.8, 184.7, 164.0, 171.2, 189.5, 176.9, 188.0, 188.6, 183.2, 177.79999999999998, 200.0, 199.1, 200.0, 198.2, 156.5, 176.6, 200.0, 188.3, 176.3, 167.0, 197.3, 188.0, 185.0, 193.7, 191.6, 175.1, 200.0, 172.1, 186.5, 200.0, 199.1, 197.29999999999998, 197.0, 192.8, 188.3, 191.9, 200.0, 173.3, 159.5, 183.8, 200.0, 183.2, 155.9, 192.8, 194.0, 191.9, 183.2, 179.9, 191.9, 200.0, 200.0, 188.3, 150.5, 199.1, 169.7, 161.0, 193.7, 185.6, 200.0, 182.9, 199.1, 200.0, 198.2, 191.0, 191.0, 196.4, 200.0, 200.0, 162.5, 191.0, 197.3, 170.9, 190.1, 190.1, 180.2, 200.0, 200.0, 191.0, 188.3, 196.4, 189.2, 200.0, 158.0, 194.6, 186.5, 194.0, 184.7, 179.0, 187.7, 177.5, 198.2, 200.0, 179.0, 200.0, 175.1, 173.9, 167.3, 167.3, 196.4, 160.4, 197.3, 200.0, 191.9, 160.4], "policy_predator_policy_reward": [14.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 4.0, 3.0, 0.0, 10.0, 5.0, 0.0, 8.0, 0.0, 0.0, 0.0, 8.0, 3.0, 8.0, 8.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 4.0, 0.0, 5.0, 5.0, 8.0, 6.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 4.0, 0.0, 0.0, 3.0, 0.0, 12.0, 0.0, 0.0, 9.0, 0.0, 0.0, 5.0, 8.0, 0.0, 0.0, 11.0, 0.0, 9.0, 11.0, 0.0, 11.0, 0.0, 0.0, 8.0, 3.0, 0.0, 0.0, 0.0, 7.0, 7.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 8.0, 8.0, 15.0, 0.0, 4.0, 4.0, 0.0, 4.0, 14.0, 7.0, 0.0, 4.0, 2.0, 5.0, 5.0, 0.0, 0.0, 0.0, 0.0, 7.0, 8.0, 0.0, 3.0, 0.0, 15.0, 0.0, 4.0, 5.0, 0.0, 5.0, 1.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 8.0, 8.0, 4.0, 5.0, 0.0, 6.0, 9.0, 0.0, 2.0, 4.0, 5.0, 0.0, 0.0, 0.0, 3.0, 7.0, 11.0, 8.0, 13.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 8.0, 0.0, 7.0, 0.0, 0.0, 0.0, 6.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 14.0, 3.0, 2.0, 7.0, 0.0, 1.0, 7.0, 0.0, 0.0, 0.0, 7.0, 0.0, 14.0, 10.0, 1.0, 0.0, 0.0, 0.0, 0.0, 6.0, 6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 11.17580979290238, "mean_inference_ms": 26.03093187806892, "mean_action_processing_ms": 5.224665029871658, "mean_env_wait_ms": 6.359527689908253, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0197218656539917, "StateBufferConnector_ms": 0.007416486740112305, "ViewRequirementAgentConnector_ms": 0.4395558834075928}, "num_episodes": 27, "episode_return_max": 400.0, "episode_return_min": 345.6, "episode_return_mean": 378.1140000000001, "episodes_this_iter": 27}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2704000, "num_agent_steps_trained": 2704000, "num_env_steps_sampled": 676000, "num_env_steps_trained": 676000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 145.1726526417747, "num_env_steps_trained_throughput_per_sec": 145.1726526417747, "timesteps_total": 676000, "num_env_steps_sampled_lifetime": 676000, "num_agent_steps_sampled_lifetime": 2704000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2704000, "timers": {"training_iteration_time_ms": 26203.038, "restore_workers_time_ms": 0.019, "training_step_time_ms": 26202.972, "sample_time_ms": 4130.92, "learn_time_ms": 22032.748, "learn_throughput": 181.548, "synch_weights_time_ms": 35.036}, "counters": {"num_env_steps_sampled": 676000, "num_env_steps_trained": 676000, "num_agent_steps_sampled": 2704000, "num_agent_steps_trained": 2704000}, "done": false, "training_iteration": 169, "trial_id": "75ec3_00000", "date": "2024-08-13_05-50-01", "timestamp": 1723542601, "time_this_iter_s": 27.641263008117676, "time_total_s": 15348.03131532669, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2515f70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 15348.03131532669, "iterations_since_restore": 169, "perf": {"cpu_util_percent": 86.17435897435898, "ram_util_percent": 82.98205128205129}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8583708542837667, "cur_kl_coeff": 0.04334650319030402, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.28566140687495356, "policy_loss": -0.0037357526928649613, "vf_loss": 0.28905368475834764, "vf_explained_var": 0.48945885688539537, "kl": 0.007923947699550302, "entropy": 1.1736099106294138, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 320355.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.2612955907093627, "cur_kl_coeff": 3.493608569429665e-27, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.08851500539498394, "policy_loss": 5.551038566168654e-05, "vf_loss": 0.08845949562780174, "vf_explained_var": -0.053111095182479376, "kl": 0.0025769893787130644, "entropy": 0.7594597070620804, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 320355.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 680000, "num_env_steps_trained": 680000, "num_agent_steps_sampled": 2720000, "num_agent_steps_trained": 2720000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": 345.6, "episode_reward_mean": 378.2059999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 150.5, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 15.0}, "policy_reward_mean": {"prey_policy": 186.293, "predator_policy": 2.81}, "custom_metrics": {}, "hist_stats": {"episode_reward": [389.0, 378.6, 390.1, 397.3, 383.9, 379.7, 380.5, 369.7, 377.5, 360.1, 379.2, 348.9, 360.6, 363.1, 370.2, 369.9, 369.6, 392.2, 395.5, 367.5, 377.5, 379.7, 359.5, 382.0, 397.3, 394.6, 366.4000000000001, 364.2, 357.0, 369.5, 369.5, 353.2, 373.4, 382.6, 371.0, 399.1, 398.2, 348.1, 391.3, 358.3, 389.3, 383.7, 372.7, 372.1, 389.5, 396.40000000000003, 390.8, 380.2, 381.3, 355.3, 388.2, 363.7, 387.9, 372.1, 391.9, 391.3, 367.6, 351.70000000000005, 379.3, 382.9, 399.1, 389.2, 387.4, 400.0, 368.5, 375.2, 380.2, 386.20000000000005, 394.0, 384.7, 389.2, 366.6, 385.5, 370.7, 373.2, 398.2, 386.0, 363.0, 345.6, 356.80000000000007, 397.3, 364.3, 382.2, 379.0, 386.5, 355.8, 388.6, 385.6, 382.9, 358.6, 386.4, 346.8, 396.4, 380.2, 400.0, 400.0, 380.6, 379.0, 391.1, 376.6], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [179.0, 200.0, 195.5, 169.1, 194.6, 195.5, 197.3, 200.0, 188.0, 191.9, 193.1, 182.6, 191.0, 186.5, 164.0, 193.7, 185.6, 191.9, 173.89999999999998, 177.2, 189.2, 185.0, 169.1, 171.8, 167.0, 182.6, 167.6, 186.5, 176.0, 183.2, 177.5, 181.4, 174.2, 187.4, 198.2, 191.0, 195.5, 200.0, 200.0, 153.5, 191.0, 186.5, 172.7, 200.0, 172.1, 187.4, 173.0, 200.0, 200.0, 197.3, 199.1, 195.5, 185.6, 174.79999999999998, 194.59999999999997, 161.6, 155.0, 179.0, 174.5, 191.0, 180.8, 184.7, 164.0, 171.2, 189.5, 176.9, 188.0, 188.6, 183.2, 177.79999999999998, 200.0, 199.1, 200.0, 198.2, 156.5, 176.6, 200.0, 188.3, 176.3, 167.0, 197.3, 188.0, 185.0, 193.7, 191.6, 175.1, 200.0, 172.1, 186.5, 200.0, 199.1, 197.29999999999998, 197.0, 192.8, 188.3, 191.9, 200.0, 173.3, 159.5, 183.8, 200.0, 183.2, 155.9, 192.8, 194.0, 191.9, 183.2, 179.9, 191.9, 200.0, 200.0, 188.3, 150.5, 199.1, 169.7, 161.0, 193.7, 185.6, 200.0, 182.9, 199.1, 200.0, 198.2, 191.0, 191.0, 196.4, 200.0, 200.0, 162.5, 191.0, 197.3, 170.9, 190.1, 190.1, 180.2, 200.0, 200.0, 191.0, 188.3, 196.4, 189.2, 200.0, 158.0, 194.6, 186.5, 194.0, 184.7, 179.0, 187.7, 177.5, 198.2, 200.0, 179.0, 200.0, 175.1, 173.9, 167.3, 167.3, 196.4, 160.4, 197.3, 200.0, 191.9, 160.4, 198.2, 176.0, 191.0, 182.0, 195.5, 191.0, 158.0, 183.8, 185.6, 200.0, 186.5, 199.1, 184.7, 198.2, 191.0, 167.6, 196.4, 185.0, 167.0, 168.8, 199.1, 197.3, 193.7, 186.5, 200.0, 200.0, 200.0, 200.0, 176.6, 197.0, 182.0, 191.0, 199.1, 182.0, 182.9, 193.7], "policy_predator_policy_reward": [5.0, 5.0, 8.0, 6.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 4.0, 0.0, 0.0, 3.0, 0.0, 12.0, 0.0, 0.0, 9.0, 0.0, 0.0, 5.0, 8.0, 0.0, 0.0, 11.0, 0.0, 9.0, 11.0, 0.0, 11.0, 0.0, 0.0, 8.0, 3.0, 0.0, 0.0, 0.0, 7.0, 7.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 8.0, 8.0, 15.0, 0.0, 4.0, 4.0, 0.0, 4.0, 14.0, 7.0, 0.0, 4.0, 2.0, 5.0, 5.0, 0.0, 0.0, 0.0, 0.0, 7.0, 8.0, 0.0, 3.0, 0.0, 15.0, 0.0, 4.0, 5.0, 0.0, 5.0, 1.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 8.0, 8.0, 4.0, 5.0, 0.0, 6.0, 9.0, 0.0, 2.0, 4.0, 5.0, 0.0, 0.0, 0.0, 3.0, 7.0, 11.0, 8.0, 13.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 8.0, 0.0, 7.0, 0.0, 0.0, 0.0, 6.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 14.0, 3.0, 2.0, 7.0, 0.0, 1.0, 7.0, 0.0, 0.0, 0.0, 7.0, 0.0, 14.0, 10.0, 1.0, 0.0, 0.0, 0.0, 0.0, 6.0, 6.0, 8.0, 0.0, 0.0, 6.0, 0.0, 0.0, 14.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 2.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 6.0, 6.0, 0.0, 4.0, 6.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 10.72329712366455, "mean_inference_ms": 26.340100894592855, "mean_action_processing_ms": 5.195168284850504, "mean_env_wait_ms": 6.450164373698135, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0196152925491333, "StateBufferConnector_ms": 0.007489681243896484, "ViewRequirementAgentConnector_ms": 0.4167945384979248}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": 345.6, "episode_return_mean": 378.2059999999999, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2720000, "num_agent_steps_trained": 2720000, "num_env_steps_sampled": 680000, "num_env_steps_trained": 680000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 144.14896925835336, "num_env_steps_trained_throughput_per_sec": 144.14896925835336, "timesteps_total": 680000, "num_env_steps_sampled_lifetime": 680000, "num_agent_steps_sampled_lifetime": 2720000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2720000, "timers": {"training_iteration_time_ms": 26472.631, "restore_workers_time_ms": 0.021, "training_step_time_ms": 26472.56, "sample_time_ms": 4155.186, "learn_time_ms": 22277.632, "learn_throughput": 179.552, "synch_weights_time_ms": 35.525}, "counters": {"num_env_steps_sampled": 680000, "num_env_steps_trained": 680000, "num_agent_steps_sampled": 2720000, "num_agent_steps_trained": 2720000}, "done": false, "training_iteration": 170, "trial_id": "75ec3_00000", "date": "2024-08-13_05-50-29", "timestamp": 1723542629, "time_this_iter_s": 27.795231103897095, "time_total_s": 15375.826546430588, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2495ca0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 15375.826546430588, "iterations_since_restore": 170, "perf": {"cpu_util_percent": 86.13000000000001, "ram_util_percent": 83.16499999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4525106698629402, "cur_kl_coeff": 0.04334650319030402, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.20669825522933727, "policy_loss": -0.0057331084265132195, "vf_loss": 0.21168719931559823, "vf_explained_var": 0.2879837639117367, "kl": 0.017167794480824245, "entropy": 1.1055082029766508, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 322245.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.2875326632270737, "cur_kl_coeff": 1.7468042847148327e-27, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.13753542466453775, "policy_loss": -0.00058726781311509, "vf_loss": 0.13812269198806174, "vf_explained_var": -0.005439730359132959, "kl": 0.010165824609680794, "entropy": 0.696373160080935, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 322245.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 684000, "num_env_steps_trained": 684000, "num_agent_steps_sampled": 2736000, "num_agent_steps_trained": 2736000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": 345.6, "episode_reward_mean": 379.958, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 150.5, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 17.0}, "policy_reward_mean": {"prey_policy": 187.424, "predator_policy": 2.555}, "custom_metrics": {}, "hist_stats": {"episode_reward": [395.5, 367.5, 377.5, 379.7, 359.5, 382.0, 397.3, 394.6, 366.4000000000001, 364.2, 357.0, 369.5, 369.5, 353.2, 373.4, 382.6, 371.0, 399.1, 398.2, 348.1, 391.3, 358.3, 389.3, 383.7, 372.7, 372.1, 389.5, 396.40000000000003, 390.8, 380.2, 381.3, 355.3, 388.2, 363.7, 387.9, 372.1, 391.9, 391.3, 367.6, 351.70000000000005, 379.3, 382.9, 399.1, 389.2, 387.4, 400.0, 368.5, 375.2, 380.2, 386.20000000000005, 394.0, 384.7, 389.2, 366.6, 385.5, 370.7, 373.2, 398.2, 386.0, 363.0, 345.6, 356.80000000000007, 397.3, 364.3, 382.2, 379.0, 386.5, 355.8, 388.6, 385.6, 382.9, 358.6, 386.4, 346.8, 396.4, 380.2, 400.0, 400.0, 380.6, 379.0, 391.1, 376.6, 387.9, 366.6, 393.7, 400.0, 391.0, 384.4, 392.2, 376.8, 391.0, 396.2, 378.0, 392.8, 395.5, 360.2, 355.8, 395.5, 394.0, 383.7], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [195.5, 200.0, 200.0, 153.5, 191.0, 186.5, 172.7, 200.0, 172.1, 187.4, 173.0, 200.0, 200.0, 197.3, 199.1, 195.5, 185.6, 174.79999999999998, 194.59999999999997, 161.6, 155.0, 179.0, 174.5, 191.0, 180.8, 184.7, 164.0, 171.2, 189.5, 176.9, 188.0, 188.6, 183.2, 177.79999999999998, 200.0, 199.1, 200.0, 198.2, 156.5, 176.6, 200.0, 188.3, 176.3, 167.0, 197.3, 188.0, 185.0, 193.7, 191.6, 175.1, 200.0, 172.1, 186.5, 200.0, 199.1, 197.29999999999998, 197.0, 192.8, 188.3, 191.9, 200.0, 173.3, 159.5, 183.8, 200.0, 183.2, 155.9, 192.8, 194.0, 191.9, 183.2, 179.9, 191.9, 200.0, 200.0, 188.3, 150.5, 199.1, 169.7, 161.0, 193.7, 185.6, 200.0, 182.9, 199.1, 200.0, 198.2, 191.0, 191.0, 196.4, 200.0, 200.0, 162.5, 191.0, 197.3, 170.9, 190.1, 190.1, 180.2, 200.0, 200.0, 191.0, 188.3, 196.4, 189.2, 200.0, 158.0, 194.6, 186.5, 194.0, 184.7, 179.0, 187.7, 177.5, 198.2, 200.0, 179.0, 200.0, 175.1, 173.9, 167.3, 167.3, 196.4, 160.4, 197.3, 200.0, 191.9, 160.4, 198.2, 176.0, 191.0, 182.0, 195.5, 191.0, 158.0, 183.8, 185.6, 200.0, 186.5, 199.1, 184.7, 198.2, 191.0, 167.6, 196.4, 185.0, 167.0, 168.8, 199.1, 197.3, 193.7, 186.5, 200.0, 200.0, 200.0, 200.0, 176.6, 197.0, 182.0, 191.0, 199.1, 182.0, 182.9, 193.7, 191.9, 194.0, 180.2, 178.4, 200.0, 193.7, 200.0, 200.0, 191.0, 200.0, 180.2, 198.2, 200.0, 189.2, 192.8, 176.0, 200.0, 191.0, 198.2, 197.0, 184.7, 191.3, 192.8, 200.0, 200.0, 195.5, 192.8, 151.4, 171.8, 167.0, 195.5, 200.0, 200.0, 191.0, 185.0, 193.7], "policy_predator_policy_reward": [0.0, 0.0, 7.0, 7.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 8.0, 8.0, 15.0, 0.0, 4.0, 4.0, 0.0, 4.0, 14.0, 7.0, 0.0, 4.0, 2.0, 5.0, 5.0, 0.0, 0.0, 0.0, 0.0, 7.0, 8.0, 0.0, 3.0, 0.0, 15.0, 0.0, 4.0, 5.0, 0.0, 5.0, 1.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 8.0, 8.0, 4.0, 5.0, 0.0, 6.0, 9.0, 0.0, 2.0, 4.0, 5.0, 0.0, 0.0, 0.0, 3.0, 7.0, 11.0, 8.0, 13.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 8.0, 0.0, 7.0, 0.0, 0.0, 0.0, 6.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 14.0, 3.0, 2.0, 7.0, 0.0, 1.0, 7.0, 0.0, 0.0, 0.0, 7.0, 0.0, 14.0, 10.0, 1.0, 0.0, 0.0, 0.0, 0.0, 6.0, 6.0, 8.0, 0.0, 0.0, 6.0, 0.0, 0.0, 14.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 2.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 6.0, 6.0, 0.0, 4.0, 6.0, 0.0, 0.0, 0.0, 2.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 3.0, 0.0, 8.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 10.0, 6.0, 17.0, 0.0, 0.0, 0.0, 3.0, 0.0, 2.0, 3.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 10.677300589398067, "mean_inference_ms": 26.2307900697125, "mean_action_processing_ms": 5.171787458555834, "mean_env_wait_ms": 6.419593017694692, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.022977113723754883, "StateBufferConnector_ms": 0.007482409477233887, "ViewRequirementAgentConnector_ms": 0.39629316329956055}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": 345.6, "episode_return_mean": 379.958, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2736000, "num_agent_steps_trained": 2736000, "num_env_steps_sampled": 684000, "num_env_steps_trained": 684000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 148.0681429115511, "num_env_steps_trained_throughput_per_sec": 148.0681429115511, "timesteps_total": 684000, "num_env_steps_sampled_lifetime": 684000, "num_agent_steps_sampled_lifetime": 2736000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2736000, "timers": {"training_iteration_time_ms": 26428.142, "restore_workers_time_ms": 0.021, "training_step_time_ms": 26428.073, "sample_time_ms": 4178.037, "learn_time_ms": 22211.443, "learn_throughput": 180.087, "synch_weights_time_ms": 34.728}, "counters": {"num_env_steps_sampled": 684000, "num_env_steps_trained": 684000, "num_agent_steps_sampled": 2736000, "num_agent_steps_trained": 2736000}, "done": false, "training_iteration": 171, "trial_id": "75ec3_00000", "date": "2024-08-13_05-50-56", "timestamp": 1723542656, "time_this_iter_s": 27.089941024780273, "time_total_s": 15402.916487455368, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b23f0160>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 15402.916487455368, "iterations_since_restore": 171, "perf": {"cpu_util_percent": 83.1657894736842, "ram_util_percent": 83.11578947368423}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8484319414884325, "cur_kl_coeff": 0.04334650319030402, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.5212919658271684, "policy_loss": -0.00386139516713758, "vf_loss": 0.5248224345977028, "vf_explained_var": 0.23522412534113282, "kl": 0.007634434858284766, "entropy": 1.1150889329178624, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 324135.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5475407409092421, "cur_kl_coeff": 1.7468042847148327e-27, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.3156875937270424, "policy_loss": -0.0014516333270837706, "vf_loss": 0.3171392268975507, "vf_explained_var": 0.0970948264081642, "kl": 0.013048203602061638, "entropy": 0.6832155828122739, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 324135.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 688000, "num_env_steps_trained": 688000, "num_agent_steps_sampled": 2752000, "num_agent_steps_trained": 2752000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": 309.0, "episode_reward_mean": 378.85299999999995, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 103.4, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 31.0}, "policy_reward_mean": {"prey_policy": 186.66649999999998, "predator_policy": 2.76}, "custom_metrics": {}, "hist_stats": {"episode_reward": [398.2, 348.1, 391.3, 358.3, 389.3, 383.7, 372.7, 372.1, 389.5, 396.40000000000003, 390.8, 380.2, 381.3, 355.3, 388.2, 363.7, 387.9, 372.1, 391.9, 391.3, 367.6, 351.70000000000005, 379.3, 382.9, 399.1, 389.2, 387.4, 400.0, 368.5, 375.2, 380.2, 386.20000000000005, 394.0, 384.7, 389.2, 366.6, 385.5, 370.7, 373.2, 398.2, 386.0, 363.0, 345.6, 356.80000000000007, 397.3, 364.3, 382.2, 379.0, 386.5, 355.8, 388.6, 385.6, 382.9, 358.6, 386.4, 346.8, 396.4, 380.2, 400.0, 400.0, 380.6, 379.0, 391.1, 376.6, 387.9, 366.6, 393.7, 400.0, 391.0, 384.4, 392.2, 376.8, 391.0, 396.2, 378.0, 392.8, 395.5, 360.2, 355.8, 395.5, 394.0, 383.7, 393.7, 361.7, 384.0, 373.3, 386.0, 400.0, 390.1, 383.4, 320.2, 361.9, 380.2, 373.2, 391.3, 365.6, 362.6, 309.0, 388.3, 324.5], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [200.0, 198.2, 156.5, 176.6, 200.0, 188.3, 176.3, 167.0, 197.3, 188.0, 185.0, 193.7, 191.6, 175.1, 200.0, 172.1, 186.5, 200.0, 199.1, 197.29999999999998, 197.0, 192.8, 188.3, 191.9, 200.0, 173.3, 159.5, 183.8, 200.0, 183.2, 155.9, 192.8, 194.0, 191.9, 183.2, 179.9, 191.9, 200.0, 200.0, 188.3, 150.5, 199.1, 169.7, 161.0, 193.7, 185.6, 200.0, 182.9, 199.1, 200.0, 198.2, 191.0, 191.0, 196.4, 200.0, 200.0, 162.5, 191.0, 197.3, 170.9, 190.1, 190.1, 180.2, 200.0, 200.0, 191.0, 188.3, 196.4, 189.2, 200.0, 158.0, 194.6, 186.5, 194.0, 184.7, 179.0, 187.7, 177.5, 198.2, 200.0, 179.0, 200.0, 175.1, 173.9, 167.3, 167.3, 196.4, 160.4, 197.3, 200.0, 191.9, 160.4, 198.2, 176.0, 191.0, 182.0, 195.5, 191.0, 158.0, 183.8, 185.6, 200.0, 186.5, 199.1, 184.7, 198.2, 191.0, 167.6, 196.4, 185.0, 167.0, 168.8, 199.1, 197.3, 193.7, 186.5, 200.0, 200.0, 200.0, 200.0, 176.6, 197.0, 182.0, 191.0, 199.1, 182.0, 182.9, 193.7, 191.9, 194.0, 180.2, 178.4, 200.0, 193.7, 200.0, 200.0, 191.0, 200.0, 180.2, 198.2, 200.0, 189.2, 192.8, 176.0, 200.0, 191.0, 198.2, 197.0, 184.7, 191.3, 192.8, 200.0, 200.0, 195.5, 192.8, 151.4, 171.8, 167.0, 195.5, 200.0, 200.0, 191.0, 185.0, 193.7, 196.4, 197.3, 179.6, 166.1, 176.0, 200.0, 173.0, 188.3, 173.0, 200.0, 200.0, 200.0, 199.1, 191.0, 196.4, 185.0, 150.2, 152.0, 173.0, 182.9, 194.6, 185.6, 176.0, 189.2, 200.0, 188.3, 187.7, 167.9, 184.7, 170.9, 146.0, 140.0, 198.2, 190.1, 190.1, 103.4], "policy_predator_policy_reward": [0.0, 0.0, 7.0, 8.0, 0.0, 3.0, 0.0, 15.0, 0.0, 4.0, 5.0, 0.0, 5.0, 1.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 8.0, 8.0, 4.0, 5.0, 0.0, 6.0, 9.0, 0.0, 2.0, 4.0, 5.0, 0.0, 0.0, 0.0, 3.0, 7.0, 11.0, 8.0, 13.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 8.0, 0.0, 7.0, 0.0, 0.0, 0.0, 6.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 14.0, 3.0, 2.0, 7.0, 0.0, 1.0, 7.0, 0.0, 0.0, 0.0, 7.0, 0.0, 14.0, 10.0, 1.0, 0.0, 0.0, 0.0, 0.0, 6.0, 6.0, 8.0, 0.0, 0.0, 6.0, 0.0, 0.0, 14.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 2.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 6.0, 6.0, 0.0, 4.0, 6.0, 0.0, 0.0, 0.0, 2.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 3.0, 0.0, 8.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 10.0, 6.0, 17.0, 0.0, 0.0, 0.0, 3.0, 0.0, 2.0, 3.0, 0.0, 0.0, 11.0, 5.0, 0.0, 8.0, 1.0, 11.0, 7.0, 6.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 10.0, 8.0, 0.0, 6.0, 0.0, 0.0, 0.0, 8.0, 3.0, 0.0, 2.0, 8.0, 7.0, 0.0, 11.0, 12.0, 0.0, 0.0, 31.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 10.630686238958338, "mean_inference_ms": 26.12078251695466, "mean_action_processing_ms": 5.148357682304197, "mean_env_wait_ms": 6.389030068765803, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.018190860748291016, "StateBufferConnector_ms": 0.006942152976989746, "ViewRequirementAgentConnector_ms": 0.3622215986251831}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": 309.0, "episode_return_mean": 378.85299999999995, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2752000, "num_agent_steps_trained": 2752000, "num_env_steps_sampled": 688000, "num_env_steps_trained": 688000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 142.76566576660585, "num_env_steps_trained_throughput_per_sec": 142.76566576660585, "timesteps_total": 688000, "num_env_steps_sampled_lifetime": 688000, "num_agent_steps_sampled_lifetime": 2752000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2752000, "timers": {"training_iteration_time_ms": 26646.111, "restore_workers_time_ms": 0.021, "training_step_time_ms": 26646.04, "sample_time_ms": 4213.785, "learn_time_ms": 22393.072, "learn_throughput": 178.627, "synch_weights_time_ms": 35.61}, "counters": {"num_env_steps_sampled": 688000, "num_env_steps_trained": 688000, "num_agent_steps_sampled": 2752000, "num_agent_steps_trained": 2752000}, "done": false, "training_iteration": 172, "trial_id": "75ec3_00000", "date": "2024-08-13_05-51-24", "timestamp": 1723542684, "time_this_iter_s": 28.10849690437317, "time_total_s": 15431.024984359741, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b256d280>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 15431.024984359741, "iterations_since_restore": 172, "perf": {"cpu_util_percent": 83.47, "ram_util_percent": 83.3775}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.186162847643176, "cur_kl_coeff": 0.04334650319030402, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.6586619882302349, "policy_loss": -0.0036784519578167605, "vf_loss": 0.6618724927818649, "vf_explained_var": 0.24557402007794255, "kl": 0.010795479894911789, "entropy": 1.162429374992532, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 326025.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5962931942963411, "cur_kl_coeff": 1.7468042847148327e-27, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.27403886683245815, "policy_loss": -0.0019548255105123476, "vf_loss": 0.2759936927108183, "vf_explained_var": 0.048710441810113414, "kl": 0.012511055565897985, "entropy": 0.6139201278093631, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 326025.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 692000, "num_env_steps_trained": 692000, "num_agent_steps_sampled": 2768000, "num_agent_steps_trained": 2768000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": 309.0, "episode_reward_mean": 377.685, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 103.4, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 31.0}, "policy_reward_mean": {"prey_policy": 185.8475, "predator_policy": 2.995}, "custom_metrics": {}, "hist_stats": {"episode_reward": [382.9, 399.1, 389.2, 387.4, 400.0, 368.5, 375.2, 380.2, 386.20000000000005, 394.0, 384.7, 389.2, 366.6, 385.5, 370.7, 373.2, 398.2, 386.0, 363.0, 345.6, 356.80000000000007, 397.3, 364.3, 382.2, 379.0, 386.5, 355.8, 388.6, 385.6, 382.9, 358.6, 386.4, 346.8, 396.4, 380.2, 400.0, 400.0, 380.6, 379.0, 391.1, 376.6, 387.9, 366.6, 393.7, 400.0, 391.0, 384.4, 392.2, 376.8, 391.0, 396.2, 378.0, 392.8, 395.5, 360.2, 355.8, 395.5, 394.0, 383.7, 393.7, 361.7, 384.0, 373.3, 386.0, 400.0, 390.1, 383.4, 320.2, 361.9, 380.2, 373.2, 391.3, 365.6, 362.6, 309.0, 388.3, 324.5, 394.6, 373.4, 329.5, 363.2, 387.0, 381.8, 390.1, 344.0, 376.4, 353.9, 389.20000000000005, 346.4, 369.1, 384.8, 381.2, 384.1, 380.2, 337.3, 389.2, 359.3, 398.2, 372.1, 399.1], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [200.0, 182.9, 199.1, 200.0, 198.2, 191.0, 191.0, 196.4, 200.0, 200.0, 162.5, 191.0, 197.3, 170.9, 190.1, 190.1, 180.2, 200.0, 200.0, 191.0, 188.3, 196.4, 189.2, 200.0, 158.0, 194.6, 186.5, 194.0, 184.7, 179.0, 187.7, 177.5, 198.2, 200.0, 179.0, 200.0, 175.1, 173.9, 167.3, 167.3, 196.4, 160.4, 197.3, 200.0, 191.9, 160.4, 198.2, 176.0, 191.0, 182.0, 195.5, 191.0, 158.0, 183.8, 185.6, 200.0, 186.5, 199.1, 184.7, 198.2, 191.0, 167.6, 196.4, 185.0, 167.0, 168.8, 199.1, 197.3, 193.7, 186.5, 200.0, 200.0, 200.0, 200.0, 176.6, 197.0, 182.0, 191.0, 199.1, 182.0, 182.9, 193.7, 191.9, 194.0, 180.2, 178.4, 200.0, 193.7, 200.0, 200.0, 191.0, 200.0, 180.2, 198.2, 200.0, 189.2, 192.8, 176.0, 200.0, 191.0, 198.2, 197.0, 184.7, 191.3, 192.8, 200.0, 200.0, 195.5, 192.8, 151.4, 171.8, 167.0, 195.5, 200.0, 200.0, 191.0, 185.0, 193.7, 196.4, 197.3, 179.6, 166.1, 176.0, 200.0, 173.0, 188.3, 173.0, 200.0, 200.0, 200.0, 199.1, 191.0, 196.4, 185.0, 150.2, 152.0, 173.0, 182.9, 194.6, 185.6, 176.0, 189.2, 200.0, 188.3, 187.7, 167.9, 184.7, 170.9, 146.0, 140.0, 198.2, 190.1, 190.1, 103.4, 194.6, 200.0, 187.4, 179.0, 145.7, 156.8, 188.0, 162.2, 200.0, 161.0, 192.5, 188.3, 197.3, 192.8, 173.0, 155.0, 195.5, 179.9, 181.1, 156.8, 197.29999999999998, 191.9, 167.0, 148.39999999999998, 199.1, 155.0, 200.0, 180.8, 189.2, 188.0, 190.1, 191.0, 195.5, 184.7, 155.0, 164.3, 189.2, 200.0, 167.3, 182.0, 200.0, 198.2, 181.1, 191.0, 199.1, 200.0], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 8.0, 0.0, 7.0, 0.0, 0.0, 0.0, 6.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 14.0, 3.0, 2.0, 7.0, 0.0, 1.0, 7.0, 0.0, 0.0, 0.0, 7.0, 0.0, 14.0, 10.0, 1.0, 0.0, 0.0, 0.0, 0.0, 6.0, 6.0, 8.0, 0.0, 0.0, 6.0, 0.0, 0.0, 14.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 2.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 6.0, 6.0, 0.0, 4.0, 6.0, 0.0, 0.0, 0.0, 2.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 3.0, 0.0, 8.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 10.0, 6.0, 17.0, 0.0, 0.0, 0.0, 3.0, 0.0, 2.0, 3.0, 0.0, 0.0, 11.0, 5.0, 0.0, 8.0, 1.0, 11.0, 7.0, 6.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 10.0, 8.0, 0.0, 6.0, 0.0, 0.0, 0.0, 8.0, 3.0, 0.0, 2.0, 8.0, 7.0, 0.0, 11.0, 12.0, 0.0, 0.0, 31.0, 0.0, 0.0, 0.0, 0.0, 7.0, 16.0, 11.0, 0.0, 13.0, 13.0, 13.0, 0.0, 1.0, 0.0, 0.0, 16.0, 0.0, 0.0, 1.0, 12.0, 4.0, 0.0, 0.0, 22.0, 9.0, 15.0, 0.0, 0.0, 4.0, 0.0, 4.0, 0.0, 3.0, 0.0, 0.0, 0.0, 18.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 10.571992445852388, "mean_inference_ms": 26.35503608271889, "mean_action_processing_ms": 5.25524756626844, "mean_env_wait_ms": 5.847338050305215, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0193864107131958, "StateBufferConnector_ms": 0.007197022438049316, "ViewRequirementAgentConnector_ms": 0.29104530811309814}, "num_episodes": 23, "episode_return_max": 400.0, "episode_return_min": 309.0, "episode_return_mean": 377.685, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2768000, "num_agent_steps_trained": 2768000, "num_env_steps_sampled": 692000, "num_env_steps_trained": 692000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 163.79212919099191, "num_env_steps_trained_throughput_per_sec": 163.79212919099191, "timesteps_total": 692000, "num_env_steps_sampled_lifetime": 692000, "num_agent_steps_sampled_lifetime": 2768000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2768000, "timers": {"training_iteration_time_ms": 26469.866, "restore_workers_time_ms": 0.022, "training_step_time_ms": 26469.795, "sample_time_ms": 4219.34, "learn_time_ms": 22211.667, "learn_throughput": 180.086, "synch_weights_time_ms": 35.394}, "counters": {"num_env_steps_sampled": 692000, "num_env_steps_trained": 692000, "num_agent_steps_sampled": 2768000, "num_agent_steps_trained": 2768000}, "done": false, "training_iteration": 173, "trial_id": "75ec3_00000", "date": "2024-08-13_05-51-49", "timestamp": 1723542709, "time_this_iter_s": 24.44065499305725, "time_total_s": 15455.465639352798, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b256dee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 15455.465639352798, "iterations_since_restore": 173, "perf": {"cpu_util_percent": 80.61176470588236, "ram_util_percent": 81.5}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4851956602363359, "cur_kl_coeff": 0.04334650319030402, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.3306232410460272, "policy_loss": -0.005259318585463223, "vf_loss": 0.3353001728501151, "vf_explained_var": 0.3055862124004061, "kl": 0.013435604058162902, "entropy": 1.1957331413945194, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 327915.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.515485071382983, "cur_kl_coeff": 1.7468042847148327e-27, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.22915604928971597, "policy_loss": -0.002598632933084099, "vf_loss": 0.23175468300955823, "vf_explained_var": 0.026429081562334897, "kl": 0.012255486060352459, "entropy": 0.5817503403103541, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 327915.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 696000, "num_env_steps_trained": 696000, "num_agent_steps_sampled": 2784000, "num_agent_steps_trained": 2784000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": 309.0, "episode_reward_mean": 376.9459999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 103.4, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 31.0}, "policy_reward_mean": {"prey_policy": 185.138, "predator_policy": 3.335}, "custom_metrics": {}, "hist_stats": {"episode_reward": [364.3, 382.2, 379.0, 386.5, 355.8, 388.6, 385.6, 382.9, 358.6, 386.4, 346.8, 396.4, 380.2, 400.0, 400.0, 380.6, 379.0, 391.1, 376.6, 387.9, 366.6, 393.7, 400.0, 391.0, 384.4, 392.2, 376.8, 391.0, 396.2, 378.0, 392.8, 395.5, 360.2, 355.8, 395.5, 394.0, 383.7, 393.7, 361.7, 384.0, 373.3, 386.0, 400.0, 390.1, 383.4, 320.2, 361.9, 380.2, 373.2, 391.3, 365.6, 362.6, 309.0, 388.3, 324.5, 394.6, 373.4, 329.5, 363.2, 387.0, 381.8, 390.1, 344.0, 376.4, 353.9, 389.20000000000005, 346.4, 369.1, 384.8, 381.2, 384.1, 380.2, 337.3, 389.2, 359.3, 398.2, 372.1, 399.1, 377.3, 392.8, 372.0, 390.0, 399.1, 396.4, 365.0, 373.3, 379.7, 373.2, 388.3, 369.1, 384.7, 376.1, 361.9, 367.9, 361.4, 380.7, 361.0, 378.1, 400.0, 357.6], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [191.9, 160.4, 198.2, 176.0, 191.0, 182.0, 195.5, 191.0, 158.0, 183.8, 185.6, 200.0, 186.5, 199.1, 184.7, 198.2, 191.0, 167.6, 196.4, 185.0, 167.0, 168.8, 199.1, 197.3, 193.7, 186.5, 200.0, 200.0, 200.0, 200.0, 176.6, 197.0, 182.0, 191.0, 199.1, 182.0, 182.9, 193.7, 191.9, 194.0, 180.2, 178.4, 200.0, 193.7, 200.0, 200.0, 191.0, 200.0, 180.2, 198.2, 200.0, 189.2, 192.8, 176.0, 200.0, 191.0, 198.2, 197.0, 184.7, 191.3, 192.8, 200.0, 200.0, 195.5, 192.8, 151.4, 171.8, 167.0, 195.5, 200.0, 200.0, 191.0, 185.0, 193.7, 196.4, 197.3, 179.6, 166.1, 176.0, 200.0, 173.0, 188.3, 173.0, 200.0, 200.0, 200.0, 199.1, 191.0, 196.4, 185.0, 150.2, 152.0, 173.0, 182.9, 194.6, 185.6, 176.0, 189.2, 200.0, 188.3, 187.7, 167.9, 184.7, 170.9, 146.0, 140.0, 198.2, 190.1, 190.1, 103.4, 194.6, 200.0, 187.4, 179.0, 145.7, 156.8, 188.0, 162.2, 200.0, 161.0, 192.5, 188.3, 197.3, 192.8, 173.0, 155.0, 195.5, 179.9, 181.1, 156.8, 197.29999999999998, 191.9, 167.0, 148.39999999999998, 199.1, 155.0, 200.0, 180.8, 189.2, 188.0, 190.1, 191.0, 195.5, 184.7, 155.0, 164.3, 189.2, 200.0, 167.3, 182.0, 200.0, 198.2, 181.1, 191.0, 199.1, 200.0, 200.0, 167.3, 200.0, 192.8, 164.0, 188.0, 200.0, 179.0, 200.0, 199.1, 196.4, 200.0, 170.0, 185.0, 194.6, 166.7, 179.0, 193.7, 174.2, 191.0, 193.7, 194.6, 154.1, 200.0, 191.9, 192.8, 195.5, 173.6, 194.6, 149.3, 177.2, 178.7, 176.0, 172.4, 194.0, 184.7, 179.0, 173.0, 200.0, 172.1, 200.0, 200.0, 169.7, 182.9], "policy_predator_policy_reward": [6.0, 6.0, 8.0, 0.0, 0.0, 6.0, 0.0, 0.0, 14.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 2.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 6.0, 6.0, 0.0, 4.0, 6.0, 0.0, 0.0, 0.0, 2.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 3.0, 0.0, 8.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 10.0, 6.0, 17.0, 0.0, 0.0, 0.0, 3.0, 0.0, 2.0, 3.0, 0.0, 0.0, 11.0, 5.0, 0.0, 8.0, 1.0, 11.0, 7.0, 6.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 10.0, 8.0, 0.0, 6.0, 0.0, 0.0, 0.0, 8.0, 3.0, 0.0, 2.0, 8.0, 7.0, 0.0, 11.0, 12.0, 0.0, 0.0, 31.0, 0.0, 0.0, 0.0, 0.0, 7.0, 16.0, 11.0, 0.0, 13.0, 13.0, 13.0, 0.0, 1.0, 0.0, 0.0, 16.0, 0.0, 0.0, 1.0, 12.0, 4.0, 0.0, 0.0, 22.0, 9.0, 15.0, 0.0, 0.0, 4.0, 0.0, 4.0, 0.0, 3.0, 0.0, 0.0, 0.0, 18.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 12.0, 8.0, 6.0, 5.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 6.0, 6.0, 0.0, 7.0, 0.0, 8.0, 0.0, 0.0, 15.0, 0.0, 0.0, 0.0, 0.0, 7.0, 6.0, 12.0, 5.0, 7.0, 13.0, 0.0, 0.0, 2.0, 9.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 5.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 10.514390576974044, "mean_inference_ms": 25.84808598127773, "mean_action_processing_ms": 5.091132582004945, "mean_env_wait_ms": 6.31345121615068, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.016162872314453125, "StateBufferConnector_ms": 0.007132768630981445, "ViewRequirementAgentConnector_ms": 0.2819387912750244}, "num_episodes": 22, "episode_return_max": 400.0, "episode_return_min": 309.0, "episode_return_mean": 376.9459999999999, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2784000, "num_agent_steps_trained": 2784000, "num_env_steps_sampled": 696000, "num_env_steps_trained": 696000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 198.815524096488, "num_env_steps_trained_throughput_per_sec": 198.815524096488, "timesteps_total": 696000, "num_env_steps_sampled_lifetime": 696000, "num_agent_steps_sampled_lifetime": 2784000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2784000, "timers": {"training_iteration_time_ms": 25943.989, "restore_workers_time_ms": 0.022, "training_step_time_ms": 25943.919, "sample_time_ms": 4180.438, "learn_time_ms": 21724.764, "learn_throughput": 184.122, "synch_weights_time_ms": 35.417}, "counters": {"num_env_steps_sampled": 696000, "num_env_steps_trained": 696000, "num_agent_steps_sampled": 2784000, "num_agent_steps_trained": 2784000}, "done": false, "training_iteration": 174, "trial_id": "75ec3_00000", "date": "2024-08-13_05-52-09", "timestamp": 1723542729, "time_this_iter_s": 20.126746892929077, "time_total_s": 15475.592386245728, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b1ae2280>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 15475.592386245728, "iterations_since_restore": 174, "perf": {"cpu_util_percent": 71.67241379310344, "ram_util_percent": 75.24827586206897}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5659850088298006, "cur_kl_coeff": 0.04334650319030402, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.363768667368546, "policy_loss": -0.004886388608929578, "vf_loss": 0.3683851876936695, "vf_explained_var": 0.29561137314195984, "kl": 0.006225819974006588, "entropy": 1.2260323928777503, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 329805.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5281821088185386, "cur_kl_coeff": 1.7468042847148327e-27, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.17698601072200787, "policy_loss": -0.0005232278391886404, "vf_loss": 0.17750923870785518, "vf_explained_var": 0.12579494743120104, "kl": 0.004187673552510036, "entropy": 0.5598926942026804, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 329805.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 700000, "num_env_steps_trained": 700000, "num_agent_steps_sampled": 2800000, "num_agent_steps_trained": 2800000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": 309.0, "episode_reward_mean": 377.7220000000001, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 103.4, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 31.0}, "policy_reward_mean": {"prey_policy": 185.516, "predator_policy": 3.345}, "custom_metrics": {}, "hist_stats": {"episode_reward": [376.6, 387.9, 366.6, 393.7, 400.0, 391.0, 384.4, 392.2, 376.8, 391.0, 396.2, 378.0, 392.8, 395.5, 360.2, 355.8, 395.5, 394.0, 383.7, 393.7, 361.7, 384.0, 373.3, 386.0, 400.0, 390.1, 383.4, 320.2, 361.9, 380.2, 373.2, 391.3, 365.6, 362.6, 309.0, 388.3, 324.5, 394.6, 373.4, 329.5, 363.2, 387.0, 381.8, 390.1, 344.0, 376.4, 353.9, 389.20000000000005, 346.4, 369.1, 384.8, 381.2, 384.1, 380.2, 337.3, 389.2, 359.3, 398.2, 372.1, 399.1, 377.3, 392.8, 372.0, 390.0, 399.1, 396.4, 365.0, 373.3, 379.7, 373.2, 388.3, 369.1, 384.7, 376.1, 361.9, 367.9, 361.4, 380.7, 361.0, 378.1, 400.0, 357.6, 397.3, 388.0, 374.0, 370.2, 391.9, 379.9, 396.4, 355.29999999999995, 382.9, 391.0000000000001, 399.1, 390.6, 392.2, 396.0, 368.8, 374.8, 391.9, 381.3], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [182.9, 193.7, 191.9, 194.0, 180.2, 178.4, 200.0, 193.7, 200.0, 200.0, 191.0, 200.0, 180.2, 198.2, 200.0, 189.2, 192.8, 176.0, 200.0, 191.0, 198.2, 197.0, 184.7, 191.3, 192.8, 200.0, 200.0, 195.5, 192.8, 151.4, 171.8, 167.0, 195.5, 200.0, 200.0, 191.0, 185.0, 193.7, 196.4, 197.3, 179.6, 166.1, 176.0, 200.0, 173.0, 188.3, 173.0, 200.0, 200.0, 200.0, 199.1, 191.0, 196.4, 185.0, 150.2, 152.0, 173.0, 182.9, 194.6, 185.6, 176.0, 189.2, 200.0, 188.3, 187.7, 167.9, 184.7, 170.9, 146.0, 140.0, 198.2, 190.1, 190.1, 103.4, 194.6, 200.0, 187.4, 179.0, 145.7, 156.8, 188.0, 162.2, 200.0, 161.0, 192.5, 188.3, 197.3, 192.8, 173.0, 155.0, 195.5, 179.9, 181.1, 156.8, 197.29999999999998, 191.9, 167.0, 148.39999999999998, 199.1, 155.0, 200.0, 180.8, 189.2, 188.0, 190.1, 191.0, 195.5, 184.7, 155.0, 164.3, 189.2, 200.0, 167.3, 182.0, 200.0, 198.2, 181.1, 191.0, 199.1, 200.0, 200.0, 167.3, 200.0, 192.8, 164.0, 188.0, 200.0, 179.0, 200.0, 199.1, 196.4, 200.0, 170.0, 185.0, 194.6, 166.7, 179.0, 193.7, 174.2, 191.0, 193.7, 194.6, 154.1, 200.0, 191.9, 192.8, 195.5, 173.6, 194.6, 149.3, 177.2, 178.7, 176.0, 172.4, 194.0, 184.7, 179.0, 173.0, 200.0, 172.1, 200.0, 200.0, 169.7, 182.9, 197.3, 200.0, 182.0, 200.0, 185.0, 185.0, 200.0, 156.2, 191.9, 200.0, 193.7, 180.2, 199.1, 197.3, 174.2, 163.1, 191.0, 191.9, 190.99999999999997, 200.0, 199.1, 200.0, 194.0, 194.6, 198.2, 191.0, 200.0, 194.0, 176.0, 180.8, 200.0, 165.8, 196.4, 195.5, 176.0, 197.3], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 2.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 3.0, 0.0, 8.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 10.0, 6.0, 17.0, 0.0, 0.0, 0.0, 3.0, 0.0, 2.0, 3.0, 0.0, 0.0, 11.0, 5.0, 0.0, 8.0, 1.0, 11.0, 7.0, 6.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 10.0, 8.0, 0.0, 6.0, 0.0, 0.0, 0.0, 8.0, 3.0, 0.0, 2.0, 8.0, 7.0, 0.0, 11.0, 12.0, 0.0, 0.0, 31.0, 0.0, 0.0, 0.0, 0.0, 7.0, 16.0, 11.0, 0.0, 13.0, 13.0, 13.0, 0.0, 1.0, 0.0, 0.0, 16.0, 0.0, 0.0, 1.0, 12.0, 4.0, 0.0, 0.0, 22.0, 9.0, 15.0, 0.0, 0.0, 4.0, 0.0, 4.0, 0.0, 3.0, 0.0, 0.0, 0.0, 18.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 12.0, 8.0, 6.0, 5.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 6.0, 6.0, 0.0, 7.0, 0.0, 8.0, 0.0, 0.0, 15.0, 0.0, 0.0, 0.0, 0.0, 7.0, 6.0, 12.0, 5.0, 7.0, 13.0, 0.0, 0.0, 2.0, 9.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 6.0, 0.0, 4.0, 0.0, 0.0, 14.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 12.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 3.0, 0.0, 0.0, 2.0, 12.0, 0.0, 0.0, 9.0, 0.0, 0.0, 3.0, 5.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 10.46740438842935, "mean_inference_ms": 25.73672741326898, "mean_action_processing_ms": 5.067741885871151, "mean_env_wait_ms": 6.283053447700704, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.016163229942321777, "StateBufferConnector_ms": 0.0071070194244384766, "ViewRequirementAgentConnector_ms": 0.27053868770599365}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": 309.0, "episode_return_mean": 377.7220000000001, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2800000, "num_agent_steps_trained": 2800000, "num_env_steps_sampled": 700000, "num_env_steps_trained": 700000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 180.17922387925955, "num_env_steps_trained_throughput_per_sec": 180.17922387925955, "timesteps_total": 700000, "num_env_steps_sampled_lifetime": 700000, "num_agent_steps_sampled_lifetime": 2800000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2800000, "timers": {"training_iteration_time_ms": 25491.453, "restore_workers_time_ms": 0.021, "training_step_time_ms": 25491.384, "sample_time_ms": 4180.939, "learn_time_ms": 21272.604, "learn_throughput": 188.035, "synch_weights_time_ms": 34.707}, "counters": {"num_env_steps_sampled": 700000, "num_env_steps_trained": 700000, "num_agent_steps_sampled": 2800000, "num_agent_steps_trained": 2800000}, "done": false, "training_iteration": 175, "trial_id": "75ec3_00000", "date": "2024-08-13_05-52-31", "timestamp": 1723542751, "time_this_iter_s": 22.24204111099243, "time_total_s": 15497.83442735672, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b25888b0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 15497.83442735672, "iterations_since_restore": 175, "perf": {"cpu_util_percent": 75.2290322580645, "ram_util_percent": 77.20967741935483}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2975538368814836, "cur_kl_coeff": 0.04334650319030402, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.5873178476918607, "policy_loss": -0.011374301407436924, "vf_loss": 0.5979517815171411, "vf_explained_var": 0.17109856277546553, "kl": 0.017080224564358697, "entropy": 1.183487798738732, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 331695.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6018490550872037, "cur_kl_coeff": 8.734021423574163e-28, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.38610422092455404, "policy_loss": -6.81085882846404e-05, "vf_loss": 0.3861723270736913, "vf_explained_var": 0.09305135191433013, "kl": 0.0027971826647078626, "entropy": 0.5308738224090092, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 331695.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 704000, "num_env_steps_trained": 704000, "num_agent_steps_sampled": 2816000, "num_agent_steps_trained": 2816000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": 309.0, "episode_reward_mean": 373.94200000000006, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 103.4, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 31.0}, "policy_reward_mean": {"prey_policy": 182.96599999999998, "predator_policy": 4.005}, "custom_metrics": {}, "hist_stats": {"episode_reward": [383.7, 393.7, 361.7, 384.0, 373.3, 386.0, 400.0, 390.1, 383.4, 320.2, 361.9, 380.2, 373.2, 391.3, 365.6, 362.6, 309.0, 388.3, 324.5, 394.6, 373.4, 329.5, 363.2, 387.0, 381.8, 390.1, 344.0, 376.4, 353.9, 389.20000000000005, 346.4, 369.1, 384.8, 381.2, 384.1, 380.2, 337.3, 389.2, 359.3, 398.2, 372.1, 399.1, 377.3, 392.8, 372.0, 390.0, 399.1, 396.4, 365.0, 373.3, 379.7, 373.2, 388.3, 369.1, 384.7, 376.1, 361.9, 367.9, 361.4, 380.7, 361.0, 378.1, 400.0, 357.6, 397.3, 388.0, 374.0, 370.2, 391.9, 379.9, 396.4, 355.29999999999995, 382.9, 391.0000000000001, 399.1, 390.6, 392.2, 396.0, 368.8, 374.8, 391.9, 381.3, 364.5, 374.8, 382.0, 345.2, 387.4, 360.9, 392.8, 369.6, 342.3, 332.3, 373.1, 340.5, 347.5, 350.2, 391.0, 361.9, 395.1, 339.1], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [185.0, 193.7, 196.4, 197.3, 179.6, 166.1, 176.0, 200.0, 173.0, 188.3, 173.0, 200.0, 200.0, 200.0, 199.1, 191.0, 196.4, 185.0, 150.2, 152.0, 173.0, 182.9, 194.6, 185.6, 176.0, 189.2, 200.0, 188.3, 187.7, 167.9, 184.7, 170.9, 146.0, 140.0, 198.2, 190.1, 190.1, 103.4, 194.6, 200.0, 187.4, 179.0, 145.7, 156.8, 188.0, 162.2, 200.0, 161.0, 192.5, 188.3, 197.3, 192.8, 173.0, 155.0, 195.5, 179.9, 181.1, 156.8, 197.29999999999998, 191.9, 167.0, 148.39999999999998, 199.1, 155.0, 200.0, 180.8, 189.2, 188.0, 190.1, 191.0, 195.5, 184.7, 155.0, 164.3, 189.2, 200.0, 167.3, 182.0, 200.0, 198.2, 181.1, 191.0, 199.1, 200.0, 200.0, 167.3, 200.0, 192.8, 164.0, 188.0, 200.0, 179.0, 200.0, 199.1, 196.4, 200.0, 170.0, 185.0, 194.6, 166.7, 179.0, 193.7, 174.2, 191.0, 193.7, 194.6, 154.1, 200.0, 191.9, 192.8, 195.5, 173.6, 194.6, 149.3, 177.2, 178.7, 176.0, 172.4, 194.0, 184.7, 179.0, 173.0, 200.0, 172.1, 200.0, 200.0, 169.7, 182.9, 197.3, 200.0, 182.0, 200.0, 185.0, 185.0, 200.0, 156.2, 191.9, 200.0, 193.7, 180.2, 199.1, 197.3, 174.2, 163.1, 191.0, 191.9, 190.99999999999997, 200.0, 199.1, 200.0, 194.0, 194.6, 198.2, 191.0, 200.0, 194.0, 176.0, 180.8, 200.0, 165.8, 196.4, 195.5, 176.0, 197.3, 165.2, 188.3, 174.8, 200.0, 185.6, 196.4, 179.3, 149.9, 191.0, 196.4, 186.5, 163.4, 192.8, 200.0, 194.6, 161.0, 131.0, 188.3, 196.4, 107.9, 157.1, 200.0, 145.4, 175.1, 164.0, 168.5, 154.1, 181.1, 193.7, 197.3, 181.4, 165.5, 194.0, 199.1, 163.1, 164.0], "policy_predator_policy_reward": [2.0, 3.0, 0.0, 0.0, 11.0, 5.0, 0.0, 8.0, 1.0, 11.0, 7.0, 6.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 10.0, 8.0, 0.0, 6.0, 0.0, 0.0, 0.0, 8.0, 3.0, 0.0, 2.0, 8.0, 7.0, 0.0, 11.0, 12.0, 0.0, 0.0, 31.0, 0.0, 0.0, 0.0, 0.0, 7.0, 16.0, 11.0, 0.0, 13.0, 13.0, 13.0, 0.0, 1.0, 0.0, 0.0, 16.0, 0.0, 0.0, 1.0, 12.0, 4.0, 0.0, 0.0, 22.0, 9.0, 15.0, 0.0, 0.0, 4.0, 0.0, 4.0, 0.0, 3.0, 0.0, 0.0, 0.0, 18.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 12.0, 8.0, 6.0, 5.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 6.0, 6.0, 0.0, 7.0, 0.0, 8.0, 0.0, 0.0, 15.0, 0.0, 0.0, 0.0, 0.0, 7.0, 6.0, 12.0, 5.0, 7.0, 13.0, 0.0, 0.0, 2.0, 9.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 6.0, 0.0, 4.0, 0.0, 0.0, 14.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 12.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 3.0, 0.0, 0.0, 2.0, 12.0, 0.0, 0.0, 9.0, 0.0, 0.0, 3.0, 5.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 1.0, 13.0, 23.0, 0.0, 28.0, 0.0, 8.0, 8.0, 14.0, 6.0, 15.0, 0.0, 15.0, 0.0, 0.0, 0.0, 5.0, 10.0, 0.0, 2.0, 0.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 10.420668606371603, "mean_inference_ms": 25.625576640076243, "mean_action_processing_ms": 5.044512940400169, "mean_env_wait_ms": 6.252933777383215, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.013542771339416504, "StateBufferConnector_ms": 0.007080078125, "ViewRequirementAgentConnector_ms": 0.2722412347793579}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": 309.0, "episode_return_mean": 373.94200000000006, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2816000, "num_agent_steps_trained": 2816000, "num_env_steps_sampled": 704000, "num_env_steps_trained": 704000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 192.4738121336834, "num_env_steps_trained_throughput_per_sec": 192.4738121336834, "timesteps_total": 704000, "num_env_steps_sampled_lifetime": 704000, "num_agent_steps_sampled_lifetime": 2816000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2816000, "timers": {"training_iteration_time_ms": 24974.056, "restore_workers_time_ms": 0.021, "training_step_time_ms": 24973.988, "sample_time_ms": 3992.591, "learn_time_ms": 20942.366, "learn_throughput": 191.0, "synch_weights_time_ms": 36.183}, "counters": {"num_env_steps_sampled": 704000, "num_env_steps_trained": 704000, "num_agent_steps_sampled": 2816000, "num_agent_steps_trained": 2816000}, "done": false, "training_iteration": 176, "trial_id": "75ec3_00000", "date": "2024-08-13_05-52-52", "timestamp": 1723542772, "time_this_iter_s": 20.860087156295776, "time_total_s": 15518.694514513016, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2515dc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 15518.694514513016, "iterations_since_restore": 176, "perf": {"cpu_util_percent": 72.94333333333333, "ram_util_percent": 78.28999999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9370934094149599, "cur_kl_coeff": 0.04334650319030402, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.35323524544615775, "policy_loss": -0.004927045207657905, "vf_loss": 0.3579949164684251, "vf_explained_var": 0.32058881013481705, "kl": 0.003861313918934597, "entropy": 1.1908578294294851, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 333585.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5780509792327407, "cur_kl_coeff": 4.367010711787082e-28, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.24199316750561434, "policy_loss": -0.0010516443196191359, "vf_loss": 0.2430448109782966, "vf_explained_var": 0.03760255568872684, "kl": 0.01009894640135485, "entropy": 0.5308042043731326, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 333585.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 708000, "num_env_steps_trained": 708000, "num_agent_steps_sampled": 2832000, "num_agent_steps_trained": 2832000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": 323.5, "episode_reward_mean": 373.296, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 103.4, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 31.0}, "policy_reward_mean": {"prey_policy": 182.108, "predator_policy": 4.54}, "custom_metrics": {}, "hist_stats": {"episode_reward": [324.5, 394.6, 373.4, 329.5, 363.2, 387.0, 381.8, 390.1, 344.0, 376.4, 353.9, 389.20000000000005, 346.4, 369.1, 384.8, 381.2, 384.1, 380.2, 337.3, 389.2, 359.3, 398.2, 372.1, 399.1, 377.3, 392.8, 372.0, 390.0, 399.1, 396.4, 365.0, 373.3, 379.7, 373.2, 388.3, 369.1, 384.7, 376.1, 361.9, 367.9, 361.4, 380.7, 361.0, 378.1, 400.0, 357.6, 397.3, 388.0, 374.0, 370.2, 391.9, 379.9, 396.4, 355.29999999999995, 382.9, 391.0000000000001, 399.1, 390.6, 392.2, 396.0, 368.8, 374.8, 391.9, 381.3, 364.5, 374.8, 382.0, 345.2, 387.4, 360.9, 392.8, 369.6, 342.3, 332.3, 373.1, 340.5, 347.5, 350.2, 391.0, 361.9, 395.1, 339.1, 376.1, 323.5, 327.2, 369.5, 371.2, 386.2, 347.4, 359.0, 385.2, 400.0, 378.0, 379.3, 393.7, 383.70000000000005, 360.1, 356.3, 371.5, 375.7], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [190.1, 103.4, 194.6, 200.0, 187.4, 179.0, 145.7, 156.8, 188.0, 162.2, 200.0, 161.0, 192.5, 188.3, 197.3, 192.8, 173.0, 155.0, 195.5, 179.9, 181.1, 156.8, 197.29999999999998, 191.9, 167.0, 148.39999999999998, 199.1, 155.0, 200.0, 180.8, 189.2, 188.0, 190.1, 191.0, 195.5, 184.7, 155.0, 164.3, 189.2, 200.0, 167.3, 182.0, 200.0, 198.2, 181.1, 191.0, 199.1, 200.0, 200.0, 167.3, 200.0, 192.8, 164.0, 188.0, 200.0, 179.0, 200.0, 199.1, 196.4, 200.0, 170.0, 185.0, 194.6, 166.7, 179.0, 193.7, 174.2, 191.0, 193.7, 194.6, 154.1, 200.0, 191.9, 192.8, 195.5, 173.6, 194.6, 149.3, 177.2, 178.7, 176.0, 172.4, 194.0, 184.7, 179.0, 173.0, 200.0, 172.1, 200.0, 200.0, 169.7, 182.9, 197.3, 200.0, 182.0, 200.0, 185.0, 185.0, 200.0, 156.2, 191.9, 200.0, 193.7, 180.2, 199.1, 197.3, 174.2, 163.1, 191.0, 191.9, 190.99999999999997, 200.0, 199.1, 200.0, 194.0, 194.6, 198.2, 191.0, 200.0, 194.0, 176.0, 180.8, 200.0, 165.8, 196.4, 195.5, 176.0, 197.3, 165.2, 188.3, 174.8, 200.0, 185.6, 196.4, 179.3, 149.9, 191.0, 196.4, 186.5, 163.4, 192.8, 200.0, 194.6, 161.0, 131.0, 188.3, 196.4, 107.9, 157.1, 200.0, 145.4, 175.1, 164.0, 168.5, 154.1, 181.1, 193.7, 197.3, 181.4, 165.5, 194.0, 199.1, 163.1, 164.0, 192.8, 179.3, 117.5, 170.0, 190.1, 106.1, 180.2, 176.3, 173.0, 189.2, 199.1, 181.1, 173.0, 154.4, 182.0, 161.0, 185.0, 198.2, 200.0, 200.0, 200.0, 167.0, 186.5, 192.8, 193.7, 200.0, 196.4, 176.3, 182.0, 166.1, 200.0, 110.3, 169.4, 190.1, 191.0, 175.7], "policy_predator_policy_reward": [31.0, 0.0, 0.0, 0.0, 0.0, 7.0, 16.0, 11.0, 0.0, 13.0, 13.0, 13.0, 0.0, 1.0, 0.0, 0.0, 16.0, 0.0, 0.0, 1.0, 12.0, 4.0, 0.0, 0.0, 22.0, 9.0, 15.0, 0.0, 0.0, 4.0, 0.0, 4.0, 0.0, 3.0, 0.0, 0.0, 0.0, 18.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 12.0, 8.0, 6.0, 5.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 6.0, 6.0, 0.0, 7.0, 0.0, 8.0, 0.0, 0.0, 15.0, 0.0, 0.0, 0.0, 0.0, 7.0, 6.0, 12.0, 5.0, 7.0, 13.0, 0.0, 0.0, 2.0, 9.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 6.0, 0.0, 4.0, 0.0, 0.0, 14.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 12.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 3.0, 0.0, 0.0, 2.0, 12.0, 0.0, 0.0, 9.0, 0.0, 0.0, 3.0, 5.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 1.0, 13.0, 23.0, 0.0, 28.0, 0.0, 8.0, 8.0, 14.0, 6.0, 15.0, 0.0, 15.0, 0.0, 0.0, 0.0, 5.0, 10.0, 0.0, 2.0, 0.0, 12.0, 3.0, 1.0, 10.0, 26.0, 23.0, 8.0, 6.0, 7.0, 0.0, 9.0, 6.0, 0.0, 16.0, 4.0, 0.0, 16.0, 0.0, 2.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 4.0, 12.0, 0.0, 18.0, 28.0, 3.0, 9.0, 9.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 10.376631238186473, "mean_inference_ms": 25.520733857958103, "mean_action_processing_ms": 5.022306748901681, "mean_env_wait_ms": 6.223924092158668, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.013565421104431152, "StateBufferConnector_ms": 0.0069653987884521484, "ViewRequirementAgentConnector_ms": 0.31469762325286865}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": 323.5, "episode_return_mean": 373.296, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2832000, "num_agent_steps_trained": 2832000, "num_env_steps_sampled": 708000, "num_env_steps_trained": 708000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 114.66325781889877, "num_env_steps_trained_throughput_per_sec": 114.66325781889877, "timesteps_total": 708000, "num_env_steps_sampled_lifetime": 708000, "num_agent_steps_sampled_lifetime": 2832000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2832000, "timers": {"training_iteration_time_ms": 25877.083, "restore_workers_time_ms": 0.021, "training_step_time_ms": 25877.013, "sample_time_ms": 4204.933, "learn_time_ms": 21638.757, "learn_throughput": 184.853, "synch_weights_time_ms": 30.398}, "counters": {"num_env_steps_sampled": 708000, "num_env_steps_trained": 708000, "num_agent_steps_sampled": 2832000, "num_agent_steps_trained": 2832000}, "done": false, "training_iteration": 177, "trial_id": "75ec3_00000", "date": "2024-08-13_05-53-27", "timestamp": 1723542807, "time_this_iter_s": 34.94997501373291, "time_total_s": 15553.644489526749, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2567160>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 15553.644489526749, "iterations_since_restore": 177, "perf": {"cpu_util_percent": 90.63877551020408, "ram_util_percent": 83.06530612244897}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6741642078552297, "cur_kl_coeff": 0.02167325159515201, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.469047022833447, "policy_loss": -0.004678013939016237, "vf_loss": 0.47351721347403275, "vf_explained_var": 0.28940472536616857, "kl": 0.009589036000946339, "entropy": 1.1736056286191183, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 335475.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.49648752342416813, "cur_kl_coeff": 4.367010711787082e-28, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.22146072383358995, "policy_loss": -0.00306935512544538, "vf_loss": 0.22453007912087727, "vf_explained_var": 0.11221201438752432, "kl": 0.012918470396211402, "entropy": 0.5236370760927755, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 335475.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 712000, "num_env_steps_trained": 712000, "num_agent_steps_sampled": 2848000, "num_agent_steps_trained": 2848000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": 312.70000000000005, "episode_reward_mean": 374.46200000000005, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 106.1, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 28.0}, "policy_reward_mean": {"prey_policy": 183.101, "predator_policy": 4.13}, "custom_metrics": {}, "hist_stats": {"episode_reward": [390.0, 399.1, 396.4, 365.0, 373.3, 379.7, 373.2, 388.3, 369.1, 384.7, 376.1, 361.9, 367.9, 361.4, 380.7, 361.0, 378.1, 400.0, 357.6, 397.3, 388.0, 374.0, 370.2, 391.9, 379.9, 396.4, 355.29999999999995, 382.9, 391.0000000000001, 399.1, 390.6, 392.2, 396.0, 368.8, 374.8, 391.9, 381.3, 364.5, 374.8, 382.0, 345.2, 387.4, 360.9, 392.8, 369.6, 342.3, 332.3, 373.1, 340.5, 347.5, 350.2, 391.0, 361.9, 395.1, 339.1, 376.1, 323.5, 327.2, 369.5, 371.2, 386.2, 347.4, 359.0, 385.2, 400.0, 378.0, 379.3, 393.7, 383.70000000000005, 360.1, 356.3, 371.5, 375.7, 389.20000000000005, 395.1, 378.1, 374.8, 371.2, 396.4, 391.70000000000005, 348.3, 384.0, 370.6, 375.2, 378.4, 381.1, 396.0, 359.9, 373.6, 390.1, 381.1, 376.8, 368.0, 380.2, 372.9, 312.70000000000005, 363.1, 381.4, 377.4, 400.0], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [200.0, 179.0, 200.0, 199.1, 196.4, 200.0, 170.0, 185.0, 194.6, 166.7, 179.0, 193.7, 174.2, 191.0, 193.7, 194.6, 154.1, 200.0, 191.9, 192.8, 195.5, 173.6, 194.6, 149.3, 177.2, 178.7, 176.0, 172.4, 194.0, 184.7, 179.0, 173.0, 200.0, 172.1, 200.0, 200.0, 169.7, 182.9, 197.3, 200.0, 182.0, 200.0, 185.0, 185.0, 200.0, 156.2, 191.9, 200.0, 193.7, 180.2, 199.1, 197.3, 174.2, 163.1, 191.0, 191.9, 190.99999999999997, 200.0, 199.1, 200.0, 194.0, 194.6, 198.2, 191.0, 200.0, 194.0, 176.0, 180.8, 200.0, 165.8, 196.4, 195.5, 176.0, 197.3, 165.2, 188.3, 174.8, 200.0, 185.6, 196.4, 179.3, 149.9, 191.0, 196.4, 186.5, 163.4, 192.8, 200.0, 194.6, 161.0, 131.0, 188.3, 196.4, 107.9, 157.1, 200.0, 145.4, 175.1, 164.0, 168.5, 154.1, 181.1, 193.7, 197.3, 181.4, 165.5, 194.0, 199.1, 163.1, 164.0, 192.8, 179.3, 117.5, 170.0, 190.1, 106.1, 180.2, 176.3, 173.0, 189.2, 199.1, 181.1, 173.0, 154.4, 182.0, 161.0, 185.0, 198.2, 200.0, 200.0, 200.0, 167.0, 186.5, 192.8, 193.7, 200.0, 196.4, 176.3, 182.0, 166.1, 200.0, 110.3, 169.4, 190.1, 191.0, 175.7, 200.0, 189.2, 194.0, 199.1, 176.0, 196.1, 174.8, 200.0, 175.1, 187.1, 199.1, 197.3, 195.5, 195.2, 129.2, 199.1, 194.0, 182.0, 166.4, 189.2, 194.6, 173.6, 196.4, 173.0, 199.1, 173.0, 194.0, 200.0, 176.9, 170.0, 167.6, 200.0, 190.1, 200.0, 188.3, 192.8, 195.5, 173.3, 161.0, 191.0, 183.2, 188.0, 182.9, 185.0, 147.2, 147.5, 178.39999999999998, 184.7, 187.4, 191.0, 190.1, 182.3, 200.0, 200.0], "policy_predator_policy_reward": [6.0, 5.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 6.0, 6.0, 0.0, 7.0, 0.0, 8.0, 0.0, 0.0, 15.0, 0.0, 0.0, 0.0, 0.0, 7.0, 6.0, 12.0, 5.0, 7.0, 13.0, 0.0, 0.0, 2.0, 9.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 6.0, 0.0, 4.0, 0.0, 0.0, 14.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 12.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 3.0, 0.0, 0.0, 2.0, 12.0, 0.0, 0.0, 9.0, 0.0, 0.0, 3.0, 5.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 1.0, 13.0, 23.0, 0.0, 28.0, 0.0, 8.0, 8.0, 14.0, 6.0, 15.0, 0.0, 15.0, 0.0, 0.0, 0.0, 5.0, 10.0, 0.0, 2.0, 0.0, 12.0, 3.0, 1.0, 10.0, 26.0, 23.0, 8.0, 6.0, 7.0, 0.0, 9.0, 6.0, 0.0, 16.0, 4.0, 0.0, 16.0, 0.0, 2.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 4.0, 12.0, 0.0, 18.0, 28.0, 3.0, 9.0, 9.0, 0.0, 0.0, 0.0, 2.0, 0.0, 6.0, 0.0, 0.0, 0.0, 8.0, 1.0, 0.0, 0.0, 1.0, 0.0, 20.0, 0.0, 2.0, 6.0, 10.0, 5.0, 0.0, 7.0, 0.0, 9.0, 0.0, 9.0, 0.0, 2.0, 11.0, 2.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 9.0, 7.0, 4.0, 5.0, 0.0, 5.0, 0.0, 18.0, 0.0, 0.0, 0.0, 3.0, 0.0, 5.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 10.700391660088833, "mean_inference_ms": 24.97077585421865, "mean_action_processing_ms": 4.996156053710148, "mean_env_wait_ms": 6.068313577603362, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.008180499076843262, "StateBufferConnector_ms": 0.0068645477294921875, "ViewRequirementAgentConnector_ms": 0.29462456703186035}, "num_episodes": 27, "episode_return_max": 400.0, "episode_return_min": 312.70000000000005, "episode_return_mean": 374.46200000000005, "episodes_this_iter": 27}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2848000, "num_agent_steps_trained": 2848000, "num_env_steps_sampled": 712000, "num_env_steps_trained": 712000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 187.26831815692933, "num_env_steps_trained_throughput_per_sec": 187.26831815692933, "timesteps_total": 712000, "num_env_steps_sampled_lifetime": 712000, "num_agent_steps_sampled_lifetime": 2848000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2848000, "timers": {"training_iteration_time_ms": 25410.212, "restore_workers_time_ms": 0.022, "training_step_time_ms": 25410.139, "sample_time_ms": 3948.899, "learn_time_ms": 21430.121, "learn_throughput": 186.653, "synch_weights_time_ms": 28.277}, "counters": {"num_env_steps_sampled": 712000, "num_env_steps_trained": 712000, "num_agent_steps_sampled": 2848000, "num_agent_steps_trained": 2848000}, "done": false, "training_iteration": 178, "trial_id": "75ec3_00000", "date": "2024-08-13_05-53-49", "timestamp": 1723542829, "time_this_iter_s": 21.437546968460083, "time_total_s": 15575.082036495209, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2515040>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 15575.082036495209, "iterations_since_restore": 178, "perf": {"cpu_util_percent": 74.74000000000001, "ram_util_percent": 83.31333333333333}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.0678977601269564, "cur_kl_coeff": 0.02167325159515201, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.5615802900855819, "policy_loss": -0.003539900214376825, "vf_loss": 0.5649612045753254, "vf_explained_var": 0.3356491498846226, "kl": 0.007335630955480803, "entropy": 1.1809949893169303, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 337365.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.2706162021564389, "cur_kl_coeff": 4.367010711787082e-28, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.11405472797366283, "policy_loss": -0.00026281775152754217, "vf_loss": 0.11431754578359822, "vf_explained_var": -0.06060281616670114, "kl": 0.006221119387087108, "entropy": 0.5119447206536298, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 337365.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 716000, "num_env_steps_trained": 716000, "num_agent_steps_sampled": 2864000, "num_agent_steps_trained": 2864000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": 312.70000000000005, "episode_reward_mean": 374.434, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 106.1, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 28.0}, "policy_reward_mean": {"prey_policy": 183.392, "predator_policy": 3.825}, "custom_metrics": {}, "hist_stats": {"episode_reward": [357.6, 397.3, 388.0, 374.0, 370.2, 391.9, 379.9, 396.4, 355.29999999999995, 382.9, 391.0000000000001, 399.1, 390.6, 392.2, 396.0, 368.8, 374.8, 391.9, 381.3, 364.5, 374.8, 382.0, 345.2, 387.4, 360.9, 392.8, 369.6, 342.3, 332.3, 373.1, 340.5, 347.5, 350.2, 391.0, 361.9, 395.1, 339.1, 376.1, 323.5, 327.2, 369.5, 371.2, 386.2, 347.4, 359.0, 385.2, 400.0, 378.0, 379.3, 393.7, 383.70000000000005, 360.1, 356.3, 371.5, 375.7, 389.20000000000005, 395.1, 378.1, 374.8, 371.2, 396.4, 391.70000000000005, 348.3, 384.0, 370.6, 375.2, 378.4, 381.1, 396.0, 359.9, 373.6, 390.1, 381.1, 376.8, 368.0, 380.2, 372.9, 312.70000000000005, 363.1, 381.4, 377.4, 400.0, 373.8, 380.7, 376.9, 377.5, 349.2, 391.9, 390.0, 389.2, 350.4, 383.8, 384.8, 367.8, 395.5, 376.6, 358.79999999999995, 385.6, 379.60000000000014, 391.0], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [169.7, 182.9, 197.3, 200.0, 182.0, 200.0, 185.0, 185.0, 200.0, 156.2, 191.9, 200.0, 193.7, 180.2, 199.1, 197.3, 174.2, 163.1, 191.0, 191.9, 190.99999999999997, 200.0, 199.1, 200.0, 194.0, 194.6, 198.2, 191.0, 200.0, 194.0, 176.0, 180.8, 200.0, 165.8, 196.4, 195.5, 176.0, 197.3, 165.2, 188.3, 174.8, 200.0, 185.6, 196.4, 179.3, 149.9, 191.0, 196.4, 186.5, 163.4, 192.8, 200.0, 194.6, 161.0, 131.0, 188.3, 196.4, 107.9, 157.1, 200.0, 145.4, 175.1, 164.0, 168.5, 154.1, 181.1, 193.7, 197.3, 181.4, 165.5, 194.0, 199.1, 163.1, 164.0, 192.8, 179.3, 117.5, 170.0, 190.1, 106.1, 180.2, 176.3, 173.0, 189.2, 199.1, 181.1, 173.0, 154.4, 182.0, 161.0, 185.0, 198.2, 200.0, 200.0, 200.0, 167.0, 186.5, 192.8, 193.7, 200.0, 196.4, 176.3, 182.0, 166.1, 200.0, 110.3, 169.4, 190.1, 191.0, 175.7, 200.0, 189.2, 194.0, 199.1, 176.0, 196.1, 174.8, 200.0, 175.1, 187.1, 199.1, 197.3, 195.5, 195.2, 129.2, 199.1, 194.0, 182.0, 166.4, 189.2, 194.6, 173.6, 196.4, 173.0, 199.1, 173.0, 194.0, 200.0, 176.9, 170.0, 167.6, 200.0, 190.1, 200.0, 188.3, 192.8, 195.5, 173.3, 161.0, 191.0, 183.2, 188.0, 182.9, 185.0, 147.2, 147.5, 178.39999999999998, 184.7, 187.4, 191.0, 190.1, 182.3, 200.0, 200.0, 185.0, 183.8, 194.6, 184.1, 188.3, 185.6, 182.89999999999998, 194.6, 149.0, 189.2, 200.0, 191.9, 185.0, 200.0, 196.4, 192.8, 173.0, 163.4, 191.0, 192.8, 186.8, 194.0, 186.5, 173.3, 199.1, 196.4, 185.6, 191.0, 185.0, 159.79999999999995, 196.4, 189.2, 187.4, 189.19999999999993, 192.8, 198.2], "policy_predator_policy_reward": [0.0, 5.0, 0.0, 0.0, 6.0, 0.0, 4.0, 0.0, 0.0, 14.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 12.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 3.0, 0.0, 0.0, 2.0, 12.0, 0.0, 0.0, 9.0, 0.0, 0.0, 3.0, 5.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 1.0, 13.0, 23.0, 0.0, 28.0, 0.0, 8.0, 8.0, 14.0, 6.0, 15.0, 0.0, 15.0, 0.0, 0.0, 0.0, 5.0, 10.0, 0.0, 2.0, 0.0, 12.0, 3.0, 1.0, 10.0, 26.0, 23.0, 8.0, 6.0, 7.0, 0.0, 9.0, 6.0, 0.0, 16.0, 4.0, 0.0, 16.0, 0.0, 2.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 4.0, 12.0, 0.0, 18.0, 28.0, 3.0, 9.0, 9.0, 0.0, 0.0, 0.0, 2.0, 0.0, 6.0, 0.0, 0.0, 0.0, 8.0, 1.0, 0.0, 0.0, 1.0, 0.0, 20.0, 0.0, 2.0, 6.0, 10.0, 5.0, 0.0, 7.0, 0.0, 9.0, 0.0, 9.0, 0.0, 2.0, 11.0, 2.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 9.0, 7.0, 4.0, 5.0, 0.0, 5.0, 0.0, 18.0, 0.0, 0.0, 0.0, 3.0, 0.0, 5.0, 0.0, 0.0, 1.0, 4.0, 0.0, 2.0, 0.0, 3.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 14.0, 0.0, 0.0, 0.0, 2.0, 2.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 14.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 10.271618345036236, "mean_inference_ms": 25.26499571791455, "mean_action_processing_ms": 4.968672580043989, "mean_env_wait_ms": 6.15506132069476, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.008293509483337402, "StateBufferConnector_ms": 0.006715059280395508, "ViewRequirementAgentConnector_ms": 0.28414857387542725}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": 312.70000000000005, "episode_return_mean": 374.434, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2864000, "num_agent_steps_trained": 2864000, "num_env_steps_sampled": 716000, "num_env_steps_trained": 716000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 183.45209690799774, "num_env_steps_trained_throughput_per_sec": 183.45209690799774, "timesteps_total": 716000, "num_env_steps_sampled_lifetime": 716000, "num_agent_steps_sampled_lifetime": 2864000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2864000, "timers": {"training_iteration_time_ms": 24835.278, "restore_workers_time_ms": 0.021, "training_step_time_ms": 24835.207, "sample_time_ms": 3811.316, "learn_time_ms": 20995.875, "learn_throughput": 190.514, "synch_weights_time_ms": 25.105}, "counters": {"num_env_steps_sampled": 716000, "num_env_steps_trained": 716000, "num_agent_steps_sampled": 2864000, "num_agent_steps_trained": 2864000}, "done": false, "training_iteration": 179, "trial_id": "75ec3_00000", "date": "2024-08-13_05-54-10", "timestamp": 1723542850, "time_this_iter_s": 21.899918794631958, "time_total_s": 15596.98195528984, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b23f0160>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 15596.98195528984, "iterations_since_restore": 179, "perf": {"cpu_util_percent": 75.67096774193548, "ram_util_percent": 83.31612903225806}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8368864068436244, "cur_kl_coeff": 0.02167325159515201, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.2783852195730322, "policy_loss": -0.004902904673858925, "vf_loss": 0.2831020579407258, "vf_explained_var": 0.32685741545662045, "kl": 0.008584970695047645, "entropy": 1.1839759480385554, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 339255.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.30673489150192057, "cur_kl_coeff": 4.367010711787082e-28, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.194546967512243, "policy_loss": -0.011156324533223317, "vf_loss": 0.20570329188579564, "vf_explained_var": 0.038869345818877854, "kl": 0.23061851623778545, "entropy": 0.6261830957162948, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 339255.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 720000, "num_env_steps_trained": 720000, "num_agent_steps_sampled": 2880000, "num_agent_steps_trained": 2880000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": 312.70000000000005, "episode_reward_mean": 372.991, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 106.1, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 28.0}, "policy_reward_mean": {"prey_policy": 182.50549999999998, "predator_policy": 3.99}, "custom_metrics": {}, "hist_stats": {"episode_reward": [381.3, 364.5, 374.8, 382.0, 345.2, 387.4, 360.9, 392.8, 369.6, 342.3, 332.3, 373.1, 340.5, 347.5, 350.2, 391.0, 361.9, 395.1, 339.1, 376.1, 323.5, 327.2, 369.5, 371.2, 386.2, 347.4, 359.0, 385.2, 400.0, 378.0, 379.3, 393.7, 383.70000000000005, 360.1, 356.3, 371.5, 375.7, 389.20000000000005, 395.1, 378.1, 374.8, 371.2, 396.4, 391.70000000000005, 348.3, 384.0, 370.6, 375.2, 378.4, 381.1, 396.0, 359.9, 373.6, 390.1, 381.1, 376.8, 368.0, 380.2, 372.9, 312.70000000000005, 363.1, 381.4, 377.4, 400.0, 373.8, 380.7, 376.9, 377.5, 349.2, 391.9, 390.0, 389.2, 350.4, 383.8, 384.8, 367.8, 395.5, 376.6, 358.79999999999995, 385.6, 379.60000000000014, 391.0, 379.1, 371.2, 340.4, 385.0, 345.4, 369.6, 399.1, 363.9, 391.0, 400.0, 391.9, 369.6, 375.0, 367.1, 374.5, 362.4, 374.7, 393.7], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [176.0, 197.3, 165.2, 188.3, 174.8, 200.0, 185.6, 196.4, 179.3, 149.9, 191.0, 196.4, 186.5, 163.4, 192.8, 200.0, 194.6, 161.0, 131.0, 188.3, 196.4, 107.9, 157.1, 200.0, 145.4, 175.1, 164.0, 168.5, 154.1, 181.1, 193.7, 197.3, 181.4, 165.5, 194.0, 199.1, 163.1, 164.0, 192.8, 179.3, 117.5, 170.0, 190.1, 106.1, 180.2, 176.3, 173.0, 189.2, 199.1, 181.1, 173.0, 154.4, 182.0, 161.0, 185.0, 198.2, 200.0, 200.0, 200.0, 167.0, 186.5, 192.8, 193.7, 200.0, 196.4, 176.3, 182.0, 166.1, 200.0, 110.3, 169.4, 190.1, 191.0, 175.7, 200.0, 189.2, 194.0, 199.1, 176.0, 196.1, 174.8, 200.0, 175.1, 187.1, 199.1, 197.3, 195.5, 195.2, 129.2, 199.1, 194.0, 182.0, 166.4, 189.2, 194.6, 173.6, 196.4, 173.0, 199.1, 173.0, 194.0, 200.0, 176.9, 170.0, 167.6, 200.0, 190.1, 200.0, 188.3, 192.8, 195.5, 173.3, 161.0, 191.0, 183.2, 188.0, 182.9, 185.0, 147.2, 147.5, 178.39999999999998, 184.7, 187.4, 191.0, 190.1, 182.3, 200.0, 200.0, 185.0, 183.8, 194.6, 184.1, 188.3, 185.6, 182.89999999999998, 194.6, 149.0, 189.2, 200.0, 191.9, 185.0, 200.0, 196.4, 192.8, 173.0, 163.4, 191.0, 192.8, 186.8, 194.0, 186.5, 173.3, 199.1, 196.4, 185.6, 191.0, 185.0, 159.79999999999995, 196.4, 189.2, 187.4, 189.19999999999993, 192.8, 198.2, 185.6, 192.5, 189.2, 182.0, 148.1, 173.3, 191.0, 182.0, 170.6, 162.8, 161.0, 194.6, 199.1, 200.0, 167.9, 182.0, 191.0, 200.0, 200.0, 200.0, 200.0, 191.9, 185.6, 176.0, 194.0, 176.0, 179.0, 181.1, 175.1, 193.4, 179.0, 172.4, 184.7, 185.0, 193.7, 200.0], "policy_predator_policy_reward": [3.0, 5.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 1.0, 13.0, 23.0, 0.0, 28.0, 0.0, 8.0, 8.0, 14.0, 6.0, 15.0, 0.0, 15.0, 0.0, 0.0, 0.0, 5.0, 10.0, 0.0, 2.0, 0.0, 12.0, 3.0, 1.0, 10.0, 26.0, 23.0, 8.0, 6.0, 7.0, 0.0, 9.0, 6.0, 0.0, 16.0, 4.0, 0.0, 16.0, 0.0, 2.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 4.0, 12.0, 0.0, 18.0, 28.0, 3.0, 9.0, 9.0, 0.0, 0.0, 0.0, 2.0, 0.0, 6.0, 0.0, 0.0, 0.0, 8.0, 1.0, 0.0, 0.0, 1.0, 0.0, 20.0, 0.0, 2.0, 6.0, 10.0, 5.0, 0.0, 7.0, 0.0, 9.0, 0.0, 9.0, 0.0, 2.0, 11.0, 2.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 9.0, 7.0, 4.0, 5.0, 0.0, 5.0, 0.0, 18.0, 0.0, 0.0, 0.0, 3.0, 0.0, 5.0, 0.0, 0.0, 1.0, 4.0, 0.0, 2.0, 0.0, 3.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 14.0, 0.0, 0.0, 0.0, 2.0, 2.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 14.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 8.0, 11.0, 6.0, 6.0, 0.0, 12.0, 6.0, 8.0, 0.0, 0.0, 8.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 5.0, 0.0, 7.0, 1.0, 5.0, 11.0, 0.0, 0.0, 5.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 10.229149630148992, "mean_inference_ms": 25.162957595590527, "mean_action_processing_ms": 4.947119915565451, "mean_env_wait_ms": 6.126997956718525, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.010855555534362793, "StateBufferConnector_ms": 0.011014342308044434, "ViewRequirementAgentConnector_ms": 0.31209075450897217}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": 312.70000000000005, "episode_return_mean": 372.991, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2880000, "num_agent_steps_trained": 2880000, "num_env_steps_sampled": 720000, "num_env_steps_trained": 720000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 189.5851313291515, "num_env_steps_trained_throughput_per_sec": 189.5851313291515, "timesteps_total": 720000, "num_env_steps_sampled_lifetime": 720000, "num_agent_steps_sampled_lifetime": 2880000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2880000, "timers": {"training_iteration_time_ms": 24170.24, "restore_workers_time_ms": 0.02, "training_step_time_ms": 24170.172, "sample_time_ms": 3790.773, "learn_time_ms": 20352.071, "learn_throughput": 196.54, "synch_weights_time_ms": 24.403}, "counters": {"num_env_steps_sampled": 720000, "num_env_steps_trained": 720000, "num_agent_steps_sampled": 2880000, "num_agent_steps_trained": 2880000}, "done": false, "training_iteration": 180, "trial_id": "75ec3_00000", "date": "2024-08-13_05-54-32", "timestamp": 1723542872, "time_this_iter_s": 21.142725944519043, "time_total_s": 15618.12468123436, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b1ae2ca0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 15618.12468123436, "iterations_since_restore": 180, "perf": {"cpu_util_percent": 74.41666666666667, "ram_util_percent": 83.38333333333335}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.1396757375310966, "cur_kl_coeff": 0.02167325159515201, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.3722281185866065, "policy_loss": -0.006645903470753519, "vf_loss": 0.37856060703526495, "vf_explained_var": 0.40475062724774474, "kl": 0.014460888147355926, "entropy": 1.1490917465043446, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 341145.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.49095005409388, "cur_kl_coeff": 6.550516067680619e-28, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.18344485105936806, "policy_loss": -0.004263430717278016, "vf_loss": 0.18770828076015245, "vf_explained_var": 0.062275564607489044, "kl": 0.02076655555885708, "entropy": 0.973107892810983, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 341145.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 724000, "num_env_steps_trained": 724000, "num_agent_steps_sampled": 2896000, "num_agent_steps_trained": 2896000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": 312.70000000000005, "episode_reward_mean": 374.7010000000001, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 106.1, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 28.0}, "policy_reward_mean": {"prey_policy": 183.7505, "predator_policy": 3.6}, "custom_metrics": {}, "hist_stats": {"episode_reward": [339.1, 376.1, 323.5, 327.2, 369.5, 371.2, 386.2, 347.4, 359.0, 385.2, 400.0, 378.0, 379.3, 393.7, 383.70000000000005, 360.1, 356.3, 371.5, 375.7, 389.20000000000005, 395.1, 378.1, 374.8, 371.2, 396.4, 391.70000000000005, 348.3, 384.0, 370.6, 375.2, 378.4, 381.1, 396.0, 359.9, 373.6, 390.1, 381.1, 376.8, 368.0, 380.2, 372.9, 312.70000000000005, 363.1, 381.4, 377.4, 400.0, 373.8, 380.7, 376.9, 377.5, 349.2, 391.9, 390.0, 389.2, 350.4, 383.8, 384.8, 367.8, 395.5, 376.6, 358.79999999999995, 385.6, 379.60000000000014, 391.0, 379.1, 371.2, 340.4, 385.0, 345.4, 369.6, 399.1, 363.9, 391.0, 400.0, 391.9, 369.6, 375.0, 367.1, 374.5, 362.4, 374.7, 393.7, 366.8, 366.8, 373.7, 390.1, 385.4, 363.0, 388.3, 381.6, 380.4, 344.5, 381.4, 375.70000000000005, 374.6, 368.6, 375.7, 359.4, 391.9, 395.5], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [163.1, 164.0, 192.8, 179.3, 117.5, 170.0, 190.1, 106.1, 180.2, 176.3, 173.0, 189.2, 199.1, 181.1, 173.0, 154.4, 182.0, 161.0, 185.0, 198.2, 200.0, 200.0, 200.0, 167.0, 186.5, 192.8, 193.7, 200.0, 196.4, 176.3, 182.0, 166.1, 200.0, 110.3, 169.4, 190.1, 191.0, 175.7, 200.0, 189.2, 194.0, 199.1, 176.0, 196.1, 174.8, 200.0, 175.1, 187.1, 199.1, 197.3, 195.5, 195.2, 129.2, 199.1, 194.0, 182.0, 166.4, 189.2, 194.6, 173.6, 196.4, 173.0, 199.1, 173.0, 194.0, 200.0, 176.9, 170.0, 167.6, 200.0, 190.1, 200.0, 188.3, 192.8, 195.5, 173.3, 161.0, 191.0, 183.2, 188.0, 182.9, 185.0, 147.2, 147.5, 178.39999999999998, 184.7, 187.4, 191.0, 190.1, 182.3, 200.0, 200.0, 185.0, 183.8, 194.6, 184.1, 188.3, 185.6, 182.89999999999998, 194.6, 149.0, 189.2, 200.0, 191.9, 185.0, 200.0, 196.4, 192.8, 173.0, 163.4, 191.0, 192.8, 186.8, 194.0, 186.5, 173.3, 199.1, 196.4, 185.6, 191.0, 185.0, 159.79999999999995, 196.4, 189.2, 187.4, 189.19999999999993, 192.8, 198.2, 185.6, 192.5, 189.2, 182.0, 148.1, 173.3, 191.0, 182.0, 170.6, 162.8, 161.0, 194.6, 199.1, 200.0, 167.9, 182.0, 191.0, 200.0, 200.0, 200.0, 200.0, 191.9, 185.6, 176.0, 194.0, 176.0, 179.0, 181.1, 175.1, 193.4, 179.0, 172.4, 184.7, 185.0, 193.7, 200.0, 165.8, 179.0, 188.0, 174.8, 182.0, 172.7, 190.1, 200.0, 196.1, 188.3, 159.2, 183.8, 200.0, 188.3, 200.0, 179.6, 196.4, 176.0, 173.0, 159.5, 193.7, 184.7, 199.1, 176.6, 196.4, 168.2, 182.9, 181.7, 190.1, 185.6, 182.3, 166.1, 191.9, 200.0, 198.2, 197.3], "policy_predator_policy_reward": [0.0, 12.0, 3.0, 1.0, 10.0, 26.0, 23.0, 8.0, 6.0, 7.0, 0.0, 9.0, 6.0, 0.0, 16.0, 4.0, 0.0, 16.0, 0.0, 2.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 4.0, 12.0, 0.0, 18.0, 28.0, 3.0, 9.0, 9.0, 0.0, 0.0, 0.0, 2.0, 0.0, 6.0, 0.0, 0.0, 0.0, 8.0, 1.0, 0.0, 0.0, 1.0, 0.0, 20.0, 0.0, 2.0, 6.0, 10.0, 5.0, 0.0, 7.0, 0.0, 9.0, 0.0, 9.0, 0.0, 2.0, 11.0, 2.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 9.0, 7.0, 4.0, 5.0, 0.0, 5.0, 0.0, 18.0, 0.0, 0.0, 0.0, 3.0, 0.0, 5.0, 0.0, 0.0, 1.0, 4.0, 0.0, 2.0, 0.0, 3.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 14.0, 0.0, 0.0, 0.0, 2.0, 2.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 14.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 8.0, 11.0, 6.0, 6.0, 0.0, 12.0, 6.0, 8.0, 0.0, 0.0, 8.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 5.0, 0.0, 7.0, 1.0, 5.0, 11.0, 0.0, 0.0, 5.0, 0.0, 0.0, 11.0, 11.0, 0.0, 4.0, 10.0, 9.0, 0.0, 0.0, 0.0, 1.0, 9.0, 11.0, 0.0, 0.0, 2.0, 0.0, 8.0, 0.0, 0.0, 12.0, 0.0, 3.0, 0.0, 0.0, 0.0, 10.0, 0.0, 4.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 10.187469685969443, "mean_inference_ms": 25.062819052123597, "mean_action_processing_ms": 4.92588694323387, "mean_env_wait_ms": 6.099367662373436, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01090705394744873, "StateBufferConnector_ms": 0.01122748851776123, "ViewRequirementAgentConnector_ms": 0.3082902431488037}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": 312.70000000000005, "episode_return_mean": 374.7010000000001, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2896000, "num_agent_steps_trained": 2896000, "num_env_steps_sampled": 724000, "num_env_steps_trained": 724000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 182.62750296032465, "num_env_steps_trained_throughput_per_sec": 182.62750296032465, "timesteps_total": 724000, "num_env_steps_sampled_lifetime": 724000, "num_agent_steps_sampled_lifetime": 2896000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2896000, "timers": {"training_iteration_time_ms": 23659.031, "restore_workers_time_ms": 0.02, "training_step_time_ms": 23658.964, "sample_time_ms": 3775.156, "learn_time_ms": 19856.667, "learn_throughput": 201.444, "synch_weights_time_ms": 24.175}, "counters": {"num_env_steps_sampled": 724000, "num_env_steps_trained": 724000, "num_agent_steps_sampled": 2896000, "num_agent_steps_trained": 2896000}, "done": false, "training_iteration": 181, "trial_id": "75ec3_00000", "date": "2024-08-13_05-54-54", "timestamp": 1723542894, "time_this_iter_s": 21.952398777008057, "time_total_s": 15640.077080011368, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b24eb430>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 15640.077080011368, "iterations_since_restore": 181, "perf": {"cpu_util_percent": 75.54193548387096, "ram_util_percent": 83.3225806451613}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8753183282005093, "cur_kl_coeff": 0.02167325159515201, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.3748963325475983, "policy_loss": -0.0014698461799453647, "vf_loss": 0.376222979067948, "vf_explained_var": 0.37369386200551635, "kl": 0.006607189289345268, "entropy": 1.1558665965599988, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 343035.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.47162857111050654, "cur_kl_coeff": 9.82577410152093e-28, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.14692516772953607, "policy_loss": -0.0007394070812210283, "vf_loss": 0.14766457465550586, "vf_explained_var": -0.030123213737729995, "kl": 0.018558212681545696, "entropy": 0.9400688481393945, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 343035.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 728000, "num_env_steps_trained": 728000, "num_agent_steps_sampled": 2912000, "num_agent_steps_trained": 2912000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": 312.70000000000005, "episode_reward_mean": 375.599, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 129.2, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 21.0}, "policy_reward_mean": {"prey_policy": 184.6745, "predator_policy": 3.125}, "custom_metrics": {}, "hist_stats": {"episode_reward": [371.2, 396.4, 391.70000000000005, 348.3, 384.0, 370.6, 375.2, 378.4, 381.1, 396.0, 359.9, 373.6, 390.1, 381.1, 376.8, 368.0, 380.2, 372.9, 312.70000000000005, 363.1, 381.4, 377.4, 400.0, 373.8, 380.7, 376.9, 377.5, 349.2, 391.9, 390.0, 389.2, 350.4, 383.8, 384.8, 367.8, 395.5, 376.6, 358.79999999999995, 385.6, 379.60000000000014, 391.0, 379.1, 371.2, 340.4, 385.0, 345.4, 369.6, 399.1, 363.9, 391.0, 400.0, 391.9, 369.6, 375.0, 367.1, 374.5, 362.4, 374.7, 393.7, 366.8, 366.8, 373.7, 390.1, 385.4, 363.0, 388.3, 381.6, 380.4, 344.5, 381.4, 375.70000000000005, 374.6, 368.6, 375.7, 359.4, 391.9, 395.5, 384.0, 379.5, 375.7, 371.20000000000005, 366.3, 358.7, 361.3, 387.00000000000006, 352.5, 390.1, 380.2, 350.0, 387.1, 372.1, 394.0, 397.3, 346.3, 368.1, 377.2, 396.4, 364.4, 379.1, 371.2], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [175.1, 187.1, 199.1, 197.3, 195.5, 195.2, 129.2, 199.1, 194.0, 182.0, 166.4, 189.2, 194.6, 173.6, 196.4, 173.0, 199.1, 173.0, 194.0, 200.0, 176.9, 170.0, 167.6, 200.0, 190.1, 200.0, 188.3, 192.8, 195.5, 173.3, 161.0, 191.0, 183.2, 188.0, 182.9, 185.0, 147.2, 147.5, 178.39999999999998, 184.7, 187.4, 191.0, 190.1, 182.3, 200.0, 200.0, 185.0, 183.8, 194.6, 184.1, 188.3, 185.6, 182.89999999999998, 194.6, 149.0, 189.2, 200.0, 191.9, 185.0, 200.0, 196.4, 192.8, 173.0, 163.4, 191.0, 192.8, 186.8, 194.0, 186.5, 173.3, 199.1, 196.4, 185.6, 191.0, 185.0, 159.79999999999995, 196.4, 189.2, 187.4, 189.19999999999993, 192.8, 198.2, 185.6, 192.5, 189.2, 182.0, 148.1, 173.3, 191.0, 182.0, 170.6, 162.8, 161.0, 194.6, 199.1, 200.0, 167.9, 182.0, 191.0, 200.0, 200.0, 200.0, 200.0, 191.9, 185.6, 176.0, 194.0, 176.0, 179.0, 181.1, 175.1, 193.4, 179.0, 172.4, 184.7, 185.0, 193.7, 200.0, 165.8, 179.0, 188.0, 174.8, 182.0, 172.7, 190.1, 200.0, 196.1, 188.3, 159.2, 183.8, 200.0, 188.3, 200.0, 179.6, 196.4, 176.0, 173.0, 159.5, 193.7, 184.7, 199.1, 176.6, 196.4, 168.2, 182.9, 181.7, 190.1, 185.6, 182.3, 166.1, 191.9, 200.0, 198.2, 197.3, 176.0, 200.0, 195.5, 176.0, 188.3, 187.4, 200.0, 171.2, 176.3, 182.0, 172.7, 170.0, 172.1, 189.2, 198.2, 186.79999999999998, 180.5, 161.0, 190.1, 200.0, 198.2, 173.0, 164.0, 161.0, 194.0, 190.1, 184.7, 187.4, 200.0, 191.0, 200.0, 197.3, 191.9, 133.4, 165.2, 191.9, 181.1, 190.1, 200.0, 196.4, 148.4, 200.0, 184.1, 185.0, 183.2, 182.0], "policy_predator_policy_reward": [8.0, 1.0, 0.0, 0.0, 1.0, 0.0, 20.0, 0.0, 2.0, 6.0, 10.0, 5.0, 0.0, 7.0, 0.0, 9.0, 0.0, 9.0, 0.0, 2.0, 11.0, 2.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 9.0, 7.0, 4.0, 5.0, 0.0, 5.0, 0.0, 18.0, 0.0, 0.0, 0.0, 3.0, 0.0, 5.0, 0.0, 0.0, 1.0, 4.0, 0.0, 2.0, 0.0, 3.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 14.0, 0.0, 0.0, 0.0, 2.0, 2.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 14.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 8.0, 11.0, 6.0, 6.0, 0.0, 12.0, 6.0, 8.0, 0.0, 0.0, 8.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 5.0, 0.0, 7.0, 1.0, 5.0, 11.0, 0.0, 0.0, 5.0, 0.0, 0.0, 11.0, 11.0, 0.0, 4.0, 10.0, 9.0, 0.0, 0.0, 0.0, 1.0, 9.0, 11.0, 0.0, 0.0, 2.0, 0.0, 8.0, 0.0, 0.0, 12.0, 0.0, 3.0, 0.0, 0.0, 0.0, 10.0, 0.0, 4.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 16.0, 0.0, 0.0, 0.0, 2.0, 0.0, 2.0, 9.0, 0.0, 0.0, 0.0, 9.0, 12.0, 13.0, 1.0, 2.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 21.0, 0.0, 11.0, 6.0, 0.0, 0.0, 0.0, 16.0, 0.0, 5.0, 5.0, 0.0, 6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 10.133139606197352, "mean_inference_ms": 25.288182946527233, "mean_action_processing_ms": 5.02820313395647, "mean_env_wait_ms": 5.586121512637943, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01177072525024414, "StateBufferConnector_ms": 0.012728333473205566, "ViewRequirementAgentConnector_ms": 0.25288069248199463}, "num_episodes": 23, "episode_return_max": 400.0, "episode_return_min": 312.70000000000005, "episode_return_mean": 375.599, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2912000, "num_agent_steps_trained": 2912000, "num_env_steps_sampled": 728000, "num_env_steps_trained": 728000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 180.22688679823952, "num_env_steps_trained_throughput_per_sec": 180.22688679823952, "timesteps_total": 728000, "num_env_steps_sampled_lifetime": 728000, "num_agent_steps_sampled_lifetime": 2912000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2912000, "timers": {"training_iteration_time_ms": 23076.662, "restore_workers_time_ms": 0.019, "training_step_time_ms": 23076.598, "sample_time_ms": 3714.947, "learn_time_ms": 19334.92, "learn_throughput": 206.88, "synch_weights_time_ms": 23.613}, "counters": {"num_env_steps_sampled": 728000, "num_env_steps_trained": 728000, "num_agent_steps_sampled": 2912000, "num_agent_steps_trained": 2912000}, "done": false, "training_iteration": 182, "trial_id": "75ec3_00000", "date": "2024-08-13_05-55-16", "timestamp": 1723542916, "time_this_iter_s": 22.280953645706177, "time_total_s": 15662.358033657074, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b25823a0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 15662.358033657074, "iterations_since_restore": 182, "perf": {"cpu_util_percent": 75.109375, "ram_util_percent": 83.35625}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8176717468276227, "cur_kl_coeff": 0.02167325159515201, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.4464835509332636, "policy_loss": -0.00169200849270931, "vf_loss": 0.44792208252129734, "vf_explained_var": 0.34536931287674677, "kl": 0.01169535351158129, "entropy": 1.1147653207577095, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 344925.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5163861360913389, "cur_kl_coeff": 9.82577410152093e-28, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.2107844312946317, "policy_loss": -0.0013693379543761096, "vf_loss": 0.21215376907969744, "vf_explained_var": 0.1412437295156812, "kl": 0.008831412987887793, "entropy": 0.8829468785139619, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 344925.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 732000, "num_env_steps_trained": 732000, "num_agent_steps_sampled": 2928000, "num_agent_steps_trained": 2928000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": 340.4, "episode_reward_mean": 376.352, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 133.4, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 21.0}, "policy_reward_mean": {"prey_policy": 185.291, "predator_policy": 2.885}, "custom_metrics": {}, "hist_stats": {"episode_reward": [400.0, 373.8, 380.7, 376.9, 377.5, 349.2, 391.9, 390.0, 389.2, 350.4, 383.8, 384.8, 367.8, 395.5, 376.6, 358.79999999999995, 385.6, 379.60000000000014, 391.0, 379.1, 371.2, 340.4, 385.0, 345.4, 369.6, 399.1, 363.9, 391.0, 400.0, 391.9, 369.6, 375.0, 367.1, 374.5, 362.4, 374.7, 393.7, 366.8, 366.8, 373.7, 390.1, 385.4, 363.0, 388.3, 381.6, 380.4, 344.5, 381.4, 375.70000000000005, 374.6, 368.6, 375.7, 359.4, 391.9, 395.5, 384.0, 379.5, 375.7, 371.20000000000005, 366.3, 358.7, 361.3, 387.00000000000006, 352.5, 390.1, 380.2, 350.0, 387.1, 372.1, 394.0, 397.3, 346.3, 368.1, 377.2, 396.4, 364.4, 379.1, 371.2, 367.7, 358.9, 386.4, 380.1, 360.0, 379.3, 371.5, 384.5, 386.8, 381.1, 369.6, 379.1, 377.6, 364.9, 383.0, 391.9, 380.2, 371.3, 389.20000000000005, 382.0, 398.2, 362.1], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [200.0, 200.0, 185.0, 183.8, 194.6, 184.1, 188.3, 185.6, 182.89999999999998, 194.6, 149.0, 189.2, 200.0, 191.9, 185.0, 200.0, 196.4, 192.8, 173.0, 163.4, 191.0, 192.8, 186.8, 194.0, 186.5, 173.3, 199.1, 196.4, 185.6, 191.0, 185.0, 159.79999999999995, 196.4, 189.2, 187.4, 189.19999999999993, 192.8, 198.2, 185.6, 192.5, 189.2, 182.0, 148.1, 173.3, 191.0, 182.0, 170.6, 162.8, 161.0, 194.6, 199.1, 200.0, 167.9, 182.0, 191.0, 200.0, 200.0, 200.0, 200.0, 191.9, 185.6, 176.0, 194.0, 176.0, 179.0, 181.1, 175.1, 193.4, 179.0, 172.4, 184.7, 185.0, 193.7, 200.0, 165.8, 179.0, 188.0, 174.8, 182.0, 172.7, 190.1, 200.0, 196.1, 188.3, 159.2, 183.8, 200.0, 188.3, 200.0, 179.6, 196.4, 176.0, 173.0, 159.5, 193.7, 184.7, 199.1, 176.6, 196.4, 168.2, 182.9, 181.7, 190.1, 185.6, 182.3, 166.1, 191.9, 200.0, 198.2, 197.3, 176.0, 200.0, 195.5, 176.0, 188.3, 187.4, 200.0, 171.2, 176.3, 182.0, 172.7, 170.0, 172.1, 189.2, 198.2, 186.79999999999998, 180.5, 161.0, 190.1, 200.0, 198.2, 173.0, 164.0, 161.0, 194.0, 190.1, 184.7, 187.4, 200.0, 191.0, 200.0, 197.3, 191.9, 133.4, 165.2, 191.9, 181.1, 190.1, 200.0, 196.4, 148.4, 200.0, 184.1, 185.0, 183.2, 182.0, 188.0, 166.7, 154.1, 192.8, 181.4, 200.0, 200.0, 175.1, 179.0, 164.0, 191.0, 188.3, 169.39999999999998, 196.1, 193.4, 190.1, 189.2, 194.6, 192.8, 188.3, 185.0, 176.6, 169.1, 200.0, 185.6, 188.0, 179.9, 176.0, 197.0, 179.0, 191.9, 200.0, 188.3, 191.9, 182.3, 179.0, 196.4, 192.79999999999998, 199.1, 182.9, 200.0, 198.2, 180.2, 176.9], "policy_predator_policy_reward": [0.0, 0.0, 1.0, 4.0, 0.0, 2.0, 0.0, 3.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 14.0, 0.0, 0.0, 0.0, 2.0, 2.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 14.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 8.0, 11.0, 6.0, 6.0, 0.0, 12.0, 6.0, 8.0, 0.0, 0.0, 8.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 5.0, 0.0, 7.0, 1.0, 5.0, 11.0, 0.0, 0.0, 5.0, 0.0, 0.0, 11.0, 11.0, 0.0, 4.0, 10.0, 9.0, 0.0, 0.0, 0.0, 1.0, 9.0, 11.0, 0.0, 0.0, 2.0, 0.0, 8.0, 0.0, 0.0, 12.0, 0.0, 3.0, 0.0, 0.0, 0.0, 10.0, 0.0, 4.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 16.0, 0.0, 0.0, 0.0, 2.0, 0.0, 2.0, 9.0, 0.0, 0.0, 0.0, 9.0, 12.0, 13.0, 1.0, 2.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 21.0, 0.0, 11.0, 6.0, 0.0, 0.0, 0.0, 16.0, 0.0, 5.0, 5.0, 0.0, 6.0, 0.0, 13.0, 1.0, 11.0, 0.0, 5.0, 0.0, 5.0, 4.0, 13.0, 0.0, 0.0, 6.0, 0.0, 0.0, 1.0, 0.0, 3.0, 0.0, 0.0, 0.0, 8.0, 0.0, 10.0, 4.0, 0.0, 9.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 10.08121473047993, "mean_inference_ms": 24.81095339643727, "mean_action_processing_ms": 4.873354482743602, "mean_env_wait_ms": 6.03061533034406, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01294565200805664, "StateBufferConnector_ms": 0.012669682502746582, "ViewRequirementAgentConnector_ms": 0.26008689403533936}, "num_episodes": 22, "episode_return_max": 400.0, "episode_return_min": 340.4, "episode_return_mean": 376.352, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2928000, "num_agent_steps_trained": 2928000, "num_env_steps_sampled": 732000, "num_env_steps_trained": 732000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 190.10976672187752, "num_env_steps_trained_throughput_per_sec": 190.10976672187752, "timesteps_total": 732000, "num_env_steps_sampled_lifetime": 732000, "num_agent_steps_sampled_lifetime": 2928000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2928000, "timers": {"training_iteration_time_ms": 22738.589, "restore_workers_time_ms": 0.019, "training_step_time_ms": 22738.525, "sample_time_ms": 3696.598, "learn_time_ms": 19014.574, "learn_throughput": 210.365, "synch_weights_time_ms": 23.918}, "counters": {"num_env_steps_sampled": 732000, "num_env_steps_trained": 732000, "num_agent_steps_sampled": 2928000, "num_agent_steps_trained": 2928000}, "done": false, "training_iteration": 183, "trial_id": "75ec3_00000", "date": "2024-08-13_05-55-37", "timestamp": 1723542937, "time_this_iter_s": 21.120206832885742, "time_total_s": 15683.47824048996, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b25678b0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 15683.47824048996, "iterations_since_restore": 183, "perf": {"cpu_util_percent": 74.32413793103447, "ram_util_percent": 83.34827586206897}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8835481162660968, "cur_kl_coeff": 0.02167325159515201, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.32271887500821667, "policy_loss": -0.002272368018717441, "vf_loss": 0.3248523784638752, "vf_explained_var": 0.48290794050251995, "kl": 0.006407199955245737, "entropy": 1.1450164646698684, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 346815.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5047918091020571, "cur_kl_coeff": 9.82577410152093e-28, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.17544084799195092, "policy_loss": -0.0017094321415892669, "vf_loss": 0.17715028102521843, "vf_explained_var": -0.021643004404804694, "kl": 0.01963925969332637, "entropy": 0.9176623754715794, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 346815.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 736000, "num_env_steps_trained": 736000, "num_agent_steps_sampled": 2944000, "num_agent_steps_trained": 2944000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": 340.4, "episode_reward_mean": 376.358, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 133.4, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 21.0}, "policy_reward_mean": {"prey_policy": 185.00900000000001, "predator_policy": 3.17}, "custom_metrics": {}, "hist_stats": {"episode_reward": [391.0, 379.1, 371.2, 340.4, 385.0, 345.4, 369.6, 399.1, 363.9, 391.0, 400.0, 391.9, 369.6, 375.0, 367.1, 374.5, 362.4, 374.7, 393.7, 366.8, 366.8, 373.7, 390.1, 385.4, 363.0, 388.3, 381.6, 380.4, 344.5, 381.4, 375.70000000000005, 374.6, 368.6, 375.7, 359.4, 391.9, 395.5, 384.0, 379.5, 375.7, 371.20000000000005, 366.3, 358.7, 361.3, 387.00000000000006, 352.5, 390.1, 380.2, 350.0, 387.1, 372.1, 394.0, 397.3, 346.3, 368.1, 377.2, 396.4, 364.4, 379.1, 371.2, 367.7, 358.9, 386.4, 380.1, 360.0, 379.3, 371.5, 384.5, 386.8, 381.1, 369.6, 379.1, 377.6, 364.9, 383.0, 391.9, 380.2, 371.3, 389.20000000000005, 382.0, 398.2, 362.1, 390.1, 385.7, 367.2, 380.2, 380.3, 344.6, 380.6, 394.6, 357.0, 371.0, 378.0, 368.90000000000003, 388.3, 369.4, 392.0, 378.5, 390.8, 395.5], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [192.8, 198.2, 185.6, 192.5, 189.2, 182.0, 148.1, 173.3, 191.0, 182.0, 170.6, 162.8, 161.0, 194.6, 199.1, 200.0, 167.9, 182.0, 191.0, 200.0, 200.0, 200.0, 200.0, 191.9, 185.6, 176.0, 194.0, 176.0, 179.0, 181.1, 175.1, 193.4, 179.0, 172.4, 184.7, 185.0, 193.7, 200.0, 165.8, 179.0, 188.0, 174.8, 182.0, 172.7, 190.1, 200.0, 196.1, 188.3, 159.2, 183.8, 200.0, 188.3, 200.0, 179.6, 196.4, 176.0, 173.0, 159.5, 193.7, 184.7, 199.1, 176.6, 196.4, 168.2, 182.9, 181.7, 190.1, 185.6, 182.3, 166.1, 191.9, 200.0, 198.2, 197.3, 176.0, 200.0, 195.5, 176.0, 188.3, 187.4, 200.0, 171.2, 176.3, 182.0, 172.7, 170.0, 172.1, 189.2, 198.2, 186.79999999999998, 180.5, 161.0, 190.1, 200.0, 198.2, 173.0, 164.0, 161.0, 194.0, 190.1, 184.7, 187.4, 200.0, 191.0, 200.0, 197.3, 191.9, 133.4, 165.2, 191.9, 181.1, 190.1, 200.0, 196.4, 148.4, 200.0, 184.1, 185.0, 183.2, 182.0, 188.0, 166.7, 154.1, 192.8, 181.4, 200.0, 200.0, 175.1, 179.0, 164.0, 191.0, 188.3, 169.39999999999998, 196.1, 193.4, 190.1, 189.2, 194.6, 192.8, 188.3, 185.0, 176.6, 169.1, 200.0, 185.6, 188.0, 179.9, 176.0, 197.0, 179.0, 191.9, 200.0, 188.3, 191.9, 182.3, 179.0, 196.4, 192.79999999999998, 199.1, 182.9, 200.0, 198.2, 180.2, 176.9, 200.0, 190.1, 182.0, 193.7, 200.0, 156.2, 189.2, 191.0, 188.3, 188.0, 152.0, 176.6, 170.0, 194.6, 194.6, 200.0, 154.39999999999998, 194.6, 162.8, 198.2, 200.0, 167.0, 160.4, 186.5, 192.8, 195.5, 195.2, 165.2, 197.0, 191.0, 188.29999999999998, 186.2, 192.8, 197.0, 200.0, 195.5], "policy_predator_policy_reward": [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 8.0, 11.0, 6.0, 6.0, 0.0, 12.0, 6.0, 8.0, 0.0, 0.0, 8.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 5.0, 0.0, 7.0, 1.0, 5.0, 11.0, 0.0, 0.0, 5.0, 0.0, 0.0, 11.0, 11.0, 0.0, 4.0, 10.0, 9.0, 0.0, 0.0, 0.0, 1.0, 9.0, 11.0, 0.0, 0.0, 2.0, 0.0, 8.0, 0.0, 0.0, 12.0, 0.0, 3.0, 0.0, 0.0, 0.0, 10.0, 0.0, 4.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 16.0, 0.0, 0.0, 0.0, 2.0, 0.0, 2.0, 9.0, 0.0, 0.0, 0.0, 9.0, 12.0, 13.0, 1.0, 2.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 21.0, 0.0, 11.0, 6.0, 0.0, 0.0, 0.0, 16.0, 0.0, 5.0, 5.0, 0.0, 6.0, 0.0, 13.0, 1.0, 11.0, 0.0, 5.0, 0.0, 5.0, 4.0, 13.0, 0.0, 0.0, 6.0, 0.0, 0.0, 1.0, 0.0, 3.0, 0.0, 0.0, 0.0, 8.0, 0.0, 10.0, 4.0, 0.0, 9.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 6.0, 4.0, 5.0, 6.0, 0.0, 0.0, 4.0, 0.0, 10.0, 6.0, 8.0, 8.0, 0.0, 0.0, 0.0, 8.0, 10.0, 0.0, 7.0, 4.0, 12.0, 10.0, 0.0, 0.0, 8.0, 1.0, 0.0, 4.0, 4.0, 0.0, 0.0, 1.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 10.038628502811797, "mean_inference_ms": 24.708816305610558, "mean_action_processing_ms": 4.852000114431886, "mean_env_wait_ms": 6.003179922791573, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01361846923828125, "StateBufferConnector_ms": 0.012672781944274902, "ViewRequirementAgentConnector_ms": 0.26809215545654297}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": 340.4, "episode_return_mean": 376.358, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2944000, "num_agent_steps_trained": 2944000, "num_env_steps_sampled": 736000, "num_env_steps_trained": 736000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 187.54411665069279, "num_env_steps_trained_throughput_per_sec": 187.54411665069279, "timesteps_total": 736000, "num_env_steps_sampled_lifetime": 736000, "num_agent_steps_sampled_lifetime": 2944000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2944000, "timers": {"training_iteration_time_ms": 22859.506, "restore_workers_time_ms": 0.02, "training_step_time_ms": 22859.44, "sample_time_ms": 3728.07, "learn_time_ms": 19102.898, "learn_throughput": 209.392, "synch_weights_time_ms": 24.676}, "counters": {"num_env_steps_sampled": 736000, "num_env_steps_trained": 736000, "num_agent_steps_sampled": 2944000, "num_agent_steps_trained": 2944000}, "done": false, "training_iteration": 184, "trial_id": "75ec3_00000", "date": "2024-08-13_05-55-59", "timestamp": 1723542959, "time_this_iter_s": 21.38482427597046, "time_total_s": 15704.86306476593, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2567280>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 15704.86306476593, "iterations_since_restore": 184, "perf": {"cpu_util_percent": 74.83225806451614, "ram_util_percent": 83.02903225806452}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6224664308722057, "cur_kl_coeff": 0.02167325159515201, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.30099934456071065, "policy_loss": -0.004921190890855595, "vf_loss": 0.3055973254824205, "vf_explained_var": 0.31180907081043907, "kl": 0.014912885285576742, "entropy": 1.192848539352417, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 348705.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4197338299490708, "cur_kl_coeff": 9.82577410152093e-28, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.18501207472943754, "policy_loss": -0.0008698938448947888, "vf_loss": 0.18588196882952213, "vf_explained_var": 0.2084763944464386, "kl": 0.012137530241890099, "entropy": 0.8206945623039569, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 348705.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 740000, "num_env_steps_trained": 740000, "num_agent_steps_sampled": 2960000, "num_agent_steps_trained": 2960000}, "env_runners": {"episode_reward_max": 398.2, "episode_reward_min": 344.5, "episode_reward_mean": 377.37700000000007, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 133.4, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 21.0}, "policy_reward_mean": {"prey_policy": 185.6435, "predator_policy": 3.045}, "custom_metrics": {}, "hist_stats": {"episode_reward": [393.7, 366.8, 366.8, 373.7, 390.1, 385.4, 363.0, 388.3, 381.6, 380.4, 344.5, 381.4, 375.70000000000005, 374.6, 368.6, 375.7, 359.4, 391.9, 395.5, 384.0, 379.5, 375.7, 371.20000000000005, 366.3, 358.7, 361.3, 387.00000000000006, 352.5, 390.1, 380.2, 350.0, 387.1, 372.1, 394.0, 397.3, 346.3, 368.1, 377.2, 396.4, 364.4, 379.1, 371.2, 367.7, 358.9, 386.4, 380.1, 360.0, 379.3, 371.5, 384.5, 386.8, 381.1, 369.6, 379.1, 377.6, 364.9, 383.0, 391.9, 380.2, 371.3, 389.20000000000005, 382.0, 398.2, 362.1, 390.1, 385.7, 367.2, 380.2, 380.3, 344.6, 380.6, 394.6, 357.0, 371.0, 378.0, 368.90000000000003, 388.3, 369.4, 392.0, 378.5, 390.8, 395.5, 366.4, 378.0, 374.8, 391.0, 379.29999999999995, 392.8, 382.9, 377.5, 391.3, 391.0, 368.9, 381.7, 372.6, 366.0, 392.8, 393.3, 361.5, 391.0], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [193.7, 200.0, 165.8, 179.0, 188.0, 174.8, 182.0, 172.7, 190.1, 200.0, 196.1, 188.3, 159.2, 183.8, 200.0, 188.3, 200.0, 179.6, 196.4, 176.0, 173.0, 159.5, 193.7, 184.7, 199.1, 176.6, 196.4, 168.2, 182.9, 181.7, 190.1, 185.6, 182.3, 166.1, 191.9, 200.0, 198.2, 197.3, 176.0, 200.0, 195.5, 176.0, 188.3, 187.4, 200.0, 171.2, 176.3, 182.0, 172.7, 170.0, 172.1, 189.2, 198.2, 186.79999999999998, 180.5, 161.0, 190.1, 200.0, 198.2, 173.0, 164.0, 161.0, 194.0, 190.1, 184.7, 187.4, 200.0, 191.0, 200.0, 197.3, 191.9, 133.4, 165.2, 191.9, 181.1, 190.1, 200.0, 196.4, 148.4, 200.0, 184.1, 185.0, 183.2, 182.0, 188.0, 166.7, 154.1, 192.8, 181.4, 200.0, 200.0, 175.1, 179.0, 164.0, 191.0, 188.3, 169.39999999999998, 196.1, 193.4, 190.1, 189.2, 194.6, 192.8, 188.3, 185.0, 176.6, 169.1, 200.0, 185.6, 188.0, 179.9, 176.0, 197.0, 179.0, 191.9, 200.0, 188.3, 191.9, 182.3, 179.0, 196.4, 192.79999999999998, 199.1, 182.9, 200.0, 198.2, 180.2, 176.9, 200.0, 190.1, 182.0, 193.7, 200.0, 156.2, 189.2, 191.0, 188.3, 188.0, 152.0, 176.6, 170.0, 194.6, 194.6, 200.0, 154.39999999999998, 194.6, 162.8, 198.2, 200.0, 167.0, 160.4, 186.5, 192.8, 195.5, 195.2, 165.2, 197.0, 191.0, 188.29999999999998, 186.2, 192.8, 197.0, 200.0, 195.5, 185.6, 174.8, 173.0, 194.0, 200.0, 174.8, 193.7, 197.3, 199.1, 171.2, 200.0, 192.8, 182.9, 200.0, 185.6, 191.9, 191.0, 197.3, 191.0, 200.0, 191.9, 170.0, 179.6, 196.1, 185.0, 176.6, 149.0, 200.0, 195.5, 197.29999999999998, 197.3, 194.0, 149.0, 195.5, 191.0, 200.0], "policy_predator_policy_reward": [0.0, 0.0, 11.0, 11.0, 0.0, 4.0, 10.0, 9.0, 0.0, 0.0, 0.0, 1.0, 9.0, 11.0, 0.0, 0.0, 2.0, 0.0, 8.0, 0.0, 0.0, 12.0, 0.0, 3.0, 0.0, 0.0, 0.0, 10.0, 0.0, 4.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 16.0, 0.0, 0.0, 0.0, 2.0, 0.0, 2.0, 9.0, 0.0, 0.0, 0.0, 9.0, 12.0, 13.0, 1.0, 2.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 21.0, 0.0, 11.0, 6.0, 0.0, 0.0, 0.0, 16.0, 0.0, 5.0, 5.0, 0.0, 6.0, 0.0, 13.0, 1.0, 11.0, 0.0, 5.0, 0.0, 5.0, 4.0, 13.0, 0.0, 0.0, 6.0, 0.0, 0.0, 1.0, 0.0, 3.0, 0.0, 0.0, 0.0, 8.0, 0.0, 10.0, 4.0, 0.0, 9.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 6.0, 4.0, 5.0, 6.0, 0.0, 0.0, 4.0, 0.0, 10.0, 6.0, 8.0, 8.0, 0.0, 0.0, 0.0, 8.0, 10.0, 0.0, 7.0, 4.0, 12.0, 10.0, 0.0, 0.0, 8.0, 1.0, 0.0, 4.0, 4.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 6.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 7.0, 1.0, 5.0, 11.0, 0.0, 0.0, 17.0, 0.0, 0.0, 0.0, 2.0, 8.0, 9.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 9.996457883789002, "mean_inference_ms": 24.60823644693613, "mean_action_processing_ms": 4.830955520296311, "mean_env_wait_ms": 5.976106295097825, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.013916611671447754, "StateBufferConnector_ms": 0.011409163475036621, "ViewRequirementAgentConnector_ms": 0.2831845283508301}, "num_episodes": 18, "episode_return_max": 398.2, "episode_return_min": 344.5, "episode_return_mean": 377.37700000000007, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2960000, "num_agent_steps_trained": 2960000, "num_env_steps_sampled": 740000, "num_env_steps_trained": 740000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 180.94332889506427, "num_env_steps_trained_throughput_per_sec": 180.94332889506427, "timesteps_total": 740000, "num_env_steps_sampled_lifetime": 740000, "num_agent_steps_sampled_lifetime": 2960000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2960000, "timers": {"training_iteration_time_ms": 22850.131, "restore_workers_time_ms": 0.02, "training_step_time_ms": 22850.064, "sample_time_ms": 3717.871, "learn_time_ms": 19103.382, "learn_throughput": 209.387, "synch_weights_time_ms": 24.906}, "counters": {"num_env_steps_sampled": 740000, "num_env_steps_trained": 740000, "num_agent_steps_sampled": 2960000, "num_agent_steps_trained": 2960000}, "done": false, "training_iteration": 185, "trial_id": "75ec3_00000", "date": "2024-08-13_05-56-21", "timestamp": 1723542981, "time_this_iter_s": 22.177295923233032, "time_total_s": 15727.040360689163, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b24951f0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 15727.040360689163, "iterations_since_restore": 185, "perf": {"cpu_util_percent": 76.13225806451612, "ram_util_percent": 83.0967741935484}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.753358893916405, "cur_kl_coeff": 0.02167325159515201, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.3060992528245878, "policy_loss": -0.006331558110409234, "vf_loss": 0.31205371124719183, "vf_explained_var": 0.27474077731843977, "kl": 0.017399370112947527, "entropy": 1.224603249534728, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 350595.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.32588406788116253, "cur_kl_coeff": 9.82577410152093e-28, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.1242405000130434, "policy_loss": -0.0008010572709497951, "vf_loss": 0.12504155667795597, "vf_explained_var": 0.014835039333060936, "kl": 0.015206503193531748, "entropy": 0.8020318219586025, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 350595.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 744000, "num_env_steps_trained": 744000, "num_agent_steps_sampled": 2976000, "num_agent_steps_trained": 2976000}, "env_runners": {"episode_reward_max": 399.1, "episode_reward_min": 344.6, "episode_reward_mean": 377.76200000000006, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 133.4, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 21.0}, "policy_reward_mean": {"prey_policy": 185.71099999999998, "predator_policy": 3.17}, "custom_metrics": {}, "hist_stats": {"episode_reward": [395.5, 384.0, 379.5, 375.7, 371.20000000000005, 366.3, 358.7, 361.3, 387.00000000000006, 352.5, 390.1, 380.2, 350.0, 387.1, 372.1, 394.0, 397.3, 346.3, 368.1, 377.2, 396.4, 364.4, 379.1, 371.2, 367.7, 358.9, 386.4, 380.1, 360.0, 379.3, 371.5, 384.5, 386.8, 381.1, 369.6, 379.1, 377.6, 364.9, 383.0, 391.9, 380.2, 371.3, 389.20000000000005, 382.0, 398.2, 362.1, 390.1, 385.7, 367.2, 380.2, 380.3, 344.6, 380.6, 394.6, 357.0, 371.0, 378.0, 368.90000000000003, 388.3, 369.4, 392.0, 378.5, 390.8, 395.5, 366.4, 378.0, 374.8, 391.0, 379.29999999999995, 392.8, 382.9, 377.5, 391.3, 391.0, 368.9, 381.7, 372.6, 366.0, 392.8, 393.3, 361.5, 391.0, 394.4, 375.7, 368.8, 363.3, 347.6, 394.6, 375.9, 382.2, 388.29999999999995, 399.1, 366.1, 359.5, 380.4, 368.29999999999995, 384.8, 367.69999999999993, 394.6, 388.8], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [198.2, 197.3, 176.0, 200.0, 195.5, 176.0, 188.3, 187.4, 200.0, 171.2, 176.3, 182.0, 172.7, 170.0, 172.1, 189.2, 198.2, 186.79999999999998, 180.5, 161.0, 190.1, 200.0, 198.2, 173.0, 164.0, 161.0, 194.0, 190.1, 184.7, 187.4, 200.0, 191.0, 200.0, 197.3, 191.9, 133.4, 165.2, 191.9, 181.1, 190.1, 200.0, 196.4, 148.4, 200.0, 184.1, 185.0, 183.2, 182.0, 188.0, 166.7, 154.1, 192.8, 181.4, 200.0, 200.0, 175.1, 179.0, 164.0, 191.0, 188.3, 169.39999999999998, 196.1, 193.4, 190.1, 189.2, 194.6, 192.8, 188.3, 185.0, 176.6, 169.1, 200.0, 185.6, 188.0, 179.9, 176.0, 197.0, 179.0, 191.9, 200.0, 188.3, 191.9, 182.3, 179.0, 196.4, 192.79999999999998, 199.1, 182.9, 200.0, 198.2, 180.2, 176.9, 200.0, 190.1, 182.0, 193.7, 200.0, 156.2, 189.2, 191.0, 188.3, 188.0, 152.0, 176.6, 170.0, 194.6, 194.6, 200.0, 154.39999999999998, 194.6, 162.8, 198.2, 200.0, 167.0, 160.4, 186.5, 192.8, 195.5, 195.2, 165.2, 197.0, 191.0, 188.29999999999998, 186.2, 192.8, 197.0, 200.0, 195.5, 185.6, 174.8, 173.0, 194.0, 200.0, 174.8, 193.7, 197.3, 199.1, 171.2, 200.0, 192.8, 182.9, 200.0, 185.6, 191.9, 191.0, 197.3, 191.0, 200.0, 191.9, 170.0, 179.6, 196.1, 185.0, 176.6, 149.0, 200.0, 195.5, 197.29999999999998, 197.3, 194.0, 149.0, 195.5, 191.0, 200.0, 197.3, 196.1, 172.1, 194.6, 197.3, 153.5, 167.0, 179.3, 160.10000000000002, 168.5, 194.6, 200.0, 193.7, 174.2, 177.2, 197.0, 191.0, 197.3, 199.1, 200.0, 179.3, 168.8, 181.1, 169.4, 182.0, 190.4, 184.1, 177.2, 181.7, 199.1, 157.4, 197.29999999999998, 194.6, 200.0, 192.79999999999998, 194.0], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 8.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 16.0, 0.0, 0.0, 0.0, 2.0, 0.0, 2.0, 9.0, 0.0, 0.0, 0.0, 9.0, 12.0, 13.0, 1.0, 2.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 21.0, 0.0, 11.0, 6.0, 0.0, 0.0, 0.0, 16.0, 0.0, 5.0, 5.0, 0.0, 6.0, 0.0, 13.0, 1.0, 11.0, 0.0, 5.0, 0.0, 5.0, 4.0, 13.0, 0.0, 0.0, 6.0, 0.0, 0.0, 1.0, 0.0, 3.0, 0.0, 0.0, 0.0, 8.0, 0.0, 10.0, 4.0, 0.0, 9.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 6.0, 4.0, 5.0, 6.0, 0.0, 0.0, 4.0, 0.0, 10.0, 6.0, 8.0, 8.0, 0.0, 0.0, 0.0, 8.0, 10.0, 0.0, 7.0, 4.0, 12.0, 10.0, 0.0, 0.0, 8.0, 1.0, 0.0, 4.0, 4.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 6.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 7.0, 1.0, 5.0, 11.0, 0.0, 0.0, 17.0, 0.0, 0.0, 0.0, 2.0, 8.0, 9.0, 0.0, 0.0, 1.0, 0.0, 9.0, 0.0, 11.0, 7.0, 6.0, 11.0, 10.0, 9.0, 0.0, 0.0, 1.0, 7.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 6.0, 9.0, 0.0, 6.0, 2.0, 0.0, 7.0, 0.0, 4.0, 13.0, 0.0, 0.0, 0.0, 2.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 9.954731884406778, "mean_inference_ms": 24.508630561609426, "mean_action_processing_ms": 4.810186355443112, "mean_env_wait_ms": 5.9492563493036945, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.013231635093688965, "StateBufferConnector_ms": 0.011771917343139648, "ViewRequirementAgentConnector_ms": 0.28485107421875}, "num_episodes": 18, "episode_return_max": 399.1, "episode_return_min": 344.6, "episode_return_mean": 377.76200000000006, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2976000, "num_agent_steps_trained": 2976000, "num_env_steps_sampled": 744000, "num_env_steps_trained": 744000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 4.095897280576061, "num_env_steps_trained_throughput_per_sec": 4.095897280576061, "timesteps_total": 744000, "num_env_steps_sampled_lifetime": 744000, "num_agent_steps_sampled_lifetime": 2976000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2976000, "timers": {"training_iteration_time_ms": 118430.625, "restore_workers_time_ms": 0.02, "training_step_time_ms": 118430.559, "sample_time_ms": 3756.784, "learn_time_ms": 114644.763, "learn_throughput": 34.89, "synch_weights_time_ms": 25.054}, "counters": {"num_env_steps_sampled": 744000, "num_env_steps_trained": 744000, "num_agent_steps_sampled": 2976000, "num_agent_steps_trained": 2976000}, "done": false, "training_iteration": 186, "trial_id": "75ec3_00000", "date": "2024-08-13_06-12-38", "timestamp": 1723543958, "time_this_iter_s": 976.8022871017456, "time_total_s": 16703.84264779091, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2495dc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 16703.84264779091, "iterations_since_restore": 186, "perf": {"cpu_util_percent": 88.13333333333333, "ram_util_percent": 83.95098039215686}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.062116357826051, "cur_kl_coeff": 0.02167325159515201, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.5041586412819072, "policy_loss": -0.00233761971944539, "vf_loss": 0.5062130046367803, "vf_explained_var": 0.27416832273599334, "kl": 0.013069468811083116, "entropy": 1.205054278096194, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 352485.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5779639142471804, "cur_kl_coeff": 9.82577410152093e-28, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.24161379618382958, "policy_loss": -0.0028916225970658676, "vf_loss": 0.24450541927698488, "vf_explained_var": 0.23384118360817116, "kl": 0.011951432067574286, "entropy": 1.0950351076151328, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 352485.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 748000, "num_env_steps_trained": 748000, "num_agent_steps_sampled": 2992000, "num_agent_steps_trained": 2992000}, "env_runners": {"episode_reward_max": 399.1, "episode_reward_min": 344.6, "episode_reward_mean": 378.88500000000005, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 149.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 17.0}, "policy_reward_mean": {"prey_policy": 186.4925, "predator_policy": 2.95}, "custom_metrics": {}, "hist_stats": {"episode_reward": [380.1, 360.0, 379.3, 371.5, 384.5, 386.8, 381.1, 369.6, 379.1, 377.6, 364.9, 383.0, 391.9, 380.2, 371.3, 389.20000000000005, 382.0, 398.2, 362.1, 390.1, 385.7, 367.2, 380.2, 380.3, 344.6, 380.6, 394.6, 357.0, 371.0, 378.0, 368.90000000000003, 388.3, 369.4, 392.0, 378.5, 390.8, 395.5, 366.4, 378.0, 374.8, 391.0, 379.29999999999995, 392.8, 382.9, 377.5, 391.3, 391.0, 368.9, 381.7, 372.6, 366.0, 392.8, 393.3, 361.5, 391.0, 394.4, 375.7, 368.8, 363.3, 347.6, 394.6, 375.9, 382.2, 388.29999999999995, 399.1, 366.1, 359.5, 380.4, 368.29999999999995, 384.8, 367.69999999999993, 394.6, 388.8, 391.0, 399.1, 357.9, 393.1, 388.3, 354.0, 384.0, 379.3, 391.90000000000003, 394.2, 398.2, 362.0, 366.5, 347.6, 399.1, 384.7, 389.3, 382.1, 369.4, 368.1, 386.8, 377.5, 361.6, 374.0, 386.0, 376.8, 368.0], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [200.0, 175.1, 179.0, 164.0, 191.0, 188.3, 169.39999999999998, 196.1, 193.4, 190.1, 189.2, 194.6, 192.8, 188.3, 185.0, 176.6, 169.1, 200.0, 185.6, 188.0, 179.9, 176.0, 197.0, 179.0, 191.9, 200.0, 188.3, 191.9, 182.3, 179.0, 196.4, 192.79999999999998, 199.1, 182.9, 200.0, 198.2, 180.2, 176.9, 200.0, 190.1, 182.0, 193.7, 200.0, 156.2, 189.2, 191.0, 188.3, 188.0, 152.0, 176.6, 170.0, 194.6, 194.6, 200.0, 154.39999999999998, 194.6, 162.8, 198.2, 200.0, 167.0, 160.4, 186.5, 192.8, 195.5, 195.2, 165.2, 197.0, 191.0, 188.29999999999998, 186.2, 192.8, 197.0, 200.0, 195.5, 185.6, 174.8, 173.0, 194.0, 200.0, 174.8, 193.7, 197.3, 199.1, 171.2, 200.0, 192.8, 182.9, 200.0, 185.6, 191.9, 191.0, 197.3, 191.0, 200.0, 191.9, 170.0, 179.6, 196.1, 185.0, 176.6, 149.0, 200.0, 195.5, 197.29999999999998, 197.3, 194.0, 149.0, 195.5, 191.0, 200.0, 197.3, 196.1, 172.1, 194.6, 197.3, 153.5, 167.0, 179.3, 160.10000000000002, 168.5, 194.6, 200.0, 193.7, 174.2, 177.2, 197.0, 191.0, 197.3, 199.1, 200.0, 179.3, 168.8, 181.1, 169.4, 182.0, 190.4, 184.1, 177.2, 181.7, 199.1, 157.4, 197.29999999999998, 194.6, 200.0, 192.79999999999998, 194.0, 191.0, 200.0, 200.0, 199.1, 163.4, 180.5, 190.1, 200.0, 198.2, 190.1, 182.0, 158.0, 176.0, 200.0, 185.6, 193.7, 192.79999999999998, 199.1, 194.0, 198.2, 198.2, 200.0, 179.0, 173.0, 182.0, 177.5, 175.4, 153.2, 199.1, 200.0, 194.6, 190.1, 185.3, 200.0, 187.1, 191.0, 189.2, 180.2, 166.1, 191.0, 189.2, 194.6, 168.5, 200.0, 173.6, 176.0, 188.0, 182.0, 200.0, 179.0, 176.0, 192.8, 176.0, 182.0], "policy_predator_policy_reward": [0.0, 5.0, 4.0, 13.0, 0.0, 0.0, 6.0, 0.0, 0.0, 1.0, 0.0, 3.0, 0.0, 0.0, 0.0, 8.0, 0.0, 10.0, 4.0, 0.0, 9.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 6.0, 4.0, 5.0, 6.0, 0.0, 0.0, 4.0, 0.0, 10.0, 6.0, 8.0, 8.0, 0.0, 0.0, 0.0, 8.0, 10.0, 0.0, 7.0, 4.0, 12.0, 10.0, 0.0, 0.0, 8.0, 1.0, 0.0, 4.0, 4.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 6.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 7.0, 1.0, 5.0, 11.0, 0.0, 0.0, 17.0, 0.0, 0.0, 0.0, 2.0, 8.0, 9.0, 0.0, 0.0, 1.0, 0.0, 9.0, 0.0, 11.0, 7.0, 6.0, 11.0, 10.0, 9.0, 0.0, 0.0, 1.0, 7.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 6.0, 9.0, 0.0, 6.0, 2.0, 0.0, 7.0, 0.0, 4.0, 13.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 7.0, 0.0, 3.0, 0.0, 0.0, 8.0, 6.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 10.0, 7.0, 0.0, 7.0, 12.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 4.0, 0.0, 0.0, 0.0, 11.0, 0.0, 3.0, 0.0, 0.0, 9.0, 0.0, 12.0, 0.0, 4.0, 7.0, 0.0, 0.0, 8.0, 0.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 10.263670216791168, "mean_inference_ms": 23.988330875020807, "mean_action_processing_ms": 4.78617285731773, "mean_env_wait_ms": 5.80262018570413, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.011462926864624023, "StateBufferConnector_ms": 0.010254859924316406, "ViewRequirementAgentConnector_ms": 0.35351741313934326}, "num_episodes": 27, "episode_return_max": 399.1, "episode_return_min": 344.6, "episode_return_mean": 378.88500000000005, "episodes_this_iter": 27}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2992000, "num_agent_steps_trained": 2992000, "num_env_steps_sampled": 748000, "num_env_steps_trained": 748000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 215.68690722378696, "num_env_steps_trained_throughput_per_sec": 215.68690722378696, "timesteps_total": 748000, "num_env_steps_sampled_lifetime": 748000, "num_agent_steps_sampled_lifetime": 2992000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2992000, "timers": {"training_iteration_time_ms": 116796.691, "restore_workers_time_ms": 0.019, "training_step_time_ms": 116796.618, "sample_time_ms": 3420.066, "learn_time_ms": 113342.675, "learn_throughput": 35.291, "synch_weights_time_ms": 29.272}, "counters": {"num_env_steps_sampled": 748000, "num_env_steps_trained": 748000, "num_agent_steps_sampled": 2992000, "num_agent_steps_trained": 2992000}, "done": false, "training_iteration": 187, "trial_id": "75ec3_00000", "date": "2024-08-13_06-12-57", "timestamp": 1723543977, "time_this_iter_s": 18.731150150299072, "time_total_s": 16722.573797941208, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2567700>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 16722.573797941208, "iterations_since_restore": 187, "perf": {"cpu_util_percent": 78.86296296296297, "ram_util_percent": 83.68148148148148}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4311533679880162, "cur_kl_coeff": 0.02167325159515201, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.17060241585723052, "policy_loss": -0.006860596102430786, "vf_loss": 0.17709145946748475, "vf_explained_var": 0.4141074162311655, "kl": 0.01714333491580532, "entropy": 1.2262452617524162, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 354375.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.35268310987878415, "cur_kl_coeff": 9.82577410152093e-28, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.09401341344737423, "policy_loss": -0.0008323022538904476, "vf_loss": 0.09484571571939683, "vf_explained_var": -0.16410764884696435, "kl": 0.021007482173108136, "entropy": 1.1169678081911076, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 354375.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 752000, "num_env_steps_trained": 752000, "num_agent_steps_sampled": 3008000, "num_agent_steps_trained": 3008000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": 344.6, "episode_reward_mean": 379.94199999999995, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 149.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 17.0}, "policy_reward_mean": {"prey_policy": 187.03099999999998, "predator_policy": 2.94}, "custom_metrics": {}, "hist_stats": {"episode_reward": [362.1, 390.1, 385.7, 367.2, 380.2, 380.3, 344.6, 380.6, 394.6, 357.0, 371.0, 378.0, 368.90000000000003, 388.3, 369.4, 392.0, 378.5, 390.8, 395.5, 366.4, 378.0, 374.8, 391.0, 379.29999999999995, 392.8, 382.9, 377.5, 391.3, 391.0, 368.9, 381.7, 372.6, 366.0, 392.8, 393.3, 361.5, 391.0, 394.4, 375.7, 368.8, 363.3, 347.6, 394.6, 375.9, 382.2, 388.29999999999995, 399.1, 366.1, 359.5, 380.4, 368.29999999999995, 384.8, 367.69999999999993, 394.6, 388.8, 391.0, 399.1, 357.9, 393.1, 388.3, 354.0, 384.0, 379.3, 391.90000000000003, 394.2, 398.2, 362.0, 366.5, 347.6, 399.1, 384.7, 389.3, 382.1, 369.4, 368.1, 386.8, 377.5, 361.6, 374.0, 386.0, 376.8, 368.0, 359.7, 394.0, 380.5, 398.0, 391.9, 400.0, 377.1, 388.4, 383.4, 385.4, 380.1, 385.5, 394.6, 372.4, 385.3, 378.4, 382.2, 399.1], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [180.2, 176.9, 200.0, 190.1, 182.0, 193.7, 200.0, 156.2, 189.2, 191.0, 188.3, 188.0, 152.0, 176.6, 170.0, 194.6, 194.6, 200.0, 154.39999999999998, 194.6, 162.8, 198.2, 200.0, 167.0, 160.4, 186.5, 192.8, 195.5, 195.2, 165.2, 197.0, 191.0, 188.29999999999998, 186.2, 192.8, 197.0, 200.0, 195.5, 185.6, 174.8, 173.0, 194.0, 200.0, 174.8, 193.7, 197.3, 199.1, 171.2, 200.0, 192.8, 182.9, 200.0, 185.6, 191.9, 191.0, 197.3, 191.0, 200.0, 191.9, 170.0, 179.6, 196.1, 185.0, 176.6, 149.0, 200.0, 195.5, 197.29999999999998, 197.3, 194.0, 149.0, 195.5, 191.0, 200.0, 197.3, 196.1, 172.1, 194.6, 197.3, 153.5, 167.0, 179.3, 160.10000000000002, 168.5, 194.6, 200.0, 193.7, 174.2, 177.2, 197.0, 191.0, 197.3, 199.1, 200.0, 179.3, 168.8, 181.1, 169.4, 182.0, 190.4, 184.1, 177.2, 181.7, 199.1, 157.4, 197.29999999999998, 194.6, 200.0, 192.79999999999998, 194.0, 191.0, 200.0, 200.0, 199.1, 163.4, 180.5, 190.1, 200.0, 198.2, 190.1, 182.0, 158.0, 176.0, 200.0, 185.6, 193.7, 192.79999999999998, 199.1, 194.0, 198.2, 198.2, 200.0, 179.0, 173.0, 182.0, 177.5, 175.4, 153.2, 199.1, 200.0, 194.6, 190.1, 185.3, 200.0, 187.1, 191.0, 189.2, 180.2, 166.1, 191.0, 189.2, 194.6, 168.5, 200.0, 173.6, 176.0, 188.0, 182.0, 200.0, 179.0, 176.0, 192.8, 176.0, 182.0, 167.9, 183.8, 200.0, 191.0, 189.2, 188.3, 200.0, 197.0, 197.3, 194.6, 200.0, 200.0, 178.7, 196.4, 188.0, 196.39999999999998, 188.0, 175.4, 193.4, 191.0, 193.7, 181.4, 200.0, 180.5, 195.5, 199.1, 197.3, 163.1, 197.3, 182.0, 182.9, 195.5, 176.0, 198.2, 199.1, 200.0], "policy_predator_policy_reward": [0.0, 5.0, 0.0, 0.0, 6.0, 4.0, 5.0, 6.0, 0.0, 0.0, 4.0, 0.0, 10.0, 6.0, 8.0, 8.0, 0.0, 0.0, 0.0, 8.0, 10.0, 0.0, 7.0, 4.0, 12.0, 10.0, 0.0, 0.0, 8.0, 1.0, 0.0, 4.0, 4.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 6.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 7.0, 1.0, 5.0, 11.0, 0.0, 0.0, 17.0, 0.0, 0.0, 0.0, 2.0, 8.0, 9.0, 0.0, 0.0, 1.0, 0.0, 9.0, 0.0, 11.0, 7.0, 6.0, 11.0, 10.0, 9.0, 0.0, 0.0, 1.0, 7.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 6.0, 9.0, 0.0, 6.0, 2.0, 0.0, 7.0, 0.0, 4.0, 13.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 7.0, 0.0, 3.0, 0.0, 0.0, 8.0, 6.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 10.0, 7.0, 0.0, 7.0, 12.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 4.0, 0.0, 0.0, 0.0, 11.0, 0.0, 3.0, 0.0, 0.0, 9.0, 0.0, 12.0, 0.0, 4.0, 7.0, 0.0, 0.0, 8.0, 0.0, 10.0, 8.0, 0.0, 0.0, 3.0, 0.0, 3.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 4.0, 10.0, 10.0, 1.0, 0.0, 5.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 12.0, 6.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 9.855856745442226, "mean_inference_ms": 24.26879527326697, "mean_action_processing_ms": 4.760426696106522, "mean_env_wait_ms": 5.885664582288615, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.009891510009765625, "StateBufferConnector_ms": 0.019977688789367676, "ViewRequirementAgentConnector_ms": 0.3662998676300049}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": 344.6, "episode_return_mean": 379.94199999999995, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 3008000, "num_agent_steps_trained": 3008000, "num_env_steps_sampled": 752000, "num_env_steps_trained": 752000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 257.4607645557836, "num_env_steps_trained_throughput_per_sec": 257.4607645557836, "timesteps_total": 752000, "num_env_steps_sampled_lifetime": 752000, "num_agent_steps_sampled_lifetime": 3008000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 3008000, "timers": {"training_iteration_time_ms": 116214.355, "restore_workers_time_ms": 0.021, "training_step_time_ms": 116214.277, "sample_time_ms": 3360.132, "learn_time_ms": 112819.72, "learn_throughput": 35.455, "synch_weights_time_ms": 29.84}, "counters": {"num_env_steps_sampled": 752000, "num_env_steps_trained": 752000, "num_agent_steps_sampled": 3008000, "num_agent_steps_trained": 3008000}, "done": false, "training_iteration": 188, "trial_id": "75ec3_00000", "date": "2024-08-13_06-13-12", "timestamp": 1723543992, "time_this_iter_s": 15.58415412902832, "time_total_s": 16738.157952070236, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b22b3ee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 16738.157952070236, "iterations_since_restore": 188, "perf": {"cpu_util_percent": 63.24090909090909, "ram_util_percent": 80.41818181818182}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6739615729679822, "cur_kl_coeff": 0.02167325159515201, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.2630892805043519, "policy_loss": -0.00643328411884054, "vf_loss": 0.26929474658598856, "vf_explained_var": 0.3679971527170252, "kl": 0.010511484629754887, "entropy": 1.2289929354632343, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 356265.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5130882652683391, "cur_kl_coeff": 1.4738661152281401e-27, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.13932302889842835, "policy_loss": -0.0026822780088950242, "vf_loss": 0.1420053064255164, "vf_explained_var": -0.04297061732837132, "kl": 0.010330236830440459, "entropy": 1.1532075322494304, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 356265.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 756000, "num_env_steps_trained": 756000, "num_agent_steps_sampled": 3024000, "num_agent_steps_trained": 3024000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": 347.6, "episode_reward_mean": 381.30899999999986, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 140.3, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 17.0}, "policy_reward_mean": {"prey_policy": 188.09449999999998, "predator_policy": 2.56}, "custom_metrics": {}, "hist_stats": {"episode_reward": [395.5, 366.4, 378.0, 374.8, 391.0, 379.29999999999995, 392.8, 382.9, 377.5, 391.3, 391.0, 368.9, 381.7, 372.6, 366.0, 392.8, 393.3, 361.5, 391.0, 394.4, 375.7, 368.8, 363.3, 347.6, 394.6, 375.9, 382.2, 388.29999999999995, 399.1, 366.1, 359.5, 380.4, 368.29999999999995, 384.8, 367.69999999999993, 394.6, 388.8, 391.0, 399.1, 357.9, 393.1, 388.3, 354.0, 384.0, 379.3, 391.90000000000003, 394.2, 398.2, 362.0, 366.5, 347.6, 399.1, 384.7, 389.3, 382.1, 369.4, 368.1, 386.8, 377.5, 361.6, 374.0, 386.0, 376.8, 368.0, 359.7, 394.0, 380.5, 398.0, 391.9, 400.0, 377.1, 388.4, 383.4, 385.4, 380.1, 385.5, 394.6, 372.4, 385.3, 378.4, 382.2, 399.1, 373.9, 375.5, 348.5, 385.6, 398.2, 400.0, 393.7, 366.5, 393.7, 397.3, 400.0, 384.2, 368.9, 395.5, 385.6, 367.20000000000005, 388.0, 393.7], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [200.0, 195.5, 185.6, 174.8, 173.0, 194.0, 200.0, 174.8, 193.7, 197.3, 199.1, 171.2, 200.0, 192.8, 182.9, 200.0, 185.6, 191.9, 191.0, 197.3, 191.0, 200.0, 191.9, 170.0, 179.6, 196.1, 185.0, 176.6, 149.0, 200.0, 195.5, 197.29999999999998, 197.3, 194.0, 149.0, 195.5, 191.0, 200.0, 197.3, 196.1, 172.1, 194.6, 197.3, 153.5, 167.0, 179.3, 160.10000000000002, 168.5, 194.6, 200.0, 193.7, 174.2, 177.2, 197.0, 191.0, 197.3, 199.1, 200.0, 179.3, 168.8, 181.1, 169.4, 182.0, 190.4, 184.1, 177.2, 181.7, 199.1, 157.4, 197.29999999999998, 194.6, 200.0, 192.79999999999998, 194.0, 191.0, 200.0, 200.0, 199.1, 163.4, 180.5, 190.1, 200.0, 198.2, 190.1, 182.0, 158.0, 176.0, 200.0, 185.6, 193.7, 192.79999999999998, 199.1, 194.0, 198.2, 198.2, 200.0, 179.0, 173.0, 182.0, 177.5, 175.4, 153.2, 199.1, 200.0, 194.6, 190.1, 185.3, 200.0, 187.1, 191.0, 189.2, 180.2, 166.1, 191.0, 189.2, 194.6, 168.5, 200.0, 173.6, 176.0, 188.0, 182.0, 200.0, 179.0, 176.0, 192.8, 176.0, 182.0, 167.9, 183.8, 200.0, 191.0, 189.2, 188.3, 200.0, 197.0, 197.3, 194.6, 200.0, 200.0, 178.7, 196.4, 188.0, 196.39999999999998, 188.0, 175.4, 193.4, 191.0, 193.7, 181.4, 200.0, 180.5, 195.5, 199.1, 197.3, 163.1, 197.3, 182.0, 182.9, 195.5, 176.0, 198.2, 199.1, 200.0, 191.9, 182.0, 189.2, 176.3, 140.3, 189.2, 192.79999999999998, 192.8, 200.0, 198.2, 200.0, 200.0, 195.5, 198.2, 200.0, 165.5, 193.7, 200.0, 200.0, 197.3, 200.0, 200.0, 177.2, 200.0, 175.7, 183.2, 195.5, 200.0, 200.0, 185.6, 172.1, 193.1, 182.0, 200.0, 194.6, 199.1], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 6.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 7.0, 1.0, 5.0, 11.0, 0.0, 0.0, 17.0, 0.0, 0.0, 0.0, 2.0, 8.0, 9.0, 0.0, 0.0, 1.0, 0.0, 9.0, 0.0, 11.0, 7.0, 6.0, 11.0, 10.0, 9.0, 0.0, 0.0, 1.0, 7.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 6.0, 9.0, 0.0, 6.0, 2.0, 0.0, 7.0, 0.0, 4.0, 13.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 7.0, 0.0, 3.0, 0.0, 0.0, 8.0, 6.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 10.0, 7.0, 0.0, 7.0, 12.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 4.0, 0.0, 0.0, 0.0, 11.0, 0.0, 3.0, 0.0, 0.0, 9.0, 0.0, 12.0, 0.0, 4.0, 7.0, 0.0, 0.0, 8.0, 0.0, 10.0, 8.0, 0.0, 0.0, 3.0, 0.0, 3.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 4.0, 10.0, 10.0, 1.0, 0.0, 5.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 12.0, 6.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 3.0, 10.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 6.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 9.814698931485985, "mean_inference_ms": 24.170831344770992, "mean_action_processing_ms": 4.740038383796715, "mean_env_wait_ms": 5.859387294384858, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.008504152297973633, "StateBufferConnector_ms": 0.019406437873840332, "ViewRequirementAgentConnector_ms": 0.32994747161865234}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": 347.6, "episode_return_mean": 381.30899999999986, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 3024000, "num_agent_steps_trained": 3024000, "num_env_steps_sampled": 756000, "num_env_steps_trained": 756000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 304.304604098223, "num_env_steps_trained_throughput_per_sec": 304.304604098223, "timesteps_total": 756000, "num_env_steps_sampled_lifetime": 756000, "num_agent_steps_sampled_lifetime": 3024000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 3024000, "timers": {"training_iteration_time_ms": 115348.423, "restore_workers_time_ms": 0.035, "training_step_time_ms": 115348.329, "sample_time_ms": 3202.3, "learn_time_ms": 112111.851, "learn_throughput": 35.679, "synch_weights_time_ms": 29.858}, "counters": {"num_env_steps_sampled": 756000, "num_env_steps_trained": 756000, "num_agent_steps_sampled": 3024000, "num_agent_steps_trained": 3024000}, "done": false, "training_iteration": 189, "trial_id": "75ec3_00000", "date": "2024-08-13_06-13-26", "timestamp": 1723544006, "time_this_iter_s": 13.190416097640991, "time_total_s": 16751.348368167877, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2567940>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 16751.348368167877, "iterations_since_restore": 189, "perf": {"cpu_util_percent": 52.88333333333333, "ram_util_percent": 82.68333333333334}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8876480105929274, "cur_kl_coeff": 0.02167325159515201, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.33085976514653315, "policy_loss": -0.0017250995237932162, "vf_loss": 0.33234402885433856, "vf_explained_var": 0.30196971294110414, "kl": 0.011112107360658822, "entropy": 1.2232611362896268, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 358155.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.45427102402010294, "cur_kl_coeff": 1.4738661152281401e-27, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.20162751581618396, "policy_loss": -0.0002521152537877834, "vf_loss": 0.20187963087560742, "vf_explained_var": 0.12409735523834431, "kl": 0.007554364273703638, "entropy": 1.1793815028099788, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 358155.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 760000, "num_env_steps_trained": 760000, "num_agent_steps_sampled": 3040000, "num_agent_steps_trained": 3040000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": 336.4, "episode_reward_mean": 380.25199999999995, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 140.3, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 21.0}, "policy_reward_mean": {"prey_policy": 187.31599999999997, "predator_policy": 2.81}, "custom_metrics": {}, "hist_stats": {"episode_reward": [391.0, 394.4, 375.7, 368.8, 363.3, 347.6, 394.6, 375.9, 382.2, 388.29999999999995, 399.1, 366.1, 359.5, 380.4, 368.29999999999995, 384.8, 367.69999999999993, 394.6, 388.8, 391.0, 399.1, 357.9, 393.1, 388.3, 354.0, 384.0, 379.3, 391.90000000000003, 394.2, 398.2, 362.0, 366.5, 347.6, 399.1, 384.7, 389.3, 382.1, 369.4, 368.1, 386.8, 377.5, 361.6, 374.0, 386.0, 376.8, 368.0, 359.7, 394.0, 380.5, 398.0, 391.9, 400.0, 377.1, 388.4, 383.4, 385.4, 380.1, 385.5, 394.6, 372.4, 385.3, 378.4, 382.2, 399.1, 373.9, 375.5, 348.5, 385.6, 398.2, 400.0, 393.7, 366.5, 393.7, 397.3, 400.0, 384.2, 368.9, 395.5, 385.6, 367.20000000000005, 388.0, 393.7, 388.0, 392.40000000000003, 381.2, 361.9, 367.1, 379.1, 398.2, 381.1, 364.1, 387.4, 388.6, 349.20000000000005, 383.5, 376.6, 336.4, 364.5, 362.1, 390.2], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [191.0, 200.0, 197.3, 196.1, 172.1, 194.6, 197.3, 153.5, 167.0, 179.3, 160.10000000000002, 168.5, 194.6, 200.0, 193.7, 174.2, 177.2, 197.0, 191.0, 197.3, 199.1, 200.0, 179.3, 168.8, 181.1, 169.4, 182.0, 190.4, 184.1, 177.2, 181.7, 199.1, 157.4, 197.29999999999998, 194.6, 200.0, 192.79999999999998, 194.0, 191.0, 200.0, 200.0, 199.1, 163.4, 180.5, 190.1, 200.0, 198.2, 190.1, 182.0, 158.0, 176.0, 200.0, 185.6, 193.7, 192.79999999999998, 199.1, 194.0, 198.2, 198.2, 200.0, 179.0, 173.0, 182.0, 177.5, 175.4, 153.2, 199.1, 200.0, 194.6, 190.1, 185.3, 200.0, 187.1, 191.0, 189.2, 180.2, 166.1, 191.0, 189.2, 194.6, 168.5, 200.0, 173.6, 176.0, 188.0, 182.0, 200.0, 179.0, 176.0, 192.8, 176.0, 182.0, 167.9, 183.8, 200.0, 191.0, 189.2, 188.3, 200.0, 197.0, 197.3, 194.6, 200.0, 200.0, 178.7, 196.4, 188.0, 196.39999999999998, 188.0, 175.4, 193.4, 191.0, 193.7, 181.4, 200.0, 180.5, 195.5, 199.1, 197.3, 163.1, 197.3, 182.0, 182.9, 195.5, 176.0, 198.2, 199.1, 200.0, 191.9, 182.0, 189.2, 176.3, 140.3, 189.2, 192.79999999999998, 192.8, 200.0, 198.2, 200.0, 200.0, 195.5, 198.2, 200.0, 165.5, 193.7, 200.0, 200.0, 197.3, 200.0, 200.0, 177.2, 200.0, 175.7, 183.2, 195.5, 200.0, 200.0, 185.6, 172.1, 193.1, 182.0, 200.0, 194.6, 199.1, 182.0, 200.0, 197.3, 193.1, 197.29999999999998, 179.9, 191.89999999999998, 155.0, 184.7, 175.4, 191.0, 178.1, 198.2, 200.0, 194.6, 186.5, 154.7, 196.4, 193.7, 193.7, 191.0, 194.6, 171.2, 164.0, 199.1, 178.4, 182.9, 193.7, 157.4, 152.0, 156.2, 194.3, 153.5, 194.6, 188.0, 198.2], "policy_predator_policy_reward": [0.0, 0.0, 1.0, 0.0, 9.0, 0.0, 11.0, 7.0, 6.0, 11.0, 10.0, 9.0, 0.0, 0.0, 1.0, 7.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 6.0, 9.0, 0.0, 6.0, 2.0, 0.0, 7.0, 0.0, 4.0, 13.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 7.0, 0.0, 3.0, 0.0, 0.0, 8.0, 6.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 10.0, 7.0, 0.0, 7.0, 12.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 4.0, 0.0, 0.0, 0.0, 11.0, 0.0, 3.0, 0.0, 0.0, 9.0, 0.0, 12.0, 0.0, 4.0, 7.0, 0.0, 0.0, 8.0, 0.0, 10.0, 8.0, 0.0, 0.0, 3.0, 0.0, 3.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 4.0, 10.0, 10.0, 1.0, 0.0, 5.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 12.0, 6.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 3.0, 10.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 6.0, 0.0, 0.0, 1.0, 5.0, 0.0, 2.0, 4.0, 0.0, 0.0, 15.0, 7.0, 0.0, 3.0, 7.0, 0.0, 0.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 3.0, 0.0, 14.0, 0.0, 0.0, 6.0, 0.0, 0.0, 6.0, 21.0, 5.0, 9.0, 14.0, 0.0, 4.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 9.773203101916133, "mean_inference_ms": 24.07171047355744, "mean_action_processing_ms": 4.719523286123818, "mean_env_wait_ms": 5.83308448667914, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005116581916809082, "StateBufferConnector_ms": 0.0195925235748291, "ViewRequirementAgentConnector_ms": 0.2673783302307129}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": 336.4, "episode_return_mean": 380.25199999999995, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 3040000, "num_agent_steps_trained": 3040000, "num_env_steps_sampled": 760000, "num_env_steps_trained": 760000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 304.90742334154135, "num_env_steps_trained_throughput_per_sec": 304.90742334154135, "timesteps_total": 760000, "num_env_steps_sampled_lifetime": 760000, "num_agent_steps_sampled_lifetime": 3040000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 3040000, "timers": {"training_iteration_time_ms": 114550.427, "restore_workers_time_ms": 0.034, "training_step_time_ms": 114550.333, "sample_time_ms": 3055.019, "learn_time_ms": 111460.828, "learn_throughput": 35.887, "synch_weights_time_ms": 29.898}, "counters": {"num_env_steps_sampled": 760000, "num_env_steps_trained": 760000, "num_agent_steps_sampled": 3040000, "num_agent_steps_trained": 3040000}, "done": false, "training_iteration": 190, "trial_id": "75ec3_00000", "date": "2024-08-13_06-13-39", "timestamp": 1723544019, "time_this_iter_s": 13.159732103347778, "time_total_s": 16764.508100271225, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2515040>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 16764.508100271225, "iterations_since_restore": 190, "perf": {"cpu_util_percent": 57.51052631578948, "ram_util_percent": 83.16315789473683}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.735039339494453, "cur_kl_coeff": 0.02167325159515201, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.8956673281296851, "policy_loss": -0.0076469967245227765, "vf_loss": 0.9029454923653729, "vf_explained_var": 0.332166271928757, "kl": 0.017017928139246737, "entropy": 1.1995671921306186, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 360045.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4140845757687376, "cur_kl_coeff": 1.4738661152281401e-27, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.1615195267503618, "policy_loss": -0.0008194530204125735, "vf_loss": 0.1623389802720686, "vf_explained_var": 0.25105297694761286, "kl": 0.004964297542606644, "entropy": 1.1621998100053696, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 360045.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 764000, "num_env_steps_trained": 764000, "num_agent_steps_sampled": 3056000, "num_agent_steps_trained": 3056000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": 336.4, "episode_reward_mean": 379.48199999999997, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 140.3, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 21.0}, "policy_reward_mean": {"prey_policy": 187.00100000000003, "predator_policy": 2.74}, "custom_metrics": {}, "hist_stats": {"episode_reward": [388.3, 354.0, 384.0, 379.3, 391.90000000000003, 394.2, 398.2, 362.0, 366.5, 347.6, 399.1, 384.7, 389.3, 382.1, 369.4, 368.1, 386.8, 377.5, 361.6, 374.0, 386.0, 376.8, 368.0, 359.7, 394.0, 380.5, 398.0, 391.9, 400.0, 377.1, 388.4, 383.4, 385.4, 380.1, 385.5, 394.6, 372.4, 385.3, 378.4, 382.2, 399.1, 373.9, 375.5, 348.5, 385.6, 398.2, 400.0, 393.7, 366.5, 393.7, 397.3, 400.0, 384.2, 368.9, 395.5, 385.6, 367.20000000000005, 388.0, 393.7, 388.0, 392.40000000000003, 381.2, 361.9, 367.1, 379.1, 398.2, 381.1, 364.1, 387.4, 388.6, 349.20000000000005, 383.5, 376.6, 336.4, 364.5, 362.1, 390.2, 370.3, 379.3, 384.7, 399.1, 385.9, 373.0, 364.8, 369.4, 381.9, 400.0, 355.9, 381.40000000000003, 369.9, 363.5, 381.1, 385.2, 381.9000000000001, 393.0, 359.8, 376.6000000000001, 364.1, 337.1000000000002, 397.3], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [198.2, 190.1, 182.0, 158.0, 176.0, 200.0, 185.6, 193.7, 192.79999999999998, 199.1, 194.0, 198.2, 198.2, 200.0, 179.0, 173.0, 182.0, 177.5, 175.4, 153.2, 199.1, 200.0, 194.6, 190.1, 185.3, 200.0, 187.1, 191.0, 189.2, 180.2, 166.1, 191.0, 189.2, 194.6, 168.5, 200.0, 173.6, 176.0, 188.0, 182.0, 200.0, 179.0, 176.0, 192.8, 176.0, 182.0, 167.9, 183.8, 200.0, 191.0, 189.2, 188.3, 200.0, 197.0, 197.3, 194.6, 200.0, 200.0, 178.7, 196.4, 188.0, 196.39999999999998, 188.0, 175.4, 193.4, 191.0, 193.7, 181.4, 200.0, 180.5, 195.5, 199.1, 197.3, 163.1, 197.3, 182.0, 182.9, 195.5, 176.0, 198.2, 199.1, 200.0, 191.9, 182.0, 189.2, 176.3, 140.3, 189.2, 192.79999999999998, 192.8, 200.0, 198.2, 200.0, 200.0, 195.5, 198.2, 200.0, 165.5, 193.7, 200.0, 200.0, 197.3, 200.0, 200.0, 177.2, 200.0, 175.7, 183.2, 195.5, 200.0, 200.0, 185.6, 172.1, 193.1, 182.0, 200.0, 194.6, 199.1, 182.0, 200.0, 197.3, 193.1, 197.29999999999998, 179.9, 191.89999999999998, 155.0, 184.7, 175.4, 191.0, 178.1, 198.2, 200.0, 194.6, 186.5, 154.7, 196.4, 193.7, 193.7, 191.0, 194.6, 171.2, 164.0, 199.1, 178.4, 182.9, 193.7, 157.4, 152.0, 156.2, 194.3, 153.5, 194.6, 188.0, 198.2, 199.1, 156.2, 190.1, 189.2, 191.9, 192.8, 199.1, 200.0, 200.0, 182.9, 175.7, 188.3, 171.5, 179.3, 189.2, 180.20000000000002, 185.0, 191.9, 200.0, 200.0, 165.79999999999995, 181.1, 178.4, 200.0, 193.7, 165.2, 170.29999999999998, 180.2, 172.1, 200.0, 197.0, 186.2, 191.89999999999998, 185.0, 197.0, 194.0, 183.8, 173.0, 179.29999999999998, 188.3, 166.1, 182.0, 150.49999999999994, 170.6, 200.0, 197.3], "policy_predator_policy_reward": [0.0, 0.0, 8.0, 6.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 10.0, 7.0, 0.0, 7.0, 12.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 4.0, 0.0, 0.0, 0.0, 11.0, 0.0, 3.0, 0.0, 0.0, 9.0, 0.0, 12.0, 0.0, 4.0, 7.0, 0.0, 0.0, 8.0, 0.0, 10.0, 8.0, 0.0, 0.0, 3.0, 0.0, 3.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 4.0, 10.0, 10.0, 1.0, 0.0, 5.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 12.0, 6.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 3.0, 10.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 6.0, 0.0, 0.0, 1.0, 5.0, 0.0, 2.0, 4.0, 0.0, 0.0, 15.0, 7.0, 0.0, 3.0, 7.0, 0.0, 0.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 3.0, 0.0, 14.0, 0.0, 0.0, 6.0, 0.0, 0.0, 6.0, 21.0, 5.0, 9.0, 14.0, 0.0, 4.0, 0.0, 5.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 9.0, 0.0, 6.0, 8.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 9.0, 3.0, 0.0, 0.0, 11.0, 0.0, 13.0, 0.0, 9.0, 1.0, 1.0, 5.0, 0.0, 2.0, 0.0, 2.0, 1.0, 6.0, 3.0, 16.0, 0.0, 16.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 9.720155719939521, "mean_inference_ms": 24.285351524577052, "mean_action_processing_ms": 4.816941671788624, "mean_env_wait_ms": 5.3447947059843814, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004531383514404297, "StateBufferConnector_ms": 0.018390297889709473, "ViewRequirementAgentConnector_ms": 0.2371675968170166}, "num_episodes": 23, "episode_return_max": 400.0, "episode_return_min": 336.4, "episode_return_mean": 379.48199999999997, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 3056000, "num_agent_steps_trained": 3056000, "num_env_steps_sampled": 764000, "num_env_steps_trained": 764000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 320.26482469453777, "num_env_steps_trained_throughput_per_sec": 320.26482469453777, "timesteps_total": 764000, "num_env_steps_sampled_lifetime": 764000, "num_agent_steps_sampled_lifetime": 3056000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 3056000, "timers": {"training_iteration_time_ms": 113609.143, "restore_workers_time_ms": 0.058, "training_step_time_ms": 113609.026, "sample_time_ms": 2860.76, "learn_time_ms": 110713.908, "learn_throughput": 36.129, "synch_weights_time_ms": 29.699}, "counters": {"num_env_steps_sampled": 764000, "num_env_steps_trained": 764000, "num_agent_steps_sampled": 3056000, "num_agent_steps_trained": 3056000}, "done": false, "training_iteration": 191, "trial_id": "75ec3_00000", "date": "2024-08-13_06-13-51", "timestamp": 1723544031, "time_this_iter_s": 12.592673063278198, "time_total_s": 16777.100773334503, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2567f70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 16777.100773334503, "iterations_since_restore": 191, "perf": {"cpu_util_percent": 57.02777777777778, "ram_util_percent": 82.80000000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9725342368362127, "cur_kl_coeff": 0.02167325159515201, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.312445674715539, "policy_loss": -0.0026514535491408966, "vf_loss": 0.31463172984550947, "vf_explained_var": 0.4246725115826521, "kl": 0.02147337482891549, "entropy": 1.1725714778143261, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 361935.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4384410596299897, "cur_kl_coeff": 7.369330576140701e-28, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.1745092474584463, "policy_loss": -0.0017604401729330815, "vf_loss": 0.17626968781622718, "vf_explained_var": 0.09096880715990824, "kl": 0.018677355771579012, "entropy": 1.1020733238528015, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 361935.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 768000, "num_env_steps_trained": 768000, "num_agent_steps_sampled": 3072000, "num_agent_steps_trained": 3072000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": 336.4, "episode_reward_mean": 379.5909999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 140.3, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 21.0}, "policy_reward_mean": {"prey_policy": 187.0655, "predator_policy": 2.73}, "custom_metrics": {}, "hist_stats": {"episode_reward": [368.0, 359.7, 394.0, 380.5, 398.0, 391.9, 400.0, 377.1, 388.4, 383.4, 385.4, 380.1, 385.5, 394.6, 372.4, 385.3, 378.4, 382.2, 399.1, 373.9, 375.5, 348.5, 385.6, 398.2, 400.0, 393.7, 366.5, 393.7, 397.3, 400.0, 384.2, 368.9, 395.5, 385.6, 367.20000000000005, 388.0, 393.7, 388.0, 392.40000000000003, 381.2, 361.9, 367.1, 379.1, 398.2, 381.1, 364.1, 387.4, 388.6, 349.20000000000005, 383.5, 376.6, 336.4, 364.5, 362.1, 390.2, 370.3, 379.3, 384.7, 399.1, 385.9, 373.0, 364.8, 369.4, 381.9, 400.0, 355.9, 381.40000000000003, 369.9, 363.5, 381.1, 385.2, 381.9000000000001, 393.0, 359.8, 376.6000000000001, 364.1, 337.1000000000002, 397.3, 346.7, 393.7, 386.0, 375.4, 381.1, 378.3, 394.6000000000001, 372.3, 373.6, 374.29999999999995, 365.0, 370.5, 397.3, 372.0, 389.7, 374.2, 360.5, 380.2, 389.2, 394.6, 400.0, 363.1], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [176.0, 182.0, 167.9, 183.8, 200.0, 191.0, 189.2, 188.3, 200.0, 197.0, 197.3, 194.6, 200.0, 200.0, 178.7, 196.4, 188.0, 196.39999999999998, 188.0, 175.4, 193.4, 191.0, 193.7, 181.4, 200.0, 180.5, 195.5, 199.1, 197.3, 163.1, 197.3, 182.0, 182.9, 195.5, 176.0, 198.2, 199.1, 200.0, 191.9, 182.0, 189.2, 176.3, 140.3, 189.2, 192.79999999999998, 192.8, 200.0, 198.2, 200.0, 200.0, 195.5, 198.2, 200.0, 165.5, 193.7, 200.0, 200.0, 197.3, 200.0, 200.0, 177.2, 200.0, 175.7, 183.2, 195.5, 200.0, 200.0, 185.6, 172.1, 193.1, 182.0, 200.0, 194.6, 199.1, 182.0, 200.0, 197.3, 193.1, 197.29999999999998, 179.9, 191.89999999999998, 155.0, 184.7, 175.4, 191.0, 178.1, 198.2, 200.0, 194.6, 186.5, 154.7, 196.4, 193.7, 193.7, 191.0, 194.6, 171.2, 164.0, 199.1, 178.4, 182.9, 193.7, 157.4, 152.0, 156.2, 194.3, 153.5, 194.6, 188.0, 198.2, 199.1, 156.2, 190.1, 189.2, 191.9, 192.8, 199.1, 200.0, 200.0, 182.9, 175.7, 188.3, 171.5, 179.3, 189.2, 180.20000000000002, 185.0, 191.9, 200.0, 200.0, 165.79999999999995, 181.1, 178.4, 200.0, 193.7, 165.2, 170.29999999999998, 180.2, 172.1, 200.0, 197.0, 186.2, 191.89999999999998, 185.0, 197.0, 194.0, 183.8, 173.0, 179.29999999999998, 188.3, 166.1, 182.0, 150.49999999999994, 170.6, 200.0, 197.3, 150.20000000000005, 186.5, 198.2, 195.5, 179.0, 200.0, 193.7, 175.7, 194.6, 186.5, 196.1, 174.2, 200.0, 194.6, 192.8, 171.5, 191.9, 175.7, 173.0, 188.29999999999998, 191.0, 161.0, 180.5, 182.0, 200.0, 197.3, 178.7, 188.3, 194.0, 193.7, 180.2, 191.0, 175.4, 175.1, 173.0, 198.2, 200.0, 189.2, 194.6, 200.0, 200.0, 200.0, 179.0, 172.1], "policy_predator_policy_reward": [0.0, 10.0, 8.0, 0.0, 0.0, 3.0, 0.0, 3.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 4.0, 10.0, 10.0, 1.0, 0.0, 5.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 12.0, 6.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 3.0, 10.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 6.0, 0.0, 0.0, 1.0, 5.0, 0.0, 2.0, 4.0, 0.0, 0.0, 15.0, 7.0, 0.0, 3.0, 7.0, 0.0, 0.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 3.0, 0.0, 14.0, 0.0, 0.0, 6.0, 0.0, 0.0, 6.0, 21.0, 5.0, 9.0, 14.0, 0.0, 4.0, 0.0, 5.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 9.0, 0.0, 6.0, 8.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 9.0, 3.0, 0.0, 0.0, 11.0, 0.0, 13.0, 0.0, 9.0, 1.0, 1.0, 5.0, 0.0, 2.0, 0.0, 2.0, 1.0, 6.0, 3.0, 16.0, 0.0, 16.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 6.0, 1.0, 6.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 8.0, 6.0, 0.0, 7.0, 6.0, 13.0, 0.0, 8.0, 0.0, 0.0, 0.0, 4.0, 1.0, 2.0, 0.0, 0.0, 3.0, 10.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 9.668921157019353, "mean_inference_ms": 23.82528985446006, "mean_action_processing_ms": 4.669014244568189, "mean_env_wait_ms": 5.768191461965716, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005972146987915039, "StateBufferConnector_ms": 0.01799154281616211, "ViewRequirementAgentConnector_ms": 0.17132902145385742}, "num_episodes": 22, "episode_return_max": 400.0, "episode_return_min": 336.4, "episode_return_mean": 379.5909999999999, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 3072000, "num_agent_steps_trained": 3072000, "num_env_steps_sampled": 768000, "num_env_steps_trained": 768000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 310.30070020115187, "num_env_steps_trained_throughput_per_sec": 310.30070020115187, "timesteps_total": 768000, "num_env_steps_sampled_lifetime": 768000, "num_agent_steps_sampled_lifetime": 3072000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 3072000, "timers": {"training_iteration_time_ms": 112678.79, "restore_workers_time_ms": 0.057, "training_step_time_ms": 112678.673, "sample_time_ms": 2712.26, "learn_time_ms": 109929.767, "learn_throughput": 36.387, "synch_weights_time_ms": 30.81}, "counters": {"num_env_steps_sampled": 768000, "num_env_steps_trained": 768000, "num_agent_steps_sampled": 3072000, "num_agent_steps_trained": 3072000}, "done": false, "training_iteration": 192, "trial_id": "75ec3_00000", "date": "2024-08-13_06-14-04", "timestamp": 1723544044, "time_this_iter_s": 12.954750061035156, "time_total_s": 16790.05552339554, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b258c9d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 16790.05552339554, "iterations_since_restore": 192, "perf": {"cpu_util_percent": 54.40555555555555, "ram_util_percent": 83.6}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5691202886954503, "cur_kl_coeff": 0.03250987739272802, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.27911721792331684, "policy_loss": -0.0009850028630040547, "vf_loss": 0.2798007361736227, "vf_explained_var": 0.43075827596679567, "kl": 0.009273612016656172, "entropy": 1.1757324370126876, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 363825.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5249613373801506, "cur_kl_coeff": 7.369330576140701e-28, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.16088332899959473, "policy_loss": -0.0016962443478405476, "vf_loss": 0.1625795727046795, "vf_explained_var": 0.0360015524127496, "kl": 0.01642546308017055, "entropy": 1.0136696638568998, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 363825.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 772000, "num_env_steps_trained": 772000, "num_agent_steps_sampled": 3088000, "num_agent_steps_trained": 3088000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": 336.4, "episode_reward_mean": 378.88800000000003, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 140.3, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 21.0}, "policy_reward_mean": {"prey_policy": 186.614, "predator_policy": 2.83}, "custom_metrics": {}, "hist_stats": {"episode_reward": [399.1, 373.9, 375.5, 348.5, 385.6, 398.2, 400.0, 393.7, 366.5, 393.7, 397.3, 400.0, 384.2, 368.9, 395.5, 385.6, 367.20000000000005, 388.0, 393.7, 388.0, 392.40000000000003, 381.2, 361.9, 367.1, 379.1, 398.2, 381.1, 364.1, 387.4, 388.6, 349.20000000000005, 383.5, 376.6, 336.4, 364.5, 362.1, 390.2, 370.3, 379.3, 384.7, 399.1, 385.9, 373.0, 364.8, 369.4, 381.9, 400.0, 355.9, 381.40000000000003, 369.9, 363.5, 381.1, 385.2, 381.9000000000001, 393.0, 359.8, 376.6000000000001, 364.1, 337.1000000000002, 397.3, 346.7, 393.7, 386.0, 375.4, 381.1, 378.3, 394.6000000000001, 372.3, 373.6, 374.29999999999995, 365.0, 370.5, 397.3, 372.0, 389.7, 374.2, 360.5, 380.2, 389.2, 394.6, 400.0, 363.1, 386.5, 374.3, 380.0, 381.1, 373.4, 396.4, 390.4, 379.6, 385.5, 380.2, 367.4, 383.4, 383.3, 383.4, 383.4, 372.5, 384.0, 349.8], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [199.1, 200.0, 191.9, 182.0, 189.2, 176.3, 140.3, 189.2, 192.79999999999998, 192.8, 200.0, 198.2, 200.0, 200.0, 195.5, 198.2, 200.0, 165.5, 193.7, 200.0, 200.0, 197.3, 200.0, 200.0, 177.2, 200.0, 175.7, 183.2, 195.5, 200.0, 200.0, 185.6, 172.1, 193.1, 182.0, 200.0, 194.6, 199.1, 182.0, 200.0, 197.3, 193.1, 197.29999999999998, 179.9, 191.89999999999998, 155.0, 184.7, 175.4, 191.0, 178.1, 198.2, 200.0, 194.6, 186.5, 154.7, 196.4, 193.7, 193.7, 191.0, 194.6, 171.2, 164.0, 199.1, 178.4, 182.9, 193.7, 157.4, 152.0, 156.2, 194.3, 153.5, 194.6, 188.0, 198.2, 199.1, 156.2, 190.1, 189.2, 191.9, 192.8, 199.1, 200.0, 200.0, 182.9, 175.7, 188.3, 171.5, 179.3, 189.2, 180.20000000000002, 185.0, 191.9, 200.0, 200.0, 165.79999999999995, 181.1, 178.4, 200.0, 193.7, 165.2, 170.29999999999998, 180.2, 172.1, 200.0, 197.0, 186.2, 191.89999999999998, 185.0, 197.0, 194.0, 183.8, 173.0, 179.29999999999998, 188.3, 166.1, 182.0, 150.49999999999994, 170.6, 200.0, 197.3, 150.20000000000005, 186.5, 198.2, 195.5, 179.0, 200.0, 193.7, 175.7, 194.6, 186.5, 196.1, 174.2, 200.0, 194.6, 192.8, 171.5, 191.9, 175.7, 173.0, 188.29999999999998, 191.0, 161.0, 180.5, 182.0, 200.0, 197.3, 178.7, 188.3, 194.0, 193.7, 180.2, 191.0, 175.4, 175.1, 173.0, 198.2, 200.0, 189.2, 194.6, 200.0, 200.0, 200.0, 179.0, 172.1, 193.7, 192.8, 198.2, 151.10000000000002, 200.0, 170.0, 191.0, 190.1, 179.0, 187.4, 196.4, 200.0, 197.3, 190.1, 187.39999999999998, 189.2, 195.5, 185.0, 182.9, 197.3, 165.2, 189.2, 192.8, 188.6, 176.3, 200.0, 187.7, 193.7, 184.1, 197.3, 179.0, 183.5, 200.0, 176.0, 168.5, 170.3], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 0.0, 7.0, 3.0, 10.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 6.0, 0.0, 0.0, 1.0, 5.0, 0.0, 2.0, 4.0, 0.0, 0.0, 15.0, 7.0, 0.0, 3.0, 7.0, 0.0, 0.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 3.0, 0.0, 14.0, 0.0, 0.0, 6.0, 0.0, 0.0, 6.0, 21.0, 5.0, 9.0, 14.0, 0.0, 4.0, 0.0, 5.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 9.0, 0.0, 6.0, 8.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 9.0, 3.0, 0.0, 0.0, 11.0, 0.0, 13.0, 0.0, 9.0, 1.0, 1.0, 5.0, 0.0, 2.0, 0.0, 2.0, 1.0, 6.0, 3.0, 16.0, 0.0, 16.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 6.0, 1.0, 6.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 8.0, 6.0, 0.0, 7.0, 6.0, 13.0, 0.0, 8.0, 0.0, 0.0, 0.0, 4.0, 1.0, 2.0, 0.0, 0.0, 3.0, 10.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 6.0, 0.0, 0.0, 12.0, 13.0, 0.0, 10.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 3.0, 3.0, 0.0, 0.0, 5.0, 0.0, 0.0, 11.0, 2.0, 0.0, 2.0, 7.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 10.0, 8.0, 0.0, 11.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 9.626191777060956, "mean_inference_ms": 23.722700827262326, "mean_action_processing_ms": 4.648091518193856, "mean_env_wait_ms": 5.741919197973803, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0059365034103393555, "StateBufferConnector_ms": 0.007667183876037598, "ViewRequirementAgentConnector_ms": 0.13263356685638428}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": 336.4, "episode_return_mean": 378.88800000000003, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 3088000, "num_agent_steps_trained": 3088000, "num_env_steps_sampled": 772000, "num_env_steps_trained": 772000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 316.89463948934247, "num_env_steps_trained_throughput_per_sec": 316.89463948934247, "timesteps_total": 772000, "num_env_steps_sampled_lifetime": 772000, "num_agent_steps_sampled_lifetime": 3088000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 3088000, "timers": {"training_iteration_time_ms": 111836.992, "restore_workers_time_ms": 0.058, "training_step_time_ms": 111836.851, "sample_time_ms": 2544.592, "learn_time_ms": 109255.837, "learn_throughput": 36.611, "synch_weights_time_ms": 30.659}, "counters": {"num_env_steps_sampled": 772000, "num_env_steps_trained": 772000, "num_agent_steps_sampled": 3088000, "num_agent_steps_trained": 3088000}, "done": false, "training_iteration": 193, "trial_id": "75ec3_00000", "date": "2024-08-13_06-14-17", "timestamp": 1723544057, "time_this_iter_s": 12.663742065429688, "time_total_s": 16802.719265460968, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b258cc10>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 16802.719265460968, "iterations_since_restore": 193, "perf": {"cpu_util_percent": 50.74444444444445, "ram_util_percent": 83.58333333333334}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.731355681834082, "cur_kl_coeff": 0.03250987739272802, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.22931581175576268, "policy_loss": -0.005641544941398832, "vf_loss": 0.2345728356421989, "vf_explained_var": 0.4565691532912078, "kl": 0.011827801345627628, "entropy": 1.1464893129136828, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 365715.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.38107389845446776, "cur_kl_coeff": 7.369330576140701e-28, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.13786875575376803, "policy_loss": -0.0007772260584508774, "vf_loss": 0.1386459822023642, "vf_explained_var": -0.00948660383148799, "kl": 0.010217774143507207, "entropy": 0.9705825267330048, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 365715.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 776000, "num_env_steps_trained": 776000, "num_agent_steps_sampled": 3104000, "num_agent_steps_trained": 3104000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": 336.4, "episode_reward_mean": 377.818, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 150.20000000000005, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 21.0}, "policy_reward_mean": {"prey_policy": 185.789, "predator_policy": 3.12}, "custom_metrics": {}, "hist_stats": {"episode_reward": [393.7, 388.0, 392.40000000000003, 381.2, 361.9, 367.1, 379.1, 398.2, 381.1, 364.1, 387.4, 388.6, 349.20000000000005, 383.5, 376.6, 336.4, 364.5, 362.1, 390.2, 370.3, 379.3, 384.7, 399.1, 385.9, 373.0, 364.8, 369.4, 381.9, 400.0, 355.9, 381.40000000000003, 369.9, 363.5, 381.1, 385.2, 381.9000000000001, 393.0, 359.8, 376.6000000000001, 364.1, 337.1000000000002, 397.3, 346.7, 393.7, 386.0, 375.4, 381.1, 378.3, 394.6000000000001, 372.3, 373.6, 374.29999999999995, 365.0, 370.5, 397.3, 372.0, 389.7, 374.2, 360.5, 380.2, 389.2, 394.6, 400.0, 363.1, 386.5, 374.3, 380.0, 381.1, 373.4, 396.4, 390.4, 379.6, 385.5, 380.2, 367.4, 383.4, 383.3, 383.4, 383.4, 372.5, 384.0, 349.8, 384.2, 368.1, 379.6, 388.3, 365.6, 378.8, 389.5, 389.7, 383.3, 366.9, 370.7, 357.4, 368.1, 390.1, 362.2, 372.8, 399.1, 400.0], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [194.6, 199.1, 182.0, 200.0, 197.3, 193.1, 197.29999999999998, 179.9, 191.89999999999998, 155.0, 184.7, 175.4, 191.0, 178.1, 198.2, 200.0, 194.6, 186.5, 154.7, 196.4, 193.7, 193.7, 191.0, 194.6, 171.2, 164.0, 199.1, 178.4, 182.9, 193.7, 157.4, 152.0, 156.2, 194.3, 153.5, 194.6, 188.0, 198.2, 199.1, 156.2, 190.1, 189.2, 191.9, 192.8, 199.1, 200.0, 200.0, 182.9, 175.7, 188.3, 171.5, 179.3, 189.2, 180.20000000000002, 185.0, 191.9, 200.0, 200.0, 165.79999999999995, 181.1, 178.4, 200.0, 193.7, 165.2, 170.29999999999998, 180.2, 172.1, 200.0, 197.0, 186.2, 191.89999999999998, 185.0, 197.0, 194.0, 183.8, 173.0, 179.29999999999998, 188.3, 166.1, 182.0, 150.49999999999994, 170.6, 200.0, 197.3, 150.20000000000005, 186.5, 198.2, 195.5, 179.0, 200.0, 193.7, 175.7, 194.6, 186.5, 196.1, 174.2, 200.0, 194.6, 192.8, 171.5, 191.9, 175.7, 173.0, 188.29999999999998, 191.0, 161.0, 180.5, 182.0, 200.0, 197.3, 178.7, 188.3, 194.0, 193.7, 180.2, 191.0, 175.4, 175.1, 173.0, 198.2, 200.0, 189.2, 194.6, 200.0, 200.0, 200.0, 179.0, 172.1, 193.7, 192.8, 198.2, 151.10000000000002, 200.0, 170.0, 191.0, 190.1, 179.0, 187.4, 196.4, 200.0, 197.3, 190.1, 187.39999999999998, 189.2, 195.5, 185.0, 182.9, 197.3, 165.2, 189.2, 192.8, 188.6, 176.3, 200.0, 187.7, 193.7, 184.1, 197.3, 179.0, 183.5, 200.0, 176.0, 168.5, 170.3, 179.0, 198.2, 183.8, 182.3, 190.1, 186.5, 197.3, 191.0, 179.3, 176.3, 177.2, 194.6, 195.5, 191.0, 200.0, 187.7, 178.1, 198.2, 170.9, 179.0, 188.0, 166.7, 162.2, 177.2, 172.7, 184.4, 200.0, 190.1, 182.9, 170.3, 188.3, 183.5, 200.0, 199.1, 200.0, 200.0], "policy_predator_policy_reward": [0.0, 0.0, 1.0, 5.0, 0.0, 2.0, 4.0, 0.0, 0.0, 15.0, 7.0, 0.0, 3.0, 7.0, 0.0, 0.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 3.0, 0.0, 14.0, 0.0, 0.0, 6.0, 0.0, 0.0, 6.0, 21.0, 5.0, 9.0, 14.0, 0.0, 4.0, 0.0, 5.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 9.0, 0.0, 6.0, 8.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 9.0, 3.0, 0.0, 0.0, 11.0, 0.0, 13.0, 0.0, 9.0, 1.0, 1.0, 5.0, 0.0, 2.0, 0.0, 2.0, 1.0, 6.0, 3.0, 16.0, 0.0, 16.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 6.0, 1.0, 6.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 8.0, 6.0, 0.0, 7.0, 6.0, 13.0, 0.0, 8.0, 0.0, 0.0, 0.0, 4.0, 1.0, 2.0, 0.0, 0.0, 3.0, 10.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 6.0, 0.0, 0.0, 12.0, 13.0, 0.0, 10.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 3.0, 3.0, 0.0, 0.0, 5.0, 0.0, 0.0, 11.0, 2.0, 0.0, 2.0, 7.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 10.0, 8.0, 0.0, 11.0, 0.0, 0.0, 7.0, 0.0, 2.0, 3.0, 0.0, 0.0, 0.0, 1.0, 9.0, 7.0, 0.0, 3.0, 0.0, 2.0, 0.0, 0.0, 7.0, 5.0, 12.0, 10.0, 6.0, 11.0, 7.0, 11.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 9.583812502265994, "mean_inference_ms": 23.6207405703477, "mean_action_processing_ms": 4.627331437200629, "mean_env_wait_ms": 5.7158519633318, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005932331085205078, "StateBufferConnector_ms": 0.007642269134521484, "ViewRequirementAgentConnector_ms": 0.1284540891647339}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": 336.4, "episode_return_mean": 377.818, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 3104000, "num_agent_steps_trained": 3104000, "num_env_steps_sampled": 776000, "num_env_steps_trained": 776000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 312.2980289644735, "num_env_steps_trained_throughput_per_sec": 312.2980289644735, "timesteps_total": 776000, "num_env_steps_sampled_lifetime": 776000, "num_agent_steps_sampled_lifetime": 3104000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 3104000, "timers": {"training_iteration_time_ms": 110984.988, "restore_workers_time_ms": 0.058, "training_step_time_ms": 110984.847, "sample_time_ms": 2359.848, "learn_time_ms": 108589.633, "learn_throughput": 36.836, "synch_weights_time_ms": 29.567}, "counters": {"num_env_steps_sampled": 776000, "num_env_steps_trained": 776000, "num_agent_steps_sampled": 3104000, "num_agent_steps_trained": 3104000}, "done": false, "training_iteration": 194, "trial_id": "75ec3_00000", "date": "2024-08-13_06-14-30", "timestamp": 1723544070, "time_this_iter_s": 12.866944074630737, "time_total_s": 16815.5862095356, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2567f70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 16815.5862095356, "iterations_since_restore": 194, "perf": {"cpu_util_percent": 51.91111111111111, "ram_util_percent": 83.51111111111112}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9420074033674108, "cur_kl_coeff": 0.03250987739272802, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.28734174130069307, "policy_loss": -0.006325827332622515, "vf_loss": 0.293320018283668, "vf_explained_var": 0.5421484194104633, "kl": 0.010690627646302747, "entropy": 1.121110218668741, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 367605.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.3308091370142484, "cur_kl_coeff": 7.369330576140701e-28, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.11484744250774384, "policy_loss": -0.0012643046524355966, "vf_loss": 0.11611174709535027, "vf_explained_var": -0.11120159925607147, "kl": 0.013721335767334097, "entropy": 0.9053408997399467, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 367605.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 780000, "num_env_steps_trained": 780000, "num_agent_steps_sampled": 3120000, "num_agent_steps_trained": 3120000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": 337.1000000000002, "episode_reward_mean": 378.69000000000017, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 150.20000000000005, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 16.0}, "policy_reward_mean": {"prey_policy": 186.47, "predator_policy": 2.875}, "custom_metrics": {}, "hist_stats": {"episode_reward": [390.2, 370.3, 379.3, 384.7, 399.1, 385.9, 373.0, 364.8, 369.4, 381.9, 400.0, 355.9, 381.40000000000003, 369.9, 363.5, 381.1, 385.2, 381.9000000000001, 393.0, 359.8, 376.6000000000001, 364.1, 337.1000000000002, 397.3, 346.7, 393.7, 386.0, 375.4, 381.1, 378.3, 394.6000000000001, 372.3, 373.6, 374.29999999999995, 365.0, 370.5, 397.3, 372.0, 389.7, 374.2, 360.5, 380.2, 389.2, 394.6, 400.0, 363.1, 386.5, 374.3, 380.0, 381.1, 373.4, 396.4, 390.4, 379.6, 385.5, 380.2, 367.4, 383.4, 383.3, 383.4, 383.4, 372.5, 384.0, 349.8, 384.2, 368.1, 379.6, 388.3, 365.6, 378.8, 389.5, 389.7, 383.3, 366.9, 370.7, 357.4, 368.1, 390.1, 362.2, 372.8, 399.1, 400.0, 392.8, 369.9, 376.6, 379.3, 377.3, 389.2, 382.9, 392.8, 400.0, 381.1, 386.0, 387.7, 380.1, 352.50000000000006, 390.1, 369.8, 354.9, 379.3], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [188.0, 198.2, 199.1, 156.2, 190.1, 189.2, 191.9, 192.8, 199.1, 200.0, 200.0, 182.9, 175.7, 188.3, 171.5, 179.3, 189.2, 180.20000000000002, 185.0, 191.9, 200.0, 200.0, 165.79999999999995, 181.1, 178.4, 200.0, 193.7, 165.2, 170.29999999999998, 180.2, 172.1, 200.0, 197.0, 186.2, 191.89999999999998, 185.0, 197.0, 194.0, 183.8, 173.0, 179.29999999999998, 188.3, 166.1, 182.0, 150.49999999999994, 170.6, 200.0, 197.3, 150.20000000000005, 186.5, 198.2, 195.5, 179.0, 200.0, 193.7, 175.7, 194.6, 186.5, 196.1, 174.2, 200.0, 194.6, 192.8, 171.5, 191.9, 175.7, 173.0, 188.29999999999998, 191.0, 161.0, 180.5, 182.0, 200.0, 197.3, 178.7, 188.3, 194.0, 193.7, 180.2, 191.0, 175.4, 175.1, 173.0, 198.2, 200.0, 189.2, 194.6, 200.0, 200.0, 200.0, 179.0, 172.1, 193.7, 192.8, 198.2, 151.10000000000002, 200.0, 170.0, 191.0, 190.1, 179.0, 187.4, 196.4, 200.0, 197.3, 190.1, 187.39999999999998, 189.2, 195.5, 185.0, 182.9, 197.3, 165.2, 189.2, 192.8, 188.6, 176.3, 200.0, 187.7, 193.7, 184.1, 197.3, 179.0, 183.5, 200.0, 176.0, 168.5, 170.3, 179.0, 198.2, 183.8, 182.3, 190.1, 186.5, 197.3, 191.0, 179.3, 176.3, 177.2, 194.6, 195.5, 191.0, 200.0, 187.7, 178.1, 198.2, 170.9, 179.0, 188.0, 166.7, 162.2, 177.2, 172.7, 184.4, 200.0, 190.1, 182.9, 170.3, 188.3, 183.5, 200.0, 199.1, 200.0, 200.0, 192.8, 200.0, 193.1, 165.8, 183.8, 192.8, 186.5, 192.8, 179.3, 197.0, 197.3, 191.9, 182.9, 200.0, 195.5, 197.3, 200.0, 200.0, 173.0, 199.1, 200.0, 179.0, 194.6, 190.1, 194.0, 169.1, 171.5, 173.0, 195.5, 194.6, 193.7, 163.1, 158.9, 179.0, 186.5, 192.8], "policy_predator_policy_reward": [4.0, 0.0, 5.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 9.0, 0.0, 6.0, 8.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 9.0, 3.0, 0.0, 0.0, 11.0, 0.0, 13.0, 0.0, 9.0, 1.0, 1.0, 5.0, 0.0, 2.0, 0.0, 2.0, 1.0, 6.0, 3.0, 16.0, 0.0, 16.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 6.0, 1.0, 6.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 8.0, 6.0, 0.0, 7.0, 6.0, 13.0, 0.0, 8.0, 0.0, 0.0, 0.0, 4.0, 1.0, 2.0, 0.0, 0.0, 3.0, 10.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 6.0, 0.0, 0.0, 12.0, 13.0, 0.0, 10.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 3.0, 3.0, 0.0, 0.0, 5.0, 0.0, 0.0, 11.0, 2.0, 0.0, 2.0, 7.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 10.0, 8.0, 0.0, 11.0, 0.0, 0.0, 7.0, 0.0, 2.0, 3.0, 0.0, 0.0, 0.0, 1.0, 9.0, 7.0, 0.0, 3.0, 0.0, 2.0, 0.0, 0.0, 7.0, 5.0, 12.0, 10.0, 6.0, 11.0, 7.0, 11.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 9.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 7.0, 3.0, 0.0, 10.0, 7.0, 8.0, 0.0, 0.0, 0.0, 6.0, 7.0, 15.0, 2.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 9.541849499894143, "mean_inference_ms": 23.519755101802097, "mean_action_processing_ms": 4.60676725513379, "mean_env_wait_ms": 5.690044096575939, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005967259407043457, "StateBufferConnector_ms": 0.004085659980773926, "ViewRequirementAgentConnector_ms": 0.1323777437210083}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": 337.1000000000002, "episode_return_mean": 378.69000000000017, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 3120000, "num_agent_steps_trained": 3120000, "num_env_steps_sampled": 780000, "num_env_steps_trained": 780000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 318.7940637763854, "num_env_steps_trained_throughput_per_sec": 318.7940637763854, "timesteps_total": 780000, "num_env_steps_sampled_lifetime": 780000, "num_agent_steps_sampled_lifetime": 3120000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 3120000, "timers": {"training_iteration_time_ms": 110029.08, "restore_workers_time_ms": 0.057, "training_step_time_ms": 110028.94, "sample_time_ms": 2179.378, "learn_time_ms": 107811.914, "learn_throughput": 37.102, "synch_weights_time_ms": 31.708}, "counters": {"num_env_steps_sampled": 780000, "num_env_steps_trained": 780000, "num_agent_steps_sampled": 3120000, "num_agent_steps_trained": 3120000}, "done": false, "training_iteration": 195, "trial_id": "75ec3_00000", "date": "2024-08-13_06-14-43", "timestamp": 1723544083, "time_this_iter_s": 12.621797800064087, "time_total_s": 16828.208007335663, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b258c790>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 16828.208007335663, "iterations_since_restore": 195, "perf": {"cpu_util_percent": 49.75, "ram_util_percent": 83.57777777777777}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.1224686004576228, "cur_kl_coeff": 0.03250987739272802, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.49202640534892295, "policy_loss": -0.0022791155535116714, "vf_loss": 0.4940032376143983, "vf_explained_var": 0.46255430393118074, "kl": 0.009298215757207198, "entropy": 1.089851758719752, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 369495.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4806153295059053, "cur_kl_coeff": 7.369330576140701e-28, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.2462122395634651, "policy_loss": -0.001109126119790648, "vf_loss": 0.2473213651154693, "vf_explained_var": 0.1216562273010375, "kl": 0.007107954437669274, "entropy": 0.9082826536168497, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 369495.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 784000, "num_env_steps_trained": 784000, "num_agent_steps_sampled": 3136000, "num_agent_steps_trained": 3136000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": 346.4, "episode_reward_mean": 378.80100000000004, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 151.10000000000002, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 15.0}, "policy_reward_mean": {"prey_policy": 186.6155, "predator_policy": 2.785}, "custom_metrics": {}, "hist_stats": {"episode_reward": [375.4, 381.1, 378.3, 394.6000000000001, 372.3, 373.6, 374.29999999999995, 365.0, 370.5, 397.3, 372.0, 389.7, 374.2, 360.5, 380.2, 389.2, 394.6, 400.0, 363.1, 386.5, 374.3, 380.0, 381.1, 373.4, 396.4, 390.4, 379.6, 385.5, 380.2, 367.4, 383.4, 383.3, 383.4, 383.4, 372.5, 384.0, 349.8, 384.2, 368.1, 379.6, 388.3, 365.6, 378.8, 389.5, 389.7, 383.3, 366.9, 370.7, 357.4, 368.1, 390.1, 362.2, 372.8, 399.1, 400.0, 392.8, 369.9, 376.6, 379.3, 377.3, 389.2, 382.9, 392.8, 400.0, 381.1, 386.0, 387.7, 380.1, 352.50000000000006, 390.1, 369.8, 354.9, 379.3, 371.3, 366.9, 381.1, 389.7, 398.2, 352.0, 367.0, 377.3, 353.20000000000005, 397.1, 374.3, 389.0, 384.59999999999997, 390.1, 367.3, 379.3, 381.3, 390.1, 371.8, 360.5, 346.4, 385.6, 359.5, 392.8, 396.4, 388.0, 372.1], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [193.7, 175.7, 194.6, 186.5, 196.1, 174.2, 200.0, 194.6, 192.8, 171.5, 191.9, 175.7, 173.0, 188.29999999999998, 191.0, 161.0, 180.5, 182.0, 200.0, 197.3, 178.7, 188.3, 194.0, 193.7, 180.2, 191.0, 175.4, 175.1, 173.0, 198.2, 200.0, 189.2, 194.6, 200.0, 200.0, 200.0, 179.0, 172.1, 193.7, 192.8, 198.2, 151.10000000000002, 200.0, 170.0, 191.0, 190.1, 179.0, 187.4, 196.4, 200.0, 197.3, 190.1, 187.39999999999998, 189.2, 195.5, 185.0, 182.9, 197.3, 165.2, 189.2, 192.8, 188.6, 176.3, 200.0, 187.7, 193.7, 184.1, 197.3, 179.0, 183.5, 200.0, 176.0, 168.5, 170.3, 179.0, 198.2, 183.8, 182.3, 190.1, 186.5, 197.3, 191.0, 179.3, 176.3, 177.2, 194.6, 195.5, 191.0, 200.0, 187.7, 178.1, 198.2, 170.9, 179.0, 188.0, 166.7, 162.2, 177.2, 172.7, 184.4, 200.0, 190.1, 182.9, 170.3, 188.3, 183.5, 200.0, 199.1, 200.0, 200.0, 192.8, 200.0, 193.1, 165.8, 183.8, 192.8, 186.5, 192.8, 179.3, 197.0, 197.3, 191.9, 182.9, 200.0, 195.5, 197.3, 200.0, 200.0, 173.0, 199.1, 200.0, 179.0, 194.6, 190.1, 194.0, 169.1, 171.5, 173.0, 195.5, 194.6, 193.7, 163.1, 158.9, 179.0, 186.5, 192.8, 188.0, 179.3, 168.2, 190.7, 190.1, 191.0, 195.5, 192.2, 198.2, 200.0, 173.0, 167.0, 188.6, 163.4, 200.0, 167.3, 170.3, 173.9, 196.1, 200.0, 191.0, 176.3, 197.0, 188.0, 185.0, 194.60000000000002, 190.1, 200.0, 183.8, 177.5, 200.0, 170.3, 174.2, 199.1, 190.1, 200.0, 186.2, 179.6, 165.5, 182.0, 167.3, 166.1, 185.6, 200.0, 185.0, 165.5, 200.0, 192.8, 196.4, 200.0, 200.0, 182.0, 184.7, 187.4], "policy_predator_policy_reward": [6.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 8.0, 6.0, 0.0, 7.0, 6.0, 13.0, 0.0, 8.0, 0.0, 0.0, 0.0, 4.0, 1.0, 2.0, 0.0, 0.0, 3.0, 10.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 6.0, 0.0, 0.0, 12.0, 13.0, 0.0, 10.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 3.0, 3.0, 0.0, 0.0, 5.0, 0.0, 0.0, 11.0, 2.0, 0.0, 2.0, 7.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 10.0, 8.0, 0.0, 11.0, 0.0, 0.0, 7.0, 0.0, 2.0, 3.0, 0.0, 0.0, 0.0, 1.0, 9.0, 7.0, 0.0, 3.0, 0.0, 2.0, 0.0, 0.0, 7.0, 5.0, 12.0, 10.0, 6.0, 11.0, 7.0, 11.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 9.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 7.0, 3.0, 0.0, 10.0, 7.0, 8.0, 0.0, 0.0, 0.0, 6.0, 7.0, 15.0, 2.0, 0.0, 0.0, 4.0, 0.0, 7.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 12.0, 7.0, 8.0, 10.0, 0.0, 0.0, 9.0, 0.0, 1.0, 0.0, 7.0, 0.0, 4.0, 5.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 9.0, 8.0, 0.0, 0.0, 0.0, 6.0, 0.0, 7.0, 6.0, 0.0, 13.0, 0.0, 0.0, 4.0, 5.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 9.83269415228686, "mean_inference_ms": 23.013684881332505, "mean_action_processing_ms": 4.582495607161029, "mean_env_wait_ms": 5.549682952676667, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005794405937194824, "StateBufferConnector_ms": 0.004301309585571289, "ViewRequirementAgentConnector_ms": 0.1589031219482422}, "num_episodes": 27, "episode_return_max": 400.0, "episode_return_min": 346.4, "episode_return_mean": 378.80100000000004, "episodes_this_iter": 27}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 3136000, "num_agent_steps_trained": 3136000, "num_env_steps_sampled": 784000, "num_env_steps_trained": 784000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 321.8354123392875, "num_env_steps_trained_throughput_per_sec": 321.8354123392875, "timesteps_total": 784000, "num_env_steps_sampled_lifetime": 784000, "num_agent_steps_sampled_lifetime": 3136000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 3136000, "timers": {"training_iteration_time_ms": 13613.252, "restore_workers_time_ms": 0.058, "training_step_time_ms": 13613.112, "sample_time_ms": 2022.54, "learn_time_ms": 11553.781, "learn_throughput": 346.207, "synch_weights_time_ms": 29.962}, "counters": {"num_env_steps_sampled": 784000, "num_env_steps_trained": 784000, "num_agent_steps_sampled": 3136000, "num_agent_steps_trained": 3136000}, "done": false, "training_iteration": 196, "trial_id": "75ec3_00000", "date": "2024-08-13_06-14-55", "timestamp": 1723544095, "time_this_iter_s": 12.488744020462036, "time_total_s": 16840.696751356125, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b258c820>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 16840.696751356125, "iterations_since_restore": 196, "perf": {"cpu_util_percent": 50.12777777777778, "ram_util_percent": 83.57222222222221}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5091094286195816, "cur_kl_coeff": 0.03250987739272802, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.2933779529922595, "policy_loss": -0.0024926588775728035, "vf_loss": 0.2956668938335189, "vf_explained_var": 0.3877250377778654, "kl": 0.006266346178544136, "entropy": 1.1350754258493898, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 371385.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.43956032788390836, "cur_kl_coeff": 7.369330576140701e-28, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.1706451425230298, "policy_loss": -0.0004556848264728037, "vf_loss": 0.17110082747916094, "vf_explained_var": 0.13180881300300518, "kl": 0.01106150562642156, "entropy": 0.8879587388858593, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 371385.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 788000, "num_env_steps_trained": 788000, "num_agent_steps_sampled": 3152000, "num_agent_steps_trained": 3152000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": 346.4, "episode_reward_mean": 378.67199999999997, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 151.10000000000002, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 15.0}, "policy_reward_mean": {"prey_policy": 186.56599999999997, "predator_policy": 2.77}, "custom_metrics": {}, "hist_stats": {"episode_reward": [363.1, 386.5, 374.3, 380.0, 381.1, 373.4, 396.4, 390.4, 379.6, 385.5, 380.2, 367.4, 383.4, 383.3, 383.4, 383.4, 372.5, 384.0, 349.8, 384.2, 368.1, 379.6, 388.3, 365.6, 378.8, 389.5, 389.7, 383.3, 366.9, 370.7, 357.4, 368.1, 390.1, 362.2, 372.8, 399.1, 400.0, 392.8, 369.9, 376.6, 379.3, 377.3, 389.2, 382.9, 392.8, 400.0, 381.1, 386.0, 387.7, 380.1, 352.50000000000006, 390.1, 369.8, 354.9, 379.3, 371.3, 366.9, 381.1, 389.7, 398.2, 352.0, 367.0, 377.3, 353.20000000000005, 397.1, 374.3, 389.0, 384.59999999999997, 390.1, 367.3, 379.3, 381.3, 390.1, 371.8, 360.5, 346.4, 385.6, 359.5, 392.8, 396.4, 388.0, 372.1, 367.9, 400.0, 386.5, 375.4, 363.9, 374.5, 384.7, 373.3, 360.59999999999997, 386.5, 384.7, 387.4, 372.9, 382.6, 388.2, 393.3, 371.8, 375.7], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [179.0, 172.1, 193.7, 192.8, 198.2, 151.10000000000002, 200.0, 170.0, 191.0, 190.1, 179.0, 187.4, 196.4, 200.0, 197.3, 190.1, 187.39999999999998, 189.2, 195.5, 185.0, 182.9, 197.3, 165.2, 189.2, 192.8, 188.6, 176.3, 200.0, 187.7, 193.7, 184.1, 197.3, 179.0, 183.5, 200.0, 176.0, 168.5, 170.3, 179.0, 198.2, 183.8, 182.3, 190.1, 186.5, 197.3, 191.0, 179.3, 176.3, 177.2, 194.6, 195.5, 191.0, 200.0, 187.7, 178.1, 198.2, 170.9, 179.0, 188.0, 166.7, 162.2, 177.2, 172.7, 184.4, 200.0, 190.1, 182.9, 170.3, 188.3, 183.5, 200.0, 199.1, 200.0, 200.0, 192.8, 200.0, 193.1, 165.8, 183.8, 192.8, 186.5, 192.8, 179.3, 197.0, 197.3, 191.9, 182.9, 200.0, 195.5, 197.3, 200.0, 200.0, 173.0, 199.1, 200.0, 179.0, 194.6, 190.1, 194.0, 169.1, 171.5, 173.0, 195.5, 194.6, 193.7, 163.1, 158.9, 179.0, 186.5, 192.8, 188.0, 179.3, 168.2, 190.7, 190.1, 191.0, 195.5, 192.2, 198.2, 200.0, 173.0, 167.0, 188.6, 163.4, 200.0, 167.3, 170.3, 173.9, 196.1, 200.0, 191.0, 176.3, 197.0, 188.0, 185.0, 194.60000000000002, 190.1, 200.0, 183.8, 177.5, 200.0, 170.3, 174.2, 199.1, 190.1, 200.0, 186.2, 179.6, 165.5, 182.0, 167.3, 166.1, 185.6, 200.0, 185.0, 165.5, 200.0, 192.8, 196.4, 200.0, 200.0, 182.0, 184.7, 187.4, 164.0, 191.9, 200.0, 200.0, 194.6, 191.9, 179.3, 190.1, 188.3, 170.6, 191.0, 177.5, 186.5, 198.2, 170.3, 194.0, 182.0, 170.60000000000002, 191.9, 194.6, 200.0, 184.7, 196.4, 191.0, 181.4, 186.5, 200.0, 167.6, 198.2, 185.0, 200.0, 191.3, 191.0, 174.8, 166.7, 200.0], "policy_predator_policy_reward": [6.0, 6.0, 0.0, 0.0, 12.0, 13.0, 0.0, 10.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 3.0, 3.0, 0.0, 0.0, 5.0, 0.0, 0.0, 11.0, 2.0, 0.0, 2.0, 7.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 10.0, 8.0, 0.0, 11.0, 0.0, 0.0, 7.0, 0.0, 2.0, 3.0, 0.0, 0.0, 0.0, 1.0, 9.0, 7.0, 0.0, 3.0, 0.0, 2.0, 0.0, 0.0, 7.0, 5.0, 12.0, 10.0, 6.0, 11.0, 7.0, 11.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 9.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 7.0, 3.0, 0.0, 10.0, 7.0, 8.0, 0.0, 0.0, 0.0, 6.0, 7.0, 15.0, 2.0, 0.0, 0.0, 4.0, 0.0, 7.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 12.0, 7.0, 8.0, 10.0, 0.0, 0.0, 9.0, 0.0, 1.0, 0.0, 7.0, 0.0, 4.0, 5.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 9.0, 8.0, 0.0, 0.0, 0.0, 6.0, 0.0, 7.0, 6.0, 0.0, 13.0, 0.0, 0.0, 4.0, 5.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 5.0, 0.0, 3.0, 3.0, 0.0, 0.0, 9.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 2.0, 8.0, 7.0, 5.0, 0.0, 2.0, 0.0, 0.0, 6.0, 9.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 9.442320573936712, "mean_inference_ms": 23.275536022295896, "mean_action_processing_ms": 4.557221924460021, "mean_env_wait_ms": 5.628736962205852, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004258394241333008, "StateBufferConnector_ms": 0.0037107467651367188, "ViewRequirementAgentConnector_ms": 0.15296173095703125}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": 346.4, "episode_return_mean": 378.67199999999997, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 3152000, "num_agent_steps_trained": 3152000, "num_env_steps_sampled": 788000, "num_env_steps_trained": 788000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 318.50016582601955, "num_env_steps_trained_throughput_per_sec": 318.50016582601955, "timesteps_total": 788000, "num_env_steps_sampled_lifetime": 788000, "num_agent_steps_sampled_lifetime": 3152000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 3152000, "timers": {"training_iteration_time_ms": 13014.596, "restore_workers_time_ms": 0.058, "training_step_time_ms": 13014.467, "sample_time_ms": 1822.208, "learn_time_ms": 11161.457, "learn_throughput": 358.376, "synch_weights_time_ms": 24.976}, "counters": {"num_env_steps_sampled": 788000, "num_env_steps_trained": 788000, "num_agent_steps_sampled": 3152000, "num_agent_steps_trained": 3152000}, "done": false, "training_iteration": 197, "trial_id": "75ec3_00000", "date": "2024-08-13_06-15-08", "timestamp": 1723544108, "time_this_iter_s": 12.64114499092102, "time_total_s": 16853.337896347046, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2495ca0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 16853.337896347046, "iterations_since_restore": 197, "perf": {"cpu_util_percent": 47.56111111111111, "ram_util_percent": 83.57222222222222}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3686680058244045, "cur_kl_coeff": 0.03250987739272802, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.3045040550271527, "policy_loss": -0.006606647427928038, "vf_loss": 0.3107093820483892, "vf_explained_var": 0.28597419255625, "kl": 0.012344590089328169, "entropy": 1.0942106611514217, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 373275.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.3981889815734965, "cur_kl_coeff": 7.369330576140701e-28, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.18363724243309762, "policy_loss": -0.0013217645296925511, "vf_loss": 0.18495900602792587, "vf_explained_var": 0.03561431128511984, "kl": 0.004326316553078109, "entropy": 0.8942559365242246, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 373275.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 792000, "num_env_steps_trained": 792000, "num_agent_steps_sampled": 3168000, "num_agent_steps_trained": 3168000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": 346.4, "episode_reward_mean": 378.65, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 158.9, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 16.0}, "policy_reward_mean": {"prey_policy": 186.455, "predator_policy": 2.87}, "custom_metrics": {}, "hist_stats": {"episode_reward": [349.8, 384.2, 368.1, 379.6, 388.3, 365.6, 378.8, 389.5, 389.7, 383.3, 366.9, 370.7, 357.4, 368.1, 390.1, 362.2, 372.8, 399.1, 400.0, 392.8, 369.9, 376.6, 379.3, 377.3, 389.2, 382.9, 392.8, 400.0, 381.1, 386.0, 387.7, 380.1, 352.50000000000006, 390.1, 369.8, 354.9, 379.3, 371.3, 366.9, 381.1, 389.7, 398.2, 352.0, 367.0, 377.3, 353.20000000000005, 397.1, 374.3, 389.0, 384.59999999999997, 390.1, 367.3, 379.3, 381.3, 390.1, 371.8, 360.5, 346.4, 385.6, 359.5, 392.8, 396.4, 388.0, 372.1, 367.9, 400.0, 386.5, 375.4, 363.9, 374.5, 384.7, 373.3, 360.59999999999997, 386.5, 384.7, 387.4, 372.9, 382.6, 388.2, 393.3, 371.8, 375.7, 359.2, 375.9, 400.0, 400.0, 387.4, 392.4, 376.5, 389.0, 372.2, 380.0, 383.3, 382.0, 372.2, 347.6, 393.20000000000005, 377.1, 379.9, 377.8], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [168.5, 170.3, 179.0, 198.2, 183.8, 182.3, 190.1, 186.5, 197.3, 191.0, 179.3, 176.3, 177.2, 194.6, 195.5, 191.0, 200.0, 187.7, 178.1, 198.2, 170.9, 179.0, 188.0, 166.7, 162.2, 177.2, 172.7, 184.4, 200.0, 190.1, 182.9, 170.3, 188.3, 183.5, 200.0, 199.1, 200.0, 200.0, 192.8, 200.0, 193.1, 165.8, 183.8, 192.8, 186.5, 192.8, 179.3, 197.0, 197.3, 191.9, 182.9, 200.0, 195.5, 197.3, 200.0, 200.0, 173.0, 199.1, 200.0, 179.0, 194.6, 190.1, 194.0, 169.1, 171.5, 173.0, 195.5, 194.6, 193.7, 163.1, 158.9, 179.0, 186.5, 192.8, 188.0, 179.3, 168.2, 190.7, 190.1, 191.0, 195.5, 192.2, 198.2, 200.0, 173.0, 167.0, 188.6, 163.4, 200.0, 167.3, 170.3, 173.9, 196.1, 200.0, 191.0, 176.3, 197.0, 188.0, 185.0, 194.60000000000002, 190.1, 200.0, 183.8, 177.5, 200.0, 170.3, 174.2, 199.1, 190.1, 200.0, 186.2, 179.6, 165.5, 182.0, 167.3, 166.1, 185.6, 200.0, 185.0, 165.5, 200.0, 192.8, 196.4, 200.0, 200.0, 182.0, 184.7, 187.4, 164.0, 191.9, 200.0, 200.0, 194.6, 191.9, 179.3, 190.1, 188.3, 170.6, 191.0, 177.5, 186.5, 198.2, 170.3, 194.0, 182.0, 170.60000000000002, 191.9, 194.6, 200.0, 184.7, 196.4, 191.0, 181.4, 186.5, 200.0, 167.6, 198.2, 185.0, 200.0, 191.3, 191.0, 174.8, 166.7, 200.0, 174.2, 167.0, 194.6, 173.3, 200.0, 200.0, 200.0, 200.0, 200.0, 187.4, 197.3, 193.1, 189.2, 182.3, 193.7, 194.3, 190.1, 172.1, 200.0, 170.0, 181.4, 191.9, 194.6, 187.4, 187.4, 180.8, 161.6, 167.0, 187.1, 199.1, 167.0, 199.1, 192.8, 181.1, 167.0, 192.8], "policy_predator_policy_reward": [11.0, 0.0, 0.0, 7.0, 0.0, 2.0, 3.0, 0.0, 0.0, 0.0, 1.0, 9.0, 7.0, 0.0, 3.0, 0.0, 2.0, 0.0, 0.0, 7.0, 5.0, 12.0, 10.0, 6.0, 11.0, 7.0, 11.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 9.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 7.0, 3.0, 0.0, 10.0, 7.0, 8.0, 0.0, 0.0, 0.0, 6.0, 7.0, 15.0, 2.0, 0.0, 0.0, 4.0, 0.0, 7.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 12.0, 7.0, 8.0, 10.0, 0.0, 0.0, 9.0, 0.0, 1.0, 0.0, 7.0, 0.0, 4.0, 5.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 9.0, 8.0, 0.0, 0.0, 0.0, 6.0, 0.0, 7.0, 6.0, 0.0, 13.0, 0.0, 0.0, 4.0, 5.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 5.0, 0.0, 3.0, 3.0, 0.0, 0.0, 9.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 2.0, 8.0, 7.0, 5.0, 0.0, 2.0, 0.0, 0.0, 6.0, 9.0, 0.0, 2.0, 16.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 5.0, 1.0, 0.0, 2.0, 8.0, 0.0, 10.0, 5.0, 5.0, 0.0, 0.0, 4.0, 0.0, 16.0, 3.0, 3.0, 4.0, 0.0, 11.0, 6.0, 0.0, 11.0, 7.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 9.402597190013374, "mean_inference_ms": 23.179376178582093, "mean_action_processing_ms": 4.537526663084866, "mean_env_wait_ms": 5.6039183929394945, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004268050193786621, "StateBufferConnector_ms": 0.0036972761154174805, "ViewRequirementAgentConnector_ms": 0.1911311149597168}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": 346.4, "episode_return_mean": 378.65, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 3168000, "num_agent_steps_trained": 3168000, "num_env_steps_sampled": 792000, "num_env_steps_trained": 792000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 311.8834446509471, "num_env_steps_trained_throughput_per_sec": 311.8834446509471, "timesteps_total": 792000, "num_env_steps_sampled_lifetime": 792000, "num_agent_steps_sampled_lifetime": 3168000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 3168000, "timers": {"training_iteration_time_ms": 12743.489, "restore_workers_time_ms": 0.054, "training_step_time_ms": 12743.371, "sample_time_ms": 1801.629, "learn_time_ms": 10913.098, "learn_throughput": 366.532, "synch_weights_time_ms": 22.748}, "counters": {"num_env_steps_sampled": 792000, "num_env_steps_trained": 792000, "num_agent_steps_sampled": 3168000, "num_agent_steps_trained": 3168000}, "done": false, "training_iteration": 198, "trial_id": "75ec3_00000", "date": "2024-08-13_06-15-21", "timestamp": 1723544121, "time_this_iter_s": 12.930306911468506, "time_total_s": 16866.268203258514, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b258c790>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 16866.268203258514, "iterations_since_restore": 198, "perf": {"cpu_util_percent": 44.44444444444444, "ram_util_percent": 83.20555555555556}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3167481858421255, "cur_kl_coeff": 0.03250987739272802, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.21387289954206498, "policy_loss": -0.00376754854276047, "vf_loss": 0.2173849605610249, "vf_explained_var": 0.3086221038349091, "kl": 0.007858759666116003, "entropy": 1.090671385848333, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 375165.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.2362172403722686, "cur_kl_coeff": 3.6846652880703503e-28, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.1009256807614177, "policy_loss": -0.0007131913903529051, "vf_loss": 0.1016388724240839, "vf_explained_var": -0.042316541879896134, "kl": 0.01485088955195744, "entropy": 0.9723792014929352, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 375165.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 796000, "num_env_steps_trained": 796000, "num_agent_steps_sampled": 3184000, "num_agent_steps_trained": 3184000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": 321.29999999999995, "episode_reward_mean": 379.6079999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 119.30000000000001, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 19.0}, "policy_reward_mean": {"prey_policy": 187.09399999999997, "predator_policy": 2.71}, "custom_metrics": {}, "hist_stats": {"episode_reward": [400.0, 392.8, 369.9, 376.6, 379.3, 377.3, 389.2, 382.9, 392.8, 400.0, 381.1, 386.0, 387.7, 380.1, 352.50000000000006, 390.1, 369.8, 354.9, 379.3, 371.3, 366.9, 381.1, 389.7, 398.2, 352.0, 367.0, 377.3, 353.20000000000005, 397.1, 374.3, 389.0, 384.59999999999997, 390.1, 367.3, 379.3, 381.3, 390.1, 371.8, 360.5, 346.4, 385.6, 359.5, 392.8, 396.4, 388.0, 372.1, 367.9, 400.0, 386.5, 375.4, 363.9, 374.5, 384.7, 373.3, 360.59999999999997, 386.5, 384.7, 387.4, 372.9, 382.6, 388.2, 393.3, 371.8, 375.7, 359.2, 375.9, 400.0, 400.0, 387.4, 392.4, 376.5, 389.0, 372.2, 380.0, 383.3, 382.0, 372.2, 347.6, 393.20000000000005, 377.1, 379.9, 377.8, 382.4, 386.0, 321.29999999999995, 372.5, 387.4, 396.4, 376.1, 380.4, 400.0, 386.7, 400.0, 391.9, 395.5, 360.3, 358.2, 385.6, 384.7, 394.6], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [200.0, 200.0, 192.8, 200.0, 193.1, 165.8, 183.8, 192.8, 186.5, 192.8, 179.3, 197.0, 197.3, 191.9, 182.9, 200.0, 195.5, 197.3, 200.0, 200.0, 173.0, 199.1, 200.0, 179.0, 194.6, 190.1, 194.0, 169.1, 171.5, 173.0, 195.5, 194.6, 193.7, 163.1, 158.9, 179.0, 186.5, 192.8, 188.0, 179.3, 168.2, 190.7, 190.1, 191.0, 195.5, 192.2, 198.2, 200.0, 173.0, 167.0, 188.6, 163.4, 200.0, 167.3, 170.3, 173.9, 196.1, 200.0, 191.0, 176.3, 197.0, 188.0, 185.0, 194.60000000000002, 190.1, 200.0, 183.8, 177.5, 200.0, 170.3, 174.2, 199.1, 190.1, 200.0, 186.2, 179.6, 165.5, 182.0, 167.3, 166.1, 185.6, 200.0, 185.0, 165.5, 200.0, 192.8, 196.4, 200.0, 200.0, 182.0, 184.7, 187.4, 164.0, 191.9, 200.0, 200.0, 194.6, 191.9, 179.3, 190.1, 188.3, 170.6, 191.0, 177.5, 186.5, 198.2, 170.3, 194.0, 182.0, 170.60000000000002, 191.9, 194.6, 200.0, 184.7, 196.4, 191.0, 181.4, 186.5, 200.0, 167.6, 198.2, 185.0, 200.0, 191.3, 191.0, 174.8, 166.7, 200.0, 174.2, 167.0, 194.6, 173.3, 200.0, 200.0, 200.0, 200.0, 200.0, 187.4, 197.3, 193.1, 189.2, 182.3, 193.7, 194.3, 190.1, 172.1, 200.0, 170.0, 181.4, 191.9, 194.6, 187.4, 187.4, 180.8, 161.6, 167.0, 187.1, 199.1, 167.0, 199.1, 192.8, 181.1, 167.0, 192.8, 196.4, 179.0, 200.0, 179.0, 173.0, 119.30000000000001, 194.6, 170.9, 193.7, 193.7, 196.4, 200.0, 190.7, 178.4, 176.0, 196.4, 200.0, 200.0, 188.0, 193.7, 200.0, 200.0, 197.3, 194.6, 195.5, 200.0, 176.0, 173.3, 167.0, 180.2, 185.6, 200.0, 191.9, 192.8, 200.0, 194.6], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 0.0, 2.0, 9.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 7.0, 3.0, 0.0, 10.0, 7.0, 8.0, 0.0, 0.0, 0.0, 6.0, 7.0, 15.0, 2.0, 0.0, 0.0, 4.0, 0.0, 7.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 12.0, 7.0, 8.0, 10.0, 0.0, 0.0, 9.0, 0.0, 1.0, 0.0, 7.0, 0.0, 4.0, 5.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 9.0, 8.0, 0.0, 0.0, 0.0, 6.0, 0.0, 7.0, 6.0, 0.0, 13.0, 0.0, 0.0, 4.0, 5.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 5.0, 0.0, 3.0, 3.0, 0.0, 0.0, 9.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 2.0, 8.0, 7.0, 5.0, 0.0, 2.0, 0.0, 0.0, 6.0, 9.0, 0.0, 2.0, 16.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 5.0, 1.0, 0.0, 2.0, 8.0, 0.0, 10.0, 5.0, 5.0, 0.0, 0.0, 4.0, 0.0, 16.0, 3.0, 3.0, 4.0, 0.0, 11.0, 6.0, 0.0, 11.0, 7.0, 0.0, 7.0, 7.0, 0.0, 19.0, 10.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 8.0, 0.0, 0.0, 4.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 9.363511035480633, "mean_inference_ms": 23.085294039316327, "mean_action_processing_ms": 4.518146027980099, "mean_env_wait_ms": 5.579483912933064, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00450587272644043, "StateBufferConnector_ms": 0.008652210235595703, "ViewRequirementAgentConnector_ms": 0.20397794246673584}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": 321.29999999999995, "episode_return_mean": 379.6079999999999, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 3184000, "num_agent_steps_trained": 3184000, "num_env_steps_sampled": 796000, "num_env_steps_trained": 796000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 356.69546202555085, "num_env_steps_trained_throughput_per_sec": 356.69546202555085, "timesteps_total": 796000, "num_env_steps_sampled_lifetime": 796000, "num_agent_steps_sampled_lifetime": 3184000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 3184000, "timers": {"training_iteration_time_ms": 12550.42, "restore_workers_time_ms": 0.04, "training_step_time_ms": 12550.319, "sample_time_ms": 1851.873, "learn_time_ms": 10670.89, "learn_throughput": 374.852, "synch_weights_time_ms": 21.887}, "counters": {"num_env_steps_sampled": 796000, "num_env_steps_trained": 796000, "num_agent_steps_sampled": 3184000, "num_agent_steps_trained": 3184000}, "done": false, "training_iteration": 199, "trial_id": "75ec3_00000", "date": "2024-08-13_06-15-32", "timestamp": 1723544132, "time_this_iter_s": 11.219255208969116, "time_total_s": 16877.487458467484, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b22b3670>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 16877.487458467484, "iterations_since_restore": 199, "perf": {"cpu_util_percent": 37.34375, "ram_util_percent": 78.3375}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.480685679543586, "cur_kl_coeff": 0.03250987739272802, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.30032983407416386, "policy_loss": -0.001972184248303098, "vf_loss": 0.30198680961097435, "vf_explained_var": 0.4040536964065814, "kl": 0.009695770491605549, "entropy": 1.1575041535670165, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 377055.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.28054781956056124, "cur_kl_coeff": 3.6846652880703503e-28, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.12991567496900205, "policy_loss": -0.0012217235004913713, "vf_loss": 0.1311373984195742, "vf_explained_var": -0.018196364275362125, "kl": 0.01603942850746058, "entropy": 0.9901247435776644, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 377055.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 800000, "num_env_steps_trained": 800000, "num_agent_steps_sampled": 3200000, "num_agent_steps_trained": 3200000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": 321.29999999999995, "episode_reward_mean": 379.63700000000006, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": 119.30000000000001, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 19.0}, "policy_reward_mean": {"prey_policy": 187.18849999999998, "predator_policy": 2.63}, "custom_metrics": {}, "hist_stats": {"episode_reward": [353.20000000000005, 397.1, 374.3, 389.0, 384.59999999999997, 390.1, 367.3, 379.3, 381.3, 390.1, 371.8, 360.5, 346.4, 385.6, 359.5, 392.8, 396.4, 388.0, 372.1, 367.9, 400.0, 386.5, 375.4, 363.9, 374.5, 384.7, 373.3, 360.59999999999997, 386.5, 384.7, 387.4, 372.9, 382.6, 388.2, 393.3, 371.8, 375.7, 359.2, 375.9, 400.0, 400.0, 387.4, 392.4, 376.5, 389.0, 372.2, 380.0, 383.3, 382.0, 372.2, 347.6, 393.20000000000005, 377.1, 379.9, 377.8, 382.4, 386.0, 321.29999999999995, 372.5, 387.4, 396.4, 376.1, 380.4, 400.0, 386.7, 400.0, 391.9, 395.5, 360.3, 358.2, 385.6, 384.7, 394.6, 398.0, 366.0, 371.2, 382.9, 400.0, 400.0, 391.0, 390.1, 358.2, 367.9, 384.7, 386.5, 377.5, 358.6, 374.3, 391.0, 342.1, 389.0, 392.8, 372.9, 363.1, 385.5, 378.2, 394.3, 359.8, 395.1, 378.0], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [170.3, 173.9, 196.1, 200.0, 191.0, 176.3, 197.0, 188.0, 185.0, 194.60000000000002, 190.1, 200.0, 183.8, 177.5, 200.0, 170.3, 174.2, 199.1, 190.1, 200.0, 186.2, 179.6, 165.5, 182.0, 167.3, 166.1, 185.6, 200.0, 185.0, 165.5, 200.0, 192.8, 196.4, 200.0, 200.0, 182.0, 184.7, 187.4, 164.0, 191.9, 200.0, 200.0, 194.6, 191.9, 179.3, 190.1, 188.3, 170.6, 191.0, 177.5, 186.5, 198.2, 170.3, 194.0, 182.0, 170.60000000000002, 191.9, 194.6, 200.0, 184.7, 196.4, 191.0, 181.4, 186.5, 200.0, 167.6, 198.2, 185.0, 200.0, 191.3, 191.0, 174.8, 166.7, 200.0, 174.2, 167.0, 194.6, 173.3, 200.0, 200.0, 200.0, 200.0, 200.0, 187.4, 197.3, 193.1, 189.2, 182.3, 193.7, 194.3, 190.1, 172.1, 200.0, 170.0, 181.4, 191.9, 194.6, 187.4, 187.4, 180.8, 161.6, 167.0, 187.1, 199.1, 167.0, 199.1, 192.8, 181.1, 167.0, 192.8, 196.4, 179.0, 200.0, 179.0, 173.0, 119.30000000000001, 194.6, 170.9, 193.7, 193.7, 196.4, 200.0, 190.7, 178.4, 176.0, 196.4, 200.0, 200.0, 188.0, 193.7, 200.0, 200.0, 197.3, 194.6, 195.5, 200.0, 176.0, 173.3, 167.0, 180.2, 185.6, 200.0, 191.9, 192.8, 200.0, 194.6, 200.0, 197.0, 173.6, 184.4, 177.5, 193.7, 196.4, 186.5, 200.0, 200.0, 200.0, 200.0, 200.0, 191.0, 194.6, 195.5, 167.0, 180.2, 191.0, 173.9, 192.8, 191.9, 194.6, 191.9, 198.2, 170.3, 183.8, 165.8, 188.3, 179.0, 191.0, 200.0, 175.1, 149.0, 188.0, 200.0, 198.2, 194.6, 191.0, 176.9, 178.4, 184.7, 195.5, 185.0, 166.4, 192.8, 189.2, 199.1, 182.0, 165.8, 200.0, 193.1, 188.0, 185.0], "policy_predator_policy_reward": [0.0, 9.0, 0.0, 1.0, 0.0, 7.0, 0.0, 4.0, 5.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 9.0, 8.0, 0.0, 0.0, 0.0, 6.0, 0.0, 7.0, 6.0, 0.0, 13.0, 0.0, 0.0, 4.0, 5.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 5.0, 0.0, 3.0, 3.0, 0.0, 0.0, 9.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 2.0, 8.0, 7.0, 5.0, 0.0, 2.0, 0.0, 0.0, 6.0, 9.0, 0.0, 2.0, 16.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 5.0, 1.0, 0.0, 2.0, 8.0, 0.0, 10.0, 5.0, 5.0, 0.0, 0.0, 4.0, 0.0, 16.0, 3.0, 3.0, 4.0, 0.0, 11.0, 6.0, 0.0, 11.0, 7.0, 0.0, 7.0, 7.0, 0.0, 19.0, 10.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 8.0, 0.0, 0.0, 4.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 9.0, 7.0, 0.0, 0.0, 0.0, 12.0, 6.0, 1.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 5.0, 10.0, 9.0, 3.0, 3.0, 0.0, 12.0, 0.0, 2.0, 5.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 9.078882822633512, "mean_inference_ms": 23.29800545019918, "mean_action_processing_ms": 4.721576572112377, "mean_env_wait_ms": 5.203467787133847, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004261016845703125, "StateBufferConnector_ms": 0.008247733116149902, "ViewRequirementAgentConnector_ms": 0.19050991535186768}, "num_episodes": 27, "episode_return_max": 400.0, "episode_return_min": 321.29999999999995, "episode_return_mean": 379.63700000000006, "episodes_this_iter": 27}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 3200000, "num_agent_steps_trained": 3200000, "num_env_steps_sampled": 800000, "num_env_steps_trained": 800000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 398.6763933551051, "num_env_steps_trained_throughput_per_sec": 398.6763933551051, "timesteps_total": 800000, "num_env_steps_sampled_lifetime": 800000, "num_agent_steps_sampled_lifetime": 3200000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 3200000, "timers": {"training_iteration_time_ms": 12241.867, "restore_workers_time_ms": 0.04, "training_step_time_ms": 12241.767, "sample_time_ms": 1806.376, "learn_time_ms": 10408.917, "learn_throughput": 384.286, "synch_weights_time_ms": 21.339}, "counters": {"num_env_steps_sampled": 800000, "num_env_steps_trained": 800000, "num_agent_steps_sampled": 3200000, "num_agent_steps_trained": 3200000}, "done": true, "training_iteration": 200, "trial_id": "75ec3_00000", "date": "2024-08-13_06-15-42", "timestamp": 1723544142, "time_this_iter_s": 10.037848949432373, "time_total_s": 16887.525307416916, "pid": 27429, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2634f70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 16887.525307416916, "iterations_since_restore": 200, "perf": {"cpu_util_percent": 26.157142857142855, "ram_util_percent": 77.92857142857143}}
