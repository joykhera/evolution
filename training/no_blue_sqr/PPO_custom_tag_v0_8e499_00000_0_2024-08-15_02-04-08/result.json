{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9108780651023148, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.369393393350026, "policy_loss": -0.0041317747729687545, "vf_loss": 6.372176107275423, "vf_explained_var": -0.0020533127759499526, "kl": 0.0067452880376639955, "entropy": 1.6029391410489562, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 945.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5534114062391892, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.784100073102921, "policy_loss": -0.005095335817279875, "vf_loss": 5.7882479730737275, "vf_explained_var": -0.000721822529242783, "kl": 0.00473713425275679, "entropy": 1.6047751769817695, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 945.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 4000, "num_env_steps_trained": 4000, "num_agent_steps_sampled": 16000, "num_agent_steps_trained": 16000}, "env_runners": {"episode_reward_max": -26.299999999999503, "episode_reward_min": -236.46000000000012, "episode_reward_mean": -98.02444444444393, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 3600, "policy_reward_min": {"prey_policy": -469.95, "predator_policy": 3.0}, "policy_reward_max": {"prey_policy": 2.0000000000000013, "predator_policy": 275.0}, "policy_reward_mean": {"prey_policy": -121.4844444444446, "predator_policy": 72.47222222222223}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-122.75999999999961, -123.94999999999953, -76.80999999999953, -102.04999999999856, -69.20999999999968, -26.299999999999503, -88.91999999999867, -103.4599999999999, -177.95000000000016, -61.91999999999977, -77.80999999999916, -54.7599999999998, -100.0499999999992, -37.82000000000023, -114.16999999999938, -120.30999999999867, -236.46000000000012, -69.72999999999928], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-32.17000000000008, -373.5900000000004, 2.0000000000000013, -469.95, -8.050000000000042, -150.76000000000042, -54.28000000000034, -152.77000000000095, -241.2100000000006, 2.0000000000000013, -4.030000000000013, -52.270000000000294, -38.20000000000025, -142.7200000000011, -291.4600000000003, 2.0000000000000013, -301.51000000000033, -86.4400000000002, -170.85999999999947, -10.06000000000003, -130.66000000000042, -28.14999999999971, -32.169999999999966, -116.58999999999928, -16.089999999999705, -190.96000000000038, -154.78000000000108, -6.04000000000004, -8.050000000000042, -223.12000000000037, -190.96000000000092, -68.34999999999916, -241.21000000000015, -249.25000000000014, -122.61999999999969, -20.109999999999722], "policy_predator_policy_reward": [67.0, 216.0, 275.0, 69.0, 5.0, 77.0, 30.0, 75.0, 99.0, 71.0, 27.0, 3.0, 20.0, 72.0, 111.0, 75.0, 64.0, 146.0, 31.0, 88.0, 16.0, 65.0, 35.0, 59.0, 70.0, 37.0, 65.0, 58.0, 112.0, 5.0, 38.0, 101.0, 145.0, 109.0, 62.0, 11.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.627688665148637, "mean_inference_ms": 1.828476964920524, "mean_action_processing_ms": 0.27110810626162646, "mean_env_wait_ms": 0.20477495757657196, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005702839957343208, "StateBufferConnector_ms": 0.0032676590813530814, "ViewRequirementAgentConnector_ms": 0.08577638202243382}, "num_episodes": 18, "episode_return_max": -26.299999999999503, "episode_return_min": -236.46000000000012, "episode_return_mean": -98.02444444444393, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 16000, "num_agent_steps_trained": 16000, "num_env_steps_sampled": 4000, "num_env_steps_trained": 4000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 366.7622498096422, "num_env_steps_trained_throughput_per_sec": 366.7622498096422, "timesteps_total": 4000, "num_env_steps_sampled_lifetime": 4000, "num_agent_steps_sampled_lifetime": 16000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 16000, "timers": {"training_iteration_time_ms": 10906.274, "restore_workers_time_ms": 0.019, "training_step_time_ms": 10906.135, "sample_time_ms": 1424.357, "learn_time_ms": 9463.48, "learn_throughput": 422.677, "synch_weights_time_ms": 14.635}, "counters": {"num_env_steps_sampled": 4000, "num_env_steps_trained": 4000, "num_agent_steps_sampled": 16000, "num_agent_steps_trained": 16000}, "done": false, "training_iteration": 1, "trial_id": "8e499_00000", "date": "2024-08-15_02-04-27", "timestamp": 1723667667, "time_this_iter_s": 10.940398216247559, "time_total_s": 10.940398216247559, "pid": 33199, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b43b2790>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 10.940398216247559, "iterations_since_restore": 1, "perf": {"cpu_util_percent": 31.60625, "ram_util_percent": 83.51875000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9255263101881144, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.015075857929451, "policy_loss": -0.004095428326122818, "vf_loss": 5.018612772951681, "vf_explained_var": -0.0014669162255746347, "kl": 0.002792610854000617, "entropy": 1.6024971195629665, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 2835.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5942366800847507, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.523130172396463, "policy_loss": -0.009865920872195925, "vf_loss": 5.531666580583684, "vf_explained_var": 0.0013957118546521223, "kl": 0.0132952138527367, "entropy": 1.584565848585159, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 2835.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 8000, "num_env_steps_trained": 8000, "num_agent_steps_sampled": 32000, "num_agent_steps_trained": 32000}, "env_runners": {"episode_reward_max": 2.9599999999999818, "episode_reward_min": -236.46000000000012, "episode_reward_mean": -100.03055555555534, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 7200, "policy_reward_min": {"prey_policy": -469.95, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 2.0000000000000013, "predator_policy": 275.0}, "policy_reward_mean": {"prey_policy": -115.51527777777788, "predator_policy": 65.5}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-122.75999999999961, -123.94999999999953, -76.80999999999953, -102.04999999999856, -69.20999999999968, -26.299999999999503, -88.91999999999867, -103.4599999999999, -177.95000000000016, -61.91999999999977, -77.80999999999916, -54.7599999999998, -100.0499999999992, -37.82000000000023, -114.16999999999938, -120.30999999999867, -236.46000000000012, -69.72999999999928, -133.36999999999875, -225.89000000000078, -50.540000000000624, -61.65000000000057, 2.9599999999999818, -157.2800000000002, -160.76999999999975, 0.8399999999999844, -162.68000000000126, -127.16999999999942, -93.00999999999867, -87.15999999999917, -147.40000000000038, -43.470000000000674, -209.1500000000011, -161.64000000000073, 0.9700000000000027, -20.24999999999946], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-32.17000000000008, -373.5900000000004, 2.0000000000000013, -469.95, -8.050000000000042, -150.76000000000042, -54.28000000000034, -152.77000000000095, -241.2100000000006, 2.0000000000000013, -4.030000000000013, -52.270000000000294, -38.20000000000025, -142.7200000000011, -291.4600000000003, 2.0000000000000013, -301.51000000000033, -86.4400000000002, -170.85999999999947, -10.06000000000003, -130.66000000000042, -28.14999999999971, -32.169999999999966, -116.58999999999928, -16.089999999999705, -190.96000000000038, -154.78000000000108, -6.04000000000004, -8.050000000000042, -223.12000000000037, -190.96000000000092, -68.34999999999916, -241.21000000000015, -249.25000000000014, -122.61999999999969, -20.109999999999722, -118.59999999999928, -152.77000000000072, -154.77999999999977, -221.1100000000004, -70.3599999999992, -34.18000000000031, -112.5699999999993, -14.080000000000041, 2.0000000000000013, -6.040000000000042, -82.41999999999994, -170.86000000000016, -199.00000000000037, -152.7699999999994, 2.0000000000000013, -30.159999999999712, -255.20000000000056, -94.47999999999927, -379.82000000000016, -68.35000000000014, -60.310000000000336, -138.70000000000036, 2.0000000000000013, -231.1600000000007, -100.50999999999989, -176.89000000000064, -58.30000000000033, -32.170000000000115, -219.01999999999956, -241.13000000000068, -56.29000000000006, -269.3500000000006, -0.00999999999999836, -2.0200000000000116, -14.080000000000041, -32.17000000000031], "policy_predator_policy_reward": [67.0, 216.0, 275.0, 69.0, 5.0, 77.0, 30.0, 75.0, 99.0, 71.0, 27.0, 3.0, 20.0, 72.0, 111.0, 75.0, 64.0, 146.0, 31.0, 88.0, 16.0, 65.0, 35.0, 59.0, 70.0, 37.0, 65.0, 58.0, 112.0, 5.0, 38.0, 101.0, 145.0, 109.0, 62.0, 11.0, 61.0, 77.0, 26.0, 124.0, 36.0, 18.0, 57.0, 8.0, 3.0, 4.0, 88.0, 8.0, 108.0, 83.0, 13.0, 16.0, 137.0, 50.0, 168.0, 153.0, 55.0, 51.0, 26.0, 116.0, 59.0, 71.0, 30.0, 17.0, 120.0, 131.0, 29.0, 135.0, 3.0, 0.0, 10.0, 16.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6163021886735862, "mean_inference_ms": 1.8274126263119972, "mean_action_processing_ms": 0.2628657819560428, "mean_env_wait_ms": 0.20548291022514062, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006746252377827962, "StateBufferConnector_ms": 0.00328520933787028, "ViewRequirementAgentConnector_ms": 0.09838442007700603}, "num_episodes": 18, "episode_return_max": 2.9599999999999818, "episode_return_min": -236.46000000000012, "episode_return_mean": -100.03055555555534, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 32000, "num_agent_steps_trained": 32000, "num_env_steps_sampled": 8000, "num_env_steps_trained": 8000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 384.32739608564253, "num_env_steps_trained_throughput_per_sec": 384.32739608564253, "timesteps_total": 8000, "num_env_steps_sampled_lifetime": 8000, "num_agent_steps_sampled_lifetime": 32000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 32000, "timers": {"training_iteration_time_ms": 10657.04, "restore_workers_time_ms": 0.028, "training_step_time_ms": 10656.934, "sample_time_ms": 1408.861, "learn_time_ms": 9231.19, "learn_throughput": 433.314, "synch_weights_time_ms": 14.297}, "counters": {"num_env_steps_sampled": 8000, "num_env_steps_trained": 8000, "num_agent_steps_sampled": 32000, "num_agent_steps_trained": 32000}, "done": false, "training_iteration": 2, "trial_id": "8e499_00000", "date": "2024-08-15_02-04-40", "timestamp": 1723667680, "time_this_iter_s": 10.451997995376587, "time_total_s": 21.392396211624146, "pid": 33199, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b4323e50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 21.392396211624146, "iterations_since_restore": 2, "perf": {"cpu_util_percent": 28.738888888888887, "ram_util_percent": 83.49444444444444}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8928516837812606, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.7702391860346314, "policy_loss": -0.011426182593731456, "vf_loss": 3.7797630393315877, "vf_explained_var": 0.004793420292082287, "kl": 0.019023289982550085, "entropy": 1.578505221182707, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 4725.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6350565547507907, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.532001031517352, "policy_loss": -0.00678017247657947, "vf_loss": 4.537720094156013, "vf_explained_var": 0.00017965694583913007, "kl": 0.010611231872913626, "entropy": 1.5476567219804835, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 4725.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 12000, "num_env_steps_trained": 12000, "num_agent_steps_sampled": 48000, "num_agent_steps_trained": 48000}, "env_runners": {"episode_reward_max": 2.9599999999999818, "episode_reward_min": -303.3600000000009, "episode_reward_mean": -97.97999999999986, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 10800, "policy_reward_min": {"prey_policy": -469.95, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 2.0000000000000013, "predator_policy": 275.0}, "policy_reward_mean": {"prey_policy": -107.64740740740747, "predator_policy": 58.657407407407405}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-122.75999999999961, -123.94999999999953, -76.80999999999953, -102.04999999999856, -69.20999999999968, -26.299999999999503, -88.91999999999867, -103.4599999999999, -177.95000000000016, -61.91999999999977, -77.80999999999916, -54.7599999999998, -100.0499999999992, -37.82000000000023, -114.16999999999938, -120.30999999999867, -236.46000000000012, -69.72999999999928, -133.36999999999875, -225.89000000000078, -50.540000000000624, -61.65000000000057, 2.9599999999999818, -157.2800000000002, -160.76999999999975, 0.8399999999999844, -162.68000000000126, -127.16999999999942, -93.00999999999867, -87.15999999999917, -147.40000000000038, -43.470000000000674, -209.1500000000011, -161.64000000000073, 0.9700000000000027, -20.24999999999946, -21.319999999999997, -44.480000000000615, -120.22999999999917, -151.45000000000007, -172.75000000000136, -93.64999999999829, -41.45000000000047, -71.59999999999935, -178.56000000000054, -303.3600000000009, -88.94999999999987, -39.82000000000038, -39.43000000000062, -3.340000000000078, -159.6200000000013, -11.260000000000078, -67.70999999999914, -80.83999999999953], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-32.17000000000008, -373.5900000000004, 2.0000000000000013, -469.95, -8.050000000000042, -150.76000000000042, -54.28000000000034, -152.77000000000095, -241.2100000000006, 2.0000000000000013, -4.030000000000013, -52.270000000000294, -38.20000000000025, -142.7200000000011, -291.4600000000003, 2.0000000000000013, -301.51000000000033, -86.4400000000002, -170.85999999999947, -10.06000000000003, -130.66000000000042, -28.14999999999971, -32.169999999999966, -116.58999999999928, -16.089999999999705, -190.96000000000038, -154.78000000000108, -6.04000000000004, -8.050000000000042, -223.12000000000037, -190.96000000000092, -68.34999999999916, -241.21000000000015, -249.25000000000014, -122.61999999999969, -20.109999999999722, -118.59999999999928, -152.77000000000072, -154.77999999999977, -221.1100000000004, -70.3599999999992, -34.18000000000031, -112.5699999999993, -14.080000000000041, 2.0000000000000013, -6.040000000000042, -82.41999999999994, -170.86000000000016, -199.00000000000037, -152.7699999999994, 2.0000000000000013, -30.159999999999712, -255.20000000000056, -94.47999999999927, -379.82000000000016, -68.35000000000014, -60.310000000000336, -138.70000000000036, 2.0000000000000013, -231.1600000000007, -100.50999999999989, -176.89000000000064, -58.30000000000033, -32.170000000000115, -219.01999999999956, -241.13000000000068, -56.29000000000006, -269.3500000000006, -0.00999999999999836, -2.0200000000000116, -14.080000000000041, -32.17000000000031, -30.159999999999716, -30.15999999999997, -94.47999999999922, 2.0000000000000013, -50.26000000000016, -192.9700000000006, -180.90999999999974, -106.54000000000016, -209.05000000000075, -138.6999999999999, -62.320000000000334, -64.32999999999915, -88.44999999999936, 2.0000000000000013, -32.17000000000008, -84.43000000000018, -194.97999999999993, -114.57999999999927, -273.37000000000046, -196.99000000000052, -148.74999999999991, -38.20000000000036, -162.82000000000093, 2.0000000000000013, -18.099999999999703, -64.32999999999922, 2.0000000000000013, -66.33999999999915, -118.59999999999944, -203.02000000000064, -50.26000000000034, 2.0000000000000013, -76.38999999999918, -62.32000000000027, -62.320000000000334, -102.51999999999991], "policy_predator_policy_reward": [67.0, 216.0, 275.0, 69.0, 5.0, 77.0, 30.0, 75.0, 99.0, 71.0, 27.0, 3.0, 20.0, 72.0, 111.0, 75.0, 64.0, 146.0, 31.0, 88.0, 16.0, 65.0, 35.0, 59.0, 70.0, 37.0, 65.0, 58.0, 112.0, 5.0, 38.0, 101.0, 145.0, 109.0, 62.0, 11.0, 61.0, 77.0, 26.0, 124.0, 36.0, 18.0, 57.0, 8.0, 3.0, 4.0, 88.0, 8.0, 108.0, 83.0, 13.0, 16.0, 137.0, 50.0, 168.0, 153.0, 55.0, 51.0, 26.0, 116.0, 59.0, 71.0, 30.0, 17.0, 120.0, 131.0, 29.0, 135.0, 3.0, 0.0, 10.0, 16.0, 28.0, 11.0, 48.0, 0.0, 97.0, 26.0, 32.0, 104.0, 123.0, 52.0, 33.0, 0.0, 45.0, 0.0, 43.0, 2.0, 106.0, 25.0, 140.0, 27.0, 88.0, 10.0, 53.0, 68.0, 33.0, 10.0, 33.0, 28.0, 70.0, 92.0, 17.0, 20.0, 32.0, 39.0, 61.0, 23.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6164328596256405, "mean_inference_ms": 1.8662630260374968, "mean_action_processing_ms": 0.2618957724668785, "mean_env_wait_ms": 0.20975408610021268, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006909944393016674, "StateBufferConnector_ms": 0.0034389672455964267, "ViewRequirementAgentConnector_ms": 0.10043868312129269}, "num_episodes": 18, "episode_return_max": 2.9599999999999818, "episode_return_min": -303.3600000000009, "episode_return_mean": -97.97999999999986, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 48000, "num_agent_steps_trained": 48000, "num_env_steps_sampled": 12000, "num_env_steps_trained": 12000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 367.42500909845353, "num_env_steps_trained_throughput_per_sec": 367.42500909845353, "timesteps_total": 12000, "num_env_steps_sampled_lifetime": 12000, "num_agent_steps_sampled_lifetime": 48000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 48000, "timers": {"training_iteration_time_ms": 10733.554, "restore_workers_time_ms": 0.024, "training_step_time_ms": 10733.469, "sample_time_ms": 1463.096, "learn_time_ms": 9253.106, "learn_throughput": 432.287, "synch_weights_time_ms": 15.01}, "counters": {"num_env_steps_sampled": 12000, "num_env_steps_trained": 12000, "num_agent_steps_sampled": 48000, "num_agent_steps_trained": 48000}, "done": false, "training_iteration": 3, "trial_id": "8e499_00000", "date": "2024-08-15_02-04-51", "timestamp": 1723667691, "time_this_iter_s": 10.942004919052124, "time_total_s": 32.33440113067627, "pid": 33199, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b4323ee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 32.33440113067627, "iterations_since_restore": 3, "perf": {"cpu_util_percent": 31.099999999999998, "ram_util_percent": 83.39374999999998}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1110974969371916, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.5109927417109255, "policy_loss": -0.012330811419745995, "vf_loss": 5.521055013666708, "vf_explained_var": 0.003163015810900895, "kl": 0.022685254204593427, "entropy": 1.5425743690874212, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 6615.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7629178076430604, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.146917514952403, "policy_loss": -0.010208656918011092, "vf_loss": 6.155702958283601, "vf_explained_var": -0.0004191998136106622, "kl": 0.014232103049956773, "entropy": 1.5204163307866092, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 6615.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 16000, "num_env_steps_trained": 16000, "num_agent_steps_sampled": 64000, "num_agent_steps_trained": 64000}, "env_runners": {"episode_reward_max": 2.9599999999999818, "episode_reward_min": -447.5200000000003, "episode_reward_mean": -104.10041666666659, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 14400, "policy_reward_min": {"prey_policy": -469.95, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 2.0000000000000013, "predator_policy": 312.0}, "policy_reward_mean": {"prey_policy": -111.1474305555556, "predator_policy": 59.09722222222222}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-122.75999999999961, -123.94999999999953, -76.80999999999953, -102.04999999999856, -69.20999999999968, -26.299999999999503, -88.91999999999867, -103.4599999999999, -177.95000000000016, -61.91999999999977, -77.80999999999916, -54.7599999999998, -100.0499999999992, -37.82000000000023, -114.16999999999938, -120.30999999999867, -236.46000000000012, -69.72999999999928, -133.36999999999875, -225.89000000000078, -50.540000000000624, -61.65000000000057, 2.9599999999999818, -157.2800000000002, -160.76999999999975, 0.8399999999999844, -162.68000000000126, -127.16999999999942, -93.00999999999867, -87.15999999999917, -147.40000000000038, -43.470000000000674, -209.1500000000011, -161.64000000000073, 0.9700000000000027, -20.24999999999946, -21.319999999999997, -44.480000000000615, -120.22999999999917, -151.45000000000007, -172.75000000000136, -93.64999999999829, -41.45000000000047, -71.59999999999935, -178.56000000000054, -303.3600000000009, -88.94999999999987, -39.82000000000038, -39.43000000000062, -3.340000000000078, -159.6200000000013, -11.260000000000078, -67.70999999999914, -80.83999999999953, -48.52000000000069, -260.2200000000003, -19.229999999999524, -49.6800000000004, -65.69000000000032, -447.5200000000003, -7.230000000000079, -409.5000000000002, -108.13999999999919, -118.08999999999983, -155.66999999999945, -95.87999999999974, -83.21000000000008, -40.72000000000015, -81.84999999999916, -89.96999999999966, -116.0800000000004, -7.110000000000083], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-32.17000000000008, -373.5900000000004, 2.0000000000000013, -469.95, -8.050000000000042, -150.76000000000042, -54.28000000000034, -152.77000000000095, -241.2100000000006, 2.0000000000000013, -4.030000000000013, -52.270000000000294, -38.20000000000025, -142.7200000000011, -291.4600000000003, 2.0000000000000013, -301.51000000000033, -86.4400000000002, -170.85999999999947, -10.06000000000003, -130.66000000000042, -28.14999999999971, -32.169999999999966, -116.58999999999928, -16.089999999999705, -190.96000000000038, -154.78000000000108, -6.04000000000004, -8.050000000000042, -223.12000000000037, -190.96000000000092, -68.34999999999916, -241.21000000000015, -249.25000000000014, -122.61999999999969, -20.109999999999722, -118.59999999999928, -152.77000000000072, -154.77999999999977, -221.1100000000004, -70.3599999999992, -34.18000000000031, -112.5699999999993, -14.080000000000041, 2.0000000000000013, -6.040000000000042, -82.41999999999994, -170.86000000000016, -199.00000000000037, -152.7699999999994, 2.0000000000000013, -30.159999999999712, -255.20000000000056, -94.47999999999927, -379.82000000000016, -68.35000000000014, -60.310000000000336, -138.70000000000036, 2.0000000000000013, -231.1600000000007, -100.50999999999989, -176.89000000000064, -58.30000000000033, -32.170000000000115, -219.01999999999956, -241.13000000000068, -56.29000000000006, -269.3500000000006, -0.00999999999999836, -2.0200000000000116, -14.080000000000041, -32.17000000000031, -30.159999999999716, -30.15999999999997, -94.47999999999922, 2.0000000000000013, -50.26000000000016, -192.9700000000006, -180.90999999999974, -106.54000000000016, -209.05000000000075, -138.6999999999999, -62.320000000000334, -64.32999999999915, -88.44999999999936, 2.0000000000000013, -32.17000000000008, -84.43000000000018, -194.97999999999993, -114.57999999999927, -273.37000000000046, -196.99000000000052, -148.74999999999991, -38.20000000000036, -162.82000000000093, 2.0000000000000013, -18.099999999999703, -64.32999999999922, 2.0000000000000013, -66.33999999999915, -118.59999999999944, -203.02000000000064, -50.26000000000034, 2.0000000000000013, -76.38999999999918, -62.32000000000027, -62.320000000000334, -102.51999999999991, -56.29000000000034, -44.23000000000035, -239.20000000000027, -203.0200000000002, -44.23000000000029, 2.0000000000000013, 2.0000000000000013, -134.68000000000075, -84.4299999999993, -50.260000000000346, -319.60000000000025, -383.9200000000001, -44.230000000000345, 2.0000000000000013, -413.6700000000002, -397.83000000000004, -68.2299999999991, -180.91000000000054, -120.60999999999936, -94.47999999999972, -215.07999999999984, -116.58999999999932, -92.4699999999997, -80.40999999999987, -100.50999999999954, -138.70000000000005, -142.7200000000007, 2.0000000000000013, -10.06000000000003, -156.79000000000073, -140.6699999999998, -58.29999999999977, -116.58999999999979, -120.48999999999985, -4.030000000000042, -14.080000000000041], "policy_predator_policy_reward": [67.0, 216.0, 275.0, 69.0, 5.0, 77.0, 30.0, 75.0, 99.0, 71.0, 27.0, 3.0, 20.0, 72.0, 111.0, 75.0, 64.0, 146.0, 31.0, 88.0, 16.0, 65.0, 35.0, 59.0, 70.0, 37.0, 65.0, 58.0, 112.0, 5.0, 38.0, 101.0, 145.0, 109.0, 62.0, 11.0, 61.0, 77.0, 26.0, 124.0, 36.0, 18.0, 57.0, 8.0, 3.0, 4.0, 88.0, 8.0, 108.0, 83.0, 13.0, 16.0, 137.0, 50.0, 168.0, 153.0, 55.0, 51.0, 26.0, 116.0, 59.0, 71.0, 30.0, 17.0, 120.0, 131.0, 29.0, 135.0, 3.0, 0.0, 10.0, 16.0, 28.0, 11.0, 48.0, 0.0, 97.0, 26.0, 32.0, 104.0, 123.0, 52.0, 33.0, 0.0, 45.0, 0.0, 43.0, 2.0, 106.0, 25.0, 140.0, 27.0, 88.0, 10.0, 53.0, 68.0, 33.0, 10.0, 33.0, 28.0, 70.0, 92.0, 17.0, 20.0, 32.0, 39.0, 61.0, 23.0, 23.0, 29.0, 35.0, 147.0, 10.0, 13.0, 38.0, 45.0, 47.0, 22.0, 86.0, 170.0, 12.0, 23.0, 90.0, 312.0, 49.0, 92.0, 38.0, 59.0, 83.0, 93.0, 0.0, 77.0, 75.0, 81.0, 43.0, 57.0, 6.0, 79.0, 33.0, 76.0, 108.0, 13.0, 3.0, 8.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6134845915799588, "mean_inference_ms": 1.8813077329947459, "mean_action_processing_ms": 0.25958878383988826, "mean_env_wait_ms": 0.21071344394425107, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006613797611660427, "StateBufferConnector_ms": 0.003524952464633518, "ViewRequirementAgentConnector_ms": 0.09724381897184584}, "num_episodes": 18, "episode_return_max": 2.9599999999999818, "episode_return_min": -447.5200000000003, "episode_return_mean": -104.10041666666659, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 64000, "num_agent_steps_trained": 64000, "num_env_steps_sampled": 16000, "num_env_steps_trained": 16000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 371.13174190941226, "num_env_steps_trained_throughput_per_sec": 371.13174190941226, "timesteps_total": 16000, "num_env_steps_sampled_lifetime": 16000, "num_agent_steps_sampled_lifetime": 64000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 64000, "timers": {"training_iteration_time_ms": 10744.629, "restore_workers_time_ms": 0.022, "training_step_time_ms": 10744.554, "sample_time_ms": 1441.604, "learn_time_ms": 9285.126, "learn_throughput": 430.797, "synch_weights_time_ms": 15.66}, "counters": {"num_env_steps_sampled": 16000, "num_env_steps_trained": 16000, "num_agent_steps_sampled": 64000, "num_agent_steps_trained": 64000}, "done": false, "training_iteration": 4, "trial_id": "8e499_00000", "date": "2024-08-15_02-05-02", "timestamp": 1723667702, "time_this_iter_s": 10.833985090255737, "time_total_s": 43.16838622093201, "pid": 33199, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b43fa160>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 43.16838622093201, "iterations_since_restore": 4, "perf": {"cpu_util_percent": 31.466666666666665, "ram_util_percent": 83.31333333333335}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9042116545810901, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.047810404641288, "policy_loss": -0.015752398268881418, "vf_loss": 9.06052370323706, "vf_explained_var": 0.004274218423025948, "kl": 0.020260723766821705, "entropy": 1.5198887430170855, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 8505.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6135947154864433, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.395902900847178, "policy_loss": -0.00925774520728737, "vf_loss": 8.403860721386298, "vf_explained_var": 0.002769233751549292, "kl": 0.012999293304977053, "entropy": 1.5083412310433766, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 8505.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 20000, "num_env_steps_trained": 20000, "num_agent_steps_sampled": 80000, "num_agent_steps_trained": 80000}, "env_runners": {"episode_reward_max": 2.9599999999999818, "episode_reward_min": -447.5200000000003, "episode_reward_mean": -121.48656565656555, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 19800, "policy_reward_min": {"prey_policy": -557.95, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 2.0000000000000013, "predator_policy": 321.0}, "policy_reward_mean": {"prey_policy": -136.68772727272733, "predator_policy": 75.94444444444444}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-122.75999999999961, -123.94999999999953, -76.80999999999953, -102.04999999999856, -69.20999999999968, -26.299999999999503, -88.91999999999867, -103.4599999999999, -177.95000000000016, -61.91999999999977, -77.80999999999916, -54.7599999999998, -100.0499999999992, -37.82000000000023, -114.16999999999938, -120.30999999999867, -236.46000000000012, -69.72999999999928, -133.36999999999875, -225.89000000000078, -50.540000000000624, -61.65000000000057, 2.9599999999999818, -157.2800000000002, -160.76999999999975, 0.8399999999999844, -162.68000000000126, -127.16999999999942, -93.00999999999867, -87.15999999999917, -147.40000000000038, -43.470000000000674, -209.1500000000011, -161.64000000000073, 0.9700000000000027, -20.24999999999946, -21.319999999999997, -44.480000000000615, -120.22999999999917, -151.45000000000007, -172.75000000000136, -93.64999999999829, -41.45000000000047, -71.59999999999935, -178.56000000000054, -303.3600000000009, -88.94999999999987, -39.82000000000038, -39.43000000000062, -3.340000000000078, -159.6200000000013, -11.260000000000078, -67.70999999999914, -80.83999999999953, -48.52000000000069, -260.2200000000003, -19.229999999999524, -49.6800000000004, -65.69000000000032, -447.5200000000003, -7.230000000000079, -409.5000000000002, -108.13999999999919, -118.08999999999983, -155.66999999999945, -95.87999999999974, -83.21000000000008, -40.72000000000015, -81.84999999999916, -89.96999999999966, -116.0800000000004, -7.110000000000083, -242.0, -92.07999999999855, -37.50999999999991, -97.1099999999991, -163.6299999999998, -356.86000000000007, -53.71999999999968, -241.03000000000011, -143.89999999999958, 1.9200000000000021, -79.86999999999989, -178.9299999999995, -38.420000000000705, -289.08, -255.55000000000018, -44.83999999999989, -107.81999999999915, -341.1700000000002, -54.68000000000002, -407.84000000000003, -272.41000000000025, -36.33, -293.4, -37.46000000000019, -334.0000000000002, -211.56999999999954, -122.64999999999947], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-32.17000000000008, -373.5900000000004, 2.0000000000000013, -469.95, -8.050000000000042, -150.76000000000042, -54.28000000000034, -152.77000000000095, -241.2100000000006, 2.0000000000000013, -4.030000000000013, -52.270000000000294, -38.20000000000025, -142.7200000000011, -291.4600000000003, 2.0000000000000013, -301.51000000000033, -86.4400000000002, -170.85999999999947, -10.06000000000003, -130.66000000000042, -28.14999999999971, -32.169999999999966, -116.58999999999928, -16.089999999999705, -190.96000000000038, -154.78000000000108, -6.04000000000004, -8.050000000000042, -223.12000000000037, -190.96000000000092, -68.34999999999916, -241.21000000000015, -249.25000000000014, -122.61999999999969, -20.109999999999722, -118.59999999999928, -152.77000000000072, -154.77999999999977, -221.1100000000004, -70.3599999999992, -34.18000000000031, -112.5699999999993, -14.080000000000041, 2.0000000000000013, -6.040000000000042, -82.41999999999994, -170.86000000000016, -199.00000000000037, -152.7699999999994, 2.0000000000000013, -30.159999999999712, -255.20000000000056, -94.47999999999927, -379.82000000000016, -68.35000000000014, -60.310000000000336, -138.70000000000036, 2.0000000000000013, -231.1600000000007, -100.50999999999989, -176.89000000000064, -58.30000000000033, -32.170000000000115, -219.01999999999956, -241.13000000000068, -56.29000000000006, -269.3500000000006, -0.00999999999999836, -2.0200000000000116, -14.080000000000041, -32.17000000000031, -30.159999999999716, -30.15999999999997, -94.47999999999922, 2.0000000000000013, -50.26000000000016, -192.9700000000006, -180.90999999999974, -106.54000000000016, -209.05000000000075, -138.6999999999999, -62.320000000000334, -64.32999999999915, -88.44999999999936, 2.0000000000000013, -32.17000000000008, -84.43000000000018, -194.97999999999993, -114.57999999999927, -273.37000000000046, -196.99000000000052, -148.74999999999991, -38.20000000000036, -162.82000000000093, 2.0000000000000013, -18.099999999999703, -64.32999999999922, 2.0000000000000013, -66.33999999999915, -118.59999999999944, -203.02000000000064, -50.26000000000034, 2.0000000000000013, -76.38999999999918, -62.32000000000027, -62.320000000000334, -102.51999999999991, -56.29000000000034, -44.23000000000035, -239.20000000000027, -203.0200000000002, -44.23000000000029, 2.0000000000000013, 2.0000000000000013, -134.68000000000075, -84.4299999999993, -50.260000000000346, -319.60000000000025, -383.9200000000001, -44.230000000000345, 2.0000000000000013, -413.6700000000002, -397.83000000000004, -68.2299999999991, -180.91000000000054, -120.60999999999936, -94.47999999999972, -215.07999999999984, -116.58999999999932, -92.4699999999997, -80.40999999999987, -100.50999999999954, -138.70000000000005, -142.7200000000007, 2.0000000000000013, -10.06000000000003, -156.79000000000073, -140.6699999999998, -58.29999999999977, -116.58999999999979, -120.48999999999985, -4.030000000000042, -14.080000000000041, -287.4000000000002, -118.60000000000001, -84.43000000000032, -152.64999999999932, -10.060000000000041, -361.45000000000005, -186.78000000000063, -64.32999999999967, -138.69999999999982, -184.93000000000015, -385.8900000000001, -208.97000000000003, -22.119999999999997, -118.5999999999995, -215.08, -557.95, -343.4799999999999, -82.41999999999976, 2.0000000000000013, -14.080000000000041, -186.7800000000002, -16.0899999999997, -245.2299999999999, -146.6999999999997, -32.170000000000364, -48.25000000000035, -233.13000000000005, -429.95000000000005, -345.73, -162.81999999999996, -367.84000000000015, 2.0000000000000013, -90.45999999999921, -335.3599999999999, -305.5300000000001, -383.64000000000004, -26.139999999999997, -114.54000000000025, -473.97, -429.87, -184.93000000000004, -295.48000000000025, -50.26000000000005, -12.069999999999999, -279.4, -448.0, -339.46000000000004, 2.0000000000000013, -367.71999999999986, -295.28, -407.8800000000001, -136.6899999999999, -42.220000000000354, -293.43000000000006], "policy_predator_policy_reward": [67.0, 216.0, 275.0, 69.0, 5.0, 77.0, 30.0, 75.0, 99.0, 71.0, 27.0, 3.0, 20.0, 72.0, 111.0, 75.0, 64.0, 146.0, 31.0, 88.0, 16.0, 65.0, 35.0, 59.0, 70.0, 37.0, 65.0, 58.0, 112.0, 5.0, 38.0, 101.0, 145.0, 109.0, 62.0, 11.0, 61.0, 77.0, 26.0, 124.0, 36.0, 18.0, 57.0, 8.0, 3.0, 4.0, 88.0, 8.0, 108.0, 83.0, 13.0, 16.0, 137.0, 50.0, 168.0, 153.0, 55.0, 51.0, 26.0, 116.0, 59.0, 71.0, 30.0, 17.0, 120.0, 131.0, 29.0, 135.0, 3.0, 0.0, 10.0, 16.0, 28.0, 11.0, 48.0, 0.0, 97.0, 26.0, 32.0, 104.0, 123.0, 52.0, 33.0, 0.0, 45.0, 0.0, 43.0, 2.0, 106.0, 25.0, 140.0, 27.0, 88.0, 10.0, 53.0, 68.0, 33.0, 10.0, 33.0, 28.0, 70.0, 92.0, 17.0, 20.0, 32.0, 39.0, 61.0, 23.0, 23.0, 29.0, 35.0, 147.0, 10.0, 13.0, 38.0, 45.0, 47.0, 22.0, 86.0, 170.0, 12.0, 23.0, 90.0, 312.0, 49.0, 92.0, 38.0, 59.0, 83.0, 93.0, 0.0, 77.0, 75.0, 81.0, 43.0, 57.0, 6.0, 79.0, 33.0, 76.0, 108.0, 13.0, 3.0, 8.0, 5.0, 159.0, 84.0, 61.0, 125.0, 209.0, 73.0, 81.0, 45.0, 115.0, 16.0, 222.0, 40.0, 47.0, 211.0, 321.0, 169.0, 113.0, 6.0, 8.0, 95.0, 28.0, 111.0, 102.0, 25.0, 17.0, 233.0, 141.0, 162.0, 91.0, 151.0, 170.0, 139.0, 179.0, 187.0, 161.0, 63.0, 23.0, 200.0, 296.0, 159.0, 49.0, 26.0, 0.0, 193.0, 241.0, 190.0, 110.0, 137.0, 192.0, 151.0, 182.0, 111.0, 102.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6108199569173169, "mean_inference_ms": 1.8908009009663822, "mean_action_processing_ms": 0.25660937125380917, "mean_env_wait_ms": 0.21038531412801645, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006658621508665759, "StateBufferConnector_ms": 0.003371696279506491, "ViewRequirementAgentConnector_ms": 0.0950666389080009}, "num_episodes": 27, "episode_return_max": 2.9599999999999818, "episode_return_min": -447.5200000000003, "episode_return_mean": -121.48656565656555, "episodes_this_iter": 27}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 80000, "num_agent_steps_trained": 80000, "num_env_steps_sampled": 20000, "num_env_steps_trained": 20000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 390.4131295894972, "num_env_steps_trained_throughput_per_sec": 390.4131295894972, "timesteps_total": 20000, "num_env_steps_sampled_lifetime": 20000, "num_agent_steps_sampled_lifetime": 80000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 80000, "timers": {"training_iteration_time_ms": 10644.816, "restore_workers_time_ms": 0.021, "training_step_time_ms": 10644.748, "sample_time_ms": 1432.436, "learn_time_ms": 9195.369, "learn_throughput": 435.002, "synch_weights_time_ms": 15.07}, "counters": {"num_env_steps_sampled": 20000, "num_env_steps_trained": 20000, "num_agent_steps_sampled": 80000, "num_agent_steps_trained": 80000}, "done": false, "training_iteration": 5, "trial_id": "8e499_00000", "date": "2024-08-15_02-05-12", "timestamp": 1723667712, "time_this_iter_s": 10.249729871749878, "time_total_s": 53.418116092681885, "pid": 33199, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x158000dc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 53.418116092681885, "iterations_since_restore": 5, "perf": {"cpu_util_percent": 29.893333333333334, "ram_util_percent": 83.19333333333333}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0023652768008924, "cur_kl_coeff": 0.22500000000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.23623087620609, "policy_loss": -0.003584480763748091, "vf_loss": 8.238924173072533, "vf_explained_var": 0.004437140907560076, "kl": 0.00396100586213098, "entropy": 1.523935431715042, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 10395.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.684746427092918, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.939837382584022, "policy_loss": -0.01347510532313396, "vf_loss": 5.951616177483211, "vf_explained_var": 0.008464000243989248, "kl": 0.016963132899302874, "entropy": 1.5155771208818627, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 10395.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 24000, "num_env_steps_trained": 24000, "num_agent_steps_sampled": 96000, "num_agent_steps_trained": 96000}, "env_runners": {"episode_reward_max": 59.04999999999987, "episode_reward_min": -447.5200000000003, "episode_reward_mean": -118.99449999999996, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -621.91, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 2.0000000000000013, "predator_policy": 361.0}, "policy_reward_mean": {"prey_policy": -149.86724999999998, "predator_policy": 90.37}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-69.72999999999928, -133.36999999999875, -225.89000000000078, -50.540000000000624, -61.65000000000057, 2.9599999999999818, -157.2800000000002, -160.76999999999975, 0.8399999999999844, -162.68000000000126, -127.16999999999942, -93.00999999999867, -87.15999999999917, -147.40000000000038, -43.470000000000674, -209.1500000000011, -161.64000000000073, 0.9700000000000027, -20.24999999999946, -21.319999999999997, -44.480000000000615, -120.22999999999917, -151.45000000000007, -172.75000000000136, -93.64999999999829, -41.45000000000047, -71.59999999999935, -178.56000000000054, -303.3600000000009, -88.94999999999987, -39.82000000000038, -39.43000000000062, -3.340000000000078, -159.6200000000013, -11.260000000000078, -67.70999999999914, -80.83999999999953, -48.52000000000069, -260.2200000000003, -19.229999999999524, -49.6800000000004, -65.69000000000032, -447.5200000000003, -7.230000000000079, -409.5000000000002, -108.13999999999919, -118.08999999999983, -155.66999999999945, -95.87999999999974, -83.21000000000008, -40.72000000000015, -81.84999999999916, -89.96999999999966, -116.0800000000004, -7.110000000000083, -242.0, -92.07999999999855, -37.50999999999991, -97.1099999999991, -163.6299999999998, -356.86000000000007, -53.71999999999968, -241.03000000000011, -143.89999999999958, 1.9200000000000021, -79.86999999999989, -178.9299999999995, -38.420000000000705, -289.08, -255.55000000000018, -44.83999999999989, -107.81999999999915, -341.1700000000002, -54.68000000000002, -407.84000000000003, -272.41000000000025, -36.33, -293.4, -37.46000000000019, -334.0000000000002, -211.56999999999954, -122.64999999999947, -89.17999999999964, -27.309999999999448, -25.069999999999652, -46.530000000000335, -40.03000000000022, -21.27999999999974, 59.04999999999987, -353.75, 18.99999999999998, -116.34000000000002, -39.629999999999946, -54.50000000000002, -239.01999999999958, -374.77000000000004, -11.220000000000079, -122.4799999999988, -58.019999999999655, -25.909999999999755], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-122.61999999999969, -20.109999999999722, -118.59999999999928, -152.77000000000072, -154.77999999999977, -221.1100000000004, -70.3599999999992, -34.18000000000031, -112.5699999999993, -14.080000000000041, 2.0000000000000013, -6.040000000000042, -82.41999999999994, -170.86000000000016, -199.00000000000037, -152.7699999999994, 2.0000000000000013, -30.159999999999712, -255.20000000000056, -94.47999999999927, -379.82000000000016, -68.35000000000014, -60.310000000000336, -138.70000000000036, 2.0000000000000013, -231.1600000000007, -100.50999999999989, -176.89000000000064, -58.30000000000033, -32.170000000000115, -219.01999999999956, -241.13000000000068, -56.29000000000006, -269.3500000000006, -0.00999999999999836, -2.0200000000000116, -14.080000000000041, -32.17000000000031, -30.159999999999716, -30.15999999999997, -94.47999999999922, 2.0000000000000013, -50.26000000000016, -192.9700000000006, -180.90999999999974, -106.54000000000016, -209.05000000000075, -138.6999999999999, -62.320000000000334, -64.32999999999915, -88.44999999999936, 2.0000000000000013, -32.17000000000008, -84.43000000000018, -194.97999999999993, -114.57999999999927, -273.37000000000046, -196.99000000000052, -148.74999999999991, -38.20000000000036, -162.82000000000093, 2.0000000000000013, -18.099999999999703, -64.32999999999922, 2.0000000000000013, -66.33999999999915, -118.59999999999944, -203.02000000000064, -50.26000000000034, 2.0000000000000013, -76.38999999999918, -62.32000000000027, -62.320000000000334, -102.51999999999991, -56.29000000000034, -44.23000000000035, -239.20000000000027, -203.0200000000002, -44.23000000000029, 2.0000000000000013, 2.0000000000000013, -134.68000000000075, -84.4299999999993, -50.260000000000346, -319.60000000000025, -383.9200000000001, -44.230000000000345, 2.0000000000000013, -413.6700000000002, -397.83000000000004, -68.2299999999991, -180.91000000000054, -120.60999999999936, -94.47999999999972, -215.07999999999984, -116.58999999999932, -92.4699999999997, -80.40999999999987, -100.50999999999954, -138.70000000000005, -142.7200000000007, 2.0000000000000013, -10.06000000000003, -156.79000000000073, -140.6699999999998, -58.29999999999977, -116.58999999999979, -120.48999999999985, -4.030000000000042, -14.080000000000041, -287.4000000000002, -118.60000000000001, -84.43000000000032, -152.64999999999932, -10.060000000000041, -361.45000000000005, -186.78000000000063, -64.32999999999967, -138.69999999999982, -184.93000000000015, -385.8900000000001, -208.97000000000003, -22.119999999999997, -118.5999999999995, -215.08, -557.95, -343.4799999999999, -82.41999999999976, 2.0000000000000013, -14.080000000000041, -186.7800000000002, -16.0899999999997, -245.2299999999999, -146.6999999999997, -32.170000000000364, -48.25000000000035, -233.13000000000005, -429.95000000000005, -345.73, -162.81999999999996, -367.84000000000015, 2.0000000000000013, -90.45999999999921, -335.3599999999999, -305.5300000000001, -383.64000000000004, -26.139999999999997, -114.54000000000025, -473.97, -429.87, -184.93000000000004, -295.48000000000025, -50.26000000000005, -12.069999999999999, -279.4, -448.0, -339.46000000000004, 2.0000000000000013, -367.71999999999986, -295.28, -407.8800000000001, -136.6899999999999, -42.220000000000354, -293.43000000000006, -92.39, -164.7899999999994, -0.00999999999999836, -58.30000000000034, 2.0000000000000013, -229.0699999999996, -16.0899999999997, -287.4400000000001, -424.0, -4.03, -22.120000000000022, -30.159999999999716, -557.95, 2.0000000000000013, -479.96000000000004, -453.78999999999996, 2.0000000000000013, -512.0, -106.49999999999977, -182.84000000000003, -102.4799999999997, -28.14999999999971, -371.41999999999996, -14.080000000000041, -223.1199999999996, -531.9, -413.95, -419.81999999999994, 2.0000000000000013, -42.220000000000354, -70.35999999999919, -223.12000000000063, -621.91, -20.109999999999715, -445.91, 2.0000000000000013], "policy_predator_policy_reward": [62.0, 11.0, 61.0, 77.0, 26.0, 124.0, 36.0, 18.0, 57.0, 8.0, 3.0, 4.0, 88.0, 8.0, 108.0, 83.0, 13.0, 16.0, 137.0, 50.0, 168.0, 153.0, 55.0, 51.0, 26.0, 116.0, 59.0, 71.0, 30.0, 17.0, 120.0, 131.0, 29.0, 135.0, 3.0, 0.0, 10.0, 16.0, 28.0, 11.0, 48.0, 0.0, 97.0, 26.0, 32.0, 104.0, 123.0, 52.0, 33.0, 0.0, 45.0, 0.0, 43.0, 2.0, 106.0, 25.0, 140.0, 27.0, 88.0, 10.0, 53.0, 68.0, 33.0, 10.0, 33.0, 28.0, 70.0, 92.0, 17.0, 20.0, 32.0, 39.0, 61.0, 23.0, 23.0, 29.0, 35.0, 147.0, 10.0, 13.0, 38.0, 45.0, 47.0, 22.0, 86.0, 170.0, 12.0, 23.0, 90.0, 312.0, 49.0, 92.0, 38.0, 59.0, 83.0, 93.0, 0.0, 77.0, 75.0, 81.0, 43.0, 57.0, 6.0, 79.0, 33.0, 76.0, 108.0, 13.0, 3.0, 8.0, 5.0, 159.0, 84.0, 61.0, 125.0, 209.0, 73.0, 81.0, 45.0, 115.0, 16.0, 222.0, 40.0, 47.0, 211.0, 321.0, 169.0, 113.0, 6.0, 8.0, 95.0, 28.0, 111.0, 102.0, 25.0, 17.0, 233.0, 141.0, 162.0, 91.0, 151.0, 170.0, 139.0, 179.0, 187.0, 161.0, 63.0, 23.0, 200.0, 296.0, 159.0, 49.0, 26.0, 0.0, 193.0, 241.0, 190.0, 110.0, 137.0, 192.0, 151.0, 182.0, 111.0, 102.0, 95.0, 73.0, 30.0, 1.0, 115.0, 87.0, 117.0, 140.0, 201.0, 187.0, 12.0, 19.0, 292.0, 323.0, 294.0, 286.0, 221.0, 308.0, 96.0, 77.0, 54.0, 37.0, 192.0, 139.0, 334.0, 182.0, 260.0, 199.0, 22.0, 7.0, 111.0, 60.0, 361.0, 223.0, 210.0, 208.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6037478401192226, "mean_inference_ms": 1.897599929634801, "mean_action_processing_ms": 0.2516834124707162, "mean_env_wait_ms": 0.20993569892848205, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0062181949615478516, "StateBufferConnector_ms": 0.003322601318359375, "ViewRequirementAgentConnector_ms": 0.09486520290374756}, "num_episodes": 18, "episode_return_max": 59.04999999999987, "episode_return_min": -447.5200000000003, "episode_return_mean": -118.99449999999996, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 96000, "num_agent_steps_trained": 96000, "num_env_steps_sampled": 24000, "num_env_steps_trained": 24000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 394.8365634895939, "num_env_steps_trained_throughput_per_sec": 394.8365634895939, "timesteps_total": 24000, "num_env_steps_sampled_lifetime": 24000, "num_agent_steps_sampled_lifetime": 96000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 96000, "timers": {"training_iteration_time_ms": 10559.144, "restore_workers_time_ms": 0.019, "training_step_time_ms": 10559.081, "sample_time_ms": 1402.11, "learn_time_ms": 9140.125, "learn_throughput": 437.631, "synch_weights_time_ms": 14.839}, "counters": {"num_env_steps_sampled": 24000, "num_env_steps_trained": 24000, "num_agent_steps_sampled": 96000, "num_agent_steps_trained": 96000}, "done": false, "training_iteration": 6, "trial_id": "8e499_00000", "date": "2024-08-15_02-05-22", "timestamp": 1723667722, "time_this_iter_s": 10.167461156845093, "time_total_s": 63.58557724952698, "pid": 33199, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b43f3430>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 63.58557724952698, "iterations_since_restore": 6, "perf": {"cpu_util_percent": 27.25, "ram_util_percent": 83.30714285714285}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0136521468244533, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.1522407655362725, "policy_loss": -0.0058365018173520055, "vf_loss": 5.157033723624295, "vf_explained_var": 0.0007082952078057345, "kl": 0.009276148989218263, "entropy": 1.510870963555795, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 12285.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6400364112680551, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.5816364661095634, "policy_loss": -0.014106428157538176, "vf_loss": 3.5938430570420765, "vf_explained_var": 0.010133496541825552, "kl": 0.018998311890162767, "entropy": 1.5089484093050478, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 12285.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 28000, "num_env_steps_trained": 28000, "num_agent_steps_sampled": 112000, "num_agent_steps_trained": 112000}, "env_runners": {"episode_reward_max": 59.04999999999987, "episode_reward_min": -447.5200000000003, "episode_reward_mean": -110.1919999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -621.91, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 2.0000000000000013, "predator_policy": 361.0}, "policy_reward_mean": {"prey_policy": -153.09599999999998, "predator_policy": 98.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.24999999999946, -21.319999999999997, -44.480000000000615, -120.22999999999917, -151.45000000000007, -172.75000000000136, -93.64999999999829, -41.45000000000047, -71.59999999999935, -178.56000000000054, -303.3600000000009, -88.94999999999987, -39.82000000000038, -39.43000000000062, -3.340000000000078, -159.6200000000013, -11.260000000000078, -67.70999999999914, -80.83999999999953, -48.52000000000069, -260.2200000000003, -19.229999999999524, -49.6800000000004, -65.69000000000032, -447.5200000000003, -7.230000000000079, -409.5000000000002, -108.13999999999919, -118.08999999999983, -155.66999999999945, -95.87999999999974, -83.21000000000008, -40.72000000000015, -81.84999999999916, -89.96999999999966, -116.0800000000004, -7.110000000000083, -242.0, -92.07999999999855, -37.50999999999991, -97.1099999999991, -163.6299999999998, -356.86000000000007, -53.71999999999968, -241.03000000000011, -143.89999999999958, 1.9200000000000021, -79.86999999999989, -178.9299999999995, -38.420000000000705, -289.08, -255.55000000000018, -44.83999999999989, -107.81999999999915, -341.1700000000002, -54.68000000000002, -407.84000000000003, -272.41000000000025, -36.33, -293.4, -37.46000000000019, -334.0000000000002, -211.56999999999954, -122.64999999999947, -89.17999999999964, -27.309999999999448, -25.069999999999652, -46.530000000000335, -40.03000000000022, -21.27999999999974, 59.04999999999987, -353.75, 18.99999999999998, -116.34000000000002, -39.629999999999946, -54.50000000000002, -239.01999999999958, -374.77000000000004, -11.220000000000079, -122.4799999999988, -58.019999999999655, -25.909999999999755, -211.94000000000045, -12.990000000000062, -128.18000000000018, 0.7800000000000026, -38.44000000000063, -21.369999999999553, -5.090000000000083, -25.29999999999945, -159.8399999999998, -36.419999999999966, -37.43000000000062, -19.22999999999942, -11.150000000000082, -68.72999999999958, -21.87999999999995, -18.219999999999427, -106.54999999999976, -83.90999999999998], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-14.080000000000041, -32.17000000000031, -30.159999999999716, -30.15999999999997, -94.47999999999922, 2.0000000000000013, -50.26000000000016, -192.9700000000006, -180.90999999999974, -106.54000000000016, -209.05000000000075, -138.6999999999999, -62.320000000000334, -64.32999999999915, -88.44999999999936, 2.0000000000000013, -32.17000000000008, -84.43000000000018, -194.97999999999993, -114.57999999999927, -273.37000000000046, -196.99000000000052, -148.74999999999991, -38.20000000000036, -162.82000000000093, 2.0000000000000013, -18.099999999999703, -64.32999999999922, 2.0000000000000013, -66.33999999999915, -118.59999999999944, -203.02000000000064, -50.26000000000034, 2.0000000000000013, -76.38999999999918, -62.32000000000027, -62.320000000000334, -102.51999999999991, -56.29000000000034, -44.23000000000035, -239.20000000000027, -203.0200000000002, -44.23000000000029, 2.0000000000000013, 2.0000000000000013, -134.68000000000075, -84.4299999999993, -50.260000000000346, -319.60000000000025, -383.9200000000001, -44.230000000000345, 2.0000000000000013, -413.6700000000002, -397.83000000000004, -68.2299999999991, -180.91000000000054, -120.60999999999936, -94.47999999999972, -215.07999999999984, -116.58999999999932, -92.4699999999997, -80.40999999999987, -100.50999999999954, -138.70000000000005, -142.7200000000007, 2.0000000000000013, -10.06000000000003, -156.79000000000073, -140.6699999999998, -58.29999999999977, -116.58999999999979, -120.48999999999985, -4.030000000000042, -14.080000000000041, -287.4000000000002, -118.60000000000001, -84.43000000000032, -152.64999999999932, -10.060000000000041, -361.45000000000005, -186.78000000000063, -64.32999999999967, -138.69999999999982, -184.93000000000015, -385.8900000000001, -208.97000000000003, -22.119999999999997, -118.5999999999995, -215.08, -557.95, -343.4799999999999, -82.41999999999976, 2.0000000000000013, -14.080000000000041, -186.7800000000002, -16.0899999999997, -245.2299999999999, -146.6999999999997, -32.170000000000364, -48.25000000000035, -233.13000000000005, -429.95000000000005, -345.73, -162.81999999999996, -367.84000000000015, 2.0000000000000013, -90.45999999999921, -335.3599999999999, -305.5300000000001, -383.64000000000004, -26.139999999999997, -114.54000000000025, -473.97, -429.87, -184.93000000000004, -295.48000000000025, -50.26000000000005, -12.069999999999999, -279.4, -448.0, -339.46000000000004, 2.0000000000000013, -367.71999999999986, -295.28, -407.8800000000001, -136.6899999999999, -42.220000000000354, -293.43000000000006, -92.39, -164.7899999999994, -0.00999999999999836, -58.30000000000034, 2.0000000000000013, -229.0699999999996, -16.0899999999997, -287.4400000000001, -424.0, -4.03, -22.120000000000022, -30.159999999999716, -557.95, 2.0000000000000013, -479.96000000000004, -453.78999999999996, 2.0000000000000013, -512.0, -106.49999999999977, -182.84000000000003, -102.4799999999997, -28.14999999999971, -371.41999999999996, -14.080000000000041, -223.1199999999996, -531.9, -413.95, -419.81999999999994, 2.0000000000000013, -42.220000000000354, -70.35999999999919, -223.12000000000063, -621.91, -20.109999999999715, -445.91, 2.0000000000000013, -291.3000000000004, -423.6400000000001, 2.0000000000000013, -236.9900000000002, -447.6800000000001, -98.49999999999936, -40.210000000000356, -0.009999999999998581, -12.070000000000041, -72.36999999999918, -46.24000000000028, -24.129999999999708, -16.089999999999705, 2.0000000000000013, -58.30000000000034, 2.0000000000000013, -273.3700000000006, -413.4700000000001, -351.20000000000005, -42.22000000000035, -8.050000000000042, -74.3799999999992, -32.170000000000364, -10.060000000000041, -14.080000000000041, -12.070000000000041, -341.66999999999996, -10.060000000000041, -174.8800000000004, 2.0000000000000013, -36.19000000000036, -4.030000000000042, -585.97, -162.58000000000038, -341.71000000000004, -38.20000000000005], "policy_predator_policy_reward": [10.0, 16.0, 28.0, 11.0, 48.0, 0.0, 97.0, 26.0, 32.0, 104.0, 123.0, 52.0, 33.0, 0.0, 45.0, 0.0, 43.0, 2.0, 106.0, 25.0, 140.0, 27.0, 88.0, 10.0, 53.0, 68.0, 33.0, 10.0, 33.0, 28.0, 70.0, 92.0, 17.0, 20.0, 32.0, 39.0, 61.0, 23.0, 23.0, 29.0, 35.0, 147.0, 10.0, 13.0, 38.0, 45.0, 47.0, 22.0, 86.0, 170.0, 12.0, 23.0, 90.0, 312.0, 49.0, 92.0, 38.0, 59.0, 83.0, 93.0, 0.0, 77.0, 75.0, 81.0, 43.0, 57.0, 6.0, 79.0, 33.0, 76.0, 108.0, 13.0, 3.0, 8.0, 5.0, 159.0, 84.0, 61.0, 125.0, 209.0, 73.0, 81.0, 45.0, 115.0, 16.0, 222.0, 40.0, 47.0, 211.0, 321.0, 169.0, 113.0, 6.0, 8.0, 95.0, 28.0, 111.0, 102.0, 25.0, 17.0, 233.0, 141.0, 162.0, 91.0, 151.0, 170.0, 139.0, 179.0, 187.0, 161.0, 63.0, 23.0, 200.0, 296.0, 159.0, 49.0, 26.0, 0.0, 193.0, 241.0, 190.0, 110.0, 137.0, 192.0, 151.0, 182.0, 111.0, 102.0, 95.0, 73.0, 30.0, 1.0, 115.0, 87.0, 117.0, 140.0, 201.0, 187.0, 12.0, 19.0, 292.0, 323.0, 294.0, 286.0, 221.0, 308.0, 96.0, 77.0, 54.0, 37.0, 192.0, 139.0, 334.0, 182.0, 260.0, 199.0, 22.0, 7.0, 111.0, 60.0, 361.0, 223.0, 210.0, 208.0, 231.0, 272.0, 104.0, 118.0, 274.0, 144.0, 22.0, 19.0, 9.0, 37.0, 28.0, 21.0, 0.0, 9.0, 1.0, 30.0, 254.0, 273.0, 156.0, 201.0, 13.0, 32.0, 6.0, 17.0, 8.0, 7.0, 128.0, 155.0, 71.0, 80.0, 19.0, 3.0, 301.0, 341.0, 143.0, 153.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5992711457672293, "mean_inference_ms": 1.9035813775069317, "mean_action_processing_ms": 0.24906023600871208, "mean_env_wait_ms": 0.20843095353835053, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005556225776672363, "StateBufferConnector_ms": 0.003317713737487793, "ViewRequirementAgentConnector_ms": 0.09204626083374023}, "num_episodes": 18, "episode_return_max": 59.04999999999987, "episode_return_min": -447.5200000000003, "episode_return_mean": -110.1919999999999, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 112000, "num_agent_steps_trained": 112000, "num_env_steps_sampled": 28000, "num_env_steps_trained": 28000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 391.58166051826566, "num_env_steps_trained_throughput_per_sec": 391.58166051826566, "timesteps_total": 28000, "num_env_steps_sampled_lifetime": 28000, "num_agent_steps_sampled_lifetime": 112000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 112000, "timers": {"training_iteration_time_ms": 10509.979, "restore_workers_time_ms": 0.018, "training_step_time_ms": 10509.92, "sample_time_ms": 1388.145, "learn_time_ms": 9105.095, "learn_throughput": 439.314, "synch_weights_time_ms": 14.755}, "counters": {"num_env_steps_sampled": 28000, "num_env_steps_trained": 28000, "num_agent_steps_sampled": 112000, "num_agent_steps_trained": 112000}, "done": false, "training_iteration": 7, "trial_id": "8e499_00000", "date": "2024-08-15_02-05-32", "timestamp": 1723667732, "time_this_iter_s": 10.219000101089478, "time_total_s": 73.80457735061646, "pid": 33199, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b43ed0d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 73.80457735061646, "iterations_since_restore": 7, "perf": {"cpu_util_percent": 28.259999999999994, "ram_util_percent": 83.14666666666666}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9657046908345172, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.4459326218044948, "policy_loss": -0.009197865470149924, "vf_loss": 1.453485093419514, "vf_explained_var": -0.00610190923251803, "kl": 0.014625734513570078, "entropy": 1.5249352972343486, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 14175.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.592462101972923, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.0323073345428657, "policy_loss": -0.00978976800599229, "vf_loss": 1.0412569033799979, "vf_explained_var": 0.009193019608341197, "kl": 0.008401973373946041, "entropy": 1.4826356181391964, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 14175.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 32000, "num_env_steps_trained": 32000, "num_agent_steps_sampled": 128000, "num_agent_steps_trained": 128000}, "env_runners": {"episode_reward_max": 59.04999999999987, "episode_reward_min": -447.5200000000003, "episode_reward_mean": -97.88249999999991, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -621.91, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 2.0000000000000013, "predator_policy": 361.0}, "policy_reward_mean": {"prey_policy": -145.58624999999998, "predator_policy": 96.645}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-80.83999999999953, -48.52000000000069, -260.2200000000003, -19.229999999999524, -49.6800000000004, -65.69000000000032, -447.5200000000003, -7.230000000000079, -409.5000000000002, -108.13999999999919, -118.08999999999983, -155.66999999999945, -95.87999999999974, -83.21000000000008, -40.72000000000015, -81.84999999999916, -89.96999999999966, -116.0800000000004, -7.110000000000083, -242.0, -92.07999999999855, -37.50999999999991, -97.1099999999991, -163.6299999999998, -356.86000000000007, -53.71999999999968, -241.03000000000011, -143.89999999999958, 1.9200000000000021, -79.86999999999989, -178.9299999999995, -38.420000000000705, -289.08, -255.55000000000018, -44.83999999999989, -107.81999999999915, -341.1700000000002, -54.68000000000002, -407.84000000000003, -272.41000000000025, -36.33, -293.4, -37.46000000000019, -334.0000000000002, -211.56999999999954, -122.64999999999947, -89.17999999999964, -27.309999999999448, -25.069999999999652, -46.530000000000335, -40.03000000000022, -21.27999999999974, 59.04999999999987, -353.75, 18.99999999999998, -116.34000000000002, -39.629999999999946, -54.50000000000002, -239.01999999999958, -374.77000000000004, -11.220000000000079, -122.4799999999988, -58.019999999999655, -25.909999999999755, -211.94000000000045, -12.990000000000062, -128.18000000000018, 0.7800000000000026, -38.44000000000063, -21.369999999999553, -5.090000000000083, -25.29999999999945, -159.8399999999998, -36.419999999999966, -37.43000000000062, -19.22999999999942, -11.150000000000082, -68.72999999999958, -21.87999999999995, -18.219999999999427, -106.54999999999976, -83.90999999999998, -34.84000000000039, -4.1300000000000825, -9.190000000000081, -10.24000000000008, -0.18000000000003746, -10.48000000000007, -22.289999999999424, -22.25999999999942, -33.060000000000464, 0.709999999999987, -51.77000000000027, -27.599999999999547, -60.480000000000416, -42.46000000000067, -12.210000000000072, -24.38999999999945, -2.060000000000084, -31.350000000000474], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-62.320000000000334, -102.51999999999991, -56.29000000000034, -44.23000000000035, -239.20000000000027, -203.0200000000002, -44.23000000000029, 2.0000000000000013, 2.0000000000000013, -134.68000000000075, -84.4299999999993, -50.260000000000346, -319.60000000000025, -383.9200000000001, -44.230000000000345, 2.0000000000000013, -413.6700000000002, -397.83000000000004, -68.2299999999991, -180.91000000000054, -120.60999999999936, -94.47999999999972, -215.07999999999984, -116.58999999999932, -92.4699999999997, -80.40999999999987, -100.50999999999954, -138.70000000000005, -142.7200000000007, 2.0000000000000013, -10.06000000000003, -156.79000000000073, -140.6699999999998, -58.29999999999977, -116.58999999999979, -120.48999999999985, -4.030000000000042, -14.080000000000041, -287.4000000000002, -118.60000000000001, -84.43000000000032, -152.64999999999932, -10.060000000000041, -361.45000000000005, -186.78000000000063, -64.32999999999967, -138.69999999999982, -184.93000000000015, -385.8900000000001, -208.97000000000003, -22.119999999999997, -118.5999999999995, -215.08, -557.95, -343.4799999999999, -82.41999999999976, 2.0000000000000013, -14.080000000000041, -186.7800000000002, -16.0899999999997, -245.2299999999999, -146.6999999999997, -32.170000000000364, -48.25000000000035, -233.13000000000005, -429.95000000000005, -345.73, -162.81999999999996, -367.84000000000015, 2.0000000000000013, -90.45999999999921, -335.3599999999999, -305.5300000000001, -383.64000000000004, -26.139999999999997, -114.54000000000025, -473.97, -429.87, -184.93000000000004, -295.48000000000025, -50.26000000000005, -12.069999999999999, -279.4, -448.0, -339.46000000000004, 2.0000000000000013, -367.71999999999986, -295.28, -407.8800000000001, -136.6899999999999, -42.220000000000354, -293.43000000000006, -92.39, -164.7899999999994, -0.00999999999999836, -58.30000000000034, 2.0000000000000013, -229.0699999999996, -16.0899999999997, -287.4400000000001, -424.0, -4.03, -22.120000000000022, -30.159999999999716, -557.95, 2.0000000000000013, -479.96000000000004, -453.78999999999996, 2.0000000000000013, -512.0, -106.49999999999977, -182.84000000000003, -102.4799999999997, -28.14999999999971, -371.41999999999996, -14.080000000000041, -223.1199999999996, -531.9, -413.95, -419.81999999999994, 2.0000000000000013, -42.220000000000354, -70.35999999999919, -223.12000000000063, -621.91, -20.109999999999715, -445.91, 2.0000000000000013, -291.3000000000004, -423.6400000000001, 2.0000000000000013, -236.9900000000002, -447.6800000000001, -98.49999999999936, -40.210000000000356, -0.009999999999998581, -12.070000000000041, -72.36999999999918, -46.24000000000028, -24.129999999999708, -16.089999999999705, 2.0000000000000013, -58.30000000000034, 2.0000000000000013, -273.3700000000006, -413.4700000000001, -351.20000000000005, -42.22000000000035, -8.050000000000042, -74.3799999999992, -32.170000000000364, -10.060000000000041, -14.080000000000041, -12.070000000000041, -341.66999999999996, -10.060000000000041, -174.8800000000004, 2.0000000000000013, -36.19000000000036, -4.030000000000042, -585.97, -162.58000000000038, -341.71000000000004, -38.20000000000005, 2.0000000000000013, -166.84000000000074, -18.099999999999703, -4.030000000000042, -6.040000000000042, -28.149999999999718, 2.0000000000000013, -46.24000000000035, 2.0000000000000013, -34.18000000000036, -94.47999999999922, 2.0000000000000013, -40.210000000000335, -14.080000000000041, -28.149999999999714, -20.109999999999705, -166.6800000000007, -74.3799999999992, 2.0000000000000013, -56.29000000000034, -34.18000000000032, -116.58999999999949, 2.0000000000000013, -118.59999999999928, -359.4800000000003, 2.0000000000000013, -66.33999999999916, -22.119999999999706, -24.129999999999708, -14.080000000000041, -44.23000000000034, -30.159999999999712, -4.030000000000042, -4.030000000000042, -26.139999999999713, -40.210000000000356], "policy_predator_policy_reward": [61.0, 23.0, 23.0, 29.0, 35.0, 147.0, 10.0, 13.0, 38.0, 45.0, 47.0, 22.0, 86.0, 170.0, 12.0, 23.0, 90.0, 312.0, 49.0, 92.0, 38.0, 59.0, 83.0, 93.0, 0.0, 77.0, 75.0, 81.0, 43.0, 57.0, 6.0, 79.0, 33.0, 76.0, 108.0, 13.0, 3.0, 8.0, 5.0, 159.0, 84.0, 61.0, 125.0, 209.0, 73.0, 81.0, 45.0, 115.0, 16.0, 222.0, 40.0, 47.0, 211.0, 321.0, 169.0, 113.0, 6.0, 8.0, 95.0, 28.0, 111.0, 102.0, 25.0, 17.0, 233.0, 141.0, 162.0, 91.0, 151.0, 170.0, 139.0, 179.0, 187.0, 161.0, 63.0, 23.0, 200.0, 296.0, 159.0, 49.0, 26.0, 0.0, 193.0, 241.0, 190.0, 110.0, 137.0, 192.0, 151.0, 182.0, 111.0, 102.0, 95.0, 73.0, 30.0, 1.0, 115.0, 87.0, 117.0, 140.0, 201.0, 187.0, 12.0, 19.0, 292.0, 323.0, 294.0, 286.0, 221.0, 308.0, 96.0, 77.0, 54.0, 37.0, 192.0, 139.0, 334.0, 182.0, 260.0, 199.0, 22.0, 7.0, 111.0, 60.0, 361.0, 223.0, 210.0, 208.0, 231.0, 272.0, 104.0, 118.0, 274.0, 144.0, 22.0, 19.0, 9.0, 37.0, 28.0, 21.0, 0.0, 9.0, 1.0, 30.0, 254.0, 273.0, 156.0, 201.0, 13.0, 32.0, 6.0, 17.0, 8.0, 7.0, 128.0, 155.0, 71.0, 80.0, 19.0, 3.0, 301.0, 341.0, 143.0, 153.0, 80.0, 50.0, 10.0, 8.0, 10.0, 15.0, 10.0, 24.0, 18.0, 14.0, 34.0, 48.0, 21.0, 11.0, 11.0, 15.0, 93.0, 115.0, 26.0, 29.0, 58.0, 41.0, 60.0, 29.0, 131.0, 166.0, 19.0, 27.0, 13.0, 13.0, 20.0, 30.0, 3.0, 3.0, 14.0, 21.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5914423326733005, "mean_inference_ms": 1.8863647796220777, "mean_action_processing_ms": 0.24507466784431345, "mean_env_wait_ms": 0.20435468037491256, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0048084259033203125, "StateBufferConnector_ms": 0.003153204917907715, "ViewRequirementAgentConnector_ms": 0.09143710136413574}, "num_episodes": 18, "episode_return_max": 59.04999999999987, "episode_return_min": -447.5200000000003, "episode_return_mean": -97.88249999999991, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 128000, "num_agent_steps_trained": 128000, "num_env_steps_sampled": 32000, "num_env_steps_trained": 32000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 393.56502145531607, "num_env_steps_trained_throughput_per_sec": 393.56502145531607, "timesteps_total": 32000, "num_env_steps_sampled_lifetime": 32000, "num_agent_steps_sampled_lifetime": 128000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 128000, "timers": {"training_iteration_time_ms": 10466.671, "restore_workers_time_ms": 0.018, "training_step_time_ms": 10466.614, "sample_time_ms": 1367.866, "learn_time_ms": 9082.186, "learn_throughput": 440.423, "synch_weights_time_ms": 14.583}, "counters": {"num_env_steps_sampled": 32000, "num_env_steps_trained": 32000, "num_agent_steps_sampled": 128000, "num_agent_steps_trained": 128000}, "done": false, "training_iteration": 8, "trial_id": "8e499_00000", "date": "2024-08-15_02-05-43", "timestamp": 1723667743, "time_this_iter_s": 10.209259033203125, "time_total_s": 84.01383638381958, "pid": 33199, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b43fa280>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 84.01383638381958, "iterations_since_restore": 8, "perf": {"cpu_util_percent": 28.949999999999992, "ram_util_percent": 83.21428571428571}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9672537066160687, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.386010055724906, "policy_loss": -0.009328261082104983, "vf_loss": 1.3938004731185853, "vf_explained_var": 0.001718775746683595, "kl": 0.013669719830561622, "entropy": 1.5171792457974147, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 16065.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5964258599139395, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.165798285296039, "policy_loss": -0.01168460236817953, "vf_loss": 1.176482796763617, "vf_explained_var": 0.009748591411681402, "kl": 0.010000912058464585, "entropy": 1.464585165687339, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 16065.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 36000, "num_env_steps_trained": 36000, "num_agent_steps_sampled": 144000, "num_agent_steps_trained": 144000}, "env_runners": {"episode_reward_max": 59.04999999999987, "episode_reward_min": -407.84000000000003, "episode_reward_mean": -75.85739999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -621.91, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 2.0000000000000013, "predator_policy": 361.0}, "policy_reward_mean": {"prey_policy": -124.93869999999997, "predator_policy": 87.01}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-97.1099999999991, -163.6299999999998, -356.86000000000007, -53.71999999999968, -241.03000000000011, -143.89999999999958, 1.9200000000000021, -79.86999999999989, -178.9299999999995, -38.420000000000705, -289.08, -255.55000000000018, -44.83999999999989, -107.81999999999915, -341.1700000000002, -54.68000000000002, -407.84000000000003, -272.41000000000025, -36.33, -293.4, -37.46000000000019, -334.0000000000002, -211.56999999999954, -122.64999999999947, -89.17999999999964, -27.309999999999448, -25.069999999999652, -46.530000000000335, -40.03000000000022, -21.27999999999974, 59.04999999999987, -353.75, 18.99999999999998, -116.34000000000002, -39.629999999999946, -54.50000000000002, -239.01999999999958, -374.77000000000004, -11.220000000000079, -122.4799999999988, -58.019999999999655, -25.909999999999755, -211.94000000000045, -12.990000000000062, -128.18000000000018, 0.7800000000000026, -38.44000000000063, -21.369999999999553, -5.090000000000083, -25.29999999999945, -159.8399999999998, -36.419999999999966, -37.43000000000062, -19.22999999999942, -11.150000000000082, -68.72999999999958, -21.87999999999995, -18.219999999999427, -106.54999999999976, -83.90999999999998, -34.84000000000039, -4.1300000000000825, -9.190000000000081, -10.24000000000008, -0.18000000000003746, -10.48000000000007, -22.289999999999424, -22.25999999999942, -33.060000000000464, 0.709999999999987, -51.77000000000027, -27.599999999999547, -60.480000000000416, -42.46000000000067, -12.210000000000072, -24.38999999999945, -2.060000000000084, -31.350000000000474, -5.090000000000083, -9.14000000000008, -19.239999999999426, -1.1100000000000632, -45.4800000000007, -44.48000000000053, -39.43000000000069, -29.3899999999997, -28.319999999999432, -33.3100000000007, -38.81000000000026, -4.100000000000083, 0.9699999999999841, -8.200000000000081, 3.989999999999959, -35.58000000000057, -1.0800000000000622, 1.920000000000003, -2.260000000000077, -32.45000000000061, -55.24999999999998, -28.389999999999468], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-186.78000000000063, -64.32999999999967, -138.69999999999982, -184.93000000000015, -385.8900000000001, -208.97000000000003, -22.119999999999997, -118.5999999999995, -215.08, -557.95, -343.4799999999999, -82.41999999999976, 2.0000000000000013, -14.080000000000041, -186.7800000000002, -16.0899999999997, -245.2299999999999, -146.6999999999997, -32.170000000000364, -48.25000000000035, -233.13000000000005, -429.95000000000005, -345.73, -162.81999999999996, -367.84000000000015, 2.0000000000000013, -90.45999999999921, -335.3599999999999, -305.5300000000001, -383.64000000000004, -26.139999999999997, -114.54000000000025, -473.97, -429.87, -184.93000000000004, -295.48000000000025, -50.26000000000005, -12.069999999999999, -279.4, -448.0, -339.46000000000004, 2.0000000000000013, -367.71999999999986, -295.28, -407.8800000000001, -136.6899999999999, -42.220000000000354, -293.43000000000006, -92.39, -164.7899999999994, -0.00999999999999836, -58.30000000000034, 2.0000000000000013, -229.0699999999996, -16.0899999999997, -287.4400000000001, -424.0, -4.03, -22.120000000000022, -30.159999999999716, -557.95, 2.0000000000000013, -479.96000000000004, -453.78999999999996, 2.0000000000000013, -512.0, -106.49999999999977, -182.84000000000003, -102.4799999999997, -28.14999999999971, -371.41999999999996, -14.080000000000041, -223.1199999999996, -531.9, -413.95, -419.81999999999994, 2.0000000000000013, -42.220000000000354, -70.35999999999919, -223.12000000000063, -621.91, -20.109999999999715, -445.91, 2.0000000000000013, -291.3000000000004, -423.6400000000001, 2.0000000000000013, -236.9900000000002, -447.6800000000001, -98.49999999999936, -40.210000000000356, -0.009999999999998581, -12.070000000000041, -72.36999999999918, -46.24000000000028, -24.129999999999708, -16.089999999999705, 2.0000000000000013, -58.30000000000034, 2.0000000000000013, -273.3700000000006, -413.4700000000001, -351.20000000000005, -42.22000000000035, -8.050000000000042, -74.3799999999992, -32.170000000000364, -10.060000000000041, -14.080000000000041, -12.070000000000041, -341.66999999999996, -10.060000000000041, -174.8800000000004, 2.0000000000000013, -36.19000000000036, -4.030000000000042, -585.97, -162.58000000000038, -341.71000000000004, -38.20000000000005, 2.0000000000000013, -166.84000000000074, -18.099999999999703, -4.030000000000042, -6.040000000000042, -28.149999999999718, 2.0000000000000013, -46.24000000000035, 2.0000000000000013, -34.18000000000036, -94.47999999999922, 2.0000000000000013, -40.210000000000335, -14.080000000000041, -28.149999999999714, -20.109999999999705, -166.6800000000007, -74.3799999999992, 2.0000000000000013, -56.29000000000034, -34.18000000000032, -116.58999999999949, 2.0000000000000013, -118.59999999999928, -359.4800000000003, 2.0000000000000013, -66.33999999999916, -22.119999999999706, -24.129999999999708, -14.080000000000041, -44.23000000000034, -30.159999999999712, -4.030000000000042, -4.030000000000042, -26.139999999999713, -40.210000000000356, -8.05000000000004, -6.040000000000042, -0.00999999999999836, -24.129999999999715, -10.060000000000041, -34.180000000000355, -20.109999999999705, 2.0000000000000013, -40.210000000000356, -52.270000000000344, -64.32999999999923, -28.14999999999971, -44.23000000000035, -38.200000000000294, -0.009999999999998581, -122.37999999999917, -44.230000000000345, -16.0899999999997, -44.23000000000035, -14.080000000000041, -160.73000000000047, -14.080000000000041, 2.0000000000000013, -18.099999999999707, -4.030000000000042, 2.0000000000000013, -12.07000000000004, -24.129999999999708, -0.00999999999999836, 2.0000000000000013, -24.129999999999708, -88.44999999999924, -14.080000000000041, 2.0000000000000013, 2.0000000000000013, -14.080000000000041, 2.0000000000000013, -50.260000000000346, -14.080000000000041, -72.36999999999918, -241.21000000000012, -6.040000000000042, 2.0000000000000013, -76.38999999999919], "policy_predator_policy_reward": [73.0, 81.0, 45.0, 115.0, 16.0, 222.0, 40.0, 47.0, 211.0, 321.0, 169.0, 113.0, 6.0, 8.0, 95.0, 28.0, 111.0, 102.0, 25.0, 17.0, 233.0, 141.0, 162.0, 91.0, 151.0, 170.0, 139.0, 179.0, 187.0, 161.0, 63.0, 23.0, 200.0, 296.0, 159.0, 49.0, 26.0, 0.0, 193.0, 241.0, 190.0, 110.0, 137.0, 192.0, 151.0, 182.0, 111.0, 102.0, 95.0, 73.0, 30.0, 1.0, 115.0, 87.0, 117.0, 140.0, 201.0, 187.0, 12.0, 19.0, 292.0, 323.0, 294.0, 286.0, 221.0, 308.0, 96.0, 77.0, 54.0, 37.0, 192.0, 139.0, 334.0, 182.0, 260.0, 199.0, 22.0, 7.0, 111.0, 60.0, 361.0, 223.0, 210.0, 208.0, 231.0, 272.0, 104.0, 118.0, 274.0, 144.0, 22.0, 19.0, 9.0, 37.0, 28.0, 21.0, 0.0, 9.0, 1.0, 30.0, 254.0, 273.0, 156.0, 201.0, 13.0, 32.0, 6.0, 17.0, 8.0, 7.0, 128.0, 155.0, 71.0, 80.0, 19.0, 3.0, 301.0, 341.0, 143.0, 153.0, 80.0, 50.0, 10.0, 8.0, 10.0, 15.0, 10.0, 24.0, 18.0, 14.0, 34.0, 48.0, 21.0, 11.0, 11.0, 15.0, 93.0, 115.0, 26.0, 29.0, 58.0, 41.0, 60.0, 29.0, 131.0, 166.0, 19.0, 27.0, 13.0, 13.0, 20.0, 30.0, 3.0, 3.0, 14.0, 21.0, 5.0, 4.0, 13.0, 2.0, 7.0, 18.0, 10.0, 7.0, 20.0, 27.0, 14.0, 34.0, 13.0, 30.0, 1.0, 92.0, 9.0, 23.0, 2.0, 23.0, 65.0, 71.0, 10.0, 2.0, 0.0, 3.0, 16.0, 12.0, 1.0, 1.0, 28.0, 49.0, 8.0, 3.0, 6.0, 8.0, 23.0, 23.0, 23.0, 31.0, 72.0, 120.0, 31.0, 15.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.583901013683992, "mean_inference_ms": 1.8680642551926203, "mean_action_processing_ms": 0.24142146455494667, "mean_env_wait_ms": 0.19993416608532605, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0042285919189453125, "StateBufferConnector_ms": 0.002988576889038086, "ViewRequirementAgentConnector_ms": 0.09074342250823975}, "num_episodes": 22, "episode_return_max": 59.04999999999987, "episode_return_min": -407.84000000000003, "episode_return_mean": -75.85739999999998, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 144000, "num_agent_steps_trained": 144000, "num_env_steps_sampled": 36000, "num_env_steps_trained": 36000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 374.11110455032053, "num_env_steps_trained_throughput_per_sec": 374.11110455032053, "timesteps_total": 36000, "num_env_steps_sampled_lifetime": 36000, "num_agent_steps_sampled_lifetime": 144000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 144000, "timers": {"training_iteration_time_ms": 10491.709, "restore_workers_time_ms": 0.017, "training_step_time_ms": 10491.656, "sample_time_ms": 1367.303, "learn_time_ms": 9108.066, "learn_throughput": 439.171, "synch_weights_time_ms": 14.419}, "counters": {"num_env_steps_sampled": 36000, "num_env_steps_trained": 36000, "num_agent_steps_sampled": 144000, "num_agent_steps_trained": 144000}, "done": false, "training_iteration": 9, "trial_id": "8e499_00000", "date": "2024-08-15_02-05-53", "timestamp": 1723667753, "time_this_iter_s": 10.696571826934814, "time_total_s": 94.7104082107544, "pid": 33199, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b43fa430>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 94.7104082107544, "iterations_since_restore": 9, "perf": {"cpu_util_percent": 29.10625, "ram_util_percent": 82.9}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0852807629360723, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.7843937887085808, "policy_loss": -0.010318235026071312, "vf_loss": 1.7935043107895625, "vf_explained_var": 0.01997584341064332, "kl": 0.010735251176892013, "entropy": 1.4929233817827134, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 17955.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6848458507073619, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.7060461133245437, "policy_loss": -0.011874090504423573, "vf_loss": 1.7163254711047682, "vf_explained_var": 0.0012560068930267656, "kl": 0.015947312541818193, "entropy": 1.3786522789606972, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 17955.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 40000, "num_env_steps_trained": 40000, "num_agent_steps_sampled": 160000, "num_agent_steps_trained": 160000}, "env_runners": {"episode_reward_max": 59.04999999999987, "episode_reward_min": -374.77000000000004, "episode_reward_mean": -42.88689999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -621.91, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 2.0000000000000013, "predator_policy": 361.0}, "policy_reward_mean": {"prey_policy": -84.66844999999995, "predator_policy": 63.225}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-122.64999999999947, -89.17999999999964, -27.309999999999448, -25.069999999999652, -46.530000000000335, -40.03000000000022, -21.27999999999974, 59.04999999999987, -353.75, 18.99999999999998, -116.34000000000002, -39.629999999999946, -54.50000000000002, -239.01999999999958, -374.77000000000004, -11.220000000000079, -122.4799999999988, -58.019999999999655, -25.909999999999755, -211.94000000000045, -12.990000000000062, -128.18000000000018, 0.7800000000000026, -38.44000000000063, -21.369999999999553, -5.090000000000083, -25.29999999999945, -159.8399999999998, -36.419999999999966, -37.43000000000062, -19.22999999999942, -11.150000000000082, -68.72999999999958, -21.87999999999995, -18.219999999999427, -106.54999999999976, -83.90999999999998, -34.84000000000039, -4.1300000000000825, -9.190000000000081, -10.24000000000008, -0.18000000000003746, -10.48000000000007, -22.289999999999424, -22.25999999999942, -33.060000000000464, 0.709999999999987, -51.77000000000027, -27.599999999999547, -60.480000000000416, -42.46000000000067, -12.210000000000072, -24.38999999999945, -2.060000000000084, -31.350000000000474, -5.090000000000083, -9.14000000000008, -19.239999999999426, -1.1100000000000632, -45.4800000000007, -44.48000000000053, -39.43000000000069, -29.3899999999997, -28.319999999999432, -33.3100000000007, -38.81000000000026, -4.100000000000083, 0.9699999999999841, -8.200000000000081, 3.989999999999959, -35.58000000000057, -1.0800000000000622, 1.920000000000003, -2.260000000000077, -32.45000000000061, -55.24999999999998, -28.389999999999468, -24.279999999999458, -29.32999999999969, -57.849999999999845, -17.20999999999954, -6.120000000000083, -336.48000000000036, -30.34000000000006, 0.9199999999999823, -12.160000000000082, -25.619999999999497, -6.180000000000081, -49.63000000000065, -3.24000000000008, -41.45000000000064, -6.18000000000008, -6.1400000000000805, -12.160000000000082, -21.359999999999474, -31.280000000000484, 3.9099999999999606, -21.24999999999943, -1.1200000000000623, -6.100000000000083], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-42.220000000000354, -293.43000000000006, -92.39, -164.7899999999994, -0.00999999999999836, -58.30000000000034, 2.0000000000000013, -229.0699999999996, -16.0899999999997, -287.4400000000001, -424.0, -4.03, -22.120000000000022, -30.159999999999716, -557.95, 2.0000000000000013, -479.96000000000004, -453.78999999999996, 2.0000000000000013, -512.0, -106.49999999999977, -182.84000000000003, -102.4799999999997, -28.14999999999971, -371.41999999999996, -14.080000000000041, -223.1199999999996, -531.9, -413.95, -419.81999999999994, 2.0000000000000013, -42.220000000000354, -70.35999999999919, -223.12000000000063, -621.91, -20.109999999999715, -445.91, 2.0000000000000013, -291.3000000000004, -423.6400000000001, 2.0000000000000013, -236.9900000000002, -447.6800000000001, -98.49999999999936, -40.210000000000356, -0.009999999999998581, -12.070000000000041, -72.36999999999918, -46.24000000000028, -24.129999999999708, -16.089999999999705, 2.0000000000000013, -58.30000000000034, 2.0000000000000013, -273.3700000000006, -413.4700000000001, -351.20000000000005, -42.22000000000035, -8.050000000000042, -74.3799999999992, -32.170000000000364, -10.060000000000041, -14.080000000000041, -12.070000000000041, -341.66999999999996, -10.060000000000041, -174.8800000000004, 2.0000000000000013, -36.19000000000036, -4.030000000000042, -585.97, -162.58000000000038, -341.71000000000004, -38.20000000000005, 2.0000000000000013, -166.84000000000074, -18.099999999999703, -4.030000000000042, -6.040000000000042, -28.149999999999718, 2.0000000000000013, -46.24000000000035, 2.0000000000000013, -34.18000000000036, -94.47999999999922, 2.0000000000000013, -40.210000000000335, -14.080000000000041, -28.149999999999714, -20.109999999999705, -166.6800000000007, -74.3799999999992, 2.0000000000000013, -56.29000000000034, -34.18000000000032, -116.58999999999949, 2.0000000000000013, -118.59999999999928, -359.4800000000003, 2.0000000000000013, -66.33999999999916, -22.119999999999706, -24.129999999999708, -14.080000000000041, -44.23000000000034, -30.159999999999712, -4.030000000000042, -4.030000000000042, -26.139999999999713, -40.210000000000356, -8.05000000000004, -6.040000000000042, -0.00999999999999836, -24.129999999999715, -10.060000000000041, -34.180000000000355, -20.109999999999705, 2.0000000000000013, -40.210000000000356, -52.270000000000344, -64.32999999999923, -28.14999999999971, -44.23000000000035, -38.200000000000294, -0.009999999999998581, -122.37999999999917, -44.230000000000345, -16.0899999999997, -44.23000000000035, -14.080000000000041, -160.73000000000047, -14.080000000000041, 2.0000000000000013, -18.099999999999707, -4.030000000000042, 2.0000000000000013, -12.07000000000004, -24.129999999999708, -0.00999999999999836, 2.0000000000000013, -24.129999999999708, -88.44999999999924, -14.080000000000041, 2.0000000000000013, 2.0000000000000013, -14.080000000000041, 2.0000000000000013, -50.260000000000346, -14.080000000000041, -72.36999999999918, -241.21000000000012, -6.040000000000042, 2.0000000000000013, -76.38999999999919, -4.030000000000042, -48.2500000000003, -4.030000000000042, -58.30000000000033, -154.7799999999998, -12.070000000000041, -30.15999999999972, -8.050000000000042, 2.0000000000000013, -22.119999999999706, -277.35000000000014, -225.1300000000001, -4.030000000000042, -60.310000000000336, -14.080000000000041, 2.0000000000000013, -20.10999999999974, -8.050000000000042, -10.060000000000041, -110.55999999999932, -30.159999999999712, -2.0200000000000338, -40.210000000000335, -82.41999999999919, -42.220000000000354, -2.020000000000042, -14.080000000000041, -72.36999999999917, -28.14999999999971, -4.030000000000038, -26.13999999999971, 2.0000000000000013, -8.050000000000042, -20.109999999999705, -70.35999999999916, 2.0000000000000013, -30.159999999999712, -22.119999999999706, -16.0899999999997, 2.0000000000000013, -34.180000000000355, -12.070000000000041, -0.009999999999998581, -20.109999999999705, -10.060000000000041, -6.040000000000042], "policy_predator_policy_reward": [111.0, 102.0, 95.0, 73.0, 30.0, 1.0, 115.0, 87.0, 117.0, 140.0, 201.0, 187.0, 12.0, 19.0, 292.0, 323.0, 294.0, 286.0, 221.0, 308.0, 96.0, 77.0, 54.0, 37.0, 192.0, 139.0, 334.0, 182.0, 260.0, 199.0, 22.0, 7.0, 111.0, 60.0, 361.0, 223.0, 210.0, 208.0, 231.0, 272.0, 104.0, 118.0, 274.0, 144.0, 22.0, 19.0, 9.0, 37.0, 28.0, 21.0, 0.0, 9.0, 1.0, 30.0, 254.0, 273.0, 156.0, 201.0, 13.0, 32.0, 6.0, 17.0, 8.0, 7.0, 128.0, 155.0, 71.0, 80.0, 19.0, 3.0, 301.0, 341.0, 143.0, 153.0, 80.0, 50.0, 10.0, 8.0, 10.0, 15.0, 10.0, 24.0, 18.0, 14.0, 34.0, 48.0, 21.0, 11.0, 11.0, 15.0, 93.0, 115.0, 26.0, 29.0, 58.0, 41.0, 60.0, 29.0, 131.0, 166.0, 19.0, 27.0, 13.0, 13.0, 20.0, 30.0, 3.0, 3.0, 14.0, 21.0, 5.0, 4.0, 13.0, 2.0, 7.0, 18.0, 10.0, 7.0, 20.0, 27.0, 14.0, 34.0, 13.0, 30.0, 1.0, 92.0, 9.0, 23.0, 2.0, 23.0, 65.0, 71.0, 10.0, 2.0, 0.0, 3.0, 16.0, 12.0, 1.0, 1.0, 28.0, 49.0, 8.0, 3.0, 6.0, 8.0, 23.0, 23.0, 23.0, 31.0, 72.0, 120.0, 31.0, 15.0, 12.0, 16.0, 3.0, 30.0, 73.0, 36.0, 9.0, 12.0, 5.0, 9.0, 15.0, 151.0, 3.0, 31.0, 8.0, 5.0, 7.0, 9.0, 50.0, 45.0, 11.0, 15.0, 42.0, 31.0, 19.0, 22.0, 37.0, 8.0, 8.0, 18.0, 13.0, 5.0, 5.0, 11.0, 36.0, 11.0, 5.0, 16.0, 9.0, 9.0, 7.0, 18.0, 8.0, 11.0, 6.0, 4.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5769259712478403, "mean_inference_ms": 1.8508435608551996, "mean_action_processing_ms": 0.23881302694165465, "mean_env_wait_ms": 0.1959114427066502, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0036519765853881836, "StateBufferConnector_ms": 0.00316011905670166, "ViewRequirementAgentConnector_ms": 0.09518313407897949}, "num_episodes": 23, "episode_return_max": 59.04999999999987, "episode_return_min": -374.77000000000004, "episode_return_mean": -42.88689999999999, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 160000, "num_agent_steps_trained": 160000, "num_env_steps_sampled": 40000, "num_env_steps_trained": 40000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 362.7558869612116, "num_env_steps_trained_throughput_per_sec": 362.7558869612116, "timesteps_total": 40000, "num_env_steps_sampled_lifetime": 40000, "num_agent_steps_sampled_lifetime": 160000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 160000, "timers": {"training_iteration_time_ms": 10545.209, "restore_workers_time_ms": 0.017, "training_step_time_ms": 10545.156, "sample_time_ms": 1362.031, "learn_time_ms": 9166.304, "learn_throughput": 436.381, "synch_weights_time_ms": 14.911}, "counters": {"num_env_steps_sampled": 40000, "num_env_steps_trained": 40000, "num_agent_steps_sampled": 160000, "num_agent_steps_trained": 160000}, "done": false, "training_iteration": 10, "trial_id": "8e499_00000", "date": "2024-08-15_02-06-05", "timestamp": 1723667765, "time_this_iter_s": 11.07619309425354, "time_total_s": 105.78660130500793, "pid": 33199, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b41cdc10>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 105.78660130500793, "iterations_since_restore": 10, "perf": {"cpu_util_percent": 32.62, "ram_util_percent": 83.30666666666666}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8984067132864049, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.4457821914127895, "policy_loss": -0.007836217216151969, "vf_loss": 2.4524158877039715, "vf_explained_var": 0.008396416839468415, "kl": 0.010689147543810399, "entropy": 1.458146838788633, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 19845.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6638165717796674, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.350810297267147, "policy_loss": -0.011986169701309076, "vf_loss": 2.3613327681072174, "vf_explained_var": 0.0032333014503357904, "kl": 0.014636985234690056, "entropy": 1.378180430868946, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 19845.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 44000, "num_env_steps_trained": 44000, "num_agent_steps_sampled": 176000, "num_agent_steps_trained": 176000}, "env_runners": {"episode_reward_max": 3.989999999999959, "episode_reward_min": -372.85000000000025, "episode_reward_mean": -35.15490000000001, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -617.97, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 2.0000000000000013, "predator_policy": 381.0}, "policy_reward_mean": {"prey_policy": -63.94244999999995, "predator_policy": 46.365}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-25.909999999999755, -211.94000000000045, -12.990000000000062, -128.18000000000018, 0.7800000000000026, -38.44000000000063, -21.369999999999553, -5.090000000000083, -25.29999999999945, -159.8399999999998, -36.419999999999966, -37.43000000000062, -19.22999999999942, -11.150000000000082, -68.72999999999958, -21.87999999999995, -18.219999999999427, -106.54999999999976, -83.90999999999998, -34.84000000000039, -4.1300000000000825, -9.190000000000081, -10.24000000000008, -0.18000000000003746, -10.48000000000007, -22.289999999999424, -22.25999999999942, -33.060000000000464, 0.709999999999987, -51.77000000000027, -27.599999999999547, -60.480000000000416, -42.46000000000067, -12.210000000000072, -24.38999999999945, -2.060000000000084, -31.350000000000474, -5.090000000000083, -9.14000000000008, -19.239999999999426, -1.1100000000000632, -45.4800000000007, -44.48000000000053, -39.43000000000069, -29.3899999999997, -28.319999999999432, -33.3100000000007, -38.81000000000026, -4.100000000000083, 0.9699999999999841, -8.200000000000081, 3.989999999999959, -35.58000000000057, -1.0800000000000622, 1.920000000000003, -2.260000000000077, -32.45000000000061, -55.24999999999998, -28.389999999999468, -24.279999999999458, -29.32999999999969, -57.849999999999845, -17.20999999999954, -6.120000000000083, -336.48000000000036, -30.34000000000006, 0.9199999999999823, -12.160000000000082, -25.619999999999497, -6.180000000000081, -49.63000000000065, -3.24000000000008, -41.45000000000064, -6.18000000000008, -6.1400000000000805, -12.160000000000082, -21.359999999999474, -31.280000000000484, 3.9099999999999606, -21.24999999999943, -1.1200000000000623, -6.100000000000083, -6.370000000000077, -54.979999999999926, -12.220000000000057, -0.08000000000004011, -372.85000000000025, -0.060000000000038335, -5.220000000000079, -155.62000000000023, -10.150000000000082, -0.08000000000004011, -18.309999999999864, -17.239999999999462, -43.53000000000069, -145.15999999999963, -16.199999999999417, 3.989999999999959, -17.279999999999458, -19.1699999999994], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-445.91, 2.0000000000000013, -291.3000000000004, -423.6400000000001, 2.0000000000000013, -236.9900000000002, -447.6800000000001, -98.49999999999936, -40.210000000000356, -0.009999999999998581, -12.070000000000041, -72.36999999999918, -46.24000000000028, -24.129999999999708, -16.089999999999705, 2.0000000000000013, -58.30000000000034, 2.0000000000000013, -273.3700000000006, -413.4700000000001, -351.20000000000005, -42.22000000000035, -8.050000000000042, -74.3799999999992, -32.170000000000364, -10.060000000000041, -14.080000000000041, -12.070000000000041, -341.66999999999996, -10.060000000000041, -174.8800000000004, 2.0000000000000013, -36.19000000000036, -4.030000000000042, -585.97, -162.58000000000038, -341.71000000000004, -38.20000000000005, 2.0000000000000013, -166.84000000000074, -18.099999999999703, -4.030000000000042, -6.040000000000042, -28.149999999999718, 2.0000000000000013, -46.24000000000035, 2.0000000000000013, -34.18000000000036, -94.47999999999922, 2.0000000000000013, -40.210000000000335, -14.080000000000041, -28.149999999999714, -20.109999999999705, -166.6800000000007, -74.3799999999992, 2.0000000000000013, -56.29000000000034, -34.18000000000032, -116.58999999999949, 2.0000000000000013, -118.59999999999928, -359.4800000000003, 2.0000000000000013, -66.33999999999916, -22.119999999999706, -24.129999999999708, -14.080000000000041, -44.23000000000034, -30.159999999999712, -4.030000000000042, -4.030000000000042, -26.139999999999713, -40.210000000000356, -8.05000000000004, -6.040000000000042, -0.00999999999999836, -24.129999999999715, -10.060000000000041, -34.180000000000355, -20.109999999999705, 2.0000000000000013, -40.210000000000356, -52.270000000000344, -64.32999999999923, -28.14999999999971, -44.23000000000035, -38.200000000000294, -0.009999999999998581, -122.37999999999917, -44.230000000000345, -16.0899999999997, -44.23000000000035, -14.080000000000041, -160.73000000000047, -14.080000000000041, 2.0000000000000013, -18.099999999999707, -4.030000000000042, 2.0000000000000013, -12.07000000000004, -24.129999999999708, -0.00999999999999836, 2.0000000000000013, -24.129999999999708, -88.44999999999924, -14.080000000000041, 2.0000000000000013, 2.0000000000000013, -14.080000000000041, 2.0000000000000013, -50.260000000000346, -14.080000000000041, -72.36999999999918, -241.21000000000012, -6.040000000000042, 2.0000000000000013, -76.38999999999919, -4.030000000000042, -48.2500000000003, -4.030000000000042, -58.30000000000033, -154.7799999999998, -12.070000000000041, -30.15999999999972, -8.050000000000042, 2.0000000000000013, -22.119999999999706, -277.35000000000014, -225.1300000000001, -4.030000000000042, -60.310000000000336, -14.080000000000041, 2.0000000000000013, -20.10999999999974, -8.050000000000042, -10.060000000000041, -110.55999999999932, -30.159999999999712, -2.0200000000000338, -40.210000000000335, -82.41999999999919, -42.220000000000354, -2.020000000000042, -14.080000000000041, -72.36999999999917, -28.14999999999971, -4.030000000000038, -26.13999999999971, 2.0000000000000013, -8.050000000000042, -20.109999999999705, -70.35999999999916, 2.0000000000000013, -30.159999999999712, -22.119999999999706, -16.0899999999997, 2.0000000000000013, -34.180000000000355, -12.070000000000041, -0.009999999999998581, -20.109999999999705, -10.060000000000041, -6.040000000000042, -0.00999999999999836, -70.35999999999916, -587.98, 2.0000000000000013, -14.080000000000041, -26.13999999999981, -14.080000000000041, 2.0000000000000013, -321.5299999999999, -271.32000000000005, 2.0000000000000013, -10.060000000000041, 2.0000000000000013, -42.220000000000354, -299.5000000000002, -22.119999999999706, -28.14999999999971, 2.0000000000000013, -14.080000000000041, 2.0000000000000013, -42.22000000000035, -16.08999999999992, -38.20000000000033, -6.040000000000042, -28.14999999999971, -74.37999999999917, -617.97, -237.1899999999996, -26.139999999999713, -10.060000000000041, -0.00999999999999836, 2.0000000000000013, -54.28000000000034, 2.0000000000000013, -18.099999999999703, -12.070000000000041], "policy_predator_policy_reward": [210.0, 208.0, 231.0, 272.0, 104.0, 118.0, 274.0, 144.0, 22.0, 19.0, 9.0, 37.0, 28.0, 21.0, 0.0, 9.0, 1.0, 30.0, 254.0, 273.0, 156.0, 201.0, 13.0, 32.0, 6.0, 17.0, 8.0, 7.0, 128.0, 155.0, 71.0, 80.0, 19.0, 3.0, 301.0, 341.0, 143.0, 153.0, 80.0, 50.0, 10.0, 8.0, 10.0, 15.0, 10.0, 24.0, 18.0, 14.0, 34.0, 48.0, 21.0, 11.0, 11.0, 15.0, 93.0, 115.0, 26.0, 29.0, 58.0, 41.0, 60.0, 29.0, 131.0, 166.0, 19.0, 27.0, 13.0, 13.0, 20.0, 30.0, 3.0, 3.0, 14.0, 21.0, 5.0, 4.0, 13.0, 2.0, 7.0, 18.0, 10.0, 7.0, 20.0, 27.0, 14.0, 34.0, 13.0, 30.0, 1.0, 92.0, 9.0, 23.0, 2.0, 23.0, 65.0, 71.0, 10.0, 2.0, 0.0, 3.0, 16.0, 12.0, 1.0, 1.0, 28.0, 49.0, 8.0, 3.0, 6.0, 8.0, 23.0, 23.0, 23.0, 31.0, 72.0, 120.0, 31.0, 15.0, 12.0, 16.0, 3.0, 30.0, 73.0, 36.0, 9.0, 12.0, 5.0, 9.0, 15.0, 151.0, 3.0, 31.0, 8.0, 5.0, 7.0, 9.0, 50.0, 45.0, 11.0, 15.0, 42.0, 31.0, 19.0, 22.0, 37.0, 8.0, 8.0, 18.0, 13.0, 5.0, 5.0, 11.0, 36.0, 11.0, 5.0, 16.0, 9.0, 9.0, 7.0, 18.0, 8.0, 11.0, 6.0, 4.0, 30.0, 34.0, 229.0, 302.0, 6.0, 22.0, 4.0, 8.0, 189.0, 31.0, 4.0, 4.0, 13.0, 22.0, 162.0, 4.0, 2.0, 14.0, 8.0, 4.0, 11.0, 29.0, 20.0, 7.0, 38.0, 21.0, 381.0, 329.0, 14.0, 6.0, 1.0, 1.0, 27.0, 8.0, 10.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.587595904276737, "mean_inference_ms": 1.8671524293080421, "mean_action_processing_ms": 0.23980204936334995, "mean_env_wait_ms": 0.19677641551928662, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005414843559265137, "StateBufferConnector_ms": 0.012192487716674805, "ViewRequirementAgentConnector_ms": 0.11753714084625244}, "num_episodes": 18, "episode_return_max": 3.989999999999959, "episode_return_min": -372.85000000000025, "episode_return_mean": -35.15490000000001, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 176000, "num_agent_steps_trained": 176000, "num_env_steps_sampled": 44000, "num_env_steps_trained": 44000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 323.3506630251109, "num_env_steps_trained_throughput_per_sec": 323.3506630251109, "timesteps_total": 44000, "num_env_steps_sampled_lifetime": 44000, "num_agent_steps_sampled_lifetime": 176000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 176000, "timers": {"training_iteration_time_ms": 10691.63, "restore_workers_time_ms": 0.016, "training_step_time_ms": 10691.586, "sample_time_ms": 1470.149, "learn_time_ms": 9204.736, "learn_throughput": 434.559, "synch_weights_time_ms": 15.057}, "counters": {"num_env_steps_sampled": 44000, "num_env_steps_trained": 44000, "num_agent_steps_sampled": 176000, "num_agent_steps_trained": 176000}, "done": false, "training_iteration": 11, "trial_id": "8e499_00000", "date": "2024-08-15_02-06-17", "timestamp": 1723667777, "time_this_iter_s": 12.377703189849854, "time_total_s": 118.16430449485779, "pid": 33199, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b43f2280>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 118.16430449485779, "iterations_since_restore": 11, "perf": {"cpu_util_percent": 42.03333333333333, "ram_util_percent": 82.70555555555555}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9239228817678633, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.792171805623978, "policy_loss": -0.009837313422874088, "vf_loss": 2.800237911088126, "vf_explained_var": 0.007349931815313914, "kl": 0.015743998134319606, "entropy": 1.4097018317570762, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 21735.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5744478153409781, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.2198311319111514, "policy_loss": -0.00979192945588794, "vf_loss": 2.2286907187214604, "vf_explained_var": 0.005656637432713988, "kl": 0.009323402823168044, "entropy": 1.3635492930967341, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 21735.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 48000, "num_env_steps_trained": 48000, "num_agent_steps_sampled": 192000, "num_agent_steps_trained": 192000}, "env_runners": {"episode_reward_max": 3.989999999999959, "episode_reward_min": -372.85000000000025, "episode_reward_mean": -34.351900000000015, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -617.97, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 2.0000000000000013, "predator_policy": 381.0}, "policy_reward_mean": {"prey_policy": -52.12094999999996, "predator_policy": 34.945}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-83.90999999999998, -34.84000000000039, -4.1300000000000825, -9.190000000000081, -10.24000000000008, -0.18000000000003746, -10.48000000000007, -22.289999999999424, -22.25999999999942, -33.060000000000464, 0.709999999999987, -51.77000000000027, -27.599999999999547, -60.480000000000416, -42.46000000000067, -12.210000000000072, -24.38999999999945, -2.060000000000084, -31.350000000000474, -5.090000000000083, -9.14000000000008, -19.239999999999426, -1.1100000000000632, -45.4800000000007, -44.48000000000053, -39.43000000000069, -29.3899999999997, -28.319999999999432, -33.3100000000007, -38.81000000000026, -4.100000000000083, 0.9699999999999841, -8.200000000000081, 3.989999999999959, -35.58000000000057, -1.0800000000000622, 1.920000000000003, -2.260000000000077, -32.45000000000061, -55.24999999999998, -28.389999999999468, -24.279999999999458, -29.32999999999969, -57.849999999999845, -17.20999999999954, -6.120000000000083, -336.48000000000036, -30.34000000000006, 0.9199999999999823, -12.160000000000082, -25.619999999999497, -6.180000000000081, -49.63000000000065, -3.24000000000008, -41.45000000000064, -6.18000000000008, -6.1400000000000805, -12.160000000000082, -21.359999999999474, -31.280000000000484, 3.9099999999999606, -21.24999999999943, -1.1200000000000623, -6.100000000000083, -6.370000000000077, -54.979999999999926, -12.220000000000057, -0.08000000000004011, -372.85000000000025, -0.060000000000038335, -5.220000000000079, -155.62000000000023, -10.150000000000082, -0.08000000000004011, -18.309999999999864, -17.239999999999462, -43.53000000000069, -145.15999999999963, -16.199999999999417, 3.989999999999959, -17.279999999999458, -19.1699999999994, -82.45999999999906, -31.74999999999975, -21.249999999999414, -173.69000000000068, -31.360000000000383, 1.9500000000000028, -86.9000000000003, -35.57000000000048, -18.19999999999941, -47.52000000000029, -50.43000000000069, -141.44000000000028, -45.539999999999715, -0.040000000000040996, -1.1900000000000295, -16.239999999999498, -75.79999999999902, -10.160000000000082], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-341.71000000000004, -38.20000000000005, 2.0000000000000013, -166.84000000000074, -18.099999999999703, -4.030000000000042, -6.040000000000042, -28.149999999999718, 2.0000000000000013, -46.24000000000035, 2.0000000000000013, -34.18000000000036, -94.47999999999922, 2.0000000000000013, -40.210000000000335, -14.080000000000041, -28.149999999999714, -20.109999999999705, -166.6800000000007, -74.3799999999992, 2.0000000000000013, -56.29000000000034, -34.18000000000032, -116.58999999999949, 2.0000000000000013, -118.59999999999928, -359.4800000000003, 2.0000000000000013, -66.33999999999916, -22.119999999999706, -24.129999999999708, -14.080000000000041, -44.23000000000034, -30.159999999999712, -4.030000000000042, -4.030000000000042, -26.139999999999713, -40.210000000000356, -8.05000000000004, -6.040000000000042, -0.00999999999999836, -24.129999999999715, -10.060000000000041, -34.180000000000355, -20.109999999999705, 2.0000000000000013, -40.210000000000356, -52.270000000000344, -64.32999999999923, -28.14999999999971, -44.23000000000035, -38.200000000000294, -0.009999999999998581, -122.37999999999917, -44.230000000000345, -16.0899999999997, -44.23000000000035, -14.080000000000041, -160.73000000000047, -14.080000000000041, 2.0000000000000013, -18.099999999999707, -4.030000000000042, 2.0000000000000013, -12.07000000000004, -24.129999999999708, -0.00999999999999836, 2.0000000000000013, -24.129999999999708, -88.44999999999924, -14.080000000000041, 2.0000000000000013, 2.0000000000000013, -14.080000000000041, 2.0000000000000013, -50.260000000000346, -14.080000000000041, -72.36999999999918, -241.21000000000012, -6.040000000000042, 2.0000000000000013, -76.38999999999919, -4.030000000000042, -48.2500000000003, -4.030000000000042, -58.30000000000033, -154.7799999999998, -12.070000000000041, -30.15999999999972, -8.050000000000042, 2.0000000000000013, -22.119999999999706, -277.35000000000014, -225.1300000000001, -4.030000000000042, -60.310000000000336, -14.080000000000041, 2.0000000000000013, -20.10999999999974, -8.050000000000042, -10.060000000000041, -110.55999999999932, -30.159999999999712, -2.0200000000000338, -40.210000000000335, -82.41999999999919, -42.220000000000354, -2.020000000000042, -14.080000000000041, -72.36999999999917, -28.14999999999971, -4.030000000000038, -26.13999999999971, 2.0000000000000013, -8.050000000000042, -20.109999999999705, -70.35999999999916, 2.0000000000000013, -30.159999999999712, -22.119999999999706, -16.0899999999997, 2.0000000000000013, -34.180000000000355, -12.070000000000041, -0.009999999999998581, -20.109999999999705, -10.060000000000041, -6.040000000000042, -0.00999999999999836, -70.35999999999916, -587.98, 2.0000000000000013, -14.080000000000041, -26.13999999999981, -14.080000000000041, 2.0000000000000013, -321.5299999999999, -271.32000000000005, 2.0000000000000013, -10.060000000000041, 2.0000000000000013, -42.220000000000354, -299.5000000000002, -22.119999999999706, -28.14999999999971, 2.0000000000000013, -14.080000000000041, 2.0000000000000013, -42.22000000000035, -16.08999999999992, -38.20000000000033, -6.040000000000042, -28.14999999999971, -74.37999999999917, -617.97, -237.1899999999996, -26.139999999999713, -10.060000000000041, -0.00999999999999836, 2.0000000000000013, -54.28000000000034, 2.0000000000000013, -18.099999999999703, -12.070000000000041, -291.4600000000005, 2.0000000000000013, -469.7500000000002, 2.0000000000000013, -26.13999999999971, -20.109999999999705, -118.6, -217.0900000000008, -60.31000000000033, -8.05000000000004, -8.050000000000042, 2.0000000000000013, -32.170000000000364, -144.7300000000003, -112.56999999999927, 2.0000000000000013, -12.070000000000041, -24.129999999999708, -14.080000000000041, -86.43999999999947, -38.20000000000033, -44.23000000000035, -38.20000000000036, -247.2400000000003, -16.0899999999997, -88.45000000000023, -6.040000000000042, 2.0000000000000013, -36.19000000000013, 2.0000000000000013, -26.13999999999975, -18.099999999999703, -88.40999999999956, -76.38999999999918, -24.129999999999708, -4.030000000000042], "policy_predator_policy_reward": [143.0, 153.0, 80.0, 50.0, 10.0, 8.0, 10.0, 15.0, 10.0, 24.0, 18.0, 14.0, 34.0, 48.0, 21.0, 11.0, 11.0, 15.0, 93.0, 115.0, 26.0, 29.0, 58.0, 41.0, 60.0, 29.0, 131.0, 166.0, 19.0, 27.0, 13.0, 13.0, 20.0, 30.0, 3.0, 3.0, 14.0, 21.0, 5.0, 4.0, 13.0, 2.0, 7.0, 18.0, 10.0, 7.0, 20.0, 27.0, 14.0, 34.0, 13.0, 30.0, 1.0, 92.0, 9.0, 23.0, 2.0, 23.0, 65.0, 71.0, 10.0, 2.0, 0.0, 3.0, 16.0, 12.0, 1.0, 1.0, 28.0, 49.0, 8.0, 3.0, 6.0, 8.0, 23.0, 23.0, 23.0, 31.0, 72.0, 120.0, 31.0, 15.0, 12.0, 16.0, 3.0, 30.0, 73.0, 36.0, 9.0, 12.0, 5.0, 9.0, 15.0, 151.0, 3.0, 31.0, 8.0, 5.0, 7.0, 9.0, 50.0, 45.0, 11.0, 15.0, 42.0, 31.0, 19.0, 22.0, 37.0, 8.0, 8.0, 18.0, 13.0, 5.0, 5.0, 11.0, 36.0, 11.0, 5.0, 16.0, 9.0, 9.0, 7.0, 18.0, 8.0, 11.0, 6.0, 4.0, 30.0, 34.0, 229.0, 302.0, 6.0, 22.0, 4.0, 8.0, 189.0, 31.0, 4.0, 4.0, 13.0, 22.0, 162.0, 4.0, 2.0, 14.0, 8.0, 4.0, 11.0, 29.0, 20.0, 7.0, 38.0, 21.0, 381.0, 329.0, 14.0, 6.0, 1.0, 1.0, 27.0, 8.0, 10.0, 1.0, 134.0, 73.0, 175.0, 261.0, 9.0, 16.0, 55.0, 107.0, 12.0, 25.0, 3.0, 5.0, 73.0, 17.0, 50.0, 25.0, 5.0, 13.0, 48.0, 5.0, 32.0, 0.0, 28.0, 116.0, 43.0, 16.0, 0.0, 4.0, 16.0, 17.0, 18.0, 10.0, 23.0, 66.0, 13.0, 5.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5988704005049573, "mean_inference_ms": 1.8866549318936348, "mean_action_processing_ms": 0.24126862681439007, "mean_env_wait_ms": 0.1981937999050431, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005461573600769043, "StateBufferConnector_ms": 0.012207984924316406, "ViewRequirementAgentConnector_ms": 0.12044310569763184}, "num_episodes": 18, "episode_return_max": 3.989999999999959, "episode_return_min": -372.85000000000025, "episode_return_mean": -34.351900000000015, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 192000, "num_agent_steps_trained": 192000, "num_env_steps_sampled": 48000, "num_env_steps_trained": 48000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 375.56622701785113, "num_env_steps_trained_throughput_per_sec": 375.56622701785113, "timesteps_total": 48000, "num_env_steps_sampled_lifetime": 48000, "num_agent_steps_sampled_lifetime": 192000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 192000, "timers": {"training_iteration_time_ms": 10715.908, "restore_workers_time_ms": 0.014, "training_step_time_ms": 10715.869, "sample_time_ms": 1469.862, "learn_time_ms": 9229.207, "learn_throughput": 433.407, "synch_weights_time_ms": 15.228}, "counters": {"num_env_steps_sampled": 48000, "num_env_steps_trained": 48000, "num_agent_steps_sampled": 192000, "num_agent_steps_trained": 192000}, "done": false, "training_iteration": 12, "trial_id": "8e499_00000", "date": "2024-08-15_02-06-28", "timestamp": 1723667788, "time_this_iter_s": 10.654818058013916, "time_total_s": 128.8191225528717, "pid": 33199, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b43f2dc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 128.8191225528717, "iterations_since_restore": 12, "perf": {"cpu_util_percent": 30.52, "ram_util_percent": 81.03999999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9410664857853026, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.9933534884736651, "policy_loss": -0.006434398293544454, "vf_loss": 0.998766754338981, "vf_explained_var": 0.007434135296988109, "kl": 0.009076726828276638, "entropy": 1.3874612860578708, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 23625.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.514449925547239, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.9094042914372588, "policy_loss": -0.01564453539633187, "vf_loss": 0.9243183371881959, "vf_explained_var": 0.012625773400856704, "kl": 0.007304889297692956, "entropy": 1.3008706768984517, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 23625.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 52000, "num_env_steps_trained": 52000, "num_agent_steps_sampled": 208000, "num_agent_steps_trained": 208000}, "env_runners": {"episode_reward_max": 3.989999999999959, "episode_reward_min": -372.85000000000025, "episode_reward_mean": -32.743200000000016, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -617.97, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 2.0000000000000013, "predator_policy": 381.0}, "policy_reward_mean": {"prey_policy": -46.786599999999964, "predator_policy": 30.415}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-31.350000000000474, -5.090000000000083, -9.14000000000008, -19.239999999999426, -1.1100000000000632, -45.4800000000007, -44.48000000000053, -39.43000000000069, -29.3899999999997, -28.319999999999432, -33.3100000000007, -38.81000000000026, -4.100000000000083, 0.9699999999999841, -8.200000000000081, 3.989999999999959, -35.58000000000057, -1.0800000000000622, 1.920000000000003, -2.260000000000077, -32.45000000000061, -55.24999999999998, -28.389999999999468, -24.279999999999458, -29.32999999999969, -57.849999999999845, -17.20999999999954, -6.120000000000083, -336.48000000000036, -30.34000000000006, 0.9199999999999823, -12.160000000000082, -25.619999999999497, -6.180000000000081, -49.63000000000065, -3.24000000000008, -41.45000000000064, -6.18000000000008, -6.1400000000000805, -12.160000000000082, -21.359999999999474, -31.280000000000484, 3.9099999999999606, -21.24999999999943, -1.1200000000000623, -6.100000000000083, -6.370000000000077, -54.979999999999926, -12.220000000000057, -0.08000000000004011, -372.85000000000025, -0.060000000000038335, -5.220000000000079, -155.62000000000023, -10.150000000000082, -0.08000000000004011, -18.309999999999864, -17.239999999999462, -43.53000000000069, -145.15999999999963, -16.199999999999417, 3.989999999999959, -17.279999999999458, -19.1699999999994, -82.45999999999906, -31.74999999999975, -21.249999999999414, -173.69000000000068, -31.360000000000383, 1.9500000000000028, -86.9000000000003, -35.57000000000048, -18.19999999999941, -47.52000000000029, -50.43000000000069, -141.44000000000028, -45.539999999999715, -0.040000000000040996, -1.1900000000000295, -16.239999999999498, -75.79999999999902, -10.160000000000082, -60.64000000000057, -18.219999999999448, -24.28999999999944, 0.969999999999981, -40.37000000000072, -32.36000000000065, -9.130000000000082, -5.1300000000000825, 1.9099999999999986, -18.249999999999435, -2.210000000000081, -2.060000000000084, -36.40000000000018, -10.140000000000082, -7.100000000000083, -18.219999999999462, -1.2200000000000588, -7.110000000000083], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-26.139999999999713, -40.210000000000356, -8.05000000000004, -6.040000000000042, -0.00999999999999836, -24.129999999999715, -10.060000000000041, -34.180000000000355, -20.109999999999705, 2.0000000000000013, -40.210000000000356, -52.270000000000344, -64.32999999999923, -28.14999999999971, -44.23000000000035, -38.200000000000294, -0.009999999999998581, -122.37999999999917, -44.230000000000345, -16.0899999999997, -44.23000000000035, -14.080000000000041, -160.73000000000047, -14.080000000000041, 2.0000000000000013, -18.099999999999707, -4.030000000000042, 2.0000000000000013, -12.07000000000004, -24.129999999999708, -0.00999999999999836, 2.0000000000000013, -24.129999999999708, -88.44999999999924, -14.080000000000041, 2.0000000000000013, 2.0000000000000013, -14.080000000000041, 2.0000000000000013, -50.260000000000346, -14.080000000000041, -72.36999999999918, -241.21000000000012, -6.040000000000042, 2.0000000000000013, -76.38999999999919, -4.030000000000042, -48.2500000000003, -4.030000000000042, -58.30000000000033, -154.7799999999998, -12.070000000000041, -30.15999999999972, -8.050000000000042, 2.0000000000000013, -22.119999999999706, -277.35000000000014, -225.1300000000001, -4.030000000000042, -60.310000000000336, -14.080000000000041, 2.0000000000000013, -20.10999999999974, -8.050000000000042, -10.060000000000041, -110.55999999999932, -30.159999999999712, -2.0200000000000338, -40.210000000000335, -82.41999999999919, -42.220000000000354, -2.020000000000042, -14.080000000000041, -72.36999999999917, -28.14999999999971, -4.030000000000038, -26.13999999999971, 2.0000000000000013, -8.050000000000042, -20.109999999999705, -70.35999999999916, 2.0000000000000013, -30.159999999999712, -22.119999999999706, -16.0899999999997, 2.0000000000000013, -34.180000000000355, -12.070000000000041, -0.009999999999998581, -20.109999999999705, -10.060000000000041, -6.040000000000042, -0.00999999999999836, -70.35999999999916, -587.98, 2.0000000000000013, -14.080000000000041, -26.13999999999981, -14.080000000000041, 2.0000000000000013, -321.5299999999999, -271.32000000000005, 2.0000000000000013, -10.060000000000041, 2.0000000000000013, -42.220000000000354, -299.5000000000002, -22.119999999999706, -28.14999999999971, 2.0000000000000013, -14.080000000000041, 2.0000000000000013, -42.22000000000035, -16.08999999999992, -38.20000000000033, -6.040000000000042, -28.14999999999971, -74.37999999999917, -617.97, -237.1899999999996, -26.139999999999713, -10.060000000000041, -0.00999999999999836, 2.0000000000000013, -54.28000000000034, 2.0000000000000013, -18.099999999999703, -12.070000000000041, -291.4600000000005, 2.0000000000000013, -469.7500000000002, 2.0000000000000013, -26.13999999999971, -20.109999999999705, -118.6, -217.0900000000008, -60.31000000000033, -8.05000000000004, -8.050000000000042, 2.0000000000000013, -32.170000000000364, -144.7300000000003, -112.56999999999927, 2.0000000000000013, -12.070000000000041, -24.129999999999708, -14.080000000000041, -86.43999999999947, -38.20000000000033, -44.23000000000035, -38.20000000000036, -247.2400000000003, -16.0899999999997, -88.45000000000023, -6.040000000000042, 2.0000000000000013, -36.19000000000013, 2.0000000000000013, -26.13999999999975, -18.099999999999703, -88.40999999999956, -76.38999999999918, -24.129999999999708, -4.030000000000042, -124.6299999999993, -0.00999999999999836, -32.170000000000314, -8.050000000000042, -8.050000000000042, -46.24000000000034, -2.020000000000042, -0.00999999999999836, -34.18000000000036, -36.190000000000346, -64.32999999999915, -4.030000000000042, -10.060000000000041, -12.070000000000041, -18.099999999999707, -4.0300000000000376, -219.06, -4.030000000000042, -6.040000000000042, -40.210000000000356, -40.210000000000356, 2.0000000000000013, -2.020000000000042, -6.040000000000042, -68.3499999999996, -8.050000000000042, -18.099999999999707, -6.040000000000042, -8.050000000000042, -8.050000000000042, -34.180000000000334, -6.04000000000004, 2.0000000000000013, -42.220000000000354, -10.060000000000041, -8.050000000000042], "policy_predator_policy_reward": [14.0, 21.0, 5.0, 4.0, 13.0, 2.0, 7.0, 18.0, 10.0, 7.0, 20.0, 27.0, 14.0, 34.0, 13.0, 30.0, 1.0, 92.0, 9.0, 23.0, 2.0, 23.0, 65.0, 71.0, 10.0, 2.0, 0.0, 3.0, 16.0, 12.0, 1.0, 1.0, 28.0, 49.0, 8.0, 3.0, 6.0, 8.0, 23.0, 23.0, 23.0, 31.0, 72.0, 120.0, 31.0, 15.0, 12.0, 16.0, 3.0, 30.0, 73.0, 36.0, 9.0, 12.0, 5.0, 9.0, 15.0, 151.0, 3.0, 31.0, 8.0, 5.0, 7.0, 9.0, 50.0, 45.0, 11.0, 15.0, 42.0, 31.0, 19.0, 22.0, 37.0, 8.0, 8.0, 18.0, 13.0, 5.0, 5.0, 11.0, 36.0, 11.0, 5.0, 16.0, 9.0, 9.0, 7.0, 18.0, 8.0, 11.0, 6.0, 4.0, 30.0, 34.0, 229.0, 302.0, 6.0, 22.0, 4.0, 8.0, 189.0, 31.0, 4.0, 4.0, 13.0, 22.0, 162.0, 4.0, 2.0, 14.0, 8.0, 4.0, 11.0, 29.0, 20.0, 7.0, 38.0, 21.0, 381.0, 329.0, 14.0, 6.0, 1.0, 1.0, 27.0, 8.0, 10.0, 1.0, 134.0, 73.0, 175.0, 261.0, 9.0, 16.0, 55.0, 107.0, 12.0, 25.0, 3.0, 5.0, 73.0, 17.0, 50.0, 25.0, 5.0, 13.0, 48.0, 5.0, 32.0, 0.0, 28.0, 116.0, 43.0, 16.0, 0.0, 4.0, 16.0, 17.0, 18.0, 10.0, 23.0, 66.0, 13.0, 5.0, 1.0, 63.0, 5.0, 17.0, 13.0, 17.0, 2.0, 1.0, 6.0, 24.0, 3.0, 33.0, 6.0, 7.0, 4.0, 13.0, 118.0, 107.0, 21.0, 7.0, 19.0, 17.0, 4.0, 2.0, 34.0, 6.0, 4.0, 10.0, 4.0, 5.0, 15.0, 7.0, 17.0, 22.0, 6.0, 5.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6098051636766177, "mean_inference_ms": 1.9056938710190587, "mean_action_processing_ms": 0.24279639625785798, "mean_env_wait_ms": 0.19990570642927938, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005461335182189941, "StateBufferConnector_ms": 0.01237499713897705, "ViewRequirementAgentConnector_ms": 0.11822509765625}, "num_episodes": 18, "episode_return_max": 3.989999999999959, "episode_return_min": -372.85000000000025, "episode_return_mean": -32.743200000000016, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 208000, "num_agent_steps_trained": 208000, "num_env_steps_sampled": 52000, "num_env_steps_trained": 52000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 387.30026977700845, "num_env_steps_trained_throughput_per_sec": 387.30026977700845, "timesteps_total": 52000, "num_env_steps_sampled_lifetime": 52000, "num_agent_steps_sampled_lifetime": 208000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 208000, "timers": {"training_iteration_time_ms": 10660.041, "restore_workers_time_ms": 0.013, "training_step_time_ms": 10660.003, "sample_time_ms": 1438.933, "learn_time_ms": 9204.32, "learn_throughput": 434.579, "synch_weights_time_ms": 15.262}, "counters": {"num_env_steps_sampled": 52000, "num_env_steps_trained": 52000, "num_agent_steps_sampled": 208000, "num_agent_steps_trained": 208000}, "done": false, "training_iteration": 13, "trial_id": "8e499_00000", "date": "2024-08-15_02-06-38", "timestamp": 1723667798, "time_this_iter_s": 10.334659099578857, "time_total_s": 139.15378165245056, "pid": 33199, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x15800f700>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 139.15378165245056, "iterations_since_restore": 13, "perf": {"cpu_util_percent": 27.71333333333333, "ram_util_percent": 81.28}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8563434030486162, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.2985290323300336, "policy_loss": -0.009368434832024847, "vf_loss": 1.3066095127945854, "vf_explained_var": 0.004239255442190422, "kl": 0.011448500796222076, "entropy": 1.4201199956041164, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 25515.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.49498515146434624, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.1165075617019462, "policy_loss": -0.01798391766604726, "vf_loss": 1.1335717257053133, "vf_explained_var": 0.0029097266298122506, "kl": 0.009197529772456841, "entropy": 1.2830033449268845, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 25515.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 56000, "num_env_steps_trained": 56000, "num_agent_steps_sampled": 224000, "num_agent_steps_trained": 224000}, "env_runners": {"episode_reward_max": 3.989999999999959, "episode_reward_min": -372.85000000000025, "episode_reward_mean": -33.36269999999997, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -617.97, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 2.0000000000000013, "predator_policy": 381.0}, "policy_reward_mean": {"prey_policy": -46.85634999999998, "predator_policy": 30.175}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-6.120000000000083, -336.48000000000036, -30.34000000000006, 0.9199999999999823, -12.160000000000082, -25.619999999999497, -6.180000000000081, -49.63000000000065, -3.24000000000008, -41.45000000000064, -6.18000000000008, -6.1400000000000805, -12.160000000000082, -21.359999999999474, -31.280000000000484, 3.9099999999999606, -21.24999999999943, -1.1200000000000623, -6.100000000000083, -6.370000000000077, -54.979999999999926, -12.220000000000057, -0.08000000000004011, -372.85000000000025, -0.060000000000038335, -5.220000000000079, -155.62000000000023, -10.150000000000082, -0.08000000000004011, -18.309999999999864, -17.239999999999462, -43.53000000000069, -145.15999999999963, -16.199999999999417, 3.989999999999959, -17.279999999999458, -19.1699999999994, -82.45999999999906, -31.74999999999975, -21.249999999999414, -173.69000000000068, -31.360000000000383, 1.9500000000000028, -86.9000000000003, -35.57000000000048, -18.19999999999941, -47.52000000000029, -50.43000000000069, -141.44000000000028, -45.539999999999715, -0.040000000000040996, -1.1900000000000295, -16.239999999999498, -75.79999999999902, -10.160000000000082, -60.64000000000057, -18.219999999999448, -24.28999999999944, 0.969999999999981, -40.37000000000072, -32.36000000000065, -9.130000000000082, -5.1300000000000825, 1.9099999999999986, -18.249999999999435, -2.210000000000081, -2.060000000000084, -36.40000000000018, -10.140000000000082, -7.100000000000083, -18.219999999999462, -1.2200000000000588, -7.110000000000083, -18.219999999999434, -45.4800000000007, -17.209999999999418, -66.65999999999951, -46.50000000000069, -14.179999999999746, -13.14999999999991, -3.150000000000081, -4.080000000000084, -54.58000000000063, 3.979999999999959, -34.47000000000059, -18.159999999999407, -25.299999999999436, -86.89999999999975, -85.88999999999882, -7.300000000000079, 2.9699999999999815, -24.279999999999443, -17.129999999999697, -5.070000000000084, -3.0900000000000825, -23.229999999999425, -20.239999999999412, 3.92999999999996, -4.080000000000078, -48.730000000000544], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [2.0000000000000013, -22.119999999999706, -277.35000000000014, -225.1300000000001, -4.030000000000042, -60.310000000000336, -14.080000000000041, 2.0000000000000013, -20.10999999999974, -8.050000000000042, -10.060000000000041, -110.55999999999932, -30.159999999999712, -2.0200000000000338, -40.210000000000335, -82.41999999999919, -42.220000000000354, -2.020000000000042, -14.080000000000041, -72.36999999999917, -28.14999999999971, -4.030000000000038, -26.13999999999971, 2.0000000000000013, -8.050000000000042, -20.109999999999705, -70.35999999999916, 2.0000000000000013, -30.159999999999712, -22.119999999999706, -16.0899999999997, 2.0000000000000013, -34.180000000000355, -12.070000000000041, -0.009999999999998581, -20.109999999999705, -10.060000000000041, -6.040000000000042, -0.00999999999999836, -70.35999999999916, -587.98, 2.0000000000000013, -14.080000000000041, -26.13999999999981, -14.080000000000041, 2.0000000000000013, -321.5299999999999, -271.32000000000005, 2.0000000000000013, -10.060000000000041, 2.0000000000000013, -42.220000000000354, -299.5000000000002, -22.119999999999706, -28.14999999999971, 2.0000000000000013, -14.080000000000041, 2.0000000000000013, -42.22000000000035, -16.08999999999992, -38.20000000000033, -6.040000000000042, -28.14999999999971, -74.37999999999917, -617.97, -237.1899999999996, -26.139999999999713, -10.060000000000041, -0.00999999999999836, 2.0000000000000013, -54.28000000000034, 2.0000000000000013, -18.099999999999703, -12.070000000000041, -291.4600000000005, 2.0000000000000013, -469.7500000000002, 2.0000000000000013, -26.13999999999971, -20.109999999999705, -118.6, -217.0900000000008, -60.31000000000033, -8.05000000000004, -8.050000000000042, 2.0000000000000013, -32.170000000000364, -144.7300000000003, -112.56999999999927, 2.0000000000000013, -12.070000000000041, -24.129999999999708, -14.080000000000041, -86.43999999999947, -38.20000000000033, -44.23000000000035, -38.20000000000036, -247.2400000000003, -16.0899999999997, -88.45000000000023, -6.040000000000042, 2.0000000000000013, -36.19000000000013, 2.0000000000000013, -26.13999999999975, -18.099999999999703, -88.40999999999956, -76.38999999999918, -24.129999999999708, -4.030000000000042, -124.6299999999993, -0.00999999999999836, -32.170000000000314, -8.050000000000042, -8.050000000000042, -46.24000000000034, -2.020000000000042, -0.00999999999999836, -34.18000000000036, -36.190000000000346, -64.32999999999915, -4.030000000000042, -10.060000000000041, -12.070000000000041, -18.099999999999707, -4.0300000000000376, -219.06, -4.030000000000042, -6.040000000000042, -40.210000000000356, -40.210000000000356, 2.0000000000000013, -2.020000000000042, -6.040000000000042, -68.3499999999996, -8.050000000000042, -18.099999999999707, -6.040000000000042, -8.050000000000042, -8.050000000000042, -34.180000000000334, -6.04000000000004, 2.0000000000000013, -42.220000000000354, -10.060000000000041, -8.050000000000042, -2.020000000000042, -38.20000000000036, -54.28000000000034, -38.20000000000036, -30.159999999999712, -8.050000000000042, -42.22000000000034, -86.4399999999992, -68.34999999999916, -28.14999999999971, -6.040000000000042, -26.13999999999971, -10.060000000000041, -16.0899999999997, 2.0000000000000013, -28.14999999999971, -8.050000000000042, -4.030000000000042, -80.40999999999921, -32.170000000000364, -2.020000000000042, 2.0000000000000013, 2.0000000000000013, -92.46999999999922, -12.070000000000041, -16.089999999999705, -16.0899999999997, -40.21000000000035, -4.030000000000042, -172.87000000000006, -0.00999999999999836, -174.880000000001, -8.050000000000042, -48.25000000000035, -4.030000000000042, 2.0000000000000013, -0.00999999999999836, -52.27000000000032, -313.1300000000008, 2.0000000000000013, -4.030000000000042, -6.040000000000042, 2.0000000000000013, -16.0899999999997, -24.129999999999722, -18.099999999999707, -22.119999999999706, -22.119999999999706, -12.070000000000041, 2.0000000000000013, -14.08000000000004, 2.0000000000000013, -12.070000000000041, -130.66000000000122], "policy_predator_policy_reward": [5.0, 9.0, 15.0, 151.0, 3.0, 31.0, 8.0, 5.0, 7.0, 9.0, 50.0, 45.0, 11.0, 15.0, 42.0, 31.0, 19.0, 22.0, 37.0, 8.0, 8.0, 18.0, 13.0, 5.0, 5.0, 11.0, 36.0, 11.0, 5.0, 16.0, 9.0, 9.0, 7.0, 18.0, 8.0, 11.0, 6.0, 4.0, 30.0, 34.0, 229.0, 302.0, 6.0, 22.0, 4.0, 8.0, 189.0, 31.0, 4.0, 4.0, 13.0, 22.0, 162.0, 4.0, 2.0, 14.0, 8.0, 4.0, 11.0, 29.0, 20.0, 7.0, 38.0, 21.0, 381.0, 329.0, 14.0, 6.0, 1.0, 1.0, 27.0, 8.0, 10.0, 1.0, 134.0, 73.0, 175.0, 261.0, 9.0, 16.0, 55.0, 107.0, 12.0, 25.0, 3.0, 5.0, 73.0, 17.0, 50.0, 25.0, 5.0, 13.0, 48.0, 5.0, 32.0, 0.0, 28.0, 116.0, 43.0, 16.0, 0.0, 4.0, 16.0, 17.0, 18.0, 10.0, 23.0, 66.0, 13.0, 5.0, 1.0, 63.0, 5.0, 17.0, 13.0, 17.0, 2.0, 1.0, 6.0, 24.0, 3.0, 33.0, 6.0, 7.0, 4.0, 13.0, 118.0, 107.0, 21.0, 7.0, 19.0, 17.0, 4.0, 2.0, 34.0, 6.0, 4.0, 10.0, 4.0, 5.0, 15.0, 7.0, 17.0, 22.0, 6.0, 5.0, 2.0, 20.0, 26.0, 21.0, 5.0, 16.0, 37.0, 25.0, 15.0, 35.0, 4.0, 14.0, 4.0, 9.0, 10.0, 13.0, 3.0, 5.0, 14.0, 44.0, 2.0, 2.0, 47.0, 9.0, 0.0, 10.0, 24.0, 7.0, 87.0, 3.0, 88.0, 1.0, 25.0, 24.0, 2.0, 3.0, 27.0, 1.0, 197.0, 97.0, 4.0, 1.0, 9.0, 2.0, 0.0, 19.0, 12.0, 12.0, 7.0, 7.0, 0.0, 8.0, 49.0, 45.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6258581596724252, "mean_inference_ms": 1.9290446093555718, "mean_action_processing_ms": 0.24462035466050425, "mean_env_wait_ms": 0.20239489542692798, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005568385124206543, "StateBufferConnector_ms": 0.012340545654296875, "ViewRequirementAgentConnector_ms": 0.11840736865997314}, "num_episodes": 27, "episode_return_max": 3.989999999999959, "episode_return_min": -372.85000000000025, "episode_return_mean": -33.36269999999997, "episodes_this_iter": 27}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 224000, "num_agent_steps_trained": 224000, "num_env_steps_sampled": 56000, "num_env_steps_trained": 56000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 385.0381830544392, "num_env_steps_trained_throughput_per_sec": 385.0381830544392, "timesteps_total": 56000, "num_env_steps_sampled_lifetime": 56000, "num_agent_steps_sampled_lifetime": 224000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 224000, "timers": {"training_iteration_time_ms": 10621.114, "restore_workers_time_ms": 0.013, "training_step_time_ms": 10621.077, "sample_time_ms": 1426.163, "learn_time_ms": 9178.533, "learn_throughput": 435.799, "synch_weights_time_ms": 14.967}, "counters": {"num_env_steps_sampled": 56000, "num_env_steps_trained": 56000, "num_agent_steps_sampled": 224000, "num_agent_steps_trained": 224000}, "done": false, "training_iteration": 14, "trial_id": "8e499_00000", "date": "2024-08-15_02-06-48", "timestamp": 1723667808, "time_this_iter_s": 10.394507884979248, "time_total_s": 149.5482895374298, "pid": 33199, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b43f2d30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 149.5482895374298, "iterations_since_restore": 14, "perf": {"cpu_util_percent": 27.9, "ram_util_percent": 80.56}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.820244630595679, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.3851054617809871, "policy_loss": -0.008159003529707512, "vf_loss": 0.3922576959727815, "vf_explained_var": 0.04273576824753373, "kl": 0.008949062484379383, "entropy": 1.4235823804108554, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 27405.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5579967058721989, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.3599293917365786, "policy_loss": -0.01093622154861728, "vf_loss": 0.3702286276125402, "vf_explained_var": 0.0061632242783036814, "kl": 0.006369865329785237, "entropy": 1.250941565743199, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 27405.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 60000, "num_env_steps_trained": 60000, "num_agent_steps_sampled": 240000, "num_agent_steps_trained": 240000}, "env_runners": {"episode_reward_max": 3.9999999999999587, "episode_reward_min": -372.85000000000025, "episode_reward_mean": -29.135499999999947, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -617.97, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 2.0000000000000013, "predator_policy": 381.0}, "policy_reward_mean": {"prey_policy": -43.07774999999999, "predator_policy": 28.51}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-6.100000000000083, -6.370000000000077, -54.979999999999926, -12.220000000000057, -0.08000000000004011, -372.85000000000025, -0.060000000000038335, -5.220000000000079, -155.62000000000023, -10.150000000000082, -0.08000000000004011, -18.309999999999864, -17.239999999999462, -43.53000000000069, -145.15999999999963, -16.199999999999417, 3.989999999999959, -17.279999999999458, -19.1699999999994, -82.45999999999906, -31.74999999999975, -21.249999999999414, -173.69000000000068, -31.360000000000383, 1.9500000000000028, -86.9000000000003, -35.57000000000048, -18.19999999999941, -47.52000000000029, -50.43000000000069, -141.44000000000028, -45.539999999999715, -0.040000000000040996, -1.1900000000000295, -16.239999999999498, -75.79999999999902, -10.160000000000082, -60.64000000000057, -18.219999999999448, -24.28999999999944, 0.969999999999981, -40.37000000000072, -32.36000000000065, -9.130000000000082, -5.1300000000000825, 1.9099999999999986, -18.249999999999435, -2.210000000000081, -2.060000000000084, -36.40000000000018, -10.140000000000082, -7.100000000000083, -18.219999999999462, -1.2200000000000588, -7.110000000000083, -18.219999999999434, -45.4800000000007, -17.209999999999418, -66.65999999999951, -46.50000000000069, -14.179999999999746, -13.14999999999991, -3.150000000000081, -4.080000000000084, -54.58000000000063, 3.979999999999959, -34.47000000000059, -18.159999999999407, -25.299999999999436, -86.89999999999975, -85.88999999999882, -7.300000000000079, 2.9699999999999815, -24.279999999999443, -17.129999999999697, -5.070000000000084, -3.0900000000000825, -23.229999999999425, -20.239999999999412, 3.92999999999996, -4.080000000000078, -48.730000000000544, -42.400000000000674, -14.179999999999746, -25.289999999999424, -3.110000000000082, -27.309999999999427, 3.9999999999999587, -29.339999999999712, 3.92999999999996, -26.29999999999944, -2.1700000000000745, 0.8899999999999827, -6.100000000000083, -6.350000000000076, -8.120000000000083, 1.9300000000000028, -7.110000000000083, -0.05000000000004011, 3.9199999999999604], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-10.060000000000041, -6.040000000000042, -0.00999999999999836, -70.35999999999916, -587.98, 2.0000000000000013, -14.080000000000041, -26.13999999999981, -14.080000000000041, 2.0000000000000013, -321.5299999999999, -271.32000000000005, 2.0000000000000013, -10.060000000000041, 2.0000000000000013, -42.220000000000354, -299.5000000000002, -22.119999999999706, -28.14999999999971, 2.0000000000000013, -14.080000000000041, 2.0000000000000013, -42.22000000000035, -16.08999999999992, -38.20000000000033, -6.040000000000042, -28.14999999999971, -74.37999999999917, -617.97, -237.1899999999996, -26.139999999999713, -10.060000000000041, -0.00999999999999836, 2.0000000000000013, -54.28000000000034, 2.0000000000000013, -18.099999999999703, -12.070000000000041, -291.4600000000005, 2.0000000000000013, -469.7500000000002, 2.0000000000000013, -26.13999999999971, -20.109999999999705, -118.6, -217.0900000000008, -60.31000000000033, -8.05000000000004, -8.050000000000042, 2.0000000000000013, -32.170000000000364, -144.7300000000003, -112.56999999999927, 2.0000000000000013, -12.070000000000041, -24.129999999999708, -14.080000000000041, -86.43999999999947, -38.20000000000033, -44.23000000000035, -38.20000000000036, -247.2400000000003, -16.0899999999997, -88.45000000000023, -6.040000000000042, 2.0000000000000013, -36.19000000000013, 2.0000000000000013, -26.13999999999975, -18.099999999999703, -88.40999999999956, -76.38999999999918, -24.129999999999708, -4.030000000000042, -124.6299999999993, -0.00999999999999836, -32.170000000000314, -8.050000000000042, -8.050000000000042, -46.24000000000034, -2.020000000000042, -0.00999999999999836, -34.18000000000036, -36.190000000000346, -64.32999999999915, -4.030000000000042, -10.060000000000041, -12.070000000000041, -18.099999999999707, -4.0300000000000376, -219.06, -4.030000000000042, -6.040000000000042, -40.210000000000356, -40.210000000000356, 2.0000000000000013, -2.020000000000042, -6.040000000000042, -68.3499999999996, -8.050000000000042, -18.099999999999707, -6.040000000000042, -8.050000000000042, -8.050000000000042, -34.180000000000334, -6.04000000000004, 2.0000000000000013, -42.220000000000354, -10.060000000000041, -8.050000000000042, -2.020000000000042, -38.20000000000036, -54.28000000000034, -38.20000000000036, -30.159999999999712, -8.050000000000042, -42.22000000000034, -86.4399999999992, -68.34999999999916, -28.14999999999971, -6.040000000000042, -26.13999999999971, -10.060000000000041, -16.0899999999997, 2.0000000000000013, -28.14999999999971, -8.050000000000042, -4.030000000000042, -80.40999999999921, -32.170000000000364, -2.020000000000042, 2.0000000000000013, 2.0000000000000013, -92.46999999999922, -12.070000000000041, -16.089999999999705, -16.0899999999997, -40.21000000000035, -4.030000000000042, -172.87000000000006, -0.00999999999999836, -174.880000000001, -8.050000000000042, -48.25000000000035, -4.030000000000042, 2.0000000000000013, -0.00999999999999836, -52.27000000000032, -313.1300000000008, 2.0000000000000013, -4.030000000000042, -6.040000000000042, 2.0000000000000013, -16.0899999999997, -24.129999999999722, -18.099999999999707, -22.119999999999706, -22.119999999999706, -12.070000000000041, 2.0000000000000013, -14.08000000000004, 2.0000000000000013, -12.070000000000041, -130.66000000000122, -22.11999999999973, -54.28000000000034, -28.14999999999971, -4.030000000000042, -44.23000000000035, -10.060000000000041, 2.0000000000000013, -20.109999999999705, -38.20000000000035, -20.109999999999705, 2.0000000000000013, 2.0000000000000013, -58.30000000000034, -6.040000000000042, 2.0000000000000013, -12.070000000000041, -26.13999999999971, -30.159999999999734, -6.040000000000042, -24.129999999999736, -20.109999999999705, 2.0000000000000013, -8.050000000000042, -8.050000000000042, 2.0000000000000013, -68.34999999999923, -16.0899999999997, -4.030000000000042, -12.070000000000041, 2.0000000000000013, -2.020000000000042, -16.0899999999997, 2.0000000000000013, -8.050000000000042, -14.080000000000041, 2.0000000000000013], "policy_predator_policy_reward": [6.0, 4.0, 30.0, 34.0, 229.0, 302.0, 6.0, 22.0, 4.0, 8.0, 189.0, 31.0, 4.0, 4.0, 13.0, 22.0, 162.0, 4.0, 2.0, 14.0, 8.0, 4.0, 11.0, 29.0, 20.0, 7.0, 38.0, 21.0, 381.0, 329.0, 14.0, 6.0, 1.0, 1.0, 27.0, 8.0, 10.0, 1.0, 134.0, 73.0, 175.0, 261.0, 9.0, 16.0, 55.0, 107.0, 12.0, 25.0, 3.0, 5.0, 73.0, 17.0, 50.0, 25.0, 5.0, 13.0, 48.0, 5.0, 32.0, 0.0, 28.0, 116.0, 43.0, 16.0, 0.0, 4.0, 16.0, 17.0, 18.0, 10.0, 23.0, 66.0, 13.0, 5.0, 1.0, 63.0, 5.0, 17.0, 13.0, 17.0, 2.0, 1.0, 6.0, 24.0, 3.0, 33.0, 6.0, 7.0, 4.0, 13.0, 118.0, 107.0, 21.0, 7.0, 19.0, 17.0, 4.0, 2.0, 34.0, 6.0, 4.0, 10.0, 4.0, 5.0, 15.0, 7.0, 17.0, 22.0, 6.0, 5.0, 2.0, 20.0, 26.0, 21.0, 5.0, 16.0, 37.0, 25.0, 15.0, 35.0, 4.0, 14.0, 4.0, 9.0, 10.0, 13.0, 3.0, 5.0, 14.0, 44.0, 2.0, 2.0, 47.0, 9.0, 0.0, 10.0, 24.0, 7.0, 87.0, 3.0, 88.0, 1.0, 25.0, 24.0, 2.0, 3.0, 27.0, 1.0, 197.0, 97.0, 4.0, 1.0, 9.0, 2.0, 0.0, 19.0, 12.0, 12.0, 7.0, 7.0, 0.0, 8.0, 49.0, 45.0, 28.0, 6.0, 3.0, 15.0, 6.0, 23.0, 4.0, 11.0, 20.0, 11.0, 0.0, 0.0, 13.0, 22.0, 7.0, 7.0, 2.0, 28.0, 13.0, 15.0, 11.0, 8.0, 5.0, 5.0, 27.0, 33.0, 3.0, 9.0, 7.0, 5.0, 2.0, 9.0, 5.0, 1.0, 8.0, 8.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6344708316772634, "mean_inference_ms": 1.9421656723572271, "mean_action_processing_ms": 0.2458626730372113, "mean_env_wait_ms": 0.20342629124903944, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055119991302490234, "StateBufferConnector_ms": 0.012247323989868164, "ViewRequirementAgentConnector_ms": 0.11633753776550293}, "num_episodes": 18, "episode_return_max": 3.9999999999999587, "episode_return_min": -372.85000000000025, "episode_return_mean": -29.135499999999947, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 240000, "num_agent_steps_trained": 240000, "num_env_steps_sampled": 60000, "num_env_steps_trained": 60000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 388.54012899495893, "num_env_steps_trained_throughput_per_sec": 388.54012899495893, "timesteps_total": 60000, "num_env_steps_sampled_lifetime": 60000, "num_agent_steps_sampled_lifetime": 240000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 240000, "timers": {"training_iteration_time_ms": 10626.053, "restore_workers_time_ms": 0.013, "training_step_time_ms": 10626.017, "sample_time_ms": 1413.196, "learn_time_ms": 9196.585, "learn_throughput": 434.944, "synch_weights_time_ms": 14.822}, "counters": {"num_env_steps_sampled": 60000, "num_env_steps_trained": 60000, "num_agent_steps_sampled": 240000, "num_agent_steps_trained": 240000}, "done": false, "training_iteration": 15, "trial_id": "8e499_00000", "date": "2024-08-15_02-06-59", "timestamp": 1723667819, "time_this_iter_s": 10.299357175827026, "time_total_s": 159.84764671325684, "pid": 33199, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x15800f4c0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 159.84764671325684, "iterations_since_restore": 15, "perf": {"cpu_util_percent": 28.478571428571428, "ram_util_percent": 80.41428571428571}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8284445108875396, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.7538035279859311, "policy_loss": -0.01049586874014013, "vf_loss": 0.7629962378905879, "vf_explained_var": 0.014896849507377262, "kl": 0.011583616833977692, "entropy": 1.3979595389946429, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 29295.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5121607218982366, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.6607000860065301, "policy_loss": -0.012871414535338917, "vf_loss": 0.6726116010278621, "vf_explained_var": -0.0020086843500692377, "kl": 0.009598982875165422, "entropy": 1.2684543077907866, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 29295.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 64000, "num_env_steps_trained": 64000, "num_agent_steps_sampled": 256000, "num_agent_steps_trained": 256000}, "env_runners": {"episode_reward_max": 3.9999999999999587, "episode_reward_min": -173.69000000000068, "episode_reward_mean": -22.86929999999993, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -469.7500000000002, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 2.0000000000000013, "predator_policy": 261.0}, "policy_reward_mean": {"prey_policy": -32.21465, "predator_policy": 20.78}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-19.1699999999994, -82.45999999999906, -31.74999999999975, -21.249999999999414, -173.69000000000068, -31.360000000000383, 1.9500000000000028, -86.9000000000003, -35.57000000000048, -18.19999999999941, -47.52000000000029, -50.43000000000069, -141.44000000000028, -45.539999999999715, -0.040000000000040996, -1.1900000000000295, -16.239999999999498, -75.79999999999902, -10.160000000000082, -60.64000000000057, -18.219999999999448, -24.28999999999944, 0.969999999999981, -40.37000000000072, -32.36000000000065, -9.130000000000082, -5.1300000000000825, 1.9099999999999986, -18.249999999999435, -2.210000000000081, -2.060000000000084, -36.40000000000018, -10.140000000000082, -7.100000000000083, -18.219999999999462, -1.2200000000000588, -7.110000000000083, -18.219999999999434, -45.4800000000007, -17.209999999999418, -66.65999999999951, -46.50000000000069, -14.179999999999746, -13.14999999999991, -3.150000000000081, -4.080000000000084, -54.58000000000063, 3.979999999999959, -34.47000000000059, -18.159999999999407, -25.299999999999436, -86.89999999999975, -85.88999999999882, -7.300000000000079, 2.9699999999999815, -24.279999999999443, -17.129999999999697, -5.070000000000084, -3.0900000000000825, -23.229999999999425, -20.239999999999412, 3.92999999999996, -4.080000000000078, -48.730000000000544, -42.400000000000674, -14.179999999999746, -25.289999999999424, -3.110000000000082, -27.309999999999427, 3.9999999999999587, -29.339999999999712, 3.92999999999996, -26.29999999999944, -2.1700000000000745, 0.8899999999999827, -6.100000000000083, -6.350000000000076, -8.120000000000083, 1.9300000000000028, -7.110000000000083, -0.05000000000004011, 3.9199999999999604, -18.219999999999423, -13.279999999999932, -8.15000000000008, -24.27999999999942, -13.21999999999994, -14.179999999999746, -30.270000000000113, -79.82999999999893, -1.050000000000063, 2.7799999999999856, -12.160000000000082, 0.959999999999989, -18.219999999999427, -7.1300000000000825, 0.9599999999999819, -3.1900000000000786, -6.120000000000081, -6.240000000000077], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-18.099999999999703, -12.070000000000041, -291.4600000000005, 2.0000000000000013, -469.7500000000002, 2.0000000000000013, -26.13999999999971, -20.109999999999705, -118.6, -217.0900000000008, -60.31000000000033, -8.05000000000004, -8.050000000000042, 2.0000000000000013, -32.170000000000364, -144.7300000000003, -112.56999999999927, 2.0000000000000013, -12.070000000000041, -24.129999999999708, -14.080000000000041, -86.43999999999947, -38.20000000000033, -44.23000000000035, -38.20000000000036, -247.2400000000003, -16.0899999999997, -88.45000000000023, -6.040000000000042, 2.0000000000000013, -36.19000000000013, 2.0000000000000013, -26.13999999999975, -18.099999999999703, -88.40999999999956, -76.38999999999918, -24.129999999999708, -4.030000000000042, -124.6299999999993, -0.00999999999999836, -32.170000000000314, -8.050000000000042, -8.050000000000042, -46.24000000000034, -2.020000000000042, -0.00999999999999836, -34.18000000000036, -36.190000000000346, -64.32999999999915, -4.030000000000042, -10.060000000000041, -12.070000000000041, -18.099999999999707, -4.0300000000000376, -219.06, -4.030000000000042, -6.040000000000042, -40.210000000000356, -40.210000000000356, 2.0000000000000013, -2.020000000000042, -6.040000000000042, -68.3499999999996, -8.050000000000042, -18.099999999999707, -6.040000000000042, -8.050000000000042, -8.050000000000042, -34.180000000000334, -6.04000000000004, 2.0000000000000013, -42.220000000000354, -10.060000000000041, -8.050000000000042, -2.020000000000042, -38.20000000000036, -54.28000000000034, -38.20000000000036, -30.159999999999712, -8.050000000000042, -42.22000000000034, -86.4399999999992, -68.34999999999916, -28.14999999999971, -6.040000000000042, -26.13999999999971, -10.060000000000041, -16.0899999999997, 2.0000000000000013, -28.14999999999971, -8.050000000000042, -4.030000000000042, -80.40999999999921, -32.170000000000364, -2.020000000000042, 2.0000000000000013, 2.0000000000000013, -92.46999999999922, -12.070000000000041, -16.089999999999705, -16.0899999999997, -40.21000000000035, -4.030000000000042, -172.87000000000006, -0.00999999999999836, -174.880000000001, -8.050000000000042, -48.25000000000035, -4.030000000000042, 2.0000000000000013, -0.00999999999999836, -52.27000000000032, -313.1300000000008, 2.0000000000000013, -4.030000000000042, -6.040000000000042, 2.0000000000000013, -16.0899999999997, -24.129999999999722, -18.099999999999707, -22.119999999999706, -22.119999999999706, -12.070000000000041, 2.0000000000000013, -14.08000000000004, 2.0000000000000013, -12.070000000000041, -130.66000000000122, -22.11999999999973, -54.28000000000034, -28.14999999999971, -4.030000000000042, -44.23000000000035, -10.060000000000041, 2.0000000000000013, -20.109999999999705, -38.20000000000035, -20.109999999999705, 2.0000000000000013, 2.0000000000000013, -58.30000000000034, -6.040000000000042, 2.0000000000000013, -12.070000000000041, -26.13999999999971, -30.159999999999734, -6.040000000000042, -24.129999999999736, -20.109999999999705, 2.0000000000000013, -8.050000000000042, -8.050000000000042, 2.0000000000000013, -68.34999999999923, -16.0899999999997, -4.030000000000042, -12.070000000000041, 2.0000000000000013, -2.020000000000042, -16.0899999999997, 2.0000000000000013, -8.050000000000042, -14.080000000000041, 2.0000000000000013, -18.099999999999714, -22.11999999999971, -14.080000000000041, -38.20000000000036, 2.0000000000000013, -28.14999999999971, -18.099999999999703, -34.180000000000355, -42.22000000000035, 2.0000000000000013, -8.050000000000042, -24.12999999999971, -24.129999999999708, -26.13999999999971, -156.79000000000093, -6.040000000000042, -2.0200000000000413, -4.030000000000042, 2.0000000000000013, -42.220000000000354, -10.060000000000041, -18.099999999999703, -2.020000000000038, -2.020000000000042, -4.030000000000042, -36.19000000000036, -16.0899999999997, -6.040000000000042, 2.0000000000000013, -6.040000000000042, -14.080000000000041, -20.10999999999972, -22.119999999999706, 2.0000000000000013, 2.0000000000000013, -46.24000000000034], "policy_predator_policy_reward": [10.0, 1.0, 134.0, 73.0, 175.0, 261.0, 9.0, 16.0, 55.0, 107.0, 12.0, 25.0, 3.0, 5.0, 73.0, 17.0, 50.0, 25.0, 5.0, 13.0, 48.0, 5.0, 32.0, 0.0, 28.0, 116.0, 43.0, 16.0, 0.0, 4.0, 16.0, 17.0, 18.0, 10.0, 23.0, 66.0, 13.0, 5.0, 1.0, 63.0, 5.0, 17.0, 13.0, 17.0, 2.0, 1.0, 6.0, 24.0, 3.0, 33.0, 6.0, 7.0, 4.0, 13.0, 118.0, 107.0, 21.0, 7.0, 19.0, 17.0, 4.0, 2.0, 34.0, 6.0, 4.0, 10.0, 4.0, 5.0, 15.0, 7.0, 17.0, 22.0, 6.0, 5.0, 2.0, 20.0, 26.0, 21.0, 5.0, 16.0, 37.0, 25.0, 15.0, 35.0, 4.0, 14.0, 4.0, 9.0, 10.0, 13.0, 3.0, 5.0, 14.0, 44.0, 2.0, 2.0, 47.0, 9.0, 0.0, 10.0, 24.0, 7.0, 87.0, 3.0, 88.0, 1.0, 25.0, 24.0, 2.0, 3.0, 27.0, 1.0, 197.0, 97.0, 4.0, 1.0, 9.0, 2.0, 0.0, 19.0, 12.0, 12.0, 7.0, 7.0, 0.0, 8.0, 49.0, 45.0, 28.0, 6.0, 3.0, 15.0, 6.0, 23.0, 4.0, 11.0, 20.0, 11.0, 0.0, 0.0, 13.0, 22.0, 7.0, 7.0, 2.0, 28.0, 13.0, 15.0, 11.0, 8.0, 5.0, 5.0, 27.0, 33.0, 3.0, 9.0, 7.0, 5.0, 2.0, 9.0, 5.0, 1.0, 8.0, 8.0, 10.0, 12.0, 22.0, 17.0, 15.0, 3.0, 18.0, 10.0, 22.0, 5.0, 5.0, 13.0, 14.0, 6.0, 4.0, 79.0, 2.0, 3.0, 22.0, 21.0, 10.0, 6.0, 2.0, 3.0, 19.0, 3.0, 8.0, 7.0, 4.0, 1.0, 19.0, 12.0, 12.0, 2.0, 19.0, 19.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6302057627277395, "mean_inference_ms": 1.9320024128257836, "mean_action_processing_ms": 0.24471249758647493, "mean_env_wait_ms": 0.2018495338391923, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0038776397705078125, "StateBufferConnector_ms": 0.0032118558883666992, "ViewRequirementAgentConnector_ms": 0.09760522842407227}, "num_episodes": 18, "episode_return_max": 3.9999999999999587, "episode_return_min": -173.69000000000068, "episode_return_mean": -22.86929999999993, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 256000, "num_agent_steps_trained": 256000, "num_env_steps_sampled": 64000, "num_env_steps_trained": 64000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 357.4996916639484, "num_env_steps_trained_throughput_per_sec": 357.4996916639484, "timesteps_total": 64000, "num_env_steps_sampled_lifetime": 64000, "num_agent_steps_sampled_lifetime": 256000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 256000, "timers": {"training_iteration_time_ms": 10731.858, "restore_workers_time_ms": 0.012, "training_step_time_ms": 10731.821, "sample_time_ms": 1419.462, "learn_time_ms": 9296.0, "learn_throughput": 430.293, "synch_weights_time_ms": 15.084}, "counters": {"num_env_steps_sampled": 64000, "num_env_steps_trained": 64000, "num_agent_steps_sampled": 256000, "num_agent_steps_trained": 256000}, "done": false, "training_iteration": 16, "trial_id": "8e499_00000", "date": "2024-08-15_02-07-10", "timestamp": 1723667830, "time_this_iter_s": 11.23758602142334, "time_total_s": 171.08523273468018, "pid": 33199, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b43f2160>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 171.08523273468018, "iterations_since_restore": 16, "perf": {"cpu_util_percent": 31.55, "ram_util_percent": 81.3125}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7946125604882442, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.36422162535329344, "policy_loss": -0.008204348299100443, "vf_loss": 0.37147650435744295, "vf_explained_var": 0.04387262432032792, "kl": 0.008439729558110245, "entropy": 1.3861883203819316, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 31185.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6371842554992153, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.3690149619637942, "policy_loss": -0.012541358138153713, "vf_loss": 0.38080326212377896, "vf_explained_var": 0.00968700130149801, "kl": 0.0075305867451427285, "entropy": 1.2332444099522142, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 31185.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 68000, "num_env_steps_trained": 68000, "num_agent_steps_sampled": 272000, "num_agent_steps_trained": 272000}, "env_runners": {"episode_reward_max": 3.9999999999999587, "episode_reward_min": -86.89999999999975, "episode_reward_mean": -15.553799999999942, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -313.1300000000008, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 2.0000000000000013, "predator_policy": 197.0}, "policy_reward_mean": {"prey_policy": -22.981899999999982, "predator_policy": 15.205}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-10.160000000000082, -60.64000000000057, -18.219999999999448, -24.28999999999944, 0.969999999999981, -40.37000000000072, -32.36000000000065, -9.130000000000082, -5.1300000000000825, 1.9099999999999986, -18.249999999999435, -2.210000000000081, -2.060000000000084, -36.40000000000018, -10.140000000000082, -7.100000000000083, -18.219999999999462, -1.2200000000000588, -7.110000000000083, -18.219999999999434, -45.4800000000007, -17.209999999999418, -66.65999999999951, -46.50000000000069, -14.179999999999746, -13.14999999999991, -3.150000000000081, -4.080000000000084, -54.58000000000063, 3.979999999999959, -34.47000000000059, -18.159999999999407, -25.299999999999436, -86.89999999999975, -85.88999999999882, -7.300000000000079, 2.9699999999999815, -24.279999999999443, -17.129999999999697, -5.070000000000084, -3.0900000000000825, -23.229999999999425, -20.239999999999412, 3.92999999999996, -4.080000000000078, -48.730000000000544, -42.400000000000674, -14.179999999999746, -25.289999999999424, -3.110000000000082, -27.309999999999427, 3.9999999999999587, -29.339999999999712, 3.92999999999996, -26.29999999999944, -2.1700000000000745, 0.8899999999999827, -6.100000000000083, -6.350000000000076, -8.120000000000083, 1.9300000000000028, -7.110000000000083, -0.05000000000004011, 3.9199999999999604, -18.219999999999423, -13.279999999999932, -8.15000000000008, -24.27999999999942, -13.21999999999994, -14.179999999999746, -30.270000000000113, -79.82999999999893, -1.050000000000063, 2.7799999999999856, -12.160000000000082, 0.959999999999989, -18.219999999999427, -7.1300000000000825, 0.9599999999999819, -3.1900000000000786, -6.120000000000081, -6.240000000000077, -3.4800000000000733, -5.100000000000083, -5.150000000000082, -9.100000000000083, -11.150000000000082, 1.8599999999999999, -10.140000000000082, -5.140000000000082, -9.150000000000082, -15.18999999999956, -6.250000000000078, -0.040000000000040996, -23.269999999999428, -11.150000000000084, -3.0800000000000827, 2.8899999999999832, -27.309999999999427, -5.100000000000083], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-24.129999999999708, -4.030000000000042, -124.6299999999993, -0.00999999999999836, -32.170000000000314, -8.050000000000042, -8.050000000000042, -46.24000000000034, -2.020000000000042, -0.00999999999999836, -34.18000000000036, -36.190000000000346, -64.32999999999915, -4.030000000000042, -10.060000000000041, -12.070000000000041, -18.099999999999707, -4.0300000000000376, -219.06, -4.030000000000042, -6.040000000000042, -40.210000000000356, -40.210000000000356, 2.0000000000000013, -2.020000000000042, -6.040000000000042, -68.3499999999996, -8.050000000000042, -18.099999999999707, -6.040000000000042, -8.050000000000042, -8.050000000000042, -34.180000000000334, -6.04000000000004, 2.0000000000000013, -42.220000000000354, -10.060000000000041, -8.050000000000042, -2.020000000000042, -38.20000000000036, -54.28000000000034, -38.20000000000036, -30.159999999999712, -8.050000000000042, -42.22000000000034, -86.4399999999992, -68.34999999999916, -28.14999999999971, -6.040000000000042, -26.13999999999971, -10.060000000000041, -16.0899999999997, 2.0000000000000013, -28.14999999999971, -8.050000000000042, -4.030000000000042, -80.40999999999921, -32.170000000000364, -2.020000000000042, 2.0000000000000013, 2.0000000000000013, -92.46999999999922, -12.070000000000041, -16.089999999999705, -16.0899999999997, -40.21000000000035, -4.030000000000042, -172.87000000000006, -0.00999999999999836, -174.880000000001, -8.050000000000042, -48.25000000000035, -4.030000000000042, 2.0000000000000013, -0.00999999999999836, -52.27000000000032, -313.1300000000008, 2.0000000000000013, -4.030000000000042, -6.040000000000042, 2.0000000000000013, -16.0899999999997, -24.129999999999722, -18.099999999999707, -22.119999999999706, -22.119999999999706, -12.070000000000041, 2.0000000000000013, -14.08000000000004, 2.0000000000000013, -12.070000000000041, -130.66000000000122, -22.11999999999973, -54.28000000000034, -28.14999999999971, -4.030000000000042, -44.23000000000035, -10.060000000000041, 2.0000000000000013, -20.109999999999705, -38.20000000000035, -20.109999999999705, 2.0000000000000013, 2.0000000000000013, -58.30000000000034, -6.040000000000042, 2.0000000000000013, -12.070000000000041, -26.13999999999971, -30.159999999999734, -6.040000000000042, -24.129999999999736, -20.109999999999705, 2.0000000000000013, -8.050000000000042, -8.050000000000042, 2.0000000000000013, -68.34999999999923, -16.0899999999997, -4.030000000000042, -12.070000000000041, 2.0000000000000013, -2.020000000000042, -16.0899999999997, 2.0000000000000013, -8.050000000000042, -14.080000000000041, 2.0000000000000013, -18.099999999999714, -22.11999999999971, -14.080000000000041, -38.20000000000036, 2.0000000000000013, -28.14999999999971, -18.099999999999703, -34.180000000000355, -42.22000000000035, 2.0000000000000013, -8.050000000000042, -24.12999999999971, -24.129999999999708, -26.13999999999971, -156.79000000000093, -6.040000000000042, -2.0200000000000413, -4.030000000000042, 2.0000000000000013, -42.220000000000354, -10.060000000000041, -18.099999999999703, -2.020000000000038, -2.020000000000042, -4.030000000000042, -36.19000000000036, -16.0899999999997, -6.040000000000042, 2.0000000000000013, -6.040000000000042, -14.080000000000041, -20.10999999999972, -22.119999999999706, 2.0000000000000013, 2.0000000000000013, -46.24000000000034, 2.0000000000000013, -94.47999999999922, -12.070000000000041, -4.030000000000042, 2.0000000000000013, -28.14999999999971, -10.060000000000041, -6.040000000000042, -14.080000000000041, -12.070000000000041, -26.13999999999971, 2.0000000000000013, -12.070000000000041, -12.070000000000041, -4.030000000000042, -20.109999999999705, -16.0899999999997, -10.060000000000041, -28.14999999999971, -6.040000000000042, -30.15999999999972, -16.0899999999997, -4.030000000000042, -0.00999999999999836, -8.050000000000042, -42.220000000000354, -14.080000000000041, -12.070000000000041, 2.0000000000000013, -14.080000000000041, 2.0000000000000013, -20.109999999999705, -22.11999999999971, -36.19000000000032, -18.099999999999703, 2.0000000000000013], "policy_predator_policy_reward": [13.0, 5.0, 1.0, 63.0, 5.0, 17.0, 13.0, 17.0, 2.0, 1.0, 6.0, 24.0, 3.0, 33.0, 6.0, 7.0, 4.0, 13.0, 118.0, 107.0, 21.0, 7.0, 19.0, 17.0, 4.0, 2.0, 34.0, 6.0, 4.0, 10.0, 4.0, 5.0, 15.0, 7.0, 17.0, 22.0, 6.0, 5.0, 2.0, 20.0, 26.0, 21.0, 5.0, 16.0, 37.0, 25.0, 15.0, 35.0, 4.0, 14.0, 4.0, 9.0, 10.0, 13.0, 3.0, 5.0, 14.0, 44.0, 2.0, 2.0, 47.0, 9.0, 0.0, 10.0, 24.0, 7.0, 87.0, 3.0, 88.0, 1.0, 25.0, 24.0, 2.0, 3.0, 27.0, 1.0, 197.0, 97.0, 4.0, 1.0, 9.0, 2.0, 0.0, 19.0, 12.0, 12.0, 7.0, 7.0, 0.0, 8.0, 49.0, 45.0, 28.0, 6.0, 3.0, 15.0, 6.0, 23.0, 4.0, 11.0, 20.0, 11.0, 0.0, 0.0, 13.0, 22.0, 7.0, 7.0, 2.0, 28.0, 13.0, 15.0, 11.0, 8.0, 5.0, 5.0, 27.0, 33.0, 3.0, 9.0, 7.0, 5.0, 2.0, 9.0, 5.0, 1.0, 8.0, 8.0, 10.0, 12.0, 22.0, 17.0, 15.0, 3.0, 18.0, 10.0, 22.0, 5.0, 5.0, 13.0, 14.0, 6.0, 4.0, 79.0, 2.0, 3.0, 22.0, 21.0, 10.0, 6.0, 2.0, 3.0, 19.0, 3.0, 8.0, 7.0, 4.0, 1.0, 19.0, 12.0, 12.0, 2.0, 19.0, 19.0, 42.0, 47.0, 4.0, 7.0, 9.0, 12.0, 3.0, 4.0, 8.0, 7.0, 13.0, 13.0, 7.0, 7.0, 8.0, 11.0, 9.0, 8.0, 15.0, 4.0, 21.0, 19.0, 1.0, 3.0, 7.0, 20.0, 7.0, 8.0, 1.0, 8.0, 11.0, 10.0, 19.0, 12.0, 2.0, 9.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6247834248541718, "mean_inference_ms": 1.91917277543646, "mean_action_processing_ms": 0.24331477550515657, "mean_env_wait_ms": 0.20021460334064764, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0037353038787841797, "StateBufferConnector_ms": 0.0031414031982421875, "ViewRequirementAgentConnector_ms": 0.09134745597839355}, "num_episodes": 18, "episode_return_max": 3.9999999999999587, "episode_return_min": -86.89999999999975, "episode_return_mean": -15.553799999999942, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 272000, "num_agent_steps_trained": 272000, "num_env_steps_sampled": 68000, "num_env_steps_trained": 68000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 390.7788739699271, "num_env_steps_trained_throughput_per_sec": 390.7788739699271, "timesteps_total": 68000, "num_env_steps_sampled_lifetime": 68000, "num_agent_steps_sampled_lifetime": 272000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 272000, "timers": {"training_iteration_time_ms": 10733.956, "restore_workers_time_ms": 0.012, "training_step_time_ms": 10733.92, "sample_time_ms": 1415.235, "learn_time_ms": 9302.434, "learn_throughput": 429.995, "synch_weights_time_ms": 15.051}, "counters": {"num_env_steps_sampled": 68000, "num_env_steps_trained": 68000, "num_agent_steps_sampled": 272000, "num_agent_steps_trained": 272000}, "done": false, "training_iteration": 17, "trial_id": "8e499_00000", "date": "2024-08-15_02-07-20", "timestamp": 1723667840, "time_this_iter_s": 10.240954160690308, "time_total_s": 181.32618689537048, "pid": 33199, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b41cde50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 181.32618689537048, "iterations_since_restore": 17, "perf": {"cpu_util_percent": 27.90666666666666, "ram_util_percent": 81.18666666666668}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7918452363875177, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.5198929446557211, "policy_loss": -0.010220432183557442, "vf_loss": 0.5285343276962599, "vf_explained_var": 0.04036697023129337, "kl": 0.014035996314978426, "entropy": 1.3869104356362076, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 33075.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5042586147075607, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.5203319945648897, "policy_loss": -0.014028454480739557, "vf_loss": 0.5334909281519084, "vf_explained_var": -0.010944052852650798, "kl": 0.008695211693162945, "entropy": 1.2260116088958013, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 33075.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 72000, "num_env_steps_trained": 72000, "num_agent_steps_sampled": 288000, "num_agent_steps_trained": 288000}, "env_runners": {"episode_reward_max": 3.9999999999999587, "episode_reward_min": -86.89999999999975, "episode_reward_mean": -13.328299999999926, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -313.1300000000008, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 2.0000000000000013, "predator_policy": 197.0}, "policy_reward_mean": {"prey_policy": -20.379149999999967, "predator_policy": 13.715}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-66.65999999999951, -46.50000000000069, -14.179999999999746, -13.14999999999991, -3.150000000000081, -4.080000000000084, -54.58000000000063, 3.979999999999959, -34.47000000000059, -18.159999999999407, -25.299999999999436, -86.89999999999975, -85.88999999999882, -7.300000000000079, 2.9699999999999815, -24.279999999999443, -17.129999999999697, -5.070000000000084, -3.0900000000000825, -23.229999999999425, -20.239999999999412, 3.92999999999996, -4.080000000000078, -48.730000000000544, -42.400000000000674, -14.179999999999746, -25.289999999999424, -3.110000000000082, -27.309999999999427, 3.9999999999999587, -29.339999999999712, 3.92999999999996, -26.29999999999944, -2.1700000000000745, 0.8899999999999827, -6.100000000000083, -6.350000000000076, -8.120000000000083, 1.9300000000000028, -7.110000000000083, -0.05000000000004011, 3.9199999999999604, -18.219999999999423, -13.279999999999932, -8.15000000000008, -24.27999999999942, -13.21999999999994, -14.179999999999746, -30.270000000000113, -79.82999999999893, -1.050000000000063, 2.7799999999999856, -12.160000000000082, 0.959999999999989, -18.219999999999427, -7.1300000000000825, 0.9599999999999819, -3.1900000000000786, -6.120000000000081, -6.240000000000077, -3.4800000000000733, -5.100000000000083, -5.150000000000082, -9.100000000000083, -11.150000000000082, 1.8599999999999999, -10.140000000000082, -5.140000000000082, -9.150000000000082, -15.18999999999956, -6.250000000000078, -0.040000000000040996, -23.269999999999428, -11.150000000000084, -3.0800000000000827, 2.8899999999999832, -27.309999999999427, -5.100000000000083, -13.159999999999906, -1.0500000000000622, -5.26000000000008, 0.8199999999999835, 3.9699999999999593, -3.1100000000000767, -2.060000000000084, -11.16000000000008, -12.160000000000082, 1.940000000000003, -7.140000000000082, -21.249999999999417, -3.0700000000000838, -6.270000000000078, -16.179999999999403, -0.09000000000003744, -21.289999999999424, -7.16000000000008, -12.450000000000077, -14.179999999999746, -9.150000000000082, 0.969999999999981], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-42.22000000000034, -86.4399999999992, -68.34999999999916, -28.14999999999971, -6.040000000000042, -26.13999999999971, -10.060000000000041, -16.0899999999997, 2.0000000000000013, -28.14999999999971, -8.050000000000042, -4.030000000000042, -80.40999999999921, -32.170000000000364, -2.020000000000042, 2.0000000000000013, 2.0000000000000013, -92.46999999999922, -12.070000000000041, -16.089999999999705, -16.0899999999997, -40.21000000000035, -4.030000000000042, -172.87000000000006, -0.00999999999999836, -174.880000000001, -8.050000000000042, -48.25000000000035, -4.030000000000042, 2.0000000000000013, -0.00999999999999836, -52.27000000000032, -313.1300000000008, 2.0000000000000013, -4.030000000000042, -6.040000000000042, 2.0000000000000013, -16.0899999999997, -24.129999999999722, -18.099999999999707, -22.119999999999706, -22.119999999999706, -12.070000000000041, 2.0000000000000013, -14.08000000000004, 2.0000000000000013, -12.070000000000041, -130.66000000000122, -22.11999999999973, -54.28000000000034, -28.14999999999971, -4.030000000000042, -44.23000000000035, -10.060000000000041, 2.0000000000000013, -20.109999999999705, -38.20000000000035, -20.109999999999705, 2.0000000000000013, 2.0000000000000013, -58.30000000000034, -6.040000000000042, 2.0000000000000013, -12.070000000000041, -26.13999999999971, -30.159999999999734, -6.040000000000042, -24.129999999999736, -20.109999999999705, 2.0000000000000013, -8.050000000000042, -8.050000000000042, 2.0000000000000013, -68.34999999999923, -16.0899999999997, -4.030000000000042, -12.070000000000041, 2.0000000000000013, -2.020000000000042, -16.0899999999997, 2.0000000000000013, -8.050000000000042, -14.080000000000041, 2.0000000000000013, -18.099999999999714, -22.11999999999971, -14.080000000000041, -38.20000000000036, 2.0000000000000013, -28.14999999999971, -18.099999999999703, -34.180000000000355, -42.22000000000035, 2.0000000000000013, -8.050000000000042, -24.12999999999971, -24.129999999999708, -26.13999999999971, -156.79000000000093, -6.040000000000042, -2.0200000000000413, -4.030000000000042, 2.0000000000000013, -42.220000000000354, -10.060000000000041, -18.099999999999703, -2.020000000000038, -2.020000000000042, -4.030000000000042, -36.19000000000036, -16.0899999999997, -6.040000000000042, 2.0000000000000013, -6.040000000000042, -14.080000000000041, -20.10999999999972, -22.119999999999706, 2.0000000000000013, 2.0000000000000013, -46.24000000000034, 2.0000000000000013, -94.47999999999922, -12.070000000000041, -4.030000000000042, 2.0000000000000013, -28.14999999999971, -10.060000000000041, -6.040000000000042, -14.080000000000041, -12.070000000000041, -26.13999999999971, 2.0000000000000013, -12.070000000000041, -12.070000000000041, -4.030000000000042, -20.109999999999705, -16.0899999999997, -10.060000000000041, -28.14999999999971, -6.040000000000042, -30.15999999999972, -16.0899999999997, -4.030000000000042, -0.00999999999999836, -8.050000000000042, -42.220000000000354, -14.080000000000041, -12.070000000000041, 2.0000000000000013, -14.080000000000041, 2.0000000000000013, -20.109999999999705, -22.11999999999971, -36.19000000000032, -18.099999999999703, 2.0000000000000013, -14.080000000000041, -14.080000000000041, 2.0000000000000013, -8.050000000000042, -22.119999999999706, -26.139999999999727, -34.18000000000036, 2.0000000000000013, 2.0000000000000013, -4.030000000000042, -4.030000000000042, -14.080000000000037, -6.040000000000042, -2.020000000000042, 2.0000000000000013, -30.159999999999712, -4.030000000000042, -24.129999999999708, 2.0000000000000013, -10.060000000000041, -16.0899999999997, -8.050000000000042, -22.119999999999706, -24.12999999999971, -12.070000000000041, 2.0000000000000013, 2.0000000000000013, -52.270000000000344, -18.099999999999703, -14.080000000000041, -2.0200000000000395, -12.070000000000041, -40.21000000000035, -14.080000000000041, -12.070000000000036, -16.0899999999997, -2.020000000000042, -84.4299999999992, -4.030000000000042, -28.14999999999971, -28.14999999999971, 2.0000000000000013, -4.030000000000042, 2.0000000000000013], "policy_predator_policy_reward": [37.0, 25.0, 15.0, 35.0, 4.0, 14.0, 4.0, 9.0, 10.0, 13.0, 3.0, 5.0, 14.0, 44.0, 2.0, 2.0, 47.0, 9.0, 0.0, 10.0, 24.0, 7.0, 87.0, 3.0, 88.0, 1.0, 25.0, 24.0, 2.0, 3.0, 27.0, 1.0, 197.0, 97.0, 4.0, 1.0, 9.0, 2.0, 0.0, 19.0, 12.0, 12.0, 7.0, 7.0, 0.0, 8.0, 49.0, 45.0, 28.0, 6.0, 3.0, 15.0, 6.0, 23.0, 4.0, 11.0, 20.0, 11.0, 0.0, 0.0, 13.0, 22.0, 7.0, 7.0, 2.0, 28.0, 13.0, 15.0, 11.0, 8.0, 5.0, 5.0, 27.0, 33.0, 3.0, 9.0, 7.0, 5.0, 2.0, 9.0, 5.0, 1.0, 8.0, 8.0, 10.0, 12.0, 22.0, 17.0, 15.0, 3.0, 18.0, 10.0, 22.0, 5.0, 5.0, 13.0, 14.0, 6.0, 4.0, 79.0, 2.0, 3.0, 22.0, 21.0, 10.0, 6.0, 2.0, 3.0, 19.0, 3.0, 8.0, 7.0, 4.0, 1.0, 19.0, 12.0, 12.0, 2.0, 19.0, 19.0, 42.0, 47.0, 4.0, 7.0, 9.0, 12.0, 3.0, 4.0, 8.0, 7.0, 13.0, 13.0, 7.0, 7.0, 8.0, 11.0, 9.0, 8.0, 15.0, 4.0, 21.0, 19.0, 1.0, 3.0, 7.0, 20.0, 7.0, 8.0, 1.0, 8.0, 11.0, 10.0, 19.0, 12.0, 2.0, 9.0, 7.0, 8.0, 0.0, 5.0, 21.0, 22.0, 15.0, 18.0, 3.0, 3.0, 11.0, 4.0, 2.0, 4.0, 16.0, 1.0, 3.0, 13.0, 6.0, 4.0, 9.0, 8.0, 12.0, 13.0, 0.0, 7.0, 24.0, 20.0, 6.0, 10.0, 7.0, 7.0, 13.0, 20.0, 9.0, 12.0, 42.0, 32.0, 3.0, 15.0, 14.0, 3.0, 3.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6186226401680367, "mean_inference_ms": 1.9048009512486113, "mean_action_processing_ms": 0.24191546117423057, "mean_env_wait_ms": 0.1986001739766883, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003777623176574707, "StateBufferConnector_ms": 0.0029900074005126953, "ViewRequirementAgentConnector_ms": 0.09178638458251953}, "num_episodes": 22, "episode_return_max": 3.9999999999999587, "episode_return_min": -86.89999999999975, "episode_return_mean": -13.328299999999926, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 288000, "num_agent_steps_trained": 288000, "num_env_steps_sampled": 72000, "num_env_steps_trained": 72000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 400.6714055315585, "num_env_steps_trained_throughput_per_sec": 400.6714055315585, "timesteps_total": 72000, "num_env_steps_sampled_lifetime": 72000, "num_agent_steps_sampled_lifetime": 288000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 288000, "timers": {"training_iteration_time_ms": 10715.93, "restore_workers_time_ms": 0.012, "training_step_time_ms": 10715.895, "sample_time_ms": 1423.048, "learn_time_ms": 9276.795, "learn_throughput": 431.183, "synch_weights_time_ms": 15.027}, "counters": {"num_env_steps_sampled": 72000, "num_env_steps_trained": 72000, "num_agent_steps_sampled": 288000, "num_agent_steps_trained": 288000}, "done": false, "training_iteration": 18, "trial_id": "8e499_00000", "date": "2024-08-15_02-07-30", "timestamp": 1723667850, "time_this_iter_s": 9.986817121505737, "time_total_s": 191.31300401687622, "pid": 33199, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b43f30d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 191.31300401687622, "iterations_since_restore": 18, "perf": {"cpu_util_percent": 27.88571428571429, "ram_util_percent": 80.96428571428571}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8576961555966625, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.5651143432136566, "policy_loss": -0.00750051675889168, "vf_loss": 0.571388850554272, "vf_explained_var": 0.02545853058497111, "kl": 0.010897880461471499, "entropy": 1.407502626237415, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 34965.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5068781623173327, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.5535717404123042, "policy_loss": -0.014434161033264543, "vf_loss": 0.567490150478161, "vf_explained_var": -0.0068995076512533525, "kl": 0.005157508777759457, "entropy": 1.2166764190588049, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 34965.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 76000, "num_env_steps_trained": 76000, "num_agent_steps_sampled": 304000, "num_agent_steps_trained": 304000}, "env_runners": {"episode_reward_max": 3.9999999999999587, "episode_reward_min": -79.82999999999893, "episode_reward_mean": -11.530199999999912, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -156.79000000000093, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 2.0000000000000013, "predator_policy": 79.0}, "policy_reward_mean": {"prey_policy": -17.11509999999998, "predator_policy": 11.35}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-48.730000000000544, -42.400000000000674, -14.179999999999746, -25.289999999999424, -3.110000000000082, -27.309999999999427, 3.9999999999999587, -29.339999999999712, 3.92999999999996, -26.29999999999944, -2.1700000000000745, 0.8899999999999827, -6.100000000000083, -6.350000000000076, -8.120000000000083, 1.9300000000000028, -7.110000000000083, -0.05000000000004011, 3.9199999999999604, -18.219999999999423, -13.279999999999932, -8.15000000000008, -24.27999999999942, -13.21999999999994, -14.179999999999746, -30.270000000000113, -79.82999999999893, -1.050000000000063, 2.7799999999999856, -12.160000000000082, 0.959999999999989, -18.219999999999427, -7.1300000000000825, 0.9599999999999819, -3.1900000000000786, -6.120000000000081, -6.240000000000077, -3.4800000000000733, -5.100000000000083, -5.150000000000082, -9.100000000000083, -11.150000000000082, 1.8599999999999999, -10.140000000000082, -5.140000000000082, -9.150000000000082, -15.18999999999956, -6.250000000000078, -0.040000000000040996, -23.269999999999428, -11.150000000000084, -3.0800000000000827, 2.8899999999999832, -27.309999999999427, -5.100000000000083, -13.159999999999906, -1.0500000000000622, -5.26000000000008, 0.8199999999999835, 3.9699999999999593, -3.1100000000000767, -2.060000000000084, -11.16000000000008, -12.160000000000082, 1.940000000000003, -7.140000000000082, -21.249999999999417, -3.0700000000000838, -6.270000000000078, -16.179999999999403, -0.09000000000003744, -21.289999999999424, -7.16000000000008, -12.450000000000077, -14.179999999999746, -9.150000000000082, 0.969999999999981, -70.7799999999987, -12.160000000000078, 0.9199999999999827, -0.040000000000040996, -9.130000000000082, -18.219999999999427, -24.279999999999465, -10.140000000000082, -48.5200000000006, -1.0700000000000631, -27.309999999999434, -18.21999999999942, -4.080000000000084, -4.090000000000082, -17.229999999999436, -21.249999999999417, -9.140000000000082, -19.22999999999943, -24.27999999999945, -5.110000000000083, -14.179999999999739, -7.100000000000083, -2.110000000000081], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-12.070000000000041, -130.66000000000122, -22.11999999999973, -54.28000000000034, -28.14999999999971, -4.030000000000042, -44.23000000000035, -10.060000000000041, 2.0000000000000013, -20.109999999999705, -38.20000000000035, -20.109999999999705, 2.0000000000000013, 2.0000000000000013, -58.30000000000034, -6.040000000000042, 2.0000000000000013, -12.070000000000041, -26.13999999999971, -30.159999999999734, -6.040000000000042, -24.129999999999736, -20.109999999999705, 2.0000000000000013, -8.050000000000042, -8.050000000000042, 2.0000000000000013, -68.34999999999923, -16.0899999999997, -4.030000000000042, -12.070000000000041, 2.0000000000000013, -2.020000000000042, -16.0899999999997, 2.0000000000000013, -8.050000000000042, -14.080000000000041, 2.0000000000000013, -18.099999999999714, -22.11999999999971, -14.080000000000041, -38.20000000000036, 2.0000000000000013, -28.14999999999971, -18.099999999999703, -34.180000000000355, -42.22000000000035, 2.0000000000000013, -8.050000000000042, -24.12999999999971, -24.129999999999708, -26.13999999999971, -156.79000000000093, -6.040000000000042, -2.0200000000000413, -4.030000000000042, 2.0000000000000013, -42.220000000000354, -10.060000000000041, -18.099999999999703, -2.020000000000038, -2.020000000000042, -4.030000000000042, -36.19000000000036, -16.0899999999997, -6.040000000000042, 2.0000000000000013, -6.040000000000042, -14.080000000000041, -20.10999999999972, -22.119999999999706, 2.0000000000000013, 2.0000000000000013, -46.24000000000034, 2.0000000000000013, -94.47999999999922, -12.070000000000041, -4.030000000000042, 2.0000000000000013, -28.14999999999971, -10.060000000000041, -6.040000000000042, -14.080000000000041, -12.070000000000041, -26.13999999999971, 2.0000000000000013, -12.070000000000041, -12.070000000000041, -4.030000000000042, -20.109999999999705, -16.0899999999997, -10.060000000000041, -28.14999999999971, -6.040000000000042, -30.15999999999972, -16.0899999999997, -4.030000000000042, -0.00999999999999836, -8.050000000000042, -42.220000000000354, -14.080000000000041, -12.070000000000041, 2.0000000000000013, -14.080000000000041, 2.0000000000000013, -20.109999999999705, -22.11999999999971, -36.19000000000032, -18.099999999999703, 2.0000000000000013, -14.080000000000041, -14.080000000000041, 2.0000000000000013, -8.050000000000042, -22.119999999999706, -26.139999999999727, -34.18000000000036, 2.0000000000000013, 2.0000000000000013, -4.030000000000042, -4.030000000000042, -14.080000000000037, -6.040000000000042, -2.020000000000042, 2.0000000000000013, -30.159999999999712, -4.030000000000042, -24.129999999999708, 2.0000000000000013, -10.060000000000041, -16.0899999999997, -8.050000000000042, -22.119999999999706, -24.12999999999971, -12.070000000000041, 2.0000000000000013, 2.0000000000000013, -52.270000000000344, -18.099999999999703, -14.080000000000041, -2.0200000000000395, -12.070000000000041, -40.21000000000035, -14.080000000000041, -12.070000000000036, -16.0899999999997, -2.020000000000042, -84.4299999999992, -4.030000000000042, -28.14999999999971, -28.14999999999971, 2.0000000000000013, -4.030000000000042, 2.0000000000000013, -142.72000000000116, -10.060000000000041, -22.119999999999706, -6.040000000000042, 2.0000000000000013, -14.080000000000041, -4.030000000000042, -0.00999999999999836, -20.109999999999708, -2.020000000000042, -32.170000000000364, -8.050000000000042, -52.27000000000033, -0.00999999999999836, -6.040000000000042, -18.099999999999707, 2.0000000000000013, -102.51999999999924, -0.00999999999999836, -10.060000000000041, -8.050000000000042, -50.260000000000346, -10.060000000000041, -30.159999999999712, -10.060000000000041, -2.020000000000042, 2.0000000000000013, -16.0899999999997, -10.060000000000041, -32.17000000000035, -34.18000000000034, -12.070000000000041, -4.030000000000042, -20.109999999999705, -14.080000000000041, -28.149999999999718, -2.020000000000042, -50.260000000000346, 2.0000000000000013, -20.109999999999705, -10.060000000000041, -22.119999999999706, -10.060000000000041, -6.040000000000042, 2.0000000000000013, -20.109999999999705], "policy_predator_policy_reward": [49.0, 45.0, 28.0, 6.0, 3.0, 15.0, 6.0, 23.0, 4.0, 11.0, 20.0, 11.0, 0.0, 0.0, 13.0, 22.0, 7.0, 7.0, 2.0, 28.0, 13.0, 15.0, 11.0, 8.0, 5.0, 5.0, 27.0, 33.0, 3.0, 9.0, 7.0, 5.0, 2.0, 9.0, 5.0, 1.0, 8.0, 8.0, 10.0, 12.0, 22.0, 17.0, 15.0, 3.0, 18.0, 10.0, 22.0, 5.0, 5.0, 13.0, 14.0, 6.0, 4.0, 79.0, 2.0, 3.0, 22.0, 21.0, 10.0, 6.0, 2.0, 3.0, 19.0, 3.0, 8.0, 7.0, 4.0, 1.0, 19.0, 12.0, 12.0, 2.0, 19.0, 19.0, 42.0, 47.0, 4.0, 7.0, 9.0, 12.0, 3.0, 4.0, 8.0, 7.0, 13.0, 13.0, 7.0, 7.0, 8.0, 11.0, 9.0, 8.0, 15.0, 4.0, 21.0, 19.0, 1.0, 3.0, 7.0, 20.0, 7.0, 8.0, 1.0, 8.0, 11.0, 10.0, 19.0, 12.0, 2.0, 9.0, 7.0, 8.0, 0.0, 5.0, 21.0, 22.0, 15.0, 18.0, 3.0, 3.0, 11.0, 4.0, 2.0, 4.0, 16.0, 1.0, 3.0, 13.0, 6.0, 4.0, 9.0, 8.0, 12.0, 13.0, 0.0, 7.0, 24.0, 20.0, 6.0, 10.0, 7.0, 7.0, 13.0, 20.0, 9.0, 12.0, 42.0, 32.0, 3.0, 15.0, 14.0, 3.0, 3.0, 0.0, 39.0, 43.0, 4.0, 12.0, 8.0, 5.0, 1.0, 3.0, 4.0, 9.0, 15.0, 7.0, 25.0, 3.0, 10.0, 4.0, 52.0, 0.0, 4.0, 5.0, 21.0, 10.0, 16.0, 6.0, 2.0, 6.0, 9.0, 1.0, 15.0, 10.0, 14.0, 11.0, 4.0, 11.0, 17.0, 6.0, 2.0, 26.0, 11.0, 2.0, 12.0, 6.0, 1.0, 8.0, 11.0, 5.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6138390967321296, "mean_inference_ms": 1.8931910450891933, "mean_action_processing_ms": 0.24068405947654578, "mean_env_wait_ms": 0.19676472809377332, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003686666488647461, "StateBufferConnector_ms": 0.0031489133834838867, "ViewRequirementAgentConnector_ms": 0.09271788597106934}, "num_episodes": 23, "episode_return_max": 3.9999999999999587, "episode_return_min": -79.82999999999893, "episode_return_mean": -11.530199999999912, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 304000, "num_agent_steps_trained": 304000, "num_env_steps_sampled": 76000, "num_env_steps_trained": 76000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 399.2464175133301, "num_env_steps_trained_throughput_per_sec": 399.2464175133301, "timesteps_total": 76000, "num_env_steps_sampled_lifetime": 76000, "num_agent_steps_sampled_lifetime": 304000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 304000, "timers": {"training_iteration_time_ms": 10648.616, "restore_workers_time_ms": 0.012, "training_step_time_ms": 10648.581, "sample_time_ms": 1413.376, "learn_time_ms": 9218.988, "learn_throughput": 433.887, "synch_weights_time_ms": 15.228}, "counters": {"num_env_steps_sampled": 76000, "num_env_steps_trained": 76000, "num_agent_steps_sampled": 304000, "num_agent_steps_trained": 304000}, "done": false, "training_iteration": 19, "trial_id": "8e499_00000", "date": "2024-08-15_02-07-40", "timestamp": 1723667860, "time_this_iter_s": 10.023910284042358, "time_total_s": 201.33691430091858, "pid": 33199, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b43f0790>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 201.33691430091858, "iterations_since_restore": 19, "perf": {"cpu_util_percent": 27.757142857142856, "ram_util_percent": 81.0642857142857}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7763468476436125, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.27675896803971634, "policy_loss": -0.007396558385647873, "vf_loss": 0.2834787958657625, "vf_explained_var": 0.06833005796664607, "kl": 0.006015385042076045, "entropy": 1.3997700030210787, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 36855.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5661513967212861, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.2991408703979918, "policy_loss": -0.009138711518731224, "vf_loss": 0.3074042068593569, "vf_explained_var": 0.02217725953727803, "kl": 0.008753743745856574, "entropy": 1.2499270861741727, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 36855.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 80000, "num_env_steps_trained": 80000, "num_agent_steps_sampled": 320000, "num_agent_steps_trained": 320000}, "env_runners": {"episode_reward_max": 3.979999999999959, "episode_reward_min": -79.82999999999893, "episode_reward_mean": -10.86719999999991, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -156.79000000000093, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 2.0000000000000013, "predator_policy": 79.0}, "policy_reward_mean": {"prey_policy": -15.808599999999974, "predator_policy": 10.375}, "custom_metrics": {}, "hist_stats": {"episode_reward": [3.9199999999999604, -18.219999999999423, -13.279999999999932, -8.15000000000008, -24.27999999999942, -13.21999999999994, -14.179999999999746, -30.270000000000113, -79.82999999999893, -1.050000000000063, 2.7799999999999856, -12.160000000000082, 0.959999999999989, -18.219999999999427, -7.1300000000000825, 0.9599999999999819, -3.1900000000000786, -6.120000000000081, -6.240000000000077, -3.4800000000000733, -5.100000000000083, -5.150000000000082, -9.100000000000083, -11.150000000000082, 1.8599999999999999, -10.140000000000082, -5.140000000000082, -9.150000000000082, -15.18999999999956, -6.250000000000078, -0.040000000000040996, -23.269999999999428, -11.150000000000084, -3.0800000000000827, 2.8899999999999832, -27.309999999999427, -5.100000000000083, -13.159999999999906, -1.0500000000000622, -5.26000000000008, 0.8199999999999835, 3.9699999999999593, -3.1100000000000767, -2.060000000000084, -11.16000000000008, -12.160000000000082, 1.940000000000003, -7.140000000000082, -21.249999999999417, -3.0700000000000838, -6.270000000000078, -16.179999999999403, -0.09000000000003744, -21.289999999999424, -7.16000000000008, -12.450000000000077, -14.179999999999746, -9.150000000000082, 0.969999999999981, -70.7799999999987, -12.160000000000078, 0.9199999999999827, -0.040000000000040996, -9.130000000000082, -18.219999999999427, -24.279999999999465, -10.140000000000082, -48.5200000000006, -1.0700000000000631, -27.309999999999434, -18.21999999999942, -4.080000000000084, -4.090000000000082, -17.229999999999436, -21.249999999999417, -9.140000000000082, -19.22999999999943, -24.27999999999945, -5.110000000000083, -14.179999999999739, -7.100000000000083, -2.110000000000081, -21.219999999999413, -2.0900000000000825, -5.090000000000083, -0.040000000000040996, -15.189999999999554, -20.2399999999995, -18.21999999999944, -7.090000000000083, 1.880000000000003, -9.160000000000082, 3.979999999999959, -10.130000000000082, -6.080000000000084, -0.040000000000040996, -10.130000000000082, -4.120000000000083, -42.460000000000704, -4.070000000000084], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-14.080000000000041, 2.0000000000000013, -18.099999999999714, -22.11999999999971, -14.080000000000041, -38.20000000000036, 2.0000000000000013, -28.14999999999971, -18.099999999999703, -34.180000000000355, -42.22000000000035, 2.0000000000000013, -8.050000000000042, -24.12999999999971, -24.129999999999708, -26.13999999999971, -156.79000000000093, -6.040000000000042, -2.0200000000000413, -4.030000000000042, 2.0000000000000013, -42.220000000000354, -10.060000000000041, -18.099999999999703, -2.020000000000038, -2.020000000000042, -4.030000000000042, -36.19000000000036, -16.0899999999997, -6.040000000000042, 2.0000000000000013, -6.040000000000042, -14.080000000000041, -20.10999999999972, -22.119999999999706, 2.0000000000000013, 2.0000000000000013, -46.24000000000034, 2.0000000000000013, -94.47999999999922, -12.070000000000041, -4.030000000000042, 2.0000000000000013, -28.14999999999971, -10.060000000000041, -6.040000000000042, -14.080000000000041, -12.070000000000041, -26.13999999999971, 2.0000000000000013, -12.070000000000041, -12.070000000000041, -4.030000000000042, -20.109999999999705, -16.0899999999997, -10.060000000000041, -28.14999999999971, -6.040000000000042, -30.15999999999972, -16.0899999999997, -4.030000000000042, -0.00999999999999836, -8.050000000000042, -42.220000000000354, -14.080000000000041, -12.070000000000041, 2.0000000000000013, -14.080000000000041, 2.0000000000000013, -20.109999999999705, -22.11999999999971, -36.19000000000032, -18.099999999999703, 2.0000000000000013, -14.080000000000041, -14.080000000000041, 2.0000000000000013, -8.050000000000042, -22.119999999999706, -26.139999999999727, -34.18000000000036, 2.0000000000000013, 2.0000000000000013, -4.030000000000042, -4.030000000000042, -14.080000000000037, -6.040000000000042, -2.020000000000042, 2.0000000000000013, -30.159999999999712, -4.030000000000042, -24.129999999999708, 2.0000000000000013, -10.060000000000041, -16.0899999999997, -8.050000000000042, -22.119999999999706, -24.12999999999971, -12.070000000000041, 2.0000000000000013, 2.0000000000000013, -52.270000000000344, -18.099999999999703, -14.080000000000041, -2.0200000000000395, -12.070000000000041, -40.21000000000035, -14.080000000000041, -12.070000000000036, -16.0899999999997, -2.020000000000042, -84.4299999999992, -4.030000000000042, -28.14999999999971, -28.14999999999971, 2.0000000000000013, -4.030000000000042, 2.0000000000000013, -142.72000000000116, -10.060000000000041, -22.119999999999706, -6.040000000000042, 2.0000000000000013, -14.080000000000041, -4.030000000000042, -0.00999999999999836, -20.109999999999708, -2.020000000000042, -32.170000000000364, -8.050000000000042, -52.27000000000033, -0.00999999999999836, -6.040000000000042, -18.099999999999707, 2.0000000000000013, -102.51999999999924, -0.00999999999999836, -10.060000000000041, -8.050000000000042, -50.260000000000346, -10.060000000000041, -30.159999999999712, -10.060000000000041, -2.020000000000042, 2.0000000000000013, -16.0899999999997, -10.060000000000041, -32.17000000000035, -34.18000000000034, -12.070000000000041, -4.030000000000042, -20.109999999999705, -14.080000000000041, -28.149999999999718, -2.020000000000042, -50.260000000000346, 2.0000000000000013, -20.109999999999705, -10.060000000000041, -22.119999999999706, -10.060000000000041, -6.040000000000042, 2.0000000000000013, -20.109999999999705, -16.089999999999705, -24.129999999999708, -16.089999999999705, 2.0000000000000013, -12.070000000000041, -2.020000000000042, -6.040000000000042, 2.0000000000000013, -18.099999999999703, -16.089999999999705, -20.109999999999708, -24.12999999999975, -14.080000000000041, -26.139999999999723, -2.0200000000000418, -12.070000000000041, -22.119999999999706, 2.0000000000000013, -14.080000000000041, -14.080000000000041, -2.020000000000042, 2.0000000000000013, -12.070000000000041, -10.060000000000041, -6.040000000000042, -6.040000000000042, -6.040000000000042, 2.0000000000000013, -14.080000000000041, -8.050000000000042, 2.0000000000000013, -22.119999999999706, -46.24000000000035, -42.220000000000354, -8.050000000000042, -2.020000000000042], "policy_predator_policy_reward": [8.0, 8.0, 10.0, 12.0, 22.0, 17.0, 15.0, 3.0, 18.0, 10.0, 22.0, 5.0, 5.0, 13.0, 14.0, 6.0, 4.0, 79.0, 2.0, 3.0, 22.0, 21.0, 10.0, 6.0, 2.0, 3.0, 19.0, 3.0, 8.0, 7.0, 4.0, 1.0, 19.0, 12.0, 12.0, 2.0, 19.0, 19.0, 42.0, 47.0, 4.0, 7.0, 9.0, 12.0, 3.0, 4.0, 8.0, 7.0, 13.0, 13.0, 7.0, 7.0, 8.0, 11.0, 9.0, 8.0, 15.0, 4.0, 21.0, 19.0, 1.0, 3.0, 7.0, 20.0, 7.0, 8.0, 1.0, 8.0, 11.0, 10.0, 19.0, 12.0, 2.0, 9.0, 7.0, 8.0, 0.0, 5.0, 21.0, 22.0, 15.0, 18.0, 3.0, 3.0, 11.0, 4.0, 2.0, 4.0, 16.0, 1.0, 3.0, 13.0, 6.0, 4.0, 9.0, 8.0, 12.0, 13.0, 0.0, 7.0, 24.0, 20.0, 6.0, 10.0, 7.0, 7.0, 13.0, 20.0, 9.0, 12.0, 42.0, 32.0, 3.0, 15.0, 14.0, 3.0, 3.0, 0.0, 39.0, 43.0, 4.0, 12.0, 8.0, 5.0, 1.0, 3.0, 4.0, 9.0, 15.0, 7.0, 25.0, 3.0, 10.0, 4.0, 52.0, 0.0, 4.0, 5.0, 21.0, 10.0, 16.0, 6.0, 2.0, 6.0, 9.0, 1.0, 15.0, 10.0, 14.0, 11.0, 4.0, 11.0, 17.0, 6.0, 2.0, 26.0, 11.0, 2.0, 12.0, 6.0, 1.0, 8.0, 11.0, 5.0, 12.0, 7.0, 9.0, 3.0, 2.0, 7.0, 3.0, 1.0, 9.0, 10.0, 5.0, 19.0, 19.0, 3.0, 7.0, 0.0, 12.0, 10.0, 10.0, 9.0, 2.0, 2.0, 5.0, 7.0, 4.0, 2.0, 4.0, 0.0, 8.0, 4.0, 5.0, 11.0, 22.0, 24.0, 5.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6098379455258507, "mean_inference_ms": 1.8841189836824015, "mean_action_processing_ms": 0.23974599397716767, "mean_env_wait_ms": 0.19557125428152683, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0035877227783203125, "StateBufferConnector_ms": 0.003091096878051758, "ViewRequirementAgentConnector_ms": 0.09039556980133057}, "num_episodes": 18, "episode_return_max": 3.979999999999959, "episode_return_min": -79.82999999999893, "episode_return_mean": -10.86719999999991, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 320000, "num_agent_steps_trained": 320000, "num_env_steps_sampled": 80000, "num_env_steps_trained": 80000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 391.0855917922735, "num_env_steps_trained_throughput_per_sec": 391.0855917922735, "timesteps_total": 80000, "num_env_steps_sampled_lifetime": 80000, "num_agent_steps_sampled_lifetime": 320000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 320000, "timers": {"training_iteration_time_ms": 10568.74, "restore_workers_time_ms": 0.012, "training_step_time_ms": 10568.706, "sample_time_ms": 1402.044, "learn_time_ms": 9151.187, "learn_throughput": 437.102, "synch_weights_time_ms": 14.647}, "counters": {"num_env_steps_sampled": 80000, "num_env_steps_trained": 80000, "num_agent_steps_sampled": 320000, "num_agent_steps_trained": 320000}, "done": false, "training_iteration": 20, "trial_id": "8e499_00000", "date": "2024-08-15_02-07-51", "timestamp": 1723667871, "time_this_iter_s": 10.23385214805603, "time_total_s": 211.5707664489746, "pid": 33199, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b43f34c0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 211.5707664489746, "iterations_since_restore": 20, "perf": {"cpu_util_percent": 26.719999999999995, "ram_util_percent": 80.85333333333331}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.787139425107411, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.39951323736754674, "policy_loss": -0.006850378731728861, "vf_loss": 0.4053108070723259, "vf_explained_var": 0.04325567376676691, "kl": 0.009358305961292885, "entropy": 1.3870209784734817, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 38745.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5092076808095924, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.3747211402619662, "policy_loss": -0.01757729580544586, "vf_loss": 0.39111817361880585, "vf_explained_var": 0.01049857360345346, "kl": 0.011802618480183935, "entropy": 1.2402842489499895, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 38745.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 84000, "num_env_steps_trained": 84000, "num_agent_steps_sampled": 336000, "num_agent_steps_trained": 336000}, "env_runners": {"episode_reward_max": 3.979999999999959, "episode_reward_min": -70.7799999999987, "episode_reward_mean": -9.522799999999926, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -142.72000000000116, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 2.0000000000000013, "predator_policy": 52.0}, "policy_reward_mean": {"prey_policy": -14.361399999999977, "predator_policy": 9.6}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-6.240000000000077, -3.4800000000000733, -5.100000000000083, -5.150000000000082, -9.100000000000083, -11.150000000000082, 1.8599999999999999, -10.140000000000082, -5.140000000000082, -9.150000000000082, -15.18999999999956, -6.250000000000078, -0.040000000000040996, -23.269999999999428, -11.150000000000084, -3.0800000000000827, 2.8899999999999832, -27.309999999999427, -5.100000000000083, -13.159999999999906, -1.0500000000000622, -5.26000000000008, 0.8199999999999835, 3.9699999999999593, -3.1100000000000767, -2.060000000000084, -11.16000000000008, -12.160000000000082, 1.940000000000003, -7.140000000000082, -21.249999999999417, -3.0700000000000838, -6.270000000000078, -16.179999999999403, -0.09000000000003744, -21.289999999999424, -7.16000000000008, -12.450000000000077, -14.179999999999746, -9.150000000000082, 0.969999999999981, -70.7799999999987, -12.160000000000078, 0.9199999999999827, -0.040000000000040996, -9.130000000000082, -18.219999999999427, -24.279999999999465, -10.140000000000082, -48.5200000000006, -1.0700000000000631, -27.309999999999434, -18.21999999999942, -4.080000000000084, -4.090000000000082, -17.229999999999436, -21.249999999999417, -9.140000000000082, -19.22999999999943, -24.27999999999945, -5.110000000000083, -14.179999999999739, -7.100000000000083, -2.110000000000081, -21.219999999999413, -2.0900000000000825, -5.090000000000083, -0.040000000000040996, -15.189999999999554, -20.2399999999995, -18.21999999999944, -7.090000000000083, 1.880000000000003, -9.160000000000082, 3.979999999999959, -10.130000000000082, -6.080000000000084, -0.040000000000040996, -10.130000000000082, -4.120000000000083, -42.460000000000704, -4.070000000000084, -4.080000000000084, -10.13000000000008, -4.130000000000081, -2.080000000000081, 0.969999999999981, -0.13000000000004008, -1.1300000000000605, 3.9099999999999606, -20.239999999999416, -3.0900000000000833, -1.0900000000000631, 2.9599999999999818, -1.050000000000063, -11.150000000000082, -2.1300000000000807, -13.169999999999959, -14.179999999999767, -26.299999999999432], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [2.0000000000000013, -46.24000000000034, 2.0000000000000013, -94.47999999999922, -12.070000000000041, -4.030000000000042, 2.0000000000000013, -28.14999999999971, -10.060000000000041, -6.040000000000042, -14.080000000000041, -12.070000000000041, -26.13999999999971, 2.0000000000000013, -12.070000000000041, -12.070000000000041, -4.030000000000042, -20.109999999999705, -16.0899999999997, -10.060000000000041, -28.14999999999971, -6.040000000000042, -30.15999999999972, -16.0899999999997, -4.030000000000042, -0.00999999999999836, -8.050000000000042, -42.220000000000354, -14.080000000000041, -12.070000000000041, 2.0000000000000013, -14.080000000000041, 2.0000000000000013, -20.109999999999705, -22.11999999999971, -36.19000000000032, -18.099999999999703, 2.0000000000000013, -14.080000000000041, -14.080000000000041, 2.0000000000000013, -8.050000000000042, -22.119999999999706, -26.139999999999727, -34.18000000000036, 2.0000000000000013, 2.0000000000000013, -4.030000000000042, -4.030000000000042, -14.080000000000037, -6.040000000000042, -2.020000000000042, 2.0000000000000013, -30.159999999999712, -4.030000000000042, -24.129999999999708, 2.0000000000000013, -10.060000000000041, -16.0899999999997, -8.050000000000042, -22.119999999999706, -24.12999999999971, -12.070000000000041, 2.0000000000000013, 2.0000000000000013, -52.270000000000344, -18.099999999999703, -14.080000000000041, -2.0200000000000395, -12.070000000000041, -40.21000000000035, -14.080000000000041, -12.070000000000036, -16.0899999999997, -2.020000000000042, -84.4299999999992, -4.030000000000042, -28.14999999999971, -28.14999999999971, 2.0000000000000013, -4.030000000000042, 2.0000000000000013, -142.72000000000116, -10.060000000000041, -22.119999999999706, -6.040000000000042, 2.0000000000000013, -14.080000000000041, -4.030000000000042, -0.00999999999999836, -20.109999999999708, -2.020000000000042, -32.170000000000364, -8.050000000000042, -52.27000000000033, -0.00999999999999836, -6.040000000000042, -18.099999999999707, 2.0000000000000013, -102.51999999999924, -0.00999999999999836, -10.060000000000041, -8.050000000000042, -50.260000000000346, -10.060000000000041, -30.159999999999712, -10.060000000000041, -2.020000000000042, 2.0000000000000013, -16.0899999999997, -10.060000000000041, -32.17000000000035, -34.18000000000034, -12.070000000000041, -4.030000000000042, -20.109999999999705, -14.080000000000041, -28.149999999999718, -2.020000000000042, -50.260000000000346, 2.0000000000000013, -20.109999999999705, -10.060000000000041, -22.119999999999706, -10.060000000000041, -6.040000000000042, 2.0000000000000013, -20.109999999999705, -16.089999999999705, -24.129999999999708, -16.089999999999705, 2.0000000000000013, -12.070000000000041, -2.020000000000042, -6.040000000000042, 2.0000000000000013, -18.099999999999703, -16.089999999999705, -20.109999999999708, -24.12999999999975, -14.080000000000041, -26.139999999999723, -2.0200000000000418, -12.070000000000041, -22.119999999999706, 2.0000000000000013, -14.080000000000041, -14.080000000000041, -2.020000000000042, 2.0000000000000013, -12.070000000000041, -10.060000000000041, -6.040000000000042, -6.040000000000042, -6.040000000000042, 2.0000000000000013, -14.080000000000041, -8.050000000000042, 2.0000000000000013, -22.119999999999706, -46.24000000000035, -42.220000000000354, -8.050000000000042, -2.020000000000042, -2.020000000000042, -10.060000000000041, -2.020000000000041, -20.109999999999705, -4.0300000000000376, -18.099999999999703, -6.040000000000042, -6.04000000000004, -4.030000000000042, 2.0000000000000013, 2.0000000000000013, -24.129999999999708, -14.08000000000004, -8.050000000000042, 2.0000000000000013, -16.0899999999997, -12.070000000000041, -32.170000000000364, -2.020000000000042, -12.070000000000041, -2.020000000000042, -12.070000000000041, -6.040000000000042, 2.0000000000000013, -2.020000000000042, -4.030000000000042, -12.070000000000041, -14.080000000000041, 2.0000000000000013, -24.129999999999708, -20.10999999999973, -10.060000000000041, -0.00999999999999836, -32.17000000000036, -10.060000000000041, -46.24000000000035], "policy_predator_policy_reward": [19.0, 19.0, 42.0, 47.0, 4.0, 7.0, 9.0, 12.0, 3.0, 4.0, 8.0, 7.0, 13.0, 13.0, 7.0, 7.0, 8.0, 11.0, 9.0, 8.0, 15.0, 4.0, 21.0, 19.0, 1.0, 3.0, 7.0, 20.0, 7.0, 8.0, 1.0, 8.0, 11.0, 10.0, 19.0, 12.0, 2.0, 9.0, 7.0, 8.0, 0.0, 5.0, 21.0, 22.0, 15.0, 18.0, 3.0, 3.0, 11.0, 4.0, 2.0, 4.0, 16.0, 1.0, 3.0, 13.0, 6.0, 4.0, 9.0, 8.0, 12.0, 13.0, 0.0, 7.0, 24.0, 20.0, 6.0, 10.0, 7.0, 7.0, 13.0, 20.0, 9.0, 12.0, 42.0, 32.0, 3.0, 15.0, 14.0, 3.0, 3.0, 0.0, 39.0, 43.0, 4.0, 12.0, 8.0, 5.0, 1.0, 3.0, 4.0, 9.0, 15.0, 7.0, 25.0, 3.0, 10.0, 4.0, 52.0, 0.0, 4.0, 5.0, 21.0, 10.0, 16.0, 6.0, 2.0, 6.0, 9.0, 1.0, 15.0, 10.0, 14.0, 11.0, 4.0, 11.0, 17.0, 6.0, 2.0, 26.0, 11.0, 2.0, 12.0, 6.0, 1.0, 8.0, 11.0, 5.0, 12.0, 7.0, 9.0, 3.0, 2.0, 7.0, 3.0, 1.0, 9.0, 10.0, 5.0, 19.0, 19.0, 3.0, 7.0, 0.0, 12.0, 10.0, 10.0, 9.0, 2.0, 2.0, 5.0, 7.0, 4.0, 2.0, 4.0, 0.0, 8.0, 4.0, 5.0, 11.0, 22.0, 24.0, 5.0, 1.0, 2.0, 6.0, 8.0, 4.0, 5.0, 13.0, 8.0, 2.0, 0.0, 3.0, 11.0, 11.0, 12.0, 9.0, 9.0, 9.0, 7.0, 17.0, 6.0, 5.0, 7.0, 6.0, 4.0, 3.0, 2.0, 3.0, 7.0, 8.0, 13.0, 7.0, 4.0, 13.0, 9.0, 9.0, 6.0, 24.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6060841634331399, "mean_inference_ms": 1.8754613542475005, "mean_action_processing_ms": 0.23890279070121723, "mean_env_wait_ms": 0.19448900733412622, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003567934036254883, "StateBufferConnector_ms": 0.003064870834350586, "ViewRequirementAgentConnector_ms": 0.08892190456390381}, "num_episodes": 18, "episode_return_max": 3.979999999999959, "episode_return_min": -70.7799999999987, "episode_return_mean": -9.522799999999926, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 336000, "num_agent_steps_trained": 336000, "num_env_steps_sampled": 84000, "num_env_steps_trained": 84000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 392.95590923760534, "num_env_steps_trained_throughput_per_sec": 392.95590923760534, "timesteps_total": 84000, "num_env_steps_sampled_lifetime": 84000, "num_agent_steps_sampled_lifetime": 336000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 336000, "timers": {"training_iteration_time_ms": 10349.619, "restore_workers_time_ms": 0.012, "training_step_time_ms": 10349.586, "sample_time_ms": 1279.012, "learn_time_ms": 9055.271, "learn_throughput": 441.732, "synch_weights_time_ms": 14.505}, "counters": {"num_env_steps_sampled": 84000, "num_env_steps_trained": 84000, "num_agent_steps_sampled": 336000, "num_agent_steps_trained": 336000}, "done": false, "training_iteration": 21, "trial_id": "8e499_00000", "date": "2024-08-15_02-08-01", "timestamp": 1723667881, "time_this_iter_s": 10.183778047561646, "time_total_s": 221.75454449653625, "pid": 33199, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b41cdc10>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 221.75454449653625, "iterations_since_restore": 21, "perf": {"cpu_util_percent": 29.20714285714286, "ram_util_percent": 80.7}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9922720041539934, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.448669354215501, "policy_loss": -0.010254487542745968, "vf_loss": 1.457248595688078, "vf_explained_var": 0.0037942956364344035, "kl": 0.014891113789768718, "entropy": 1.3823847001822538, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 40635.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5868040617969301, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.304391310147192, "policy_loss": -0.009767343371394508, "vf_loss": 1.3133071901463957, "vf_explained_var": 0.017776262034814826, "kl": 0.008514652652340996, "entropy": 1.1649614399703092, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 40635.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 88000, "num_env_steps_trained": 88000, "num_agent_steps_sampled": 352000, "num_agent_steps_trained": 352000}, "env_runners": {"episode_reward_max": 3.979999999999959, "episode_reward_min": -116.18999999999897, "episode_reward_mean": -10.788099999999906, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -233.1700000000007, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 2.0000000000000013, "predator_policy": 117.0}, "policy_reward_mean": {"prey_policy": -14.894049999999975, "predator_policy": 9.5}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-5.100000000000083, -13.159999999999906, -1.0500000000000622, -5.26000000000008, 0.8199999999999835, 3.9699999999999593, -3.1100000000000767, -2.060000000000084, -11.16000000000008, -12.160000000000082, 1.940000000000003, -7.140000000000082, -21.249999999999417, -3.0700000000000838, -6.270000000000078, -16.179999999999403, -0.09000000000003744, -21.289999999999424, -7.16000000000008, -12.450000000000077, -14.179999999999746, -9.150000000000082, 0.969999999999981, -70.7799999999987, -12.160000000000078, 0.9199999999999827, -0.040000000000040996, -9.130000000000082, -18.219999999999427, -24.279999999999465, -10.140000000000082, -48.5200000000006, -1.0700000000000631, -27.309999999999434, -18.21999999999942, -4.080000000000084, -4.090000000000082, -17.229999999999436, -21.249999999999417, -9.140000000000082, -19.22999999999943, -24.27999999999945, -5.110000000000083, -14.179999999999739, -7.100000000000083, -2.110000000000081, -21.219999999999413, -2.0900000000000825, -5.090000000000083, -0.040000000000040996, -15.189999999999554, -20.2399999999995, -18.21999999999944, -7.090000000000083, 1.880000000000003, -9.160000000000082, 3.979999999999959, -10.130000000000082, -6.080000000000084, -0.040000000000040996, -10.130000000000082, -4.120000000000083, -42.460000000000704, -4.070000000000084, -4.080000000000084, -10.13000000000008, -4.130000000000081, -2.080000000000081, 0.969999999999981, -0.13000000000004008, -1.1300000000000605, 3.9099999999999606, -20.239999999999416, -3.0900000000000833, -1.0900000000000631, 2.9599999999999818, -1.050000000000063, -11.150000000000082, -2.1300000000000807, -13.169999999999959, -14.179999999999767, -26.299999999999432, 0.9199999999999827, -7.170000000000082, -13.169999999999952, 2.9799999999999813, -17.209999999999408, -116.18999999999897, 2.9299999999999824, -0.050000000000041, -0.040000000000040996, -18.21999999999949, -24.24999999999942, -9.130000000000082, -11.150000000000082, -15.189999999999554, -31.46000000000037, -14.189999999999749, 0.9599999999999814, -3.0900000000000816], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-18.099999999999703, 2.0000000000000013, -14.080000000000041, -14.080000000000041, 2.0000000000000013, -8.050000000000042, -22.119999999999706, -26.139999999999727, -34.18000000000036, 2.0000000000000013, 2.0000000000000013, -4.030000000000042, -4.030000000000042, -14.080000000000037, -6.040000000000042, -2.020000000000042, 2.0000000000000013, -30.159999999999712, -4.030000000000042, -24.129999999999708, 2.0000000000000013, -10.060000000000041, -16.0899999999997, -8.050000000000042, -22.119999999999706, -24.12999999999971, -12.070000000000041, 2.0000000000000013, 2.0000000000000013, -52.270000000000344, -18.099999999999703, -14.080000000000041, -2.0200000000000395, -12.070000000000041, -40.21000000000035, -14.080000000000041, -12.070000000000036, -16.0899999999997, -2.020000000000042, -84.4299999999992, -4.030000000000042, -28.14999999999971, -28.14999999999971, 2.0000000000000013, -4.030000000000042, 2.0000000000000013, -142.72000000000116, -10.060000000000041, -22.119999999999706, -6.040000000000042, 2.0000000000000013, -14.080000000000041, -4.030000000000042, -0.00999999999999836, -20.109999999999708, -2.020000000000042, -32.170000000000364, -8.050000000000042, -52.27000000000033, -0.00999999999999836, -6.040000000000042, -18.099999999999707, 2.0000000000000013, -102.51999999999924, -0.00999999999999836, -10.060000000000041, -8.050000000000042, -50.260000000000346, -10.060000000000041, -30.159999999999712, -10.060000000000041, -2.020000000000042, 2.0000000000000013, -16.0899999999997, -10.060000000000041, -32.17000000000035, -34.18000000000034, -12.070000000000041, -4.030000000000042, -20.109999999999705, -14.080000000000041, -28.149999999999718, -2.020000000000042, -50.260000000000346, 2.0000000000000013, -20.109999999999705, -10.060000000000041, -22.119999999999706, -10.060000000000041, -6.040000000000042, 2.0000000000000013, -20.109999999999705, -16.089999999999705, -24.129999999999708, -16.089999999999705, 2.0000000000000013, -12.070000000000041, -2.020000000000042, -6.040000000000042, 2.0000000000000013, -18.099999999999703, -16.089999999999705, -20.109999999999708, -24.12999999999975, -14.080000000000041, -26.139999999999723, -2.0200000000000418, -12.070000000000041, -22.119999999999706, 2.0000000000000013, -14.080000000000041, -14.080000000000041, -2.020000000000042, 2.0000000000000013, -12.070000000000041, -10.060000000000041, -6.040000000000042, -6.040000000000042, -6.040000000000042, 2.0000000000000013, -14.080000000000041, -8.050000000000042, 2.0000000000000013, -22.119999999999706, -46.24000000000035, -42.220000000000354, -8.050000000000042, -2.020000000000042, -2.020000000000042, -10.060000000000041, -2.020000000000041, -20.109999999999705, -4.0300000000000376, -18.099999999999703, -6.040000000000042, -6.04000000000004, -4.030000000000042, 2.0000000000000013, 2.0000000000000013, -24.129999999999708, -14.08000000000004, -8.050000000000042, 2.0000000000000013, -16.0899999999997, -12.070000000000041, -32.170000000000364, -2.020000000000042, -12.070000000000041, -2.020000000000042, -12.070000000000041, -6.040000000000042, 2.0000000000000013, -2.020000000000042, -4.030000000000042, -12.070000000000041, -14.080000000000041, 2.0000000000000013, -24.129999999999708, -20.10999999999973, -10.060000000000041, -0.00999999999999836, -32.17000000000036, -10.060000000000041, -46.24000000000035, 2.0000000000000013, -14.080000000000041, -8.050000000000042, -22.119999999999706, -10.060000000000041, -20.10999999999972, 2.0000000000000013, -2.020000000000042, -16.0899999999997, -22.119999999999706, -2.020000000000042, -233.1700000000007, -12.070000000000041, 2.0000000000000013, -8.050000000000042, 2.0000000000000013, -0.00999999999999836, -4.030000000000042, -40.21000000000033, -0.00999999999999836, -30.159999999999723, -16.0899999999997, -20.109999999999705, -2.020000000000042, -10.060000000000041, -16.089999999999705, -20.109999999999708, -14.080000000000041, -74.37999999999923, -14.080000000000041, -8.050000000000042, -26.13999999999971, -6.040000000000042, 2.0000000000000013, -6.040000000000041, -8.05000000000004], "policy_predator_policy_reward": [2.0, 9.0, 7.0, 8.0, 0.0, 5.0, 21.0, 22.0, 15.0, 18.0, 3.0, 3.0, 11.0, 4.0, 2.0, 4.0, 16.0, 1.0, 3.0, 13.0, 6.0, 4.0, 9.0, 8.0, 12.0, 13.0, 0.0, 7.0, 24.0, 20.0, 6.0, 10.0, 7.0, 7.0, 13.0, 20.0, 9.0, 12.0, 42.0, 32.0, 3.0, 15.0, 14.0, 3.0, 3.0, 0.0, 39.0, 43.0, 4.0, 12.0, 8.0, 5.0, 1.0, 3.0, 4.0, 9.0, 15.0, 7.0, 25.0, 3.0, 10.0, 4.0, 52.0, 0.0, 4.0, 5.0, 21.0, 10.0, 16.0, 6.0, 2.0, 6.0, 9.0, 1.0, 15.0, 10.0, 14.0, 11.0, 4.0, 11.0, 17.0, 6.0, 2.0, 26.0, 11.0, 2.0, 12.0, 6.0, 1.0, 8.0, 11.0, 5.0, 12.0, 7.0, 9.0, 3.0, 2.0, 7.0, 3.0, 1.0, 9.0, 10.0, 5.0, 19.0, 19.0, 3.0, 7.0, 0.0, 12.0, 10.0, 10.0, 9.0, 2.0, 2.0, 5.0, 7.0, 4.0, 2.0, 4.0, 0.0, 8.0, 4.0, 5.0, 11.0, 22.0, 24.0, 5.0, 1.0, 2.0, 6.0, 8.0, 4.0, 5.0, 13.0, 8.0, 2.0, 0.0, 3.0, 11.0, 11.0, 12.0, 9.0, 9.0, 9.0, 7.0, 17.0, 6.0, 5.0, 7.0, 6.0, 4.0, 3.0, 2.0, 3.0, 7.0, 8.0, 13.0, 7.0, 4.0, 13.0, 9.0, 9.0, 6.0, 24.0, 8.0, 5.0, 11.0, 12.0, 16.0, 1.0, 2.0, 1.0, 9.0, 12.0, 117.0, 2.0, 6.0, 7.0, 1.0, 5.0, 1.0, 3.0, 6.0, 16.0, 20.0, 2.0, 11.0, 2.0, 7.0, 8.0, 6.0, 13.0, 37.0, 20.0, 9.0, 11.0, 1.0, 4.0, 5.0, 6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6027209690585945, "mean_inference_ms": 1.8680623665374634, "mean_action_processing_ms": 0.23820005874915162, "mean_env_wait_ms": 0.1933711806238876, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0038336515426635742, "StateBufferConnector_ms": 0.0031540393829345703, "ViewRequirementAgentConnector_ms": 0.09275829792022705}, "num_episodes": 18, "episode_return_max": 3.979999999999959, "episode_return_min": -116.18999999999897, "episode_return_mean": -10.788099999999906, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 352000, "num_agent_steps_trained": 352000, "num_env_steps_sampled": 88000, "num_env_steps_trained": 88000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 361.70328772780067, "num_env_steps_trained_throughput_per_sec": 361.70328772780067, "timesteps_total": 88000, "num_env_steps_sampled_lifetime": 88000, "num_agent_steps_sampled_lifetime": 352000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 352000, "timers": {"training_iteration_time_ms": 10390.439, "restore_workers_time_ms": 0.012, "training_step_time_ms": 10390.406, "sample_time_ms": 1269.398, "learn_time_ms": 9106.105, "learn_throughput": 439.266, "synch_weights_time_ms": 14.095}, "counters": {"num_env_steps_sampled": 88000, "num_env_steps_trained": 88000, "num_agent_steps_sampled": 352000, "num_agent_steps_trained": 352000}, "done": false, "training_iteration": 22, "trial_id": "8e499_00000", "date": "2024-08-15_02-08-12", "timestamp": 1723667892, "time_this_iter_s": 11.067328929901123, "time_total_s": 232.82187342643738, "pid": 33199, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b43ed0d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 232.82187342643738, "iterations_since_restore": 22, "perf": {"cpu_util_percent": 32.212500000000006, "ram_util_percent": 81.76875000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9412173052471151, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.0740003652988919, "policy_loss": -0.00838753616316589, "vf_loss": 1.0812047127535733, "vf_explained_var": 0.0035536107562837145, "kl": 0.010517237134275747, "entropy": 1.381068510100955, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 42525.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.578137552154758, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.8579142956260256, "policy_loss": -0.017036573136984198, "vf_loss": 0.8733696025357676, "vf_explained_var": 0.020358843967397375, "kl": 0.0158126439096328, "entropy": 1.1811434463849144, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 42525.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 92000, "num_env_steps_trained": 92000, "num_agent_steps_sampled": 368000, "num_agent_steps_trained": 368000}, "env_runners": {"episode_reward_max": 3.989999999999959, "episode_reward_min": -123.38999999999939, "episode_reward_mean": -13.68389999999993, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -277.3900000000002, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 2.0000000000000013, "predator_policy": 124.0}, "policy_reward_mean": {"prey_policy": -17.486949999999975, "predator_policy": 10.645}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-9.130000000000082, -18.219999999999427, -24.279999999999465, -10.140000000000082, -48.5200000000006, -1.0700000000000631, -27.309999999999434, -18.21999999999942, -4.080000000000084, -4.090000000000082, -17.229999999999436, -21.249999999999417, -9.140000000000082, -19.22999999999943, -24.27999999999945, -5.110000000000083, -14.179999999999739, -7.100000000000083, -2.110000000000081, -21.219999999999413, -2.0900000000000825, -5.090000000000083, -0.040000000000040996, -15.189999999999554, -20.2399999999995, -18.21999999999944, -7.090000000000083, 1.880000000000003, -9.160000000000082, 3.979999999999959, -10.130000000000082, -6.080000000000084, -0.040000000000040996, -10.130000000000082, -4.120000000000083, -42.460000000000704, -4.070000000000084, -4.080000000000084, -10.13000000000008, -4.130000000000081, -2.080000000000081, 0.969999999999981, -0.13000000000004008, -1.1300000000000605, 3.9099999999999606, -20.239999999999416, -3.0900000000000833, -1.0900000000000631, 2.9599999999999818, -1.050000000000063, -11.150000000000082, -2.1300000000000807, -13.169999999999959, -14.179999999999767, -26.299999999999432, 0.9199999999999827, -7.170000000000082, -13.169999999999952, 2.9799999999999813, -17.209999999999408, -116.18999999999897, 2.9299999999999824, -0.050000000000041, -0.040000000000040996, -18.21999999999949, -24.24999999999942, -9.130000000000082, -11.150000000000082, -15.189999999999554, -31.46000000000037, -14.189999999999749, 0.9599999999999814, -3.0900000000000816, -18.2399999999998, -8.110000000000083, -12.160000000000082, -24.280000000000058, -3.1300000000000807, -7.110000000000083, -2.0800000000000827, -48.79000000000021, -9.130000000000082, -48.55000000000011, -123.38999999999939, 2.909999999999983, -15.189999999999582, -13.169999999999916, -18.21999999999944, -98.0099999999996, -6.180000000000081, 0.969999999999981, -38.42000000000066, -0.10000000000003921, -6.100000000000083, -0.060000000000041, -3.110000000000083, -31.35000000000044, -0.10000000000004099, 3.989999999999959, -8.120000000000083], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-20.109999999999708, -2.020000000000042, -32.170000000000364, -8.050000000000042, -52.27000000000033, -0.00999999999999836, -6.040000000000042, -18.099999999999707, 2.0000000000000013, -102.51999999999924, -0.00999999999999836, -10.060000000000041, -8.050000000000042, -50.260000000000346, -10.060000000000041, -30.159999999999712, -10.060000000000041, -2.020000000000042, 2.0000000000000013, -16.0899999999997, -10.060000000000041, -32.17000000000035, -34.18000000000034, -12.070000000000041, -4.030000000000042, -20.109999999999705, -14.080000000000041, -28.149999999999718, -2.020000000000042, -50.260000000000346, 2.0000000000000013, -20.109999999999705, -10.060000000000041, -22.119999999999706, -10.060000000000041, -6.040000000000042, 2.0000000000000013, -20.109999999999705, -16.089999999999705, -24.129999999999708, -16.089999999999705, 2.0000000000000013, -12.070000000000041, -2.020000000000042, -6.040000000000042, 2.0000000000000013, -18.099999999999703, -16.089999999999705, -20.109999999999708, -24.12999999999975, -14.080000000000041, -26.139999999999723, -2.0200000000000418, -12.070000000000041, -22.119999999999706, 2.0000000000000013, -14.080000000000041, -14.080000000000041, -2.020000000000042, 2.0000000000000013, -12.070000000000041, -10.060000000000041, -6.040000000000042, -6.040000000000042, -6.040000000000042, 2.0000000000000013, -14.080000000000041, -8.050000000000042, 2.0000000000000013, -22.119999999999706, -46.24000000000035, -42.220000000000354, -8.050000000000042, -2.020000000000042, -2.020000000000042, -10.060000000000041, -2.020000000000041, -20.109999999999705, -4.0300000000000376, -18.099999999999703, -6.040000000000042, -6.04000000000004, -4.030000000000042, 2.0000000000000013, 2.0000000000000013, -24.129999999999708, -14.08000000000004, -8.050000000000042, 2.0000000000000013, -16.0899999999997, -12.070000000000041, -32.170000000000364, -2.020000000000042, -12.070000000000041, -2.020000000000042, -12.070000000000041, -6.040000000000042, 2.0000000000000013, -2.020000000000042, -4.030000000000042, -12.070000000000041, -14.080000000000041, 2.0000000000000013, -24.129999999999708, -20.10999999999973, -10.060000000000041, -0.00999999999999836, -32.17000000000036, -10.060000000000041, -46.24000000000035, 2.0000000000000013, -14.080000000000041, -8.050000000000042, -22.119999999999706, -10.060000000000041, -20.10999999999972, 2.0000000000000013, -2.020000000000042, -16.0899999999997, -22.119999999999706, -2.020000000000042, -233.1700000000007, -12.070000000000041, 2.0000000000000013, -8.050000000000042, 2.0000000000000013, -0.00999999999999836, -4.030000000000042, -40.21000000000033, -0.00999999999999836, -30.159999999999723, -16.0899999999997, -20.109999999999705, -2.020000000000042, -10.060000000000041, -16.089999999999705, -20.109999999999708, -14.080000000000041, -74.37999999999923, -14.080000000000041, -8.050000000000042, -26.13999999999971, -6.040000000000042, 2.0000000000000013, -6.040000000000041, -8.05000000000004, -44.23000000000001, -0.00999999999999836, -8.050000000000042, -10.060000000000041, -12.070000000000041, -16.089999999999705, 2.0000000000000013, -54.28000000000004, -4.030000000000042, -18.09999999999971, -14.080000000000041, -4.030000000000042, -14.080000000000041, 2.0000000000000013, -118.59999999999977, -36.190000000000346, -10.060000000000041, -12.070000000000041, -98.49999999999976, -8.050000000000042, 2.0000000000000013, -277.3900000000002, 2.0000000000000013, -16.0899999999997, 2.0000000000000013, -36.19000000000036, -10.06000000000004, -20.109999999999705, 2.0000000000000013, -42.220000000000354, -190.9600000000001, -8.050000000000042, -28.14999999999971, -4.030000000000042, -4.030000000000042, 2.0000000000000013, -26.139999999999766, -54.280000000000335, 2.0000000000000013, -18.099999999999703, -0.00999999999999836, -16.089999999999705, -8.050000000000042, -0.00999999999999836, -16.0899999999997, -2.020000000000042, -54.28000000000034, -12.070000000000041, -0.00999999999999836, -16.0899999999997, 2.0000000000000013, -0.00999999999999836, -8.050000000000042, -12.070000000000041], "policy_predator_policy_reward": [4.0, 9.0, 15.0, 7.0, 25.0, 3.0, 10.0, 4.0, 52.0, 0.0, 4.0, 5.0, 21.0, 10.0, 16.0, 6.0, 2.0, 6.0, 9.0, 1.0, 15.0, 10.0, 14.0, 11.0, 4.0, 11.0, 17.0, 6.0, 2.0, 26.0, 11.0, 2.0, 12.0, 6.0, 1.0, 8.0, 11.0, 5.0, 12.0, 7.0, 9.0, 3.0, 2.0, 7.0, 3.0, 1.0, 9.0, 10.0, 5.0, 19.0, 19.0, 3.0, 7.0, 0.0, 12.0, 10.0, 10.0, 9.0, 2.0, 2.0, 5.0, 7.0, 4.0, 2.0, 4.0, 0.0, 8.0, 4.0, 5.0, 11.0, 22.0, 24.0, 5.0, 1.0, 2.0, 6.0, 8.0, 4.0, 5.0, 13.0, 8.0, 2.0, 0.0, 3.0, 11.0, 11.0, 12.0, 9.0, 9.0, 9.0, 7.0, 17.0, 6.0, 5.0, 7.0, 6.0, 4.0, 3.0, 2.0, 3.0, 7.0, 8.0, 13.0, 7.0, 4.0, 13.0, 9.0, 9.0, 6.0, 24.0, 8.0, 5.0, 11.0, 12.0, 16.0, 1.0, 2.0, 1.0, 9.0, 12.0, 117.0, 2.0, 6.0, 7.0, 1.0, 5.0, 1.0, 3.0, 6.0, 16.0, 20.0, 2.0, 11.0, 2.0, 7.0, 8.0, 6.0, 13.0, 37.0, 20.0, 9.0, 11.0, 1.0, 4.0, 5.0, 6.0, 5.0, 21.0, 6.0, 4.0, 9.0, 7.0, 28.0, 0.0, 9.0, 10.0, 3.0, 8.0, 8.0, 2.0, 56.0, 50.0, 6.0, 7.0, 34.0, 24.0, 28.0, 124.0, 9.0, 8.0, 0.0, 19.0, 11.0, 6.0, 0.0, 22.0, 11.0, 90.0, 12.0, 14.0, 0.0, 3.0, 14.0, 28.0, 6.0, 10.0, 1.0, 9.0, 4.0, 4.0, 8.0, 7.0, 28.0, 7.0, 9.0, 7.0, 1.0, 1.0, 5.0, 7.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5992369088595808, "mean_inference_ms": 1.85887325682469, "mean_action_processing_ms": 0.23693374810555107, "mean_env_wait_ms": 0.19200768032095017, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004118919372558594, "StateBufferConnector_ms": 0.0031893253326416016, "ViewRequirementAgentConnector_ms": 0.09320676326751709}, "num_episodes": 27, "episode_return_max": 3.989999999999959, "episode_return_min": -123.38999999999939, "episode_return_mean": -13.68389999999993, "episodes_this_iter": 27}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 368000, "num_agent_steps_trained": 368000, "num_env_steps_sampled": 92000, "num_env_steps_trained": 92000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 368.1022418074774, "num_env_steps_trained_throughput_per_sec": 368.1022418074774, "timesteps_total": 92000, "num_env_steps_sampled_lifetime": 92000, "num_agent_steps_sampled_lifetime": 368000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 368000, "timers": {"training_iteration_time_ms": 10444.304, "restore_workers_time_ms": 0.012, "training_step_time_ms": 10444.268, "sample_time_ms": 1273.384, "learn_time_ms": 9154.82, "learn_throughput": 436.928, "synch_weights_time_ms": 14.891}, "counters": {"num_env_steps_sampled": 92000, "num_env_steps_trained": 92000, "num_agent_steps_sampled": 368000, "num_agent_steps_trained": 368000}, "done": false, "training_iteration": 23, "trial_id": "8e499_00000", "date": "2024-08-15_02-08-23", "timestamp": 1723667903, "time_this_iter_s": 10.949111938476562, "time_total_s": 243.77098536491394, "pid": 33199, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b43f23a0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 243.77098536491394, "iterations_since_restore": 23, "perf": {"cpu_util_percent": 42.887499999999996, "ram_util_percent": 82.53125}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7609734892450943, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.282255256515016, "policy_loss": -0.00877666571596391, "vf_loss": 0.2902363083855047, "vf_explained_var": 0.047783837463489916, "kl": 0.007072110447141496, "entropy": 1.3878518821070434, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 44415.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5136933442835928, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.28469167175738475, "policy_loss": -0.013753631849842214, "vf_loss": 0.29780569150896063, "vf_explained_var": -0.0028739782552870494, "kl": 0.006396117188693346, "entropy": 1.179666357633298, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 44415.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 96000, "num_env_steps_trained": 96000, "num_agent_steps_sampled": 384000, "num_agent_steps_trained": 384000}, "env_runners": {"episode_reward_max": 3.989999999999959, "episode_reward_min": -123.38999999999939, "episode_reward_mean": -11.675099999999976, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -277.3900000000002, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 2.0000000000000013, "predator_policy": 124.0}, "policy_reward_mean": {"prey_policy": -15.597549999999979, "predator_policy": 9.76}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-2.110000000000081, -21.219999999999413, -2.0900000000000825, -5.090000000000083, -0.040000000000040996, -15.189999999999554, -20.2399999999995, -18.21999999999944, -7.090000000000083, 1.880000000000003, -9.160000000000082, 3.979999999999959, -10.130000000000082, -6.080000000000084, -0.040000000000040996, -10.130000000000082, -4.120000000000083, -42.460000000000704, -4.070000000000084, -4.080000000000084, -10.13000000000008, -4.130000000000081, -2.080000000000081, 0.969999999999981, -0.13000000000004008, -1.1300000000000605, 3.9099999999999606, -20.239999999999416, -3.0900000000000833, -1.0900000000000631, 2.9599999999999818, -1.050000000000063, -11.150000000000082, -2.1300000000000807, -13.169999999999959, -14.179999999999767, -26.299999999999432, 0.9199999999999827, -7.170000000000082, -13.169999999999952, 2.9799999999999813, -17.209999999999408, -116.18999999999897, 2.9299999999999824, -0.050000000000041, -0.040000000000040996, -18.21999999999949, -24.24999999999942, -9.130000000000082, -11.150000000000082, -15.189999999999554, -31.46000000000037, -14.189999999999749, 0.9599999999999814, -3.0900000000000816, -18.2399999999998, -8.110000000000083, -12.160000000000082, -24.280000000000058, -3.1300000000000807, -7.110000000000083, -2.0800000000000827, -48.79000000000021, -9.130000000000082, -48.55000000000011, -123.38999999999939, 2.909999999999983, -15.189999999999582, -13.169999999999916, -18.21999999999944, -98.0099999999996, -6.180000000000081, 0.969999999999981, -38.42000000000066, -0.10000000000003921, -6.100000000000083, -0.060000000000041, -3.110000000000083, -31.35000000000044, -0.10000000000004099, 3.989999999999959, -8.120000000000083, -6.100000000000083, -31.34000000000045, 2.9799999999999813, 2.949999999999982, 0.9599999999999819, 0.939999999999981, -1.0600000000000631, 0.9499999999999819, -21.209999999999408, -4.080000000000084, -2.1100000000000794, -1.050000000000063, 0.9699999999999819, -12.160000000000082, -2.060000000000084, 0.9399999999999819, -2.070000000000082, -9.150000000000082], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [2.0000000000000013, -20.109999999999705, -16.089999999999705, -24.129999999999708, -16.089999999999705, 2.0000000000000013, -12.070000000000041, -2.020000000000042, -6.040000000000042, 2.0000000000000013, -18.099999999999703, -16.089999999999705, -20.109999999999708, -24.12999999999975, -14.080000000000041, -26.139999999999723, -2.0200000000000418, -12.070000000000041, -22.119999999999706, 2.0000000000000013, -14.080000000000041, -14.080000000000041, -2.020000000000042, 2.0000000000000013, -12.070000000000041, -10.060000000000041, -6.040000000000042, -6.040000000000042, -6.040000000000042, 2.0000000000000013, -14.080000000000041, -8.050000000000042, 2.0000000000000013, -22.119999999999706, -46.24000000000035, -42.220000000000354, -8.050000000000042, -2.020000000000042, -2.020000000000042, -10.060000000000041, -2.020000000000041, -20.109999999999705, -4.0300000000000376, -18.099999999999703, -6.040000000000042, -6.04000000000004, -4.030000000000042, 2.0000000000000013, 2.0000000000000013, -24.129999999999708, -14.08000000000004, -8.050000000000042, 2.0000000000000013, -16.0899999999997, -12.070000000000041, -32.170000000000364, -2.020000000000042, -12.070000000000041, -2.020000000000042, -12.070000000000041, -6.040000000000042, 2.0000000000000013, -2.020000000000042, -4.030000000000042, -12.070000000000041, -14.080000000000041, 2.0000000000000013, -24.129999999999708, -20.10999999999973, -10.060000000000041, -0.00999999999999836, -32.17000000000036, -10.060000000000041, -46.24000000000035, 2.0000000000000013, -14.080000000000041, -8.050000000000042, -22.119999999999706, -10.060000000000041, -20.10999999999972, 2.0000000000000013, -2.020000000000042, -16.0899999999997, -22.119999999999706, -2.020000000000042, -233.1700000000007, -12.070000000000041, 2.0000000000000013, -8.050000000000042, 2.0000000000000013, -0.00999999999999836, -4.030000000000042, -40.21000000000033, -0.00999999999999836, -30.159999999999723, -16.0899999999997, -20.109999999999705, -2.020000000000042, -10.060000000000041, -16.089999999999705, -20.109999999999708, -14.080000000000041, -74.37999999999923, -14.080000000000041, -8.050000000000042, -26.13999999999971, -6.040000000000042, 2.0000000000000013, -6.040000000000041, -8.05000000000004, -44.23000000000001, -0.00999999999999836, -8.050000000000042, -10.060000000000041, -12.070000000000041, -16.089999999999705, 2.0000000000000013, -54.28000000000004, -4.030000000000042, -18.09999999999971, -14.080000000000041, -4.030000000000042, -14.080000000000041, 2.0000000000000013, -118.59999999999977, -36.190000000000346, -10.060000000000041, -12.070000000000041, -98.49999999999976, -8.050000000000042, 2.0000000000000013, -277.3900000000002, 2.0000000000000013, -16.0899999999997, 2.0000000000000013, -36.19000000000036, -10.06000000000004, -20.109999999999705, 2.0000000000000013, -42.220000000000354, -190.9600000000001, -8.050000000000042, -28.14999999999971, -4.030000000000042, -4.030000000000042, 2.0000000000000013, -26.139999999999766, -54.280000000000335, 2.0000000000000013, -18.099999999999703, -0.00999999999999836, -16.089999999999705, -8.050000000000042, -0.00999999999999836, -16.0899999999997, -2.020000000000042, -54.28000000000034, -12.070000000000041, -0.00999999999999836, -16.0899999999997, 2.0000000000000013, -0.00999999999999836, -8.050000000000042, -12.070000000000041, -2.0200000000000413, -14.080000000000041, -38.20000000000034, -26.139999999999713, -2.020000000000042, 2.0000000000000013, 2.0000000000000013, -8.050000000000042, 2.0000000000000013, -6.040000000000042, -0.00999999999999836, -8.050000000000042, -0.00999999999999836, -8.050000000000042, 2.0000000000000013, -8.050000000000042, -14.080000000000041, -24.129999999999708, -14.080000000000041, 2.0000000000000013, -10.060000000000041, -8.05000000000004, -4.030000000000042, -2.020000000000042, 2.0000000000000013, -4.030000000000042, -2.020000000000042, -26.13999999999971, -4.030000000000042, -4.030000000000042, 2.0000000000000013, -10.060000000000041, -12.070000000000041, 2.0000000000000013, -10.060000000000041, -16.0899999999997], "policy_predator_policy_reward": [11.0, 5.0, 12.0, 7.0, 9.0, 3.0, 2.0, 7.0, 3.0, 1.0, 9.0, 10.0, 5.0, 19.0, 19.0, 3.0, 7.0, 0.0, 12.0, 10.0, 10.0, 9.0, 2.0, 2.0, 5.0, 7.0, 4.0, 2.0, 4.0, 0.0, 8.0, 4.0, 5.0, 11.0, 22.0, 24.0, 5.0, 1.0, 2.0, 6.0, 8.0, 4.0, 5.0, 13.0, 8.0, 2.0, 0.0, 3.0, 11.0, 11.0, 12.0, 9.0, 9.0, 9.0, 7.0, 17.0, 6.0, 5.0, 7.0, 6.0, 4.0, 3.0, 2.0, 3.0, 7.0, 8.0, 13.0, 7.0, 4.0, 13.0, 9.0, 9.0, 6.0, 24.0, 8.0, 5.0, 11.0, 12.0, 16.0, 1.0, 2.0, 1.0, 9.0, 12.0, 117.0, 2.0, 6.0, 7.0, 1.0, 5.0, 1.0, 3.0, 6.0, 16.0, 20.0, 2.0, 11.0, 2.0, 7.0, 8.0, 6.0, 13.0, 37.0, 20.0, 9.0, 11.0, 1.0, 4.0, 5.0, 6.0, 5.0, 21.0, 6.0, 4.0, 9.0, 7.0, 28.0, 0.0, 9.0, 10.0, 3.0, 8.0, 8.0, 2.0, 56.0, 50.0, 6.0, 7.0, 34.0, 24.0, 28.0, 124.0, 9.0, 8.0, 0.0, 19.0, 11.0, 6.0, 0.0, 22.0, 11.0, 90.0, 12.0, 14.0, 0.0, 3.0, 14.0, 28.0, 6.0, 10.0, 1.0, 9.0, 4.0, 4.0, 8.0, 7.0, 28.0, 7.0, 9.0, 7.0, 1.0, 1.0, 5.0, 7.0, 8.0, 2.0, 9.0, 24.0, 1.0, 2.0, 5.0, 4.0, 1.0, 4.0, 5.0, 4.0, 5.0, 2.0, 2.0, 5.0, 4.0, 13.0, 0.0, 8.0, 6.0, 10.0, 2.0, 3.0, 0.0, 3.0, 14.0, 2.0, 3.0, 3.0, 3.0, 6.0, 5.0, 3.0, 8.0, 9.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6013928604627162, "mean_inference_ms": 1.8693725010809672, "mean_action_processing_ms": 0.23856594107481732, "mean_env_wait_ms": 0.1929246513482292, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004843235015869141, "StateBufferConnector_ms": 0.0037614107131958008, "ViewRequirementAgentConnector_ms": 0.11369884014129639}, "num_episodes": 18, "episode_return_max": 3.989999999999959, "episode_return_min": -123.38999999999939, "episode_return_mean": -11.675099999999976, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 384000, "num_agent_steps_trained": 384000, "num_env_steps_sampled": 96000, "num_env_steps_trained": 96000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 303.8532852878115, "num_env_steps_trained_throughput_per_sec": 303.8532852878115, "timesteps_total": 96000, "num_env_steps_sampled_lifetime": 96000, "num_agent_steps_sampled_lifetime": 384000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 384000, "timers": {"training_iteration_time_ms": 10721.872, "restore_workers_time_ms": 0.014, "training_step_time_ms": 10721.829, "sample_time_ms": 1432.546, "learn_time_ms": 9271.756, "learn_throughput": 431.418, "synch_weights_time_ms": 16.241}, "counters": {"num_env_steps_sampled": 96000, "num_env_steps_trained": 96000, "num_agent_steps_sampled": 384000, "num_agent_steps_trained": 384000}, "done": false, "training_iteration": 24, "trial_id": "8e499_00000", "date": "2024-08-15_02-08-36", "timestamp": 1723667916, "time_this_iter_s": 13.207995891571045, "time_total_s": 256.978981256485, "pid": 33199, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x15800f9d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 256.978981256485, "iterations_since_restore": 24, "perf": {"cpu_util_percent": 56.76315789473684, "ram_util_percent": 82.44736842105263}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9079941343772349, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.504871746211771, "policy_loss": -0.009061070466561924, "vf_loss": 0.5126930762195674, "vf_explained_var": 0.06659340275027764, "kl": 0.011019921981934166, "entropy": 1.3646640841923063, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 46305.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5239627333860549, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.7283362065057551, "policy_loss": -0.01495608678531079, "vf_loss": 0.7424120923750614, "vf_explained_var": -0.0017492978661148636, "kl": 0.008801978120448943, "entropy": 1.1556548420083586, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 46305.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 100000, "num_env_steps_trained": 100000, "num_agent_steps_sampled": 400000, "num_agent_steps_trained": 400000}, "env_runners": {"episode_reward_max": 3.989999999999959, "episode_reward_min": -123.38999999999939, "episode_reward_mean": -11.596799999999975, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -277.3900000000002, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 2.0000000000000013, "predator_policy": 124.0}, "policy_reward_mean": {"prey_policy": -15.768399999999986, "predator_policy": 9.97}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.070000000000084, -4.080000000000084, -10.13000000000008, -4.130000000000081, -2.080000000000081, 0.969999999999981, -0.13000000000004008, -1.1300000000000605, 3.9099999999999606, -20.239999999999416, -3.0900000000000833, -1.0900000000000631, 2.9599999999999818, -1.050000000000063, -11.150000000000082, -2.1300000000000807, -13.169999999999959, -14.179999999999767, -26.299999999999432, 0.9199999999999827, -7.170000000000082, -13.169999999999952, 2.9799999999999813, -17.209999999999408, -116.18999999999897, 2.9299999999999824, -0.050000000000041, -0.040000000000040996, -18.21999999999949, -24.24999999999942, -9.130000000000082, -11.150000000000082, -15.189999999999554, -31.46000000000037, -14.189999999999749, 0.9599999999999814, -3.0900000000000816, -18.2399999999998, -8.110000000000083, -12.160000000000082, -24.280000000000058, -3.1300000000000807, -7.110000000000083, -2.0800000000000827, -48.79000000000021, -9.130000000000082, -48.55000000000011, -123.38999999999939, 2.909999999999983, -15.189999999999582, -13.169999999999916, -18.21999999999944, -98.0099999999996, -6.180000000000081, 0.969999999999981, -38.42000000000066, -0.10000000000003921, -6.100000000000083, -0.060000000000041, -3.110000000000083, -31.35000000000044, -0.10000000000004099, 3.989999999999959, -8.120000000000083, -6.100000000000083, -31.34000000000045, 2.9799999999999813, 2.949999999999982, 0.9599999999999819, 0.939999999999981, -1.0600000000000631, 0.9499999999999819, -21.209999999999408, -4.080000000000084, -2.1100000000000794, -1.050000000000063, 0.9699999999999819, -12.160000000000082, -2.060000000000084, 0.9399999999999819, -2.070000000000082, -9.150000000000082, 2.939999999999982, 0.9599999999999828, 3.9599999999999596, 1.9400000000000026, -18.219999999999448, -21.24999999999943, -0.07000000000004011, 1.9100000000000028, -0.05000000000004011, -7.230000000000077, -25.28999999999942, -6.110000000000083, -32.40000000000062, -39.33000000000016, -9.130000000000082, 1.9300000000000028, -4.170000000000082, -10.110000000000083], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-8.050000000000042, -2.020000000000042, -2.020000000000042, -10.060000000000041, -2.020000000000041, -20.109999999999705, -4.0300000000000376, -18.099999999999703, -6.040000000000042, -6.04000000000004, -4.030000000000042, 2.0000000000000013, 2.0000000000000013, -24.129999999999708, -14.08000000000004, -8.050000000000042, 2.0000000000000013, -16.0899999999997, -12.070000000000041, -32.170000000000364, -2.020000000000042, -12.070000000000041, -2.020000000000042, -12.070000000000041, -6.040000000000042, 2.0000000000000013, -2.020000000000042, -4.030000000000042, -12.070000000000041, -14.080000000000041, 2.0000000000000013, -24.129999999999708, -20.10999999999973, -10.060000000000041, -0.00999999999999836, -32.17000000000036, -10.060000000000041, -46.24000000000035, 2.0000000000000013, -14.080000000000041, -8.050000000000042, -22.119999999999706, -10.060000000000041, -20.10999999999972, 2.0000000000000013, -2.020000000000042, -16.0899999999997, -22.119999999999706, -2.020000000000042, -233.1700000000007, -12.070000000000041, 2.0000000000000013, -8.050000000000042, 2.0000000000000013, -0.00999999999999836, -4.030000000000042, -40.21000000000033, -0.00999999999999836, -30.159999999999723, -16.0899999999997, -20.109999999999705, -2.020000000000042, -10.060000000000041, -16.089999999999705, -20.109999999999708, -14.080000000000041, -74.37999999999923, -14.080000000000041, -8.050000000000042, -26.13999999999971, -6.040000000000042, 2.0000000000000013, -6.040000000000041, -8.05000000000004, -44.23000000000001, -0.00999999999999836, -8.050000000000042, -10.060000000000041, -12.070000000000041, -16.089999999999705, 2.0000000000000013, -54.28000000000004, -4.030000000000042, -18.09999999999971, -14.080000000000041, -4.030000000000042, -14.080000000000041, 2.0000000000000013, -118.59999999999977, -36.190000000000346, -10.060000000000041, -12.070000000000041, -98.49999999999976, -8.050000000000042, 2.0000000000000013, -277.3900000000002, 2.0000000000000013, -16.0899999999997, 2.0000000000000013, -36.19000000000036, -10.06000000000004, -20.109999999999705, 2.0000000000000013, -42.220000000000354, -190.9600000000001, -8.050000000000042, -28.14999999999971, -4.030000000000042, -4.030000000000042, 2.0000000000000013, -26.139999999999766, -54.280000000000335, 2.0000000000000013, -18.099999999999703, -0.00999999999999836, -16.089999999999705, -8.050000000000042, -0.00999999999999836, -16.0899999999997, -2.020000000000042, -54.28000000000034, -12.070000000000041, -0.00999999999999836, -16.0899999999997, 2.0000000000000013, -0.00999999999999836, -8.050000000000042, -12.070000000000041, -2.0200000000000413, -14.080000000000041, -38.20000000000034, -26.139999999999713, -2.020000000000042, 2.0000000000000013, 2.0000000000000013, -8.050000000000042, 2.0000000000000013, -6.040000000000042, -0.00999999999999836, -8.050000000000042, -0.00999999999999836, -8.050000000000042, 2.0000000000000013, -8.050000000000042, -14.080000000000041, -24.129999999999708, -14.080000000000041, 2.0000000000000013, -10.060000000000041, -8.05000000000004, -4.030000000000042, -2.020000000000042, 2.0000000000000013, -4.030000000000042, -2.020000000000042, -26.13999999999971, -4.030000000000042, -4.030000000000042, 2.0000000000000013, -10.060000000000041, -12.070000000000041, 2.0000000000000013, -10.060000000000041, -16.0899999999997, 2.0000000000000013, -10.060000000000041, 2.0000000000000013, -6.040000000000042, 2.0000000000000013, -6.040000000000042, -10.060000000000041, 2.0000000000000013, -42.22000000000035, 2.0000000000000013, -30.159999999999723, -16.0899999999997, 2.0000000000000013, -12.070000000000041, -16.0899999999997, 2.0000000000000013, 2.0000000000000013, -8.050000000000042, 2.0000000000000013, -44.23000000000035, -24.129999999999708, -30.159999999999712, -6.040000000000042, -12.070000000000041, -78.3999999999992, 2.0000000000000013, -34.18000000000008, -28.15, -12.070000000000041, -10.060000000000041, -12.070000000000041, 2.0000000000000013, -32.170000000000364, 2.0000000000000013, -14.080000000000041, -4.030000000000042], "policy_predator_policy_reward": [5.0, 1.0, 2.0, 6.0, 8.0, 4.0, 5.0, 13.0, 8.0, 2.0, 0.0, 3.0, 11.0, 11.0, 12.0, 9.0, 9.0, 9.0, 7.0, 17.0, 6.0, 5.0, 7.0, 6.0, 4.0, 3.0, 2.0, 3.0, 7.0, 8.0, 13.0, 7.0, 4.0, 13.0, 9.0, 9.0, 6.0, 24.0, 8.0, 5.0, 11.0, 12.0, 16.0, 1.0, 2.0, 1.0, 9.0, 12.0, 117.0, 2.0, 6.0, 7.0, 1.0, 5.0, 1.0, 3.0, 6.0, 16.0, 20.0, 2.0, 11.0, 2.0, 7.0, 8.0, 6.0, 13.0, 37.0, 20.0, 9.0, 11.0, 1.0, 4.0, 5.0, 6.0, 5.0, 21.0, 6.0, 4.0, 9.0, 7.0, 28.0, 0.0, 9.0, 10.0, 3.0, 8.0, 8.0, 2.0, 56.0, 50.0, 6.0, 7.0, 34.0, 24.0, 28.0, 124.0, 9.0, 8.0, 0.0, 19.0, 11.0, 6.0, 0.0, 22.0, 11.0, 90.0, 12.0, 14.0, 0.0, 3.0, 14.0, 28.0, 6.0, 10.0, 1.0, 9.0, 4.0, 4.0, 8.0, 7.0, 28.0, 7.0, 9.0, 7.0, 1.0, 1.0, 5.0, 7.0, 8.0, 2.0, 9.0, 24.0, 1.0, 2.0, 5.0, 4.0, 1.0, 4.0, 5.0, 4.0, 5.0, 2.0, 2.0, 5.0, 4.0, 13.0, 0.0, 8.0, 6.0, 10.0, 2.0, 3.0, 0.0, 3.0, 14.0, 2.0, 3.0, 3.0, 3.0, 6.0, 5.0, 3.0, 8.0, 9.0, 6.0, 5.0, 1.0, 4.0, 4.0, 4.0, 4.0, 6.0, 17.0, 5.0, 5.0, 20.0, 7.0, 3.0, 9.0, 7.0, 1.0, 5.0, 22.0, 13.0, 13.0, 16.0, 5.0, 7.0, 40.0, 4.0, 7.0, 16.0, 7.0, 6.0, 7.0, 5.0, 10.0, 16.0, 0.0, 8.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6057863563015041, "mean_inference_ms": 1.8846641684962588, "mean_action_processing_ms": 0.24050154452953124, "mean_env_wait_ms": 0.19455239902915267, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005677700042724609, "StateBufferConnector_ms": 0.003878474235534668, "ViewRequirementAgentConnector_ms": 0.12470448017120361}, "num_episodes": 18, "episode_return_max": 3.989999999999959, "episode_return_min": -123.38999999999939, "episode_return_mean": -11.596799999999975, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 400000, "num_agent_steps_trained": 400000, "num_env_steps_sampled": 100000, "num_env_steps_trained": 100000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 359.0513393788665, "num_env_steps_trained_throughput_per_sec": 359.0513393788665, "timesteps_total": 100000, "num_env_steps_sampled_lifetime": 100000, "num_agent_steps_sampled_lifetime": 400000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 400000, "timers": {"training_iteration_time_ms": 10806.424, "restore_workers_time_ms": 0.015, "training_step_time_ms": 10806.38, "sample_time_ms": 1474.548, "learn_time_ms": 9313.469, "learn_throughput": 429.486, "synch_weights_time_ms": 16.853}, "counters": {"num_env_steps_sampled": 100000, "num_env_steps_trained": 100000, "num_agent_steps_sampled": 400000, "num_agent_steps_trained": 400000}, "done": false, "training_iteration": 25, "trial_id": "8e499_00000", "date": "2024-08-15_02-08-47", "timestamp": 1723667927, "time_this_iter_s": 11.18733286857605, "time_total_s": 268.16631412506104, "pid": 33199, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x158031820>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 268.16631412506104, "iterations_since_restore": 25, "perf": {"cpu_util_percent": 35.61875, "ram_util_percent": 82.36250000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8861962062656564, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.7982901048565668, "policy_loss": -0.011019377377643077, "vf_loss": 0.808508168074189, "vf_explained_var": 0.04174824978308703, "kl": 0.007122791098992029, "entropy": 1.3107235943198834, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 48195.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.555007045928921, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.6538755634466984, "policy_loss": -0.01759761646525471, "vf_loss": 0.6707677291972297, "vf_explained_var": 0.004969415935889753, "kl": 0.0070545013602002484, "entropy": 1.1113669090170077, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 48195.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 104000, "num_env_steps_trained": 104000, "num_agent_steps_sampled": 416000, "num_agent_steps_trained": 416000}, "env_runners": {"episode_reward_max": 3.989999999999959, "episode_reward_min": -123.38999999999939, "episode_reward_mean": -12.612199999999971, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -277.3900000000002, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 2.0000000000000013, "predator_policy": 124.0}, "policy_reward_mean": {"prey_policy": -17.316099999999988, "predator_policy": 11.01}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-26.299999999999432, 0.9199999999999827, -7.170000000000082, -13.169999999999952, 2.9799999999999813, -17.209999999999408, -116.18999999999897, 2.9299999999999824, -0.050000000000041, -0.040000000000040996, -18.21999999999949, -24.24999999999942, -9.130000000000082, -11.150000000000082, -15.189999999999554, -31.46000000000037, -14.189999999999749, 0.9599999999999814, -3.0900000000000816, -18.2399999999998, -8.110000000000083, -12.160000000000082, -24.280000000000058, -3.1300000000000807, -7.110000000000083, -2.0800000000000827, -48.79000000000021, -9.130000000000082, -48.55000000000011, -123.38999999999939, 2.909999999999983, -15.189999999999582, -13.169999999999916, -18.21999999999944, -98.0099999999996, -6.180000000000081, 0.969999999999981, -38.42000000000066, -0.10000000000003921, -6.100000000000083, -0.060000000000041, -3.110000000000083, -31.35000000000044, -0.10000000000004099, 3.989999999999959, -8.120000000000083, -6.100000000000083, -31.34000000000045, 2.9799999999999813, 2.949999999999982, 0.9599999999999819, 0.939999999999981, -1.0600000000000631, 0.9499999999999819, -21.209999999999408, -4.080000000000084, -2.1100000000000794, -1.050000000000063, 0.9699999999999819, -12.160000000000082, -2.060000000000084, 0.9399999999999819, -2.070000000000082, -9.150000000000082, 2.939999999999982, 0.9599999999999828, 3.9599999999999596, 1.9400000000000026, -18.219999999999448, -21.24999999999943, -0.07000000000004011, 1.9100000000000028, -0.05000000000004011, -7.230000000000077, -25.28999999999942, -6.110000000000083, -32.40000000000062, -39.33000000000016, -9.130000000000082, 1.9300000000000028, -4.170000000000082, -10.110000000000083, -9.130000000000082, -10.140000000000082, -7.120000000000083, 1.9300000000000033, -3.0700000000000838, -0.19000000000003747, -4.090000000000082, -19.669999999999604, -11.110000000000083, -7.110000000000083, -18.259999999999447, 1.9000000000000026, -29.32999999999969, -10.140000000000082, -6.100000000000083, -13.16999999999991, 0.699999999999983, -41.45000000000013], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-10.060000000000041, -46.24000000000035, 2.0000000000000013, -14.080000000000041, -8.050000000000042, -22.119999999999706, -10.060000000000041, -20.10999999999972, 2.0000000000000013, -2.020000000000042, -16.0899999999997, -22.119999999999706, -2.020000000000042, -233.1700000000007, -12.070000000000041, 2.0000000000000013, -8.050000000000042, 2.0000000000000013, -0.00999999999999836, -4.030000000000042, -40.21000000000033, -0.00999999999999836, -30.159999999999723, -16.0899999999997, -20.109999999999705, -2.020000000000042, -10.060000000000041, -16.089999999999705, -20.109999999999708, -14.080000000000041, -74.37999999999923, -14.080000000000041, -8.050000000000042, -26.13999999999971, -6.040000000000042, 2.0000000000000013, -6.040000000000041, -8.05000000000004, -44.23000000000001, -0.00999999999999836, -8.050000000000042, -10.060000000000041, -12.070000000000041, -16.089999999999705, 2.0000000000000013, -54.28000000000004, -4.030000000000042, -18.09999999999971, -14.080000000000041, -4.030000000000042, -14.080000000000041, 2.0000000000000013, -118.59999999999977, -36.190000000000346, -10.060000000000041, -12.070000000000041, -98.49999999999976, -8.050000000000042, 2.0000000000000013, -277.3900000000002, 2.0000000000000013, -16.0899999999997, 2.0000000000000013, -36.19000000000036, -10.06000000000004, -20.109999999999705, 2.0000000000000013, -42.220000000000354, -190.9600000000001, -8.050000000000042, -28.14999999999971, -4.030000000000042, -4.030000000000042, 2.0000000000000013, -26.139999999999766, -54.280000000000335, 2.0000000000000013, -18.099999999999703, -0.00999999999999836, -16.089999999999705, -8.050000000000042, -0.00999999999999836, -16.0899999999997, -2.020000000000042, -54.28000000000034, -12.070000000000041, -0.00999999999999836, -16.0899999999997, 2.0000000000000013, -0.00999999999999836, -8.050000000000042, -12.070000000000041, -2.0200000000000413, -14.080000000000041, -38.20000000000034, -26.139999999999713, -2.020000000000042, 2.0000000000000013, 2.0000000000000013, -8.050000000000042, 2.0000000000000013, -6.040000000000042, -0.00999999999999836, -8.050000000000042, -0.00999999999999836, -8.050000000000042, 2.0000000000000013, -8.050000000000042, -14.080000000000041, -24.129999999999708, -14.080000000000041, 2.0000000000000013, -10.060000000000041, -8.05000000000004, -4.030000000000042, -2.020000000000042, 2.0000000000000013, -4.030000000000042, -2.020000000000042, -26.13999999999971, -4.030000000000042, -4.030000000000042, 2.0000000000000013, -10.060000000000041, -12.070000000000041, 2.0000000000000013, -10.060000000000041, -16.0899999999997, 2.0000000000000013, -10.060000000000041, 2.0000000000000013, -6.040000000000042, 2.0000000000000013, -6.040000000000042, -10.060000000000041, 2.0000000000000013, -42.22000000000035, 2.0000000000000013, -30.159999999999723, -16.0899999999997, 2.0000000000000013, -12.070000000000041, -16.0899999999997, 2.0000000000000013, 2.0000000000000013, -8.050000000000042, 2.0000000000000013, -44.23000000000035, -24.129999999999708, -30.159999999999712, -6.040000000000042, -12.070000000000041, -78.3999999999992, 2.0000000000000013, -34.18000000000008, -28.15, -12.070000000000041, -10.060000000000041, -12.070000000000041, 2.0000000000000013, -32.170000000000364, 2.0000000000000013, -14.080000000000041, -4.030000000000042, -0.00999999999999836, -22.119999999999706, -26.139999999999723, 2.0000000000000013, -2.020000000000042, -18.099999999999703, 2.0000000000000013, -12.070000000000041, -4.030000000000042, -6.040000000000042, -30.159999999999727, -4.030000000000042, 2.0000000000000013, -16.0899999999997, -132.67000000000115, 2.0000000000000013, -6.040000000000042, -12.070000000000041, -14.080000000000041, -4.030000000000042, -50.260000000000346, 2.0000000000000013, 2.0000000000000013, -18.099999999999703, -60.310000000000336, -2.020000000000042, -14.080000000000041, -10.060000000000041, -18.099999999999707, 2.0000000000000013, -14.080000000000041, -16.0899999999997, -58.30000000000034, 2.0000000000000013, -4.030000000000042, -82.4199999999998], "policy_predator_policy_reward": [6.0, 24.0, 8.0, 5.0, 11.0, 12.0, 16.0, 1.0, 2.0, 1.0, 9.0, 12.0, 117.0, 2.0, 6.0, 7.0, 1.0, 5.0, 1.0, 3.0, 6.0, 16.0, 20.0, 2.0, 11.0, 2.0, 7.0, 8.0, 6.0, 13.0, 37.0, 20.0, 9.0, 11.0, 1.0, 4.0, 5.0, 6.0, 5.0, 21.0, 6.0, 4.0, 9.0, 7.0, 28.0, 0.0, 9.0, 10.0, 3.0, 8.0, 8.0, 2.0, 56.0, 50.0, 6.0, 7.0, 34.0, 24.0, 28.0, 124.0, 9.0, 8.0, 0.0, 19.0, 11.0, 6.0, 0.0, 22.0, 11.0, 90.0, 12.0, 14.0, 0.0, 3.0, 14.0, 28.0, 6.0, 10.0, 1.0, 9.0, 4.0, 4.0, 8.0, 7.0, 28.0, 7.0, 9.0, 7.0, 1.0, 1.0, 5.0, 7.0, 8.0, 2.0, 9.0, 24.0, 1.0, 2.0, 5.0, 4.0, 1.0, 4.0, 5.0, 4.0, 5.0, 2.0, 2.0, 5.0, 4.0, 13.0, 0.0, 8.0, 6.0, 10.0, 2.0, 3.0, 0.0, 3.0, 14.0, 2.0, 3.0, 3.0, 3.0, 6.0, 5.0, 3.0, 8.0, 9.0, 6.0, 5.0, 1.0, 4.0, 4.0, 4.0, 4.0, 6.0, 17.0, 5.0, 5.0, 20.0, 7.0, 3.0, 9.0, 7.0, 1.0, 5.0, 22.0, 13.0, 13.0, 16.0, 5.0, 7.0, 40.0, 4.0, 7.0, 16.0, 7.0, 6.0, 7.0, 5.0, 10.0, 16.0, 0.0, 8.0, 12.0, 1.0, 5.0, 9.0, 3.0, 10.0, 7.0, 5.0, 3.0, 4.0, 18.0, 16.0, 1.0, 9.0, 64.0, 47.0, 7.0, 0.0, 8.0, 3.0, 4.0, 26.0, 8.0, 10.0, 2.0, 31.0, 6.0, 8.0, 7.0, 3.0, 8.0, 9.0, 27.0, 30.0, 3.0, 42.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6105423035308197, "mean_inference_ms": 1.9002712271408222, "mean_action_processing_ms": 0.2425238873567259, "mean_env_wait_ms": 0.19634891044884623, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006201267242431641, "StateBufferConnector_ms": 0.003941178321838379, "ViewRequirementAgentConnector_ms": 0.12528884410858154}, "num_episodes": 18, "episode_return_max": 3.989999999999959, "episode_return_min": -123.38999999999939, "episode_return_mean": -12.612199999999971, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 416000, "num_agent_steps_trained": 416000, "num_env_steps_sampled": 104000, "num_env_steps_trained": 104000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 367.87657258522245, "num_env_steps_trained_throughput_per_sec": 367.87657258522245, "timesteps_total": 104000, "num_env_steps_sampled_lifetime": 104000, "num_agent_steps_sampled_lifetime": 416000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 416000, "timers": {"training_iteration_time_ms": 10774.863, "restore_workers_time_ms": 0.016, "training_step_time_ms": 10774.818, "sample_time_ms": 1485.555, "learn_time_ms": 9270.974, "learn_throughput": 431.454, "synch_weights_time_ms": 16.67}, "counters": {"num_env_steps_sampled": 104000, "num_env_steps_trained": 104000, "num_agent_steps_sampled": 416000, "num_agent_steps_trained": 416000}, "done": false, "training_iteration": 26, "trial_id": "8e499_00000", "date": "2024-08-15_02-08-58", "timestamp": 1723667938, "time_this_iter_s": 10.936434984207153, "time_total_s": 279.1027491092682, "pid": 33199, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x15800f4c0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 279.1027491092682, "iterations_since_restore": 26, "perf": {"cpu_util_percent": 33.49333333333333, "ram_util_percent": 82.58}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8985494894877313, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.5460214639466906, "policy_loss": -0.008196788231186844, "vf_loss": 0.5533164812695412, "vf_explained_var": 0.10764047960755686, "kl": 0.008015752928004551, "entropy": 1.2565636031842105, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 50085.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6636507089254717, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.5288048011473769, "policy_loss": -0.012765363290679281, "vf_loss": 0.5409913670488451, "vf_explained_var": 0.012829195254694217, "kl": 0.005787979771372058, "entropy": 1.0996834158266664, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 50085.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 108000, "num_env_steps_trained": 108000, "num_agent_steps_sampled": 432000, "num_agent_steps_trained": 432000}, "env_runners": {"episode_reward_max": 3.9999999999999587, "episode_reward_min": -123.38999999999939, "episode_reward_mean": -11.910799999999973, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -277.3900000000002, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 2.0000000000000013, "predator_policy": 124.0}, "policy_reward_mean": {"prey_policy": -17.175400000000003, "predator_policy": 11.22}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-24.280000000000058, -3.1300000000000807, -7.110000000000083, -2.0800000000000827, -48.79000000000021, -9.130000000000082, -48.55000000000011, -123.38999999999939, 2.909999999999983, -15.189999999999582, -13.169999999999916, -18.21999999999944, -98.0099999999996, -6.180000000000081, 0.969999999999981, -38.42000000000066, -0.10000000000003921, -6.100000000000083, -0.060000000000041, -3.110000000000083, -31.35000000000044, -0.10000000000004099, 3.989999999999959, -8.120000000000083, -6.100000000000083, -31.34000000000045, 2.9799999999999813, 2.949999999999982, 0.9599999999999819, 0.939999999999981, -1.0600000000000631, 0.9499999999999819, -21.209999999999408, -4.080000000000084, -2.1100000000000794, -1.050000000000063, 0.9699999999999819, -12.160000000000082, -2.060000000000084, 0.9399999999999819, -2.070000000000082, -9.150000000000082, 2.939999999999982, 0.9599999999999828, 3.9599999999999596, 1.9400000000000026, -18.219999999999448, -21.24999999999943, -0.07000000000004011, 1.9100000000000028, -0.05000000000004011, -7.230000000000077, -25.28999999999942, -6.110000000000083, -32.40000000000062, -39.33000000000016, -9.130000000000082, 1.9300000000000028, -4.170000000000082, -10.110000000000083, -9.130000000000082, -10.140000000000082, -7.120000000000083, 1.9300000000000033, -3.0700000000000838, -0.19000000000003747, -4.090000000000082, -19.669999999999604, -11.110000000000083, -7.110000000000083, -18.259999999999447, 1.9000000000000026, -29.32999999999969, -10.140000000000082, -6.100000000000083, -13.16999999999991, 0.699999999999983, -41.45000000000013, -26.299999999999425, 0.9099999999999818, -3.120000000000081, 1.920000000000003, -6.100000000000083, -33.43000000000066, 3.9999999999999587, -15.209999999999553, -16.199999999999445, -5.100000000000083, -1.0800000000000622, 0.8899999999999836, 2.9699999999999815, -21.249999999999414, -23.26999999999942, -5.090000000000083, 0.9399999999999819, -13.199999999999912, 2.9199999999999826, -31.35000000000043, -81.13999999999854, -0.10000000000003921], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [2.0000000000000013, -54.28000000000004, -4.030000000000042, -18.09999999999971, -14.080000000000041, -4.030000000000042, -14.080000000000041, 2.0000000000000013, -118.59999999999977, -36.190000000000346, -10.060000000000041, -12.070000000000041, -98.49999999999976, -8.050000000000042, 2.0000000000000013, -277.3900000000002, 2.0000000000000013, -16.0899999999997, 2.0000000000000013, -36.19000000000036, -10.06000000000004, -20.109999999999705, 2.0000000000000013, -42.220000000000354, -190.9600000000001, -8.050000000000042, -28.14999999999971, -4.030000000000042, -4.030000000000042, 2.0000000000000013, -26.139999999999766, -54.280000000000335, 2.0000000000000013, -18.099999999999703, -0.00999999999999836, -16.089999999999705, -8.050000000000042, -0.00999999999999836, -16.0899999999997, -2.020000000000042, -54.28000000000034, -12.070000000000041, -0.00999999999999836, -16.0899999999997, 2.0000000000000013, -0.00999999999999836, -8.050000000000042, -12.070000000000041, -2.0200000000000413, -14.080000000000041, -38.20000000000034, -26.139999999999713, -2.020000000000042, 2.0000000000000013, 2.0000000000000013, -8.050000000000042, 2.0000000000000013, -6.040000000000042, -0.00999999999999836, -8.050000000000042, -0.00999999999999836, -8.050000000000042, 2.0000000000000013, -8.050000000000042, -14.080000000000041, -24.129999999999708, -14.080000000000041, 2.0000000000000013, -10.060000000000041, -8.05000000000004, -4.030000000000042, -2.020000000000042, 2.0000000000000013, -4.030000000000042, -2.020000000000042, -26.13999999999971, -4.030000000000042, -4.030000000000042, 2.0000000000000013, -10.060000000000041, -12.070000000000041, 2.0000000000000013, -10.060000000000041, -16.0899999999997, 2.0000000000000013, -10.060000000000041, 2.0000000000000013, -6.040000000000042, 2.0000000000000013, -6.040000000000042, -10.060000000000041, 2.0000000000000013, -42.22000000000035, 2.0000000000000013, -30.159999999999723, -16.0899999999997, 2.0000000000000013, -12.070000000000041, -16.0899999999997, 2.0000000000000013, 2.0000000000000013, -8.050000000000042, 2.0000000000000013, -44.23000000000035, -24.129999999999708, -30.159999999999712, -6.040000000000042, -12.070000000000041, -78.3999999999992, 2.0000000000000013, -34.18000000000008, -28.15, -12.070000000000041, -10.060000000000041, -12.070000000000041, 2.0000000000000013, -32.170000000000364, 2.0000000000000013, -14.080000000000041, -4.030000000000042, -0.00999999999999836, -22.119999999999706, -26.139999999999723, 2.0000000000000013, -2.020000000000042, -18.099999999999703, 2.0000000000000013, -12.070000000000041, -4.030000000000042, -6.040000000000042, -30.159999999999727, -4.030000000000042, 2.0000000000000013, -16.0899999999997, -132.67000000000115, 2.0000000000000013, -6.040000000000042, -12.070000000000041, -14.080000000000041, -4.030000000000042, -50.260000000000346, 2.0000000000000013, 2.0000000000000013, -18.099999999999703, -60.310000000000336, -2.020000000000042, -14.080000000000041, -10.060000000000041, -18.099999999999707, 2.0000000000000013, -14.080000000000041, -16.0899999999997, -58.30000000000034, 2.0000000000000013, -4.030000000000042, -82.4199999999998, -46.24000000000035, -10.060000000000041, 2.0000000000000013, -16.0899999999997, 2.0000000000000013, -22.119999999999706, 2.0000000000000013, -14.080000000000041, -6.040000000000042, -10.060000000000041, -40.210000000000335, -42.220000000000354, 2.0000000000000013, 2.0000000000000013, -14.080000000000041, -24.129999999999708, -24.129999999999725, -12.070000000000041, -10.060000000000041, -6.040000000000042, -14.080000000000041, 2.0000000000000013, 2.0000000000000013, -20.109999999999705, -4.030000000000042, 2.0000000000000013, -32.170000000000364, -14.080000000000041, -14.080000000000041, -36.19000000000036, -8.050000000000042, -6.040000000000042, -10.060000000000041, 2.0000000000000013, -14.080000000000041, -22.119999999999706, -14.080000000000041, 2.0000000000000013, -52.270000000000344, -14.080000000000041, -82.41999999999919, -142.7200000000011, -18.099999999999703, 2.0000000000000013], "policy_predator_policy_reward": [28.0, 0.0, 9.0, 10.0, 3.0, 8.0, 8.0, 2.0, 56.0, 50.0, 6.0, 7.0, 34.0, 24.0, 28.0, 124.0, 9.0, 8.0, 0.0, 19.0, 11.0, 6.0, 0.0, 22.0, 11.0, 90.0, 12.0, 14.0, 0.0, 3.0, 14.0, 28.0, 6.0, 10.0, 1.0, 9.0, 4.0, 4.0, 8.0, 7.0, 28.0, 7.0, 9.0, 7.0, 1.0, 1.0, 5.0, 7.0, 8.0, 2.0, 9.0, 24.0, 1.0, 2.0, 5.0, 4.0, 1.0, 4.0, 5.0, 4.0, 5.0, 2.0, 2.0, 5.0, 4.0, 13.0, 0.0, 8.0, 6.0, 10.0, 2.0, 3.0, 0.0, 3.0, 14.0, 2.0, 3.0, 3.0, 3.0, 6.0, 5.0, 3.0, 8.0, 9.0, 6.0, 5.0, 1.0, 4.0, 4.0, 4.0, 4.0, 6.0, 17.0, 5.0, 5.0, 20.0, 7.0, 3.0, 9.0, 7.0, 1.0, 5.0, 22.0, 13.0, 13.0, 16.0, 5.0, 7.0, 40.0, 4.0, 7.0, 16.0, 7.0, 6.0, 7.0, 5.0, 10.0, 16.0, 0.0, 8.0, 12.0, 1.0, 5.0, 9.0, 3.0, 10.0, 7.0, 5.0, 3.0, 4.0, 18.0, 16.0, 1.0, 9.0, 64.0, 47.0, 7.0, 0.0, 8.0, 3.0, 4.0, 26.0, 8.0, 10.0, 2.0, 31.0, 6.0, 8.0, 7.0, 3.0, 8.0, 9.0, 27.0, 30.0, 3.0, 42.0, 6.0, 24.0, 6.0, 9.0, 5.0, 12.0, 6.0, 8.0, 6.0, 4.0, 34.0, 15.0, 0.0, 0.0, 10.0, 13.0, 3.0, 17.0, 5.0, 6.0, 8.0, 3.0, 8.0, 11.0, 3.0, 2.0, 8.0, 17.0, 19.0, 8.0, 4.0, 5.0, 3.0, 6.0, 12.0, 11.0, 8.0, 7.0, 19.0, 16.0, 70.0, 74.0, 10.0, 6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6166373892643, "mean_inference_ms": 1.9186615601889094, "mean_action_processing_ms": 0.24482747277639677, "mean_env_wait_ms": 0.19874732271119952, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006981611251831055, "StateBufferConnector_ms": 0.0039130449295043945, "ViewRequirementAgentConnector_ms": 0.1267150640487671}, "num_episodes": 22, "episode_return_max": 3.9999999999999587, "episode_return_min": -123.38999999999939, "episode_return_mean": -11.910799999999973, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 432000, "num_agent_steps_trained": 432000, "num_env_steps_sampled": 108000, "num_env_steps_trained": 108000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 368.4611910734052, "num_env_steps_trained_throughput_per_sec": 368.4611910734052, "timesteps_total": 108000, "num_env_steps_sampled_lifetime": 108000, "num_agent_steps_sampled_lifetime": 432000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 432000, "timers": {"training_iteration_time_ms": 10836.862, "restore_workers_time_ms": 0.016, "training_step_time_ms": 10836.817, "sample_time_ms": 1497.349, "learn_time_ms": 9321.061, "learn_throughput": 429.136, "synch_weights_time_ms": 16.647}, "counters": {"num_env_steps_sampled": 108000, "num_env_steps_trained": 108000, "num_agent_steps_sampled": 432000, "num_agent_steps_trained": 432000}, "done": false, "training_iteration": 27, "trial_id": "8e499_00000", "date": "2024-08-15_02-09-09", "timestamp": 1723667949, "time_this_iter_s": 10.911787986755371, "time_total_s": 290.01453709602356, "pid": 33199, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x15800f160>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 290.01453709602356, "iterations_since_restore": 27, "perf": {"cpu_util_percent": 36.3, "ram_util_percent": 83.45625}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1256924111376363, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.1819714865356525, "policy_loss": -0.00519541472531658, "vf_loss": 4.186163302451845, "vf_explained_var": -0.002295903964017434, "kl": 0.008920887526522276, "entropy": 1.262997061550302, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 51975.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6586596002654423, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.387836630949898, "policy_loss": -0.01117380242770114, "vf_loss": 3.397524833931494, "vf_explained_var": 0.01856446136873235, "kl": 0.014856048191713805, "entropy": 1.0322499862423649, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 51975.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 112000, "num_env_steps_trained": 112000, "num_agent_steps_sampled": 448000, "num_agent_steps_trained": 448000}, "env_runners": {"episode_reward_max": 3.9999999999999587, "episode_reward_min": -270.63000000000017, "episode_reward_mean": -20.024899999999956, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -349.7500000000001, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 2.0000000000000013, "predator_policy": 163.0}, "policy_reward_mean": {"prey_policy": -26.632450000000002, "predator_policy": 16.62}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-8.120000000000083, -6.100000000000083, -31.34000000000045, 2.9799999999999813, 2.949999999999982, 0.9599999999999819, 0.939999999999981, -1.0600000000000631, 0.9499999999999819, -21.209999999999408, -4.080000000000084, -2.1100000000000794, -1.050000000000063, 0.9699999999999819, -12.160000000000082, -2.060000000000084, 0.9399999999999819, -2.070000000000082, -9.150000000000082, 2.939999999999982, 0.9599999999999828, 3.9599999999999596, 1.9400000000000026, -18.219999999999448, -21.24999999999943, -0.07000000000004011, 1.9100000000000028, -0.05000000000004011, -7.230000000000077, -25.28999999999942, -6.110000000000083, -32.40000000000062, -39.33000000000016, -9.130000000000082, 1.9300000000000028, -4.170000000000082, -10.110000000000083, -9.130000000000082, -10.140000000000082, -7.120000000000083, 1.9300000000000033, -3.0700000000000838, -0.19000000000003747, -4.090000000000082, -19.669999999999604, -11.110000000000083, -7.110000000000083, -18.259999999999447, 1.9000000000000026, -29.32999999999969, -10.140000000000082, -6.100000000000083, -13.16999999999991, 0.699999999999983, -41.45000000000013, -26.299999999999425, 0.9099999999999818, -3.120000000000081, 1.920000000000003, -6.100000000000083, -33.43000000000066, 3.9999999999999587, -15.209999999999553, -16.199999999999445, -5.100000000000083, -1.0800000000000622, 0.8899999999999836, 2.9699999999999815, -21.249999999999414, -23.26999999999942, -5.090000000000083, 0.9399999999999819, -13.199999999999912, 2.9199999999999826, -31.35000000000043, -81.13999999999854, -0.10000000000003921, -31.340000000000195, -118.64999999999957, -7.110000000000083, -50.39000000000072, -62.789999999999566, -67.49999999999906, -10.160000000000082, -13.16999999999991, -2.1300000000000816, -78.63000000000005, -2.060000000000084, -20.339999999999456, -11.150000000000082, -99.85999999999984, -22.239999999999412, -270.63000000000017, -1.0900000000000623, -8.120000000000083, -118.35999999999943, -83.1499999999996, -9.130000000000082, -56.32000000000011, -155.69000000000057], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-8.050000000000042, -12.070000000000041, -2.0200000000000413, -14.080000000000041, -38.20000000000034, -26.139999999999713, -2.020000000000042, 2.0000000000000013, 2.0000000000000013, -8.050000000000042, 2.0000000000000013, -6.040000000000042, -0.00999999999999836, -8.050000000000042, -0.00999999999999836, -8.050000000000042, 2.0000000000000013, -8.050000000000042, -14.080000000000041, -24.129999999999708, -14.080000000000041, 2.0000000000000013, -10.060000000000041, -8.05000000000004, -4.030000000000042, -2.020000000000042, 2.0000000000000013, -4.030000000000042, -2.020000000000042, -26.13999999999971, -4.030000000000042, -4.030000000000042, 2.0000000000000013, -10.060000000000041, -12.070000000000041, 2.0000000000000013, -10.060000000000041, -16.0899999999997, 2.0000000000000013, -10.060000000000041, 2.0000000000000013, -6.040000000000042, 2.0000000000000013, -6.040000000000042, -10.060000000000041, 2.0000000000000013, -42.22000000000035, 2.0000000000000013, -30.159999999999723, -16.0899999999997, 2.0000000000000013, -12.070000000000041, -16.0899999999997, 2.0000000000000013, 2.0000000000000013, -8.050000000000042, 2.0000000000000013, -44.23000000000035, -24.129999999999708, -30.159999999999712, -6.040000000000042, -12.070000000000041, -78.3999999999992, 2.0000000000000013, -34.18000000000008, -28.15, -12.070000000000041, -10.060000000000041, -12.070000000000041, 2.0000000000000013, -32.170000000000364, 2.0000000000000013, -14.080000000000041, -4.030000000000042, -0.00999999999999836, -22.119999999999706, -26.139999999999723, 2.0000000000000013, -2.020000000000042, -18.099999999999703, 2.0000000000000013, -12.070000000000041, -4.030000000000042, -6.040000000000042, -30.159999999999727, -4.030000000000042, 2.0000000000000013, -16.0899999999997, -132.67000000000115, 2.0000000000000013, -6.040000000000042, -12.070000000000041, -14.080000000000041, -4.030000000000042, -50.260000000000346, 2.0000000000000013, 2.0000000000000013, -18.099999999999703, -60.310000000000336, -2.020000000000042, -14.080000000000041, -10.060000000000041, -18.099999999999707, 2.0000000000000013, -14.080000000000041, -16.0899999999997, -58.30000000000034, 2.0000000000000013, -4.030000000000042, -82.4199999999998, -46.24000000000035, -10.060000000000041, 2.0000000000000013, -16.0899999999997, 2.0000000000000013, -22.119999999999706, 2.0000000000000013, -14.080000000000041, -6.040000000000042, -10.060000000000041, -40.210000000000335, -42.220000000000354, 2.0000000000000013, 2.0000000000000013, -14.080000000000041, -24.129999999999708, -24.129999999999725, -12.070000000000041, -10.060000000000041, -6.040000000000042, -14.080000000000041, 2.0000000000000013, 2.0000000000000013, -20.109999999999705, -4.030000000000042, 2.0000000000000013, -32.170000000000364, -14.080000000000041, -14.080000000000041, -36.19000000000036, -8.050000000000042, -6.040000000000042, -10.060000000000041, 2.0000000000000013, -14.080000000000041, -22.119999999999706, -14.080000000000041, 2.0000000000000013, -52.270000000000344, -14.080000000000041, -82.41999999999919, -142.7200000000011, -18.099999999999703, 2.0000000000000013, -48.2500000000003, -16.089999999999844, -325.63, -2.020000000000042, -14.080000000000041, -4.030000000000042, -30.159999999999716, -44.23000000000035, -36.190000000000246, -118.59999999999928, -52.27000000000026, -44.23000000000026, -10.060000000000041, -18.099999999999703, -18.099999999999703, -12.070000000000041, -10.060000000000038, -12.070000000000041, -48.25000000000002, -74.38000000000001, -4.030000000000042, -4.030000000000042, -24.129999999999736, -40.210000000000356, -8.050000000000042, -18.099999999999703, -349.7500000000001, -20.109999999999705, -26.13999999999971, -18.099999999999703, -275.38000000000005, -249.25, 2.0000000000000013, -16.0899999999997, -2.020000000000042, -18.099999999999707, -237.19000000000023, -32.1700000000003, -8.050000000000042, -219.10000000000025, -12.070000000000041, -10.060000000000041, -247.24000000000012, -14.080000000000041, -317.5900000000002, -18.099999999999703], "policy_predator_policy_reward": [5.0, 7.0, 8.0, 2.0, 9.0, 24.0, 1.0, 2.0, 5.0, 4.0, 1.0, 4.0, 5.0, 4.0, 5.0, 2.0, 2.0, 5.0, 4.0, 13.0, 0.0, 8.0, 6.0, 10.0, 2.0, 3.0, 0.0, 3.0, 14.0, 2.0, 3.0, 3.0, 3.0, 6.0, 5.0, 3.0, 8.0, 9.0, 6.0, 5.0, 1.0, 4.0, 4.0, 4.0, 4.0, 6.0, 17.0, 5.0, 5.0, 20.0, 7.0, 3.0, 9.0, 7.0, 1.0, 5.0, 22.0, 13.0, 13.0, 16.0, 5.0, 7.0, 40.0, 4.0, 7.0, 16.0, 7.0, 6.0, 7.0, 5.0, 10.0, 16.0, 0.0, 8.0, 12.0, 1.0, 5.0, 9.0, 3.0, 10.0, 7.0, 5.0, 3.0, 4.0, 18.0, 16.0, 1.0, 9.0, 64.0, 47.0, 7.0, 0.0, 8.0, 3.0, 4.0, 26.0, 8.0, 10.0, 2.0, 31.0, 6.0, 8.0, 7.0, 3.0, 8.0, 9.0, 27.0, 30.0, 3.0, 42.0, 6.0, 24.0, 6.0, 9.0, 5.0, 12.0, 6.0, 8.0, 6.0, 4.0, 34.0, 15.0, 0.0, 0.0, 10.0, 13.0, 3.0, 17.0, 5.0, 6.0, 8.0, 3.0, 8.0, 11.0, 3.0, 2.0, 8.0, 17.0, 19.0, 8.0, 4.0, 5.0, 3.0, 6.0, 12.0, 11.0, 8.0, 7.0, 19.0, 16.0, 70.0, 74.0, 10.0, 6.0, 28.0, 5.0, 141.0, 68.0, 8.0, 3.0, 23.0, 1.0, 36.0, 56.0, 3.0, 26.0, 10.0, 8.0, 10.0, 7.0, 12.0, 8.0, 27.0, 17.0, 3.0, 3.0, 20.0, 24.0, 5.0, 10.0, 163.0, 107.0, 10.0, 12.0, 141.0, 113.0, 4.0, 9.0, 2.0, 10.0, 41.0, 110.0, 96.0, 48.0, 7.0, 6.0, 104.0, 101.0, 152.0, 28.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6236112739529259, "mean_inference_ms": 1.9416662021276998, "mean_action_processing_ms": 0.2530231355745088, "mean_env_wait_ms": 0.20116035012443942, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007898688316345215, "StateBufferConnector_ms": 0.003929257392883301, "ViewRequirementAgentConnector_ms": 0.1273266077041626}, "num_episodes": 23, "episode_return_max": 3.9999999999999587, "episode_return_min": -270.63000000000017, "episode_return_mean": -20.024899999999956, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 448000, "num_agent_steps_trained": 448000, "num_env_steps_sampled": 112000, "num_env_steps_trained": 112000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 358.9215326592889, "num_env_steps_trained_throughput_per_sec": 358.9215326592889, "timesteps_total": 112000, "num_env_steps_sampled_lifetime": 112000, "num_agent_steps_sampled_lifetime": 448000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 448000, "timers": {"training_iteration_time_ms": 10952.988, "restore_workers_time_ms": 0.016, "training_step_time_ms": 10952.942, "sample_time_ms": 1547.977, "learn_time_ms": 9386.335, "learn_throughput": 426.151, "synch_weights_time_ms": 16.86}, "counters": {"num_env_steps_sampled": 112000, "num_env_steps_trained": 112000, "num_agent_steps_sampled": 448000, "num_agent_steps_trained": 448000}, "done": false, "training_iteration": 28, "trial_id": "8e499_00000", "date": "2024-08-15_02-09-20", "timestamp": 1723667960, "time_this_iter_s": 11.174956798553467, "time_total_s": 301.189493894577, "pid": 33199, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b43f2dc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 301.189493894577, "iterations_since_restore": 28, "perf": {"cpu_util_percent": 31.775000000000002, "ram_util_percent": 82.49375}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2882564445178974, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.5604489900763072, "policy_loss": -0.008056142268623546, "vf_loss": 1.5676406651577621, "vf_explained_var": 0.1758899984220979, "kl": 0.007684115329627697, "entropy": 1.2537236308925366, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 53865.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6683131307284668, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.2027905450926886, "policy_loss": -0.013314327587023693, "vf_loss": 2.215324306866479, "vf_explained_var": 0.011068399526454784, "kl": 0.007805752243828432, "entropy": 1.0615373979169855, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 53865.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 116000, "num_env_steps_trained": 116000, "num_agent_steps_sampled": 464000, "num_agent_steps_trained": 464000}, "env_runners": {"episode_reward_max": 3.9999999999999587, "episode_reward_min": -270.63000000000017, "episode_reward_mean": -24.035999999999966, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -349.7500000000001, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 2.0000000000000013, "predator_policy": 163.0}, "policy_reward_mean": {"prey_policy": -30.76299999999999, "predator_policy": 18.745}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-9.150000000000082, 2.939999999999982, 0.9599999999999828, 3.9599999999999596, 1.9400000000000026, -18.219999999999448, -21.24999999999943, -0.07000000000004011, 1.9100000000000028, -0.05000000000004011, -7.230000000000077, -25.28999999999942, -6.110000000000083, -32.40000000000062, -39.33000000000016, -9.130000000000082, 1.9300000000000028, -4.170000000000082, -10.110000000000083, -9.130000000000082, -10.140000000000082, -7.120000000000083, 1.9300000000000033, -3.0700000000000838, -0.19000000000003747, -4.090000000000082, -19.669999999999604, -11.110000000000083, -7.110000000000083, -18.259999999999447, 1.9000000000000026, -29.32999999999969, -10.140000000000082, -6.100000000000083, -13.16999999999991, 0.699999999999983, -41.45000000000013, -26.299999999999425, 0.9099999999999818, -3.120000000000081, 1.920000000000003, -6.100000000000083, -33.43000000000066, 3.9999999999999587, -15.209999999999553, -16.199999999999445, -5.100000000000083, -1.0800000000000622, 0.8899999999999836, 2.9699999999999815, -21.249999999999414, -23.26999999999942, -5.090000000000083, 0.9399999999999819, -13.199999999999912, 2.9199999999999826, -31.35000000000043, -81.13999999999854, -0.10000000000003921, -31.340000000000195, -118.64999999999957, -7.110000000000083, -50.39000000000072, -62.789999999999566, -67.49999999999906, -10.160000000000082, -13.16999999999991, -2.1300000000000816, -78.63000000000005, -2.060000000000084, -20.339999999999456, -11.150000000000082, -99.85999999999984, -22.239999999999412, -270.63000000000017, -1.0900000000000623, -8.120000000000083, -118.35999999999943, -83.1499999999996, -9.130000000000082, -56.32000000000011, -155.69000000000057, -5.110000000000081, 2.9699999999999815, -7.110000000000081, -62.6100000000006, -33.390000000000434, -1.0700000000000631, 2.9799999999999813, -49.53000000000012, -11.150000000000084, -149.73000000000093, -11.140000000000082, -13.169999999999991, -2.0900000000000833, -52.41000000000044, -63.639999999999056, -20.239999999999416, -0.040000000000040996, -5.300000000000079], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-10.060000000000041, -16.0899999999997, 2.0000000000000013, -10.060000000000041, 2.0000000000000013, -6.040000000000042, 2.0000000000000013, -6.040000000000042, -10.060000000000041, 2.0000000000000013, -42.22000000000035, 2.0000000000000013, -30.159999999999723, -16.0899999999997, 2.0000000000000013, -12.070000000000041, -16.0899999999997, 2.0000000000000013, 2.0000000000000013, -8.050000000000042, 2.0000000000000013, -44.23000000000035, -24.129999999999708, -30.159999999999712, -6.040000000000042, -12.070000000000041, -78.3999999999992, 2.0000000000000013, -34.18000000000008, -28.15, -12.070000000000041, -10.060000000000041, -12.070000000000041, 2.0000000000000013, -32.170000000000364, 2.0000000000000013, -14.080000000000041, -4.030000000000042, -0.00999999999999836, -22.119999999999706, -26.139999999999723, 2.0000000000000013, -2.020000000000042, -18.099999999999703, 2.0000000000000013, -12.070000000000041, -4.030000000000042, -6.040000000000042, -30.159999999999727, -4.030000000000042, 2.0000000000000013, -16.0899999999997, -132.67000000000115, 2.0000000000000013, -6.040000000000042, -12.070000000000041, -14.080000000000041, -4.030000000000042, -50.260000000000346, 2.0000000000000013, 2.0000000000000013, -18.099999999999703, -60.310000000000336, -2.020000000000042, -14.080000000000041, -10.060000000000041, -18.099999999999707, 2.0000000000000013, -14.080000000000041, -16.0899999999997, -58.30000000000034, 2.0000000000000013, -4.030000000000042, -82.4199999999998, -46.24000000000035, -10.060000000000041, 2.0000000000000013, -16.0899999999997, 2.0000000000000013, -22.119999999999706, 2.0000000000000013, -14.080000000000041, -6.040000000000042, -10.060000000000041, -40.210000000000335, -42.220000000000354, 2.0000000000000013, 2.0000000000000013, -14.080000000000041, -24.129999999999708, -24.129999999999725, -12.070000000000041, -10.060000000000041, -6.040000000000042, -14.080000000000041, 2.0000000000000013, 2.0000000000000013, -20.109999999999705, -4.030000000000042, 2.0000000000000013, -32.170000000000364, -14.080000000000041, -14.080000000000041, -36.19000000000036, -8.050000000000042, -6.040000000000042, -10.060000000000041, 2.0000000000000013, -14.080000000000041, -22.119999999999706, -14.080000000000041, 2.0000000000000013, -52.270000000000344, -14.080000000000041, -82.41999999999919, -142.7200000000011, -18.099999999999703, 2.0000000000000013, -48.2500000000003, -16.089999999999844, -325.63, -2.020000000000042, -14.080000000000041, -4.030000000000042, -30.159999999999716, -44.23000000000035, -36.190000000000246, -118.59999999999928, -52.27000000000026, -44.23000000000026, -10.060000000000041, -18.099999999999703, -18.099999999999703, -12.070000000000041, -10.060000000000038, -12.070000000000041, -48.25000000000002, -74.38000000000001, -4.030000000000042, -4.030000000000042, -24.129999999999736, -40.210000000000356, -8.050000000000042, -18.099999999999703, -349.7500000000001, -20.109999999999705, -26.13999999999971, -18.099999999999703, -275.38000000000005, -249.25, 2.0000000000000013, -16.0899999999997, -2.020000000000042, -18.099999999999707, -237.19000000000023, -32.1700000000003, -8.050000000000042, -219.10000000000025, -12.070000000000041, -10.060000000000041, -247.24000000000012, -14.080000000000041, -317.5900000000002, -18.099999999999703, -20.109999999999705, 2.0000000000000013, 2.0000000000000013, -4.030000000000042, -6.040000000000037, -12.070000000000041, -38.19999999999999, -80.40999999999919, -72.36999999999942, -2.0200000000000413, -12.070000000000041, 2.0000000000000013, -2.020000000000042, 2.0000000000000013, -68.34999999999965, -34.18000000000036, -14.080000000000041, -12.070000000000041, -287.4400000000005, -56.29000000000014, -16.0899999999997, -8.050000000000042, -24.12999999999974, -6.040000000000042, -14.080000000000041, -0.00999999999999836, -46.240000000000215, -32.17000000000016, -44.2300000000002, -80.40999999999941, -28.149999999999714, -16.0899999999997, -2.020000000000042, -2.020000000000042, -58.30000000000034, 2.0000000000000013], "policy_predator_policy_reward": [8.0, 9.0, 6.0, 5.0, 1.0, 4.0, 4.0, 4.0, 4.0, 6.0, 17.0, 5.0, 5.0, 20.0, 7.0, 3.0, 9.0, 7.0, 1.0, 5.0, 22.0, 13.0, 13.0, 16.0, 5.0, 7.0, 40.0, 4.0, 7.0, 16.0, 7.0, 6.0, 7.0, 5.0, 10.0, 16.0, 0.0, 8.0, 12.0, 1.0, 5.0, 9.0, 3.0, 10.0, 7.0, 5.0, 3.0, 4.0, 18.0, 16.0, 1.0, 9.0, 64.0, 47.0, 7.0, 0.0, 8.0, 3.0, 4.0, 26.0, 8.0, 10.0, 2.0, 31.0, 6.0, 8.0, 7.0, 3.0, 8.0, 9.0, 27.0, 30.0, 3.0, 42.0, 6.0, 24.0, 6.0, 9.0, 5.0, 12.0, 6.0, 8.0, 6.0, 4.0, 34.0, 15.0, 0.0, 0.0, 10.0, 13.0, 3.0, 17.0, 5.0, 6.0, 8.0, 3.0, 8.0, 11.0, 3.0, 2.0, 8.0, 17.0, 19.0, 8.0, 4.0, 5.0, 3.0, 6.0, 12.0, 11.0, 8.0, 7.0, 19.0, 16.0, 70.0, 74.0, 10.0, 6.0, 28.0, 5.0, 141.0, 68.0, 8.0, 3.0, 23.0, 1.0, 36.0, 56.0, 3.0, 26.0, 10.0, 8.0, 10.0, 7.0, 12.0, 8.0, 27.0, 17.0, 3.0, 3.0, 20.0, 24.0, 5.0, 10.0, 163.0, 107.0, 10.0, 12.0, 141.0, 113.0, 4.0, 9.0, 2.0, 10.0, 41.0, 110.0, 96.0, 48.0, 7.0, 6.0, 104.0, 101.0, 152.0, 28.0, 2.0, 11.0, 3.0, 2.0, 0.0, 11.0, 15.0, 41.0, 30.0, 11.0, 2.0, 7.0, 2.0, 1.0, 47.0, 6.0, 7.0, 8.0, 52.0, 142.0, 4.0, 9.0, 4.0, 13.0, 8.0, 4.0, 13.0, 13.0, 4.0, 57.0, 15.0, 9.0, 2.0, 2.0, 28.0, 23.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6233838911707995, "mean_inference_ms": 1.9431793904746928, "mean_action_processing_ms": 0.2569745889204318, "mean_env_wait_ms": 0.20131894391634422, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00711822509765625, "StateBufferConnector_ms": 0.003187894821166992, "ViewRequirementAgentConnector_ms": 0.10699462890625}, "num_episodes": 18, "episode_return_max": 3.9999999999999587, "episode_return_min": -270.63000000000017, "episode_return_mean": -24.035999999999966, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 464000, "num_agent_steps_trained": 464000, "num_env_steps_sampled": 116000, "num_env_steps_trained": 116000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 355.9783229666971, "num_env_steps_trained_throughput_per_sec": 355.9783229666971, "timesteps_total": 116000, "num_env_steps_sampled_lifetime": 116000, "num_agent_steps_sampled_lifetime": 464000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 464000, "timers": {"training_iteration_time_ms": 11074.764, "restore_workers_time_ms": 0.016, "training_step_time_ms": 11074.718, "sample_time_ms": 1549.129, "learn_time_ms": 9507.097, "learn_throughput": 420.738, "synch_weights_time_ms": 16.654}, "counters": {"num_env_steps_sampled": 116000, "num_env_steps_trained": 116000, "num_agent_steps_sampled": 464000, "num_agent_steps_trained": 464000}, "done": false, "training_iteration": 29, "trial_id": "8e499_00000", "date": "2024-08-15_02-09-32", "timestamp": 1723667972, "time_this_iter_s": 11.287561893463135, "time_total_s": 312.47705578804016, "pid": 33199, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b43f0700>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 312.47705578804016, "iterations_since_restore": 29, "perf": {"cpu_util_percent": 37.21875, "ram_util_percent": 83.55000000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0824409380003257, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.621949480734174, "policy_loss": -0.008164552693555831, "vf_loss": 1.6289333782025746, "vf_explained_var": 0.24124405201149995, "kl": 0.010494733478866519, "entropy": 1.2247478354544867, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 55755.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6974434412897579, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.24620364380892, "policy_loss": -0.012822916653135388, "vf_loss": 2.2582764331625884, "vf_explained_var": 0.017104898211817262, "kl": 0.007501308673996944, "entropy": 1.1014009880010414, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 55755.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 120000, "num_env_steps_trained": 120000, "num_agent_steps_sampled": 480000, "num_agent_steps_trained": 480000}, "env_runners": {"episode_reward_max": 3.9999999999999587, "episode_reward_min": -270.63000000000017, "episode_reward_mean": -29.579799999999935, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -349.7500000000001, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 2.0000000000000013, "predator_policy": 163.0}, "policy_reward_mean": {"prey_policy": -36.169900000000005, "predator_policy": 21.38}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-10.110000000000083, -9.130000000000082, -10.140000000000082, -7.120000000000083, 1.9300000000000033, -3.0700000000000838, -0.19000000000003747, -4.090000000000082, -19.669999999999604, -11.110000000000083, -7.110000000000083, -18.259999999999447, 1.9000000000000026, -29.32999999999969, -10.140000000000082, -6.100000000000083, -13.16999999999991, 0.699999999999983, -41.45000000000013, -26.299999999999425, 0.9099999999999818, -3.120000000000081, 1.920000000000003, -6.100000000000083, -33.43000000000066, 3.9999999999999587, -15.209999999999553, -16.199999999999445, -5.100000000000083, -1.0800000000000622, 0.8899999999999836, 2.9699999999999815, -21.249999999999414, -23.26999999999942, -5.090000000000083, 0.9399999999999819, -13.199999999999912, 2.9199999999999826, -31.35000000000043, -81.13999999999854, -0.10000000000003921, -31.340000000000195, -118.64999999999957, -7.110000000000083, -50.39000000000072, -62.789999999999566, -67.49999999999906, -10.160000000000082, -13.16999999999991, -2.1300000000000816, -78.63000000000005, -2.060000000000084, -20.339999999999456, -11.150000000000082, -99.85999999999984, -22.239999999999412, -270.63000000000017, -1.0900000000000623, -8.120000000000083, -118.35999999999943, -83.1499999999996, -9.130000000000082, -56.32000000000011, -155.69000000000057, -5.110000000000081, 2.9699999999999815, -7.110000000000081, -62.6100000000006, -33.390000000000434, -1.0700000000000631, 2.9799999999999813, -49.53000000000012, -11.150000000000084, -149.73000000000093, -11.140000000000082, -13.169999999999991, -2.0900000000000833, -52.41000000000044, -63.639999999999056, -20.239999999999416, -0.040000000000040996, -5.300000000000079, -21.24999999999943, -11.330000000000075, -8.120000000000083, -21.319999999999474, -56.54000000000055, -3.0700000000000838, -17.20999999999965, -98.85000000000016, -26.239999999999416, -154.4700000000019, -24.249999999999474, -86.72999999999847, -77.86999999999892, -6.100000000000081, -1.2300000000000597, -23.75999999999954, -67.54999999999902, -7.250000000000078], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-14.080000000000041, -4.030000000000042, -0.00999999999999836, -22.119999999999706, -26.139999999999723, 2.0000000000000013, -2.020000000000042, -18.099999999999703, 2.0000000000000013, -12.070000000000041, -4.030000000000042, -6.040000000000042, -30.159999999999727, -4.030000000000042, 2.0000000000000013, -16.0899999999997, -132.67000000000115, 2.0000000000000013, -6.040000000000042, -12.070000000000041, -14.080000000000041, -4.030000000000042, -50.260000000000346, 2.0000000000000013, 2.0000000000000013, -18.099999999999703, -60.310000000000336, -2.020000000000042, -14.080000000000041, -10.060000000000041, -18.099999999999707, 2.0000000000000013, -14.080000000000041, -16.0899999999997, -58.30000000000034, 2.0000000000000013, -4.030000000000042, -82.4199999999998, -46.24000000000035, -10.060000000000041, 2.0000000000000013, -16.0899999999997, 2.0000000000000013, -22.119999999999706, 2.0000000000000013, -14.080000000000041, -6.040000000000042, -10.060000000000041, -40.210000000000335, -42.220000000000354, 2.0000000000000013, 2.0000000000000013, -14.080000000000041, -24.129999999999708, -24.129999999999725, -12.070000000000041, -10.060000000000041, -6.040000000000042, -14.080000000000041, 2.0000000000000013, 2.0000000000000013, -20.109999999999705, -4.030000000000042, 2.0000000000000013, -32.170000000000364, -14.080000000000041, -14.080000000000041, -36.19000000000036, -8.050000000000042, -6.040000000000042, -10.060000000000041, 2.0000000000000013, -14.080000000000041, -22.119999999999706, -14.080000000000041, 2.0000000000000013, -52.270000000000344, -14.080000000000041, -82.41999999999919, -142.7200000000011, -18.099999999999703, 2.0000000000000013, -48.2500000000003, -16.089999999999844, -325.63, -2.020000000000042, -14.080000000000041, -4.030000000000042, -30.159999999999716, -44.23000000000035, -36.190000000000246, -118.59999999999928, -52.27000000000026, -44.23000000000026, -10.060000000000041, -18.099999999999703, -18.099999999999703, -12.070000000000041, -10.060000000000038, -12.070000000000041, -48.25000000000002, -74.38000000000001, -4.030000000000042, -4.030000000000042, -24.129999999999736, -40.210000000000356, -8.050000000000042, -18.099999999999703, -349.7500000000001, -20.109999999999705, -26.13999999999971, -18.099999999999703, -275.38000000000005, -249.25, 2.0000000000000013, -16.0899999999997, -2.020000000000042, -18.099999999999707, -237.19000000000023, -32.1700000000003, -8.050000000000042, -219.10000000000025, -12.070000000000041, -10.060000000000041, -247.24000000000012, -14.080000000000041, -317.5900000000002, -18.099999999999703, -20.109999999999705, 2.0000000000000013, 2.0000000000000013, -4.030000000000042, -6.040000000000037, -12.070000000000041, -38.19999999999999, -80.40999999999919, -72.36999999999942, -2.0200000000000413, -12.070000000000041, 2.0000000000000013, -2.020000000000042, 2.0000000000000013, -68.34999999999965, -34.18000000000036, -14.080000000000041, -12.070000000000041, -287.4400000000005, -56.29000000000014, -16.0899999999997, -8.050000000000042, -24.12999999999974, -6.040000000000042, -14.080000000000041, -0.00999999999999836, -46.240000000000215, -32.17000000000016, -44.2300000000002, -80.40999999999941, -28.149999999999714, -16.0899999999997, -2.020000000000042, -2.020000000000042, -58.30000000000034, 2.0000000000000013, -20.109999999999776, -26.13999999999971, 2.0000000000000013, -64.32999999999919, -10.060000000000041, -10.060000000000041, -50.26000000000032, -10.060000000000041, -68.34999999999974, -36.19000000000007, -8.050000000000042, -2.020000000000042, -0.00999999999999836, -38.200000000000244, -128.6499999999997, -38.200000000000074, -30.159999999999712, -14.080000000000041, -120.60999999999946, -170.86000000000098, -36.190000000000346, -10.060000000000036, -100.50999999999924, -42.2200000000003, -8.050000000000042, -162.82000000000087, -14.08000000000004, -2.020000000000042, -38.20000000000034, -4.030000000000042, 2.0000000000000013, -150.7600000000011, -42.220000000000184, -64.3299999999995, 2.0000000000000013, -48.25000000000035], "policy_predator_policy_reward": [0.0, 8.0, 12.0, 1.0, 5.0, 9.0, 3.0, 10.0, 7.0, 5.0, 3.0, 4.0, 18.0, 16.0, 1.0, 9.0, 64.0, 47.0, 7.0, 0.0, 8.0, 3.0, 4.0, 26.0, 8.0, 10.0, 2.0, 31.0, 6.0, 8.0, 7.0, 3.0, 8.0, 9.0, 27.0, 30.0, 3.0, 42.0, 6.0, 24.0, 6.0, 9.0, 5.0, 12.0, 6.0, 8.0, 6.0, 4.0, 34.0, 15.0, 0.0, 0.0, 10.0, 13.0, 3.0, 17.0, 5.0, 6.0, 8.0, 3.0, 8.0, 11.0, 3.0, 2.0, 8.0, 17.0, 19.0, 8.0, 4.0, 5.0, 3.0, 6.0, 12.0, 11.0, 8.0, 7.0, 19.0, 16.0, 70.0, 74.0, 10.0, 6.0, 28.0, 5.0, 141.0, 68.0, 8.0, 3.0, 23.0, 1.0, 36.0, 56.0, 3.0, 26.0, 10.0, 8.0, 10.0, 7.0, 12.0, 8.0, 27.0, 17.0, 3.0, 3.0, 20.0, 24.0, 5.0, 10.0, 163.0, 107.0, 10.0, 12.0, 141.0, 113.0, 4.0, 9.0, 2.0, 10.0, 41.0, 110.0, 96.0, 48.0, 7.0, 6.0, 104.0, 101.0, 152.0, 28.0, 2.0, 11.0, 3.0, 2.0, 0.0, 11.0, 15.0, 41.0, 30.0, 11.0, 2.0, 7.0, 2.0, 1.0, 47.0, 6.0, 7.0, 8.0, 52.0, 142.0, 4.0, 9.0, 4.0, 13.0, 8.0, 4.0, 13.0, 13.0, 4.0, 57.0, 15.0, 9.0, 2.0, 2.0, 28.0, 23.0, 4.0, 21.0, 33.0, 18.0, 6.0, 6.0, 11.0, 28.0, 42.0, 6.0, 2.0, 5.0, 5.0, 16.0, 3.0, 65.0, 15.0, 3.0, 78.0, 59.0, 8.0, 14.0, 52.0, 4.0, 80.0, 13.0, 8.0, 2.0, 18.0, 23.0, 57.0, 68.0, 35.0, 4.0, 25.0, 14.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6219471854844489, "mean_inference_ms": 1.9408846734577025, "mean_action_processing_ms": 0.26022219381959355, "mean_env_wait_ms": 0.2009849712339016, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006326198577880859, "StateBufferConnector_ms": 0.0031142234802246094, "ViewRequirementAgentConnector_ms": 0.09921574592590332}, "num_episodes": 18, "episode_return_max": 3.9999999999999587, "episode_return_min": -270.63000000000017, "episode_return_mean": -29.579799999999935, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 480000, "num_agent_steps_trained": 480000, "num_env_steps_sampled": 120000, "num_env_steps_trained": 120000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 398.4638025222004, "num_env_steps_trained_throughput_per_sec": 398.4638025222004, "timesteps_total": 120000, "num_env_steps_sampled_lifetime": 120000, "num_agent_steps_sampled_lifetime": 480000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 480000, "timers": {"training_iteration_time_ms": 11055.826, "restore_workers_time_ms": 0.016, "training_step_time_ms": 11055.779, "sample_time_ms": 1564.087, "learn_time_ms": 9473.27, "learn_throughput": 422.241, "synch_weights_time_ms": 16.573}, "counters": {"num_env_steps_sampled": 120000, "num_env_steps_trained": 120000, "num_agent_steps_sampled": 480000, "num_agent_steps_trained": 480000}, "done": false, "training_iteration": 30, "trial_id": "8e499_00000", "date": "2024-08-15_02-09-42", "timestamp": 1723667982, "time_this_iter_s": 10.045557260513306, "time_total_s": 322.52261304855347, "pid": 33199, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b43f0a60>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 322.52261304855347, "iterations_since_restore": 30, "perf": {"cpu_util_percent": 28.95714285714286, "ram_util_percent": 83.49285714285715}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0862556474864797, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.4483006755510965, "policy_loss": -0.006942842606080588, "vf_loss": 1.454409066378755, "vf_explained_var": 0.3357756548142307, "kl": 0.007417343267876739, "entropy": 1.240437125970447, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 57645.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8420346164514148, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.126896448457052, "policy_loss": -0.011123496764117764, "vf_loss": 2.1366707480773726, "vf_explained_var": 0.017328708607053, "kl": 0.013491972260559447, "entropy": 1.0782540422898752, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 57645.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 124000, "num_env_steps_trained": 124000, "num_agent_steps_sampled": 496000, "num_agent_steps_trained": 496000}, "env_runners": {"episode_reward_max": 3.9999999999999587, "episode_reward_min": -270.63000000000017, "episode_reward_mean": -36.651499999999906, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -349.7500000000001, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 2.0000000000000013, "predator_policy": 163.0}, "policy_reward_mean": {"prey_policy": -41.36575, "predator_policy": 23.04}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-41.45000000000013, -26.299999999999425, 0.9099999999999818, -3.120000000000081, 1.920000000000003, -6.100000000000083, -33.43000000000066, 3.9999999999999587, -15.209999999999553, -16.199999999999445, -5.100000000000083, -1.0800000000000622, 0.8899999999999836, 2.9699999999999815, -21.249999999999414, -23.26999999999942, -5.090000000000083, 0.9399999999999819, -13.199999999999912, 2.9199999999999826, -31.35000000000043, -81.13999999999854, -0.10000000000003921, -31.340000000000195, -118.64999999999957, -7.110000000000083, -50.39000000000072, -62.789999999999566, -67.49999999999906, -10.160000000000082, -13.16999999999991, -2.1300000000000816, -78.63000000000005, -2.060000000000084, -20.339999999999456, -11.150000000000082, -99.85999999999984, -22.239999999999412, -270.63000000000017, -1.0900000000000623, -8.120000000000083, -118.35999999999943, -83.1499999999996, -9.130000000000082, -56.32000000000011, -155.69000000000057, -5.110000000000081, 2.9699999999999815, -7.110000000000081, -62.6100000000006, -33.390000000000434, -1.0700000000000631, 2.9799999999999813, -49.53000000000012, -11.150000000000084, -149.73000000000093, -11.140000000000082, -13.169999999999991, -2.0900000000000833, -52.41000000000044, -63.639999999999056, -20.239999999999416, -0.040000000000040996, -5.300000000000079, -21.24999999999943, -11.330000000000075, -8.120000000000083, -21.319999999999474, -56.54000000000055, -3.0700000000000838, -17.20999999999965, -98.85000000000016, -26.239999999999416, -154.4700000000019, -24.249999999999474, -86.72999999999847, -77.86999999999892, -6.100000000000081, -1.2300000000000597, -23.75999999999954, -67.54999999999902, -7.250000000000078, -11.26000000000008, -128.00000000000165, -2.060000000000084, -4.080000000000084, -23.26999999999942, -25.289999999999445, -8.23000000000008, -10.140000000000082, -90.97999999999888, -10.150000000000082, -7.16000000000008, -13.169999999999945, -90.92999999999873, -53.57000000000006, -180.43999999999932, -23.26999999999942, -173.2799999999995, -6.100000000000081], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-4.030000000000042, -82.4199999999998, -46.24000000000035, -10.060000000000041, 2.0000000000000013, -16.0899999999997, 2.0000000000000013, -22.119999999999706, 2.0000000000000013, -14.080000000000041, -6.040000000000042, -10.060000000000041, -40.210000000000335, -42.220000000000354, 2.0000000000000013, 2.0000000000000013, -14.080000000000041, -24.129999999999708, -24.129999999999725, -12.070000000000041, -10.060000000000041, -6.040000000000042, -14.080000000000041, 2.0000000000000013, 2.0000000000000013, -20.109999999999705, -4.030000000000042, 2.0000000000000013, -32.170000000000364, -14.080000000000041, -14.080000000000041, -36.19000000000036, -8.050000000000042, -6.040000000000042, -10.060000000000041, 2.0000000000000013, -14.080000000000041, -22.119999999999706, -14.080000000000041, 2.0000000000000013, -52.270000000000344, -14.080000000000041, -82.41999999999919, -142.7200000000011, -18.099999999999703, 2.0000000000000013, -48.2500000000003, -16.089999999999844, -325.63, -2.020000000000042, -14.080000000000041, -4.030000000000042, -30.159999999999716, -44.23000000000035, -36.190000000000246, -118.59999999999928, -52.27000000000026, -44.23000000000026, -10.060000000000041, -18.099999999999703, -18.099999999999703, -12.070000000000041, -10.060000000000038, -12.070000000000041, -48.25000000000002, -74.38000000000001, -4.030000000000042, -4.030000000000042, -24.129999999999736, -40.210000000000356, -8.050000000000042, -18.099999999999703, -349.7500000000001, -20.109999999999705, -26.13999999999971, -18.099999999999703, -275.38000000000005, -249.25, 2.0000000000000013, -16.0899999999997, -2.020000000000042, -18.099999999999707, -237.19000000000023, -32.1700000000003, -8.050000000000042, -219.10000000000025, -12.070000000000041, -10.060000000000041, -247.24000000000012, -14.080000000000041, -317.5900000000002, -18.099999999999703, -20.109999999999705, 2.0000000000000013, 2.0000000000000013, -4.030000000000042, -6.040000000000037, -12.070000000000041, -38.19999999999999, -80.40999999999919, -72.36999999999942, -2.0200000000000413, -12.070000000000041, 2.0000000000000013, -2.020000000000042, 2.0000000000000013, -68.34999999999965, -34.18000000000036, -14.080000000000041, -12.070000000000041, -287.4400000000005, -56.29000000000014, -16.0899999999997, -8.050000000000042, -24.12999999999974, -6.040000000000042, -14.080000000000041, -0.00999999999999836, -46.240000000000215, -32.17000000000016, -44.2300000000002, -80.40999999999941, -28.149999999999714, -16.0899999999997, -2.020000000000042, -2.020000000000042, -58.30000000000034, 2.0000000000000013, -20.109999999999776, -26.13999999999971, 2.0000000000000013, -64.32999999999919, -10.060000000000041, -10.060000000000041, -50.26000000000032, -10.060000000000041, -68.34999999999974, -36.19000000000007, -8.050000000000042, -2.020000000000042, -0.00999999999999836, -38.200000000000244, -128.6499999999997, -38.200000000000074, -30.159999999999712, -14.080000000000041, -120.60999999999946, -170.86000000000098, -36.190000000000346, -10.060000000000036, -100.50999999999924, -42.2200000000003, -8.050000000000042, -162.82000000000087, -14.08000000000004, -2.020000000000042, -38.20000000000034, -4.030000000000042, 2.0000000000000013, -150.7600000000011, -42.220000000000184, -64.3299999999995, 2.0000000000000013, -48.25000000000035, -10.060000000000041, -38.20000000000036, -102.51999999999947, -94.47999999999946, -6.040000000000042, -2.020000000000042, -10.060000000000041, -2.020000000000042, -34.18000000000036, -16.089999999999705, -2.020000000000042, -52.270000000000344, -32.170000000000364, -10.060000000000041, -14.080000000000041, -10.060000000000041, -86.43999999999943, -106.5399999999995, -18.09999999999971, -8.050000000000042, -22.119999999999713, -6.040000000000042, -14.08000000000004, -16.0899999999997, -58.300000000000246, -124.62999999999936, -2.020000000000042, -108.55, -190.96000000000038, -94.48000000000012, -14.080000000000041, -36.19000000000036, -138.6999999999996, -114.58000000000001, -18.099999999999735, 2.0000000000000013], "policy_predator_policy_reward": [3.0, 42.0, 6.0, 24.0, 6.0, 9.0, 5.0, 12.0, 6.0, 8.0, 6.0, 4.0, 34.0, 15.0, 0.0, 0.0, 10.0, 13.0, 3.0, 17.0, 5.0, 6.0, 8.0, 3.0, 8.0, 11.0, 3.0, 2.0, 8.0, 17.0, 19.0, 8.0, 4.0, 5.0, 3.0, 6.0, 12.0, 11.0, 8.0, 7.0, 19.0, 16.0, 70.0, 74.0, 10.0, 6.0, 28.0, 5.0, 141.0, 68.0, 8.0, 3.0, 23.0, 1.0, 36.0, 56.0, 3.0, 26.0, 10.0, 8.0, 10.0, 7.0, 12.0, 8.0, 27.0, 17.0, 3.0, 3.0, 20.0, 24.0, 5.0, 10.0, 163.0, 107.0, 10.0, 12.0, 141.0, 113.0, 4.0, 9.0, 2.0, 10.0, 41.0, 110.0, 96.0, 48.0, 7.0, 6.0, 104.0, 101.0, 152.0, 28.0, 2.0, 11.0, 3.0, 2.0, 0.0, 11.0, 15.0, 41.0, 30.0, 11.0, 2.0, 7.0, 2.0, 1.0, 47.0, 6.0, 7.0, 8.0, 52.0, 142.0, 4.0, 9.0, 4.0, 13.0, 8.0, 4.0, 13.0, 13.0, 4.0, 57.0, 15.0, 9.0, 2.0, 2.0, 28.0, 23.0, 4.0, 21.0, 33.0, 18.0, 6.0, 6.0, 11.0, 28.0, 42.0, 6.0, 2.0, 5.0, 5.0, 16.0, 3.0, 65.0, 15.0, 3.0, 78.0, 59.0, 8.0, 14.0, 52.0, 4.0, 80.0, 13.0, 8.0, 2.0, 18.0, 23.0, 57.0, 68.0, 35.0, 4.0, 25.0, 14.0, 20.0, 17.0, 54.0, 15.0, 4.0, 2.0, 2.0, 6.0, 18.0, 9.0, 10.0, 19.0, 17.0, 17.0, 8.0, 6.0, 69.0, 33.0, 14.0, 2.0, 15.0, 6.0, 9.0, 8.0, 34.0, 58.0, 55.0, 2.0, 9.0, 96.0, 8.0, 19.0, 76.0, 4.0, 0.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.620123799818959, "mean_inference_ms": 1.936626473511129, "mean_action_processing_ms": 0.2631775101894318, "mean_env_wait_ms": 0.20041372831195958, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00578761100769043, "StateBufferConnector_ms": 0.0030684471130371094, "ViewRequirementAgentConnector_ms": 0.09563636779785156}, "num_episodes": 18, "episode_return_max": 3.9999999999999587, "episode_return_min": -270.63000000000017, "episode_return_mean": -36.651499999999906, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 496000, "num_agent_steps_trained": 496000, "num_env_steps_sampled": 124000, "num_env_steps_trained": 124000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 394.9606987736366, "num_env_steps_trained_throughput_per_sec": 394.9606987736366, "timesteps_total": 124000, "num_env_steps_sampled_lifetime": 124000, "num_agent_steps_sampled_lifetime": 496000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 496000, "timers": {"training_iteration_time_ms": 11050.659, "restore_workers_time_ms": 0.016, "training_step_time_ms": 11050.611, "sample_time_ms": 1558.296, "learn_time_ms": 9473.817, "learn_throughput": 422.216, "synch_weights_time_ms": 16.539}, "counters": {"num_env_steps_sampled": 124000, "num_env_steps_trained": 124000, "num_agent_steps_sampled": 496000, "num_agent_steps_trained": 496000}, "done": false, "training_iteration": 31, "trial_id": "8e499_00000", "date": "2024-08-15_02-09-52", "timestamp": 1723667992, "time_this_iter_s": 10.182118892669678, "time_total_s": 332.70473194122314, "pid": 33199, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x158036790>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 332.70473194122314, "iterations_since_restore": 31, "perf": {"cpu_util_percent": 29.692857142857143, "ram_util_percent": 83.68571428571428}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.155914029936311, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.390354389425308, "policy_loss": -0.008306951700985707, "vf_loss": 2.3974115401979477, "vf_explained_var": 0.3077179157544696, "kl": 0.011109312986493577, "entropy": 1.1728698090270713, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 59535.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8058514801755784, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.451846863605358, "policy_loss": -0.00854729703878836, "vf_loss": 3.4593582456074063, "vf_explained_var": 0.021200225719068416, "kl": 0.010359177964684017, "entropy": 1.079191206056605, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 59535.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 128000, "num_env_steps_trained": 128000, "num_agent_steps_sampled": 512000, "num_agent_steps_trained": 512000}, "env_runners": {"episode_reward_max": 2.9799999999999813, "episode_reward_min": -322.31000000000046, "episode_reward_mean": -50.11429999999992, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -349.7500000000001, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 2.0000000000000013, "predator_policy": 163.0}, "policy_reward_mean": {"prey_policy": -50.69214999999999, "predator_policy": 25.635}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-62.789999999999566, -67.49999999999906, -10.160000000000082, -13.16999999999991, -2.1300000000000816, -78.63000000000005, -2.060000000000084, -20.339999999999456, -11.150000000000082, -99.85999999999984, -22.239999999999412, -270.63000000000017, -1.0900000000000623, -8.120000000000083, -118.35999999999943, -83.1499999999996, -9.130000000000082, -56.32000000000011, -155.69000000000057, -5.110000000000081, 2.9699999999999815, -7.110000000000081, -62.6100000000006, -33.390000000000434, -1.0700000000000631, 2.9799999999999813, -49.53000000000012, -11.150000000000084, -149.73000000000093, -11.140000000000082, -13.169999999999991, -2.0900000000000833, -52.41000000000044, -63.639999999999056, -20.239999999999416, -0.040000000000040996, -5.300000000000079, -21.24999999999943, -11.330000000000075, -8.120000000000083, -21.319999999999474, -56.54000000000055, -3.0700000000000838, -17.20999999999965, -98.85000000000016, -26.239999999999416, -154.4700000000019, -24.249999999999474, -86.72999999999847, -77.86999999999892, -6.100000000000081, -1.2300000000000597, -23.75999999999954, -67.54999999999902, -7.250000000000078, -11.26000000000008, -128.00000000000165, -2.060000000000084, -4.080000000000084, -23.26999999999942, -25.289999999999445, -8.23000000000008, -10.140000000000082, -90.97999999999888, -10.150000000000082, -7.16000000000008, -13.169999999999945, -90.92999999999873, -53.57000000000006, -180.43999999999932, -23.26999999999942, -173.2799999999995, -6.100000000000081, -5.090000000000083, -6.120000000000074, -322.31000000000046, -121.18999999999882, -18.219999999999477, -14.239999999999815, -1.0800000000000622, -5.090000000000083, -114.6099999999998, -227.5700000000003, 2.939999999999982, -25.289999999999445, 1.8800000000000012, -284.0700000000003, 0.9199999999999823, -83.68999999999866, -262.15999999999997, -0.1100000000000392, -12.24000000000008, -7.16000000000008, -237.65000000000066, 2.9599999999999818, -67.71000000000019, 1.980000000000003, -11.150000000000082, -7.110000000000083, -39.43000000000058], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-36.190000000000246, -118.59999999999928, -52.27000000000026, -44.23000000000026, -10.060000000000041, -18.099999999999703, -18.099999999999703, -12.070000000000041, -10.060000000000038, -12.070000000000041, -48.25000000000002, -74.38000000000001, -4.030000000000042, -4.030000000000042, -24.129999999999736, -40.210000000000356, -8.050000000000042, -18.099999999999703, -349.7500000000001, -20.109999999999705, -26.13999999999971, -18.099999999999703, -275.38000000000005, -249.25, 2.0000000000000013, -16.0899999999997, -2.020000000000042, -18.099999999999707, -237.19000000000023, -32.1700000000003, -8.050000000000042, -219.10000000000025, -12.070000000000041, -10.060000000000041, -247.24000000000012, -14.080000000000041, -317.5900000000002, -18.099999999999703, -20.109999999999705, 2.0000000000000013, 2.0000000000000013, -4.030000000000042, -6.040000000000037, -12.070000000000041, -38.19999999999999, -80.40999999999919, -72.36999999999942, -2.0200000000000413, -12.070000000000041, 2.0000000000000013, -2.020000000000042, 2.0000000000000013, -68.34999999999965, -34.18000000000036, -14.080000000000041, -12.070000000000041, -287.4400000000005, -56.29000000000014, -16.0899999999997, -8.050000000000042, -24.12999999999974, -6.040000000000042, -14.080000000000041, -0.00999999999999836, -46.240000000000215, -32.17000000000016, -44.2300000000002, -80.40999999999941, -28.149999999999714, -16.0899999999997, -2.020000000000042, -2.020000000000042, -58.30000000000034, 2.0000000000000013, -20.109999999999776, -26.13999999999971, 2.0000000000000013, -64.32999999999919, -10.060000000000041, -10.060000000000041, -50.26000000000032, -10.060000000000041, -68.34999999999974, -36.19000000000007, -8.050000000000042, -2.020000000000042, -0.00999999999999836, -38.200000000000244, -128.6499999999997, -38.200000000000074, -30.159999999999712, -14.080000000000041, -120.60999999999946, -170.86000000000098, -36.190000000000346, -10.060000000000036, -100.50999999999924, -42.2200000000003, -8.050000000000042, -162.82000000000087, -14.08000000000004, -2.020000000000042, -38.20000000000034, -4.030000000000042, 2.0000000000000013, -150.7600000000011, -42.220000000000184, -64.3299999999995, 2.0000000000000013, -48.25000000000035, -10.060000000000041, -38.20000000000036, -102.51999999999947, -94.47999999999946, -6.040000000000042, -2.020000000000042, -10.060000000000041, -2.020000000000042, -34.18000000000036, -16.089999999999705, -2.020000000000042, -52.270000000000344, -32.170000000000364, -10.060000000000041, -14.080000000000041, -10.060000000000041, -86.43999999999943, -106.5399999999995, -18.09999999999971, -8.050000000000042, -22.119999999999713, -6.040000000000042, -14.08000000000004, -16.0899999999997, -58.300000000000246, -124.62999999999936, -2.020000000000042, -108.55, -190.96000000000038, -94.48000000000012, -14.080000000000041, -36.19000000000036, -138.6999999999996, -114.58000000000001, -18.099999999999735, 2.0000000000000013, -6.040000000000042, -8.050000000000042, -18.09999999999973, -2.020000000000042, -201.01000000000016, -259.30000000000024, -78.39999999999947, -156.79000000000104, -2.020000000000042, -38.20000000000033, -20.109999999999705, -24.129999999999747, -14.080000000000041, 2.0000000000000013, -16.0899999999997, 2.0000000000000013, -98.49999999999997, -221.11000000000016, -148.7499999999999, -162.8199999999999, 2.0000000000000013, -10.060000000000041, -12.070000000000041, -42.220000000000354, 2.0000000000000013, -22.119999999999706, -221.11000000000004, -190.96000000000026, -14.080000000000041, 2.0000000000000013, -96.48999999999933, -38.20000000000025, -207.04000000000008, -223.11999999999998, -20.109999999999705, 2.0000000000000013, -8.050000000000038, -36.19000000000035, -14.080000000000041, -14.080000000000037, -154.7800000000002, -172.8700000000003, 2.0000000000000013, -6.040000000000042, -74.37999999999973, -64.32999999999973, -0.00999999999999836, -0.009999999999998581, -20.109999999999705, -6.040000000000042, -6.040000000000042, -12.070000000000041, -76.38999999999925, -6.040000000000031], "policy_predator_policy_reward": [36.0, 56.0, 3.0, 26.0, 10.0, 8.0, 10.0, 7.0, 12.0, 8.0, 27.0, 17.0, 3.0, 3.0, 20.0, 24.0, 5.0, 10.0, 163.0, 107.0, 10.0, 12.0, 141.0, 113.0, 4.0, 9.0, 2.0, 10.0, 41.0, 110.0, 96.0, 48.0, 7.0, 6.0, 104.0, 101.0, 152.0, 28.0, 2.0, 11.0, 3.0, 2.0, 0.0, 11.0, 15.0, 41.0, 30.0, 11.0, 2.0, 7.0, 2.0, 1.0, 47.0, 6.0, 7.0, 8.0, 52.0, 142.0, 4.0, 9.0, 4.0, 13.0, 8.0, 4.0, 13.0, 13.0, 4.0, 57.0, 15.0, 9.0, 2.0, 2.0, 28.0, 23.0, 4.0, 21.0, 33.0, 18.0, 6.0, 6.0, 11.0, 28.0, 42.0, 6.0, 2.0, 5.0, 5.0, 16.0, 3.0, 65.0, 15.0, 3.0, 78.0, 59.0, 8.0, 14.0, 52.0, 4.0, 80.0, 13.0, 8.0, 2.0, 18.0, 23.0, 57.0, 68.0, 35.0, 4.0, 25.0, 14.0, 20.0, 17.0, 54.0, 15.0, 4.0, 2.0, 2.0, 6.0, 18.0, 9.0, 10.0, 19.0, 17.0, 17.0, 8.0, 6.0, 69.0, 33.0, 14.0, 2.0, 15.0, 6.0, 9.0, 8.0, 34.0, 58.0, 55.0, 2.0, 9.0, 96.0, 8.0, 19.0, 76.0, 4.0, 0.0, 10.0, 4.0, 5.0, 2.0, 12.0, 0.0, 138.0, 78.0, 36.0, 15.0, 7.0, 6.0, 24.0, 3.0, 8.0, 9.0, 0.0, 102.0, 103.0, 3.0, 81.0, 5.0, 6.0, 2.0, 27.0, 12.0, 10.0, 120.0, 8.0, 5.0, 8.0, 2.0, 49.0, 84.0, 84.0, 11.0, 7.0, 14.0, 18.0, 16.0, 5.0, 83.0, 7.0, 4.0, 3.0, 6.0, 65.0, 0.0, 2.0, 2.0, 13.0, 7.0, 4.0, 1.0, 42.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6177409896250863, "mean_inference_ms": 1.9302080208245294, "mean_action_processing_ms": 0.2666491491858615, "mean_env_wait_ms": 0.19978828560568812, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004836916923522949, "StateBufferConnector_ms": 0.003120899200439453, "ViewRequirementAgentConnector_ms": 0.09260869026184082}, "num_episodes": 27, "episode_return_max": 2.9799999999999813, "episode_return_min": -322.31000000000046, "episode_return_mean": -50.11429999999992, "episodes_this_iter": 27}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 512000, "num_agent_steps_trained": 512000, "num_env_steps_sampled": 128000, "num_env_steps_trained": 128000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 371.0261930018156, "num_env_steps_trained_throughput_per_sec": 371.0261930018156, "timesteps_total": 128000, "num_env_steps_sampled_lifetime": 128000, "num_agent_steps_sampled_lifetime": 512000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 512000, "timers": {"training_iteration_time_ms": 11022.871, "restore_workers_time_ms": 0.016, "training_step_time_ms": 11022.823, "sample_time_ms": 1562.884, "learn_time_ms": 9441.124, "learn_throughput": 423.678, "synch_weights_time_ms": 16.685}, "counters": {"num_env_steps_sampled": 128000, "num_env_steps_trained": 128000, "num_agent_steps_sampled": 512000, "num_agent_steps_trained": 512000}, "done": false, "training_iteration": 32, "trial_id": "8e499_00000", "date": "2024-08-15_02-10-03", "timestamp": 1723668003, "time_this_iter_s": 10.830048322677612, "time_total_s": 343.53478026390076, "pid": 33199, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b43f0040>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 343.53478026390076, "iterations_since_restore": 32, "perf": {"cpu_util_percent": 31.418749999999996, "ram_util_percent": 83.5375}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2697410845251942, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.9396422143335696, "policy_loss": -0.00848451938046507, "vf_loss": 2.947098438575785, "vf_explained_var": 0.3079565119491052, "kl": 0.009140394848844534, "entropy": 1.139022702893252, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 61425.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9768494600499118, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.6415404607379247, "policy_loss": -0.007744369145591187, "vf_loss": 3.648267324387081, "vf_explained_var": 0.025382627570439898, "kl": 0.010175135709860379, "entropy": 1.0876169238140974, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 61425.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 132000, "num_env_steps_trained": 132000, "num_agent_steps_sampled": 528000, "num_agent_steps_trained": 528000}, "env_runners": {"episode_reward_max": 2.9799999999999813, "episode_reward_min": -361.71000000000043, "episode_reward_mean": -58.32089999999993, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -317.5900000000002, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 2.0000000000000013, "predator_policy": 152.0}, "policy_reward_mean": {"prey_policy": -54.37045, "predator_policy": 25.21}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-155.69000000000057, -5.110000000000081, 2.9699999999999815, -7.110000000000081, -62.6100000000006, -33.390000000000434, -1.0700000000000631, 2.9799999999999813, -49.53000000000012, -11.150000000000084, -149.73000000000093, -11.140000000000082, -13.169999999999991, -2.0900000000000833, -52.41000000000044, -63.639999999999056, -20.239999999999416, -0.040000000000040996, -5.300000000000079, -21.24999999999943, -11.330000000000075, -8.120000000000083, -21.319999999999474, -56.54000000000055, -3.0700000000000838, -17.20999999999965, -98.85000000000016, -26.239999999999416, -154.4700000000019, -24.249999999999474, -86.72999999999847, -77.86999999999892, -6.100000000000081, -1.2300000000000597, -23.75999999999954, -67.54999999999902, -7.250000000000078, -11.26000000000008, -128.00000000000165, -2.060000000000084, -4.080000000000084, -23.26999999999942, -25.289999999999445, -8.23000000000008, -10.140000000000082, -90.97999999999888, -10.150000000000082, -7.16000000000008, -13.169999999999945, -90.92999999999873, -53.57000000000006, -180.43999999999932, -23.26999999999942, -173.2799999999995, -6.100000000000081, -5.090000000000083, -6.120000000000074, -322.31000000000046, -121.18999999999882, -18.219999999999477, -14.239999999999815, -1.0800000000000622, -5.090000000000083, -114.6099999999998, -227.5700000000003, 2.939999999999982, -25.289999999999445, 1.8800000000000012, -284.0700000000003, 0.9199999999999823, -83.68999999999866, -262.15999999999997, -0.1100000000000392, -12.24000000000008, -7.16000000000008, -237.65000000000066, 2.9599999999999818, -67.71000000000019, 1.980000000000003, -11.150000000000082, -7.110000000000083, -39.43000000000058, -227.690000000001, -92.94999999999953, -361.71000000000043, -3.120000000000081, -7.110000000000083, -323.41000000000037, -1.050000000000063, -86.58999999999989, -27.289999999999424, 1.9500000000000028, -21.24999999999944, -84.87999999999958, -6.100000000000083, -14.179999999999824, -9.130000000000082, -355.72000000000054, -12.160000000000082, -125.09999999999897], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-317.5900000000002, -18.099999999999703, -20.109999999999705, 2.0000000000000013, 2.0000000000000013, -4.030000000000042, -6.040000000000037, -12.070000000000041, -38.19999999999999, -80.40999999999919, -72.36999999999942, -2.0200000000000413, -12.070000000000041, 2.0000000000000013, -2.020000000000042, 2.0000000000000013, -68.34999999999965, -34.18000000000036, -14.080000000000041, -12.070000000000041, -287.4400000000005, -56.29000000000014, -16.0899999999997, -8.050000000000042, -24.12999999999974, -6.040000000000042, -14.080000000000041, -0.00999999999999836, -46.240000000000215, -32.17000000000016, -44.2300000000002, -80.40999999999941, -28.149999999999714, -16.0899999999997, -2.020000000000042, -2.020000000000042, -58.30000000000034, 2.0000000000000013, -20.109999999999776, -26.13999999999971, 2.0000000000000013, -64.32999999999919, -10.060000000000041, -10.060000000000041, -50.26000000000032, -10.060000000000041, -68.34999999999974, -36.19000000000007, -8.050000000000042, -2.020000000000042, -0.00999999999999836, -38.200000000000244, -128.6499999999997, -38.200000000000074, -30.159999999999712, -14.080000000000041, -120.60999999999946, -170.86000000000098, -36.190000000000346, -10.060000000000036, -100.50999999999924, -42.2200000000003, -8.050000000000042, -162.82000000000087, -14.08000000000004, -2.020000000000042, -38.20000000000034, -4.030000000000042, 2.0000000000000013, -150.7600000000011, -42.220000000000184, -64.3299999999995, 2.0000000000000013, -48.25000000000035, -10.060000000000041, -38.20000000000036, -102.51999999999947, -94.47999999999946, -6.040000000000042, -2.020000000000042, -10.060000000000041, -2.020000000000042, -34.18000000000036, -16.089999999999705, -2.020000000000042, -52.270000000000344, -32.170000000000364, -10.060000000000041, -14.080000000000041, -10.060000000000041, -86.43999999999943, -106.5399999999995, -18.09999999999971, -8.050000000000042, -22.119999999999713, -6.040000000000042, -14.08000000000004, -16.0899999999997, -58.300000000000246, -124.62999999999936, -2.020000000000042, -108.55, -190.96000000000038, -94.48000000000012, -14.080000000000041, -36.19000000000036, -138.6999999999996, -114.58000000000001, -18.099999999999735, 2.0000000000000013, -6.040000000000042, -8.050000000000042, -18.09999999999973, -2.020000000000042, -201.01000000000016, -259.30000000000024, -78.39999999999947, -156.79000000000104, -2.020000000000042, -38.20000000000033, -20.109999999999705, -24.129999999999747, -14.080000000000041, 2.0000000000000013, -16.0899999999997, 2.0000000000000013, -98.49999999999997, -221.11000000000016, -148.7499999999999, -162.8199999999999, 2.0000000000000013, -10.060000000000041, -12.070000000000041, -42.220000000000354, 2.0000000000000013, -22.119999999999706, -221.11000000000004, -190.96000000000026, -14.080000000000041, 2.0000000000000013, -96.48999999999933, -38.20000000000025, -207.04000000000008, -223.11999999999998, -20.109999999999705, 2.0000000000000013, -8.050000000000038, -36.19000000000035, -14.080000000000041, -14.080000000000037, -154.7800000000002, -172.8700000000003, 2.0000000000000013, -6.040000000000042, -74.37999999999973, -64.32999999999973, -0.00999999999999836, -0.009999999999998581, -20.109999999999705, -6.040000000000042, -6.040000000000042, -12.070000000000041, -76.38999999999925, -6.040000000000031, -192.9700000000006, -142.72000000000037, -166.83999999999986, -20.11000000000004, -279.4000000000002, -261.3100000000002, -18.099999999999703, -2.0200000000000387, -6.040000000000042, -12.070000000000041, -251.2600000000001, -229.14999999999998, -6.040000000000042, -0.00999999999999836, -12.070000000000041, -303.52000000000015, -40.210000000000356, -14.080000000000041, 2.0000000000000013, -8.050000000000042, -2.020000000000042, -44.23000000000035, -12.070000000000041, -160.81000000000026, -2.0200000000000413, -14.080000000000041, -10.060000000000034, -22.119999999999706, -6.040000000000042, -16.089999999999726, -249.25000000000014, -293.47000000000025, -28.14999999999971, -0.00999999999999836, -100.50999999999951, -116.5899999999994], "policy_predator_policy_reward": [152.0, 28.0, 2.0, 11.0, 3.0, 2.0, 0.0, 11.0, 15.0, 41.0, 30.0, 11.0, 2.0, 7.0, 2.0, 1.0, 47.0, 6.0, 7.0, 8.0, 52.0, 142.0, 4.0, 9.0, 4.0, 13.0, 8.0, 4.0, 13.0, 13.0, 4.0, 57.0, 15.0, 9.0, 2.0, 2.0, 28.0, 23.0, 4.0, 21.0, 33.0, 18.0, 6.0, 6.0, 11.0, 28.0, 42.0, 6.0, 2.0, 5.0, 5.0, 16.0, 3.0, 65.0, 15.0, 3.0, 78.0, 59.0, 8.0, 14.0, 52.0, 4.0, 80.0, 13.0, 8.0, 2.0, 18.0, 23.0, 57.0, 68.0, 35.0, 4.0, 25.0, 14.0, 20.0, 17.0, 54.0, 15.0, 4.0, 2.0, 2.0, 6.0, 18.0, 9.0, 10.0, 19.0, 17.0, 17.0, 8.0, 6.0, 69.0, 33.0, 14.0, 2.0, 15.0, 6.0, 9.0, 8.0, 34.0, 58.0, 55.0, 2.0, 9.0, 96.0, 8.0, 19.0, 76.0, 4.0, 0.0, 10.0, 4.0, 5.0, 2.0, 12.0, 0.0, 138.0, 78.0, 36.0, 15.0, 7.0, 6.0, 24.0, 3.0, 8.0, 9.0, 0.0, 102.0, 103.0, 3.0, 81.0, 5.0, 6.0, 2.0, 27.0, 12.0, 10.0, 120.0, 8.0, 5.0, 8.0, 2.0, 49.0, 84.0, 84.0, 11.0, 7.0, 14.0, 18.0, 16.0, 5.0, 83.0, 7.0, 4.0, 3.0, 6.0, 65.0, 0.0, 2.0, 2.0, 13.0, 7.0, 4.0, 1.0, 42.0, 82.0, 26.0, 16.0, 78.0, 33.0, 146.0, 10.0, 7.0, 4.0, 7.0, 144.0, 13.0, 4.0, 1.0, 130.0, 99.0, 22.0, 5.0, 3.0, 5.0, 23.0, 2.0, 86.0, 2.0, 5.0, 5.0, 0.0, 18.0, 6.0, 7.0, 139.0, 48.0, 15.0, 1.0, 88.0, 4.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6155049314855248, "mean_inference_ms": 1.9247996897120228, "mean_action_processing_ms": 0.26503851650920646, "mean_env_wait_ms": 0.19908622798475994, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004184365272521973, "StateBufferConnector_ms": 0.0032438039779663086, "ViewRequirementAgentConnector_ms": 0.09315836429595947}, "num_episodes": 18, "episode_return_max": 2.9799999999999813, "episode_return_min": -361.71000000000043, "episode_return_mean": -58.32089999999993, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 528000, "num_agent_steps_trained": 528000, "num_env_steps_sampled": 132000, "num_env_steps_trained": 132000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 362.1378632915113, "num_env_steps_trained_throughput_per_sec": 362.1378632915113, "timesteps_total": 132000, "num_env_steps_sampled_lifetime": 132000, "num_agent_steps_sampled_lifetime": 528000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 528000, "timers": {"training_iteration_time_ms": 11040.768, "restore_workers_time_ms": 0.016, "training_step_time_ms": 11040.722, "sample_time_ms": 1563.726, "learn_time_ms": 9459.717, "learn_throughput": 422.846, "synch_weights_time_ms": 15.494}, "counters": {"num_env_steps_sampled": 132000, "num_env_steps_trained": 132000, "num_agent_steps_sampled": 528000, "num_agent_steps_trained": 528000}, "done": false, "training_iteration": 33, "trial_id": "8e499_00000", "date": "2024-08-15_02-10-14", "timestamp": 1723668014, "time_this_iter_s": 11.085849046707153, "time_total_s": 354.6206293106079, "pid": 33199, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b43f0af0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 354.6206293106079, "iterations_since_restore": 33, "perf": {"cpu_util_percent": 33.712500000000006, "ram_util_percent": 83.59375}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.240891367133963, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.018265863701149, "policy_loss": -0.006307598497600309, "vf_loss": 4.023348409915097, "vf_explained_var": 0.3828794429541896, "kl": 0.010889447895951226, "entropy": 1.1159404654351492, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 63315.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7467734357194294, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.081940502842898, "policy_loss": -0.00902098926725408, "vf_loss": 5.0898571309589205, "vf_explained_var": 0.03251335715490674, "kl": 0.011043483250008158, "entropy": 1.0669220169385274, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 63315.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 136000, "num_env_steps_trained": 136000, "num_agent_steps_sampled": 544000, "num_agent_steps_trained": 544000}, "env_runners": {"episode_reward_max": 2.9599999999999818, "episode_reward_min": -394.47000000000025, "episode_reward_mean": -75.58359999999992, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -351.76000000000016, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 2.0000000000000013, "predator_policy": 159.0}, "policy_reward_mean": {"prey_policy": -68.75180000000002, "predator_policy": 30.96}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-5.300000000000079, -21.24999999999943, -11.330000000000075, -8.120000000000083, -21.319999999999474, -56.54000000000055, -3.0700000000000838, -17.20999999999965, -98.85000000000016, -26.239999999999416, -154.4700000000019, -24.249999999999474, -86.72999999999847, -77.86999999999892, -6.100000000000081, -1.2300000000000597, -23.75999999999954, -67.54999999999902, -7.250000000000078, -11.26000000000008, -128.00000000000165, -2.060000000000084, -4.080000000000084, -23.26999999999942, -25.289999999999445, -8.23000000000008, -10.140000000000082, -90.97999999999888, -10.150000000000082, -7.16000000000008, -13.169999999999945, -90.92999999999873, -53.57000000000006, -180.43999999999932, -23.26999999999942, -173.2799999999995, -6.100000000000081, -5.090000000000083, -6.120000000000074, -322.31000000000046, -121.18999999999882, -18.219999999999477, -14.239999999999815, -1.0800000000000622, -5.090000000000083, -114.6099999999998, -227.5700000000003, 2.939999999999982, -25.289999999999445, 1.8800000000000012, -284.0700000000003, 0.9199999999999823, -83.68999999999866, -262.15999999999997, -0.1100000000000392, -12.24000000000008, -7.16000000000008, -237.65000000000066, 2.9599999999999818, -67.71000000000019, 1.980000000000003, -11.150000000000082, -7.110000000000083, -39.43000000000058, -227.690000000001, -92.94999999999953, -361.71000000000043, -3.120000000000081, -7.110000000000083, -323.41000000000037, -1.050000000000063, -86.58999999999989, -27.289999999999424, 1.9500000000000028, -21.24999999999944, -84.87999999999958, -6.100000000000083, -14.179999999999824, -9.130000000000082, -355.72000000000054, -12.160000000000082, -125.09999999999897, -7.110000000000083, -121.23999999999938, -26.29999999999944, -184.29000000000016, -13.219999999999908, -394.47000000000025, -62.31000000000009, 1.920000000000003, -5.1300000000000825, -5.090000000000083, -12.180000000000081, -5.090000000000082, -16.199999999999438, -350.63000000000017, -305.2300000000008, -329.3500000000002, -388.13000000000034, -134.38999999999953], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-58.30000000000034, 2.0000000000000013, -20.109999999999776, -26.13999999999971, 2.0000000000000013, -64.32999999999919, -10.060000000000041, -10.060000000000041, -50.26000000000032, -10.060000000000041, -68.34999999999974, -36.19000000000007, -8.050000000000042, -2.020000000000042, -0.00999999999999836, -38.200000000000244, -128.6499999999997, -38.200000000000074, -30.159999999999712, -14.080000000000041, -120.60999999999946, -170.86000000000098, -36.190000000000346, -10.060000000000036, -100.50999999999924, -42.2200000000003, -8.050000000000042, -162.82000000000087, -14.08000000000004, -2.020000000000042, -38.20000000000034, -4.030000000000042, 2.0000000000000013, -150.7600000000011, -42.220000000000184, -64.3299999999995, 2.0000000000000013, -48.25000000000035, -10.060000000000041, -38.20000000000036, -102.51999999999947, -94.47999999999946, -6.040000000000042, -2.020000000000042, -10.060000000000041, -2.020000000000042, -34.18000000000036, -16.089999999999705, -2.020000000000042, -52.270000000000344, -32.170000000000364, -10.060000000000041, -14.080000000000041, -10.060000000000041, -86.43999999999943, -106.5399999999995, -18.09999999999971, -8.050000000000042, -22.119999999999713, -6.040000000000042, -14.08000000000004, -16.0899999999997, -58.300000000000246, -124.62999999999936, -2.020000000000042, -108.55, -190.96000000000038, -94.48000000000012, -14.080000000000041, -36.19000000000036, -138.6999999999996, -114.58000000000001, -18.099999999999735, 2.0000000000000013, -6.040000000000042, -8.050000000000042, -18.09999999999973, -2.020000000000042, -201.01000000000016, -259.30000000000024, -78.39999999999947, -156.79000000000104, -2.020000000000042, -38.20000000000033, -20.109999999999705, -24.129999999999747, -14.080000000000041, 2.0000000000000013, -16.0899999999997, 2.0000000000000013, -98.49999999999997, -221.11000000000016, -148.7499999999999, -162.8199999999999, 2.0000000000000013, -10.060000000000041, -12.070000000000041, -42.220000000000354, 2.0000000000000013, -22.119999999999706, -221.11000000000004, -190.96000000000026, -14.080000000000041, 2.0000000000000013, -96.48999999999933, -38.20000000000025, -207.04000000000008, -223.11999999999998, -20.109999999999705, 2.0000000000000013, -8.050000000000038, -36.19000000000035, -14.080000000000041, -14.080000000000037, -154.7800000000002, -172.8700000000003, 2.0000000000000013, -6.040000000000042, -74.37999999999973, -64.32999999999973, -0.00999999999999836, -0.009999999999998581, -20.109999999999705, -6.040000000000042, -6.040000000000042, -12.070000000000041, -76.38999999999925, -6.040000000000031, -192.9700000000006, -142.72000000000037, -166.83999999999986, -20.11000000000004, -279.4000000000002, -261.3100000000002, -18.099999999999703, -2.0200000000000387, -6.040000000000042, -12.070000000000041, -251.2600000000001, -229.14999999999998, -6.040000000000042, -0.00999999999999836, -12.070000000000041, -303.52000000000015, -40.210000000000356, -14.080000000000041, 2.0000000000000013, -8.050000000000042, -2.020000000000042, -44.23000000000035, -12.070000000000041, -160.81000000000026, -2.0200000000000413, -14.080000000000041, -10.060000000000034, -22.119999999999706, -6.040000000000042, -16.089999999999726, -249.25000000000014, -293.47000000000025, -28.14999999999971, -0.00999999999999836, -100.50999999999951, -116.5899999999994, -2.020000000000042, -16.08999999999972, -18.099999999999703, -227.14000000000027, -18.099999999999703, -38.200000000000315, -351.76000000000016, -104.52999999999999, -26.13999999999971, -14.080000000000041, -347.7400000000001, -345.73000000000013, -231.12000000000012, -36.19000000000034, 2.0000000000000013, -14.080000000000041, -6.040000000000042, -16.0899999999997, -14.080000000000041, -0.00999999999999836, -10.060000000000041, -22.119999999999713, -16.089999999999705, 2.0000000000000013, -2.020000000000042, -34.18000000000036, -186.94000000000005, -337.69000000000017, -223.12000000000012, -221.1100000000003, -243.22000000000008, -225.13, -299.50000000000006, -325.6300000000001, -243.22000000000025, -32.17000000000036], "policy_predator_policy_reward": [28.0, 23.0, 4.0, 21.0, 33.0, 18.0, 6.0, 6.0, 11.0, 28.0, 42.0, 6.0, 2.0, 5.0, 5.0, 16.0, 3.0, 65.0, 15.0, 3.0, 78.0, 59.0, 8.0, 14.0, 52.0, 4.0, 80.0, 13.0, 8.0, 2.0, 18.0, 23.0, 57.0, 68.0, 35.0, 4.0, 25.0, 14.0, 20.0, 17.0, 54.0, 15.0, 4.0, 2.0, 2.0, 6.0, 18.0, 9.0, 10.0, 19.0, 17.0, 17.0, 8.0, 6.0, 69.0, 33.0, 14.0, 2.0, 15.0, 6.0, 9.0, 8.0, 34.0, 58.0, 55.0, 2.0, 9.0, 96.0, 8.0, 19.0, 76.0, 4.0, 0.0, 10.0, 4.0, 5.0, 2.0, 12.0, 0.0, 138.0, 78.0, 36.0, 15.0, 7.0, 6.0, 24.0, 3.0, 8.0, 9.0, 0.0, 102.0, 103.0, 3.0, 81.0, 5.0, 6.0, 2.0, 27.0, 12.0, 10.0, 120.0, 8.0, 5.0, 8.0, 2.0, 49.0, 84.0, 84.0, 11.0, 7.0, 14.0, 18.0, 16.0, 5.0, 83.0, 7.0, 4.0, 3.0, 6.0, 65.0, 0.0, 2.0, 2.0, 13.0, 7.0, 4.0, 1.0, 42.0, 82.0, 26.0, 16.0, 78.0, 33.0, 146.0, 10.0, 7.0, 4.0, 7.0, 144.0, 13.0, 4.0, 1.0, 130.0, 99.0, 22.0, 5.0, 3.0, 5.0, 23.0, 2.0, 86.0, 2.0, 5.0, 5.0, 0.0, 18.0, 6.0, 7.0, 139.0, 48.0, 15.0, 1.0, 88.0, 4.0, 1.0, 10.0, 121.0, 3.0, 17.0, 13.0, 130.0, 142.0, 13.0, 14.0, 140.0, 159.0, 102.0, 103.0, 6.0, 8.0, 8.0, 9.0, 1.0, 8.0, 18.0, 2.0, 5.0, 4.0, 10.0, 10.0, 156.0, 18.0, 131.0, 8.0, 3.0, 136.0, 108.0, 129.0, 6.0, 135.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6138566416303584, "mean_inference_ms": 1.9196010466254563, "mean_action_processing_ms": 0.263946906441776, "mean_env_wait_ms": 0.1986048488545051, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004211306571960449, "StateBufferConnector_ms": 0.0032804012298583984, "ViewRequirementAgentConnector_ms": 0.09223031997680664}, "num_episodes": 18, "episode_return_max": 2.9599999999999818, "episode_return_min": -394.47000000000025, "episode_return_mean": -75.58359999999992, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 544000, "num_agent_steps_trained": 544000, "num_env_steps_sampled": 136000, "num_env_steps_trained": 136000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 391.0812797790038, "num_env_steps_trained_throughput_per_sec": 391.0812797790038, "timesteps_total": 136000, "num_env_steps_sampled_lifetime": 136000, "num_agent_steps_sampled_lifetime": 544000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 544000, "timers": {"training_iteration_time_ms": 10747.147, "restore_workers_time_ms": 0.014, "training_step_time_ms": 10747.108, "sample_time_ms": 1407.078, "learn_time_ms": 9324.225, "learn_throughput": 428.99, "synch_weights_time_ms": 14.182}, "counters": {"num_env_steps_sampled": 136000, "num_env_steps_trained": 136000, "num_agent_steps_sampled": 544000, "num_agent_steps_trained": 544000}, "done": false, "training_iteration": 34, "trial_id": "8e499_00000", "date": "2024-08-15_02-10-24", "timestamp": 1723668024, "time_this_iter_s": 10.233957052230835, "time_total_s": 364.85458636283875, "pid": 33199, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b43f35e0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 364.85458636283875, "iterations_since_restore": 34, "perf": {"cpu_util_percent": 28.08571428571429, "ram_util_percent": 82.84285714285716}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2248746051832482, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.294602596949018, "policy_loss": -0.006819452307182093, "vf_loss": 4.300149622417631, "vf_explained_var": 0.42486429346932303, "kl": 0.011310486470678244, "entropy": 1.0898115212639803, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 65205.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8335414847053548, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.6387972834249025, "policy_loss": -0.005906914105446684, "vf_loss": 4.644102859623218, "vf_explained_var": 0.047295805890724144, "kl": 0.006013382379911664, "entropy": 1.098760040285726, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 65205.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 140000, "num_env_steps_trained": 140000, "num_agent_steps_sampled": 560000, "num_agent_steps_trained": 560000}, "env_runners": {"episode_reward_max": 2.9599999999999818, "episode_reward_min": -394.47000000000025, "episode_reward_mean": -93.69519999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -357.7900000000001, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 2.0000000000000013, "predator_policy": 159.0}, "policy_reward_mean": {"prey_policy": -83.98760000000001, "predator_policy": 37.14}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-7.250000000000078, -11.26000000000008, -128.00000000000165, -2.060000000000084, -4.080000000000084, -23.26999999999942, -25.289999999999445, -8.23000000000008, -10.140000000000082, -90.97999999999888, -10.150000000000082, -7.16000000000008, -13.169999999999945, -90.92999999999873, -53.57000000000006, -180.43999999999932, -23.26999999999942, -173.2799999999995, -6.100000000000081, -5.090000000000083, -6.120000000000074, -322.31000000000046, -121.18999999999882, -18.219999999999477, -14.239999999999815, -1.0800000000000622, -5.090000000000083, -114.6099999999998, -227.5700000000003, 2.939999999999982, -25.289999999999445, 1.8800000000000012, -284.0700000000003, 0.9199999999999823, -83.68999999999866, -262.15999999999997, -0.1100000000000392, -12.24000000000008, -7.16000000000008, -237.65000000000066, 2.9599999999999818, -67.71000000000019, 1.980000000000003, -11.150000000000082, -7.110000000000083, -39.43000000000058, -227.690000000001, -92.94999999999953, -361.71000000000043, -3.120000000000081, -7.110000000000083, -323.41000000000037, -1.050000000000063, -86.58999999999989, -27.289999999999424, 1.9500000000000028, -21.24999999999944, -84.87999999999958, -6.100000000000083, -14.179999999999824, -9.130000000000082, -355.72000000000054, -12.160000000000082, -125.09999999999897, -7.110000000000083, -121.23999999999938, -26.29999999999944, -184.29000000000016, -13.219999999999908, -394.47000000000025, -62.31000000000009, 1.920000000000003, -5.1300000000000825, -5.090000000000083, -12.180000000000081, -5.090000000000082, -16.199999999999438, -350.63000000000017, -305.2300000000008, -329.3500000000002, -388.13000000000034, -134.38999999999953, -216.35999999999996, -89.74999999999987, -290.0000000000007, 0.929999999999981, -123.32999999999956, -102.83999999999968, -262.86000000000007, 0.9199999999999809, -341.9500000000004, -372.1500000000002, -3.0700000000000838, -230.79000000000104, -9.130000000000082, 2.949999999999982, -5.080000000000084, -123.25999999999948, -353.5100000000003, -3.0700000000000838], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [2.0000000000000013, -48.25000000000035, -10.060000000000041, -38.20000000000036, -102.51999999999947, -94.47999999999946, -6.040000000000042, -2.020000000000042, -10.060000000000041, -2.020000000000042, -34.18000000000036, -16.089999999999705, -2.020000000000042, -52.270000000000344, -32.170000000000364, -10.060000000000041, -14.080000000000041, -10.060000000000041, -86.43999999999943, -106.5399999999995, -18.09999999999971, -8.050000000000042, -22.119999999999713, -6.040000000000042, -14.08000000000004, -16.0899999999997, -58.300000000000246, -124.62999999999936, -2.020000000000042, -108.55, -190.96000000000038, -94.48000000000012, -14.080000000000041, -36.19000000000036, -138.6999999999996, -114.58000000000001, -18.099999999999735, 2.0000000000000013, -6.040000000000042, -8.050000000000042, -18.09999999999973, -2.020000000000042, -201.01000000000016, -259.30000000000024, -78.39999999999947, -156.79000000000104, -2.020000000000042, -38.20000000000033, -20.109999999999705, -24.129999999999747, -14.080000000000041, 2.0000000000000013, -16.0899999999997, 2.0000000000000013, -98.49999999999997, -221.11000000000016, -148.7499999999999, -162.8199999999999, 2.0000000000000013, -10.060000000000041, -12.070000000000041, -42.220000000000354, 2.0000000000000013, -22.119999999999706, -221.11000000000004, -190.96000000000026, -14.080000000000041, 2.0000000000000013, -96.48999999999933, -38.20000000000025, -207.04000000000008, -223.11999999999998, -20.109999999999705, 2.0000000000000013, -8.050000000000038, -36.19000000000035, -14.080000000000041, -14.080000000000037, -154.7800000000002, -172.8700000000003, 2.0000000000000013, -6.040000000000042, -74.37999999999973, -64.32999999999973, -0.00999999999999836, -0.009999999999998581, -20.109999999999705, -6.040000000000042, -6.040000000000042, -12.070000000000041, -76.38999999999925, -6.040000000000031, -192.9700000000006, -142.72000000000037, -166.83999999999986, -20.11000000000004, -279.4000000000002, -261.3100000000002, -18.099999999999703, -2.0200000000000387, -6.040000000000042, -12.070000000000041, -251.2600000000001, -229.14999999999998, -6.040000000000042, -0.00999999999999836, -12.070000000000041, -303.52000000000015, -40.210000000000356, -14.080000000000041, 2.0000000000000013, -8.050000000000042, -2.020000000000042, -44.23000000000035, -12.070000000000041, -160.81000000000026, -2.0200000000000413, -14.080000000000041, -10.060000000000034, -22.119999999999706, -6.040000000000042, -16.089999999999726, -249.25000000000014, -293.47000000000025, -28.14999999999971, -0.00999999999999836, -100.50999999999951, -116.5899999999994, -2.020000000000042, -16.08999999999972, -18.099999999999703, -227.14000000000027, -18.099999999999703, -38.200000000000315, -351.76000000000016, -104.52999999999999, -26.13999999999971, -14.080000000000041, -347.7400000000001, -345.73000000000013, -231.12000000000012, -36.19000000000034, 2.0000000000000013, -14.080000000000041, -6.040000000000042, -16.0899999999997, -14.080000000000041, -0.00999999999999836, -10.060000000000041, -22.119999999999713, -16.089999999999705, 2.0000000000000013, -2.020000000000042, -34.18000000000036, -186.94000000000005, -337.69000000000017, -223.12000000000012, -221.1100000000003, -243.22000000000008, -225.13, -299.50000000000006, -325.6300000000001, -243.22000000000025, -32.17000000000036, -158.79999999999998, -311.56000000000006, -10.060000000000041, -337.6900000000001, -196.9900000000002, -201.01000000000025, -0.00999999999999836, -10.060000000000041, -229.15000000000012, -34.180000000000284, -357.7900000000001, -8.05000000000003, -180.90999999999997, -188.95000000000016, -14.080000000000041, 2.0000000000000013, -325.6300000000002, -263.3200000000002, -341.7100000000001, -287.44000000000005, -6.040000000000042, -4.030000000000042, -180.91000000000054, -174.88000000000045, -16.0899999999997, -6.040000000000042, 2.0000000000000013, -8.050000000000042, -8.050000000000042, -4.030000000000042, -40.210000000000306, -209.05000000000018, -237.19000000000005, -263.32000000000016, -0.00999999999999836, -10.060000000000041], "policy_predator_policy_reward": [25.0, 14.0, 20.0, 17.0, 54.0, 15.0, 4.0, 2.0, 2.0, 6.0, 18.0, 9.0, 10.0, 19.0, 17.0, 17.0, 8.0, 6.0, 69.0, 33.0, 14.0, 2.0, 15.0, 6.0, 9.0, 8.0, 34.0, 58.0, 55.0, 2.0, 9.0, 96.0, 8.0, 19.0, 76.0, 4.0, 0.0, 10.0, 4.0, 5.0, 2.0, 12.0, 0.0, 138.0, 78.0, 36.0, 15.0, 7.0, 6.0, 24.0, 3.0, 8.0, 9.0, 0.0, 102.0, 103.0, 3.0, 81.0, 5.0, 6.0, 2.0, 27.0, 12.0, 10.0, 120.0, 8.0, 5.0, 8.0, 2.0, 49.0, 84.0, 84.0, 11.0, 7.0, 14.0, 18.0, 16.0, 5.0, 83.0, 7.0, 4.0, 3.0, 6.0, 65.0, 0.0, 2.0, 2.0, 13.0, 7.0, 4.0, 1.0, 42.0, 82.0, 26.0, 16.0, 78.0, 33.0, 146.0, 10.0, 7.0, 4.0, 7.0, 144.0, 13.0, 4.0, 1.0, 130.0, 99.0, 22.0, 5.0, 3.0, 5.0, 23.0, 2.0, 86.0, 2.0, 5.0, 5.0, 0.0, 18.0, 6.0, 7.0, 139.0, 48.0, 15.0, 1.0, 88.0, 4.0, 1.0, 10.0, 121.0, 3.0, 17.0, 13.0, 130.0, 142.0, 13.0, 14.0, 140.0, 159.0, 102.0, 103.0, 6.0, 8.0, 8.0, 9.0, 1.0, 8.0, 18.0, 2.0, 5.0, 4.0, 10.0, 10.0, 156.0, 18.0, 131.0, 8.0, 3.0, 136.0, 108.0, 129.0, 6.0, 135.0, 128.0, 126.0, 128.0, 130.0, 104.0, 4.0, 6.0, 5.0, 21.0, 119.0, 120.0, 143.0, 15.0, 92.0, 6.0, 7.0, 142.0, 105.0, 109.0, 148.0, 4.0, 3.0, 14.0, 111.0, 9.0, 4.0, 4.0, 5.0, 5.0, 2.0, 2.0, 124.0, 130.0, 17.0, 1.0, 6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6121606454858943, "mean_inference_ms": 1.9139551431595465, "mean_action_processing_ms": 0.2628467693227995, "mean_env_wait_ms": 0.19807473282439025, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004221558570861816, "StateBufferConnector_ms": 0.0032781362533569336, "ViewRequirementAgentConnector_ms": 0.09209072589874268}, "num_episodes": 18, "episode_return_max": 2.9599999999999818, "episode_return_min": -394.47000000000025, "episode_return_mean": -93.69519999999999, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 560000, "num_agent_steps_trained": 560000, "num_env_steps_sampled": 140000, "num_env_steps_trained": 140000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 368.8967633150404, "num_env_steps_trained_throughput_per_sec": 368.8967633150404, "timesteps_total": 140000, "num_env_steps_sampled_lifetime": 140000, "num_agent_steps_sampled_lifetime": 560000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 560000, "timers": {"training_iteration_time_ms": 10717.415, "restore_workers_time_ms": 0.013, "training_step_time_ms": 10717.376, "sample_time_ms": 1364.303, "learn_time_ms": 9337.624, "learn_throughput": 428.374, "synch_weights_time_ms": 13.986}, "counters": {"num_env_steps_sampled": 140000, "num_env_steps_trained": 140000, "num_agent_steps_sampled": 560000, "num_agent_steps_trained": 560000}, "done": false, "training_iteration": 35, "trial_id": "8e499_00000", "date": "2024-08-15_02-10-35", "timestamp": 1723668035, "time_this_iter_s": 10.869012117385864, "time_total_s": 375.7235984802246, "pid": 33199, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x15800f160>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 375.7235984802246, "iterations_since_restore": 35, "perf": {"cpu_util_percent": 29.0625, "ram_util_percent": 82.51249999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6939223642387087, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.9990087776587755, "policy_loss": -0.004616063933021256, "vf_loss": 5.002229227716961, "vf_explained_var": 0.44646515862020864, "kl": 0.012405398217865288, "entropy": 1.1201217065097162, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 67095.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.986554372074112, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.414563973113974, "policy_loss": -0.00620308202720942, "vf_loss": 5.420079411905278, "vf_explained_var": 0.04745513957644266, "kl": 0.0068762793728435806, "entropy": 1.1280329191495502, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 67095.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 144000, "num_env_steps_trained": 144000, "num_agent_steps_sampled": 576000, "num_agent_steps_trained": 576000}, "env_runners": {"episode_reward_max": 2.9599999999999818, "episode_reward_min": -407.88000000000045, "episode_reward_mean": -110.22810000000001, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -357.7900000000001, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 2.0000000000000013, "predator_policy": 164.0}, "policy_reward_mean": {"prey_policy": -97.34405000000002, "predator_policy": 42.23}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-121.18999999999882, -18.219999999999477, -14.239999999999815, -1.0800000000000622, -5.090000000000083, -114.6099999999998, -227.5700000000003, 2.939999999999982, -25.289999999999445, 1.8800000000000012, -284.0700000000003, 0.9199999999999823, -83.68999999999866, -262.15999999999997, -0.1100000000000392, -12.24000000000008, -7.16000000000008, -237.65000000000066, 2.9599999999999818, -67.71000000000019, 1.980000000000003, -11.150000000000082, -7.110000000000083, -39.43000000000058, -227.690000000001, -92.94999999999953, -361.71000000000043, -3.120000000000081, -7.110000000000083, -323.41000000000037, -1.050000000000063, -86.58999999999989, -27.289999999999424, 1.9500000000000028, -21.24999999999944, -84.87999999999958, -6.100000000000083, -14.179999999999824, -9.130000000000082, -355.72000000000054, -12.160000000000082, -125.09999999999897, -7.110000000000083, -121.23999999999938, -26.29999999999944, -184.29000000000016, -13.219999999999908, -394.47000000000025, -62.31000000000009, 1.920000000000003, -5.1300000000000825, -5.090000000000083, -12.180000000000081, -5.090000000000082, -16.199999999999438, -350.63000000000017, -305.2300000000008, -329.3500000000002, -388.13000000000034, -134.38999999999953, -216.35999999999996, -89.74999999999987, -290.0000000000007, 0.929999999999981, -123.32999999999956, -102.83999999999968, -262.86000000000007, 0.9199999999999809, -341.9500000000004, -372.1500000000002, -3.0700000000000838, -230.79000000000104, -9.130000000000082, 2.949999999999982, -5.080000000000084, -123.25999999999948, -353.5100000000003, -3.0700000000000838, -54.08000000000005, -7.140000000000082, -407.88000000000045, -188.40000000000015, -298.18000000000023, -110.12999999999964, -106.08999999999975, -63.36000000000017, -81.84999999999991, -267.82000000000045, -149.5199999999991, -2.1700000000000808, -4.080000000000084, -398.2700000000001, -3.0900000000000833, 1.9500000000000028, -270.9400000000003, -7.110000000000083, -4.110000000000083, -163.19000000000005, -6.15000000000008, -263.8300000000002], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-78.39999999999947, -156.79000000000104, -2.020000000000042, -38.20000000000033, -20.109999999999705, -24.129999999999747, -14.080000000000041, 2.0000000000000013, -16.0899999999997, 2.0000000000000013, -98.49999999999997, -221.11000000000016, -148.7499999999999, -162.8199999999999, 2.0000000000000013, -10.060000000000041, -12.070000000000041, -42.220000000000354, 2.0000000000000013, -22.119999999999706, -221.11000000000004, -190.96000000000026, -14.080000000000041, 2.0000000000000013, -96.48999999999933, -38.20000000000025, -207.04000000000008, -223.11999999999998, -20.109999999999705, 2.0000000000000013, -8.050000000000038, -36.19000000000035, -14.080000000000041, -14.080000000000037, -154.7800000000002, -172.8700000000003, 2.0000000000000013, -6.040000000000042, -74.37999999999973, -64.32999999999973, -0.00999999999999836, -0.009999999999998581, -20.109999999999705, -6.040000000000042, -6.040000000000042, -12.070000000000041, -76.38999999999925, -6.040000000000031, -192.9700000000006, -142.72000000000037, -166.83999999999986, -20.11000000000004, -279.4000000000002, -261.3100000000002, -18.099999999999703, -2.0200000000000387, -6.040000000000042, -12.070000000000041, -251.2600000000001, -229.14999999999998, -6.040000000000042, -0.00999999999999836, -12.070000000000041, -303.52000000000015, -40.210000000000356, -14.080000000000041, 2.0000000000000013, -8.050000000000042, -2.020000000000042, -44.23000000000035, -12.070000000000041, -160.81000000000026, -2.0200000000000413, -14.080000000000041, -10.060000000000034, -22.119999999999706, -6.040000000000042, -16.089999999999726, -249.25000000000014, -293.47000000000025, -28.14999999999971, -0.00999999999999836, -100.50999999999951, -116.5899999999994, -2.020000000000042, -16.08999999999972, -18.099999999999703, -227.14000000000027, -18.099999999999703, -38.200000000000315, -351.76000000000016, -104.52999999999999, -26.13999999999971, -14.080000000000041, -347.7400000000001, -345.73000000000013, -231.12000000000012, -36.19000000000034, 2.0000000000000013, -14.080000000000041, -6.040000000000042, -16.0899999999997, -14.080000000000041, -0.00999999999999836, -10.060000000000041, -22.119999999999713, -16.089999999999705, 2.0000000000000013, -2.020000000000042, -34.18000000000036, -186.94000000000005, -337.69000000000017, -223.12000000000012, -221.1100000000003, -243.22000000000008, -225.13, -299.50000000000006, -325.6300000000001, -243.22000000000025, -32.17000000000036, -158.79999999999998, -311.56000000000006, -10.060000000000041, -337.6900000000001, -196.9900000000002, -201.01000000000025, -0.00999999999999836, -10.060000000000041, -229.15000000000012, -34.180000000000284, -357.7900000000001, -8.05000000000003, -180.90999999999997, -188.95000000000016, -14.080000000000041, 2.0000000000000013, -325.6300000000002, -263.3200000000002, -341.7100000000001, -287.44000000000005, -6.040000000000042, -4.030000000000042, -180.91000000000054, -174.88000000000045, -16.0899999999997, -6.040000000000042, 2.0000000000000013, -8.050000000000042, -8.050000000000042, -4.030000000000042, -40.210000000000306, -209.05000000000018, -237.19000000000005, -263.32000000000016, -0.00999999999999836, -10.060000000000041, -4.030000000000042, -209.05, -22.119999999999706, -2.020000000000042, -273.3700000000001, -301.51000000000016, -166.84000000000003, -110.55999999999999, -194.97999999999985, -239.20000000000022, -211.06000000000006, -12.070000000000041, -196.98999999999995, -18.099999999999703, -10.060000000000041, -259.3000000000001, -12.070000000000041, -154.78000000000003, -184.93000000000015, -176.89000000000004, -203.02000000000015, -98.49999999999923, -32.170000000000364, 2.0000000000000013, -14.080000000000041, 2.0000000000000013, -329.65000000000003, -323.62000000000006, -4.030000000000042, -10.060000000000041, 2.0000000000000013, -8.050000000000042, -225.13000000000017, -160.80999999999997, -6.040000000000042, -12.070000000000041, -20.109999999999705, 2.0000000000000013, -124.63000000000002, -110.55999999999997, -10.060000000000038, -16.0899999999997, -178.9000000000001, -184.9300000000001], "policy_predator_policy_reward": [78.0, 36.0, 15.0, 7.0, 6.0, 24.0, 3.0, 8.0, 9.0, 0.0, 102.0, 103.0, 3.0, 81.0, 5.0, 6.0, 2.0, 27.0, 12.0, 10.0, 120.0, 8.0, 5.0, 8.0, 2.0, 49.0, 84.0, 84.0, 11.0, 7.0, 14.0, 18.0, 16.0, 5.0, 83.0, 7.0, 4.0, 3.0, 6.0, 65.0, 0.0, 2.0, 2.0, 13.0, 7.0, 4.0, 1.0, 42.0, 82.0, 26.0, 16.0, 78.0, 33.0, 146.0, 10.0, 7.0, 4.0, 7.0, 144.0, 13.0, 4.0, 1.0, 130.0, 99.0, 22.0, 5.0, 3.0, 5.0, 23.0, 2.0, 86.0, 2.0, 5.0, 5.0, 0.0, 18.0, 6.0, 7.0, 139.0, 48.0, 15.0, 1.0, 88.0, 4.0, 1.0, 10.0, 121.0, 3.0, 17.0, 13.0, 130.0, 142.0, 13.0, 14.0, 140.0, 159.0, 102.0, 103.0, 6.0, 8.0, 8.0, 9.0, 1.0, 8.0, 18.0, 2.0, 5.0, 4.0, 10.0, 10.0, 156.0, 18.0, 131.0, 8.0, 3.0, 136.0, 108.0, 129.0, 6.0, 135.0, 128.0, 126.0, 128.0, 130.0, 104.0, 4.0, 6.0, 5.0, 21.0, 119.0, 120.0, 143.0, 15.0, 92.0, 6.0, 7.0, 142.0, 105.0, 109.0, 148.0, 4.0, 3.0, 14.0, 111.0, 9.0, 4.0, 4.0, 5.0, 5.0, 2.0, 2.0, 124.0, 130.0, 17.0, 1.0, 6.0, 81.0, 78.0, 6.0, 11.0, 3.0, 164.0, 4.0, 85.0, 7.0, 129.0, 0.0, 113.0, 4.0, 105.0, 94.0, 112.0, 85.0, 0.0, 0.0, 94.0, 28.0, 124.0, 14.0, 14.0, 0.0, 8.0, 100.0, 155.0, 6.0, 5.0, 5.0, 3.0, 115.0, 0.0, 7.0, 4.0, 3.0, 11.0, 3.0, 69.0, 15.0, 5.0, 98.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6101793412271213, "mean_inference_ms": 1.908584369960804, "mean_action_processing_ms": 0.2608431936205555, "mean_env_wait_ms": 0.19752882118947068, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0042400360107421875, "StateBufferConnector_ms": 0.0033233165740966797, "ViewRequirementAgentConnector_ms": 0.0934910774230957}, "num_episodes": 22, "episode_return_max": 2.9599999999999818, "episode_return_min": -407.88000000000045, "episode_return_mean": -110.22810000000001, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 576000, "num_agent_steps_trained": 576000, "num_env_steps_sampled": 144000, "num_env_steps_trained": 144000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 391.20633941512966, "num_env_steps_trained_throughput_per_sec": 391.20633941512966, "timesteps_total": 144000, "num_env_steps_sampled_lifetime": 144000, "num_agent_steps_sampled_lifetime": 576000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 576000, "timers": {"training_iteration_time_ms": 10652.572, "restore_workers_time_ms": 0.013, "training_step_time_ms": 10652.534, "sample_time_ms": 1348.626, "learn_time_ms": 9288.566, "learn_throughput": 430.637, "synch_weights_time_ms": 14.047}, "counters": {"num_env_steps_sampled": 144000, "num_env_steps_trained": 144000, "num_agent_steps_sampled": 576000, "num_agent_steps_trained": 576000}, "done": false, "training_iteration": 36, "trial_id": "8e499_00000", "date": "2024-08-15_02-10-45", "timestamp": 1723668045, "time_this_iter_s": 10.229266166687012, "time_total_s": 385.9528646469116, "pid": 33199, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x1580310d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 385.9528646469116, "iterations_since_restore": 36, "perf": {"cpu_util_percent": 29.735714285714284, "ram_util_percent": 82.34285714285714}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7010189452183941, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.079714492515281, "policy_loss": -0.006272703574763404, "vf_loss": 8.084727652363046, "vf_explained_var": 0.32073117068835666, "kl": 0.011196042108944997, "entropy": 0.9193811952752411, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 68985.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0549530891829697, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.843034667312784, "policy_loss": -0.009020112798593584, "vf_loss": 6.850808279098026, "vf_explained_var": 0.05338154665376774, "kl": 0.012465015666054952, "entropy": 1.1260925516249642, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 68985.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 148000, "num_env_steps_trained": 148000, "num_agent_steps_sampled": 592000, "num_agent_steps_trained": 592000}, "env_runners": {"episode_reward_max": 2.949999999999982, "episode_reward_min": -407.88000000000045, "episode_reward_mean": -133.58240000000004, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -357.7900000000001, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 2.0000000000000013, "predator_policy": 164.0}, "policy_reward_mean": {"prey_policy": -122.17620000000005, "predator_policy": 55.385}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-39.43000000000058, -227.690000000001, -92.94999999999953, -361.71000000000043, -3.120000000000081, -7.110000000000083, -323.41000000000037, -1.050000000000063, -86.58999999999989, -27.289999999999424, 1.9500000000000028, -21.24999999999944, -84.87999999999958, -6.100000000000083, -14.179999999999824, -9.130000000000082, -355.72000000000054, -12.160000000000082, -125.09999999999897, -7.110000000000083, -121.23999999999938, -26.29999999999944, -184.29000000000016, -13.219999999999908, -394.47000000000025, -62.31000000000009, 1.920000000000003, -5.1300000000000825, -5.090000000000083, -12.180000000000081, -5.090000000000082, -16.199999999999438, -350.63000000000017, -305.2300000000008, -329.3500000000002, -388.13000000000034, -134.38999999999953, -216.35999999999996, -89.74999999999987, -290.0000000000007, 0.929999999999981, -123.32999999999956, -102.83999999999968, -262.86000000000007, 0.9199999999999809, -341.9500000000004, -372.1500000000002, -3.0700000000000838, -230.79000000000104, -9.130000000000082, 2.949999999999982, -5.080000000000084, -123.25999999999948, -353.5100000000003, -3.0700000000000838, -54.08000000000005, -7.140000000000082, -407.88000000000045, -188.40000000000015, -298.18000000000023, -110.12999999999964, -106.08999999999975, -63.36000000000017, -81.84999999999991, -267.82000000000045, -149.5199999999991, -2.1700000000000808, -4.080000000000084, -398.2700000000001, -3.0900000000000833, 1.9500000000000028, -270.9400000000003, -7.110000000000083, -4.110000000000083, -163.19000000000005, -6.15000000000008, -263.8300000000002, -326.5600000000003, -237.63000000000008, -344.54000000000013, -265.5900000000001, 1.980000000000003, -133.78999999999996, -184.41000000000093, -339.6500000000004, -302.73000000000013, -87.73999999999954, 0.9399999999999819, -54.450000000000095, -5.090000000000083, -99.8199999999997, -8.14000000000008, -348.0400000000002, -161.52000000000004, -215.81000000000085, -90.93999999999986, -308.88, -8.280000000000078, -223.83000000000013, -80.56999999999992], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-76.38999999999925, -6.040000000000031, -192.9700000000006, -142.72000000000037, -166.83999999999986, -20.11000000000004, -279.4000000000002, -261.3100000000002, -18.099999999999703, -2.0200000000000387, -6.040000000000042, -12.070000000000041, -251.2600000000001, -229.14999999999998, -6.040000000000042, -0.00999999999999836, -12.070000000000041, -303.52000000000015, -40.210000000000356, -14.080000000000041, 2.0000000000000013, -8.050000000000042, -2.020000000000042, -44.23000000000035, -12.070000000000041, -160.81000000000026, -2.0200000000000413, -14.080000000000041, -10.060000000000034, -22.119999999999706, -6.040000000000042, -16.089999999999726, -249.25000000000014, -293.47000000000025, -28.14999999999971, -0.00999999999999836, -100.50999999999951, -116.5899999999994, -2.020000000000042, -16.08999999999972, -18.099999999999703, -227.14000000000027, -18.099999999999703, -38.200000000000315, -351.76000000000016, -104.52999999999999, -26.13999999999971, -14.080000000000041, -347.7400000000001, -345.73000000000013, -231.12000000000012, -36.19000000000034, 2.0000000000000013, -14.080000000000041, -6.040000000000042, -16.0899999999997, -14.080000000000041, -0.00999999999999836, -10.060000000000041, -22.119999999999713, -16.089999999999705, 2.0000000000000013, -2.020000000000042, -34.18000000000036, -186.94000000000005, -337.69000000000017, -223.12000000000012, -221.1100000000003, -243.22000000000008, -225.13, -299.50000000000006, -325.6300000000001, -243.22000000000025, -32.17000000000036, -158.79999999999998, -311.56000000000006, -10.060000000000041, -337.6900000000001, -196.9900000000002, -201.01000000000025, -0.00999999999999836, -10.060000000000041, -229.15000000000012, -34.180000000000284, -357.7900000000001, -8.05000000000003, -180.90999999999997, -188.95000000000016, -14.080000000000041, 2.0000000000000013, -325.6300000000002, -263.3200000000002, -341.7100000000001, -287.44000000000005, -6.040000000000042, -4.030000000000042, -180.91000000000054, -174.88000000000045, -16.0899999999997, -6.040000000000042, 2.0000000000000013, -8.050000000000042, -8.050000000000042, -4.030000000000042, -40.210000000000306, -209.05000000000018, -237.19000000000005, -263.32000000000016, -0.00999999999999836, -10.060000000000041, -4.030000000000042, -209.05, -22.119999999999706, -2.020000000000042, -273.3700000000001, -301.51000000000016, -166.84000000000003, -110.55999999999999, -194.97999999999985, -239.20000000000022, -211.06000000000006, -12.070000000000041, -196.98999999999995, -18.099999999999703, -10.060000000000041, -259.3000000000001, -12.070000000000041, -154.78000000000003, -184.93000000000015, -176.89000000000004, -203.02000000000015, -98.49999999999923, -32.170000000000364, 2.0000000000000013, -14.080000000000041, 2.0000000000000013, -329.65000000000003, -323.62000000000006, -4.030000000000042, -10.060000000000041, 2.0000000000000013, -8.050000000000042, -225.13000000000017, -160.80999999999997, -6.040000000000042, -12.070000000000041, -20.109999999999705, 2.0000000000000013, -124.63000000000002, -110.55999999999997, -10.060000000000038, -16.0899999999997, -178.9000000000001, -184.9300000000001, -265.33000000000004, -245.23000000000002, -203.02000000000004, -321.61000000000007, -245.23000000000002, -261.31, -186.94, -329.65000000000003, -0.00999999999999836, -0.00999999999999836, -98.49999999999952, -257.2900000000001, -170.82000000000085, -317.5900000000001, -223.12000000000006, -305.5300000000003, -229.14999999999998, -323.58000000000004, -299.50000000000006, -46.24000000000029, -10.060000000000041, 2.0000000000000013, -34.18000000000006, -52.27000000000004, 2.0000000000000013, -16.089999999999705, -353.7700000000001, -8.050000000000042, -14.08000000000004, -10.060000000000041, -319.6000000000001, -287.44000000000005, -152.77, -148.75000000000006, -160.8100000000007, -199.00000000000003, -174.88000000000008, -10.060000000000041, -291.3, -323.58000000000004, -54.28000000000034, 2.0000000000000013, -180.9099999999999, -182.92000000000007, -297.49, -14.080000000000037], "policy_predator_policy_reward": [1.0, 42.0, 82.0, 26.0, 16.0, 78.0, 33.0, 146.0, 10.0, 7.0, 4.0, 7.0, 144.0, 13.0, 4.0, 1.0, 130.0, 99.0, 22.0, 5.0, 3.0, 5.0, 23.0, 2.0, 86.0, 2.0, 5.0, 5.0, 0.0, 18.0, 6.0, 7.0, 139.0, 48.0, 15.0, 1.0, 88.0, 4.0, 1.0, 10.0, 121.0, 3.0, 17.0, 13.0, 130.0, 142.0, 13.0, 14.0, 140.0, 159.0, 102.0, 103.0, 6.0, 8.0, 8.0, 9.0, 1.0, 8.0, 18.0, 2.0, 5.0, 4.0, 10.0, 10.0, 156.0, 18.0, 131.0, 8.0, 3.0, 136.0, 108.0, 129.0, 6.0, 135.0, 128.0, 126.0, 128.0, 130.0, 104.0, 4.0, 6.0, 5.0, 21.0, 119.0, 120.0, 143.0, 15.0, 92.0, 6.0, 7.0, 142.0, 105.0, 109.0, 148.0, 4.0, 3.0, 14.0, 111.0, 9.0, 4.0, 4.0, 5.0, 5.0, 2.0, 2.0, 124.0, 130.0, 17.0, 1.0, 6.0, 81.0, 78.0, 6.0, 11.0, 3.0, 164.0, 4.0, 85.0, 7.0, 129.0, 0.0, 113.0, 4.0, 105.0, 94.0, 112.0, 85.0, 0.0, 0.0, 94.0, 28.0, 124.0, 14.0, 14.0, 0.0, 8.0, 100.0, 155.0, 6.0, 5.0, 5.0, 3.0, 115.0, 0.0, 7.0, 4.0, 3.0, 11.0, 3.0, 69.0, 15.0, 5.0, 98.0, 2.0, 123.0, 61.0, 147.0, 140.0, 122.0, 40.0, 142.0, 109.0, 1.0, 1.0, 103.0, 119.0, 157.0, 147.0, 35.0, 154.0, 99.0, 151.0, 129.0, 129.0, 4.0, 5.0, 29.0, 3.0, 0.0, 9.0, 117.0, 145.0, 6.0, 10.0, 148.0, 111.0, 71.0, 69.0, 139.0, 5.0, 85.0, 9.0, 151.0, 155.0, 28.0, 16.0, 48.0, 92.0, 108.0, 123.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.60825584970731, "mean_inference_ms": 1.903639880076948, "mean_action_processing_ms": 0.2603962050657866, "mean_env_wait_ms": 0.1968819874609424, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004209399223327637, "StateBufferConnector_ms": 0.0032306909561157227, "ViewRequirementAgentConnector_ms": 0.0925225019454956}, "num_episodes": 23, "episode_return_max": 2.949999999999982, "episode_return_min": -407.88000000000045, "episode_return_mean": -133.58240000000004, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 592000, "num_agent_steps_trained": 592000, "num_env_steps_sampled": 148000, "num_env_steps_trained": 148000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 392.4886265854154, "num_env_steps_trained_throughput_per_sec": 392.4886265854154, "timesteps_total": 148000, "num_env_steps_sampled_lifetime": 148000, "num_agent_steps_sampled_lifetime": 592000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 592000, "timers": {"training_iteration_time_ms": 10586.113, "restore_workers_time_ms": 0.013, "training_step_time_ms": 10586.076, "sample_time_ms": 1338.481, "learn_time_ms": 9232.269, "learn_throughput": 433.263, "synch_weights_time_ms": 14.117}, "counters": {"num_env_steps_sampled": 148000, "num_env_steps_trained": 148000, "num_agent_steps_sampled": 592000, "num_agent_steps_trained": 592000}, "done": false, "training_iteration": 37, "trial_id": "8e499_00000", "date": "2024-08-15_02-10-56", "timestamp": 1723668056, "time_this_iter_s": 10.203476905822754, "time_total_s": 396.1563415527344, "pid": 33199, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x1580dd3a0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 396.1563415527344, "iterations_since_restore": 37, "perf": {"cpu_util_percent": 27.71333333333333, "ram_util_percent": 82.22666666666667}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7282745661874297, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.091970192944562, "policy_loss": -0.0008849403010336338, "vf_loss": 9.091178146493498, "vf_explained_var": 0.26147130286252057, "kl": 0.01490638494901639, "entropy": 0.8890302409255315, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 70875.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0981302928514582, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.396590949114037, "policy_loss": -0.007463304118977653, "vf_loss": 8.40282544635591, "vf_explained_var": 0.04866664277182685, "kl": 0.012288171161899347, "entropy": 1.0905639983989575, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 70875.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 152000, "num_env_steps_trained": 152000, "num_agent_steps_sampled": 608000, "num_agent_steps_trained": 608000}, "env_runners": {"episode_reward_max": 2.949999999999982, "episode_reward_min": -407.88000000000045, "episode_reward_mean": -153.46150000000003, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -373.8700000000001, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 2.0000000000000013, "predator_policy": 175.0}, "policy_reward_mean": {"prey_policy": -144.23575000000005, "predator_policy": 67.505}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-125.09999999999897, -7.110000000000083, -121.23999999999938, -26.29999999999944, -184.29000000000016, -13.219999999999908, -394.47000000000025, -62.31000000000009, 1.920000000000003, -5.1300000000000825, -5.090000000000083, -12.180000000000081, -5.090000000000082, -16.199999999999438, -350.63000000000017, -305.2300000000008, -329.3500000000002, -388.13000000000034, -134.38999999999953, -216.35999999999996, -89.74999999999987, -290.0000000000007, 0.929999999999981, -123.32999999999956, -102.83999999999968, -262.86000000000007, 0.9199999999999809, -341.9500000000004, -372.1500000000002, -3.0700000000000838, -230.79000000000104, -9.130000000000082, 2.949999999999982, -5.080000000000084, -123.25999999999948, -353.5100000000003, -3.0700000000000838, -54.08000000000005, -7.140000000000082, -407.88000000000045, -188.40000000000015, -298.18000000000023, -110.12999999999964, -106.08999999999975, -63.36000000000017, -81.84999999999991, -267.82000000000045, -149.5199999999991, -2.1700000000000808, -4.080000000000084, -398.2700000000001, -3.0900000000000833, 1.9500000000000028, -270.9400000000003, -7.110000000000083, -4.110000000000083, -163.19000000000005, -6.15000000000008, -263.8300000000002, -326.5600000000003, -237.63000000000008, -344.54000000000013, -265.5900000000001, 1.980000000000003, -133.78999999999996, -184.41000000000093, -339.6500000000004, -302.73000000000013, -87.73999999999954, 0.9399999999999819, -54.450000000000095, -5.090000000000083, -99.8199999999997, -8.14000000000008, -348.0400000000002, -161.52000000000004, -215.81000000000085, -90.93999999999986, -308.88, -8.280000000000078, -223.83000000000013, -80.56999999999992, -149.23000000000008, -54.03000000000008, -219.35000000000048, -345.8900000000002, -239.23000000000008, -346.2000000000001, -77.18999999999984, -185.7800000000001, -87.44999999999959, -284.62000000000006, -364.8800000000003, -90.19999999999979, -318.7600000000001, -182.00000000000006, -81.03999999999984, -79.52999999999975, -335.41, -218.93999999999994], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-100.50999999999951, -116.5899999999994, -2.020000000000042, -16.08999999999972, -18.099999999999703, -227.14000000000027, -18.099999999999703, -38.200000000000315, -351.76000000000016, -104.52999999999999, -26.13999999999971, -14.080000000000041, -347.7400000000001, -345.73000000000013, -231.12000000000012, -36.19000000000034, 2.0000000000000013, -14.080000000000041, -6.040000000000042, -16.0899999999997, -14.080000000000041, -0.00999999999999836, -10.060000000000041, -22.119999999999713, -16.089999999999705, 2.0000000000000013, -2.020000000000042, -34.18000000000036, -186.94000000000005, -337.69000000000017, -223.12000000000012, -221.1100000000003, -243.22000000000008, -225.13, -299.50000000000006, -325.6300000000001, -243.22000000000025, -32.17000000000036, -158.79999999999998, -311.56000000000006, -10.060000000000041, -337.6900000000001, -196.9900000000002, -201.01000000000025, -0.00999999999999836, -10.060000000000041, -229.15000000000012, -34.180000000000284, -357.7900000000001, -8.05000000000003, -180.90999999999997, -188.95000000000016, -14.080000000000041, 2.0000000000000013, -325.6300000000002, -263.3200000000002, -341.7100000000001, -287.44000000000005, -6.040000000000042, -4.030000000000042, -180.91000000000054, -174.88000000000045, -16.0899999999997, -6.040000000000042, 2.0000000000000013, -8.050000000000042, -8.050000000000042, -4.030000000000042, -40.210000000000306, -209.05000000000018, -237.19000000000005, -263.32000000000016, -0.00999999999999836, -10.060000000000041, -4.030000000000042, -209.05, -22.119999999999706, -2.020000000000042, -273.3700000000001, -301.51000000000016, -166.84000000000003, -110.55999999999999, -194.97999999999985, -239.20000000000022, -211.06000000000006, -12.070000000000041, -196.98999999999995, -18.099999999999703, -10.060000000000041, -259.3000000000001, -12.070000000000041, -154.78000000000003, -184.93000000000015, -176.89000000000004, -203.02000000000015, -98.49999999999923, -32.170000000000364, 2.0000000000000013, -14.080000000000041, 2.0000000000000013, -329.65000000000003, -323.62000000000006, -4.030000000000042, -10.060000000000041, 2.0000000000000013, -8.050000000000042, -225.13000000000017, -160.80999999999997, -6.040000000000042, -12.070000000000041, -20.109999999999705, 2.0000000000000013, -124.63000000000002, -110.55999999999997, -10.060000000000038, -16.0899999999997, -178.9000000000001, -184.9300000000001, -265.33000000000004, -245.23000000000002, -203.02000000000004, -321.61000000000007, -245.23000000000002, -261.31, -186.94, -329.65000000000003, -0.00999999999999836, -0.00999999999999836, -98.49999999999952, -257.2900000000001, -170.82000000000085, -317.5900000000001, -223.12000000000006, -305.5300000000003, -229.14999999999998, -323.58000000000004, -299.50000000000006, -46.24000000000029, -10.060000000000041, 2.0000000000000013, -34.18000000000006, -52.27000000000004, 2.0000000000000013, -16.089999999999705, -353.7700000000001, -8.050000000000042, -14.08000000000004, -10.060000000000041, -319.6000000000001, -287.44000000000005, -152.77, -148.75000000000006, -160.8100000000007, -199.00000000000003, -174.88000000000008, -10.060000000000041, -291.3, -323.58000000000004, -54.28000000000034, 2.0000000000000013, -180.9099999999999, -182.92000000000007, -297.49, -14.080000000000037, -114.58, -128.65000000000003, -8.050000000000042, -194.98000000000005, -291.46, -176.8900000000005, -285.4300000000002, -291.46000000000015, -213.07000000000002, -231.1599999999999, -309.55, -329.65000000000003, -10.060000000000041, -225.12999999999994, -207.04000000000008, -146.73999999999998, -255.28000000000014, -32.17000000000032, -311.5600000000001, -211.06, -259.30000000000007, -315.5800000000001, -178.9, -58.30000000000013, -297.45, -261.31000000000006, -128.64999999999986, -269.3500000000001, -36.18999999999986, -168.84999999999994, -271.35999999999996, -32.170000000000215, -373.8700000000001, -307.53999999999996, -186.94000000000003, -198.9999999999999], "policy_predator_policy_reward": [88.0, 4.0, 1.0, 10.0, 121.0, 3.0, 17.0, 13.0, 130.0, 142.0, 13.0, 14.0, 140.0, 159.0, 102.0, 103.0, 6.0, 8.0, 8.0, 9.0, 1.0, 8.0, 18.0, 2.0, 5.0, 4.0, 10.0, 10.0, 156.0, 18.0, 131.0, 8.0, 3.0, 136.0, 108.0, 129.0, 6.0, 135.0, 128.0, 126.0, 128.0, 130.0, 104.0, 4.0, 6.0, 5.0, 21.0, 119.0, 120.0, 143.0, 15.0, 92.0, 6.0, 7.0, 142.0, 105.0, 109.0, 148.0, 4.0, 3.0, 14.0, 111.0, 9.0, 4.0, 4.0, 5.0, 5.0, 2.0, 2.0, 124.0, 130.0, 17.0, 1.0, 6.0, 81.0, 78.0, 6.0, 11.0, 3.0, 164.0, 4.0, 85.0, 7.0, 129.0, 0.0, 113.0, 4.0, 105.0, 94.0, 112.0, 85.0, 0.0, 0.0, 94.0, 28.0, 124.0, 14.0, 14.0, 0.0, 8.0, 100.0, 155.0, 6.0, 5.0, 5.0, 3.0, 115.0, 0.0, 7.0, 4.0, 3.0, 11.0, 3.0, 69.0, 15.0, 5.0, 98.0, 2.0, 123.0, 61.0, 147.0, 140.0, 122.0, 40.0, 142.0, 109.0, 1.0, 1.0, 103.0, 119.0, 157.0, 147.0, 35.0, 154.0, 99.0, 151.0, 129.0, 129.0, 4.0, 5.0, 29.0, 3.0, 0.0, 9.0, 117.0, 145.0, 6.0, 10.0, 148.0, 111.0, 71.0, 69.0, 139.0, 5.0, 85.0, 9.0, 151.0, 155.0, 28.0, 16.0, 48.0, 92.0, 108.0, 123.0, 57.0, 37.0, 78.0, 71.0, 120.0, 129.0, 110.0, 121.0, 96.0, 109.0, 141.0, 152.0, 66.0, 92.0, 72.0, 96.0, 90.0, 110.0, 108.0, 130.0, 54.0, 156.0, 51.0, 96.0, 109.0, 131.0, 106.0, 110.0, 24.0, 100.0, 108.0, 116.0, 175.0, 171.0, 86.0, 81.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6064949140569013, "mean_inference_ms": 1.8997903627726458, "mean_action_processing_ms": 0.25945930782948795, "mean_env_wait_ms": 0.1964429553471794, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0037271976470947266, "StateBufferConnector_ms": 0.0030690431594848633, "ViewRequirementAgentConnector_ms": 0.09049701690673828}, "num_episodes": 18, "episode_return_max": 2.949999999999982, "episode_return_min": -407.88000000000045, "episode_return_mean": -153.46150000000003, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 608000, "num_agent_steps_trained": 608000, "num_env_steps_sampled": 152000, "num_env_steps_trained": 152000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 385.5344430846623, "num_env_steps_trained_throughput_per_sec": 385.5344430846623, "timesteps_total": 152000, "num_env_steps_sampled_lifetime": 152000, "num_agent_steps_sampled_lifetime": 608000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 608000, "timers": {"training_iteration_time_ms": 10509.185, "restore_workers_time_ms": 0.013, "training_step_time_ms": 10509.147, "sample_time_ms": 1291.725, "learn_time_ms": 9201.835, "learn_throughput": 434.696, "synch_weights_time_ms": 14.159}, "counters": {"num_env_steps_sampled": 152000, "num_env_steps_trained": 152000, "num_agent_steps_sampled": 608000, "num_agent_steps_trained": 608000}, "done": false, "training_iteration": 38, "trial_id": "8e499_00000", "date": "2024-08-15_02-11-06", "timestamp": 1723668066, "time_this_iter_s": 10.419846057891846, "time_total_s": 406.5761876106262, "pid": 33199, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x15800f700>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 406.5761876106262, "iterations_since_restore": 38, "perf": {"cpu_util_percent": 30.664285714285718, "ram_util_percent": 82.57142857142857}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.717694891319073, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.33298530881367, "policy_loss": -0.0019368032742508505, "vf_loss": 9.333643208861982, "vf_explained_var": -0.21178109343089754, "kl": 0.011367955575697542, "entropy": 0.8150305748616576, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 72765.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9537113763037182, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.682638347464263, "policy_loss": -0.008053562741495037, "vf_loss": 6.689495999472482, "vf_explained_var": 0.09229636428848145, "kl": 0.011959086853404223, "entropy": 0.9386995142099088, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 72765.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 156000, "num_env_steps_trained": 156000, "num_agent_steps_sampled": 624000, "num_agent_steps_trained": 624000}, "env_runners": {"episode_reward_max": 2.949999999999982, "episode_reward_min": -407.88000000000045, "episode_reward_mean": -150.34340000000003, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -373.8700000000001, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 2.0000000000000013, "predator_policy": 175.0}, "policy_reward_mean": {"prey_policy": -149.41170000000002, "predator_policy": 74.24}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-134.38999999999953, -216.35999999999996, -89.74999999999987, -290.0000000000007, 0.929999999999981, -123.32999999999956, -102.83999999999968, -262.86000000000007, 0.9199999999999809, -341.9500000000004, -372.1500000000002, -3.0700000000000838, -230.79000000000104, -9.130000000000082, 2.949999999999982, -5.080000000000084, -123.25999999999948, -353.5100000000003, -3.0700000000000838, -54.08000000000005, -7.140000000000082, -407.88000000000045, -188.40000000000015, -298.18000000000023, -110.12999999999964, -106.08999999999975, -63.36000000000017, -81.84999999999991, -267.82000000000045, -149.5199999999991, -2.1700000000000808, -4.080000000000084, -398.2700000000001, -3.0900000000000833, 1.9500000000000028, -270.9400000000003, -7.110000000000083, -4.110000000000083, -163.19000000000005, -6.15000000000008, -263.8300000000002, -326.5600000000003, -237.63000000000008, -344.54000000000013, -265.5900000000001, 1.980000000000003, -133.78999999999996, -184.41000000000093, -339.6500000000004, -302.73000000000013, -87.73999999999954, 0.9399999999999819, -54.450000000000095, -5.090000000000083, -99.8199999999997, -8.14000000000008, -348.0400000000002, -161.52000000000004, -215.81000000000085, -90.93999999999986, -308.88, -8.280000000000078, -223.83000000000013, -80.56999999999992, -149.23000000000008, -54.03000000000008, -219.35000000000048, -345.8900000000002, -239.23000000000008, -346.2000000000001, -77.18999999999984, -185.7800000000001, -87.44999999999959, -284.62000000000006, -364.8800000000003, -90.19999999999979, -318.7600000000001, -182.00000000000006, -81.03999999999984, -79.52999999999975, -335.41, -218.93999999999994, -131.40000000000055, -125.37999999999988, -23.489999999999707, -30.36000000000012, -47.150000000000134, -77.53999999999989, -222.01000000000005, -83.6099999999996, -264.5700000000001, -46.21000000000001, -34.5299999999998, -99.59999999999918, -225.40000000000032, -137.44999999999996, -319.80000000000007, -76.72999999999983, -62.72000000000014, -29.389999999999784], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-243.22000000000025, -32.17000000000036, -158.79999999999998, -311.56000000000006, -10.060000000000041, -337.6900000000001, -196.9900000000002, -201.01000000000025, -0.00999999999999836, -10.060000000000041, -229.15000000000012, -34.180000000000284, -357.7900000000001, -8.05000000000003, -180.90999999999997, -188.95000000000016, -14.080000000000041, 2.0000000000000013, -325.6300000000002, -263.3200000000002, -341.7100000000001, -287.44000000000005, -6.040000000000042, -4.030000000000042, -180.91000000000054, -174.88000000000045, -16.0899999999997, -6.040000000000042, 2.0000000000000013, -8.050000000000042, -8.050000000000042, -4.030000000000042, -40.210000000000306, -209.05000000000018, -237.19000000000005, -263.32000000000016, -0.00999999999999836, -10.060000000000041, -4.030000000000042, -209.05, -22.119999999999706, -2.020000000000042, -273.3700000000001, -301.51000000000016, -166.84000000000003, -110.55999999999999, -194.97999999999985, -239.20000000000022, -211.06000000000006, -12.070000000000041, -196.98999999999995, -18.099999999999703, -10.060000000000041, -259.3000000000001, -12.070000000000041, -154.78000000000003, -184.93000000000015, -176.89000000000004, -203.02000000000015, -98.49999999999923, -32.170000000000364, 2.0000000000000013, -14.080000000000041, 2.0000000000000013, -329.65000000000003, -323.62000000000006, -4.030000000000042, -10.060000000000041, 2.0000000000000013, -8.050000000000042, -225.13000000000017, -160.80999999999997, -6.040000000000042, -12.070000000000041, -20.109999999999705, 2.0000000000000013, -124.63000000000002, -110.55999999999997, -10.060000000000038, -16.0899999999997, -178.9000000000001, -184.9300000000001, -265.33000000000004, -245.23000000000002, -203.02000000000004, -321.61000000000007, -245.23000000000002, -261.31, -186.94, -329.65000000000003, -0.00999999999999836, -0.00999999999999836, -98.49999999999952, -257.2900000000001, -170.82000000000085, -317.5900000000001, -223.12000000000006, -305.5300000000003, -229.14999999999998, -323.58000000000004, -299.50000000000006, -46.24000000000029, -10.060000000000041, 2.0000000000000013, -34.18000000000006, -52.27000000000004, 2.0000000000000013, -16.089999999999705, -353.7700000000001, -8.050000000000042, -14.08000000000004, -10.060000000000041, -319.6000000000001, -287.44000000000005, -152.77, -148.75000000000006, -160.8100000000007, -199.00000000000003, -174.88000000000008, -10.060000000000041, -291.3, -323.58000000000004, -54.28000000000034, 2.0000000000000013, -180.9099999999999, -182.92000000000007, -297.49, -14.080000000000037, -114.58, -128.65000000000003, -8.050000000000042, -194.98000000000005, -291.46, -176.8900000000005, -285.4300000000002, -291.46000000000015, -213.07000000000002, -231.1599999999999, -309.55, -329.65000000000003, -10.060000000000041, -225.12999999999994, -207.04000000000008, -146.73999999999998, -255.28000000000014, -32.17000000000032, -311.5600000000001, -211.06, -259.30000000000007, -315.5800000000001, -178.9, -58.30000000000013, -297.45, -261.31000000000006, -128.64999999999986, -269.3500000000001, -36.18999999999986, -168.84999999999994, -271.35999999999996, -32.170000000000215, -373.8700000000001, -307.53999999999996, -186.94000000000003, -198.9999999999999, -86.43999999999954, -190.9599999999998, -188.94999999999993, -84.42999999999999, -16.089999999999996, -78.3999999999996, -28.14999999999971, -40.210000000000356, -6.040000000000042, -221.10999999999996, -30.159999999999727, -275.38000000000005, -205.03000000000003, -194.98, -285.43000000000006, -34.18000000000031, -303.52, -209.05, -241.2100000000001, 2.0000000000000013, -78.39999999999975, -24.12999999999983, -32.17000000000035, -285.4300000000003, -267.3400000000003, -211.0600000000002, -106.53999999999976, -180.91, -263.32000000000005, -295.48000000000013, -345.73000000000013, 2.0000000000000013, -309.55000000000007, -32.17000000000036, -30.159999999999712, -44.230000000000345], "policy_predator_policy_reward": [6.0, 135.0, 128.0, 126.0, 128.0, 130.0, 104.0, 4.0, 6.0, 5.0, 21.0, 119.0, 120.0, 143.0, 15.0, 92.0, 6.0, 7.0, 142.0, 105.0, 109.0, 148.0, 4.0, 3.0, 14.0, 111.0, 9.0, 4.0, 4.0, 5.0, 5.0, 2.0, 2.0, 124.0, 130.0, 17.0, 1.0, 6.0, 81.0, 78.0, 6.0, 11.0, 3.0, 164.0, 4.0, 85.0, 7.0, 129.0, 0.0, 113.0, 4.0, 105.0, 94.0, 112.0, 85.0, 0.0, 0.0, 94.0, 28.0, 124.0, 14.0, 14.0, 0.0, 8.0, 100.0, 155.0, 6.0, 5.0, 5.0, 3.0, 115.0, 0.0, 7.0, 4.0, 3.0, 11.0, 3.0, 69.0, 15.0, 5.0, 98.0, 2.0, 123.0, 61.0, 147.0, 140.0, 122.0, 40.0, 142.0, 109.0, 1.0, 1.0, 103.0, 119.0, 157.0, 147.0, 35.0, 154.0, 99.0, 151.0, 129.0, 129.0, 4.0, 5.0, 29.0, 3.0, 0.0, 9.0, 117.0, 145.0, 6.0, 10.0, 148.0, 111.0, 71.0, 69.0, 139.0, 5.0, 85.0, 9.0, 151.0, 155.0, 28.0, 16.0, 48.0, 92.0, 108.0, 123.0, 57.0, 37.0, 78.0, 71.0, 120.0, 129.0, 110.0, 121.0, 96.0, 109.0, 141.0, 152.0, 66.0, 92.0, 72.0, 96.0, 90.0, 110.0, 108.0, 130.0, 54.0, 156.0, 51.0, 96.0, 109.0, 131.0, 106.0, 110.0, 24.0, 100.0, 108.0, 116.0, 175.0, 171.0, 86.0, 81.0, 94.0, 52.0, 80.0, 68.0, 29.0, 42.0, 21.0, 17.0, 86.0, 94.0, 109.0, 119.0, 83.0, 95.0, 115.0, 121.0, 124.0, 124.0, 94.0, 99.0, 25.0, 43.0, 86.0, 132.0, 107.0, 146.0, 83.0, 67.0, 127.0, 112.0, 128.0, 139.0, 132.0, 147.0, 22.0, 23.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6053309445352264, "mean_inference_ms": 1.8981730911395902, "mean_action_processing_ms": 0.2587748209418054, "mean_env_wait_ms": 0.19629694824337393, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00396883487701416, "StateBufferConnector_ms": 0.0031255483627319336, "ViewRequirementAgentConnector_ms": 0.09425771236419678}, "num_episodes": 18, "episode_return_max": 2.949999999999982, "episode_return_min": -407.88000000000045, "episode_return_mean": -150.34340000000003, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 624000, "num_agent_steps_trained": 624000, "num_env_steps_sampled": 156000, "num_env_steps_trained": 156000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 364.5868648586662, "num_env_steps_trained_throughput_per_sec": 364.5868648586662, "timesteps_total": 156000, "num_env_steps_sampled_lifetime": 156000, "num_agent_steps_sampled_lifetime": 624000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 624000, "timers": {"training_iteration_time_ms": 10482.653, "restore_workers_time_ms": 0.013, "training_step_time_ms": 10482.615, "sample_time_ms": 1317.909, "learn_time_ms": 9148.998, "learn_throughput": 437.206, "synch_weights_time_ms": 14.336}, "counters": {"num_env_steps_sampled": 156000, "num_env_steps_trained": 156000, "num_agent_steps_sampled": 624000, "num_agent_steps_trained": 624000}, "done": false, "training_iteration": 39, "trial_id": "8e499_00000", "date": "2024-08-15_02-11-17", "timestamp": 1723668077, "time_this_iter_s": 10.976199865341187, "time_total_s": 417.5523874759674, "pid": 33199, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x15800f670>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 417.5523874759674, "iterations_since_restore": 39, "perf": {"cpu_util_percent": 32.63125, "ram_util_percent": 83.38125}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.771163823711809, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.141405906879083, "policy_loss": -0.0030177386285411933, "vf_loss": 9.143533051707758, "vf_explained_var": -0.056088158409431495, "kl": 0.00791624384685158, "entropy": 0.7578782712340986, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 74655.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.112709796523291, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.4822584497865545, "policy_loss": -0.014806313488494467, "vf_loss": 5.494873932429722, "vf_explained_var": 0.1254648940273063, "kl": 0.02190836741978192, "entropy": 0.9634146749657929, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 74655.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 160000, "num_env_steps_trained": 160000, "num_agent_steps_sampled": 640000, "num_agent_steps_trained": 640000}, "env_runners": {"episode_reward_max": 1.980000000000003, "episode_reward_min": -398.2700000000001, "episode_reward_mean": -145.82430000000005, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -375.88000000000005, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 2.0000000000000013, "predator_policy": 175.0}, "policy_reward_mean": {"prey_policy": -156.65715000000003, "predator_policy": 83.745}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-188.40000000000015, -298.18000000000023, -110.12999999999964, -106.08999999999975, -63.36000000000017, -81.84999999999991, -267.82000000000045, -149.5199999999991, -2.1700000000000808, -4.080000000000084, -398.2700000000001, -3.0900000000000833, 1.9500000000000028, -270.9400000000003, -7.110000000000083, -4.110000000000083, -163.19000000000005, -6.15000000000008, -263.8300000000002, -326.5600000000003, -237.63000000000008, -344.54000000000013, -265.5900000000001, 1.980000000000003, -133.78999999999996, -184.41000000000093, -339.6500000000004, -302.73000000000013, -87.73999999999954, 0.9399999999999819, -54.450000000000095, -5.090000000000083, -99.8199999999997, -8.14000000000008, -348.0400000000002, -161.52000000000004, -215.81000000000085, -90.93999999999986, -308.88, -8.280000000000078, -223.83000000000013, -80.56999999999992, -149.23000000000008, -54.03000000000008, -219.35000000000048, -345.8900000000002, -239.23000000000008, -346.2000000000001, -77.18999999999984, -185.7800000000001, -87.44999999999959, -284.62000000000006, -364.8800000000003, -90.19999999999979, -318.7600000000001, -182.00000000000006, -81.03999999999984, -79.52999999999975, -335.41, -218.93999999999994, -131.40000000000055, -125.37999999999988, -23.489999999999707, -30.36000000000012, -47.150000000000134, -77.53999999999989, -222.01000000000005, -83.6099999999996, -264.5700000000001, -46.21000000000001, -34.5299999999998, -99.59999999999918, -225.40000000000032, -137.44999999999996, -319.80000000000007, -76.72999999999983, -62.72000000000014, -29.389999999999784, -250.57000000000022, -92.30999999999904, -395.63000000000017, -54.60000000000013, -135.85999999999967, -0.09000000000003744, -194.41000000000014, -25.8299999999997, -50.93000000000024, -258.60000000000014, 1.980000000000003, -15.189999999999682, -131.85999999999996, -50.62999999999987, -146.97000000000173, -39.130000000000074, -69.71000000000015, -214.41000000000102, -242.92000000000084, -169.11, -69.46000000000004, -67.68999999999998], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-166.84000000000003, -110.55999999999999, -194.97999999999985, -239.20000000000022, -211.06000000000006, -12.070000000000041, -196.98999999999995, -18.099999999999703, -10.060000000000041, -259.3000000000001, -12.070000000000041, -154.78000000000003, -184.93000000000015, -176.89000000000004, -203.02000000000015, -98.49999999999923, -32.170000000000364, 2.0000000000000013, -14.080000000000041, 2.0000000000000013, -329.65000000000003, -323.62000000000006, -4.030000000000042, -10.060000000000041, 2.0000000000000013, -8.050000000000042, -225.13000000000017, -160.80999999999997, -6.040000000000042, -12.070000000000041, -20.109999999999705, 2.0000000000000013, -124.63000000000002, -110.55999999999997, -10.060000000000038, -16.0899999999997, -178.9000000000001, -184.9300000000001, -265.33000000000004, -245.23000000000002, -203.02000000000004, -321.61000000000007, -245.23000000000002, -261.31, -186.94, -329.65000000000003, -0.00999999999999836, -0.00999999999999836, -98.49999999999952, -257.2900000000001, -170.82000000000085, -317.5900000000001, -223.12000000000006, -305.5300000000003, -229.14999999999998, -323.58000000000004, -299.50000000000006, -46.24000000000029, -10.060000000000041, 2.0000000000000013, -34.18000000000006, -52.27000000000004, 2.0000000000000013, -16.089999999999705, -353.7700000000001, -8.050000000000042, -14.08000000000004, -10.060000000000041, -319.6000000000001, -287.44000000000005, -152.77, -148.75000000000006, -160.8100000000007, -199.00000000000003, -174.88000000000008, -10.060000000000041, -291.3, -323.58000000000004, -54.28000000000034, 2.0000000000000013, -180.9099999999999, -182.92000000000007, -297.49, -14.080000000000037, -114.58, -128.65000000000003, -8.050000000000042, -194.98000000000005, -291.46, -176.8900000000005, -285.4300000000002, -291.46000000000015, -213.07000000000002, -231.1599999999999, -309.55, -329.65000000000003, -10.060000000000041, -225.12999999999994, -207.04000000000008, -146.73999999999998, -255.28000000000014, -32.17000000000032, -311.5600000000001, -211.06, -259.30000000000007, -315.5800000000001, -178.9, -58.30000000000013, -297.45, -261.31000000000006, -128.64999999999986, -269.3500000000001, -36.18999999999986, -168.84999999999994, -271.35999999999996, -32.170000000000215, -373.8700000000001, -307.53999999999996, -186.94000000000003, -198.9999999999999, -86.43999999999954, -190.9599999999998, -188.94999999999993, -84.42999999999999, -16.089999999999996, -78.3999999999996, -28.14999999999971, -40.210000000000356, -6.040000000000042, -221.10999999999996, -30.159999999999727, -275.38000000000005, -205.03000000000003, -194.98, -285.43000000000006, -34.18000000000031, -303.52, -209.05, -241.2100000000001, 2.0000000000000013, -78.39999999999975, -24.12999999999983, -32.17000000000035, -285.4300000000003, -267.3400000000003, -211.0600000000002, -106.53999999999976, -180.91, -263.32000000000005, -295.48000000000013, -345.73000000000013, 2.0000000000000013, -309.55000000000007, -32.17000000000036, -30.159999999999712, -44.230000000000345, -237.19000000000017, -275.3800000000001, -164.82999999999964, -94.4799999999994, -369.8500000000001, -355.7800000000001, -4.030000000000042, -313.57, -118.59999999999945, -251.26, -16.089999999999716, 2.0000000000000013, -140.67000000000007, -347.74000000000007, -154.78000000000065, -8.050000000000042, -170.8600000000003, -12.070000000000038, -271.36, -247.24000000000007, 2.0000000000000013, -2.020000000000042, -6.040000000000042, -28.14999999999976, -233.17000000000002, -136.69000000000062, -114.58000000000006, -8.050000000000042, -132.6300000000012, -267.3400000000006, -217.08999999999995, -6.040000000000042, -319.6, -20.109999999999705, -245.19000000000068, -243.22000000000034, -207.04000000000076, -375.88000000000005, -235.18000000000012, -184.93, -8.050000000000042, -281.4100000000003, -305.5300000000001, -30.159999999999716], "policy_predator_policy_reward": [4.0, 85.0, 7.0, 129.0, 0.0, 113.0, 4.0, 105.0, 94.0, 112.0, 85.0, 0.0, 0.0, 94.0, 28.0, 124.0, 14.0, 14.0, 0.0, 8.0, 100.0, 155.0, 6.0, 5.0, 5.0, 3.0, 115.0, 0.0, 7.0, 4.0, 3.0, 11.0, 3.0, 69.0, 15.0, 5.0, 98.0, 2.0, 123.0, 61.0, 147.0, 140.0, 122.0, 40.0, 142.0, 109.0, 1.0, 1.0, 103.0, 119.0, 157.0, 147.0, 35.0, 154.0, 99.0, 151.0, 129.0, 129.0, 4.0, 5.0, 29.0, 3.0, 0.0, 9.0, 117.0, 145.0, 6.0, 10.0, 148.0, 111.0, 71.0, 69.0, 139.0, 5.0, 85.0, 9.0, 151.0, 155.0, 28.0, 16.0, 48.0, 92.0, 108.0, 123.0, 57.0, 37.0, 78.0, 71.0, 120.0, 129.0, 110.0, 121.0, 96.0, 109.0, 141.0, 152.0, 66.0, 92.0, 72.0, 96.0, 90.0, 110.0, 108.0, 130.0, 54.0, 156.0, 51.0, 96.0, 109.0, 131.0, 106.0, 110.0, 24.0, 100.0, 108.0, 116.0, 175.0, 171.0, 86.0, 81.0, 94.0, 52.0, 80.0, 68.0, 29.0, 42.0, 21.0, 17.0, 86.0, 94.0, 109.0, 119.0, 83.0, 95.0, 115.0, 121.0, 124.0, 124.0, 94.0, 99.0, 25.0, 43.0, 86.0, 132.0, 107.0, 146.0, 83.0, 67.0, 127.0, 112.0, 128.0, 139.0, 132.0, 147.0, 22.0, 23.0, 136.0, 126.0, 80.0, 87.0, 155.0, 175.0, 133.0, 130.0, 115.0, 119.0, 7.0, 7.0, 141.0, 153.0, 62.0, 75.0, 65.0, 67.0, 128.0, 132.0, 2.0, 0.0, 0.0, 19.0, 114.0, 124.0, 42.0, 30.0, 126.0, 127.0, 91.0, 93.0, 126.0, 144.0, 139.0, 135.0, 170.0, 170.0, 127.0, 124.0, 113.0, 107.0, 142.0, 126.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6041466039689459, "mean_inference_ms": 1.8961750342229977, "mean_action_processing_ms": 0.25733953830564354, "mean_env_wait_ms": 0.19620537293543197, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003942608833312988, "StateBufferConnector_ms": 0.0031450986862182617, "ViewRequirementAgentConnector_ms": 0.09508252143859863}, "num_episodes": 22, "episode_return_max": 1.980000000000003, "episode_return_min": -398.2700000000001, "episode_return_mean": -145.82430000000005, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 640000, "num_agent_steps_trained": 640000, "num_env_steps_sampled": 160000, "num_env_steps_trained": 160000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 387.9758496525872, "num_env_steps_trained_throughput_per_sec": 387.9758496525872, "timesteps_total": 160000, "num_env_steps_sampled_lifetime": 160000, "num_agent_steps_sampled_lifetime": 640000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 640000, "timers": {"training_iteration_time_ms": 10509.789, "restore_workers_time_ms": 0.013, "training_step_time_ms": 10509.752, "sample_time_ms": 1313.16, "learn_time_ms": 9180.726, "learn_throughput": 435.695, "synch_weights_time_ms": 14.502}, "counters": {"num_env_steps_sampled": 160000, "num_env_steps_trained": 160000, "num_agent_steps_sampled": 640000, "num_agent_steps_trained": 640000}, "done": false, "training_iteration": 40, "trial_id": "8e499_00000", "date": "2024-08-15_02-11-27", "timestamp": 1723668087, "time_this_iter_s": 10.315738916397095, "time_total_s": 427.8681263923645, "pid": 33199, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b43f0af0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 427.8681263923645, "iterations_since_restore": 40, "perf": {"cpu_util_percent": 27.906666666666663, "ram_util_percent": 82.81333333333332}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.2347360997288317, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.675594572541575, "policy_loss": -0.0006895159847945684, "vf_loss": 8.674996597047835, "vf_explained_var": -0.19291245416989403, "kl": 0.011444346618394404, "entropy": 0.7560434293179285, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 76545.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.369425622212193, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.4188700812203545, "policy_loss": -0.00904245995288153, "vf_loss": 3.426562651124581, "vf_explained_var": 0.1353952001642298, "kl": 0.008999212730834523, "entropy": 0.896328831570489, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 76545.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 164000, "num_env_steps_trained": 164000, "num_agent_steps_sampled": 656000, "num_agent_steps_trained": 656000}, "env_runners": {"episode_reward_max": 1.980000000000003, "episode_reward_min": -395.63000000000017, "episode_reward_mean": -119.91740000000003, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -375.88000000000005, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 2.0000000000000013, "predator_policy": 175.0}, "policy_reward_mean": {"prey_policy": -139.92370000000003, "predator_policy": 79.965}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.980000000000003, -133.78999999999996, -184.41000000000093, -339.6500000000004, -302.73000000000013, -87.73999999999954, 0.9399999999999819, -54.450000000000095, -5.090000000000083, -99.8199999999997, -8.14000000000008, -348.0400000000002, -161.52000000000004, -215.81000000000085, -90.93999999999986, -308.88, -8.280000000000078, -223.83000000000013, -80.56999999999992, -149.23000000000008, -54.03000000000008, -219.35000000000048, -345.8900000000002, -239.23000000000008, -346.2000000000001, -77.18999999999984, -185.7800000000001, -87.44999999999959, -284.62000000000006, -364.8800000000003, -90.19999999999979, -318.7600000000001, -182.00000000000006, -81.03999999999984, -79.52999999999975, -335.41, -218.93999999999994, -131.40000000000055, -125.37999999999988, -23.489999999999707, -30.36000000000012, -47.150000000000134, -77.53999999999989, -222.01000000000005, -83.6099999999996, -264.5700000000001, -46.21000000000001, -34.5299999999998, -99.59999999999918, -225.40000000000032, -137.44999999999996, -319.80000000000007, -76.72999999999983, -62.72000000000014, -29.389999999999784, -250.57000000000022, -92.30999999999904, -395.63000000000017, -54.60000000000013, -135.85999999999967, -0.09000000000003744, -194.41000000000014, -25.8299999999997, -50.93000000000024, -258.60000000000014, 1.980000000000003, -15.189999999999682, -131.85999999999996, -50.62999999999987, -146.97000000000173, -39.130000000000074, -69.71000000000015, -214.41000000000102, -242.92000000000084, -169.11, -69.46000000000004, -67.68999999999998, -9.240000000000078, -30.619999999999386, -32.40000000000055, -53.570000000000675, -6.17000000000008, -3.070000000000065, -0.17999999999999705, -6.100000000000083, -34.910000000000046, -10.250000000000064, -35.91000000000032, -31.569999999999965, -13.210000000000077, -24.390000000000008, -154.11000000000092, -21.319999999999943, -37.48999999999974, -327.2000000000002, -22.25999999999942, -14.159999999999732, -28.8199999999999, -65.85999999999954, -7.16000000000008], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-0.00999999999999836, -0.00999999999999836, -98.49999999999952, -257.2900000000001, -170.82000000000085, -317.5900000000001, -223.12000000000006, -305.5300000000003, -229.14999999999998, -323.58000000000004, -299.50000000000006, -46.24000000000029, -10.060000000000041, 2.0000000000000013, -34.18000000000006, -52.27000000000004, 2.0000000000000013, -16.089999999999705, -353.7700000000001, -8.050000000000042, -14.08000000000004, -10.060000000000041, -319.6000000000001, -287.44000000000005, -152.77, -148.75000000000006, -160.8100000000007, -199.00000000000003, -174.88000000000008, -10.060000000000041, -291.3, -323.58000000000004, -54.28000000000034, 2.0000000000000013, -180.9099999999999, -182.92000000000007, -297.49, -14.080000000000037, -114.58, -128.65000000000003, -8.050000000000042, -194.98000000000005, -291.46, -176.8900000000005, -285.4300000000002, -291.46000000000015, -213.07000000000002, -231.1599999999999, -309.55, -329.65000000000003, -10.060000000000041, -225.12999999999994, -207.04000000000008, -146.73999999999998, -255.28000000000014, -32.17000000000032, -311.5600000000001, -211.06, -259.30000000000007, -315.5800000000001, -178.9, -58.30000000000013, -297.45, -261.31000000000006, -128.64999999999986, -269.3500000000001, -36.18999999999986, -168.84999999999994, -271.35999999999996, -32.170000000000215, -373.8700000000001, -307.53999999999996, -186.94000000000003, -198.9999999999999, -86.43999999999954, -190.9599999999998, -188.94999999999993, -84.42999999999999, -16.089999999999996, -78.3999999999996, -28.14999999999971, -40.210000000000356, -6.040000000000042, -221.10999999999996, -30.159999999999727, -275.38000000000005, -205.03000000000003, -194.98, -285.43000000000006, -34.18000000000031, -303.52, -209.05, -241.2100000000001, 2.0000000000000013, -78.39999999999975, -24.12999999999983, -32.17000000000035, -285.4300000000003, -267.3400000000003, -211.0600000000002, -106.53999999999976, -180.91, -263.32000000000005, -295.48000000000013, -345.73000000000013, 2.0000000000000013, -309.55000000000007, -32.17000000000036, -30.159999999999712, -44.230000000000345, -237.19000000000017, -275.3800000000001, -164.82999999999964, -94.4799999999994, -369.8500000000001, -355.7800000000001, -4.030000000000042, -313.57, -118.59999999999945, -251.26, -16.089999999999716, 2.0000000000000013, -140.67000000000007, -347.74000000000007, -154.78000000000065, -8.050000000000042, -170.8600000000003, -12.070000000000038, -271.36, -247.24000000000007, 2.0000000000000013, -2.020000000000042, -6.040000000000042, -28.14999999999976, -233.17000000000002, -136.69000000000062, -114.58000000000006, -8.050000000000042, -132.6300000000012, -267.3400000000006, -217.08999999999995, -6.040000000000042, -319.6, -20.109999999999705, -245.19000000000068, -243.22000000000034, -207.04000000000076, -375.88000000000005, -235.18000000000012, -184.93, -8.050000000000042, -281.4100000000003, -305.5300000000001, -30.159999999999716, 2.0000000000000013, -46.23999999999996, -14.080000000000041, -106.53999999999932, 2.0000000000000013, -78.39999999999924, -76.38999999999918, -34.180000000000234, -4.030000000000035, -26.139999999999716, -12.070000000000041, 2.0000000000000013, -30.159999999999712, -2.020000000000004, -4.030000000000042, -12.070000000000041, -176.89000000000004, -2.020000000000042, 2.0000000000000013, -48.24999999999981, -0.00999999999999836, -178.90000000000072, -10.060000000000034, -100.5099999999998, -22.119999999999944, -16.0899999999997, -68.34999999999992, -6.040000000000042, -215.0400000000007, -213.07000000000022, -38.19999999999994, -22.119999999999706, -64.32999999999919, -30.159999999999986, -293.47000000000014, -345.73000000000013, -14.080000000000041, -34.18000000000027, -18.099999999999703, -10.060000000000041, -6.040000000000042, -154.7800000000002, -108.55000000000008, -60.309999999999775, -18.10000000000001, -10.060000000000038], "policy_predator_policy_reward": [1.0, 1.0, 103.0, 119.0, 157.0, 147.0, 35.0, 154.0, 99.0, 151.0, 129.0, 129.0, 4.0, 5.0, 29.0, 3.0, 0.0, 9.0, 117.0, 145.0, 6.0, 10.0, 148.0, 111.0, 71.0, 69.0, 139.0, 5.0, 85.0, 9.0, 151.0, 155.0, 28.0, 16.0, 48.0, 92.0, 108.0, 123.0, 57.0, 37.0, 78.0, 71.0, 120.0, 129.0, 110.0, 121.0, 96.0, 109.0, 141.0, 152.0, 66.0, 92.0, 72.0, 96.0, 90.0, 110.0, 108.0, 130.0, 54.0, 156.0, 51.0, 96.0, 109.0, 131.0, 106.0, 110.0, 24.0, 100.0, 108.0, 116.0, 175.0, 171.0, 86.0, 81.0, 94.0, 52.0, 80.0, 68.0, 29.0, 42.0, 21.0, 17.0, 86.0, 94.0, 109.0, 119.0, 83.0, 95.0, 115.0, 121.0, 124.0, 124.0, 94.0, 99.0, 25.0, 43.0, 86.0, 132.0, 107.0, 146.0, 83.0, 67.0, 127.0, 112.0, 128.0, 139.0, 132.0, 147.0, 22.0, 23.0, 136.0, 126.0, 80.0, 87.0, 155.0, 175.0, 133.0, 130.0, 115.0, 119.0, 7.0, 7.0, 141.0, 153.0, 62.0, 75.0, 65.0, 67.0, 128.0, 132.0, 2.0, 0.0, 0.0, 19.0, 114.0, 124.0, 42.0, 30.0, 126.0, 127.0, 91.0, 93.0, 126.0, 144.0, 139.0, 135.0, 170.0, 170.0, 127.0, 124.0, 113.0, 107.0, 142.0, 126.0, 18.0, 17.0, 40.0, 50.0, 6.0, 38.0, 39.0, 18.0, 9.0, 15.0, 0.0, 7.0, 16.0, 16.0, 4.0, 6.0, 74.0, 70.0, 17.0, 19.0, 70.0, 73.0, 36.0, 43.0, 12.0, 13.0, 25.0, 25.0, 133.0, 141.0, 15.0, 24.0, 39.0, 18.0, 168.0, 144.0, 10.0, 16.0, 10.0, 4.0, 67.0, 65.0, 60.0, 43.0, 14.0, 7.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6037126812420165, "mean_inference_ms": 1.8948262327141696, "mean_action_processing_ms": 0.2577473557903923, "mean_env_wait_ms": 0.1963509564603421, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003952145576477051, "StateBufferConnector_ms": 0.0031409263610839844, "ViewRequirementAgentConnector_ms": 0.0943608283996582}, "num_episodes": 23, "episode_return_max": 1.980000000000003, "episode_return_min": -395.63000000000017, "episode_return_mean": -119.91740000000003, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 656000, "num_agent_steps_trained": 656000, "num_env_steps_sampled": 164000, "num_env_steps_trained": 164000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 391.46071766656485, "num_env_steps_trained_throughput_per_sec": 391.46071766656485, "timesteps_total": 164000, "num_env_steps_sampled_lifetime": 164000, "num_agent_steps_sampled_lifetime": 656000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 656000, "timers": {"training_iteration_time_ms": 10518.844, "restore_workers_time_ms": 0.013, "training_step_time_ms": 10518.807, "sample_time_ms": 1319.311, "learn_time_ms": 9183.679, "learn_throughput": 435.555, "synch_weights_time_ms": 14.537}, "counters": {"num_env_steps_sampled": 164000, "num_env_steps_trained": 164000, "num_agent_steps_sampled": 656000, "num_agent_steps_trained": 656000}, "done": false, "training_iteration": 41, "trial_id": "8e499_00000", "date": "2024-08-15_02-11-38", "timestamp": 1723668098, "time_this_iter_s": 10.22364091873169, "time_total_s": 438.0917673110962, "pid": 33199, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x158036040>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 438.0917673110962, "iterations_since_restore": 41, "perf": {"cpu_util_percent": 27.828571428571426, "ram_util_percent": 82.56428571428572}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.4167347377570216, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.4216361113957, "policy_loss": -0.0037517369388499196, "vf_loss": 8.42457571761318, "vf_explained_var": -0.42698374400063166, "kl": 0.007219043230074859, "entropy": 0.7300960353127233, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 78435.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4375083602925458, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.4916619996860545, "policy_loss": -0.012773064528370187, "vf_loss": 1.5025234333737187, "vf_explained_var": 0.12365505846719893, "kl": 0.012744223454882067, "entropy": 0.9244025052855255, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 78435.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 168000, "num_env_steps_trained": 168000, "num_agent_steps_sampled": 672000, "num_agent_steps_trained": 672000}, "env_runners": {"episode_reward_max": 2.989999999999981, "episode_reward_min": -395.63000000000017, "episode_reward_mean": -96.74290000000002, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -375.88000000000005, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 2.0000000000000013, "predator_policy": 175.0}, "policy_reward_mean": {"prey_policy": -118.08645000000004, "predator_policy": 69.715}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-80.56999999999992, -149.23000000000008, -54.03000000000008, -219.35000000000048, -345.8900000000002, -239.23000000000008, -346.2000000000001, -77.18999999999984, -185.7800000000001, -87.44999999999959, -284.62000000000006, -364.8800000000003, -90.19999999999979, -318.7600000000001, -182.00000000000006, -81.03999999999984, -79.52999999999975, -335.41, -218.93999999999994, -131.40000000000055, -125.37999999999988, -23.489999999999707, -30.36000000000012, -47.150000000000134, -77.53999999999989, -222.01000000000005, -83.6099999999996, -264.5700000000001, -46.21000000000001, -34.5299999999998, -99.59999999999918, -225.40000000000032, -137.44999999999996, -319.80000000000007, -76.72999999999983, -62.72000000000014, -29.389999999999784, -250.57000000000022, -92.30999999999904, -395.63000000000017, -54.60000000000013, -135.85999999999967, -0.09000000000003744, -194.41000000000014, -25.8299999999997, -50.93000000000024, -258.60000000000014, 1.980000000000003, -15.189999999999682, -131.85999999999996, -50.62999999999987, -146.97000000000173, -39.130000000000074, -69.71000000000015, -214.41000000000102, -242.92000000000084, -169.11, -69.46000000000004, -67.68999999999998, -9.240000000000078, -30.619999999999386, -32.40000000000055, -53.570000000000675, -6.17000000000008, -3.070000000000065, -0.17999999999999705, -6.100000000000083, -34.910000000000046, -10.250000000000064, -35.91000000000032, -31.569999999999965, -13.210000000000077, -24.390000000000008, -154.11000000000092, -21.319999999999943, -37.48999999999974, -327.2000000000002, -22.25999999999942, -14.159999999999732, -28.8199999999999, -65.85999999999954, -7.16000000000008, -32.360000000000554, 1.9800000000000026, -24.2799999999995, -40.520000000000664, -8.120000000000083, -4.090000000000083, 0.7599999999999861, -1.050000000000063, -27.92999999999975, -47.55000000000062, -28.629999999999427, 0.9299999999999818, 2.989999999999981, 1.900000000000003, -0.08000000000003922, -4.110000000000082, -20.29999999999965, -22.289999999999907], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-297.49, -14.080000000000037, -114.58, -128.65000000000003, -8.050000000000042, -194.98000000000005, -291.46, -176.8900000000005, -285.4300000000002, -291.46000000000015, -213.07000000000002, -231.1599999999999, -309.55, -329.65000000000003, -10.060000000000041, -225.12999999999994, -207.04000000000008, -146.73999999999998, -255.28000000000014, -32.17000000000032, -311.5600000000001, -211.06, -259.30000000000007, -315.5800000000001, -178.9, -58.30000000000013, -297.45, -261.31000000000006, -128.64999999999986, -269.3500000000001, -36.18999999999986, -168.84999999999994, -271.35999999999996, -32.170000000000215, -373.8700000000001, -307.53999999999996, -186.94000000000003, -198.9999999999999, -86.43999999999954, -190.9599999999998, -188.94999999999993, -84.42999999999999, -16.089999999999996, -78.3999999999996, -28.14999999999971, -40.210000000000356, -6.040000000000042, -221.10999999999996, -30.159999999999727, -275.38000000000005, -205.03000000000003, -194.98, -285.43000000000006, -34.18000000000031, -303.52, -209.05, -241.2100000000001, 2.0000000000000013, -78.39999999999975, -24.12999999999983, -32.17000000000035, -285.4300000000003, -267.3400000000003, -211.0600000000002, -106.53999999999976, -180.91, -263.32000000000005, -295.48000000000013, -345.73000000000013, 2.0000000000000013, -309.55000000000007, -32.17000000000036, -30.159999999999712, -44.230000000000345, -237.19000000000017, -275.3800000000001, -164.82999999999964, -94.4799999999994, -369.8500000000001, -355.7800000000001, -4.030000000000042, -313.57, -118.59999999999945, -251.26, -16.089999999999716, 2.0000000000000013, -140.67000000000007, -347.74000000000007, -154.78000000000065, -8.050000000000042, -170.8600000000003, -12.070000000000038, -271.36, -247.24000000000007, 2.0000000000000013, -2.020000000000042, -6.040000000000042, -28.14999999999976, -233.17000000000002, -136.69000000000062, -114.58000000000006, -8.050000000000042, -132.6300000000012, -267.3400000000006, -217.08999999999995, -6.040000000000042, -319.6, -20.109999999999705, -245.19000000000068, -243.22000000000034, -207.04000000000076, -375.88000000000005, -235.18000000000012, -184.93, -8.050000000000042, -281.4100000000003, -305.5300000000001, -30.159999999999716, 2.0000000000000013, -46.23999999999996, -14.080000000000041, -106.53999999999932, 2.0000000000000013, -78.39999999999924, -76.38999999999918, -34.180000000000234, -4.030000000000035, -26.139999999999716, -12.070000000000041, 2.0000000000000013, -30.159999999999712, -2.020000000000004, -4.030000000000042, -12.070000000000041, -176.89000000000004, -2.020000000000042, 2.0000000000000013, -48.24999999999981, -0.00999999999999836, -178.90000000000072, -10.060000000000034, -100.5099999999998, -22.119999999999944, -16.0899999999997, -68.34999999999992, -6.040000000000042, -215.0400000000007, -213.07000000000022, -38.19999999999994, -22.119999999999706, -64.32999999999919, -30.159999999999986, -293.47000000000014, -345.73000000000013, -14.080000000000041, -34.18000000000027, -18.099999999999703, -10.060000000000041, -6.040000000000042, -154.7800000000002, -108.55000000000008, -60.309999999999775, -18.10000000000001, -10.060000000000038, -26.13999999999971, -42.22000000000031, -2.020000000000042, 2.0000000000000013, -2.020000000000042, -50.26000000000031, -50.2600000000003, -50.260000000000346, -14.080000000000041, -6.040000000000042, -6.040000000000042, -8.050000000000042, 2.0000000000000013, -46.240000000000336, -0.00999999999999836, -6.040000000000042, -184.9300000000005, 2.0000000000000013, -24.129999999999797, -82.41999999999919, -10.060000000000041, -112.56999999999928, 2.0000000000000013, -12.070000000000041, -0.00999999999999836, 2.0000000000000013, 2.0000000000000013, -18.09999999999986, 2.0000000000000013, -14.080000000000041, -18.099999999999703, -0.009999999999998581, 2.0000000000000013, -58.30000000000022, -18.09999999999971, -36.18999999999994], "policy_predator_policy_reward": [108.0, 123.0, 57.0, 37.0, 78.0, 71.0, 120.0, 129.0, 110.0, 121.0, 96.0, 109.0, 141.0, 152.0, 66.0, 92.0, 72.0, 96.0, 90.0, 110.0, 108.0, 130.0, 54.0, 156.0, 51.0, 96.0, 109.0, 131.0, 106.0, 110.0, 24.0, 100.0, 108.0, 116.0, 175.0, 171.0, 86.0, 81.0, 94.0, 52.0, 80.0, 68.0, 29.0, 42.0, 21.0, 17.0, 86.0, 94.0, 109.0, 119.0, 83.0, 95.0, 115.0, 121.0, 124.0, 124.0, 94.0, 99.0, 25.0, 43.0, 86.0, 132.0, 107.0, 146.0, 83.0, 67.0, 127.0, 112.0, 128.0, 139.0, 132.0, 147.0, 22.0, 23.0, 136.0, 126.0, 80.0, 87.0, 155.0, 175.0, 133.0, 130.0, 115.0, 119.0, 7.0, 7.0, 141.0, 153.0, 62.0, 75.0, 65.0, 67.0, 128.0, 132.0, 2.0, 0.0, 0.0, 19.0, 114.0, 124.0, 42.0, 30.0, 126.0, 127.0, 91.0, 93.0, 126.0, 144.0, 139.0, 135.0, 170.0, 170.0, 127.0, 124.0, 113.0, 107.0, 142.0, 126.0, 18.0, 17.0, 40.0, 50.0, 6.0, 38.0, 39.0, 18.0, 9.0, 15.0, 0.0, 7.0, 16.0, 16.0, 4.0, 6.0, 74.0, 70.0, 17.0, 19.0, 70.0, 73.0, 36.0, 43.0, 12.0, 13.0, 25.0, 25.0, 133.0, 141.0, 15.0, 24.0, 39.0, 18.0, 168.0, 144.0, 10.0, 16.0, 10.0, 4.0, 67.0, 65.0, 60.0, 43.0, 14.0, 7.0, 17.0, 19.0, 2.0, 0.0, 27.0, 1.0, 44.0, 16.0, 8.0, 4.0, 5.0, 5.0, 21.0, 24.0, 1.0, 4.0, 79.0, 76.0, 41.0, 18.0, 51.0, 43.0, 4.0, 7.0, 0.0, 1.0, 10.0, 8.0, 8.0, 4.0, 11.0, 3.0, 18.0, 18.0, 21.0, 11.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6025022872897496, "mean_inference_ms": 1.8934515668520655, "mean_action_processing_ms": 0.25690014909668824, "mean_env_wait_ms": 0.19619475755821614, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0037897825241088867, "StateBufferConnector_ms": 0.003100872039794922, "ViewRequirementAgentConnector_ms": 0.0943368673324585}, "num_episodes": 18, "episode_return_max": 2.989999999999981, "episode_return_min": -395.63000000000017, "episode_return_mean": -96.74290000000002, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 672000, "num_agent_steps_trained": 672000, "num_env_steps_sampled": 168000, "num_env_steps_trained": 168000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 167.17417296806804, "num_env_steps_trained_throughput_per_sec": 167.17417296806804, "timesteps_total": 168000, "num_env_steps_sampled_lifetime": 168000, "num_agent_steps_sampled_lifetime": 672000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 672000, "timers": {"training_iteration_time_ms": 11833.467, "restore_workers_time_ms": 0.012, "training_step_time_ms": 11833.431, "sample_time_ms": 1310.983, "learn_time_ms": 10506.21, "learn_throughput": 380.727, "synch_weights_time_ms": 15.094}, "counters": {"num_env_steps_sampled": 168000, "num_env_steps_trained": 168000, "num_agent_steps_sampled": 672000, "num_agent_steps_trained": 672000}, "done": false, "training_iteration": 42, "trial_id": "8e499_00000", "date": "2024-08-15_02-12-02", "timestamp": 1723668122, "time_this_iter_s": 23.961770057678223, "time_total_s": 462.0535373687744, "pid": 33199, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x1580dd670>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 462.0535373687744, "iterations_since_restore": 42, "perf": {"cpu_util_percent": 44.383333333333326, "ram_util_percent": 83.27222222222223}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.0913988442963394, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.303762103893138, "policy_loss": -0.0001615706887884588, "vf_loss": 7.3030176321665445, "vf_explained_var": -0.06525744019992767, "kl": 0.008053716174199522, "entropy": 0.735826382245967, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 80325.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0959117109813388, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.6941753013799874, "policy_loss": -0.009708758729396673, "vf_loss": 0.7027651287792694, "vf_explained_var": 0.10932431776056845, "kl": 0.007459554042518776, "entropy": 0.7997627747752679, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 80325.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 172000, "num_env_steps_trained": 172000, "num_agent_steps_sampled": 688000, "num_agent_steps_trained": 688000}, "env_runners": {"episode_reward_max": 3.9999999999999587, "episode_reward_min": -395.63000000000017, "episode_reward_mean": -63.50060000000002, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -375.88000000000005, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 2.0000000000000013, "predator_policy": 175.0}, "policy_reward_mean": {"prey_policy": -84.65029999999999, "predator_policy": 52.9}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-218.93999999999994, -131.40000000000055, -125.37999999999988, -23.489999999999707, -30.36000000000012, -47.150000000000134, -77.53999999999989, -222.01000000000005, -83.6099999999996, -264.5700000000001, -46.21000000000001, -34.5299999999998, -99.59999999999918, -225.40000000000032, -137.44999999999996, -319.80000000000007, -76.72999999999983, -62.72000000000014, -29.389999999999784, -250.57000000000022, -92.30999999999904, -395.63000000000017, -54.60000000000013, -135.85999999999967, -0.09000000000003744, -194.41000000000014, -25.8299999999997, -50.93000000000024, -258.60000000000014, 1.980000000000003, -15.189999999999682, -131.85999999999996, -50.62999999999987, -146.97000000000173, -39.130000000000074, -69.71000000000015, -214.41000000000102, -242.92000000000084, -169.11, -69.46000000000004, -67.68999999999998, -9.240000000000078, -30.619999999999386, -32.40000000000055, -53.570000000000675, -6.17000000000008, -3.070000000000065, -0.17999999999999705, -6.100000000000083, -34.910000000000046, -10.250000000000064, -35.91000000000032, -31.569999999999965, -13.210000000000077, -24.390000000000008, -154.11000000000092, -21.319999999999943, -37.48999999999974, -327.2000000000002, -22.25999999999942, -14.159999999999732, -28.8199999999999, -65.85999999999954, -7.16000000000008, -32.360000000000554, 1.9800000000000026, -24.2799999999995, -40.520000000000664, -8.120000000000083, -4.090000000000083, 0.7599999999999861, -1.050000000000063, -27.92999999999975, -47.55000000000062, -28.629999999999427, 0.9299999999999818, 2.989999999999981, 1.900000000000003, -0.08000000000003922, -4.110000000000082, -20.29999999999965, -22.289999999999907, -28.35999999999948, -3.150000000000075, -57.53000000000069, -19.229999999999514, 0.9399999999999819, -22.259999999999476, 2.989999999999981, 3.9999999999999587, -20.249999999999552, -3.0900000000000825, -3.110000000000082, -3.210000000000081, -8.120000000000083, 1.880000000000003, -3.0700000000000633, -13.199999999999983, -14.219999999999919, -8.14000000000008], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-186.94000000000003, -198.9999999999999, -86.43999999999954, -190.9599999999998, -188.94999999999993, -84.42999999999999, -16.089999999999996, -78.3999999999996, -28.14999999999971, -40.210000000000356, -6.040000000000042, -221.10999999999996, -30.159999999999727, -275.38000000000005, -205.03000000000003, -194.98, -285.43000000000006, -34.18000000000031, -303.52, -209.05, -241.2100000000001, 2.0000000000000013, -78.39999999999975, -24.12999999999983, -32.17000000000035, -285.4300000000003, -267.3400000000003, -211.0600000000002, -106.53999999999976, -180.91, -263.32000000000005, -295.48000000000013, -345.73000000000013, 2.0000000000000013, -309.55000000000007, -32.17000000000036, -30.159999999999712, -44.230000000000345, -237.19000000000017, -275.3800000000001, -164.82999999999964, -94.4799999999994, -369.8500000000001, -355.7800000000001, -4.030000000000042, -313.57, -118.59999999999945, -251.26, -16.089999999999716, 2.0000000000000013, -140.67000000000007, -347.74000000000007, -154.78000000000065, -8.050000000000042, -170.8600000000003, -12.070000000000038, -271.36, -247.24000000000007, 2.0000000000000013, -2.020000000000042, -6.040000000000042, -28.14999999999976, -233.17000000000002, -136.69000000000062, -114.58000000000006, -8.050000000000042, -132.6300000000012, -267.3400000000006, -217.08999999999995, -6.040000000000042, -319.6, -20.109999999999705, -245.19000000000068, -243.22000000000034, -207.04000000000076, -375.88000000000005, -235.18000000000012, -184.93, -8.050000000000042, -281.4100000000003, -305.5300000000001, -30.159999999999716, 2.0000000000000013, -46.23999999999996, -14.080000000000041, -106.53999999999932, 2.0000000000000013, -78.39999999999924, -76.38999999999918, -34.180000000000234, -4.030000000000035, -26.139999999999716, -12.070000000000041, 2.0000000000000013, -30.159999999999712, -2.020000000000004, -4.030000000000042, -12.070000000000041, -176.89000000000004, -2.020000000000042, 2.0000000000000013, -48.24999999999981, -0.00999999999999836, -178.90000000000072, -10.060000000000034, -100.5099999999998, -22.119999999999944, -16.0899999999997, -68.34999999999992, -6.040000000000042, -215.0400000000007, -213.07000000000022, -38.19999999999994, -22.119999999999706, -64.32999999999919, -30.159999999999986, -293.47000000000014, -345.73000000000013, -14.080000000000041, -34.18000000000027, -18.099999999999703, -10.060000000000041, -6.040000000000042, -154.7800000000002, -108.55000000000008, -60.309999999999775, -18.10000000000001, -10.060000000000038, -26.13999999999971, -42.22000000000031, -2.020000000000042, 2.0000000000000013, -2.020000000000042, -50.26000000000031, -50.2600000000003, -50.260000000000346, -14.080000000000041, -6.040000000000042, -6.040000000000042, -8.050000000000042, 2.0000000000000013, -46.240000000000336, -0.00999999999999836, -6.040000000000042, -184.9300000000005, 2.0000000000000013, -24.129999999999797, -82.41999999999919, -10.060000000000041, -112.56999999999928, 2.0000000000000013, -12.070000000000041, -0.00999999999999836, 2.0000000000000013, 2.0000000000000013, -18.09999999999986, 2.0000000000000013, -14.080000000000041, -18.099999999999703, -0.009999999999998581, 2.0000000000000013, -58.30000000000022, -18.09999999999971, -36.18999999999994, 2.0000000000000013, -70.35999999999918, -20.10999999999973, -6.040000000000042, -60.310000000000336, -42.220000000000354, -34.18000000000025, -8.050000000000042, 2.0000000000000013, -10.060000000000041, -4.030000000000042, -44.23000000000033, -0.00999999999999836, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, -46.24000000000024, -0.00999999999999836, 2.0000000000000013, -16.0899999999997, -2.0200000000000293, -16.0899999999997, -14.080000000000025, -24.129999999999708, -22.11999999999973, 2.0000000000000013, -22.119999999999706, 2.0000000000000013, -0.00999999999999836, -10.060000000000032, -18.099999999999707, -18.099999999999742, -24.129999999999793, -16.0899999999997, -26.13999999999972, 2.0000000000000013], "policy_predator_policy_reward": [86.0, 81.0, 94.0, 52.0, 80.0, 68.0, 29.0, 42.0, 21.0, 17.0, 86.0, 94.0, 109.0, 119.0, 83.0, 95.0, 115.0, 121.0, 124.0, 124.0, 94.0, 99.0, 25.0, 43.0, 86.0, 132.0, 107.0, 146.0, 83.0, 67.0, 127.0, 112.0, 128.0, 139.0, 132.0, 147.0, 22.0, 23.0, 136.0, 126.0, 80.0, 87.0, 155.0, 175.0, 133.0, 130.0, 115.0, 119.0, 7.0, 7.0, 141.0, 153.0, 62.0, 75.0, 65.0, 67.0, 128.0, 132.0, 2.0, 0.0, 0.0, 19.0, 114.0, 124.0, 42.0, 30.0, 126.0, 127.0, 91.0, 93.0, 126.0, 144.0, 139.0, 135.0, 170.0, 170.0, 127.0, 124.0, 113.0, 107.0, 142.0, 126.0, 18.0, 17.0, 40.0, 50.0, 6.0, 38.0, 39.0, 18.0, 9.0, 15.0, 0.0, 7.0, 16.0, 16.0, 4.0, 6.0, 74.0, 70.0, 17.0, 19.0, 70.0, 73.0, 36.0, 43.0, 12.0, 13.0, 25.0, 25.0, 133.0, 141.0, 15.0, 24.0, 39.0, 18.0, 168.0, 144.0, 10.0, 16.0, 10.0, 4.0, 67.0, 65.0, 60.0, 43.0, 14.0, 7.0, 17.0, 19.0, 2.0, 0.0, 27.0, 1.0, 44.0, 16.0, 8.0, 4.0, 5.0, 5.0, 21.0, 24.0, 1.0, 4.0, 79.0, 76.0, 41.0, 18.0, 51.0, 43.0, 4.0, 7.0, 0.0, 1.0, 10.0, 8.0, 8.0, 4.0, 11.0, 3.0, 18.0, 18.0, 21.0, 11.0, 35.0, 5.0, 14.0, 9.0, 31.0, 14.0, 16.0, 7.0, 3.0, 6.0, 22.0, 4.0, 0.0, 1.0, 0.0, 0.0, 13.0, 13.0, 2.0, 9.0, 4.0, 11.0, 17.0, 18.0, 8.0, 4.0, 12.0, 10.0, 6.0, 1.0, 8.0, 15.0, 16.0, 10.0, 2.0, 14.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6020962374293104, "mean_inference_ms": 1.8930559768362685, "mean_action_processing_ms": 0.2565200680262472, "mean_env_wait_ms": 0.19628495055914777, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004689335823059082, "StateBufferConnector_ms": 0.0032578706741333008, "ViewRequirementAgentConnector_ms": 0.10446929931640625}, "num_episodes": 18, "episode_return_max": 3.9999999999999587, "episode_return_min": -395.63000000000017, "episode_return_mean": -63.50060000000002, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 688000, "num_agent_steps_trained": 688000, "num_env_steps_sampled": 172000, "num_env_steps_trained": 172000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 344.4373408137227, "num_env_steps_trained_throughput_per_sec": 344.4373408137227, "timesteps_total": 172000, "num_env_steps_sampled_lifetime": 172000, "num_agent_steps_sampled_lifetime": 688000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 688000, "timers": {"training_iteration_time_ms": 11890.23, "restore_workers_time_ms": 0.012, "training_step_time_ms": 11890.194, "sample_time_ms": 1336.466, "learn_time_ms": 10536.902, "learn_throughput": 379.618, "synch_weights_time_ms": 15.42}, "counters": {"num_env_steps_sampled": 172000, "num_env_steps_trained": 172000, "num_agent_steps_sampled": 688000, "num_agent_steps_trained": 688000}, "done": false, "training_iteration": 43, "trial_id": "8e499_00000", "date": "2024-08-15_02-12-13", "timestamp": 1723668133, "time_this_iter_s": 11.659688949584961, "time_total_s": 473.7132263183594, "pid": 33199, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x1580dd5e0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 473.7132263183594, "iterations_since_restore": 43, "perf": {"cpu_util_percent": 48.77058823529412, "ram_util_percent": 83.02941176470588}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.9269517920635364, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.8156912861677705, "policy_loss": -0.0020856228131042034, "vf_loss": 3.8171983235727542, "vf_explained_var": 0.041267256604300605, "kl": 0.005143010100850256, "entropy": 0.7384387953886911, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 82215.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0778564320433708, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.5148144987822022, "policy_loss": -0.00949553130539479, "vf_loss": 0.523767405426593, "vf_explained_var": 0.12611697249942355, "kl": 0.0036174942375322063, "entropy": 0.7475687531251756, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 82215.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 176000, "num_env_steps_trained": 176000, "num_agent_steps_sampled": 704000, "num_agent_steps_trained": 704000}, "env_runners": {"episode_reward_max": 3.9999999999999587, "episode_reward_min": -395.63000000000017, "episode_reward_mean": -43.36159999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -375.88000000000005, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 2.0000000000000013, "predator_policy": 175.0}, "policy_reward_mean": {"prey_policy": -59.705799999999996, "predator_policy": 38.025}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-29.389999999999784, -250.57000000000022, -92.30999999999904, -395.63000000000017, -54.60000000000013, -135.85999999999967, -0.09000000000003744, -194.41000000000014, -25.8299999999997, -50.93000000000024, -258.60000000000014, 1.980000000000003, -15.189999999999682, -131.85999999999996, -50.62999999999987, -146.97000000000173, -39.130000000000074, -69.71000000000015, -214.41000000000102, -242.92000000000084, -169.11, -69.46000000000004, -67.68999999999998, -9.240000000000078, -30.619999999999386, -32.40000000000055, -53.570000000000675, -6.17000000000008, -3.070000000000065, -0.17999999999999705, -6.100000000000083, -34.910000000000046, -10.250000000000064, -35.91000000000032, -31.569999999999965, -13.210000000000077, -24.390000000000008, -154.11000000000092, -21.319999999999943, -37.48999999999974, -327.2000000000002, -22.25999999999942, -14.159999999999732, -28.8199999999999, -65.85999999999954, -7.16000000000008, -32.360000000000554, 1.9800000000000026, -24.2799999999995, -40.520000000000664, -8.120000000000083, -4.090000000000083, 0.7599999999999861, -1.050000000000063, -27.92999999999975, -47.55000000000062, -28.629999999999427, 0.9299999999999818, 2.989999999999981, 1.900000000000003, -0.08000000000003922, -4.110000000000082, -20.29999999999965, -22.289999999999907, -28.35999999999948, -3.150000000000075, -57.53000000000069, -19.229999999999514, 0.9399999999999819, -22.259999999999476, 2.989999999999981, 3.9999999999999587, -20.249999999999552, -3.0900000000000825, -3.110000000000082, -3.210000000000081, -8.120000000000083, 1.880000000000003, -3.0700000000000633, -13.199999999999983, -14.219999999999919, -8.14000000000008, -12.160000000000082, -9.130000000000082, -21.249999999999513, 2.9799999999999813, -66.49999999999822, -17.20999999999956, 3.9499999999999598, -1.0500000000000418, -6.110000000000081, -6.100000000000083, -25.289999999999424, 0.969999999999981, -7.140000000000068, -6.100000000000083, 0.9599999999999819, -25.489999999999526, -13.169999999999924, -5.150000000000082], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-30.159999999999712, -44.230000000000345, -237.19000000000017, -275.3800000000001, -164.82999999999964, -94.4799999999994, -369.8500000000001, -355.7800000000001, -4.030000000000042, -313.57, -118.59999999999945, -251.26, -16.089999999999716, 2.0000000000000013, -140.67000000000007, -347.74000000000007, -154.78000000000065, -8.050000000000042, -170.8600000000003, -12.070000000000038, -271.36, -247.24000000000007, 2.0000000000000013, -2.020000000000042, -6.040000000000042, -28.14999999999976, -233.17000000000002, -136.69000000000062, -114.58000000000006, -8.050000000000042, -132.6300000000012, -267.3400000000006, -217.08999999999995, -6.040000000000042, -319.6, -20.109999999999705, -245.19000000000068, -243.22000000000034, -207.04000000000076, -375.88000000000005, -235.18000000000012, -184.93, -8.050000000000042, -281.4100000000003, -305.5300000000001, -30.159999999999716, 2.0000000000000013, -46.23999999999996, -14.080000000000041, -106.53999999999932, 2.0000000000000013, -78.39999999999924, -76.38999999999918, -34.180000000000234, -4.030000000000035, -26.139999999999716, -12.070000000000041, 2.0000000000000013, -30.159999999999712, -2.020000000000004, -4.030000000000042, -12.070000000000041, -176.89000000000004, -2.020000000000042, 2.0000000000000013, -48.24999999999981, -0.00999999999999836, -178.90000000000072, -10.060000000000034, -100.5099999999998, -22.119999999999944, -16.0899999999997, -68.34999999999992, -6.040000000000042, -215.0400000000007, -213.07000000000022, -38.19999999999994, -22.119999999999706, -64.32999999999919, -30.159999999999986, -293.47000000000014, -345.73000000000013, -14.080000000000041, -34.18000000000027, -18.099999999999703, -10.060000000000041, -6.040000000000042, -154.7800000000002, -108.55000000000008, -60.309999999999775, -18.10000000000001, -10.060000000000038, -26.13999999999971, -42.22000000000031, -2.020000000000042, 2.0000000000000013, -2.020000000000042, -50.26000000000031, -50.2600000000003, -50.260000000000346, -14.080000000000041, -6.040000000000042, -6.040000000000042, -8.050000000000042, 2.0000000000000013, -46.240000000000336, -0.00999999999999836, -6.040000000000042, -184.9300000000005, 2.0000000000000013, -24.129999999999797, -82.41999999999919, -10.060000000000041, -112.56999999999928, 2.0000000000000013, -12.070000000000041, -0.00999999999999836, 2.0000000000000013, 2.0000000000000013, -18.09999999999986, 2.0000000000000013, -14.080000000000041, -18.099999999999703, -0.009999999999998581, 2.0000000000000013, -58.30000000000022, -18.09999999999971, -36.18999999999994, 2.0000000000000013, -70.35999999999918, -20.10999999999973, -6.040000000000042, -60.310000000000336, -42.220000000000354, -34.18000000000025, -8.050000000000042, 2.0000000000000013, -10.060000000000041, -4.030000000000042, -44.23000000000033, -0.00999999999999836, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, -46.24000000000024, -0.00999999999999836, 2.0000000000000013, -16.0899999999997, -2.0200000000000293, -16.0899999999997, -14.080000000000025, -24.129999999999708, -22.11999999999973, 2.0000000000000013, -22.119999999999706, 2.0000000000000013, -0.00999999999999836, -10.060000000000032, -18.099999999999707, -18.099999999999742, -24.129999999999793, -16.0899999999997, -26.13999999999972, 2.0000000000000013, -10.060000000000041, -18.099999999999707, -8.050000000000042, -14.080000000000041, -46.24000000000028, -0.00999999999999836, -2.0200000000000413, 2.0000000000000013, -48.25000000000035, -48.25000000000034, -2.020000000000042, -36.190000000000225, 2.0000000000000013, -8.050000000000042, 2.0000000000000013, -8.050000000000031, 2.0000000000000013, -20.109999999999705, -0.00999999999999836, -16.0899999999997, -42.220000000000354, -12.070000000000041, -0.00999999999999836, -2.020000000000042, -18.099999999999756, -6.040000000000042, -2.020000000000042, -14.080000000000041, 2.0000000000000013, -6.040000000000042, -110.47999999999924, -0.00999999999999836, -28.14999999999971, -2.020000000000042, -22.119999999999706, -4.030000000000042], "policy_predator_policy_reward": [22.0, 23.0, 136.0, 126.0, 80.0, 87.0, 155.0, 175.0, 133.0, 130.0, 115.0, 119.0, 7.0, 7.0, 141.0, 153.0, 62.0, 75.0, 65.0, 67.0, 128.0, 132.0, 2.0, 0.0, 0.0, 19.0, 114.0, 124.0, 42.0, 30.0, 126.0, 127.0, 91.0, 93.0, 126.0, 144.0, 139.0, 135.0, 170.0, 170.0, 127.0, 124.0, 113.0, 107.0, 142.0, 126.0, 18.0, 17.0, 40.0, 50.0, 6.0, 38.0, 39.0, 18.0, 9.0, 15.0, 0.0, 7.0, 16.0, 16.0, 4.0, 6.0, 74.0, 70.0, 17.0, 19.0, 70.0, 73.0, 36.0, 43.0, 12.0, 13.0, 25.0, 25.0, 133.0, 141.0, 15.0, 24.0, 39.0, 18.0, 168.0, 144.0, 10.0, 16.0, 10.0, 4.0, 67.0, 65.0, 60.0, 43.0, 14.0, 7.0, 17.0, 19.0, 2.0, 0.0, 27.0, 1.0, 44.0, 16.0, 8.0, 4.0, 5.0, 5.0, 21.0, 24.0, 1.0, 4.0, 79.0, 76.0, 41.0, 18.0, 51.0, 43.0, 4.0, 7.0, 0.0, 1.0, 10.0, 8.0, 8.0, 4.0, 11.0, 3.0, 18.0, 18.0, 21.0, 11.0, 35.0, 5.0, 14.0, 9.0, 31.0, 14.0, 16.0, 7.0, 3.0, 6.0, 22.0, 4.0, 0.0, 1.0, 0.0, 0.0, 13.0, 13.0, 2.0, 9.0, 4.0, 11.0, 17.0, 18.0, 8.0, 4.0, 12.0, 10.0, 6.0, 1.0, 8.0, 15.0, 16.0, 10.0, 2.0, 14.0, 6.0, 10.0, 8.0, 5.0, 10.0, 15.0, 1.0, 2.0, 3.0, 27.0, 9.0, 12.0, 5.0, 5.0, 0.0, 5.0, 11.0, 1.0, 1.0, 9.0, 7.0, 22.0, 2.0, 1.0, 9.0, 8.0, 8.0, 2.0, 1.0, 4.0, 57.0, 28.0, 8.0, 9.0, 12.0, 9.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6013405792091502, "mean_inference_ms": 1.8911305988916192, "mean_action_processing_ms": 0.25601782022664593, "mean_env_wait_ms": 0.1961249222660014, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0044863224029541016, "StateBufferConnector_ms": 0.0031853914260864258, "ViewRequirementAgentConnector_ms": 0.10038638114929199}, "num_episodes": 18, "episode_return_max": 3.9999999999999587, "episode_return_min": -395.63000000000017, "episode_return_mean": -43.36159999999999, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 704000, "num_agent_steps_trained": 704000, "num_env_steps_sampled": 176000, "num_env_steps_trained": 176000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 385.681388653973, "num_env_steps_trained_throughput_per_sec": 385.681388653973, "timesteps_total": 176000, "num_env_steps_sampled_lifetime": 176000, "num_agent_steps_sampled_lifetime": 704000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 704000, "timers": {"training_iteration_time_ms": 11904.55, "restore_workers_time_ms": 0.012, "training_step_time_ms": 11904.514, "sample_time_ms": 1341.361, "learn_time_ms": 10546.359, "learn_throughput": 379.278, "synch_weights_time_ms": 15.379}, "counters": {"num_env_steps_sampled": 176000, "num_env_steps_trained": 176000, "num_agent_steps_sampled": 704000, "num_agent_steps_trained": 704000}, "done": false, "training_iteration": 44, "trial_id": "8e499_00000", "date": "2024-08-15_02-12-24", "timestamp": 1723668144, "time_this_iter_s": 10.377494096755981, "time_total_s": 484.09072041511536, "pid": 33199, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x158036940>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 484.09072041511536, "iterations_since_restore": 44, "perf": {"cpu_util_percent": 38.621428571428574, "ram_util_percent": 82.97857142857143}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.4255939628396717, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.0699097104804225, "policy_loss": -0.004870117420981091, "vf_loss": 2.073907940476029, "vf_explained_var": 0.01171763223945779, "kl": 0.007750077041851655, "entropy": 0.7670005796132264, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 84105.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8712850106140924, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.7637221286943054, "policy_loss": -0.009314035175851098, "vf_loss": 0.7725993698386465, "vf_explained_var": 0.1312456365930971, "kl": 0.005823911070264483, "entropy": 0.6905971099144568, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 84105.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 180000, "num_env_steps_trained": 180000, "num_agent_steps_sampled": 720000, "num_agent_steps_trained": 720000}, "env_runners": {"episode_reward_max": 3.9999999999999587, "episode_reward_min": -327.2000000000002, "episode_reward_mean": -18.88839999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -345.73000000000013, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 2.0000000000000013, "predator_policy": 168.0}, "policy_reward_mean": {"prey_policy": -28.109199999999973, "predator_policy": 18.665}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-67.68999999999998, -9.240000000000078, -30.619999999999386, -32.40000000000055, -53.570000000000675, -6.17000000000008, -3.070000000000065, -0.17999999999999705, -6.100000000000083, -34.910000000000046, -10.250000000000064, -35.91000000000032, -31.569999999999965, -13.210000000000077, -24.390000000000008, -154.11000000000092, -21.319999999999943, -37.48999999999974, -327.2000000000002, -22.25999999999942, -14.159999999999732, -28.8199999999999, -65.85999999999954, -7.16000000000008, -32.360000000000554, 1.9800000000000026, -24.2799999999995, -40.520000000000664, -8.120000000000083, -4.090000000000083, 0.7599999999999861, -1.050000000000063, -27.92999999999975, -47.55000000000062, -28.629999999999427, 0.9299999999999818, 2.989999999999981, 1.900000000000003, -0.08000000000003922, -4.110000000000082, -20.29999999999965, -22.289999999999907, -28.35999999999948, -3.150000000000075, -57.53000000000069, -19.229999999999514, 0.9399999999999819, -22.259999999999476, 2.989999999999981, 3.9999999999999587, -20.249999999999552, -3.0900000000000825, -3.110000000000082, -3.210000000000081, -8.120000000000083, 1.880000000000003, -3.0700000000000633, -13.199999999999983, -14.219999999999919, -8.14000000000008, -12.160000000000082, -9.130000000000082, -21.249999999999513, 2.9799999999999813, -66.49999999999822, -17.20999999999956, 3.9499999999999598, -1.0500000000000418, -6.110000000000081, -6.100000000000083, -25.289999999999424, 0.969999999999981, -7.140000000000068, -6.100000000000083, 0.9599999999999819, -25.489999999999526, -13.169999999999924, -5.150000000000082, -5.090000000000083, -3.160000000000081, -5.120000000000083, -7.110000000000083, -4.080000000000084, 2.989999999999981, 3.9999999999999587, 0.9499999999999819, -29.329999999999675, -2.060000000000084, -11.15000000000008, -8.430000000000076, -20.239999999999437, -2.060000000000084, 1.980000000000003, -6.14000000000007, -4.100000000000083, -12.160000000000078, -10.140000000000082, -12.160000000000078, -23.269999999999442, -32.43000000000064], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-305.5300000000001, -30.159999999999716, 2.0000000000000013, -46.23999999999996, -14.080000000000041, -106.53999999999932, 2.0000000000000013, -78.39999999999924, -76.38999999999918, -34.180000000000234, -4.030000000000035, -26.139999999999716, -12.070000000000041, 2.0000000000000013, -30.159999999999712, -2.020000000000004, -4.030000000000042, -12.070000000000041, -176.89000000000004, -2.020000000000042, 2.0000000000000013, -48.24999999999981, -0.00999999999999836, -178.90000000000072, -10.060000000000034, -100.5099999999998, -22.119999999999944, -16.0899999999997, -68.34999999999992, -6.040000000000042, -215.0400000000007, -213.07000000000022, -38.19999999999994, -22.119999999999706, -64.32999999999919, -30.159999999999986, -293.47000000000014, -345.73000000000013, -14.080000000000041, -34.18000000000027, -18.099999999999703, -10.060000000000041, -6.040000000000042, -154.7800000000002, -108.55000000000008, -60.309999999999775, -18.10000000000001, -10.060000000000038, -26.13999999999971, -42.22000000000031, -2.020000000000042, 2.0000000000000013, -2.020000000000042, -50.26000000000031, -50.2600000000003, -50.260000000000346, -14.080000000000041, -6.040000000000042, -6.040000000000042, -8.050000000000042, 2.0000000000000013, -46.240000000000336, -0.00999999999999836, -6.040000000000042, -184.9300000000005, 2.0000000000000013, -24.129999999999797, -82.41999999999919, -10.060000000000041, -112.56999999999928, 2.0000000000000013, -12.070000000000041, -0.00999999999999836, 2.0000000000000013, 2.0000000000000013, -18.09999999999986, 2.0000000000000013, -14.080000000000041, -18.099999999999703, -0.009999999999998581, 2.0000000000000013, -58.30000000000022, -18.09999999999971, -36.18999999999994, 2.0000000000000013, -70.35999999999918, -20.10999999999973, -6.040000000000042, -60.310000000000336, -42.220000000000354, -34.18000000000025, -8.050000000000042, 2.0000000000000013, -10.060000000000041, -4.030000000000042, -44.23000000000033, -0.00999999999999836, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, -46.24000000000024, -0.00999999999999836, 2.0000000000000013, -16.0899999999997, -2.0200000000000293, -16.0899999999997, -14.080000000000025, -24.129999999999708, -22.11999999999973, 2.0000000000000013, -22.119999999999706, 2.0000000000000013, -0.00999999999999836, -10.060000000000032, -18.099999999999707, -18.099999999999742, -24.129999999999793, -16.0899999999997, -26.13999999999972, 2.0000000000000013, -10.060000000000041, -18.099999999999707, -8.050000000000042, -14.080000000000041, -46.24000000000028, -0.00999999999999836, -2.0200000000000413, 2.0000000000000013, -48.25000000000035, -48.25000000000034, -2.020000000000042, -36.190000000000225, 2.0000000000000013, -8.050000000000042, 2.0000000000000013, -8.050000000000031, 2.0000000000000013, -20.109999999999705, -0.00999999999999836, -16.0899999999997, -42.220000000000354, -12.070000000000041, -0.00999999999999836, -2.020000000000042, -18.099999999999756, -6.040000000000042, -2.020000000000042, -14.080000000000041, 2.0000000000000013, -6.040000000000042, -110.47999999999924, -0.00999999999999836, -28.14999999999971, -2.020000000000042, -22.119999999999706, -4.030000000000042, -2.020000000000042, -12.070000000000041, 2.0000000000000013, -30.159999999999712, -22.119999999999706, 2.0000000000000013, -16.0899999999997, -2.020000000000042, -10.060000000000041, -2.020000000000042, -0.00999999999999836, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, -8.050000000000042, -40.210000000000356, -22.119999999999738, -8.050000000000042, -0.00999999999999836, -14.080000000000036, -12.070000000000041, -2.020000000000042, -80.40999999999943, -16.0899999999997, -28.14999999999972, -10.060000000000041, 2.0000000000000013, 2.0000000000000013, -2.0200000000000373, -16.089999999999755, -8.050000000000042, -2.020000000000042, -14.080000000000041, -26.139999999999723, -2.020000000000042, -12.070000000000041, -12.070000000000041, -18.099999999999703, -10.060000000000041, -34.18000000000036, -16.089999999999762, -32.170000000000364, -50.26000000000034], "policy_predator_policy_reward": [142.0, 126.0, 18.0, 17.0, 40.0, 50.0, 6.0, 38.0, 39.0, 18.0, 9.0, 15.0, 0.0, 7.0, 16.0, 16.0, 4.0, 6.0, 74.0, 70.0, 17.0, 19.0, 70.0, 73.0, 36.0, 43.0, 12.0, 13.0, 25.0, 25.0, 133.0, 141.0, 15.0, 24.0, 39.0, 18.0, 168.0, 144.0, 10.0, 16.0, 10.0, 4.0, 67.0, 65.0, 60.0, 43.0, 14.0, 7.0, 17.0, 19.0, 2.0, 0.0, 27.0, 1.0, 44.0, 16.0, 8.0, 4.0, 5.0, 5.0, 21.0, 24.0, 1.0, 4.0, 79.0, 76.0, 41.0, 18.0, 51.0, 43.0, 4.0, 7.0, 0.0, 1.0, 10.0, 8.0, 8.0, 4.0, 11.0, 3.0, 18.0, 18.0, 21.0, 11.0, 35.0, 5.0, 14.0, 9.0, 31.0, 14.0, 16.0, 7.0, 3.0, 6.0, 22.0, 4.0, 0.0, 1.0, 0.0, 0.0, 13.0, 13.0, 2.0, 9.0, 4.0, 11.0, 17.0, 18.0, 8.0, 4.0, 12.0, 10.0, 6.0, 1.0, 8.0, 15.0, 16.0, 10.0, 2.0, 14.0, 6.0, 10.0, 8.0, 5.0, 10.0, 15.0, 1.0, 2.0, 3.0, 27.0, 9.0, 12.0, 5.0, 5.0, 0.0, 5.0, 11.0, 1.0, 1.0, 9.0, 7.0, 22.0, 2.0, 1.0, 9.0, 8.0, 8.0, 2.0, 1.0, 4.0, 57.0, 28.0, 8.0, 9.0, 12.0, 9.0, 2.0, 7.0, 11.0, 14.0, 3.0, 12.0, 2.0, 9.0, 6.0, 2.0, 0.0, 1.0, 0.0, 0.0, 2.0, 5.0, 8.0, 25.0, 5.0, 1.0, 3.0, 12.0, 39.0, 35.0, 17.0, 7.0, 6.0, 0.0, 0.0, 2.0, 10.0, 8.0, 8.0, 4.0, 8.0, 8.0, 7.0, 7.0, 6.0, 10.0, 26.0, 1.0, 30.0, 20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.600469805231387, "mean_inference_ms": 1.889107199589982, "mean_action_processing_ms": 0.25545444209518897, "mean_env_wait_ms": 0.19592108318484733, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0045511722564697266, "StateBufferConnector_ms": 0.003128647804260254, "ViewRequirementAgentConnector_ms": 0.09792912006378174}, "num_episodes": 22, "episode_return_max": 3.9999999999999587, "episode_return_min": -327.2000000000002, "episode_return_mean": -18.88839999999998, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 720000, "num_agent_steps_trained": 720000, "num_env_steps_sampled": 180000, "num_env_steps_trained": 180000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 374.77578132998184, "num_env_steps_trained_throughput_per_sec": 374.77578132998184, "timesteps_total": 180000, "num_env_steps_sampled_lifetime": 180000, "num_agent_steps_sampled_lifetime": 720000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 720000, "timers": {"training_iteration_time_ms": 11887.541, "restore_workers_time_ms": 0.012, "training_step_time_ms": 11887.455, "sample_time_ms": 1349.322, "learn_time_ms": 10521.505, "learn_throughput": 380.174, "synch_weights_time_ms": 15.19}, "counters": {"num_env_steps_sampled": 180000, "num_env_steps_trained": 180000, "num_agent_steps_sampled": 720000, "num_agent_steps_trained": 720000}, "done": false, "training_iteration": 45, "trial_id": "8e499_00000", "date": "2024-08-15_02-12-35", "timestamp": 1723668155, "time_this_iter_s": 10.734143018722534, "time_total_s": 494.8248634338379, "pid": 33199, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b43f3160>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 494.8248634338379, "iterations_since_restore": 45, "perf": {"cpu_util_percent": 37.55333333333333, "ram_util_percent": 83.21333333333334}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.450347337584016, "cur_kl_coeff": 0.11250000000000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.9406041613646916, "policy_loss": -0.005968766625990313, "vf_loss": 0.946149269266734, "vf_explained_var": 0.10491238700018989, "kl": 0.003765856492268372, "entropy": 0.8061280485814211, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 85995.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9121590202762967, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.42586090806840854, "policy_loss": -0.014247601909720629, "vf_loss": 0.4390810216042809, "vf_explained_var": 0.05764073701131912, "kl": 0.013699833553746946, "entropy": 0.7416901017307604, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 85995.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 184000, "num_env_steps_trained": 184000, "num_agent_steps_sampled": 736000, "num_agent_steps_trained": 736000}, "env_runners": {"episode_reward_max": 3.9999999999999587, "episode_reward_min": -66.49999999999822, "episode_reward_mean": -10.66909999999996, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -184.9300000000005, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 2.0000000000000013, "predator_policy": 79.0}, "policy_reward_mean": {"prey_policy": -16.07954999999998, "predator_policy": 10.745}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-7.16000000000008, -32.360000000000554, 1.9800000000000026, -24.2799999999995, -40.520000000000664, -8.120000000000083, -4.090000000000083, 0.7599999999999861, -1.050000000000063, -27.92999999999975, -47.55000000000062, -28.629999999999427, 0.9299999999999818, 2.989999999999981, 1.900000000000003, -0.08000000000003922, -4.110000000000082, -20.29999999999965, -22.289999999999907, -28.35999999999948, -3.150000000000075, -57.53000000000069, -19.229999999999514, 0.9399999999999819, -22.259999999999476, 2.989999999999981, 3.9999999999999587, -20.249999999999552, -3.0900000000000825, -3.110000000000082, -3.210000000000081, -8.120000000000083, 1.880000000000003, -3.0700000000000633, -13.199999999999983, -14.219999999999919, -8.14000000000008, -12.160000000000082, -9.130000000000082, -21.249999999999513, 2.9799999999999813, -66.49999999999822, -17.20999999999956, 3.9499999999999598, -1.0500000000000418, -6.110000000000081, -6.100000000000083, -25.289999999999424, 0.969999999999981, -7.140000000000068, -6.100000000000083, 0.9599999999999819, -25.489999999999526, -13.169999999999924, -5.150000000000082, -5.090000000000083, -3.160000000000081, -5.120000000000083, -7.110000000000083, -4.080000000000084, 2.989999999999981, 3.9999999999999587, 0.9499999999999819, -29.329999999999675, -2.060000000000084, -11.15000000000008, -8.430000000000076, -20.239999999999437, -2.060000000000084, 1.980000000000003, -6.14000000000007, -4.100000000000083, -12.160000000000078, -10.140000000000082, -12.160000000000078, -23.269999999999442, -32.43000000000064, -12.260000000000073, 3.9999999999999587, -2.0800000000000827, -5.090000000000083, -12.160000000000078, -16.19999999999943, 3.9099999999999606, 1.8800000000000026, -26.439999999999472, -6.100000000000083, -2.060000000000083, -0.040000000000040996, -8.150000000000075, -9.13000000000008, -7.200000000000079, -16.249999999999464, -6.100000000000083, -3.0700000000000838, -14.159999999999739, -1.050000000000063, -21.299999999999457, -34.2900000000007, -15.229999999999567], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-18.10000000000001, -10.060000000000038, -26.13999999999971, -42.22000000000031, -2.020000000000042, 2.0000000000000013, -2.020000000000042, -50.26000000000031, -50.2600000000003, -50.260000000000346, -14.080000000000041, -6.040000000000042, -6.040000000000042, -8.050000000000042, 2.0000000000000013, -46.240000000000336, -0.00999999999999836, -6.040000000000042, -184.9300000000005, 2.0000000000000013, -24.129999999999797, -82.41999999999919, -10.060000000000041, -112.56999999999928, 2.0000000000000013, -12.070000000000041, -0.00999999999999836, 2.0000000000000013, 2.0000000000000013, -18.09999999999986, 2.0000000000000013, -14.080000000000041, -18.099999999999703, -0.009999999999998581, 2.0000000000000013, -58.30000000000022, -18.09999999999971, -36.18999999999994, 2.0000000000000013, -70.35999999999918, -20.10999999999973, -6.040000000000042, -60.310000000000336, -42.220000000000354, -34.18000000000025, -8.050000000000042, 2.0000000000000013, -10.060000000000041, -4.030000000000042, -44.23000000000033, -0.00999999999999836, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, -46.24000000000024, -0.00999999999999836, 2.0000000000000013, -16.0899999999997, -2.0200000000000293, -16.0899999999997, -14.080000000000025, -24.129999999999708, -22.11999999999973, 2.0000000000000013, -22.119999999999706, 2.0000000000000013, -0.00999999999999836, -10.060000000000032, -18.099999999999707, -18.099999999999742, -24.129999999999793, -16.0899999999997, -26.13999999999972, 2.0000000000000013, -10.060000000000041, -18.099999999999707, -8.050000000000042, -14.080000000000041, -46.24000000000028, -0.00999999999999836, -2.0200000000000413, 2.0000000000000013, -48.25000000000035, -48.25000000000034, -2.020000000000042, -36.190000000000225, 2.0000000000000013, -8.050000000000042, 2.0000000000000013, -8.050000000000031, 2.0000000000000013, -20.109999999999705, -0.00999999999999836, -16.0899999999997, -42.220000000000354, -12.070000000000041, -0.00999999999999836, -2.020000000000042, -18.099999999999756, -6.040000000000042, -2.020000000000042, -14.080000000000041, 2.0000000000000013, -6.040000000000042, -110.47999999999924, -0.00999999999999836, -28.14999999999971, -2.020000000000042, -22.119999999999706, -4.030000000000042, -2.020000000000042, -12.070000000000041, 2.0000000000000013, -30.159999999999712, -22.119999999999706, 2.0000000000000013, -16.0899999999997, -2.020000000000042, -10.060000000000041, -2.020000000000042, -0.00999999999999836, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, -8.050000000000042, -40.210000000000356, -22.119999999999738, -8.050000000000042, -0.00999999999999836, -14.080000000000036, -12.070000000000041, -2.020000000000042, -80.40999999999943, -16.0899999999997, -28.14999999999972, -10.060000000000041, 2.0000000000000013, 2.0000000000000013, -2.0200000000000373, -16.089999999999755, -8.050000000000042, -2.020000000000042, -14.080000000000041, -26.139999999999723, -2.020000000000042, -12.070000000000041, -12.070000000000041, -18.099999999999703, -10.060000000000041, -34.18000000000036, -16.089999999999762, -32.170000000000364, -50.26000000000034, -8.050000000000042, -40.21000000000033, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, -14.080000000000041, -8.050000000000042, -6.040000000000042, 2.0000000000000013, -30.159999999999716, -14.080000000000041, -22.119999999999717, -16.0899999999997, 2.0000000000000013, 2.0000000000000013, -22.119999999999706, -42.220000000000354, -42.22000000000029, -10.060000000000041, -6.040000000000042, 2.0000000000000013, -10.060000000000041, -6.040000000000042, 2.0000000000000013, -2.020000000000042, -24.129999999999733, -14.080000000000037, -8.050000000000042, -18.099999999999707, -18.09999999999978, -14.080000000000041, -32.170000000000336, -0.00999999999999836, -16.089999999999726, -6.040000000000042, -4.030000000000042, -18.099999999999707, -10.060000000000041, -2.020000000000042, -4.030000000000042, -28.14999999999971, -28.149999999999732, -20.109999999999726, -34.180000000000355, -8.050000000000042, -34.18000000000036], "policy_predator_policy_reward": [14.0, 7.0, 17.0, 19.0, 2.0, 0.0, 27.0, 1.0, 44.0, 16.0, 8.0, 4.0, 5.0, 5.0, 21.0, 24.0, 1.0, 4.0, 79.0, 76.0, 41.0, 18.0, 51.0, 43.0, 4.0, 7.0, 0.0, 1.0, 10.0, 8.0, 8.0, 4.0, 11.0, 3.0, 18.0, 18.0, 21.0, 11.0, 35.0, 5.0, 14.0, 9.0, 31.0, 14.0, 16.0, 7.0, 3.0, 6.0, 22.0, 4.0, 0.0, 1.0, 0.0, 0.0, 13.0, 13.0, 2.0, 9.0, 4.0, 11.0, 17.0, 18.0, 8.0, 4.0, 12.0, 10.0, 6.0, 1.0, 8.0, 15.0, 16.0, 10.0, 2.0, 14.0, 6.0, 10.0, 8.0, 5.0, 10.0, 15.0, 1.0, 2.0, 3.0, 27.0, 9.0, 12.0, 5.0, 5.0, 0.0, 5.0, 11.0, 1.0, 1.0, 9.0, 7.0, 22.0, 2.0, 1.0, 9.0, 8.0, 8.0, 2.0, 1.0, 4.0, 57.0, 28.0, 8.0, 9.0, 12.0, 9.0, 2.0, 7.0, 11.0, 14.0, 3.0, 12.0, 2.0, 9.0, 6.0, 2.0, 0.0, 1.0, 0.0, 0.0, 2.0, 5.0, 8.0, 25.0, 5.0, 1.0, 3.0, 12.0, 39.0, 35.0, 17.0, 7.0, 6.0, 0.0, 0.0, 2.0, 10.0, 8.0, 8.0, 4.0, 8.0, 8.0, 7.0, 7.0, 6.0, 10.0, 26.0, 1.0, 30.0, 20.0, 20.0, 16.0, 0.0, 0.0, 8.0, 2.0, 4.0, 5.0, 16.0, 0.0, 5.0, 15.0, 9.0, 9.0, 12.0, 10.0, 17.0, 41.0, 6.0, 4.0, 0.0, 6.0, 4.0, 0.0, 12.0, 6.0, 13.0, 0.0, 13.0, 16.0, 20.0, 10.0, 1.0, 9.0, 3.0, 4.0, 2.0, 12.0, 2.0, 3.0, 11.0, 24.0, 0.0, 20.0, 9.0, 18.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5994744407075465, "mean_inference_ms": 1.8865018268417606, "mean_action_processing_ms": 0.25481145837920127, "mean_env_wait_ms": 0.19565820764115938, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005076169967651367, "StateBufferConnector_ms": 0.0031396150588989258, "ViewRequirementAgentConnector_ms": 0.09951424598693848}, "num_episodes": 23, "episode_return_max": 3.9999999999999587, "episode_return_min": -66.49999999999822, "episode_return_mean": -10.66909999999996, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 736000, "num_agent_steps_trained": 736000, "num_env_steps_sampled": 184000, "num_env_steps_trained": 184000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 398.30165241421776, "num_env_steps_trained_throughput_per_sec": 398.30165241421776, "timesteps_total": 184000, "num_env_steps_sampled_lifetime": 184000, "num_agent_steps_sampled_lifetime": 736000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 736000, "timers": {"training_iteration_time_ms": 11869.327, "restore_workers_time_ms": 0.012, "training_step_time_ms": 11869.24, "sample_time_ms": 1340.665, "learn_time_ms": 10512.029, "learn_throughput": 380.516, "synch_weights_time_ms": 15.105}, "counters": {"num_env_steps_sampled": 184000, "num_env_steps_trained": 184000, "num_agent_steps_sampled": 736000, "num_agent_steps_trained": 736000}, "done": false, "training_iteration": 46, "trial_id": "8e499_00000", "date": "2024-08-15_02-12-45", "timestamp": 1723668165, "time_this_iter_s": 10.048525094985962, "time_total_s": 504.87338852882385, "pid": 33199, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b43f2310>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 504.87338852882385, "iterations_since_restore": 46, "perf": {"cpu_util_percent": 36.74666666666667, "ram_util_percent": 83.02666666666667}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6622104600781487, "cur_kl_coeff": 0.056250000000000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.5557747346856606, "policy_loss": -0.004068564140932664, "vf_loss": 0.5595650487712451, "vf_explained_var": 0.03889876181486422, "kl": 0.004946697014011094, "entropy": 0.7776771070465209, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 87885.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7954378144923973, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.4605479554637833, "policy_loss": -0.011430581126155125, "vf_loss": 0.4712619489356974, "vf_explained_var": 0.044738238103806026, "kl": 0.009554505337318032, "entropy": 0.7368062846559696, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 87885.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 188000, "num_env_steps_trained": 188000, "num_agent_steps_sampled": 752000, "num_agent_steps_trained": 752000}, "env_runners": {"episode_reward_max": 3.9999999999999587, "episode_reward_min": -66.49999999999822, "episode_reward_mean": -8.86239999999996, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -110.47999999999924, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 2.0000000000000013, "predator_policy": 57.0}, "policy_reward_mean": {"prey_policy": -13.39619999999998, "predator_policy": 8.965}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-22.289999999999907, -28.35999999999948, -3.150000000000075, -57.53000000000069, -19.229999999999514, 0.9399999999999819, -22.259999999999476, 2.989999999999981, 3.9999999999999587, -20.249999999999552, -3.0900000000000825, -3.110000000000082, -3.210000000000081, -8.120000000000083, 1.880000000000003, -3.0700000000000633, -13.199999999999983, -14.219999999999919, -8.14000000000008, -12.160000000000082, -9.130000000000082, -21.249999999999513, 2.9799999999999813, -66.49999999999822, -17.20999999999956, 3.9499999999999598, -1.0500000000000418, -6.110000000000081, -6.100000000000083, -25.289999999999424, 0.969999999999981, -7.140000000000068, -6.100000000000083, 0.9599999999999819, -25.489999999999526, -13.169999999999924, -5.150000000000082, -5.090000000000083, -3.160000000000081, -5.120000000000083, -7.110000000000083, -4.080000000000084, 2.989999999999981, 3.9999999999999587, 0.9499999999999819, -29.329999999999675, -2.060000000000084, -11.15000000000008, -8.430000000000076, -20.239999999999437, -2.060000000000084, 1.980000000000003, -6.14000000000007, -4.100000000000083, -12.160000000000078, -10.140000000000082, -12.160000000000078, -23.269999999999442, -32.43000000000064, -12.260000000000073, 3.9999999999999587, -2.0800000000000827, -5.090000000000083, -12.160000000000078, -16.19999999999943, 3.9099999999999606, 1.8800000000000026, -26.439999999999472, -6.100000000000083, -2.060000000000083, -0.040000000000040996, -8.150000000000075, -9.13000000000008, -7.200000000000079, -16.249999999999464, -6.100000000000083, -3.0700000000000838, -14.159999999999739, -1.050000000000063, -21.299999999999457, -34.2900000000007, -15.229999999999567, -0.040000000000040996, -30.340000000000018, -2.2300000000000804, 0.9299999999999827, -0.07000000000004011, -5.090000000000083, 1.820000000000003, -6.120000000000083, -5.090000000000082, -0.04000000000004011, 0.9699999999999819, -12.210000000000079, -11.170000000000082, -1.0500000000000613, 3.9999999999999587, 2.9699999999999815, 3.859999999999962, 1.9500000000000028], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-18.09999999999971, -36.18999999999994, 2.0000000000000013, -70.35999999999918, -20.10999999999973, -6.040000000000042, -60.310000000000336, -42.220000000000354, -34.18000000000025, -8.050000000000042, 2.0000000000000013, -10.060000000000041, -4.030000000000042, -44.23000000000033, -0.00999999999999836, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, -46.24000000000024, -0.00999999999999836, 2.0000000000000013, -16.0899999999997, -2.0200000000000293, -16.0899999999997, -14.080000000000025, -24.129999999999708, -22.11999999999973, 2.0000000000000013, -22.119999999999706, 2.0000000000000013, -0.00999999999999836, -10.060000000000032, -18.099999999999707, -18.099999999999742, -24.129999999999793, -16.0899999999997, -26.13999999999972, 2.0000000000000013, -10.060000000000041, -18.099999999999707, -8.050000000000042, -14.080000000000041, -46.24000000000028, -0.00999999999999836, -2.0200000000000413, 2.0000000000000013, -48.25000000000035, -48.25000000000034, -2.020000000000042, -36.190000000000225, 2.0000000000000013, -8.050000000000042, 2.0000000000000013, -8.050000000000031, 2.0000000000000013, -20.109999999999705, -0.00999999999999836, -16.0899999999997, -42.220000000000354, -12.070000000000041, -0.00999999999999836, -2.020000000000042, -18.099999999999756, -6.040000000000042, -2.020000000000042, -14.080000000000041, 2.0000000000000013, -6.040000000000042, -110.47999999999924, -0.00999999999999836, -28.14999999999971, -2.020000000000042, -22.119999999999706, -4.030000000000042, -2.020000000000042, -12.070000000000041, 2.0000000000000013, -30.159999999999712, -22.119999999999706, 2.0000000000000013, -16.0899999999997, -2.020000000000042, -10.060000000000041, -2.020000000000042, -0.00999999999999836, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, -8.050000000000042, -40.210000000000356, -22.119999999999738, -8.050000000000042, -0.00999999999999836, -14.080000000000036, -12.070000000000041, -2.020000000000042, -80.40999999999943, -16.0899999999997, -28.14999999999972, -10.060000000000041, 2.0000000000000013, 2.0000000000000013, -2.0200000000000373, -16.089999999999755, -8.050000000000042, -2.020000000000042, -14.080000000000041, -26.139999999999723, -2.020000000000042, -12.070000000000041, -12.070000000000041, -18.099999999999703, -10.060000000000041, -34.18000000000036, -16.089999999999762, -32.170000000000364, -50.26000000000034, -8.050000000000042, -40.21000000000033, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, -14.080000000000041, -8.050000000000042, -6.040000000000042, 2.0000000000000013, -30.159999999999716, -14.080000000000041, -22.119999999999717, -16.0899999999997, 2.0000000000000013, 2.0000000000000013, -22.119999999999706, -42.220000000000354, -42.22000000000029, -10.060000000000041, -6.040000000000042, 2.0000000000000013, -10.060000000000041, -6.040000000000042, 2.0000000000000013, -2.020000000000042, -24.129999999999733, -14.080000000000037, -8.050000000000042, -18.099999999999707, -18.09999999999978, -14.080000000000041, -32.170000000000336, -0.00999999999999836, -16.089999999999726, -6.040000000000042, -4.030000000000042, -18.099999999999707, -10.060000000000041, -2.020000000000042, -4.030000000000042, -28.14999999999971, -28.149999999999732, -20.109999999999726, -34.180000000000355, -8.050000000000042, -34.18000000000036, -6.040000000000042, 2.0000000000000013, -2.020000000000042, -62.3200000000003, -0.00999999999999836, -42.220000000000354, 2.0000000000000013, -12.070000000000041, -12.070000000000041, 2.0000000000000013, -8.050000000000042, -6.040000000000042, 2.0000000000000013, -34.18000000000036, -14.080000000000041, -6.040000000000042, -16.08999999999971, 2.0000000000000013, 2.0000000000000013, -6.040000000000042, 2.0000000000000013, -4.030000000000042, -14.080000000000041, -24.12999999999972, -12.070000000000041, -18.099999999999703, -0.00999999999999836, -6.040000000000041, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, -4.030000000000042, -26.13999999999971, 2.0000000000000013, -8.050000000000042, 2.0000000000000013], "policy_predator_policy_reward": [21.0, 11.0, 35.0, 5.0, 14.0, 9.0, 31.0, 14.0, 16.0, 7.0, 3.0, 6.0, 22.0, 4.0, 0.0, 1.0, 0.0, 0.0, 13.0, 13.0, 2.0, 9.0, 4.0, 11.0, 17.0, 18.0, 8.0, 4.0, 12.0, 10.0, 6.0, 1.0, 8.0, 15.0, 16.0, 10.0, 2.0, 14.0, 6.0, 10.0, 8.0, 5.0, 10.0, 15.0, 1.0, 2.0, 3.0, 27.0, 9.0, 12.0, 5.0, 5.0, 0.0, 5.0, 11.0, 1.0, 1.0, 9.0, 7.0, 22.0, 2.0, 1.0, 9.0, 8.0, 8.0, 2.0, 1.0, 4.0, 57.0, 28.0, 8.0, 9.0, 12.0, 9.0, 2.0, 7.0, 11.0, 14.0, 3.0, 12.0, 2.0, 9.0, 6.0, 2.0, 0.0, 1.0, 0.0, 0.0, 2.0, 5.0, 8.0, 25.0, 5.0, 1.0, 3.0, 12.0, 39.0, 35.0, 17.0, 7.0, 6.0, 0.0, 0.0, 2.0, 10.0, 8.0, 8.0, 4.0, 8.0, 8.0, 7.0, 7.0, 6.0, 10.0, 26.0, 1.0, 30.0, 20.0, 20.0, 16.0, 0.0, 0.0, 8.0, 2.0, 4.0, 5.0, 16.0, 0.0, 5.0, 15.0, 9.0, 9.0, 12.0, 10.0, 17.0, 41.0, 6.0, 4.0, 0.0, 6.0, 4.0, 0.0, 12.0, 6.0, 13.0, 0.0, 13.0, 16.0, 20.0, 10.0, 1.0, 9.0, 3.0, 4.0, 2.0, 12.0, 2.0, 3.0, 11.0, 24.0, 0.0, 20.0, 9.0, 18.0, 4.0, 0.0, 20.0, 14.0, 20.0, 20.0, 4.0, 7.0, 4.0, 6.0, 5.0, 4.0, 17.0, 17.0, 8.0, 6.0, 1.0, 8.0, 0.0, 4.0, 3.0, 0.0, 15.0, 11.0, 10.0, 9.0, 1.0, 4.0, 0.0, 0.0, 2.0, 3.0, 14.0, 14.0, 3.0, 5.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5987567233978963, "mean_inference_ms": 1.8846024578481575, "mean_action_processing_ms": 0.2543911870915182, "mean_env_wait_ms": 0.19548710708474168, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005657315254211426, "StateBufferConnector_ms": 0.0031801462173461914, "ViewRequirementAgentConnector_ms": 0.10011768341064453}, "num_episodes": 18, "episode_return_max": 3.9999999999999587, "episode_return_min": -66.49999999999822, "episode_return_mean": -8.86239999999996, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 752000, "num_agent_steps_trained": 752000, "num_env_steps_sampled": 188000, "num_env_steps_trained": 188000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 27.106651170162117, "num_env_steps_trained_throughput_per_sec": 27.106651170162117, "timesteps_total": 188000, "num_env_steps_sampled_lifetime": 188000, "num_agent_steps_sampled_lifetime": 752000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 752000, "timers": {"training_iteration_time_ms": 25606.715, "restore_workers_time_ms": 0.012, "training_step_time_ms": 25606.629, "sample_time_ms": 1337.391, "learn_time_ms": 24252.478, "learn_throughput": 164.932, "synch_weights_time_ms": 15.334}, "counters": {"num_env_steps_sampled": 188000, "num_env_steps_trained": 188000, "num_agent_steps_sampled": 752000, "num_agent_steps_trained": 752000}, "done": false, "training_iteration": 47, "trial_id": "8e499_00000", "date": "2024-08-15_02-15-12", "timestamp": 1723668312, "time_this_iter_s": 147.57554292678833, "time_total_s": 652.4489314556122, "pid": 33199, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x158031f70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 652.4489314556122, "iterations_since_restore": 47, "perf": {"cpu_util_percent": 38.3, "ram_util_percent": 83.45333333333333}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2694703767539333, "cur_kl_coeff": 0.028125000000000008, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.5455523174906534, "policy_loss": -0.005431781966170227, "vf_loss": 0.5507942746674258, "vf_explained_var": 0.017394425534697437, "kl": 0.006749301526079823, "entropy": 0.7709138821357142, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 89775.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9875328329899323, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.4474412958000795, "policy_loss": -0.00905218078020625, "vf_loss": 0.4558445914175421, "vf_explained_var": 0.05120677888078034, "kl": 0.008651805434667877, "entropy": 0.8416935565925779, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 89775.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 192000, "num_env_steps_trained": 192000, "num_agent_steps_sampled": 768000, "num_agent_steps_trained": 768000}, "env_runners": {"episode_reward_max": 3.9999999999999587, "episode_reward_min": -66.49999999999822, "episode_reward_mean": -8.07449999999995, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -110.47999999999924, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 2.0000000000000013, "predator_policy": 57.0}, "policy_reward_mean": {"prey_policy": -12.602249999999987, "predator_policy": 8.565}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-8.14000000000008, -12.160000000000082, -9.130000000000082, -21.249999999999513, 2.9799999999999813, -66.49999999999822, -17.20999999999956, 3.9499999999999598, -1.0500000000000418, -6.110000000000081, -6.100000000000083, -25.289999999999424, 0.969999999999981, -7.140000000000068, -6.100000000000083, 0.9599999999999819, -25.489999999999526, -13.169999999999924, -5.150000000000082, -5.090000000000083, -3.160000000000081, -5.120000000000083, -7.110000000000083, -4.080000000000084, 2.989999999999981, 3.9999999999999587, 0.9499999999999819, -29.329999999999675, -2.060000000000084, -11.15000000000008, -8.430000000000076, -20.239999999999437, -2.060000000000084, 1.980000000000003, -6.14000000000007, -4.100000000000083, -12.160000000000078, -10.140000000000082, -12.160000000000078, -23.269999999999442, -32.43000000000064, -12.260000000000073, 3.9999999999999587, -2.0800000000000827, -5.090000000000083, -12.160000000000078, -16.19999999999943, 3.9099999999999606, 1.8800000000000026, -26.439999999999472, -6.100000000000083, -2.060000000000083, -0.040000000000040996, -8.150000000000075, -9.13000000000008, -7.200000000000079, -16.249999999999464, -6.100000000000083, -3.0700000000000838, -14.159999999999739, -1.050000000000063, -21.299999999999457, -34.2900000000007, -15.229999999999567, -0.040000000000040996, -30.340000000000018, -2.2300000000000804, 0.9299999999999827, -0.07000000000004011, -5.090000000000083, 1.820000000000003, -6.120000000000083, -5.090000000000082, -0.04000000000004011, 0.9699999999999819, -12.210000000000079, -11.170000000000082, -1.0500000000000613, 3.9999999999999587, 2.9699999999999815, 3.859999999999962, 1.9500000000000028, -27.309999999999466, 2.9199999999999826, -3.1400000000000814, -17.209999999999408, -3.070000000000075, 1.920000000000003, 3.93999999999996, -3.070000000000083, -0.08000000000004011, -5.090000000000083, 1.9800000000000026, -6.100000000000083, -26.299999999999446, -16.219999999999438, 2.939999999999982, -8.120000000000083, -18.239999999999423, -12.240000000000077], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-26.13999999999972, 2.0000000000000013, -10.060000000000041, -18.099999999999707, -8.050000000000042, -14.080000000000041, -46.24000000000028, -0.00999999999999836, -2.0200000000000413, 2.0000000000000013, -48.25000000000035, -48.25000000000034, -2.020000000000042, -36.190000000000225, 2.0000000000000013, -8.050000000000042, 2.0000000000000013, -8.050000000000031, 2.0000000000000013, -20.109999999999705, -0.00999999999999836, -16.0899999999997, -42.220000000000354, -12.070000000000041, -0.00999999999999836, -2.020000000000042, -18.099999999999756, -6.040000000000042, -2.020000000000042, -14.080000000000041, 2.0000000000000013, -6.040000000000042, -110.47999999999924, -0.00999999999999836, -28.14999999999971, -2.020000000000042, -22.119999999999706, -4.030000000000042, -2.020000000000042, -12.070000000000041, 2.0000000000000013, -30.159999999999712, -22.119999999999706, 2.0000000000000013, -16.0899999999997, -2.020000000000042, -10.060000000000041, -2.020000000000042, -0.00999999999999836, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, -8.050000000000042, -40.210000000000356, -22.119999999999738, -8.050000000000042, -0.00999999999999836, -14.080000000000036, -12.070000000000041, -2.020000000000042, -80.40999999999943, -16.0899999999997, -28.14999999999972, -10.060000000000041, 2.0000000000000013, 2.0000000000000013, -2.0200000000000373, -16.089999999999755, -8.050000000000042, -2.020000000000042, -14.080000000000041, -26.139999999999723, -2.020000000000042, -12.070000000000041, -12.070000000000041, -18.099999999999703, -10.060000000000041, -34.18000000000036, -16.089999999999762, -32.170000000000364, -50.26000000000034, -8.050000000000042, -40.21000000000033, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, -14.080000000000041, -8.050000000000042, -6.040000000000042, 2.0000000000000013, -30.159999999999716, -14.080000000000041, -22.119999999999717, -16.0899999999997, 2.0000000000000013, 2.0000000000000013, -22.119999999999706, -42.220000000000354, -42.22000000000029, -10.060000000000041, -6.040000000000042, 2.0000000000000013, -10.060000000000041, -6.040000000000042, 2.0000000000000013, -2.020000000000042, -24.129999999999733, -14.080000000000037, -8.050000000000042, -18.099999999999707, -18.09999999999978, -14.080000000000041, -32.170000000000336, -0.00999999999999836, -16.089999999999726, -6.040000000000042, -4.030000000000042, -18.099999999999707, -10.060000000000041, -2.020000000000042, -4.030000000000042, -28.14999999999971, -28.149999999999732, -20.109999999999726, -34.180000000000355, -8.050000000000042, -34.18000000000036, -6.040000000000042, 2.0000000000000013, -2.020000000000042, -62.3200000000003, -0.00999999999999836, -42.220000000000354, 2.0000000000000013, -12.070000000000041, -12.070000000000041, 2.0000000000000013, -8.050000000000042, -6.040000000000042, 2.0000000000000013, -34.18000000000036, -14.080000000000041, -6.040000000000042, -16.08999999999971, 2.0000000000000013, 2.0000000000000013, -6.040000000000042, 2.0000000000000013, -4.030000000000042, -14.080000000000041, -24.12999999999972, -12.070000000000041, -18.099999999999703, -0.00999999999999836, -6.040000000000041, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, -4.030000000000042, -26.13999999999971, 2.0000000000000013, -8.050000000000042, 2.0000000000000013, -54.280000000000314, -4.030000000000042, -14.080000000000041, 2.0000000000000013, 2.0000000000000013, -26.13999999999971, -20.109999999999705, -18.099999999999703, -0.00999999999999836, -10.060000000000041, 2.0000000000000013, -14.080000000000041, -10.060000000000041, 2.0000000000000013, 2.0000000000000013, -12.070000000000041, -8.050000000000042, -4.030000000000041, -16.0899999999997, 2.0000000000000013, -2.020000000000042, 2.0000000000000013, -4.030000000000042, -12.070000000000041, -36.19000000000029, -20.109999999999705, -42.220000000000354, 2.0000000000000013, 2.0000000000000013, -10.060000000000041, -2.020000000000042, -18.099999999999714, -8.050000000000042, -36.19000000000036, -22.119999999999717, -22.119999999999706], "policy_predator_policy_reward": [2.0, 14.0, 6.0, 10.0, 8.0, 5.0, 10.0, 15.0, 1.0, 2.0, 3.0, 27.0, 9.0, 12.0, 5.0, 5.0, 0.0, 5.0, 11.0, 1.0, 1.0, 9.0, 7.0, 22.0, 2.0, 1.0, 9.0, 8.0, 8.0, 2.0, 1.0, 4.0, 57.0, 28.0, 8.0, 9.0, 12.0, 9.0, 2.0, 7.0, 11.0, 14.0, 3.0, 12.0, 2.0, 9.0, 6.0, 2.0, 0.0, 1.0, 0.0, 0.0, 2.0, 5.0, 8.0, 25.0, 5.0, 1.0, 3.0, 12.0, 39.0, 35.0, 17.0, 7.0, 6.0, 0.0, 0.0, 2.0, 10.0, 8.0, 8.0, 4.0, 8.0, 8.0, 7.0, 7.0, 6.0, 10.0, 26.0, 1.0, 30.0, 20.0, 20.0, 16.0, 0.0, 0.0, 8.0, 2.0, 4.0, 5.0, 16.0, 0.0, 5.0, 15.0, 9.0, 9.0, 12.0, 10.0, 17.0, 41.0, 6.0, 4.0, 0.0, 6.0, 4.0, 0.0, 12.0, 6.0, 13.0, 0.0, 13.0, 16.0, 20.0, 10.0, 1.0, 9.0, 3.0, 4.0, 2.0, 12.0, 2.0, 3.0, 11.0, 24.0, 0.0, 20.0, 9.0, 18.0, 4.0, 0.0, 20.0, 14.0, 20.0, 20.0, 4.0, 7.0, 4.0, 6.0, 5.0, 4.0, 17.0, 17.0, 8.0, 6.0, 1.0, 8.0, 0.0, 4.0, 3.0, 0.0, 15.0, 11.0, 10.0, 9.0, 1.0, 4.0, 0.0, 0.0, 2.0, 3.0, 14.0, 14.0, 3.0, 5.0, 15.0, 16.0, 8.0, 7.0, 13.0, 8.0, 10.0, 11.0, 5.0, 2.0, 6.0, 8.0, 6.0, 6.0, 0.0, 7.0, 5.0, 7.0, 0.0, 9.0, 2.0, 0.0, 3.0, 7.0, 10.0, 20.0, 22.0, 2.0, 5.0, 6.0, 4.0, 8.0, 12.0, 14.0, 18.0, 14.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5976618981511714, "mean_inference_ms": 1.8816632045517299, "mean_action_processing_ms": 0.2538557888686778, "mean_env_wait_ms": 0.1951461509079045, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005163669586181641, "StateBufferConnector_ms": 0.0029948949813842773, "ViewRequirementAgentConnector_ms": 0.08957839012145996}, "num_episodes": 18, "episode_return_max": 3.9999999999999587, "episode_return_min": -66.49999999999822, "episode_return_mean": -8.07449999999995, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 768000, "num_agent_steps_trained": 768000, "num_env_steps_sampled": 192000, "num_env_steps_trained": 192000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 387.86953362300295, "num_env_steps_trained_throughput_per_sec": 387.86953362300295, "timesteps_total": 192000, "num_env_steps_sampled_lifetime": 192000, "num_agent_steps_sampled_lifetime": 768000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 768000, "timers": {"training_iteration_time_ms": 25600.469, "restore_workers_time_ms": 0.013, "training_step_time_ms": 25600.381, "sample_time_ms": 1330.484, "learn_time_ms": 24253.227, "learn_throughput": 164.927, "synch_weights_time_ms": 15.42}, "counters": {"num_env_steps_sampled": 192000, "num_env_steps_trained": 192000, "num_agent_steps_sampled": 768000, "num_agent_steps_trained": 768000}, "done": false, "training_iteration": 48, "trial_id": "8e499_00000", "date": "2024-08-15_02-15-23", "timestamp": 1723668323, "time_this_iter_s": 10.351691007614136, "time_total_s": 662.8006224632263, "pid": 33199, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x1580be1f0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 662.8006224632263, "iterations_since_restore": 48, "perf": {"cpu_util_percent": 40.47857142857142, "ram_util_percent": 83.34285714285713}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2133325051693689, "cur_kl_coeff": 0.028125000000000008, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.39096608903830643, "policy_loss": -0.004414226554787506, "vf_loss": 0.39517512039808683, "vf_explained_var": 0.068382465208649, "kl": 0.00729579363645075, "entropy": 0.7371285862077481, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 91665.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9563772243166727, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.3227951686351425, "policy_loss": -0.006663109191136543, "vf_loss": 0.3291538771317666, "vf_explained_var": 0.11119090400675617, "kl": 0.004058679574997227, "entropy": 0.7922650593298453, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 91665.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 196000, "num_env_steps_trained": 196000, "num_agent_steps_sampled": 784000, "num_agent_steps_trained": 784000}, "env_runners": {"episode_reward_max": 3.9999999999999587, "episode_reward_min": -34.2900000000007, "episode_reward_mean": -7.572399999999964, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -80.40999999999943, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 2.0000000000000013, "predator_policy": 41.0}, "policy_reward_mean": {"prey_policy": -12.311199999999994, "predator_policy": 8.525}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-7.110000000000083, -4.080000000000084, 2.989999999999981, 3.9999999999999587, 0.9499999999999819, -29.329999999999675, -2.060000000000084, -11.15000000000008, -8.430000000000076, -20.239999999999437, -2.060000000000084, 1.980000000000003, -6.14000000000007, -4.100000000000083, -12.160000000000078, -10.140000000000082, -12.160000000000078, -23.269999999999442, -32.43000000000064, -12.260000000000073, 3.9999999999999587, -2.0800000000000827, -5.090000000000083, -12.160000000000078, -16.19999999999943, 3.9099999999999606, 1.8800000000000026, -26.439999999999472, -6.100000000000083, -2.060000000000083, -0.040000000000040996, -8.150000000000075, -9.13000000000008, -7.200000000000079, -16.249999999999464, -6.100000000000083, -3.0700000000000838, -14.159999999999739, -1.050000000000063, -21.299999999999457, -34.2900000000007, -15.229999999999567, -0.040000000000040996, -30.340000000000018, -2.2300000000000804, 0.9299999999999827, -0.07000000000004011, -5.090000000000083, 1.820000000000003, -6.120000000000083, -5.090000000000082, -0.04000000000004011, 0.9699999999999819, -12.210000000000079, -11.170000000000082, -1.0500000000000613, 3.9999999999999587, 2.9699999999999815, 3.859999999999962, 1.9500000000000028, -27.309999999999466, 2.9199999999999826, -3.1400000000000814, -17.209999999999408, -3.070000000000075, 1.920000000000003, 3.93999999999996, -3.070000000000083, -0.08000000000004011, -5.090000000000083, 1.9800000000000026, -6.100000000000083, -26.299999999999446, -16.219999999999438, 2.939999999999982, -8.120000000000083, -18.239999999999423, -12.240000000000077, -15.18999999999959, -27.31999999999943, -13.169999999999916, -16.239999999999515, -2.060000000000084, 1.9300000000000028, -32.36000000000056, -12.15000000000008, 0.9299999999999827, -4.190000000000069, 1.9400000000000026, -14.189999999999742, -14.17999999999976, -25.319999999999457, -2.060000000000083, 3.9999999999999587, 3.9999999999999587, 3.9999999999999587, -10.27000000000008, -13.240000000000004, -2.060000000000083, 2.909999999999983], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-16.0899999999997, -2.020000000000042, -10.060000000000041, -2.020000000000042, -0.00999999999999836, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, -8.050000000000042, -40.210000000000356, -22.119999999999738, -8.050000000000042, -0.00999999999999836, -14.080000000000036, -12.070000000000041, -2.020000000000042, -80.40999999999943, -16.0899999999997, -28.14999999999972, -10.060000000000041, 2.0000000000000013, 2.0000000000000013, -2.0200000000000373, -16.089999999999755, -8.050000000000042, -2.020000000000042, -14.080000000000041, -26.139999999999723, -2.020000000000042, -12.070000000000041, -12.070000000000041, -18.099999999999703, -10.060000000000041, -34.18000000000036, -16.089999999999762, -32.170000000000364, -50.26000000000034, -8.050000000000042, -40.21000000000033, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, -14.080000000000041, -8.050000000000042, -6.040000000000042, 2.0000000000000013, -30.159999999999716, -14.080000000000041, -22.119999999999717, -16.0899999999997, 2.0000000000000013, 2.0000000000000013, -22.119999999999706, -42.220000000000354, -42.22000000000029, -10.060000000000041, -6.040000000000042, 2.0000000000000013, -10.060000000000041, -6.040000000000042, 2.0000000000000013, -2.020000000000042, -24.129999999999733, -14.080000000000037, -8.050000000000042, -18.099999999999707, -18.09999999999978, -14.080000000000041, -32.170000000000336, -0.00999999999999836, -16.089999999999726, -6.040000000000042, -4.030000000000042, -18.099999999999707, -10.060000000000041, -2.020000000000042, -4.030000000000042, -28.14999999999971, -28.149999999999732, -20.109999999999726, -34.180000000000355, -8.050000000000042, -34.18000000000036, -6.040000000000042, 2.0000000000000013, -2.020000000000042, -62.3200000000003, -0.00999999999999836, -42.220000000000354, 2.0000000000000013, -12.070000000000041, -12.070000000000041, 2.0000000000000013, -8.050000000000042, -6.040000000000042, 2.0000000000000013, -34.18000000000036, -14.080000000000041, -6.040000000000042, -16.08999999999971, 2.0000000000000013, 2.0000000000000013, -6.040000000000042, 2.0000000000000013, -4.030000000000042, -14.080000000000041, -24.12999999999972, -12.070000000000041, -18.099999999999703, -0.00999999999999836, -6.040000000000041, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, -4.030000000000042, -26.13999999999971, 2.0000000000000013, -8.050000000000042, 2.0000000000000013, -54.280000000000314, -4.030000000000042, -14.080000000000041, 2.0000000000000013, 2.0000000000000013, -26.13999999999971, -20.109999999999705, -18.099999999999703, -0.00999999999999836, -10.060000000000041, 2.0000000000000013, -14.080000000000041, -10.060000000000041, 2.0000000000000013, 2.0000000000000013, -12.070000000000041, -8.050000000000042, -4.030000000000041, -16.0899999999997, 2.0000000000000013, -2.020000000000042, 2.0000000000000013, -4.030000000000042, -12.070000000000041, -36.19000000000029, -20.109999999999705, -42.220000000000354, 2.0000000000000013, 2.0000000000000013, -10.060000000000041, -2.020000000000042, -18.099999999999714, -8.050000000000042, -36.19000000000036, -22.119999999999717, -22.119999999999706, -30.159999999999723, -4.030000000000042, -22.119999999999706, -38.20000000000036, -22.119999999999706, -8.050000000000042, -16.0899999999997, -28.149999999999757, -6.040000000000042, -2.020000000000042, -12.070000000000041, 2.0000000000000013, -58.30000000000028, -10.060000000000041, -10.060000000000041, -16.0899999999997, 2.0000000000000013, -12.070000000000041, -22.11999999999976, -12.070000000000041, -10.060000000000041, 2.0000000000000013, -12.070000000000041, -22.11999999999971, -0.00999999999999836, -32.170000000000364, -56.29000000000033, -4.030000000000042, 2.0000000000000013, -10.060000000000041, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, -12.070000000000041, -38.20000000000033, -2.020000000000042, -42.22000000000032, 2.0000000000000013, -10.060000000000041, -16.0899999999997, 2.0000000000000013], "policy_predator_policy_reward": [2.0, 9.0, 6.0, 2.0, 0.0, 1.0, 0.0, 0.0, 2.0, 5.0, 8.0, 25.0, 5.0, 1.0, 3.0, 12.0, 39.0, 35.0, 17.0, 7.0, 6.0, 0.0, 0.0, 2.0, 10.0, 8.0, 8.0, 4.0, 8.0, 8.0, 7.0, 7.0, 6.0, 10.0, 26.0, 1.0, 30.0, 20.0, 20.0, 16.0, 0.0, 0.0, 8.0, 2.0, 4.0, 5.0, 16.0, 0.0, 5.0, 15.0, 9.0, 9.0, 12.0, 10.0, 17.0, 41.0, 6.0, 4.0, 0.0, 6.0, 4.0, 0.0, 12.0, 6.0, 13.0, 0.0, 13.0, 16.0, 20.0, 10.0, 1.0, 9.0, 3.0, 4.0, 2.0, 12.0, 2.0, 3.0, 11.0, 24.0, 0.0, 20.0, 9.0, 18.0, 4.0, 0.0, 20.0, 14.0, 20.0, 20.0, 4.0, 7.0, 4.0, 6.0, 5.0, 4.0, 17.0, 17.0, 8.0, 6.0, 1.0, 8.0, 0.0, 4.0, 3.0, 0.0, 15.0, 11.0, 10.0, 9.0, 1.0, 4.0, 0.0, 0.0, 2.0, 3.0, 14.0, 14.0, 3.0, 5.0, 15.0, 16.0, 8.0, 7.0, 13.0, 8.0, 10.0, 11.0, 5.0, 2.0, 6.0, 8.0, 6.0, 6.0, 0.0, 7.0, 5.0, 7.0, 0.0, 9.0, 2.0, 0.0, 3.0, 7.0, 10.0, 20.0, 22.0, 2.0, 5.0, 6.0, 4.0, 8.0, 12.0, 14.0, 18.0, 14.0, 1.0, 18.0, 14.0, 19.0, 5.0, 12.0, 4.0, 24.0, 2.0, 4.0, 5.0, 7.0, 0.0, 36.0, 9.0, 5.0, 7.0, 4.0, 13.0, 17.0, 6.0, 4.0, 11.0, 9.0, 17.0, 1.0, 9.0, 26.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 17.0, 14.0, 6.0, 0.0, 9.0, 8.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5965175451880157, "mean_inference_ms": 1.8777827966526326, "mean_action_processing_ms": 0.2525544805519615, "mean_env_wait_ms": 0.19472794108331307, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006134510040283203, "StateBufferConnector_ms": 0.0030080080032348633, "ViewRequirementAgentConnector_ms": 0.09009361267089844}, "num_episodes": 22, "episode_return_max": 3.9999999999999587, "episode_return_min": -34.2900000000007, "episode_return_mean": -7.572399999999964, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 784000, "num_agent_steps_trained": 784000, "num_env_steps_sampled": 196000, "num_env_steps_trained": 196000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 380.3776021533217, "num_env_steps_trained_throughput_per_sec": 380.3776021533217, "timesteps_total": 196000, "num_env_steps_sampled_lifetime": 196000, "num_agent_steps_sampled_lifetime": 784000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 784000, "timers": {"training_iteration_time_ms": 25554.924, "restore_workers_time_ms": 0.013, "training_step_time_ms": 25554.836, "sample_time_ms": 1311.65, "learn_time_ms": 24226.487, "learn_throughput": 165.109, "synch_weights_time_ms": 15.265}, "counters": {"num_env_steps_sampled": 196000, "num_env_steps_trained": 196000, "num_agent_steps_sampled": 784000, "num_agent_steps_trained": 784000}, "done": false, "training_iteration": 49, "trial_id": "8e499_00000", "date": "2024-08-15_02-15-33", "timestamp": 1723668333, "time_this_iter_s": 10.569940090179443, "time_total_s": 673.3705625534058, "pid": 33199, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x15810cd30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 673.3705625534058, "iterations_since_restore": 49, "perf": {"cpu_util_percent": 39.126666666666665, "ram_util_percent": 83.45333333333333}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2744277005867353, "cur_kl_coeff": 0.028125000000000008, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.4995803270548109, "policy_loss": -0.00722855372383954, "vf_loss": 0.5066406278107217, "vf_explained_var": 0.04006609494093234, "kl": 0.005982344932103859, "entropy": 0.7361023327030202, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 93555.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8433657327814708, "cur_kl_coeff": 0.03749999999999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.45519843061526044, "policy_loss": -0.008321815999668268, "vf_loss": 0.46319039116179933, "vf_explained_var": 0.09111338018109559, "kl": 0.008796133339387122, "entropy": 0.8435278615308186, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 93555.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 200000, "num_env_steps_trained": 200000, "num_agent_steps_sampled": 800000, "num_agent_steps_trained": 800000}, "env_runners": {"episode_reward_max": 3.9999999999999587, "episode_reward_min": -41.450000000000614, "episode_reward_mean": -6.5909999999999584, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -80.40999999999921, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 2.0000000000000013, "predator_policy": 41.0}, "policy_reward_mean": {"prey_policy": -11.165499999999984, "predator_policy": 7.87}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-12.160000000000078, -16.19999999999943, 3.9099999999999606, 1.8800000000000026, -26.439999999999472, -6.100000000000083, -2.060000000000083, -0.040000000000040996, -8.150000000000075, -9.13000000000008, -7.200000000000079, -16.249999999999464, -6.100000000000083, -3.0700000000000838, -14.159999999999739, -1.050000000000063, -21.299999999999457, -34.2900000000007, -15.229999999999567, -0.040000000000040996, -30.340000000000018, -2.2300000000000804, 0.9299999999999827, -0.07000000000004011, -5.090000000000083, 1.820000000000003, -6.120000000000083, -5.090000000000082, -0.04000000000004011, 0.9699999999999819, -12.210000000000079, -11.170000000000082, -1.0500000000000613, 3.9999999999999587, 2.9699999999999815, 3.859999999999962, 1.9500000000000028, -27.309999999999466, 2.9199999999999826, -3.1400000000000814, -17.209999999999408, -3.070000000000075, 1.920000000000003, 3.93999999999996, -3.070000000000083, -0.08000000000004011, -5.090000000000083, 1.9800000000000026, -6.100000000000083, -26.299999999999446, -16.219999999999438, 2.939999999999982, -8.120000000000083, -18.239999999999423, -12.240000000000077, -15.18999999999959, -27.31999999999943, -13.169999999999916, -16.239999999999515, -2.060000000000084, 1.9300000000000028, -32.36000000000056, -12.15000000000008, 0.9299999999999827, -4.190000000000069, 1.9400000000000026, -14.189999999999742, -14.17999999999976, -25.319999999999457, -2.060000000000083, 3.9999999999999587, 3.9999999999999587, 3.9999999999999587, -10.27000000000008, -13.240000000000004, -2.060000000000083, 2.909999999999983, -25.289999999999424, -0.10000000000003921, 1.980000000000003, 0.9499999999999819, -41.450000000000614, -0.0900000000000401, 1.910000000000002, 0.909999999999996, 2.989999999999981, 0.9699999999999854, -8.120000000000083, -12.160000000000082, 1.980000000000003, 0.9599999999999828, 1.9500000000000028, -20.229999999999425, -8.130000000000082, 0.9599999999999819, 0.9699999999999819, -1.1100000000000614, 3.9599999999999596, 0.969999999999981, 2.989999999999981], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [2.0000000000000013, -30.159999999999716, -14.080000000000041, -22.119999999999717, -16.0899999999997, 2.0000000000000013, 2.0000000000000013, -22.119999999999706, -42.220000000000354, -42.22000000000029, -10.060000000000041, -6.040000000000042, 2.0000000000000013, -10.060000000000041, -6.040000000000042, 2.0000000000000013, -2.020000000000042, -24.129999999999733, -14.080000000000037, -8.050000000000042, -18.099999999999707, -18.09999999999978, -14.080000000000041, -32.170000000000336, -0.00999999999999836, -16.089999999999726, -6.040000000000042, -4.030000000000042, -18.099999999999707, -10.060000000000041, -2.020000000000042, -4.030000000000042, -28.14999999999971, -28.149999999999732, -20.109999999999726, -34.180000000000355, -8.050000000000042, -34.18000000000036, -6.040000000000042, 2.0000000000000013, -2.020000000000042, -62.3200000000003, -0.00999999999999836, -42.220000000000354, 2.0000000000000013, -12.070000000000041, -12.070000000000041, 2.0000000000000013, -8.050000000000042, -6.040000000000042, 2.0000000000000013, -34.18000000000036, -14.080000000000041, -6.040000000000042, -16.08999999999971, 2.0000000000000013, 2.0000000000000013, -6.040000000000042, 2.0000000000000013, -4.030000000000042, -14.080000000000041, -24.12999999999972, -12.070000000000041, -18.099999999999703, -0.00999999999999836, -6.040000000000041, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, -4.030000000000042, -26.13999999999971, 2.0000000000000013, -8.050000000000042, 2.0000000000000013, -54.280000000000314, -4.030000000000042, -14.080000000000041, 2.0000000000000013, 2.0000000000000013, -26.13999999999971, -20.109999999999705, -18.099999999999703, -0.00999999999999836, -10.060000000000041, 2.0000000000000013, -14.080000000000041, -10.060000000000041, 2.0000000000000013, 2.0000000000000013, -12.070000000000041, -8.050000000000042, -4.030000000000041, -16.0899999999997, 2.0000000000000013, -2.020000000000042, 2.0000000000000013, -4.030000000000042, -12.070000000000041, -36.19000000000029, -20.109999999999705, -42.220000000000354, 2.0000000000000013, 2.0000000000000013, -10.060000000000041, -2.020000000000042, -18.099999999999714, -8.050000000000042, -36.19000000000036, -22.119999999999717, -22.119999999999706, -30.159999999999723, -4.030000000000042, -22.119999999999706, -38.20000000000036, -22.119999999999706, -8.050000000000042, -16.0899999999997, -28.149999999999757, -6.040000000000042, -2.020000000000042, -12.070000000000041, 2.0000000000000013, -58.30000000000028, -10.060000000000041, -10.060000000000041, -16.0899999999997, 2.0000000000000013, -12.070000000000041, -22.11999999999976, -12.070000000000041, -10.060000000000041, 2.0000000000000013, -12.070000000000041, -22.11999999999971, -0.00999999999999836, -32.170000000000364, -56.29000000000033, -4.030000000000042, 2.0000000000000013, -10.060000000000041, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, -12.070000000000041, -38.20000000000033, -2.020000000000042, -42.22000000000032, 2.0000000000000013, -10.060000000000041, -16.0899999999997, 2.0000000000000013, -44.23000000000025, -10.060000000000041, 2.0000000000000013, -18.099999999999703, -2.020000000000042, 2.0000000000000013, -8.050000000000042, 2.0000000000000013, -6.040000000000042, -80.40999999999921, -0.00999999999999836, -14.080000000000041, -16.0899999999997, 2.0000000000000013, 2.0000000000000013, -16.089999999999755, 2.0000000000000013, -0.00999999999999836, 2.0000000000000013, -4.03000000000004, -22.119999999999745, 2.0000000000000013, -2.020000000000042, -26.139999999999773, 2.0000000000000013, -2.020000000000042, -6.040000000000042, 2.0000000000000013, -8.050000000000042, 2.0000000000000013, -12.070000000000041, -30.159999999999716, -24.129999999999708, 2.0000000000000013, 2.0000000000000013, -6.040000000000042, 2.0000000000000013, -4.030000000000042, -20.109999999999705, 2.0000000000000013, 2.0000000000000013, -6.040000000000042, -0.00999999999999836, -2.020000000000042, 2.0000000000000013, -0.00999999999999836], "policy_predator_policy_reward": [16.0, 0.0, 5.0, 15.0, 9.0, 9.0, 12.0, 10.0, 17.0, 41.0, 6.0, 4.0, 0.0, 6.0, 4.0, 0.0, 12.0, 6.0, 13.0, 0.0, 13.0, 16.0, 20.0, 10.0, 1.0, 9.0, 3.0, 4.0, 2.0, 12.0, 2.0, 3.0, 11.0, 24.0, 0.0, 20.0, 9.0, 18.0, 4.0, 0.0, 20.0, 14.0, 20.0, 20.0, 4.0, 7.0, 4.0, 6.0, 5.0, 4.0, 17.0, 17.0, 8.0, 6.0, 1.0, 8.0, 0.0, 4.0, 3.0, 0.0, 15.0, 11.0, 10.0, 9.0, 1.0, 4.0, 0.0, 0.0, 2.0, 3.0, 14.0, 14.0, 3.0, 5.0, 15.0, 16.0, 8.0, 7.0, 13.0, 8.0, 10.0, 11.0, 5.0, 2.0, 6.0, 8.0, 6.0, 6.0, 0.0, 7.0, 5.0, 7.0, 0.0, 9.0, 2.0, 0.0, 3.0, 7.0, 10.0, 20.0, 22.0, 2.0, 5.0, 6.0, 4.0, 8.0, 12.0, 14.0, 18.0, 14.0, 1.0, 18.0, 14.0, 19.0, 5.0, 12.0, 4.0, 24.0, 2.0, 4.0, 5.0, 7.0, 0.0, 36.0, 9.0, 5.0, 7.0, 4.0, 13.0, 17.0, 6.0, 4.0, 11.0, 9.0, 17.0, 1.0, 9.0, 26.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 17.0, 14.0, 6.0, 0.0, 9.0, 8.0, 16.0, 13.0, 6.0, 10.0, 2.0, 0.0, 2.0, 5.0, 4.0, 41.0, 7.0, 7.0, 9.0, 7.0, 6.0, 9.0, 0.0, 1.0, 0.0, 3.0, 7.0, 5.0, 7.0, 9.0, 2.0, 0.0, 3.0, 2.0, 3.0, 5.0, 18.0, 4.0, 11.0, 3.0, 1.0, 4.0, 0.0, 3.0, 10.0, 7.0, 4.0, 4.0, 1.0, 2.0, 0.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5957893736140583, "mean_inference_ms": 1.8752234536789163, "mean_action_processing_ms": 0.25279024956963053, "mean_env_wait_ms": 0.19448734839085155, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006633877754211426, "StateBufferConnector_ms": 0.0030336380004882812, "ViewRequirementAgentConnector_ms": 0.09240126609802246}, "num_episodes": 23, "episode_return_max": 3.9999999999999587, "episode_return_min": -41.450000000000614, "episode_return_mean": -6.5909999999999584, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 800000, "num_agent_steps_trained": 800000, "num_env_steps_sampled": 200000, "num_env_steps_trained": 200000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 389.41901552417244, "num_env_steps_trained_throughput_per_sec": 389.41901552417244, "timesteps_total": 200000, "num_env_steps_sampled_lifetime": 200000, "num_agent_steps_sampled_lifetime": 800000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 800000, "timers": {"training_iteration_time_ms": 25551.103, "restore_workers_time_ms": 0.014, "training_step_time_ms": 25551.015, "sample_time_ms": 1310.867, "learn_time_ms": 24223.414, "learn_throughput": 165.129, "synch_weights_time_ms": 15.277}, "counters": {"num_env_steps_sampled": 200000, "num_env_steps_trained": 200000, "num_agent_steps_sampled": 800000, "num_agent_steps_trained": 800000}, "done": false, "training_iteration": 50, "trial_id": "8e499_00000", "date": "2024-08-15_02-15-44", "timestamp": 1723668344, "time_this_iter_s": 10.279787063598633, "time_total_s": 683.6503496170044, "pid": 33199, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x15810cdc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 683.6503496170044, "iterations_since_restore": 50, "perf": {"cpu_util_percent": 30.060000000000002, "ram_util_percent": 83.54666666666665}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2246524772946796, "cur_kl_coeff": 0.028125000000000008, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.2230949995694338, "policy_loss": -0.005336346875422846, "vf_loss": 1.2282038120207963, "vf_explained_var": 0.0038223455507288536, "kl": 0.00809000693623054, "entropy": 0.7413299140160676, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 95445.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.024306932943208, "cur_kl_coeff": 0.03749999999999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.0618202957842084, "policy_loss": -0.017612384663520272, "vf_loss": 1.0789429881900707, "vf_explained_var": 0.08434968524509007, "kl": 0.013058401006445184, "entropy": 0.8803473846622245, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 95445.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 204000, "num_env_steps_trained": 204000, "num_agent_steps_sampled": 816000, "num_agent_steps_trained": 816000}, "env_runners": {"episode_reward_max": 3.9999999999999587, "episode_reward_min": -96.99999999999888, "episode_reward_mean": -7.19409999999997, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -325.63000000000005, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 2.0000000000000013, "predator_policy": 159.0}, "policy_reward_mean": {"prey_policy": -13.487049999999995, "predator_policy": 9.89}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-15.229999999999567, -0.040000000000040996, -30.340000000000018, -2.2300000000000804, 0.9299999999999827, -0.07000000000004011, -5.090000000000083, 1.820000000000003, -6.120000000000083, -5.090000000000082, -0.04000000000004011, 0.9699999999999819, -12.210000000000079, -11.170000000000082, -1.0500000000000613, 3.9999999999999587, 2.9699999999999815, 3.859999999999962, 1.9500000000000028, -27.309999999999466, 2.9199999999999826, -3.1400000000000814, -17.209999999999408, -3.070000000000075, 1.920000000000003, 3.93999999999996, -3.070000000000083, -0.08000000000004011, -5.090000000000083, 1.9800000000000026, -6.100000000000083, -26.299999999999446, -16.219999999999438, 2.939999999999982, -8.120000000000083, -18.239999999999423, -12.240000000000077, -15.18999999999959, -27.31999999999943, -13.169999999999916, -16.239999999999515, -2.060000000000084, 1.9300000000000028, -32.36000000000056, -12.15000000000008, 0.9299999999999827, -4.190000000000069, 1.9400000000000026, -14.189999999999742, -14.17999999999976, -25.319999999999457, -2.060000000000083, 3.9999999999999587, 3.9999999999999587, 3.9999999999999587, -10.27000000000008, -13.240000000000004, -2.060000000000083, 2.909999999999983, -25.289999999999424, -0.10000000000003921, 1.980000000000003, 0.9499999999999819, -41.450000000000614, -0.0900000000000401, 1.910000000000002, 0.909999999999996, 2.989999999999981, 0.9699999999999854, -8.120000000000083, -12.160000000000082, 1.980000000000003, 0.9599999999999828, 1.9500000000000028, -20.229999999999425, -8.130000000000082, 0.9599999999999819, 0.9699999999999819, -1.1100000000000614, 3.9599999999999596, 0.969999999999981, 2.989999999999981, -33.37000000000056, 3.979999999999959, 0.969999999999981, -0.10000000000004099, -9.340000000000078, -11.150000000000082, -8.290000000000079, -10.240000000000078, -27.7299999999999, -0.06000000000004011, -96.99999999999888, -4.100000000000083, 3.9699999999999593, 1.960000000000003, -11.150000000000082, 1.9000000000000026, -8.120000000000083, -30.34999999999999], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-8.050000000000042, -34.18000000000036, -6.040000000000042, 2.0000000000000013, -2.020000000000042, -62.3200000000003, -0.00999999999999836, -42.220000000000354, 2.0000000000000013, -12.070000000000041, -12.070000000000041, 2.0000000000000013, -8.050000000000042, -6.040000000000042, 2.0000000000000013, -34.18000000000036, -14.080000000000041, -6.040000000000042, -16.08999999999971, 2.0000000000000013, 2.0000000000000013, -6.040000000000042, 2.0000000000000013, -4.030000000000042, -14.080000000000041, -24.12999999999972, -12.070000000000041, -18.099999999999703, -0.00999999999999836, -6.040000000000041, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, -4.030000000000042, -26.13999999999971, 2.0000000000000013, -8.050000000000042, 2.0000000000000013, -54.280000000000314, -4.030000000000042, -14.080000000000041, 2.0000000000000013, 2.0000000000000013, -26.13999999999971, -20.109999999999705, -18.099999999999703, -0.00999999999999836, -10.060000000000041, 2.0000000000000013, -14.080000000000041, -10.060000000000041, 2.0000000000000013, 2.0000000000000013, -12.070000000000041, -8.050000000000042, -4.030000000000041, -16.0899999999997, 2.0000000000000013, -2.020000000000042, 2.0000000000000013, -4.030000000000042, -12.070000000000041, -36.19000000000029, -20.109999999999705, -42.220000000000354, 2.0000000000000013, 2.0000000000000013, -10.060000000000041, -2.020000000000042, -18.099999999999714, -8.050000000000042, -36.19000000000036, -22.119999999999717, -22.119999999999706, -30.159999999999723, -4.030000000000042, -22.119999999999706, -38.20000000000036, -22.119999999999706, -8.050000000000042, -16.0899999999997, -28.149999999999757, -6.040000000000042, -2.020000000000042, -12.070000000000041, 2.0000000000000013, -58.30000000000028, -10.060000000000041, -10.060000000000041, -16.0899999999997, 2.0000000000000013, -12.070000000000041, -22.11999999999976, -12.070000000000041, -10.060000000000041, 2.0000000000000013, -12.070000000000041, -22.11999999999971, -0.00999999999999836, -32.170000000000364, -56.29000000000033, -4.030000000000042, 2.0000000000000013, -10.060000000000041, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, -12.070000000000041, -38.20000000000033, -2.020000000000042, -42.22000000000032, 2.0000000000000013, -10.060000000000041, -16.0899999999997, 2.0000000000000013, -44.23000000000025, -10.060000000000041, 2.0000000000000013, -18.099999999999703, -2.020000000000042, 2.0000000000000013, -8.050000000000042, 2.0000000000000013, -6.040000000000042, -80.40999999999921, -0.00999999999999836, -14.080000000000041, -16.0899999999997, 2.0000000000000013, 2.0000000000000013, -16.089999999999755, 2.0000000000000013, -0.00999999999999836, 2.0000000000000013, -4.03000000000004, -22.119999999999745, 2.0000000000000013, -2.020000000000042, -26.139999999999773, 2.0000000000000013, -2.020000000000042, -6.040000000000042, 2.0000000000000013, -8.050000000000042, 2.0000000000000013, -12.070000000000041, -30.159999999999716, -24.129999999999708, 2.0000000000000013, 2.0000000000000013, -6.040000000000042, 2.0000000000000013, -4.030000000000042, -20.109999999999705, 2.0000000000000013, 2.0000000000000013, -6.040000000000042, -0.00999999999999836, -2.020000000000042, 2.0000000000000013, -0.00999999999999836, -38.20000000000036, -32.17000000000027, -2.020000000000042, 2.0000000000000013, -4.030000000000042, 2.0000000000000013, -16.0899999999997, -0.00999999999999836, 2.0000000000000013, -66.33999999999916, -14.080000000000041, -12.070000000000041, -54.28000000000034, -0.00999999999999836, -46.24000000000034, 2.0000000000000013, -18.099999999999703, -325.63000000000005, 2.0000000000000013, -10.060000000000041, -182.92000000000093, -14.080000000000007, -14.080000000000041, -2.020000000000042, -4.030000000000042, 2.0000000000000013, -6.040000000000042, 2.0000000000000013, -14.080000000000041, -12.070000000000041, -18.099999999999703, 2.0000000000000013, 2.0000000000000013, -22.119999999999706, -20.109999999999705, -46.240000000000315], "policy_predator_policy_reward": [9.0, 18.0, 4.0, 0.0, 20.0, 14.0, 20.0, 20.0, 4.0, 7.0, 4.0, 6.0, 5.0, 4.0, 17.0, 17.0, 8.0, 6.0, 1.0, 8.0, 0.0, 4.0, 3.0, 0.0, 15.0, 11.0, 10.0, 9.0, 1.0, 4.0, 0.0, 0.0, 2.0, 3.0, 14.0, 14.0, 3.0, 5.0, 15.0, 16.0, 8.0, 7.0, 13.0, 8.0, 10.0, 11.0, 5.0, 2.0, 6.0, 8.0, 6.0, 6.0, 0.0, 7.0, 5.0, 7.0, 0.0, 9.0, 2.0, 0.0, 3.0, 7.0, 10.0, 20.0, 22.0, 2.0, 5.0, 6.0, 4.0, 8.0, 12.0, 14.0, 18.0, 14.0, 1.0, 18.0, 14.0, 19.0, 5.0, 12.0, 4.0, 24.0, 2.0, 4.0, 5.0, 7.0, 0.0, 36.0, 9.0, 5.0, 7.0, 4.0, 13.0, 17.0, 6.0, 4.0, 11.0, 9.0, 17.0, 1.0, 9.0, 26.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 17.0, 14.0, 6.0, 0.0, 9.0, 8.0, 16.0, 13.0, 6.0, 10.0, 2.0, 0.0, 2.0, 5.0, 4.0, 41.0, 7.0, 7.0, 9.0, 7.0, 6.0, 9.0, 0.0, 1.0, 0.0, 3.0, 7.0, 5.0, 7.0, 9.0, 2.0, 0.0, 3.0, 2.0, 3.0, 5.0, 18.0, 4.0, 11.0, 3.0, 1.0, 4.0, 0.0, 3.0, 10.0, 7.0, 4.0, 4.0, 1.0, 2.0, 0.0, 1.0, 27.0, 10.0, 2.0, 2.0, 3.0, 0.0, 7.0, 9.0, 27.0, 28.0, 7.0, 8.0, 27.0, 19.0, 12.0, 22.0, 159.0, 157.0, 6.0, 2.0, 0.0, 100.0, 5.0, 7.0, 3.0, 3.0, 2.0, 4.0, 7.0, 8.0, 10.0, 8.0, 0.0, 12.0, 21.0, 15.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5946394554728981, "mean_inference_ms": 1.8728196925662122, "mean_action_processing_ms": 0.2520037884369675, "mean_env_wait_ms": 0.19408610159944678, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006279706954956055, "StateBufferConnector_ms": 0.003103971481323242, "ViewRequirementAgentConnector_ms": 0.09688568115234375}, "num_episodes": 18, "episode_return_max": 3.9999999999999587, "episode_return_min": -96.99999999999888, "episode_return_mean": -7.19409999999997, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 816000, "num_agent_steps_trained": 816000, "num_env_steps_sampled": 204000, "num_env_steps_trained": 204000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 12.903742756351486, "num_env_steps_trained_throughput_per_sec": 12.903742756351486, "timesteps_total": 204000, "num_env_steps_sampled_lifetime": 204000, "num_agent_steps_sampled_lifetime": 816000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 816000, "timers": {"training_iteration_time_ms": 55528.047, "restore_workers_time_ms": 0.014, "training_step_time_ms": 55527.958, "sample_time_ms": 1317.119, "learn_time_ms": 54193.871, "learn_throughput": 73.809, "synch_weights_time_ms": 15.225}, "counters": {"num_env_steps_sampled": 204000, "num_env_steps_trained": 204000, "num_agent_steps_sampled": 816000, "num_agent_steps_trained": 816000}, "done": false, "training_iteration": 51, "trial_id": "8e499_00000", "date": "2024-08-15_02-20-54", "timestamp": 1723668654, "time_this_iter_s": 310.0438940525055, "time_total_s": 993.6942436695099, "pid": 33199, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x1580bed30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 993.6942436695099, "iterations_since_restore": 51, "perf": {"cpu_util_percent": 35.800000000000004, "ram_util_percent": 83.6375}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.295837320111416, "cur_kl_coeff": 0.028125000000000008, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.5132194683665321, "policy_loss": -0.002657068534335368, "vf_loss": 0.5156440595490119, "vf_explained_var": 0.031053864798217853, "kl": 0.008265815889938091, "entropy": 0.8727869426131879, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 97335.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9123601735111266, "cur_kl_coeff": 0.03749999999999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.41986451429664773, "policy_loss": -0.010168217081655427, "vf_loss": 0.42974117925832855, "vf_explained_var": 0.040596735319763266, "kl": 0.007774707187351795, "entropy": 0.8517152187054751, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 97335.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 208000, "num_env_steps_trained": 208000, "num_agent_steps_sampled": 832000, "num_agent_steps_trained": 832000}, "env_runners": {"episode_reward_max": 3.9999999999999587, "episode_reward_min": -132.4599999999998, "episode_reward_mean": -8.70579999999995, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -325.63000000000005, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 2.0000000000000013, "predator_policy": 159.0}, "policy_reward_mean": {"prey_policy": -14.66289999999999, "predator_policy": 10.31}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.9500000000000028, -27.309999999999466, 2.9199999999999826, -3.1400000000000814, -17.209999999999408, -3.070000000000075, 1.920000000000003, 3.93999999999996, -3.070000000000083, -0.08000000000004011, -5.090000000000083, 1.9800000000000026, -6.100000000000083, -26.299999999999446, -16.219999999999438, 2.939999999999982, -8.120000000000083, -18.239999999999423, -12.240000000000077, -15.18999999999959, -27.31999999999943, -13.169999999999916, -16.239999999999515, -2.060000000000084, 1.9300000000000028, -32.36000000000056, -12.15000000000008, 0.9299999999999827, -4.190000000000069, 1.9400000000000026, -14.189999999999742, -14.17999999999976, -25.319999999999457, -2.060000000000083, 3.9999999999999587, 3.9999999999999587, 3.9999999999999587, -10.27000000000008, -13.240000000000004, -2.060000000000083, 2.909999999999983, -25.289999999999424, -0.10000000000003921, 1.980000000000003, 0.9499999999999819, -41.450000000000614, -0.0900000000000401, 1.910000000000002, 0.909999999999996, 2.989999999999981, 0.9699999999999854, -8.120000000000083, -12.160000000000082, 1.980000000000003, 0.9599999999999828, 1.9500000000000028, -20.229999999999425, -8.130000000000082, 0.9599999999999819, 0.9699999999999819, -1.1100000000000614, 3.9599999999999596, 0.969999999999981, 2.989999999999981, -33.37000000000056, 3.979999999999959, 0.969999999999981, -0.10000000000004099, -9.340000000000078, -11.150000000000082, -8.290000000000079, -10.240000000000078, -27.7299999999999, -0.06000000000004011, -96.99999999999888, -4.100000000000083, 3.9699999999999593, 1.960000000000003, -11.150000000000082, 1.9000000000000026, -8.120000000000083, -30.34999999999999, -132.4599999999998, 3.9999999999999587, -5.090000000000083, -1.0600000000000631, 0.9299999999999827, -14.209999999999749, -16.19999999999956, 0.969999999999981, 1.9700000000000029, -2.060000000000083, -21.24999999999943, 1.870000000000001, -6.100000000000083, -16.1499999999994, -7.210000000000077, -5.090000000000083, 1.980000000000003, -10.140000000000082], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-8.050000000000042, 2.0000000000000013, -54.280000000000314, -4.030000000000042, -14.080000000000041, 2.0000000000000013, 2.0000000000000013, -26.13999999999971, -20.109999999999705, -18.099999999999703, -0.00999999999999836, -10.060000000000041, 2.0000000000000013, -14.080000000000041, -10.060000000000041, 2.0000000000000013, 2.0000000000000013, -12.070000000000041, -8.050000000000042, -4.030000000000041, -16.0899999999997, 2.0000000000000013, -2.020000000000042, 2.0000000000000013, -4.030000000000042, -12.070000000000041, -36.19000000000029, -20.109999999999705, -42.220000000000354, 2.0000000000000013, 2.0000000000000013, -10.060000000000041, -2.020000000000042, -18.099999999999714, -8.050000000000042, -36.19000000000036, -22.119999999999717, -22.119999999999706, -30.159999999999723, -4.030000000000042, -22.119999999999706, -38.20000000000036, -22.119999999999706, -8.050000000000042, -16.0899999999997, -28.149999999999757, -6.040000000000042, -2.020000000000042, -12.070000000000041, 2.0000000000000013, -58.30000000000028, -10.060000000000041, -10.060000000000041, -16.0899999999997, 2.0000000000000013, -12.070000000000041, -22.11999999999976, -12.070000000000041, -10.060000000000041, 2.0000000000000013, -12.070000000000041, -22.11999999999971, -0.00999999999999836, -32.170000000000364, -56.29000000000033, -4.030000000000042, 2.0000000000000013, -10.060000000000041, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, -12.070000000000041, -38.20000000000033, -2.020000000000042, -42.22000000000032, 2.0000000000000013, -10.060000000000041, -16.0899999999997, 2.0000000000000013, -44.23000000000025, -10.060000000000041, 2.0000000000000013, -18.099999999999703, -2.020000000000042, 2.0000000000000013, -8.050000000000042, 2.0000000000000013, -6.040000000000042, -80.40999999999921, -0.00999999999999836, -14.080000000000041, -16.0899999999997, 2.0000000000000013, 2.0000000000000013, -16.089999999999755, 2.0000000000000013, -0.00999999999999836, 2.0000000000000013, -4.03000000000004, -22.119999999999745, 2.0000000000000013, -2.020000000000042, -26.139999999999773, 2.0000000000000013, -2.020000000000042, -6.040000000000042, 2.0000000000000013, -8.050000000000042, 2.0000000000000013, -12.070000000000041, -30.159999999999716, -24.129999999999708, 2.0000000000000013, 2.0000000000000013, -6.040000000000042, 2.0000000000000013, -4.030000000000042, -20.109999999999705, 2.0000000000000013, 2.0000000000000013, -6.040000000000042, -0.00999999999999836, -2.020000000000042, 2.0000000000000013, -0.00999999999999836, -38.20000000000036, -32.17000000000027, -2.020000000000042, 2.0000000000000013, -4.030000000000042, 2.0000000000000013, -16.0899999999997, -0.00999999999999836, 2.0000000000000013, -66.33999999999916, -14.080000000000041, -12.070000000000041, -54.28000000000034, -0.00999999999999836, -46.24000000000034, 2.0000000000000013, -18.099999999999703, -325.63000000000005, 2.0000000000000013, -10.060000000000041, -182.92000000000093, -14.080000000000007, -14.080000000000041, -2.020000000000042, -4.030000000000042, 2.0000000000000013, -6.040000000000042, 2.0000000000000013, -14.080000000000041, -12.070000000000041, -18.099999999999703, 2.0000000000000013, 2.0000000000000013, -22.119999999999706, -20.109999999999705, -46.240000000000315, -291.46000000000015, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, -4.030000000000042, -10.060000000000041, -10.060000000000041, 2.0000000000000013, 2.0000000000000013, -12.070000000000041, -6.040000000000042, -32.170000000000364, -6.040000000000042, -30.15999999999978, -4.030000000000042, 2.0000000000000013, -4.030000000000042, 2.0000000000000013, 2.0000000000000013, -10.060000000000041, -34.180000000000355, -12.070000000000041, 2.0000000000000013, -24.129999999999708, -6.040000000000042, -10.060000000000041, -18.099999999999703, -8.05000000000004, -18.099999999999703, -20.109999999999722, -14.080000000000041, -0.00999999999999836, -2.020000000000037, 2.0000000000000013, -16.0899999999997, -8.050000000000042], "policy_predator_policy_reward": [3.0, 5.0, 15.0, 16.0, 8.0, 7.0, 13.0, 8.0, 10.0, 11.0, 5.0, 2.0, 6.0, 8.0, 6.0, 6.0, 0.0, 7.0, 5.0, 7.0, 0.0, 9.0, 2.0, 0.0, 3.0, 7.0, 10.0, 20.0, 22.0, 2.0, 5.0, 6.0, 4.0, 8.0, 12.0, 14.0, 18.0, 14.0, 1.0, 18.0, 14.0, 19.0, 5.0, 12.0, 4.0, 24.0, 2.0, 4.0, 5.0, 7.0, 0.0, 36.0, 9.0, 5.0, 7.0, 4.0, 13.0, 17.0, 6.0, 4.0, 11.0, 9.0, 17.0, 1.0, 9.0, 26.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 17.0, 14.0, 6.0, 0.0, 9.0, 8.0, 16.0, 13.0, 6.0, 10.0, 2.0, 0.0, 2.0, 5.0, 4.0, 41.0, 7.0, 7.0, 9.0, 7.0, 6.0, 9.0, 0.0, 1.0, 0.0, 3.0, 7.0, 5.0, 7.0, 9.0, 2.0, 0.0, 3.0, 2.0, 3.0, 5.0, 18.0, 4.0, 11.0, 3.0, 1.0, 4.0, 0.0, 3.0, 10.0, 7.0, 4.0, 4.0, 1.0, 2.0, 0.0, 1.0, 27.0, 10.0, 2.0, 2.0, 3.0, 0.0, 7.0, 9.0, 27.0, 28.0, 7.0, 8.0, 27.0, 19.0, 12.0, 22.0, 159.0, 157.0, 6.0, 2.0, 0.0, 100.0, 5.0, 7.0, 3.0, 3.0, 2.0, 4.0, 7.0, 8.0, 10.0, 8.0, 0.0, 12.0, 21.0, 15.0, 13.0, 144.0, 0.0, 0.0, 6.0, 3.0, 6.0, 1.0, 4.0, 7.0, 10.0, 14.0, 3.0, 17.0, 0.0, 3.0, 3.0, 1.0, 6.0, 0.0, 18.0, 7.0, 12.0, 12.0, 6.0, 4.0, 0.0, 10.0, 10.0, 21.0, 8.0, 1.0, 1.0, 1.0, 5.0, 9.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5940455901268606, "mean_inference_ms": 1.8707560070818812, "mean_action_processing_ms": 0.25152733956429096, "mean_env_wait_ms": 0.19388393867838943, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005932211875915527, "StateBufferConnector_ms": 0.0030961036682128906, "ViewRequirementAgentConnector_ms": 0.09583902359008789}, "num_episodes": 18, "episode_return_max": 3.9999999999999587, "episode_return_min": -132.4599999999998, "episode_return_mean": -8.70579999999995, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 832000, "num_agent_steps_trained": 832000, "num_env_steps_sampled": 208000, "num_env_steps_trained": 208000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 397.60020073847414, "num_env_steps_trained_throughput_per_sec": 397.60020073847414, "timesteps_total": 208000, "num_env_steps_sampled_lifetime": 208000, "num_agent_steps_sampled_lifetime": 832000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 832000, "timers": {"training_iteration_time_ms": 54141.369, "restore_workers_time_ms": 0.014, "training_step_time_ms": 54141.28, "sample_time_ms": 1319.51, "learn_time_ms": 52805.731, "learn_throughput": 75.749, "synch_weights_time_ms": 14.356}, "counters": {"num_env_steps_sampled": 208000, "num_env_steps_trained": 208000, "num_agent_steps_sampled": 832000, "num_agent_steps_trained": 832000}, "done": false, "training_iteration": 52, "trial_id": "8e499_00000", "date": "2024-08-15_02-21-04", "timestamp": 1723668664, "time_this_iter_s": 10.065140962600708, "time_total_s": 1003.7593846321106, "pid": 33199, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x1580318b0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1003.7593846321106, "iterations_since_restore": 52, "perf": {"cpu_util_percent": 28.792857142857144, "ram_util_percent": 83.15714285714284}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.434444236786908, "cur_kl_coeff": 0.028125000000000008, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.49660244357806665, "policy_loss": -0.0037894677735431483, "vf_loss": 0.5002053161925345, "vf_explained_var": 0.10069047792878731, "kl": 0.006634528853112623, "entropy": 0.8847166025133991, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 99225.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1993888603474097, "cur_kl_coeff": 0.03749999999999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.4994748997182041, "policy_loss": -0.010986865600866695, "vf_loss": 0.510045645495374, "vf_explained_var": 0.1643073090485164, "kl": 0.011096457568269958, "entropy": 0.7976546198602706, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 99225.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 212000, "num_env_steps_trained": 212000, "num_agent_steps_sampled": 848000, "num_agent_steps_trained": 848000}, "env_runners": {"episode_reward_max": 3.9999999999999587, "episode_reward_min": -132.4599999999998, "episode_reward_mean": -9.373199999999978, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -325.63000000000005, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 2.0000000000000013, "predator_policy": 159.0}, "policy_reward_mean": {"prey_policy": -15.40659999999999, "predator_policy": 10.72}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-12.240000000000077, -15.18999999999959, -27.31999999999943, -13.169999999999916, -16.239999999999515, -2.060000000000084, 1.9300000000000028, -32.36000000000056, -12.15000000000008, 0.9299999999999827, -4.190000000000069, 1.9400000000000026, -14.189999999999742, -14.17999999999976, -25.319999999999457, -2.060000000000083, 3.9999999999999587, 3.9999999999999587, 3.9999999999999587, -10.27000000000008, -13.240000000000004, -2.060000000000083, 2.909999999999983, -25.289999999999424, -0.10000000000003921, 1.980000000000003, 0.9499999999999819, -41.450000000000614, -0.0900000000000401, 1.910000000000002, 0.909999999999996, 2.989999999999981, 0.9699999999999854, -8.120000000000083, -12.160000000000082, 1.980000000000003, 0.9599999999999828, 1.9500000000000028, -20.229999999999425, -8.130000000000082, 0.9599999999999819, 0.9699999999999819, -1.1100000000000614, 3.9599999999999596, 0.969999999999981, 2.989999999999981, -33.37000000000056, 3.979999999999959, 0.969999999999981, -0.10000000000004099, -9.340000000000078, -11.150000000000082, -8.290000000000079, -10.240000000000078, -27.7299999999999, -0.06000000000004011, -96.99999999999888, -4.100000000000083, 3.9699999999999593, 1.960000000000003, -11.150000000000082, 1.9000000000000026, -8.120000000000083, -30.34999999999999, -132.4599999999998, 3.9999999999999587, -5.090000000000083, -1.0600000000000631, 0.9299999999999827, -14.209999999999749, -16.19999999999956, 0.969999999999981, 1.9700000000000029, -2.060000000000083, -21.24999999999943, 1.870000000000001, -6.100000000000083, -16.1499999999994, -7.210000000000077, -5.090000000000083, 1.980000000000003, -10.140000000000082, -6.100000000000083, -2.060000000000083, -20.239999999999437, -9.14000000000008, -2.160000000000072, -13.249999999999904, -44.480000000000594, -28.319999999999435, -11.150000000000082, -7.110000000000083, -0.13000000000004008, -8.120000000000081, -10.140000000000082, -9.130000000000082, -4.23000000000008, -8.120000000000083, 0.9599999999999814, -2.120000000000081], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-22.119999999999717, -22.119999999999706, -30.159999999999723, -4.030000000000042, -22.119999999999706, -38.20000000000036, -22.119999999999706, -8.050000000000042, -16.0899999999997, -28.149999999999757, -6.040000000000042, -2.020000000000042, -12.070000000000041, 2.0000000000000013, -58.30000000000028, -10.060000000000041, -10.060000000000041, -16.0899999999997, 2.0000000000000013, -12.070000000000041, -22.11999999999976, -12.070000000000041, -10.060000000000041, 2.0000000000000013, -12.070000000000041, -22.11999999999971, -0.00999999999999836, -32.170000000000364, -56.29000000000033, -4.030000000000042, 2.0000000000000013, -10.060000000000041, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, -12.070000000000041, -38.20000000000033, -2.020000000000042, -42.22000000000032, 2.0000000000000013, -10.060000000000041, -16.0899999999997, 2.0000000000000013, -44.23000000000025, -10.060000000000041, 2.0000000000000013, -18.099999999999703, -2.020000000000042, 2.0000000000000013, -8.050000000000042, 2.0000000000000013, -6.040000000000042, -80.40999999999921, -0.00999999999999836, -14.080000000000041, -16.0899999999997, 2.0000000000000013, 2.0000000000000013, -16.089999999999755, 2.0000000000000013, -0.00999999999999836, 2.0000000000000013, -4.03000000000004, -22.119999999999745, 2.0000000000000013, -2.020000000000042, -26.139999999999773, 2.0000000000000013, -2.020000000000042, -6.040000000000042, 2.0000000000000013, -8.050000000000042, 2.0000000000000013, -12.070000000000041, -30.159999999999716, -24.129999999999708, 2.0000000000000013, 2.0000000000000013, -6.040000000000042, 2.0000000000000013, -4.030000000000042, -20.109999999999705, 2.0000000000000013, 2.0000000000000013, -6.040000000000042, -0.00999999999999836, -2.020000000000042, 2.0000000000000013, -0.00999999999999836, -38.20000000000036, -32.17000000000027, -2.020000000000042, 2.0000000000000013, -4.030000000000042, 2.0000000000000013, -16.0899999999997, -0.00999999999999836, 2.0000000000000013, -66.33999999999916, -14.080000000000041, -12.070000000000041, -54.28000000000034, -0.00999999999999836, -46.24000000000034, 2.0000000000000013, -18.099999999999703, -325.63000000000005, 2.0000000000000013, -10.060000000000041, -182.92000000000093, -14.080000000000007, -14.080000000000041, -2.020000000000042, -4.030000000000042, 2.0000000000000013, -6.040000000000042, 2.0000000000000013, -14.080000000000041, -12.070000000000041, -18.099999999999703, 2.0000000000000013, 2.0000000000000013, -22.119999999999706, -20.109999999999705, -46.240000000000315, -291.46000000000015, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, -4.030000000000042, -10.060000000000041, -10.060000000000041, 2.0000000000000013, 2.0000000000000013, -12.070000000000041, -6.040000000000042, -32.170000000000364, -6.040000000000042, -30.15999999999978, -4.030000000000042, 2.0000000000000013, -4.030000000000042, 2.0000000000000013, 2.0000000000000013, -10.060000000000041, -34.180000000000355, -12.070000000000041, 2.0000000000000013, -24.129999999999708, -6.040000000000042, -10.060000000000041, -18.099999999999703, -8.05000000000004, -18.099999999999703, -20.109999999999722, -14.080000000000041, -0.00999999999999836, -2.020000000000037, 2.0000000000000013, -16.0899999999997, -8.050000000000042, 2.0000000000000013, -18.099999999999703, 2.0000000000000013, -10.060000000000041, -44.23000000000035, -0.00999999999999836, -20.109999999999726, -4.030000000000042, -20.10999999999974, -8.050000000000042, -32.170000000000364, -14.080000000000041, -0.00999999999999836, -92.46999999999923, -12.070000000000041, -48.250000000000284, -10.060000000000041, -16.089999999999705, -14.080000000000041, -4.030000000000038, -24.129999999999708, 2.0000000000000013, -12.070000000000036, -8.050000000000042, -6.040000000000042, -18.099999999999703, -12.070000000000041, -10.060000000000041, -4.030000000000042, -38.20000000000036, -12.070000000000041, -8.050000000000042, -6.040000000000042, 2.0000000000000013, 2.0000000000000013, -22.119999999999706], "policy_predator_policy_reward": [18.0, 14.0, 1.0, 18.0, 14.0, 19.0, 5.0, 12.0, 4.0, 24.0, 2.0, 4.0, 5.0, 7.0, 0.0, 36.0, 9.0, 5.0, 7.0, 4.0, 13.0, 17.0, 6.0, 4.0, 11.0, 9.0, 17.0, 1.0, 9.0, 26.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 20.0, 17.0, 14.0, 6.0, 0.0, 9.0, 8.0, 16.0, 13.0, 6.0, 10.0, 2.0, 0.0, 2.0, 5.0, 4.0, 41.0, 7.0, 7.0, 9.0, 7.0, 6.0, 9.0, 0.0, 1.0, 0.0, 3.0, 7.0, 5.0, 7.0, 9.0, 2.0, 0.0, 3.0, 2.0, 3.0, 5.0, 18.0, 4.0, 11.0, 3.0, 1.0, 4.0, 0.0, 3.0, 10.0, 7.0, 4.0, 4.0, 1.0, 2.0, 0.0, 1.0, 27.0, 10.0, 2.0, 2.0, 3.0, 0.0, 7.0, 9.0, 27.0, 28.0, 7.0, 8.0, 27.0, 19.0, 12.0, 22.0, 159.0, 157.0, 6.0, 2.0, 0.0, 100.0, 5.0, 7.0, 3.0, 3.0, 2.0, 4.0, 7.0, 8.0, 10.0, 8.0, 0.0, 12.0, 21.0, 15.0, 13.0, 144.0, 0.0, 0.0, 6.0, 3.0, 6.0, 1.0, 4.0, 7.0, 10.0, 14.0, 3.0, 17.0, 0.0, 3.0, 3.0, 1.0, 6.0, 0.0, 18.0, 7.0, 12.0, 12.0, 6.0, 4.0, 0.0, 10.0, 10.0, 21.0, 8.0, 1.0, 1.0, 1.0, 5.0, 9.0, 0.0, 10.0, 0.0, 6.0, 19.0, 5.0, 11.0, 4.0, 15.0, 11.0, 17.0, 16.0, 47.0, 1.0, 17.0, 15.0, 9.0, 6.0, 0.0, 11.0, 12.0, 10.0, 5.0, 7.0, 4.0, 10.0, 7.0, 6.0, 20.0, 18.0, 7.0, 5.0, 1.0, 4.0, 12.0, 6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5933987857089421, "mean_inference_ms": 1.868049017976815, "mean_action_processing_ms": 0.25101802355737995, "mean_env_wait_ms": 0.19363224435017443, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005432009696960449, "StateBufferConnector_ms": 0.003072381019592285, "ViewRequirementAgentConnector_ms": 0.09531044960021973}, "num_episodes": 18, "episode_return_max": 3.9999999999999587, "episode_return_min": -132.4599999999998, "episode_return_mean": -9.373199999999978, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 848000, "num_agent_steps_trained": 848000, "num_env_steps_sampled": 212000, "num_env_steps_trained": 212000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 417.02774676547904, "num_env_steps_trained_throughput_per_sec": 417.02774676547904, "timesteps_total": 212000, "num_env_steps_sampled_lifetime": 212000, "num_agent_steps_sampled_lifetime": 848000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 848000, "timers": {"training_iteration_time_ms": 53939.224, "restore_workers_time_ms": 0.014, "training_step_time_ms": 53939.135, "sample_time_ms": 1284.464, "learn_time_ms": 52639.129, "learn_throughput": 75.989, "synch_weights_time_ms": 14.144}, "counters": {"num_env_steps_sampled": 212000, "num_env_steps_trained": 212000, "num_agent_steps_sampled": 848000, "num_agent_steps_trained": 848000}, "done": false, "training_iteration": 53, "trial_id": "8e499_00000", "date": "2024-08-15_02-21-13", "timestamp": 1723668673, "time_this_iter_s": 9.597669839859009, "time_total_s": 1013.3570544719696, "pid": 33199, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x158036040>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1013.3570544719696, "iterations_since_restore": 53, "perf": {"cpu_util_percent": 27.171428571428574, "ram_util_percent": 83.39285714285715}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3168191682409358, "cur_kl_coeff": 0.028125000000000008, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.5818352579755127, "policy_loss": -0.007229712883271671, "vf_loss": 0.588736899547949, "vf_explained_var": 0.012953679807602413, "kl": 0.011664749131913205, "entropy": 0.8396277376899013, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 101115.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9680466419489926, "cur_kl_coeff": 0.03749999999999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.533390229154457, "policy_loss": -0.016448903518911234, "vf_loss": 0.549221245992298, "vf_explained_var": 0.030122996764208276, "kl": 0.01647698892885158, "entropy": 0.7675229949610574, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 101115.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 216000, "num_env_steps_trained": 216000, "num_agent_steps_sampled": 864000, "num_agent_steps_trained": 864000}, "env_runners": {"episode_reward_max": 3.9999999999999587, "episode_reward_min": -132.4599999999998, "episode_reward_mean": -8.232399999999995, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -325.63000000000005, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 2.0000000000000013, "predator_policy": 159.0}, "policy_reward_mean": {"prey_policy": -14.321199999999985, "predator_policy": 10.205}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.909999999999983, -25.289999999999424, -0.10000000000003921, 1.980000000000003, 0.9499999999999819, -41.450000000000614, -0.0900000000000401, 1.910000000000002, 0.909999999999996, 2.989999999999981, 0.9699999999999854, -8.120000000000083, -12.160000000000082, 1.980000000000003, 0.9599999999999828, 1.9500000000000028, -20.229999999999425, -8.130000000000082, 0.9599999999999819, 0.9699999999999819, -1.1100000000000614, 3.9599999999999596, 0.969999999999981, 2.989999999999981, -33.37000000000056, 3.979999999999959, 0.969999999999981, -0.10000000000004099, -9.340000000000078, -11.150000000000082, -8.290000000000079, -10.240000000000078, -27.7299999999999, -0.06000000000004011, -96.99999999999888, -4.100000000000083, 3.9699999999999593, 1.960000000000003, -11.150000000000082, 1.9000000000000026, -8.120000000000083, -30.34999999999999, -132.4599999999998, 3.9999999999999587, -5.090000000000083, -1.0600000000000631, 0.9299999999999827, -14.209999999999749, -16.19999999999956, 0.969999999999981, 1.9700000000000029, -2.060000000000083, -21.24999999999943, 1.870000000000001, -6.100000000000083, -16.1499999999994, -7.210000000000077, -5.090000000000083, 1.980000000000003, -10.140000000000082, -6.100000000000083, -2.060000000000083, -20.239999999999437, -9.14000000000008, -2.160000000000072, -13.249999999999904, -44.480000000000594, -28.319999999999435, -11.150000000000082, -7.110000000000083, -0.13000000000004008, -8.120000000000081, -10.140000000000082, -9.130000000000082, -4.23000000000008, -8.120000000000083, 0.9599999999999814, -2.120000000000081, 0.9699999999999819, 1.8100000000000005, -2.060000000000083, -21.249999999999563, -12.160000000000082, 2.9699999999999815, 3.9999999999999587, -9.130000000000082, 0.9499999999999827, 3.9099999999999606, -0.04000000000004011, -13.169999999999916, 0.969999999999981, -12.160000000000078, -13.259999999999936, -5.100000000000083, -0.05000000000004011, -4.080000000000084, -7.180000000000081, -8.120000000000083, 3.8299999999999628, 2.989999999999981], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-16.0899999999997, 2.0000000000000013, -44.23000000000025, -10.060000000000041, 2.0000000000000013, -18.099999999999703, -2.020000000000042, 2.0000000000000013, -8.050000000000042, 2.0000000000000013, -6.040000000000042, -80.40999999999921, -0.00999999999999836, -14.080000000000041, -16.0899999999997, 2.0000000000000013, 2.0000000000000013, -16.089999999999755, 2.0000000000000013, -0.00999999999999836, 2.0000000000000013, -4.03000000000004, -22.119999999999745, 2.0000000000000013, -2.020000000000042, -26.139999999999773, 2.0000000000000013, -2.020000000000042, -6.040000000000042, 2.0000000000000013, -8.050000000000042, 2.0000000000000013, -12.070000000000041, -30.159999999999716, -24.129999999999708, 2.0000000000000013, 2.0000000000000013, -6.040000000000042, 2.0000000000000013, -4.030000000000042, -20.109999999999705, 2.0000000000000013, 2.0000000000000013, -6.040000000000042, -0.00999999999999836, -2.020000000000042, 2.0000000000000013, -0.00999999999999836, -38.20000000000036, -32.17000000000027, -2.020000000000042, 2.0000000000000013, -4.030000000000042, 2.0000000000000013, -16.0899999999997, -0.00999999999999836, 2.0000000000000013, -66.33999999999916, -14.080000000000041, -12.070000000000041, -54.28000000000034, -0.00999999999999836, -46.24000000000034, 2.0000000000000013, -18.099999999999703, -325.63000000000005, 2.0000000000000013, -10.060000000000041, -182.92000000000093, -14.080000000000007, -14.080000000000041, -2.020000000000042, -4.030000000000042, 2.0000000000000013, -6.040000000000042, 2.0000000000000013, -14.080000000000041, -12.070000000000041, -18.099999999999703, 2.0000000000000013, 2.0000000000000013, -22.119999999999706, -20.109999999999705, -46.240000000000315, -291.46000000000015, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, -4.030000000000042, -10.060000000000041, -10.060000000000041, 2.0000000000000013, 2.0000000000000013, -12.070000000000041, -6.040000000000042, -32.170000000000364, -6.040000000000042, -30.15999999999978, -4.030000000000042, 2.0000000000000013, -4.030000000000042, 2.0000000000000013, 2.0000000000000013, -10.060000000000041, -34.180000000000355, -12.070000000000041, 2.0000000000000013, -24.129999999999708, -6.040000000000042, -10.060000000000041, -18.099999999999703, -8.05000000000004, -18.099999999999703, -20.109999999999722, -14.080000000000041, -0.00999999999999836, -2.020000000000037, 2.0000000000000013, -16.0899999999997, -8.050000000000042, 2.0000000000000013, -18.099999999999703, 2.0000000000000013, -10.060000000000041, -44.23000000000035, -0.00999999999999836, -20.109999999999726, -4.030000000000042, -20.10999999999974, -8.050000000000042, -32.170000000000364, -14.080000000000041, -0.00999999999999836, -92.46999999999923, -12.070000000000041, -48.250000000000284, -10.060000000000041, -16.089999999999705, -14.080000000000041, -4.030000000000038, -24.129999999999708, 2.0000000000000013, -12.070000000000036, -8.050000000000042, -6.040000000000042, -18.099999999999703, -12.070000000000041, -10.060000000000041, -4.030000000000042, -38.20000000000036, -12.070000000000041, -8.050000000000042, -6.040000000000042, 2.0000000000000013, 2.0000000000000013, -22.119999999999706, 2.0000000000000013, -4.030000000000042, -10.060000000000041, -24.129999999999736, 2.0000000000000013, -10.060000000000041, -8.050000000000042, -38.19999999999978, -14.080000000000041, -14.080000000000041, 2.0000000000000013, -4.030000000000042, 2.0000000000000013, 2.0000000000000013, -10.060000000000041, -12.070000000000025, 2.0000000000000013, -8.050000000000042, -16.0899999999997, 2.0000000000000013, 2.0000000000000013, -6.040000000000042, -18.099999999999707, -12.070000000000041, -2.020000000000042, -0.00999999999999836, -30.159999999999712, 2.0000000000000013, -40.210000000000356, -8.050000000000042, -12.070000000000041, -4.030000000000042, 2.0000000000000013, -8.050000000000042, -2.020000000000042, -10.060000000000041, -8.050000000000042, -24.12999999999971, -12.070000000000041, -8.050000000000042, 2.0000000000000013, -32.170000000000364, -0.00999999999999836, 2.0000000000000013], "policy_predator_policy_reward": [9.0, 8.0, 16.0, 13.0, 6.0, 10.0, 2.0, 0.0, 2.0, 5.0, 4.0, 41.0, 7.0, 7.0, 9.0, 7.0, 6.0, 9.0, 0.0, 1.0, 0.0, 3.0, 7.0, 5.0, 7.0, 9.0, 2.0, 0.0, 3.0, 2.0, 3.0, 5.0, 18.0, 4.0, 11.0, 3.0, 1.0, 4.0, 0.0, 3.0, 10.0, 7.0, 4.0, 4.0, 1.0, 2.0, 0.0, 1.0, 27.0, 10.0, 2.0, 2.0, 3.0, 0.0, 7.0, 9.0, 27.0, 28.0, 7.0, 8.0, 27.0, 19.0, 12.0, 22.0, 159.0, 157.0, 6.0, 2.0, 0.0, 100.0, 5.0, 7.0, 3.0, 3.0, 2.0, 4.0, 7.0, 8.0, 10.0, 8.0, 0.0, 12.0, 21.0, 15.0, 13.0, 144.0, 0.0, 0.0, 6.0, 3.0, 6.0, 1.0, 4.0, 7.0, 10.0, 14.0, 3.0, 17.0, 0.0, 3.0, 3.0, 1.0, 6.0, 0.0, 18.0, 7.0, 12.0, 12.0, 6.0, 4.0, 0.0, 10.0, 10.0, 21.0, 8.0, 1.0, 1.0, 1.0, 5.0, 9.0, 0.0, 10.0, 0.0, 6.0, 19.0, 5.0, 11.0, 4.0, 15.0, 11.0, 17.0, 16.0, 47.0, 1.0, 17.0, 15.0, 9.0, 6.0, 0.0, 11.0, 12.0, 10.0, 5.0, 7.0, 4.0, 10.0, 7.0, 6.0, 20.0, 18.0, 7.0, 5.0, 1.0, 4.0, 12.0, 6.0, 0.0, 3.0, 18.0, 18.0, 0.0, 6.0, 14.0, 11.0, 8.0, 8.0, 2.0, 3.0, 0.0, 0.0, 13.0, 0.0, 5.0, 2.0, 9.0, 9.0, 4.0, 0.0, 7.0, 10.0, 2.0, 1.0, 16.0, 0.0, 18.0, 17.0, 4.0, 7.0, 1.0, 5.0, 6.0, 2.0, 12.0, 13.0, 5.0, 7.0, 17.0, 17.0, 1.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.5924838867415919, "mean_inference_ms": 1.8647137582579467, "mean_action_processing_ms": 0.25043351306886363, "mean_env_wait_ms": 0.19328974021176876, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004426240921020508, "StateBufferConnector_ms": 0.0030515193939208984, "ViewRequirementAgentConnector_ms": 0.0955272912979126}, "num_episodes": 22, "episode_return_max": 3.9999999999999587, "episode_return_min": -132.4599999999998, "episode_return_mean": -8.232399999999995, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 864000, "num_agent_steps_trained": 864000, "num_env_steps_sampled": 216000, "num_env_steps_trained": 216000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 392.3593874978607, "num_env_steps_trained_throughput_per_sec": 392.3593874978607, "timesteps_total": 216000, "num_env_steps_sampled_lifetime": 216000, "num_agent_steps_sampled_lifetime": 864000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 864000, "timers": {"training_iteration_time_ms": 53921.572, "restore_workers_time_ms": 0.013, "training_step_time_ms": 53921.483, "sample_time_ms": 1285.693, "learn_time_ms": 52620.447, "learn_throughput": 76.016, "synch_weights_time_ms": 13.873}, "counters": {"num_env_steps_sampled": 216000, "num_env_steps_trained": 216000, "num_agent_steps_sampled": 864000, "num_agent_steps_trained": 864000}, "done": false, "training_iteration": 54, "trial_id": "8e499_00000", "date": "2024-08-15_02-21-24", "timestamp": 1723668684, "time_this_iter_s": 10.200511932373047, "time_total_s": 1023.5575664043427, "pid": 33199, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x158036af0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1023.5575664043427, "iterations_since_restore": 54, "perf": {"cpu_util_percent": 30.16428571428571, "ram_util_percent": 83.44285714285714}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.267082219827112, "cur_kl_coeff": 0.028125000000000008, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.6904102556604557, "policy_loss": -0.0033055336920485372, "vf_loss": 0.6935130392984739, "vf_explained_var": 0.011510268910221323, "kl": 0.007208876919088092, "entropy": 0.8356617708370169, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 103005.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0189690763593982, "cur_kl_coeff": 0.03749999999999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.492035726919307, "policy_loss": -0.016411820394430485, "vf_loss": 0.5079857669066066, "vf_explained_var": 0.06329224147493877, "kl": 0.012314143943766885, "entropy": 0.8310998356216168, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 103005.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 220000, "num_env_steps_trained": 220000, "num_agent_steps_sampled": 880000, "num_agent_steps_trained": 880000}, "env_runners": {"episode_reward_max": 3.9999999999999587, "episode_reward_min": -184.01000000000028, "episode_reward_mean": -10.4902, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -383.9200000000001, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 2.0000000000000013, "predator_policy": 190.0}, "policy_reward_mean": {"prey_policy": -17.1001, "predator_policy": 11.855}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.989999999999981, -33.37000000000056, 3.979999999999959, 0.969999999999981, -0.10000000000004099, -9.340000000000078, -11.150000000000082, -8.290000000000079, -10.240000000000078, -27.7299999999999, -0.06000000000004011, -96.99999999999888, -4.100000000000083, 3.9699999999999593, 1.960000000000003, -11.150000000000082, 1.9000000000000026, -8.120000000000083, -30.34999999999999, -132.4599999999998, 3.9999999999999587, -5.090000000000083, -1.0600000000000631, 0.9299999999999827, -14.209999999999749, -16.19999999999956, 0.969999999999981, 1.9700000000000029, -2.060000000000083, -21.24999999999943, 1.870000000000001, -6.100000000000083, -16.1499999999994, -7.210000000000077, -5.090000000000083, 1.980000000000003, -10.140000000000082, -6.100000000000083, -2.060000000000083, -20.239999999999437, -9.14000000000008, -2.160000000000072, -13.249999999999904, -44.480000000000594, -28.319999999999435, -11.150000000000082, -7.110000000000083, -0.13000000000004008, -8.120000000000081, -10.140000000000082, -9.130000000000082, -4.23000000000008, -8.120000000000083, 0.9599999999999814, -2.120000000000081, 0.9699999999999819, 1.8100000000000005, -2.060000000000083, -21.249999999999563, -12.160000000000082, 2.9699999999999815, 3.9999999999999587, -9.130000000000082, 0.9499999999999827, 3.9099999999999606, -0.04000000000004011, -13.169999999999916, 0.969999999999981, -12.160000000000078, -13.259999999999936, -5.100000000000083, -0.05000000000004011, -4.080000000000084, -7.180000000000081, -8.120000000000083, 3.8299999999999628, 2.989999999999981, -11.140000000000082, -4.060000000000084, 3.989999999999959, 0.969999999999981, -38.58000000000036, -12.14999999999991, -6.070000000000084, -3.160000000000079, 2.9199999999999826, 3.9999999999999587, -0.050000000000041, 1.9500000000000028, -3.0800000000000836, -13.129999999999917, 3.979999999999959, -1.0700000000000622, -4.120000000000083, -9.120000000000083, 3.9699999999999593, -22.25999999999942, -184.01000000000028, 2.9699999999999815, -30.83999999999984], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [2.0000000000000013, -0.00999999999999836, -38.20000000000036, -32.17000000000027, -2.020000000000042, 2.0000000000000013, -4.030000000000042, 2.0000000000000013, -16.0899999999997, -0.00999999999999836, 2.0000000000000013, -66.33999999999916, -14.080000000000041, -12.070000000000041, -54.28000000000034, -0.00999999999999836, -46.24000000000034, 2.0000000000000013, -18.099999999999703, -325.63000000000005, 2.0000000000000013, -10.060000000000041, -182.92000000000093, -14.080000000000007, -14.080000000000041, -2.020000000000042, -4.030000000000042, 2.0000000000000013, -6.040000000000042, 2.0000000000000013, -14.080000000000041, -12.070000000000041, -18.099999999999703, 2.0000000000000013, 2.0000000000000013, -22.119999999999706, -20.109999999999705, -46.240000000000315, -291.46000000000015, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, -4.030000000000042, -10.060000000000041, -10.060000000000041, 2.0000000000000013, 2.0000000000000013, -12.070000000000041, -6.040000000000042, -32.170000000000364, -6.040000000000042, -30.15999999999978, -4.030000000000042, 2.0000000000000013, -4.030000000000042, 2.0000000000000013, 2.0000000000000013, -10.060000000000041, -34.180000000000355, -12.070000000000041, 2.0000000000000013, -24.129999999999708, -6.040000000000042, -10.060000000000041, -18.099999999999703, -8.05000000000004, -18.099999999999703, -20.109999999999722, -14.080000000000041, -0.00999999999999836, -2.020000000000037, 2.0000000000000013, -16.0899999999997, -8.050000000000042, 2.0000000000000013, -18.099999999999703, 2.0000000000000013, -10.060000000000041, -44.23000000000035, -0.00999999999999836, -20.109999999999726, -4.030000000000042, -20.10999999999974, -8.050000000000042, -32.170000000000364, -14.080000000000041, -0.00999999999999836, -92.46999999999923, -12.070000000000041, -48.250000000000284, -10.060000000000041, -16.089999999999705, -14.080000000000041, -4.030000000000038, -24.129999999999708, 2.0000000000000013, -12.070000000000036, -8.050000000000042, -6.040000000000042, -18.099999999999703, -12.070000000000041, -10.060000000000041, -4.030000000000042, -38.20000000000036, -12.070000000000041, -8.050000000000042, -6.040000000000042, 2.0000000000000013, 2.0000000000000013, -22.119999999999706, 2.0000000000000013, -4.030000000000042, -10.060000000000041, -24.129999999999736, 2.0000000000000013, -10.060000000000041, -8.050000000000042, -38.19999999999978, -14.080000000000041, -14.080000000000041, 2.0000000000000013, -4.030000000000042, 2.0000000000000013, 2.0000000000000013, -10.060000000000041, -12.070000000000025, 2.0000000000000013, -8.050000000000042, -16.0899999999997, 2.0000000000000013, 2.0000000000000013, -6.040000000000042, -18.099999999999707, -12.070000000000041, -2.020000000000042, -0.00999999999999836, -30.159999999999712, 2.0000000000000013, -40.210000000000356, -8.050000000000042, -12.070000000000041, -4.030000000000042, 2.0000000000000013, -8.050000000000042, -2.020000000000042, -10.060000000000041, -8.050000000000042, -24.12999999999971, -12.070000000000041, -8.050000000000042, 2.0000000000000013, -32.170000000000364, -0.00999999999999836, 2.0000000000000013, -16.0899999999997, -8.050000000000042, -6.040000000000042, -2.020000000000042, -0.00999999999999836, 2.0000000000000013, -4.030000000000042, 2.0000000000000013, -8.050000000000042, -104.52999999999953, -15.099999999999783, -8.050000000000042, -4.030000000000042, -6.040000000000042, -2.020000000000042, -26.13999999999972, -14.080000000000041, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, -8.050000000000042, 2.0000000000000013, 2.0000000000000013, -8.050000000000042, -14.080000000000041, 2.0000000000000013, -6.040000000000042, -16.0899999999997, 2.0000000000000013, -2.020000000000042, -12.070000000000041, 2.0000000000000013, -22.119999999999706, 2.0000000000000013, -6.040000000000042, -14.080000000000041, 2.0000000000000013, -4.030000000000042, -36.19000000000036, -12.070000000000041, -383.9200000000001, -16.0899999999997, -4.030000000000042, 2.0000000000000013, -10.060000000000041, -154.780000000001], "policy_predator_policy_reward": [0.0, 1.0, 27.0, 10.0, 2.0, 2.0, 3.0, 0.0, 7.0, 9.0, 27.0, 28.0, 7.0, 8.0, 27.0, 19.0, 12.0, 22.0, 159.0, 157.0, 6.0, 2.0, 0.0, 100.0, 5.0, 7.0, 3.0, 3.0, 2.0, 4.0, 7.0, 8.0, 10.0, 8.0, 0.0, 12.0, 21.0, 15.0, 13.0, 144.0, 0.0, 0.0, 6.0, 3.0, 6.0, 1.0, 4.0, 7.0, 10.0, 14.0, 3.0, 17.0, 0.0, 3.0, 3.0, 1.0, 6.0, 0.0, 18.0, 7.0, 12.0, 12.0, 6.0, 4.0, 0.0, 10.0, 10.0, 21.0, 8.0, 1.0, 1.0, 1.0, 5.0, 9.0, 0.0, 10.0, 0.0, 6.0, 19.0, 5.0, 11.0, 4.0, 15.0, 11.0, 17.0, 16.0, 47.0, 1.0, 17.0, 15.0, 9.0, 6.0, 0.0, 11.0, 12.0, 10.0, 5.0, 7.0, 4.0, 10.0, 7.0, 6.0, 20.0, 18.0, 7.0, 5.0, 1.0, 4.0, 12.0, 6.0, 0.0, 3.0, 18.0, 18.0, 0.0, 6.0, 14.0, 11.0, 8.0, 8.0, 2.0, 3.0, 0.0, 0.0, 13.0, 0.0, 5.0, 2.0, 9.0, 9.0, 4.0, 0.0, 7.0, 10.0, 2.0, 1.0, 16.0, 0.0, 18.0, 17.0, 4.0, 7.0, 1.0, 5.0, 6.0, 2.0, 12.0, 13.0, 5.0, 7.0, 17.0, 17.0, 1.0, 0.0, 9.0, 4.0, 4.0, 0.0, 1.0, 1.0, 3.0, 0.0, 52.0, 22.0, 2.0, 9.0, 0.0, 4.0, 14.0, 11.0, 7.0, 8.0, 0.0, 0.0, 2.0, 4.0, 3.0, 5.0, 1.0, 8.0, 9.0, 0.0, 2.0, 2.0, 2.0, 7.0, 12.0, 4.0, 10.0, 1.0, 3.0, 3.0, 8.0, 18.0, 190.0, 26.0, 3.0, 2.0, 67.0, 67.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.59162980377848, "mean_inference_ms": 1.8626942089927683, "mean_action_processing_ms": 0.2498997705275218, "mean_env_wait_ms": 0.19308947378890648, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003865480422973633, "StateBufferConnector_ms": 0.003142118453979492, "ViewRequirementAgentConnector_ms": 0.09887862205505371}, "num_episodes": 23, "episode_return_max": 3.9999999999999587, "episode_return_min": -184.01000000000028, "episode_return_mean": -10.4902, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 880000, "num_agent_steps_trained": 880000, "num_env_steps_sampled": 220000, "num_env_steps_trained": 220000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 354.45815766908004, "num_env_steps_trained_throughput_per_sec": 354.45815766908004, "timesteps_total": 220000, "num_env_steps_sampled_lifetime": 220000, "num_agent_steps_sampled_lifetime": 880000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 880000, "timers": {"training_iteration_time_ms": 53982.75, "restore_workers_time_ms": 0.014, "training_step_time_ms": 53982.71, "sample_time_ms": 1293.388, "learn_time_ms": 52673.777, "learn_throughput": 75.939, "synch_weights_time_ms": 14.055}, "counters": {"num_env_steps_sampled": 220000, "num_env_steps_trained": 220000, "num_agent_steps_sampled": 880000, "num_agent_steps_trained": 880000}, "done": false, "training_iteration": 55, "trial_id": "8e499_00000", "date": "2024-08-15_02-21-35", "timestamp": 1723668695, "time_this_iter_s": 11.332271099090576, "time_total_s": 1034.8898375034332, "pid": 33199, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x1580f8280>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1034.8898375034332, "iterations_since_restore": 55, "perf": {"cpu_util_percent": 35.818749999999994, "ram_util_percent": 82.73125}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.212545775972977, "cur_kl_coeff": 0.028125000000000008, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.6154287520855192, "policy_loss": -0.004900940193760174, "vf_loss": 0.6201402627059786, "vf_explained_var": 0.022969258525384166, "kl": 0.006735213434467078, "entropy": 0.7217363915430806, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 104895.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9772224164907894, "cur_kl_coeff": 0.03749999999999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.48186980705676236, "policy_loss": -0.01434120874945567, "vf_loss": 0.49576087143843767, "vf_explained_var": 0.09355707162271731, "kl": 0.01200380639106564, "entropy": 0.7594083119952489, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 104895.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 224000, "num_env_steps_trained": 224000, "num_agent_steps_sampled": 896000, "num_agent_steps_trained": 896000}, "env_runners": {"episode_reward_max": 3.9999999999999587, "episode_reward_min": -184.01000000000028, "episode_reward_mean": -10.027200000000002, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -383.9200000000001, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 2.0000000000000013, "predator_policy": 190.0}, "policy_reward_mean": {"prey_policy": -14.788599999999983, "predator_policy": 9.775}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30.34999999999999, -132.4599999999998, 3.9999999999999587, -5.090000000000083, -1.0600000000000631, 0.9299999999999827, -14.209999999999749, -16.19999999999956, 0.969999999999981, 1.9700000000000029, -2.060000000000083, -21.24999999999943, 1.870000000000001, -6.100000000000083, -16.1499999999994, -7.210000000000077, -5.090000000000083, 1.980000000000003, -10.140000000000082, -6.100000000000083, -2.060000000000083, -20.239999999999437, -9.14000000000008, -2.160000000000072, -13.249999999999904, -44.480000000000594, -28.319999999999435, -11.150000000000082, -7.110000000000083, -0.13000000000004008, -8.120000000000081, -10.140000000000082, -9.130000000000082, -4.23000000000008, -8.120000000000083, 0.9599999999999814, -2.120000000000081, 0.9699999999999819, 1.8100000000000005, -2.060000000000083, -21.249999999999563, -12.160000000000082, 2.9699999999999815, 3.9999999999999587, -9.130000000000082, 0.9499999999999827, 3.9099999999999606, -0.04000000000004011, -13.169999999999916, 0.969999999999981, -12.160000000000078, -13.259999999999936, -5.100000000000083, -0.05000000000004011, -4.080000000000084, -7.180000000000081, -8.120000000000083, 3.8299999999999628, 2.989999999999981, -11.140000000000082, -4.060000000000084, 3.989999999999959, 0.969999999999981, -38.58000000000036, -12.14999999999991, -6.070000000000084, -3.160000000000079, 2.9199999999999826, 3.9999999999999587, -0.050000000000041, 1.9500000000000028, -3.0800000000000836, -13.129999999999917, 3.979999999999959, -1.0700000000000622, -4.120000000000083, -9.120000000000083, 3.9699999999999593, -22.25999999999942, -184.01000000000028, 2.9699999999999815, -30.83999999999984, -2.060000000000084, -9.360000000000072, -1.0800000000000631, -5.090000000000083, -0.10000000000003921, -14.179999999999774, -0.10000000000003921, -3.0700000000000838, -41.45000000000063, -7.110000000000083, -10.140000000000082, -7.110000000000083, -8.120000000000083, -16.19999999999943, -8.120000000000083, 2.989999999999981, -1.050000000000063, -27.22999999999941], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-20.109999999999705, -46.240000000000315, -291.46000000000015, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, -4.030000000000042, -10.060000000000041, -10.060000000000041, 2.0000000000000013, 2.0000000000000013, -12.070000000000041, -6.040000000000042, -32.170000000000364, -6.040000000000042, -30.15999999999978, -4.030000000000042, 2.0000000000000013, -4.030000000000042, 2.0000000000000013, 2.0000000000000013, -10.060000000000041, -34.180000000000355, -12.070000000000041, 2.0000000000000013, -24.129999999999708, -6.040000000000042, -10.060000000000041, -18.099999999999703, -8.05000000000004, -18.099999999999703, -20.109999999999722, -14.080000000000041, -0.00999999999999836, -2.020000000000037, 2.0000000000000013, -16.0899999999997, -8.050000000000042, 2.0000000000000013, -18.099999999999703, 2.0000000000000013, -10.060000000000041, -44.23000000000035, -0.00999999999999836, -20.109999999999726, -4.030000000000042, -20.10999999999974, -8.050000000000042, -32.170000000000364, -14.080000000000041, -0.00999999999999836, -92.46999999999923, -12.070000000000041, -48.250000000000284, -10.060000000000041, -16.089999999999705, -14.080000000000041, -4.030000000000038, -24.129999999999708, 2.0000000000000013, -12.070000000000036, -8.050000000000042, -6.040000000000042, -18.099999999999703, -12.070000000000041, -10.060000000000041, -4.030000000000042, -38.20000000000036, -12.070000000000041, -8.050000000000042, -6.040000000000042, 2.0000000000000013, 2.0000000000000013, -22.119999999999706, 2.0000000000000013, -4.030000000000042, -10.060000000000041, -24.129999999999736, 2.0000000000000013, -10.060000000000041, -8.050000000000042, -38.19999999999978, -14.080000000000041, -14.080000000000041, 2.0000000000000013, -4.030000000000042, 2.0000000000000013, 2.0000000000000013, -10.060000000000041, -12.070000000000025, 2.0000000000000013, -8.050000000000042, -16.0899999999997, 2.0000000000000013, 2.0000000000000013, -6.040000000000042, -18.099999999999707, -12.070000000000041, -2.020000000000042, -0.00999999999999836, -30.159999999999712, 2.0000000000000013, -40.210000000000356, -8.050000000000042, -12.070000000000041, -4.030000000000042, 2.0000000000000013, -8.050000000000042, -2.020000000000042, -10.060000000000041, -8.050000000000042, -24.12999999999971, -12.070000000000041, -8.050000000000042, 2.0000000000000013, -32.170000000000364, -0.00999999999999836, 2.0000000000000013, -16.0899999999997, -8.050000000000042, -6.040000000000042, -2.020000000000042, -0.00999999999999836, 2.0000000000000013, -4.030000000000042, 2.0000000000000013, -8.050000000000042, -104.52999999999953, -15.099999999999783, -8.050000000000042, -4.030000000000042, -6.040000000000042, -2.020000000000042, -26.13999999999972, -14.080000000000041, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, -8.050000000000042, 2.0000000000000013, 2.0000000000000013, -8.050000000000042, -14.080000000000041, 2.0000000000000013, -6.040000000000042, -16.0899999999997, 2.0000000000000013, -2.020000000000042, -12.070000000000041, 2.0000000000000013, -22.119999999999706, 2.0000000000000013, -6.040000000000042, -14.080000000000041, 2.0000000000000013, -4.030000000000042, -36.19000000000036, -12.070000000000041, -383.9200000000001, -16.0899999999997, -4.030000000000042, 2.0000000000000013, -10.060000000000041, -154.780000000001, -4.030000000000042, -4.030000000000042, 2.0000000000000013, -70.3599999999992, -10.060000000000041, -2.020000000000042, -12.070000000000041, -2.0200000000000418, 2.0000000000000013, -18.099999999999703, -32.17000000000035, -0.00999999999999836, -18.099999999999703, 2.0000000000000013, -2.020000000000042, -8.050000000000042, -78.39999999999925, -8.050000000000042, -20.109999999999705, 2.0000000000000013, -12.070000000000041, -12.07000000000004, -12.070000000000041, -6.040000000000042, -22.119999999999706, 2.0000000000000013, -22.11999999999971, -14.08000000000004, -12.070000000000041, -8.050000000000042, 2.0000000000000013, -0.00999999999999836, -4.03000000000004, -2.020000000000042, -22.119999999999706, -20.109999999999705], "policy_predator_policy_reward": [21.0, 15.0, 13.0, 144.0, 0.0, 0.0, 6.0, 3.0, 6.0, 1.0, 4.0, 7.0, 10.0, 14.0, 3.0, 17.0, 0.0, 3.0, 3.0, 1.0, 6.0, 0.0, 18.0, 7.0, 12.0, 12.0, 6.0, 4.0, 0.0, 10.0, 10.0, 21.0, 8.0, 1.0, 1.0, 1.0, 5.0, 9.0, 0.0, 10.0, 0.0, 6.0, 19.0, 5.0, 11.0, 4.0, 15.0, 11.0, 17.0, 16.0, 47.0, 1.0, 17.0, 15.0, 9.0, 6.0, 0.0, 11.0, 12.0, 10.0, 5.0, 7.0, 4.0, 10.0, 7.0, 6.0, 20.0, 18.0, 7.0, 5.0, 1.0, 4.0, 12.0, 6.0, 0.0, 3.0, 18.0, 18.0, 0.0, 6.0, 14.0, 11.0, 8.0, 8.0, 2.0, 3.0, 0.0, 0.0, 13.0, 0.0, 5.0, 2.0, 9.0, 9.0, 4.0, 0.0, 7.0, 10.0, 2.0, 1.0, 16.0, 0.0, 18.0, 17.0, 4.0, 7.0, 1.0, 5.0, 6.0, 2.0, 12.0, 13.0, 5.0, 7.0, 17.0, 17.0, 1.0, 0.0, 9.0, 4.0, 4.0, 0.0, 1.0, 1.0, 3.0, 0.0, 52.0, 22.0, 2.0, 9.0, 0.0, 4.0, 14.0, 11.0, 7.0, 8.0, 0.0, 0.0, 2.0, 4.0, 3.0, 5.0, 1.0, 8.0, 9.0, 0.0, 2.0, 2.0, 2.0, 7.0, 12.0, 4.0, 10.0, 1.0, 3.0, 3.0, 8.0, 18.0, 190.0, 26.0, 3.0, 2.0, 67.0, 67.0, 3.0, 3.0, 31.0, 28.0, 6.0, 5.0, 7.0, 2.0, 6.0, 10.0, 13.0, 5.0, 10.0, 6.0, 5.0, 2.0, 13.0, 32.0, 0.0, 11.0, 7.0, 7.0, 6.0, 5.0, 12.0, 0.0, 8.0, 12.0, 7.0, 5.0, 0.0, 1.0, 1.0, 4.0, 3.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.0620603251639493, "mean_inference_ms": 6.276198121502841, "mean_action_processing_ms": 0.2501995185924361, "mean_env_wait_ms": 0.9271150237163012, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.015388727188110352, "StateBufferConnector_ms": 0.005741119384765625, "ViewRequirementAgentConnector_ms": 0.21369397640228271}, "num_episodes": 18, "episode_return_max": 3.9999999999999587, "episode_return_min": -184.01000000000028, "episode_return_mean": -10.027200000000002, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 896000, "num_agent_steps_trained": 896000, "num_env_steps_sampled": 224000, "num_env_steps_trained": 224000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 4.311542158762656, "num_env_steps_trained_throughput_per_sec": 4.311542158762656, "timesteps_total": 224000, "num_env_steps_sampled_lifetime": 224000, "num_agent_steps_sampled_lifetime": 896000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 896000, "timers": {"training_iteration_time_ms": 145752.715, "restore_workers_time_ms": 0.014, "training_step_time_ms": 145752.673, "sample_time_ms": 92869.061, "learn_time_ms": 52865.884, "learn_throughput": 75.663, "synch_weights_time_ms": 15.226}, "counters": {"num_env_steps_sampled": 224000, "num_env_steps_trained": 224000, "num_agent_steps_sampled": 896000, "num_agent_steps_trained": 896000}, "done": false, "training_iteration": 56, "trial_id": "8e499_00000", "date": "2024-08-15_02-37-03", "timestamp": 1723669623, "time_this_iter_s": 927.8111870288849, "time_total_s": 1962.7010245323181, "pid": 33199, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x1580dd4c0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1962.7010245323181, "iterations_since_restore": 56, "perf": {"cpu_util_percent": 71.52000000000001, "ram_util_percent": 83.18499999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1720381106885653, "cur_kl_coeff": 0.028125000000000008, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.2410473155391171, "policy_loss": -0.004943368254998137, "vf_loss": 0.24572504283367563, "vf_explained_var": 0.076441791574791, "kl": 0.009445015343728139, "entropy": 0.8257646417807019, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 106785.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6832780963371671, "cur_kl_coeff": 0.03749999999999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.22255313913288513, "policy_loss": -0.01589412980998753, "vf_loss": 0.23813702290746502, "vf_explained_var": 0.07087345936941722, "kl": 0.008273204027775578, "entropy": 0.6406701245951274, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 106785.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 228000, "num_env_steps_trained": 228000, "num_agent_steps_sampled": 912000, "num_agent_steps_trained": 912000}, "env_runners": {"episode_reward_max": 3.9999999999999587, "episode_reward_min": -184.01000000000028, "episode_reward_mean": -8.727700000000016, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -383.9200000000001, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 2.0000000000000013, "predator_policy": 190.0}, "policy_reward_mean": {"prey_policy": -13.833849999999984, "predator_policy": 9.47}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-10.140000000000082, -6.100000000000083, -2.060000000000083, -20.239999999999437, -9.14000000000008, -2.160000000000072, -13.249999999999904, -44.480000000000594, -28.319999999999435, -11.150000000000082, -7.110000000000083, -0.13000000000004008, -8.120000000000081, -10.140000000000082, -9.130000000000082, -4.23000000000008, -8.120000000000083, 0.9599999999999814, -2.120000000000081, 0.9699999999999819, 1.8100000000000005, -2.060000000000083, -21.249999999999563, -12.160000000000082, 2.9699999999999815, 3.9999999999999587, -9.130000000000082, 0.9499999999999827, 3.9099999999999606, -0.04000000000004011, -13.169999999999916, 0.969999999999981, -12.160000000000078, -13.259999999999936, -5.100000000000083, -0.05000000000004011, -4.080000000000084, -7.180000000000081, -8.120000000000083, 3.8299999999999628, 2.989999999999981, -11.140000000000082, -4.060000000000084, 3.989999999999959, 0.969999999999981, -38.58000000000036, -12.14999999999991, -6.070000000000084, -3.160000000000079, 2.9199999999999826, 3.9999999999999587, -0.050000000000041, 1.9500000000000028, -3.0800000000000836, -13.129999999999917, 3.979999999999959, -1.0700000000000622, -4.120000000000083, -9.120000000000083, 3.9699999999999593, -22.25999999999942, -184.01000000000028, 2.9699999999999815, -30.83999999999984, -2.060000000000084, -9.360000000000072, -1.0800000000000631, -5.090000000000083, -0.10000000000003921, -14.179999999999774, -0.10000000000003921, -3.0700000000000838, -41.45000000000063, -7.110000000000083, -10.140000000000082, -7.110000000000083, -8.120000000000083, -16.19999999999943, -8.120000000000083, 2.989999999999981, -1.050000000000063, -27.22999999999941, -9.130000000000082, -4.080000000000084, -10.370000000000077, -17.209999999999432, -10.140000000000082, -11.170000000000082, -1.1300000000000632, -0.12000000000004098, 1.980000000000003, -1.0500000000000622, -2.0900000000000833, -9.130000000000082, -9.21000000000008, -6.100000000000083, -15.219999999999564, 0.8299999999999844, -0.10000000000003921, -12.120000000000083], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-16.0899999999997, -8.050000000000042, 2.0000000000000013, -18.099999999999703, 2.0000000000000013, -10.060000000000041, -44.23000000000035, -0.00999999999999836, -20.109999999999726, -4.030000000000042, -20.10999999999974, -8.050000000000042, -32.170000000000364, -14.080000000000041, -0.00999999999999836, -92.46999999999923, -12.070000000000041, -48.250000000000284, -10.060000000000041, -16.089999999999705, -14.080000000000041, -4.030000000000038, -24.129999999999708, 2.0000000000000013, -12.070000000000036, -8.050000000000042, -6.040000000000042, -18.099999999999703, -12.070000000000041, -10.060000000000041, -4.030000000000042, -38.20000000000036, -12.070000000000041, -8.050000000000042, -6.040000000000042, 2.0000000000000013, 2.0000000000000013, -22.119999999999706, 2.0000000000000013, -4.030000000000042, -10.060000000000041, -24.129999999999736, 2.0000000000000013, -10.060000000000041, -8.050000000000042, -38.19999999999978, -14.080000000000041, -14.080000000000041, 2.0000000000000013, -4.030000000000042, 2.0000000000000013, 2.0000000000000013, -10.060000000000041, -12.070000000000025, 2.0000000000000013, -8.050000000000042, -16.0899999999997, 2.0000000000000013, 2.0000000000000013, -6.040000000000042, -18.099999999999707, -12.070000000000041, -2.020000000000042, -0.00999999999999836, -30.159999999999712, 2.0000000000000013, -40.210000000000356, -8.050000000000042, -12.070000000000041, -4.030000000000042, 2.0000000000000013, -8.050000000000042, -2.020000000000042, -10.060000000000041, -8.050000000000042, -24.12999999999971, -12.070000000000041, -8.050000000000042, 2.0000000000000013, -32.170000000000364, -0.00999999999999836, 2.0000000000000013, -16.0899999999997, -8.050000000000042, -6.040000000000042, -2.020000000000042, -0.00999999999999836, 2.0000000000000013, -4.030000000000042, 2.0000000000000013, -8.050000000000042, -104.52999999999953, -15.099999999999783, -8.050000000000042, -4.030000000000042, -6.040000000000042, -2.020000000000042, -26.13999999999972, -14.080000000000041, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, -8.050000000000042, 2.0000000000000013, 2.0000000000000013, -8.050000000000042, -14.080000000000041, 2.0000000000000013, -6.040000000000042, -16.0899999999997, 2.0000000000000013, -2.020000000000042, -12.070000000000041, 2.0000000000000013, -22.119999999999706, 2.0000000000000013, -6.040000000000042, -14.080000000000041, 2.0000000000000013, -4.030000000000042, -36.19000000000036, -12.070000000000041, -383.9200000000001, -16.0899999999997, -4.030000000000042, 2.0000000000000013, -10.060000000000041, -154.780000000001, -4.030000000000042, -4.030000000000042, 2.0000000000000013, -70.3599999999992, -10.060000000000041, -2.020000000000042, -12.070000000000041, -2.0200000000000418, 2.0000000000000013, -18.099999999999703, -32.17000000000035, -0.00999999999999836, -18.099999999999703, 2.0000000000000013, -2.020000000000042, -8.050000000000042, -78.39999999999925, -8.050000000000042, -20.109999999999705, 2.0000000000000013, -12.070000000000041, -12.07000000000004, -12.070000000000041, -6.040000000000042, -22.119999999999706, 2.0000000000000013, -22.11999999999971, -14.08000000000004, -12.070000000000041, -8.050000000000042, 2.0000000000000013, -0.00999999999999836, -4.03000000000004, -2.020000000000042, -22.119999999999706, -20.109999999999705, -6.040000000000042, -16.0899999999997, 2.0000000000000013, -14.080000000000041, 2.0000000000000013, -72.36999999999934, -36.19000000000035, -2.020000000000042, -8.050000000000042, -16.0899999999997, -32.17000000000036, 2.0000000000000013, -22.119999999999706, -0.00999999999999836, -18.099999999999703, -2.020000000000042, 2.0000000000000013, -2.020000000000042, 2.0000000000000013, -8.050000000000042, -14.080000000000041, -0.00999999999999836, -12.070000000000041, -10.060000000000041, -36.19000000000036, -2.020000000000042, -0.00999999999999836, -16.0899999999997, -32.170000000000364, -8.050000000000042, -32.170000000000364, 2.0000000000000013, 2.0000000000000013, -18.099999999999703, -6.040000000000042, -14.080000000000041], "policy_predator_policy_reward": [5.0, 9.0, 0.0, 10.0, 0.0, 6.0, 19.0, 5.0, 11.0, 4.0, 15.0, 11.0, 17.0, 16.0, 47.0, 1.0, 17.0, 15.0, 9.0, 6.0, 0.0, 11.0, 12.0, 10.0, 5.0, 7.0, 4.0, 10.0, 7.0, 6.0, 20.0, 18.0, 7.0, 5.0, 1.0, 4.0, 12.0, 6.0, 0.0, 3.0, 18.0, 18.0, 0.0, 6.0, 14.0, 11.0, 8.0, 8.0, 2.0, 3.0, 0.0, 0.0, 13.0, 0.0, 5.0, 2.0, 9.0, 9.0, 4.0, 0.0, 7.0, 10.0, 2.0, 1.0, 16.0, 0.0, 18.0, 17.0, 4.0, 7.0, 1.0, 5.0, 6.0, 2.0, 12.0, 13.0, 5.0, 7.0, 17.0, 17.0, 1.0, 0.0, 9.0, 4.0, 4.0, 0.0, 1.0, 1.0, 3.0, 0.0, 52.0, 22.0, 2.0, 9.0, 0.0, 4.0, 14.0, 11.0, 7.0, 8.0, 0.0, 0.0, 2.0, 4.0, 3.0, 5.0, 1.0, 8.0, 9.0, 0.0, 2.0, 2.0, 2.0, 7.0, 12.0, 4.0, 10.0, 1.0, 3.0, 3.0, 8.0, 18.0, 190.0, 26.0, 3.0, 2.0, 67.0, 67.0, 3.0, 3.0, 31.0, 28.0, 6.0, 5.0, 7.0, 2.0, 6.0, 10.0, 13.0, 5.0, 10.0, 6.0, 5.0, 2.0, 13.0, 32.0, 0.0, 11.0, 7.0, 7.0, 6.0, 5.0, 12.0, 0.0, 8.0, 12.0, 7.0, 5.0, 0.0, 1.0, 1.0, 4.0, 3.0, 12.0, 4.0, 9.0, 8.0, 0.0, 34.0, 26.0, 11.0, 10.0, 9.0, 5.0, 17.0, 2.0, 9.0, 12.0, 10.0, 10.0, 0.0, 2.0, 5.0, 0.0, 8.0, 4.0, 6.0, 7.0, 19.0, 10.0, 9.0, 1.0, 8.0, 17.0, 17.0, 14.0, 10.0, 6.0, 8.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 3.5080924846052444, "mean_inference_ms": 10.616085082126219, "mean_action_processing_ms": 0.2510295802029644, "mean_env_wait_ms": 1.6487647878678144, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01538228988647461, "StateBufferConnector_ms": 0.005817055702209473, "ViewRequirementAgentConnector_ms": 0.22161948680877686}, "num_episodes": 18, "episode_return_max": 3.9999999999999587, "episode_return_min": -184.01000000000028, "episode_return_mean": -8.727700000000016, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 912000, "num_agent_steps_trained": 912000, "num_env_steps_sampled": 228000, "num_env_steps_trained": 228000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 320.16984107246225, "num_env_steps_trained_throughput_per_sec": 320.16984107246225, "timesteps_total": 228000, "num_env_steps_sampled_lifetime": 228000, "num_agent_steps_sampled_lifetime": 912000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 912000, "timers": {"training_iteration_time_ms": 132245.527, "restore_workers_time_ms": 0.014, "training_step_time_ms": 132245.482, "sample_time_ms": 92970.344, "learn_time_ms": 39257.318, "learn_throughput": 101.892, "synch_weights_time_ms": 15.194}, "counters": {"num_env_steps_sampled": 228000, "num_env_steps_trained": 228000, "num_agent_steps_sampled": 912000, "num_agent_steps_trained": 912000}, "done": false, "training_iteration": 57, "trial_id": "8e499_00000", "date": "2024-08-15_02-37-15", "timestamp": 1723669635, "time_this_iter_s": 12.552058935165405, "time_total_s": 1975.2530834674835, "pid": 33199, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x1580be940>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1975.2530834674835, "iterations_since_restore": 57, "perf": {"cpu_util_percent": 58.083333333333336, "ram_util_percent": 83.77777777777779}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.296409151730714, "cur_kl_coeff": 0.028125000000000008, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.3110459379812397, "policy_loss": -0.004322206037779334, "vf_loss": 0.3151796164099502, "vf_explained_var": 0.13261682119949786, "kl": 0.006703227924313375, "entropy": 0.8005567460463792, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 108675.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.938635108237544, "cur_kl_coeff": 0.03749999999999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.3201566983781208, "policy_loss": -0.01097685485935361, "vf_loss": 0.330943281412748, "vf_explained_var": 0.11102421927073645, "kl": 0.005073929129371404, "entropy": 0.5833153189174712, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 108675.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 232000, "num_env_steps_trained": 232000, "num_agent_steps_sampled": 928000, "num_agent_steps_trained": 928000}, "env_runners": {"episode_reward_max": 3.9999999999999587, "episode_reward_min": -184.01000000000028, "episode_reward_mean": -7.532300000000018, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -383.9200000000001, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 2.0000000000000013, "predator_policy": 190.0}, "policy_reward_mean": {"prey_policy": -12.286149999999985, "predator_policy": 8.52}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-21.249999999999563, -12.160000000000082, 2.9699999999999815, 3.9999999999999587, -9.130000000000082, 0.9499999999999827, 3.9099999999999606, -0.04000000000004011, -13.169999999999916, 0.969999999999981, -12.160000000000078, -13.259999999999936, -5.100000000000083, -0.05000000000004011, -4.080000000000084, -7.180000000000081, -8.120000000000083, 3.8299999999999628, 2.989999999999981, -11.140000000000082, -4.060000000000084, 3.989999999999959, 0.969999999999981, -38.58000000000036, -12.14999999999991, -6.070000000000084, -3.160000000000079, 2.9199999999999826, 3.9999999999999587, -0.050000000000041, 1.9500000000000028, -3.0800000000000836, -13.129999999999917, 3.979999999999959, -1.0700000000000622, -4.120000000000083, -9.120000000000083, 3.9699999999999593, -22.25999999999942, -184.01000000000028, 2.9699999999999815, -30.83999999999984, -2.060000000000084, -9.360000000000072, -1.0800000000000631, -5.090000000000083, -0.10000000000003921, -14.179999999999774, -0.10000000000003921, -3.0700000000000838, -41.45000000000063, -7.110000000000083, -10.140000000000082, -7.110000000000083, -8.120000000000083, -16.19999999999943, -8.120000000000083, 2.989999999999981, -1.050000000000063, -27.22999999999941, -9.130000000000082, -4.080000000000084, -10.370000000000077, -17.209999999999432, -10.140000000000082, -11.170000000000082, -1.1300000000000632, -0.12000000000004098, 1.980000000000003, -1.0500000000000622, -2.0900000000000833, -9.130000000000082, -9.21000000000008, -6.100000000000083, -15.219999999999564, 0.8299999999999844, -0.10000000000003921, -12.120000000000083, 1.9500000000000028, -1.050000000000063, -2.060000000000084, 1.960000000000003, 0.9699999999999819, 1.980000000000003, 2.989999999999981, -19.25999999999945, 3.9599999999999596, -1.050000000000063, -11.150000000000082, -3.0700000000000838, -15.189999999999916, -1.050000000000063, 1.9700000000000033, -1.1200000000000614, -32.36000000000064, 3.989999999999959, 1.9400000000000017, -8.150000000000082, 3.9999999999999587, -5.120000000000081], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-8.050000000000042, -38.19999999999978, -14.080000000000041, -14.080000000000041, 2.0000000000000013, -4.030000000000042, 2.0000000000000013, 2.0000000000000013, -10.060000000000041, -12.070000000000025, 2.0000000000000013, -8.050000000000042, -16.0899999999997, 2.0000000000000013, 2.0000000000000013, -6.040000000000042, -18.099999999999707, -12.070000000000041, -2.020000000000042, -0.00999999999999836, -30.159999999999712, 2.0000000000000013, -40.210000000000356, -8.050000000000042, -12.070000000000041, -4.030000000000042, 2.0000000000000013, -8.050000000000042, -2.020000000000042, -10.060000000000041, -8.050000000000042, -24.12999999999971, -12.070000000000041, -8.050000000000042, 2.0000000000000013, -32.170000000000364, -0.00999999999999836, 2.0000000000000013, -16.0899999999997, -8.050000000000042, -6.040000000000042, -2.020000000000042, -0.00999999999999836, 2.0000000000000013, -4.030000000000042, 2.0000000000000013, -8.050000000000042, -104.52999999999953, -15.099999999999783, -8.050000000000042, -4.030000000000042, -6.040000000000042, -2.020000000000042, -26.13999999999972, -14.080000000000041, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, -8.050000000000042, 2.0000000000000013, 2.0000000000000013, -8.050000000000042, -14.080000000000041, 2.0000000000000013, -6.040000000000042, -16.0899999999997, 2.0000000000000013, -2.020000000000042, -12.070000000000041, 2.0000000000000013, -22.119999999999706, 2.0000000000000013, -6.040000000000042, -14.080000000000041, 2.0000000000000013, -4.030000000000042, -36.19000000000036, -12.070000000000041, -383.9200000000001, -16.0899999999997, -4.030000000000042, 2.0000000000000013, -10.060000000000041, -154.780000000001, -4.030000000000042, -4.030000000000042, 2.0000000000000013, -70.3599999999992, -10.060000000000041, -2.020000000000042, -12.070000000000041, -2.0200000000000418, 2.0000000000000013, -18.099999999999703, -32.17000000000035, -0.00999999999999836, -18.099999999999703, 2.0000000000000013, -2.020000000000042, -8.050000000000042, -78.39999999999925, -8.050000000000042, -20.109999999999705, 2.0000000000000013, -12.070000000000041, -12.07000000000004, -12.070000000000041, -6.040000000000042, -22.119999999999706, 2.0000000000000013, -22.11999999999971, -14.08000000000004, -12.070000000000041, -8.050000000000042, 2.0000000000000013, -0.00999999999999836, -4.03000000000004, -2.020000000000042, -22.119999999999706, -20.109999999999705, -6.040000000000042, -16.0899999999997, 2.0000000000000013, -14.080000000000041, 2.0000000000000013, -72.36999999999934, -36.19000000000035, -2.020000000000042, -8.050000000000042, -16.0899999999997, -32.17000000000036, 2.0000000000000013, -22.119999999999706, -0.00999999999999836, -18.099999999999703, -2.020000000000042, 2.0000000000000013, -2.020000000000042, 2.0000000000000013, -8.050000000000042, -14.080000000000041, -0.00999999999999836, -12.070000000000041, -10.060000000000041, -36.19000000000036, -2.020000000000042, -0.00999999999999836, -16.0899999999997, -32.170000000000364, -8.050000000000042, -32.170000000000364, 2.0000000000000013, 2.0000000000000013, -18.099999999999703, -6.040000000000042, -14.080000000000041, 2.0000000000000013, -8.050000000000042, -0.00999999999999836, -6.040000000000042, -10.060000000000041, 2.0000000000000013, 2.0000000000000013, -6.040000000000042, 2.0000000000000013, -4.030000000000042, 2.0000000000000013, -2.020000000000042, -0.00999999999999836, 2.0000000000000013, -38.200000000000344, -10.060000000000041, 2.0000000000000013, -6.040000000000042, -8.050000000000042, 2.0000000000000013, -12.070000000000041, -14.080000000000041, -6.040000000000042, -4.030000000000032, -4.030000000000042, -30.159999999999712, -0.00999999999999836, -6.040000000000042, 2.0000000000000013, -4.030000000000042, 2.0000000000000013, -22.119999999999706, -66.33999999999916, -2.020000000000042, -0.00999999999999836, 2.0000000000000013, -10.060000000000041, 2.0000000000000013, -18.099999999999703, -8.050000000000042, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, -22.119999999999706], "policy_predator_policy_reward": [14.0, 11.0, 8.0, 8.0, 2.0, 3.0, 0.0, 0.0, 13.0, 0.0, 5.0, 2.0, 9.0, 9.0, 4.0, 0.0, 7.0, 10.0, 2.0, 1.0, 16.0, 0.0, 18.0, 17.0, 4.0, 7.0, 1.0, 5.0, 6.0, 2.0, 12.0, 13.0, 5.0, 7.0, 17.0, 17.0, 1.0, 0.0, 9.0, 4.0, 4.0, 0.0, 1.0, 1.0, 3.0, 0.0, 52.0, 22.0, 2.0, 9.0, 0.0, 4.0, 14.0, 11.0, 7.0, 8.0, 0.0, 0.0, 2.0, 4.0, 3.0, 5.0, 1.0, 8.0, 9.0, 0.0, 2.0, 2.0, 2.0, 7.0, 12.0, 4.0, 10.0, 1.0, 3.0, 3.0, 8.0, 18.0, 190.0, 26.0, 3.0, 2.0, 67.0, 67.0, 3.0, 3.0, 31.0, 28.0, 6.0, 5.0, 7.0, 2.0, 6.0, 10.0, 13.0, 5.0, 10.0, 6.0, 5.0, 2.0, 13.0, 32.0, 0.0, 11.0, 7.0, 7.0, 6.0, 5.0, 12.0, 0.0, 8.0, 12.0, 7.0, 5.0, 0.0, 1.0, 1.0, 4.0, 3.0, 12.0, 4.0, 9.0, 8.0, 0.0, 34.0, 26.0, 11.0, 10.0, 9.0, 5.0, 17.0, 2.0, 9.0, 12.0, 10.0, 10.0, 0.0, 2.0, 5.0, 0.0, 8.0, 4.0, 6.0, 7.0, 19.0, 10.0, 9.0, 1.0, 8.0, 17.0, 17.0, 14.0, 10.0, 6.0, 8.0, 0.0, 5.0, 3.0, 4.0, 1.0, 6.0, 0.0, 2.0, 4.0, 0.0, 3.0, 0.0, 2.0, 0.0, 1.0, 10.0, 19.0, 4.0, 4.0, 0.0, 5.0, 7.0, 8.0, 7.0, 0.0, 11.0, 8.0, 4.0, 1.0, 2.0, 2.0, 7.0, 12.0, 2.0, 34.0, 1.0, 1.0, 5.0, 5.0, 10.0, 8.0, 0.0, 0.0, 12.0, 3.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 5.284758335852234, "mean_inference_ms": 15.592782010624951, "mean_action_processing_ms": 0.251700328810071, "mean_env_wait_ms": 2.7125780470384826, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01545095443725586, "StateBufferConnector_ms": 0.006035208702087402, "ViewRequirementAgentConnector_ms": 0.23045289516448975}, "num_episodes": 22, "episode_return_max": 3.9999999999999587, "episode_return_min": -184.01000000000028, "episode_return_mean": -7.532300000000018, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 928000, "num_agent_steps_trained": 928000, "num_env_steps_sampled": 232000, "num_env_steps_trained": 232000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 339.26348921525243, "num_env_steps_trained_throughput_per_sec": 339.26348921525243, "timesteps_total": 232000, "num_env_steps_sampled_lifetime": 232000, "num_agent_steps_sampled_lifetime": 928000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 928000, "timers": {"training_iteration_time_ms": 132393.276, "restore_workers_time_ms": 0.013, "training_step_time_ms": 132393.233, "sample_time_ms": 93001.12, "learn_time_ms": 39374.384, "learn_throughput": 101.589, "synch_weights_time_ms": 14.966}, "counters": {"num_env_steps_sampled": 232000, "num_env_steps_trained": 232000, "num_agent_steps_sampled": 928000, "num_agent_steps_trained": 928000}, "done": false, "training_iteration": 58, "trial_id": "8e499_00000", "date": "2024-08-15_02-37-27", "timestamp": 1723669647, "time_this_iter_s": 11.830095052719116, "time_total_s": 1987.0831785202026, "pid": 33199, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x1580bea60>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1987.0831785202026, "iterations_since_restore": 58, "perf": {"cpu_util_percent": 53.48823529411764, "ram_util_percent": 83.20588235294117}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3227013495548692, "cur_kl_coeff": 0.028125000000000008, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.31563100030734426, "policy_loss": -0.003418158376638694, "vf_loss": 0.3188209300161039, "vf_explained_var": 0.11668408576142851, "kl": 0.008114834508372488, "entropy": 0.7633868059468648, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 110565.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8876146835467172, "cur_kl_coeff": 0.03749999999999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.310599546138568, "policy_loss": -0.009980919720634581, "vf_loss": 0.3202202281813019, "vf_explained_var": 0.1298661213387888, "kl": 0.009606320425809549, "entropy": 0.6269028168191355, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 110565.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 236000, "num_env_steps_trained": 236000, "num_agent_steps_sampled": 944000, "num_agent_steps_trained": 944000}, "env_runners": {"episode_reward_max": 3.9999999999999587, "episode_reward_min": -184.01000000000028, "episode_reward_mean": -7.399000000000017, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -383.9200000000001, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 2.0000000000000013, "predator_policy": 190.0}, "policy_reward_mean": {"prey_policy": -11.954499999999978, "predator_policy": 8.255}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.989999999999981, -11.140000000000082, -4.060000000000084, 3.989999999999959, 0.969999999999981, -38.58000000000036, -12.14999999999991, -6.070000000000084, -3.160000000000079, 2.9199999999999826, 3.9999999999999587, -0.050000000000041, 1.9500000000000028, -3.0800000000000836, -13.129999999999917, 3.979999999999959, -1.0700000000000622, -4.120000000000083, -9.120000000000083, 3.9699999999999593, -22.25999999999942, -184.01000000000028, 2.9699999999999815, -30.83999999999984, -2.060000000000084, -9.360000000000072, -1.0800000000000631, -5.090000000000083, -0.10000000000003921, -14.179999999999774, -0.10000000000003921, -3.0700000000000838, -41.45000000000063, -7.110000000000083, -10.140000000000082, -7.110000000000083, -8.120000000000083, -16.19999999999943, -8.120000000000083, 2.989999999999981, -1.050000000000063, -27.22999999999941, -9.130000000000082, -4.080000000000084, -10.370000000000077, -17.209999999999432, -10.140000000000082, -11.170000000000082, -1.1300000000000632, -0.12000000000004098, 1.980000000000003, -1.0500000000000622, -2.0900000000000833, -9.130000000000082, -9.21000000000008, -6.100000000000083, -15.219999999999564, 0.8299999999999844, -0.10000000000003921, -12.120000000000083, 1.9500000000000028, -1.050000000000063, -2.060000000000084, 1.960000000000003, 0.9699999999999819, 1.980000000000003, 2.989999999999981, -19.25999999999945, 3.9599999999999596, -1.050000000000063, -11.150000000000082, -3.0700000000000838, -15.189999999999916, -1.050000000000063, 1.9700000000000033, -1.1200000000000614, -32.36000000000064, 3.989999999999959, 1.9400000000000017, -8.150000000000082, 3.9999999999999587, -5.120000000000081, 0.969999999999981, -16.19999999999974, -10.15000000000008, 1.9700000000000029, -0.08000000000003922, 1.980000000000003, -11.150000000000082, -3.0700000000000838, -0.040000000000040996, -17.209999999999408, 0.969999999999981, -7.110000000000083, -4.200000000000081, -11.150000000000082, 0.9099999999999849, 0.9499999999999819, -4.100000000000081, 0.9699999999999819], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-0.00999999999999836, 2.0000000000000013, -16.0899999999997, -8.050000000000042, -6.040000000000042, -2.020000000000042, -0.00999999999999836, 2.0000000000000013, -4.030000000000042, 2.0000000000000013, -8.050000000000042, -104.52999999999953, -15.099999999999783, -8.050000000000042, -4.030000000000042, -6.040000000000042, -2.020000000000042, -26.13999999999972, -14.080000000000041, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, -8.050000000000042, 2.0000000000000013, 2.0000000000000013, -8.050000000000042, -14.080000000000041, 2.0000000000000013, -6.040000000000042, -16.0899999999997, 2.0000000000000013, -2.020000000000042, -12.070000000000041, 2.0000000000000013, -22.119999999999706, 2.0000000000000013, -6.040000000000042, -14.080000000000041, 2.0000000000000013, -4.030000000000042, -36.19000000000036, -12.070000000000041, -383.9200000000001, -16.0899999999997, -4.030000000000042, 2.0000000000000013, -10.060000000000041, -154.780000000001, -4.030000000000042, -4.030000000000042, 2.0000000000000013, -70.3599999999992, -10.060000000000041, -2.020000000000042, -12.070000000000041, -2.0200000000000418, 2.0000000000000013, -18.099999999999703, -32.17000000000035, -0.00999999999999836, -18.099999999999703, 2.0000000000000013, -2.020000000000042, -8.050000000000042, -78.39999999999925, -8.050000000000042, -20.109999999999705, 2.0000000000000013, -12.070000000000041, -12.07000000000004, -12.070000000000041, -6.040000000000042, -22.119999999999706, 2.0000000000000013, -22.11999999999971, -14.08000000000004, -12.070000000000041, -8.050000000000042, 2.0000000000000013, -0.00999999999999836, -4.03000000000004, -2.020000000000042, -22.119999999999706, -20.109999999999705, -6.040000000000042, -16.0899999999997, 2.0000000000000013, -14.080000000000041, 2.0000000000000013, -72.36999999999934, -36.19000000000035, -2.020000000000042, -8.050000000000042, -16.0899999999997, -32.17000000000036, 2.0000000000000013, -22.119999999999706, -0.00999999999999836, -18.099999999999703, -2.020000000000042, 2.0000000000000013, -2.020000000000042, 2.0000000000000013, -8.050000000000042, -14.080000000000041, -0.00999999999999836, -12.070000000000041, -10.060000000000041, -36.19000000000036, -2.020000000000042, -0.00999999999999836, -16.0899999999997, -32.170000000000364, -8.050000000000042, -32.170000000000364, 2.0000000000000013, 2.0000000000000013, -18.099999999999703, -6.040000000000042, -14.080000000000041, 2.0000000000000013, -8.050000000000042, -0.00999999999999836, -6.040000000000042, -10.060000000000041, 2.0000000000000013, 2.0000000000000013, -6.040000000000042, 2.0000000000000013, -4.030000000000042, 2.0000000000000013, -2.020000000000042, -0.00999999999999836, 2.0000000000000013, -38.200000000000344, -10.060000000000041, 2.0000000000000013, -6.040000000000042, -8.050000000000042, 2.0000000000000013, -12.070000000000041, -14.080000000000041, -6.040000000000042, -4.030000000000032, -4.030000000000042, -30.159999999999712, -0.00999999999999836, -6.040000000000042, 2.0000000000000013, -4.030000000000042, 2.0000000000000013, -22.119999999999706, -66.33999999999916, -2.020000000000042, -0.00999999999999836, 2.0000000000000013, -10.060000000000041, 2.0000000000000013, -18.099999999999703, -8.050000000000042, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, -22.119999999999706, -0.00999999999999836, -2.020000000000042, -32.17000000000006, -4.030000000000042, -22.119999999999713, -4.030000000000042, -4.030000000000042, 2.0000000000000013, 2.0000000000000013, -14.080000000000041, -0.00999999999999836, -0.00999999999999836, -16.0899999999997, -10.060000000000041, -2.020000000000042, -8.050000000000042, -6.040000000000042, 2.0000000000000013, -18.099999999999703, -20.109999999999705, -4.030000000000042, 2.0000000000000013, -0.00999999999999836, -18.099999999999717, -38.20000000000032, 2.0000000000000013, -26.13999999999971, -0.00999999999999836, -12.07000000000004, -2.020000000000042, -8.050000000000042, 2.0000000000000013, -18.099999999999703, 2.0000000000000013, 2.0000000000000013, -4.030000000000042], "policy_predator_policy_reward": [1.0, 0.0, 9.0, 4.0, 4.0, 0.0, 1.0, 1.0, 3.0, 0.0, 52.0, 22.0, 2.0, 9.0, 0.0, 4.0, 14.0, 11.0, 7.0, 8.0, 0.0, 0.0, 2.0, 4.0, 3.0, 5.0, 1.0, 8.0, 9.0, 0.0, 2.0, 2.0, 2.0, 7.0, 12.0, 4.0, 10.0, 1.0, 3.0, 3.0, 8.0, 18.0, 190.0, 26.0, 3.0, 2.0, 67.0, 67.0, 3.0, 3.0, 31.0, 28.0, 6.0, 5.0, 7.0, 2.0, 6.0, 10.0, 13.0, 5.0, 10.0, 6.0, 5.0, 2.0, 13.0, 32.0, 0.0, 11.0, 7.0, 7.0, 6.0, 5.0, 12.0, 0.0, 8.0, 12.0, 7.0, 5.0, 0.0, 1.0, 1.0, 4.0, 3.0, 12.0, 4.0, 9.0, 8.0, 0.0, 34.0, 26.0, 11.0, 10.0, 9.0, 5.0, 17.0, 2.0, 9.0, 12.0, 10.0, 10.0, 0.0, 2.0, 5.0, 0.0, 8.0, 4.0, 6.0, 7.0, 19.0, 10.0, 9.0, 1.0, 8.0, 17.0, 17.0, 14.0, 10.0, 6.0, 8.0, 0.0, 5.0, 3.0, 4.0, 1.0, 6.0, 0.0, 2.0, 4.0, 0.0, 3.0, 0.0, 2.0, 0.0, 1.0, 10.0, 19.0, 4.0, 4.0, 0.0, 5.0, 7.0, 8.0, 7.0, 0.0, 11.0, 8.0, 4.0, 1.0, 2.0, 2.0, 7.0, 12.0, 2.0, 34.0, 1.0, 1.0, 5.0, 5.0, 10.0, 8.0, 0.0, 0.0, 12.0, 3.0, 2.0, 1.0, 11.0, 9.0, 6.0, 10.0, 1.0, 3.0, 4.0, 8.0, 1.0, 1.0, 9.0, 6.0, 2.0, 5.0, 0.0, 4.0, 11.0, 10.0, 0.0, 3.0, 2.0, 9.0, 16.0, 16.0, 10.0, 5.0, 7.0, 8.0, 2.0, 5.0, 10.0, 2.0, 3.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 6.682474535693914, "mean_inference_ms": 19.78807795692253, "mean_action_processing_ms": 0.2533902120025769, "mean_env_wait_ms": 3.410046179717234, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.015596866607666016, "StateBufferConnector_ms": 0.006580948829650879, "ViewRequirementAgentConnector_ms": 0.23980605602264404}, "num_episodes": 18, "episode_return_max": 3.9999999999999587, "episode_return_min": -184.01000000000028, "episode_return_mean": -7.399000000000017, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 944000, "num_agent_steps_trained": 944000, "num_env_steps_sampled": 236000, "num_env_steps_trained": 236000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 4.2178678431244165, "num_env_steps_trained_throughput_per_sec": 4.2178678431244165, "timesteps_total": 236000, "num_env_steps_sampled_lifetime": 236000, "num_agent_steps_sampled_lifetime": 944000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 944000, "timers": {"training_iteration_time_ms": 226176.334, "restore_workers_time_ms": 0.013, "training_step_time_ms": 226176.291, "sample_time_ms": 93013.031, "learn_time_ms": 133144.673, "learn_throughput": 30.043, "synch_weights_time_ms": 15.893}, "counters": {"num_env_steps_sampled": 236000, "num_env_steps_trained": 236000, "num_agent_steps_sampled": 944000, "num_agent_steps_trained": 944000}, "done": false, "training_iteration": 59, "trial_id": "8e499_00000", "date": "2024-08-15_02-53-16", "timestamp": 1723670596, "time_this_iter_s": 948.4527609348297, "time_total_s": 2935.5359394550323, "pid": 33199, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x1580bee50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2935.5359394550323, "iterations_since_restore": 59, "perf": {"cpu_util_percent": 43.71764705882353, "ram_util_percent": 78.87647058823529}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3519292673421284, "cur_kl_coeff": 0.028125000000000008, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.39412533162289826, "policy_loss": -0.004911798068258182, "vf_loss": 0.39888435871064387, "vf_explained_var": 0.16483685866234796, "kl": 0.00543185423940046, "entropy": 0.8037743926679016, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 112455.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0363372399456918, "cur_kl_coeff": 0.03749999999999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.37753250700179564, "policy_loss": -0.01184801881339539, "vf_loss": 0.3891926816383761, "vf_explained_var": 0.1563242215012747, "kl": 0.005009193618852333, "entropy": 0.611397967168263, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 112455.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 240000, "num_env_steps_trained": 240000, "num_agent_steps_sampled": 960000, "num_agent_steps_trained": 960000}, "env_runners": {"episode_reward_max": 3.9999999999999587, "episode_reward_min": -41.45000000000063, "episode_reward_mean": -6.01180000000001, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -154.780000000001, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 2.0000000000000013, "predator_policy": 67.0}, "policy_reward_mean": {"prey_policy": -10.240899999999968, "predator_policy": 7.235}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30.83999999999984, -2.060000000000084, -9.360000000000072, -1.0800000000000631, -5.090000000000083, -0.10000000000003921, -14.179999999999774, -0.10000000000003921, -3.0700000000000838, -41.45000000000063, -7.110000000000083, -10.140000000000082, -7.110000000000083, -8.120000000000083, -16.19999999999943, -8.120000000000083, 2.989999999999981, -1.050000000000063, -27.22999999999941, -9.130000000000082, -4.080000000000084, -10.370000000000077, -17.209999999999432, -10.140000000000082, -11.170000000000082, -1.1300000000000632, -0.12000000000004098, 1.980000000000003, -1.0500000000000622, -2.0900000000000833, -9.130000000000082, -9.21000000000008, -6.100000000000083, -15.219999999999564, 0.8299999999999844, -0.10000000000003921, -12.120000000000083, 1.9500000000000028, -1.050000000000063, -2.060000000000084, 1.960000000000003, 0.9699999999999819, 1.980000000000003, 2.989999999999981, -19.25999999999945, 3.9599999999999596, -1.050000000000063, -11.150000000000082, -3.0700000000000838, -15.189999999999916, -1.050000000000063, 1.9700000000000033, -1.1200000000000614, -32.36000000000064, 3.989999999999959, 1.9400000000000017, -8.150000000000082, 3.9999999999999587, -5.120000000000081, 0.969999999999981, -16.19999999999974, -10.15000000000008, 1.9700000000000029, -0.08000000000003922, 1.980000000000003, -11.150000000000082, -3.0700000000000838, -0.040000000000040996, -17.209999999999408, 0.969999999999981, -7.110000000000083, -4.200000000000081, -11.150000000000082, 0.9099999999999849, 0.9499999999999819, -4.100000000000081, 0.9699999999999819, -9.130000000000082, -10.150000000000082, 3.989999999999959, -7.110000000000083, 1.9800000000000026, -1.0600000000000596, -14.16999999999975, -9.130000000000082, -4.080000000000084, -14.229999999999748, -3.070000000000082, -7.110000000000083, -13.169999999999916, -10.130000000000082, -0.1200000000000392, -1.050000000000063, -0.04000000000003744, -12.160000000000082, -16.19999999999941, 2.939999999999982, -8.120000000000083, -12.160000000000078, -2.060000000000084], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-10.060000000000041, -154.780000000001, -4.030000000000042, -4.030000000000042, 2.0000000000000013, -70.3599999999992, -10.060000000000041, -2.020000000000042, -12.070000000000041, -2.0200000000000418, 2.0000000000000013, -18.099999999999703, -32.17000000000035, -0.00999999999999836, -18.099999999999703, 2.0000000000000013, -2.020000000000042, -8.050000000000042, -78.39999999999925, -8.050000000000042, -20.109999999999705, 2.0000000000000013, -12.070000000000041, -12.07000000000004, -12.070000000000041, -6.040000000000042, -22.119999999999706, 2.0000000000000013, -22.11999999999971, -14.08000000000004, -12.070000000000041, -8.050000000000042, 2.0000000000000013, -0.00999999999999836, -4.03000000000004, -2.020000000000042, -22.119999999999706, -20.109999999999705, -6.040000000000042, -16.0899999999997, 2.0000000000000013, -14.080000000000041, 2.0000000000000013, -72.36999999999934, -36.19000000000035, -2.020000000000042, -8.050000000000042, -16.0899999999997, -32.17000000000036, 2.0000000000000013, -22.119999999999706, -0.00999999999999836, -18.099999999999703, -2.020000000000042, 2.0000000000000013, -2.020000000000042, 2.0000000000000013, -8.050000000000042, -14.080000000000041, -0.00999999999999836, -12.070000000000041, -10.060000000000041, -36.19000000000036, -2.020000000000042, -0.00999999999999836, -16.0899999999997, -32.170000000000364, -8.050000000000042, -32.170000000000364, 2.0000000000000013, 2.0000000000000013, -18.099999999999703, -6.040000000000042, -14.080000000000041, 2.0000000000000013, -8.050000000000042, -0.00999999999999836, -6.040000000000042, -10.060000000000041, 2.0000000000000013, 2.0000000000000013, -6.040000000000042, 2.0000000000000013, -4.030000000000042, 2.0000000000000013, -2.020000000000042, -0.00999999999999836, 2.0000000000000013, -38.200000000000344, -10.060000000000041, 2.0000000000000013, -6.040000000000042, -8.050000000000042, 2.0000000000000013, -12.070000000000041, -14.080000000000041, -6.040000000000042, -4.030000000000032, -4.030000000000042, -30.159999999999712, -0.00999999999999836, -6.040000000000042, 2.0000000000000013, -4.030000000000042, 2.0000000000000013, -22.119999999999706, -66.33999999999916, -2.020000000000042, -0.00999999999999836, 2.0000000000000013, -10.060000000000041, 2.0000000000000013, -18.099999999999703, -8.050000000000042, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, -22.119999999999706, -0.00999999999999836, -2.020000000000042, -32.17000000000006, -4.030000000000042, -22.119999999999713, -4.030000000000042, -4.030000000000042, 2.0000000000000013, 2.0000000000000013, -14.080000000000041, -0.00999999999999836, -0.00999999999999836, -16.0899999999997, -10.060000000000041, -2.020000000000042, -8.050000000000042, -6.040000000000042, 2.0000000000000013, -18.099999999999703, -20.109999999999705, -4.030000000000042, 2.0000000000000013, -0.00999999999999836, -18.099999999999717, -38.20000000000032, 2.0000000000000013, -26.13999999999971, -0.00999999999999836, -12.07000000000004, -2.020000000000042, -8.050000000000042, 2.0000000000000013, -18.099999999999703, 2.0000000000000013, 2.0000000000000013, -4.030000000000042, -18.099999999999703, -4.030000000000042, -20.109999999999705, -6.040000000000042, 2.0000000000000013, -0.00999999999999836, -10.060000000000041, -8.050000000000042, -2.020000000000042, 2.0000000000000013, -0.00999999999999836, -8.05000000000004, -30.159999999999712, -0.00999999999999836, -18.099999999999703, -4.030000000000042, -2.020000000000042, -10.06000000000004, -14.080000000000041, -28.14999999999971, -12.070000000000041, 2.0000000000000013, -4.030000000000042, -14.080000000000041, -10.060000000000041, -20.109999999999705, -6.040000000000042, -16.089999999999705, -22.119999999999706, 2.0000000000000013, -8.050000000000042, 2.0000000000000013, -0.00999999999999836, -4.03000000000004, -10.060000000000041, -18.099999999999703, -22.119999999999706, -14.080000000000041, -10.060000000000041, 2.0000000000000013, 2.0000000000000013, -22.119999999999717, -18.09999999999971, -10.060000000000036, -10.060000000000041, 2.0000000000000013], "policy_predator_policy_reward": [67.0, 67.0, 3.0, 3.0, 31.0, 28.0, 6.0, 5.0, 7.0, 2.0, 6.0, 10.0, 13.0, 5.0, 10.0, 6.0, 5.0, 2.0, 13.0, 32.0, 0.0, 11.0, 7.0, 7.0, 6.0, 5.0, 12.0, 0.0, 8.0, 12.0, 7.0, 5.0, 0.0, 1.0, 1.0, 4.0, 3.0, 12.0, 4.0, 9.0, 8.0, 0.0, 34.0, 26.0, 11.0, 10.0, 9.0, 5.0, 17.0, 2.0, 9.0, 12.0, 10.0, 10.0, 0.0, 2.0, 5.0, 0.0, 8.0, 4.0, 6.0, 7.0, 19.0, 10.0, 9.0, 1.0, 8.0, 17.0, 17.0, 14.0, 10.0, 6.0, 8.0, 0.0, 5.0, 3.0, 4.0, 1.0, 6.0, 0.0, 2.0, 4.0, 0.0, 3.0, 0.0, 2.0, 0.0, 1.0, 10.0, 19.0, 4.0, 4.0, 0.0, 5.0, 7.0, 8.0, 7.0, 0.0, 11.0, 8.0, 4.0, 1.0, 2.0, 2.0, 7.0, 12.0, 2.0, 34.0, 1.0, 1.0, 5.0, 5.0, 10.0, 8.0, 0.0, 0.0, 12.0, 3.0, 2.0, 1.0, 11.0, 9.0, 6.0, 10.0, 1.0, 3.0, 4.0, 8.0, 1.0, 1.0, 9.0, 6.0, 2.0, 5.0, 0.0, 4.0, 11.0, 10.0, 0.0, 3.0, 2.0, 9.0, 16.0, 16.0, 10.0, 5.0, 7.0, 8.0, 2.0, 5.0, 10.0, 2.0, 3.0, 0.0, 3.0, 10.0, 9.0, 7.0, 1.0, 1.0, 5.0, 6.0, 2.0, 0.0, 1.0, 6.0, 16.0, 0.0, 10.0, 3.0, 7.0, 1.0, 13.0, 15.0, 0.0, 7.0, 8.0, 3.0, 6.0, 11.0, 3.0, 9.0, 8.0, 12.0, 0.0, 5.0, 1.0, 3.0, 10.0, 6.0, 12.0, 8.0, 5.0, 6.0, 7.0, 5.0, 10.0, 6.0, 0.0, 6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 8.402489355582576, "mean_inference_ms": 25.292473880502204, "mean_action_processing_ms": 0.25543016167788907, "mean_env_wait_ms": 4.0967219892544255, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01652383804321289, "StateBufferConnector_ms": 0.007371783256530762, "ViewRequirementAgentConnector_ms": 0.25684094429016113}, "num_episodes": 23, "episode_return_max": 3.9999999999999587, "episode_return_min": -41.45000000000063, "episode_return_mean": -6.01180000000001, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 960000, "num_agent_steps_trained": 960000, "num_env_steps_sampled": 240000, "num_env_steps_trained": 240000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 316.3632896742403, "num_env_steps_trained_throughput_per_sec": 316.3632896742403, "timesteps_total": 240000, "num_env_steps_sampled_lifetime": 240000, "num_agent_steps_sampled_lifetime": 960000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 960000, "timers": {"training_iteration_time_ms": 226413.532, "restore_workers_time_ms": 0.013, "training_step_time_ms": 226413.488, "sample_time_ms": 93110.963, "learn_time_ms": 133283.393, "learn_throughput": 30.011, "synch_weights_time_ms": 16.185}, "counters": {"num_env_steps_sampled": 240000, "num_env_steps_trained": 240000, "num_agent_steps_sampled": 960000, "num_agent_steps_trained": 960000}, "done": false, "training_iteration": 60, "trial_id": "8e499_00000", "date": "2024-08-15_02-53-28", "timestamp": 1723670608, "time_this_iter_s": 12.69222092628479, "time_total_s": 2948.228160381317, "pid": 33199, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x15810c670>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2948.228160381317, "iterations_since_restore": 60, "perf": {"cpu_util_percent": 69.30000000000001, "ram_util_percent": 78.82777777777778}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2184003035069773, "cur_kl_coeff": 0.028125000000000008, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.31470483758304485, "policy_loss": -0.004548760254931434, "vf_loss": 0.31900246826705164, "vf_explained_var": 0.12103445290257692, "kl": 0.008929025375112712, "entropy": 0.7816607755327981, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 114345.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.837467645337342, "cur_kl_coeff": 0.03749999999999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.29438952319715145, "policy_loss": -0.016710190533133096, "vf_loss": 0.3101293982863402, "vf_explained_var": 0.11531569945118415, "kl": 0.025875076256634565, "entropy": 0.623442473581859, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 114345.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 244000, "num_env_steps_trained": 244000, "num_agent_steps_sampled": 976000, "num_agent_steps_trained": 976000}, "env_runners": {"episode_reward_max": 3.9999999999999587, "episode_reward_min": -32.36000000000064, "episode_reward_mean": -5.695799999999992, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -72.36999999999934, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 2.0000000000000013, "predator_policy": 34.0}, "policy_reward_mean": {"prey_policy": -9.637899999999975, "predator_policy": 6.79}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-27.22999999999941, -9.130000000000082, -4.080000000000084, -10.370000000000077, -17.209999999999432, -10.140000000000082, -11.170000000000082, -1.1300000000000632, -0.12000000000004098, 1.980000000000003, -1.0500000000000622, -2.0900000000000833, -9.130000000000082, -9.21000000000008, -6.100000000000083, -15.219999999999564, 0.8299999999999844, -0.10000000000003921, -12.120000000000083, 1.9500000000000028, -1.050000000000063, -2.060000000000084, 1.960000000000003, 0.9699999999999819, 1.980000000000003, 2.989999999999981, -19.25999999999945, 3.9599999999999596, -1.050000000000063, -11.150000000000082, -3.0700000000000838, -15.189999999999916, -1.050000000000063, 1.9700000000000033, -1.1200000000000614, -32.36000000000064, 3.989999999999959, 1.9400000000000017, -8.150000000000082, 3.9999999999999587, -5.120000000000081, 0.969999999999981, -16.19999999999974, -10.15000000000008, 1.9700000000000029, -0.08000000000003922, 1.980000000000003, -11.150000000000082, -3.0700000000000838, -0.040000000000040996, -17.209999999999408, 0.969999999999981, -7.110000000000083, -4.200000000000081, -11.150000000000082, 0.9099999999999849, 0.9499999999999819, -4.100000000000081, 0.9699999999999819, -9.130000000000082, -10.150000000000082, 3.989999999999959, -7.110000000000083, 1.9800000000000026, -1.0600000000000596, -14.16999999999975, -9.130000000000082, -4.080000000000084, -14.229999999999748, -3.070000000000082, -7.110000000000083, -13.169999999999916, -10.130000000000082, -0.1200000000000392, -1.050000000000063, -0.04000000000003744, -12.160000000000082, -16.19999999999941, 2.939999999999982, -8.120000000000083, -12.160000000000078, -2.060000000000084, -4.130000000000081, -2.060000000000083, 3.9699999999999593, 3.9499999999999598, 0.9399999999999858, -17.19999999999941, 1.9400000000000026, -32.360000000000575, -17.209999999999408, -5.080000000000084, -0.060000000000041, -17.189999999999404, -12.310000000000077, 3.9199999999999604, -8.120000000000083, -25.289999999999452, -1.2000000000000615, -3.100000000000083], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-22.119999999999706, -20.109999999999705, -6.040000000000042, -16.0899999999997, 2.0000000000000013, -14.080000000000041, 2.0000000000000013, -72.36999999999934, -36.19000000000035, -2.020000000000042, -8.050000000000042, -16.0899999999997, -32.17000000000036, 2.0000000000000013, -22.119999999999706, -0.00999999999999836, -18.099999999999703, -2.020000000000042, 2.0000000000000013, -2.020000000000042, 2.0000000000000013, -8.050000000000042, -14.080000000000041, -0.00999999999999836, -12.070000000000041, -10.060000000000041, -36.19000000000036, -2.020000000000042, -0.00999999999999836, -16.0899999999997, -32.170000000000364, -8.050000000000042, -32.170000000000364, 2.0000000000000013, 2.0000000000000013, -18.099999999999703, -6.040000000000042, -14.080000000000041, 2.0000000000000013, -8.050000000000042, -0.00999999999999836, -6.040000000000042, -10.060000000000041, 2.0000000000000013, 2.0000000000000013, -6.040000000000042, 2.0000000000000013, -4.030000000000042, 2.0000000000000013, -2.020000000000042, -0.00999999999999836, 2.0000000000000013, -38.200000000000344, -10.060000000000041, 2.0000000000000013, -6.040000000000042, -8.050000000000042, 2.0000000000000013, -12.070000000000041, -14.080000000000041, -6.040000000000042, -4.030000000000032, -4.030000000000042, -30.159999999999712, -0.00999999999999836, -6.040000000000042, 2.0000000000000013, -4.030000000000042, 2.0000000000000013, -22.119999999999706, -66.33999999999916, -2.020000000000042, -0.00999999999999836, 2.0000000000000013, -10.060000000000041, 2.0000000000000013, -18.099999999999703, -8.050000000000042, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, -22.119999999999706, -0.00999999999999836, -2.020000000000042, -32.17000000000006, -4.030000000000042, -22.119999999999713, -4.030000000000042, -4.030000000000042, 2.0000000000000013, 2.0000000000000013, -14.080000000000041, -0.00999999999999836, -0.00999999999999836, -16.0899999999997, -10.060000000000041, -2.020000000000042, -8.050000000000042, -6.040000000000042, 2.0000000000000013, -18.099999999999703, -20.109999999999705, -4.030000000000042, 2.0000000000000013, -0.00999999999999836, -18.099999999999717, -38.20000000000032, 2.0000000000000013, -26.13999999999971, -0.00999999999999836, -12.07000000000004, -2.020000000000042, -8.050000000000042, 2.0000000000000013, -18.099999999999703, 2.0000000000000013, 2.0000000000000013, -4.030000000000042, -18.099999999999703, -4.030000000000042, -20.109999999999705, -6.040000000000042, 2.0000000000000013, -0.00999999999999836, -10.060000000000041, -8.050000000000042, -2.020000000000042, 2.0000000000000013, -0.00999999999999836, -8.05000000000004, -30.159999999999712, -0.00999999999999836, -18.099999999999703, -4.030000000000042, -2.020000000000042, -10.06000000000004, -14.080000000000041, -28.14999999999971, -12.070000000000041, 2.0000000000000013, -4.030000000000042, -14.080000000000041, -10.060000000000041, -20.109999999999705, -6.040000000000042, -16.089999999999705, -22.119999999999706, 2.0000000000000013, -8.050000000000042, 2.0000000000000013, -0.00999999999999836, -4.03000000000004, -10.060000000000041, -18.099999999999703, -22.119999999999706, -14.080000000000041, -10.060000000000041, 2.0000000000000013, 2.0000000000000013, -22.119999999999717, -18.09999999999971, -10.060000000000036, -10.060000000000041, 2.0000000000000013, -14.080000000000041, -8.05000000000004, 2.0000000000000013, -10.060000000000041, -4.030000000000042, 2.0000000000000013, 2.0000000000000013, -8.050000000000042, -10.060000000000041, 2.0000000000000013, -18.099999999999707, -18.099999999999703, -10.060000000000041, 2.0000000000000013, -32.170000000000364, -36.19000000000028, -16.0899999999997, -22.119999999999706, -0.00999999999999836, -12.070000000000041, -8.050000000000042, -0.00999999999999836, -22.119999999999706, -12.070000000000041, -54.28000000000034, -4.030000000000042, 2.0000000000000013, -14.080000000000041, -12.07000000000004, -8.050000000000042, 2.0000000000000013, -56.29000000000033, 2.0000000000000013, -38.20000000000036, -16.0899999999997, -0.00999999999999836], "policy_predator_policy_reward": [3.0, 12.0, 4.0, 9.0, 8.0, 0.0, 34.0, 26.0, 11.0, 10.0, 9.0, 5.0, 17.0, 2.0, 9.0, 12.0, 10.0, 10.0, 0.0, 2.0, 5.0, 0.0, 8.0, 4.0, 6.0, 7.0, 19.0, 10.0, 9.0, 1.0, 8.0, 17.0, 17.0, 14.0, 10.0, 6.0, 8.0, 0.0, 5.0, 3.0, 4.0, 1.0, 6.0, 0.0, 2.0, 4.0, 0.0, 3.0, 0.0, 2.0, 0.0, 1.0, 10.0, 19.0, 4.0, 4.0, 0.0, 5.0, 7.0, 8.0, 7.0, 0.0, 11.0, 8.0, 4.0, 1.0, 2.0, 2.0, 7.0, 12.0, 2.0, 34.0, 1.0, 1.0, 5.0, 5.0, 10.0, 8.0, 0.0, 0.0, 12.0, 3.0, 2.0, 1.0, 11.0, 9.0, 6.0, 10.0, 1.0, 3.0, 4.0, 8.0, 1.0, 1.0, 9.0, 6.0, 2.0, 5.0, 0.0, 4.0, 11.0, 10.0, 0.0, 3.0, 2.0, 9.0, 16.0, 16.0, 10.0, 5.0, 7.0, 8.0, 2.0, 5.0, 10.0, 2.0, 3.0, 0.0, 3.0, 10.0, 9.0, 7.0, 1.0, 1.0, 5.0, 6.0, 2.0, 0.0, 1.0, 6.0, 16.0, 0.0, 10.0, 3.0, 7.0, 1.0, 13.0, 15.0, 0.0, 7.0, 8.0, 3.0, 6.0, 11.0, 3.0, 9.0, 8.0, 12.0, 0.0, 5.0, 1.0, 3.0, 10.0, 6.0, 12.0, 8.0, 5.0, 6.0, 7.0, 5.0, 10.0, 6.0, 0.0, 6.0, 10.0, 8.0, 6.0, 0.0, 3.0, 3.0, 5.0, 5.0, 6.0, 3.0, 8.0, 11.0, 6.0, 4.0, 25.0, 11.0, 9.0, 12.0, 0.0, 7.0, 3.0, 5.0, 12.0, 5.0, 26.0, 20.0, 8.0, 8.0, 5.0, 7.0, 20.0, 9.0, 18.0, 17.0, 4.0, 9.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 8.652482115467663, "mean_inference_ms": 24.939107947079314, "mean_action_processing_ms": 0.2563707121746968, "mean_env_wait_ms": 4.037663038615379, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005159974098205566, "StateBufferConnector_ms": 0.004765629768371582, "ViewRequirementAgentConnector_ms": 0.14309167861938477}, "num_episodes": 18, "episode_return_max": 3.9999999999999587, "episode_return_min": -32.36000000000064, "episode_return_mean": -5.695799999999992, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 976000, "num_agent_steps_trained": 976000, "num_env_steps_sampled": 244000, "num_env_steps_trained": 244000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 354.24626257268244, "num_env_steps_trained_throughput_per_sec": 354.24626257268244, "timesteps_total": 244000, "num_env_steps_sampled_lifetime": 244000, "num_agent_steps_sampled_lifetime": 976000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 976000, "timers": {"training_iteration_time_ms": 196543.932, "restore_workers_time_ms": 0.013, "training_step_time_ms": 196543.888, "sample_time_ms": 93131.371, "learn_time_ms": 103393.572, "learn_throughput": 38.687, "synch_weights_time_ms": 16.233}, "counters": {"num_env_steps_sampled": 244000, "num_env_steps_trained": 244000, "num_agent_steps_sampled": 976000, "num_agent_steps_trained": 976000}, "done": false, "training_iteration": 61, "trial_id": "8e499_00000", "date": "2024-08-15_02-53-40", "timestamp": 1723670620, "time_this_iter_s": 11.345499038696289, "time_total_s": 2959.5736594200134, "pid": 33199, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x1580f81f0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2959.5736594200134, "iterations_since_restore": 61, "perf": {"cpu_util_percent": 36.2125, "ram_util_percent": 82.5}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.158224800946536, "cur_kl_coeff": 0.028125000000000008, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.31767332625609856, "policy_loss": -0.009120891717257638, "vf_loss": 0.32644765680747, "vf_explained_var": 0.12474844244422105, "kl": 0.01232216450755646, "entropy": 0.6868571511336735, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 116235.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9764899257629637, "cur_kl_coeff": 0.056250000000000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.29387620591248076, "policy_loss": -0.009026912652404497, "vf_loss": 0.30254315218106576, "vf_explained_var": 0.16738602083826823, "kl": 0.006399375284303334, "entropy": 0.7350010441093848, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 116235.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 248000, "num_env_steps_trained": 248000, "num_agent_steps_sampled": 992000, "num_agent_steps_trained": 992000}, "env_runners": {"episode_reward_max": 3.9999999999999587, "episode_reward_min": -32.36000000000064, "episode_reward_mean": -5.529499999999996, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -66.33999999999916, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 2.0000000000000013, "predator_policy": 34.0}, "policy_reward_mean": {"prey_policy": -9.004749999999975, "predator_policy": 6.24}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-12.120000000000083, 1.9500000000000028, -1.050000000000063, -2.060000000000084, 1.960000000000003, 0.9699999999999819, 1.980000000000003, 2.989999999999981, -19.25999999999945, 3.9599999999999596, -1.050000000000063, -11.150000000000082, -3.0700000000000838, -15.189999999999916, -1.050000000000063, 1.9700000000000033, -1.1200000000000614, -32.36000000000064, 3.989999999999959, 1.9400000000000017, -8.150000000000082, 3.9999999999999587, -5.120000000000081, 0.969999999999981, -16.19999999999974, -10.15000000000008, 1.9700000000000029, -0.08000000000003922, 1.980000000000003, -11.150000000000082, -3.0700000000000838, -0.040000000000040996, -17.209999999999408, 0.969999999999981, -7.110000000000083, -4.200000000000081, -11.150000000000082, 0.9099999999999849, 0.9499999999999819, -4.100000000000081, 0.9699999999999819, -9.130000000000082, -10.150000000000082, 3.989999999999959, -7.110000000000083, 1.9800000000000026, -1.0600000000000596, -14.16999999999975, -9.130000000000082, -4.080000000000084, -14.229999999999748, -3.070000000000082, -7.110000000000083, -13.169999999999916, -10.130000000000082, -0.1200000000000392, -1.050000000000063, -0.04000000000003744, -12.160000000000082, -16.19999999999941, 2.939999999999982, -8.120000000000083, -12.160000000000078, -2.060000000000084, -4.130000000000081, -2.060000000000083, 3.9699999999999593, 3.9499999999999598, 0.9399999999999858, -17.19999999999941, 1.9400000000000026, -32.360000000000575, -17.209999999999408, -5.080000000000084, -0.060000000000041, -17.189999999999404, -12.310000000000077, 3.9199999999999604, -8.120000000000083, -25.289999999999452, -1.2000000000000615, -3.100000000000083, 0.8899999999999836, -14.179999999999739, -21.299999999999443, -7.110000000000083, -1.050000000000063, -14.17999999999976, 0.9299999999999827, -0.050000000000032116, 2.989999999999981, -7.110000000000083, -4.080000000000084, -4.080000000000084, -30.300000000000104, -9.150000000000082, 0.949999999999981, -2.0900000000000825, -8.110000000000083, 2.989999999999981], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-6.040000000000042, -14.080000000000041, 2.0000000000000013, -8.050000000000042, -0.00999999999999836, -6.040000000000042, -10.060000000000041, 2.0000000000000013, 2.0000000000000013, -6.040000000000042, 2.0000000000000013, -4.030000000000042, 2.0000000000000013, -2.020000000000042, -0.00999999999999836, 2.0000000000000013, -38.200000000000344, -10.060000000000041, 2.0000000000000013, -6.040000000000042, -8.050000000000042, 2.0000000000000013, -12.070000000000041, -14.080000000000041, -6.040000000000042, -4.030000000000032, -4.030000000000042, -30.159999999999712, -0.00999999999999836, -6.040000000000042, 2.0000000000000013, -4.030000000000042, 2.0000000000000013, -22.119999999999706, -66.33999999999916, -2.020000000000042, -0.00999999999999836, 2.0000000000000013, -10.060000000000041, 2.0000000000000013, -18.099999999999703, -8.050000000000042, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, -22.119999999999706, -0.00999999999999836, -2.020000000000042, -32.17000000000006, -4.030000000000042, -22.119999999999713, -4.030000000000042, -4.030000000000042, 2.0000000000000013, 2.0000000000000013, -14.080000000000041, -0.00999999999999836, -0.00999999999999836, -16.0899999999997, -10.060000000000041, -2.020000000000042, -8.050000000000042, -6.040000000000042, 2.0000000000000013, -18.099999999999703, -20.109999999999705, -4.030000000000042, 2.0000000000000013, -0.00999999999999836, -18.099999999999717, -38.20000000000032, 2.0000000000000013, -26.13999999999971, -0.00999999999999836, -12.07000000000004, -2.020000000000042, -8.050000000000042, 2.0000000000000013, -18.099999999999703, 2.0000000000000013, 2.0000000000000013, -4.030000000000042, -18.099999999999703, -4.030000000000042, -20.109999999999705, -6.040000000000042, 2.0000000000000013, -0.00999999999999836, -10.060000000000041, -8.050000000000042, -2.020000000000042, 2.0000000000000013, -0.00999999999999836, -8.05000000000004, -30.159999999999712, -0.00999999999999836, -18.099999999999703, -4.030000000000042, -2.020000000000042, -10.06000000000004, -14.080000000000041, -28.14999999999971, -12.070000000000041, 2.0000000000000013, -4.030000000000042, -14.080000000000041, -10.060000000000041, -20.109999999999705, -6.040000000000042, -16.089999999999705, -22.119999999999706, 2.0000000000000013, -8.050000000000042, 2.0000000000000013, -0.00999999999999836, -4.03000000000004, -10.060000000000041, -18.099999999999703, -22.119999999999706, -14.080000000000041, -10.060000000000041, 2.0000000000000013, 2.0000000000000013, -22.119999999999717, -18.09999999999971, -10.060000000000036, -10.060000000000041, 2.0000000000000013, -14.080000000000041, -8.05000000000004, 2.0000000000000013, -10.060000000000041, -4.030000000000042, 2.0000000000000013, 2.0000000000000013, -8.050000000000042, -10.060000000000041, 2.0000000000000013, -18.099999999999707, -18.099999999999703, -10.060000000000041, 2.0000000000000013, -32.170000000000364, -36.19000000000028, -16.0899999999997, -22.119999999999706, -0.00999999999999836, -12.070000000000041, -8.050000000000042, -0.00999999999999836, -22.119999999999706, -12.070000000000041, -54.28000000000034, -4.030000000000042, 2.0000000000000013, -14.080000000000041, -12.07000000000004, -8.050000000000042, 2.0000000000000013, -56.29000000000033, 2.0000000000000013, -38.20000000000036, -16.0899999999997, -0.00999999999999836, 2.0000000000000013, -20.109999999999705, -8.050000000000042, -24.129999999999708, -42.22000000000035, -14.080000000000041, -12.070000000000041, -6.040000000000042, -8.050000000000042, 2.0000000000000013, -28.149999999999718, -4.030000000000042, 2.0000000000000013, -12.070000000000041, -2.0200000000000378, -4.030000000000042, -0.00999999999999836, 2.0000000000000013, -2.020000000000042, -16.0899999999997, 2.0000000000000013, -14.080000000000041, -4.030000000000042, -8.050000000000042, -36.19000000000036, -20.109999999999705, -6.040000000000042, -20.109999999999705, -8.050000000000042, 2.0000000000000013, 2.0000000000000013, -16.0899999999997, -16.0899999999997, -2.020000000000042, 2.0000000000000013, -0.00999999999999836], "policy_predator_policy_reward": [8.0, 0.0, 5.0, 3.0, 4.0, 1.0, 6.0, 0.0, 2.0, 4.0, 0.0, 3.0, 0.0, 2.0, 0.0, 1.0, 10.0, 19.0, 4.0, 4.0, 0.0, 5.0, 7.0, 8.0, 7.0, 0.0, 11.0, 8.0, 4.0, 1.0, 2.0, 2.0, 7.0, 12.0, 2.0, 34.0, 1.0, 1.0, 5.0, 5.0, 10.0, 8.0, 0.0, 0.0, 12.0, 3.0, 2.0, 1.0, 11.0, 9.0, 6.0, 10.0, 1.0, 3.0, 4.0, 8.0, 1.0, 1.0, 9.0, 6.0, 2.0, 5.0, 0.0, 4.0, 11.0, 10.0, 0.0, 3.0, 2.0, 9.0, 16.0, 16.0, 10.0, 5.0, 7.0, 8.0, 2.0, 5.0, 10.0, 2.0, 3.0, 0.0, 3.0, 10.0, 9.0, 7.0, 1.0, 1.0, 5.0, 6.0, 2.0, 0.0, 1.0, 6.0, 16.0, 0.0, 10.0, 3.0, 7.0, 1.0, 13.0, 15.0, 0.0, 7.0, 8.0, 3.0, 6.0, 11.0, 3.0, 9.0, 8.0, 12.0, 0.0, 5.0, 1.0, 3.0, 10.0, 6.0, 12.0, 8.0, 5.0, 6.0, 7.0, 5.0, 10.0, 6.0, 0.0, 6.0, 10.0, 8.0, 6.0, 0.0, 3.0, 3.0, 5.0, 5.0, 6.0, 3.0, 8.0, 11.0, 6.0, 4.0, 25.0, 11.0, 9.0, 12.0, 0.0, 7.0, 3.0, 5.0, 12.0, 5.0, 26.0, 20.0, 8.0, 8.0, 5.0, 7.0, 20.0, 9.0, 18.0, 17.0, 4.0, 9.0, 11.0, 8.0, 5.0, 13.0, 20.0, 15.0, 7.0, 4.0, 0.0, 5.0, 8.0, 10.0, 7.0, 4.0, 3.0, 3.0, 0.0, 1.0, 2.0, 9.0, 8.0, 0.0, 3.0, 5.0, 5.0, 21.0, 11.0, 6.0, 4.0, 3.0, 8.0, 4.0, 1.0, 9.0, 0.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 8.531156485269152, "mean_inference_ms": 24.593980147071825, "mean_action_processing_ms": 0.25683225881591565, "mean_env_wait_ms": 3.9801320769670663, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005102276802062988, "StateBufferConnector_ms": 0.004729509353637695, "ViewRequirementAgentConnector_ms": 0.13575530052185059}, "num_episodes": 18, "episode_return_max": 3.9999999999999587, "episode_return_min": -32.36000000000064, "episode_return_mean": -5.529499999999996, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 992000, "num_agent_steps_trained": 992000, "num_env_steps_sampled": 248000, "num_env_steps_trained": 248000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 371.9472265181102, "num_env_steps_trained_throughput_per_sec": 371.9472265181102, "timesteps_total": 248000, "num_env_steps_sampled_lifetime": 248000, "num_agent_steps_sampled_lifetime": 992000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 992000, "timers": {"training_iteration_time_ms": 196613.318, "restore_workers_time_ms": 0.013, "training_step_time_ms": 196613.272, "sample_time_ms": 93136.927, "learn_time_ms": 103456.517, "learn_throughput": 38.664, "synch_weights_time_ms": 16.987}, "counters": {"num_env_steps_sampled": 248000, "num_env_steps_trained": 248000, "num_agent_steps_sampled": 992000, "num_agent_steps_trained": 992000}, "done": false, "training_iteration": 62, "trial_id": "8e499_00000", "date": "2024-08-15_02-53-51", "timestamp": 1723670631, "time_this_iter_s": 10.804413318634033, "time_total_s": 2970.3780727386475, "pid": 33199, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x1580f8040>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2970.3780727386475, "iterations_since_restore": 62, "perf": {"cpu_util_percent": 33.9375, "ram_util_percent": 82.25}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4693084121065796, "cur_kl_coeff": 0.028125000000000008, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.072184090182264, "policy_loss": -0.005954193579594767, "vf_loss": 1.07793546658029, "vf_explained_var": 0.05852241156593202, "kl": 0.007211161498681485, "entropy": 0.7098573126174785, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 118125.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2535547711388775, "cur_kl_coeff": 0.056250000000000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.8250567717132745, "policy_loss": -0.007722620956264633, "vf_loss": 0.8323315175358581, "vf_explained_var": 0.07276777858456607, "kl": 0.007962245317875137, "entropy": 0.7456304280846208, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 118125.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 252000, "num_env_steps_trained": 252000, "num_agent_steps_sampled": 1008000, "num_agent_steps_trained": 1008000}, "env_runners": {"episode_reward_max": 3.9999999999999587, "episode_reward_min": -32.360000000000575, "episode_reward_mean": -6.646999999999978, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -108.54999999999929, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 2.0000000000000013, "predator_policy": 48.0}, "policy_reward_mean": {"prey_policy": -10.76349999999996, "predator_policy": 7.44}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-5.120000000000081, 0.969999999999981, -16.19999999999974, -10.15000000000008, 1.9700000000000029, -0.08000000000003922, 1.980000000000003, -11.150000000000082, -3.0700000000000838, -0.040000000000040996, -17.209999999999408, 0.969999999999981, -7.110000000000083, -4.200000000000081, -11.150000000000082, 0.9099999999999849, 0.9499999999999819, -4.100000000000081, 0.9699999999999819, -9.130000000000082, -10.150000000000082, 3.989999999999959, -7.110000000000083, 1.9800000000000026, -1.0600000000000596, -14.16999999999975, -9.130000000000082, -4.080000000000084, -14.229999999999748, -3.070000000000082, -7.110000000000083, -13.169999999999916, -10.130000000000082, -0.1200000000000392, -1.050000000000063, -0.04000000000003744, -12.160000000000082, -16.19999999999941, 2.939999999999982, -8.120000000000083, -12.160000000000078, -2.060000000000084, -4.130000000000081, -2.060000000000083, 3.9699999999999593, 3.9499999999999598, 0.9399999999999858, -17.19999999999941, 1.9400000000000026, -32.360000000000575, -17.209999999999408, -5.080000000000084, -0.060000000000041, -17.189999999999404, -12.310000000000077, 3.9199999999999604, -8.120000000000083, -25.289999999999452, -1.2000000000000615, -3.100000000000083, 0.8899999999999836, -14.179999999999739, -21.299999999999443, -7.110000000000083, -1.050000000000063, -14.17999999999976, 0.9299999999999827, -0.050000000000032116, 2.989999999999981, -7.110000000000083, -4.080000000000084, -4.080000000000084, -30.300000000000104, -9.150000000000082, 0.949999999999981, -2.0900000000000825, -8.110000000000083, 2.989999999999981, -3.0700000000000838, -4.070000000000084, -13.20999999999993, -14.179999999999739, -1.1600000000000623, -7.110000000000083, -9.24000000000008, -4.220000000000066, 0.969999999999981, -0.040000000000040996, 3.9999999999999587, -29.339999999999627, -5.090000000000083, -4.080000000000082, -2.060000000000084, -4.240000000000053, -28.55999999999958, -22.259999999999415, -7.110000000000083, -17.209999999999418, -10.160000000000082, -12.230000000000079], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [2.0000000000000013, -22.119999999999706, -0.00999999999999836, -2.020000000000042, -32.17000000000006, -4.030000000000042, -22.119999999999713, -4.030000000000042, -4.030000000000042, 2.0000000000000013, 2.0000000000000013, -14.080000000000041, -0.00999999999999836, -0.00999999999999836, -16.0899999999997, -10.060000000000041, -2.020000000000042, -8.050000000000042, -6.040000000000042, 2.0000000000000013, -18.099999999999703, -20.109999999999705, -4.030000000000042, 2.0000000000000013, -0.00999999999999836, -18.099999999999717, -38.20000000000032, 2.0000000000000013, -26.13999999999971, -0.00999999999999836, -12.07000000000004, -2.020000000000042, -8.050000000000042, 2.0000000000000013, -18.099999999999703, 2.0000000000000013, 2.0000000000000013, -4.030000000000042, -18.099999999999703, -4.030000000000042, -20.109999999999705, -6.040000000000042, 2.0000000000000013, -0.00999999999999836, -10.060000000000041, -8.050000000000042, -2.020000000000042, 2.0000000000000013, -0.00999999999999836, -8.05000000000004, -30.159999999999712, -0.00999999999999836, -18.099999999999703, -4.030000000000042, -2.020000000000042, -10.06000000000004, -14.080000000000041, -28.14999999999971, -12.070000000000041, 2.0000000000000013, -4.030000000000042, -14.080000000000041, -10.060000000000041, -20.109999999999705, -6.040000000000042, -16.089999999999705, -22.119999999999706, 2.0000000000000013, -8.050000000000042, 2.0000000000000013, -0.00999999999999836, -4.03000000000004, -10.060000000000041, -18.099999999999703, -22.119999999999706, -14.080000000000041, -10.060000000000041, 2.0000000000000013, 2.0000000000000013, -22.119999999999717, -18.09999999999971, -10.060000000000036, -10.060000000000041, 2.0000000000000013, -14.080000000000041, -8.05000000000004, 2.0000000000000013, -10.060000000000041, -4.030000000000042, 2.0000000000000013, 2.0000000000000013, -8.050000000000042, -10.060000000000041, 2.0000000000000013, -18.099999999999707, -18.099999999999703, -10.060000000000041, 2.0000000000000013, -32.170000000000364, -36.19000000000028, -16.0899999999997, -22.119999999999706, -0.00999999999999836, -12.070000000000041, -8.050000000000042, -0.00999999999999836, -22.119999999999706, -12.070000000000041, -54.28000000000034, -4.030000000000042, 2.0000000000000013, -14.080000000000041, -12.07000000000004, -8.050000000000042, 2.0000000000000013, -56.29000000000033, 2.0000000000000013, -38.20000000000036, -16.0899999999997, -0.00999999999999836, 2.0000000000000013, -20.109999999999705, -8.050000000000042, -24.129999999999708, -42.22000000000035, -14.080000000000041, -12.070000000000041, -6.040000000000042, -8.050000000000042, 2.0000000000000013, -28.149999999999718, -4.030000000000042, 2.0000000000000013, -12.070000000000041, -2.0200000000000378, -4.030000000000042, -0.00999999999999836, 2.0000000000000013, -2.020000000000042, -16.0899999999997, 2.0000000000000013, -14.080000000000041, -4.030000000000042, -8.050000000000042, -36.19000000000036, -20.109999999999705, -6.040000000000042, -20.109999999999705, -8.050000000000042, 2.0000000000000013, 2.0000000000000013, -16.0899999999997, -16.0899999999997, -2.020000000000042, 2.0000000000000013, -0.00999999999999836, -8.050000000000042, -2.020000000000042, -10.060000000000041, -0.00999999999999836, -12.070000000000041, -26.139999999999716, -16.089999999999712, -16.0899999999997, -8.050000000000042, -20.109999999999708, -4.030000000000042, -14.080000000000041, -2.020000000000042, -42.220000000000354, -16.0899999999997, -24.12999999999984, -2.020000000000042, -0.00999999999999836, -6.040000000000042, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, -0.00999999999999836, -64.32999999999922, 2.0000000000000013, -16.0899999999997, -14.080000000000041, 2.0000000000000013, -0.00999999999999836, -8.050000000000042, -26.13999999999971, -18.09999999999984, -108.54999999999929, -0.00999999999999836, -34.18000000000008, -14.080000000000041, -20.109999999999705, 2.0000000000000013, -30.159999999999712, -8.050000000000042, -6.040000000000042, -22.119999999999706, -38.20000000000035, -4.030000000000042], "policy_predator_policy_reward": [12.0, 3.0, 2.0, 1.0, 11.0, 9.0, 6.0, 10.0, 1.0, 3.0, 4.0, 8.0, 1.0, 1.0, 9.0, 6.0, 2.0, 5.0, 0.0, 4.0, 11.0, 10.0, 0.0, 3.0, 2.0, 9.0, 16.0, 16.0, 10.0, 5.0, 7.0, 8.0, 2.0, 5.0, 10.0, 2.0, 3.0, 0.0, 3.0, 10.0, 9.0, 7.0, 1.0, 1.0, 5.0, 6.0, 2.0, 0.0, 1.0, 6.0, 16.0, 0.0, 10.0, 3.0, 7.0, 1.0, 13.0, 15.0, 0.0, 7.0, 8.0, 3.0, 6.0, 11.0, 3.0, 9.0, 8.0, 12.0, 0.0, 5.0, 1.0, 3.0, 10.0, 6.0, 12.0, 8.0, 5.0, 6.0, 7.0, 5.0, 10.0, 6.0, 0.0, 6.0, 10.0, 8.0, 6.0, 0.0, 3.0, 3.0, 5.0, 5.0, 6.0, 3.0, 8.0, 11.0, 6.0, 4.0, 25.0, 11.0, 9.0, 12.0, 0.0, 7.0, 3.0, 5.0, 12.0, 5.0, 26.0, 20.0, 8.0, 8.0, 5.0, 7.0, 20.0, 9.0, 18.0, 17.0, 4.0, 9.0, 11.0, 8.0, 5.0, 13.0, 20.0, 15.0, 7.0, 4.0, 0.0, 5.0, 8.0, 10.0, 7.0, 4.0, 3.0, 3.0, 0.0, 1.0, 2.0, 9.0, 8.0, 0.0, 3.0, 5.0, 5.0, 21.0, 11.0, 6.0, 4.0, 3.0, 8.0, 4.0, 1.0, 9.0, 0.0, 1.0, 2.0, 5.0, 0.0, 6.0, 7.0, 18.0, 9.0, 9.0, 13.0, 14.0, 3.0, 8.0, 14.0, 21.0, 18.0, 18.0, 2.0, 1.0, 4.0, 0.0, 0.0, 0.0, 28.0, 7.0, 0.0, 9.0, 0.0, 8.0, 1.0, 5.0, 23.0, 17.0, 32.0, 48.0, 10.0, 16.0, 11.0, 0.0, 15.0, 6.0, 6.0, 12.0, 18.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 8.385521800573313, "mean_inference_ms": 24.20371220218468, "mean_action_processing_ms": 0.2572021486451814, "mean_env_wait_ms": 3.8963479359663835, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005335807800292969, "StateBufferConnector_ms": 0.0047588348388671875, "ViewRequirementAgentConnector_ms": 0.13306093215942383}, "num_episodes": 22, "episode_return_max": 3.9999999999999587, "episode_return_min": -32.360000000000575, "episode_return_mean": -6.646999999999978, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1008000, "num_agent_steps_trained": 1008000, "num_env_steps_sampled": 252000, "num_env_steps_trained": 252000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 374.8288833337388, "num_env_steps_trained_throughput_per_sec": 374.8288833337388, "timesteps_total": 252000, "num_env_steps_sampled_lifetime": 252000, "num_agent_steps_sampled_lifetime": 1008000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1008000, "timers": {"training_iteration_time_ms": 196721.302, "restore_workers_time_ms": 0.013, "training_step_time_ms": 196721.256, "sample_time_ms": 93150.231, "learn_time_ms": 103550.781, "learn_throughput": 38.628, "synch_weights_time_ms": 17.165}, "counters": {"num_env_steps_sampled": 252000, "num_env_steps_trained": 252000, "num_agent_steps_sampled": 1008000, "num_agent_steps_trained": 1008000}, "done": false, "training_iteration": 63, "trial_id": "8e499_00000", "date": "2024-08-15_02-54-01", "timestamp": 1723670641, "time_this_iter_s": 10.71173620223999, "time_total_s": 2981.0898089408875, "pid": 33199, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x1580f83a0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2981.0898089408875, "iterations_since_restore": 63, "perf": {"cpu_util_percent": 30.853333333333335, "ram_util_percent": 82.14}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3039013065200633, "cur_kl_coeff": 0.028125000000000008, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.516860361491877, "policy_loss": -0.005288053442177081, "vf_loss": 0.5218916661702293, "vf_explained_var": 0.05714031126764085, "kl": 0.009128877648071413, "entropy": 0.727779148589997, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 120015.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1550519097103644, "cur_kl_coeff": 0.056250000000000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.4802665529622808, "policy_loss": -0.00919862121796955, "vf_loss": 0.48915537631782213, "vf_explained_var": 0.08764733539687262, "kl": 0.0055074979773582534, "entropy": 0.6626459357915101, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 120015.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 256000, "num_env_steps_trained": 256000, "num_agent_steps_sampled": 1024000, "num_agent_steps_trained": 1024000}, "env_runners": {"episode_reward_max": 3.9999999999999587, "episode_reward_min": -32.470000000000375, "episode_reward_mean": -7.877699999999967, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -108.54999999999929, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 2.0000000000000013, "predator_policy": 48.0}, "policy_reward_mean": {"prey_policy": -11.838849999999969, "predator_policy": 7.9}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.9800000000000026, -1.0600000000000596, -14.16999999999975, -9.130000000000082, -4.080000000000084, -14.229999999999748, -3.070000000000082, -7.110000000000083, -13.169999999999916, -10.130000000000082, -0.1200000000000392, -1.050000000000063, -0.04000000000003744, -12.160000000000082, -16.19999999999941, 2.939999999999982, -8.120000000000083, -12.160000000000078, -2.060000000000084, -4.130000000000081, -2.060000000000083, 3.9699999999999593, 3.9499999999999598, 0.9399999999999858, -17.19999999999941, 1.9400000000000026, -32.360000000000575, -17.209999999999408, -5.080000000000084, -0.060000000000041, -17.189999999999404, -12.310000000000077, 3.9199999999999604, -8.120000000000083, -25.289999999999452, -1.2000000000000615, -3.100000000000083, 0.8899999999999836, -14.179999999999739, -21.299999999999443, -7.110000000000083, -1.050000000000063, -14.17999999999976, 0.9299999999999827, -0.050000000000032116, 2.989999999999981, -7.110000000000083, -4.080000000000084, -4.080000000000084, -30.300000000000104, -9.150000000000082, 0.949999999999981, -2.0900000000000825, -8.110000000000083, 2.989999999999981, -3.0700000000000838, -4.070000000000084, -13.20999999999993, -14.179999999999739, -1.1600000000000623, -7.110000000000083, -9.24000000000008, -4.220000000000066, 0.969999999999981, -0.040000000000040996, 3.9999999999999587, -29.339999999999627, -5.090000000000083, -4.080000000000082, -2.060000000000084, -4.240000000000053, -28.55999999999958, -22.259999999999415, -7.110000000000083, -17.209999999999418, -10.160000000000082, -12.230000000000079, 1.9700000000000024, -4.080000000000084, 0.9499999999999819, -13.169999999999952, 1.980000000000003, -32.470000000000375, -13.129999999999924, -12.140000000000082, -30.4, 0.969999999999981, -2.060000000000084, -29.31999999999971, -31.32000000000044, 3.9999999999999587, 2.9799999999999813, -22.259999999999433, -16.199999999999406, -1.050000000000063, -2.060000000000084, -28.369999999999518, -2.0800000000000827, 1.980000000000003, -1.0500000000000622], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-2.020000000000042, 2.0000000000000013, -0.00999999999999836, -8.05000000000004, -30.159999999999712, -0.00999999999999836, -18.099999999999703, -4.030000000000042, -2.020000000000042, -10.06000000000004, -14.080000000000041, -28.14999999999971, -12.070000000000041, 2.0000000000000013, -4.030000000000042, -14.080000000000041, -10.060000000000041, -20.109999999999705, -6.040000000000042, -16.089999999999705, -22.119999999999706, 2.0000000000000013, -8.050000000000042, 2.0000000000000013, -0.00999999999999836, -4.03000000000004, -10.060000000000041, -18.099999999999703, -22.119999999999706, -14.080000000000041, -10.060000000000041, 2.0000000000000013, 2.0000000000000013, -22.119999999999717, -18.09999999999971, -10.060000000000036, -10.060000000000041, 2.0000000000000013, -14.080000000000041, -8.05000000000004, 2.0000000000000013, -10.060000000000041, -4.030000000000042, 2.0000000000000013, 2.0000000000000013, -8.050000000000042, -10.060000000000041, 2.0000000000000013, -18.099999999999707, -18.099999999999703, -10.060000000000041, 2.0000000000000013, -32.170000000000364, -36.19000000000028, -16.0899999999997, -22.119999999999706, -0.00999999999999836, -12.070000000000041, -8.050000000000042, -0.00999999999999836, -22.119999999999706, -12.070000000000041, -54.28000000000034, -4.030000000000042, 2.0000000000000013, -14.080000000000041, -12.07000000000004, -8.050000000000042, 2.0000000000000013, -56.29000000000033, 2.0000000000000013, -38.20000000000036, -16.0899999999997, -0.00999999999999836, 2.0000000000000013, -20.109999999999705, -8.050000000000042, -24.129999999999708, -42.22000000000035, -14.080000000000041, -12.070000000000041, -6.040000000000042, -8.050000000000042, 2.0000000000000013, -28.149999999999718, -4.030000000000042, 2.0000000000000013, -12.070000000000041, -2.0200000000000378, -4.030000000000042, -0.00999999999999836, 2.0000000000000013, -2.020000000000042, -16.0899999999997, 2.0000000000000013, -14.080000000000041, -4.030000000000042, -8.050000000000042, -36.19000000000036, -20.109999999999705, -6.040000000000042, -20.109999999999705, -8.050000000000042, 2.0000000000000013, 2.0000000000000013, -16.0899999999997, -16.0899999999997, -2.020000000000042, 2.0000000000000013, -0.00999999999999836, -8.050000000000042, -2.020000000000042, -10.060000000000041, -0.00999999999999836, -12.070000000000041, -26.139999999999716, -16.089999999999712, -16.0899999999997, -8.050000000000042, -20.109999999999708, -4.030000000000042, -14.080000000000041, -2.020000000000042, -42.220000000000354, -16.0899999999997, -24.12999999999984, -2.020000000000042, -0.00999999999999836, -6.040000000000042, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, -0.00999999999999836, -64.32999999999922, 2.0000000000000013, -16.0899999999997, -14.080000000000041, 2.0000000000000013, -0.00999999999999836, -8.050000000000042, -26.13999999999971, -18.09999999999984, -108.54999999999929, -0.00999999999999836, -34.18000000000008, -14.080000000000041, -20.109999999999705, 2.0000000000000013, -30.159999999999712, -8.050000000000042, -6.040000000000042, -22.119999999999706, -38.20000000000035, -4.030000000000042, -4.030000000000042, 2.0000000000000013, 2.0000000000000013, -14.080000000000041, 2.0000000000000013, -8.050000000000042, -24.129999999999725, -6.040000000000042, -0.00999999999999836, -0.009999999999998581, -12.070000000000041, -78.39999999999931, -12.070000000000041, -10.060000000000041, -12.070000000000041, -12.070000000000041, -24.129999999999708, -52.27000000000029, -2.020000000000042, -0.00999999999999836, -10.060000000000041, 2.0000000000000013, -6.040000000000042, -54.28000000000034, -10.060000000000038, -50.260000000000346, 2.0000000000000013, 2.0000000000000013, -2.0200000000000418, 2.0000000000000013, -34.18000000000035, -14.080000000000041, -16.0899999999997, -20.109999999999705, -6.040000000000042, -0.00999999999999836, -4.030000000000042, -4.030000000000042, -68.34999999999927, -2.020000000000042, 2.0000000000000013, -14.080000000000041, 2.0000000000000013, -2.020000000000037, 2.0000000000000013, -8.050000000000042], "policy_predator_policy_reward": [2.0, 0.0, 1.0, 6.0, 16.0, 0.0, 10.0, 3.0, 7.0, 1.0, 13.0, 15.0, 0.0, 7.0, 8.0, 3.0, 6.0, 11.0, 3.0, 9.0, 8.0, 12.0, 0.0, 5.0, 1.0, 3.0, 10.0, 6.0, 12.0, 8.0, 5.0, 6.0, 7.0, 5.0, 10.0, 6.0, 0.0, 6.0, 10.0, 8.0, 6.0, 0.0, 3.0, 3.0, 5.0, 5.0, 6.0, 3.0, 8.0, 11.0, 6.0, 4.0, 25.0, 11.0, 9.0, 12.0, 0.0, 7.0, 3.0, 5.0, 12.0, 5.0, 26.0, 20.0, 8.0, 8.0, 5.0, 7.0, 20.0, 9.0, 18.0, 17.0, 4.0, 9.0, 11.0, 8.0, 5.0, 13.0, 20.0, 15.0, 7.0, 4.0, 0.0, 5.0, 8.0, 10.0, 7.0, 4.0, 3.0, 3.0, 0.0, 1.0, 2.0, 9.0, 8.0, 0.0, 3.0, 5.0, 5.0, 21.0, 11.0, 6.0, 4.0, 3.0, 8.0, 4.0, 1.0, 9.0, 0.0, 1.0, 2.0, 5.0, 0.0, 6.0, 7.0, 18.0, 9.0, 9.0, 13.0, 14.0, 3.0, 8.0, 14.0, 21.0, 18.0, 18.0, 2.0, 1.0, 4.0, 0.0, 0.0, 0.0, 28.0, 7.0, 0.0, 9.0, 0.0, 8.0, 1.0, 5.0, 23.0, 17.0, 32.0, 48.0, 10.0, 16.0, 11.0, 0.0, 15.0, 6.0, 6.0, 12.0, 18.0, 12.0, 3.0, 1.0, 8.0, 0.0, 2.0, 5.0, 4.0, 13.0, 1.0, 1.0, 25.0, 33.0, 8.0, 1.0, 5.0, 7.0, 16.0, 30.0, 1.0, 2.0, 0.0, 6.0, 5.0, 26.0, 1.0, 28.0, 0.0, 0.0, 2.0, 1.0, 21.0, 5.0, 9.0, 11.0, 1.0, 4.0, 3.0, 3.0, 15.0, 27.0, 5.0, 5.0, 2.0, 0.0, 0.0, 5.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 7.559968144098002, "mean_inference_ms": 24.482292328177994, "mean_action_processing_ms": 0.25777396498733085, "mean_env_wait_ms": 3.842734710776132, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005158185958862305, "StateBufferConnector_ms": 0.004179835319519043, "ViewRequirementAgentConnector_ms": 0.12020552158355713}, "num_episodes": 23, "episode_return_max": 3.9999999999999587, "episode_return_min": -32.470000000000375, "episode_return_mean": -7.877699999999967, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1024000, "num_agent_steps_trained": 1024000, "num_env_steps_sampled": 256000, "num_env_steps_trained": 256000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 388.3032539703884, "num_env_steps_trained_throughput_per_sec": 388.3032539703884, "timesteps_total": 256000, "num_env_steps_sampled_lifetime": 256000, "num_agent_steps_sampled_lifetime": 1024000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1024000, "timers": {"training_iteration_time_ms": 196731.952, "restore_workers_time_ms": 0.013, "training_step_time_ms": 196731.906, "sample_time_ms": 93152.635, "learn_time_ms": 103559.105, "learn_throughput": 38.625, "synch_weights_time_ms": 17.151}, "counters": {"num_env_steps_sampled": 256000, "num_env_steps_trained": 256000, "num_agent_steps_sampled": 1024000, "num_agent_steps_trained": 1024000}, "done": false, "training_iteration": 64, "trial_id": "8e499_00000", "date": "2024-08-15_02-54-12", "timestamp": 1723670652, "time_this_iter_s": 10.353183031082153, "time_total_s": 2991.4429919719696, "pid": 33199, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b43f2430>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2991.4429919719696, "iterations_since_restore": 64, "perf": {"cpu_util_percent": 31.099999999999998, "ram_util_percent": 82.38571428571427}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2521434658103519, "cur_kl_coeff": 0.028125000000000008, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.5571539250867708, "policy_loss": -0.005091473194474857, "vf_loss": 0.5620488674305971, "vf_explained_var": 0.08119307904647141, "kl": 0.006987755029013529, "entropy": 0.6564998034762327, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 121905.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9587154137867469, "cur_kl_coeff": 0.056250000000000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.6747098055738394, "policy_loss": -0.008454505578496509, "vf_loss": 0.6827761593102305, "vf_explained_var": 0.08004037006191475, "kl": 0.0069004704220537675, "entropy": 0.675673683358248, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 121905.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 260000, "num_env_steps_trained": 260000, "num_agent_steps_sampled": 1040000, "num_agent_steps_trained": 1040000}, "env_runners": {"episode_reward_max": 3.9999999999999587, "episode_reward_min": -57.61000000000056, "episode_reward_mean": -8.163199999999971, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -108.5499999999993, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 2.0000000000000013, "predator_policy": 52.0}, "policy_reward_mean": {"prey_policy": -12.391599999999976, "predator_policy": 8.31}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-2.060000000000084, -4.130000000000081, -2.060000000000083, 3.9699999999999593, 3.9499999999999598, 0.9399999999999858, -17.19999999999941, 1.9400000000000026, -32.360000000000575, -17.209999999999408, -5.080000000000084, -0.060000000000041, -17.189999999999404, -12.310000000000077, 3.9199999999999604, -8.120000000000083, -25.289999999999452, -1.2000000000000615, -3.100000000000083, 0.8899999999999836, -14.179999999999739, -21.299999999999443, -7.110000000000083, -1.050000000000063, -14.17999999999976, 0.9299999999999827, -0.050000000000032116, 2.989999999999981, -7.110000000000083, -4.080000000000084, -4.080000000000084, -30.300000000000104, -9.150000000000082, 0.949999999999981, -2.0900000000000825, -8.110000000000083, 2.989999999999981, -3.0700000000000838, -4.070000000000084, -13.20999999999993, -14.179999999999739, -1.1600000000000623, -7.110000000000083, -9.24000000000008, -4.220000000000066, 0.969999999999981, -0.040000000000040996, 3.9999999999999587, -29.339999999999627, -5.090000000000083, -4.080000000000082, -2.060000000000084, -4.240000000000053, -28.55999999999958, -22.259999999999415, -7.110000000000083, -17.209999999999418, -10.160000000000082, -12.230000000000079, 1.9700000000000024, -4.080000000000084, 0.9499999999999819, -13.169999999999952, 1.980000000000003, -32.470000000000375, -13.129999999999924, -12.140000000000082, -30.4, 0.969999999999981, -2.060000000000084, -29.31999999999971, -31.32000000000044, 3.9999999999999587, 2.9799999999999813, -22.259999999999433, -16.199999999999406, -1.050000000000063, -2.060000000000084, -28.369999999999518, -2.0800000000000827, 1.980000000000003, -1.0500000000000622, -22.25999999999944, -57.61000000000056, 0.9699999999999819, -7.110000000000083, 2.989999999999981, -2.110000000000083, 1.9500000000000028, 2.809999999999985, -7.110000000000083, -11.150000000000082, 2.849999999999984, -27.309999999999448, -6.090000000000083, 3.9699999999999593, -5.090000000000083, 2.9699999999999815, -9.130000000000082, -13.16999999999993], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-10.060000000000041, 2.0000000000000013, -14.080000000000041, -8.05000000000004, 2.0000000000000013, -10.060000000000041, -4.030000000000042, 2.0000000000000013, 2.0000000000000013, -8.050000000000042, -10.060000000000041, 2.0000000000000013, -18.099999999999707, -18.099999999999703, -10.060000000000041, 2.0000000000000013, -32.170000000000364, -36.19000000000028, -16.0899999999997, -22.119999999999706, -0.00999999999999836, -12.070000000000041, -8.050000000000042, -0.00999999999999836, -22.119999999999706, -12.070000000000041, -54.28000000000034, -4.030000000000042, 2.0000000000000013, -14.080000000000041, -12.07000000000004, -8.050000000000042, 2.0000000000000013, -56.29000000000033, 2.0000000000000013, -38.20000000000036, -16.0899999999997, -0.00999999999999836, 2.0000000000000013, -20.109999999999705, -8.050000000000042, -24.129999999999708, -42.22000000000035, -14.080000000000041, -12.070000000000041, -6.040000000000042, -8.050000000000042, 2.0000000000000013, -28.149999999999718, -4.030000000000042, 2.0000000000000013, -12.070000000000041, -2.0200000000000378, -4.030000000000042, -0.00999999999999836, 2.0000000000000013, -2.020000000000042, -16.0899999999997, 2.0000000000000013, -14.080000000000041, -4.030000000000042, -8.050000000000042, -36.19000000000036, -20.109999999999705, -6.040000000000042, -20.109999999999705, -8.050000000000042, 2.0000000000000013, 2.0000000000000013, -16.0899999999997, -16.0899999999997, -2.020000000000042, 2.0000000000000013, -0.00999999999999836, -8.050000000000042, -2.020000000000042, -10.060000000000041, -0.00999999999999836, -12.070000000000041, -26.139999999999716, -16.089999999999712, -16.0899999999997, -8.050000000000042, -20.109999999999708, -4.030000000000042, -14.080000000000041, -2.020000000000042, -42.220000000000354, -16.0899999999997, -24.12999999999984, -2.020000000000042, -0.00999999999999836, -6.040000000000042, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, -0.00999999999999836, -64.32999999999922, 2.0000000000000013, -16.0899999999997, -14.080000000000041, 2.0000000000000013, -0.00999999999999836, -8.050000000000042, -26.13999999999971, -18.09999999999984, -108.54999999999929, -0.00999999999999836, -34.18000000000008, -14.080000000000041, -20.109999999999705, 2.0000000000000013, -30.159999999999712, -8.050000000000042, -6.040000000000042, -22.119999999999706, -38.20000000000035, -4.030000000000042, -4.030000000000042, 2.0000000000000013, 2.0000000000000013, -14.080000000000041, 2.0000000000000013, -8.050000000000042, -24.129999999999725, -6.040000000000042, -0.00999999999999836, -0.009999999999998581, -12.070000000000041, -78.39999999999931, -12.070000000000041, -10.060000000000041, -12.070000000000041, -12.070000000000041, -24.129999999999708, -52.27000000000029, -2.020000000000042, -0.00999999999999836, -10.060000000000041, 2.0000000000000013, -6.040000000000042, -54.28000000000034, -10.060000000000038, -50.260000000000346, 2.0000000000000013, 2.0000000000000013, -2.0200000000000418, 2.0000000000000013, -34.18000000000035, -14.080000000000041, -16.0899999999997, -20.109999999999705, -6.040000000000042, -0.00999999999999836, -4.030000000000042, -4.030000000000042, -68.34999999999927, -2.020000000000042, 2.0000000000000013, -14.080000000000041, 2.0000000000000013, -2.020000000000037, 2.0000000000000013, -8.050000000000042, -0.00999999999999836, -48.25000000000035, -108.5499999999993, -10.060000000000041, 2.0000000000000013, -4.030000000000042, -20.109999999999705, 2.0000000000000013, 2.0000000000000013, -0.00999999999999836, -14.080000000000041, -4.030000000000042, 2.0000000000000013, -8.050000000000042, 2.0000000000000013, -36.19000000000036, -12.070000000000041, -6.040000000000042, -20.109999999999705, -6.040000000000042, -28.14999999999971, 2.0000000000000013, -36.19000000000036, -22.11999999999974, -8.050000000000042, -6.040000000000042, -4.030000000000042, 2.0000000000000013, -0.00999999999999836, -14.080000000000041, -4.030000000000042, 2.0000000000000013, -16.0899999999997, -6.040000000000042, -28.149999999999714, -2.020000000000042], "policy_predator_policy_reward": [0.0, 6.0, 10.0, 8.0, 6.0, 0.0, 3.0, 3.0, 5.0, 5.0, 6.0, 3.0, 8.0, 11.0, 6.0, 4.0, 25.0, 11.0, 9.0, 12.0, 0.0, 7.0, 3.0, 5.0, 12.0, 5.0, 26.0, 20.0, 8.0, 8.0, 5.0, 7.0, 20.0, 9.0, 18.0, 17.0, 4.0, 9.0, 11.0, 8.0, 5.0, 13.0, 20.0, 15.0, 7.0, 4.0, 0.0, 5.0, 8.0, 10.0, 7.0, 4.0, 3.0, 3.0, 0.0, 1.0, 2.0, 9.0, 8.0, 0.0, 3.0, 5.0, 5.0, 21.0, 11.0, 6.0, 4.0, 3.0, 8.0, 4.0, 1.0, 9.0, 0.0, 1.0, 2.0, 5.0, 0.0, 6.0, 7.0, 18.0, 9.0, 9.0, 13.0, 14.0, 3.0, 8.0, 14.0, 21.0, 18.0, 18.0, 2.0, 1.0, 4.0, 0.0, 0.0, 0.0, 28.0, 7.0, 0.0, 9.0, 0.0, 8.0, 1.0, 5.0, 23.0, 17.0, 32.0, 48.0, 10.0, 16.0, 11.0, 0.0, 15.0, 6.0, 6.0, 12.0, 18.0, 12.0, 3.0, 1.0, 8.0, 0.0, 2.0, 5.0, 4.0, 13.0, 1.0, 1.0, 25.0, 33.0, 8.0, 1.0, 5.0, 7.0, 16.0, 30.0, 1.0, 2.0, 0.0, 6.0, 5.0, 26.0, 1.0, 28.0, 0.0, 0.0, 2.0, 1.0, 21.0, 5.0, 9.0, 11.0, 1.0, 4.0, 3.0, 3.0, 15.0, 27.0, 5.0, 5.0, 2.0, 0.0, 0.0, 5.0, 1.0, 25.0, 52.0, 9.0, 0.0, 3.0, 11.0, 0.0, 1.0, 0.0, 8.0, 8.0, 3.0, 5.0, 19.0, 18.0, 4.0, 7.0, 11.0, 4.0, 15.0, 14.0, 1.0, 30.0, 3.0, 5.0, 3.0, 3.0, 1.0, 8.0, 2.0, 3.0, 4.0, 9.0, 12.0, 5.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 8.138282527586705, "mean_inference_ms": 23.475886328311436, "mean_action_processing_ms": 0.25707875494180443, "mean_env_wait_ms": 3.789707779459442, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004139304161071777, "StateBufferConnector_ms": 0.0033121109008789062, "ViewRequirementAgentConnector_ms": 0.10181629657745361}, "num_episodes": 18, "episode_return_max": 3.9999999999999587, "episode_return_min": -57.61000000000056, "episode_return_mean": -8.163199999999971, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1040000, "num_agent_steps_trained": 1040000, "num_env_steps_sampled": 260000, "num_env_steps_trained": 260000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 4.170680572902107, "num_env_steps_trained_throughput_per_sec": 4.170680572902107, "timesteps_total": 260000, "num_env_steps_sampled_lifetime": 260000, "num_agent_steps_sampled_lifetime": 1040000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1040000, "timers": {"training_iteration_time_ms": 291511.077, "restore_workers_time_ms": 0.013, "training_step_time_ms": 291511.033, "sample_time_ms": 93137.732, "learn_time_ms": 198352.18, "learn_throughput": 20.166, "synch_weights_time_ms": 17.954}, "counters": {"num_env_steps_sampled": 260000, "num_env_steps_trained": 260000, "num_agent_steps_sampled": 1040000, "num_agent_steps_trained": 1040000}, "done": false, "training_iteration": 65, "trial_id": "8e499_00000", "date": "2024-08-15_03-10-11", "timestamp": 1723671611, "time_this_iter_s": 959.1441700458527, "time_total_s": 3950.5871620178223, "pid": 33199, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x1580f8040>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3950.5871620178223, "iterations_since_restore": 65, "perf": {"cpu_util_percent": 46.788888888888884, "ram_util_percent": 83.05000000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.090747109426077, "cur_kl_coeff": 0.028125000000000008, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.41662944558436277, "policy_loss": -0.007519886761696802, "vf_loss": 0.4240076096245536, "vf_explained_var": 0.23484596077096526, "kl": 0.005039048609405269, "entropy": 0.6526321764660891, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 123795.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8933957708181528, "cur_kl_coeff": 0.056250000000000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.47310433583301753, "policy_loss": -0.008575335749124408, "vf_loss": 0.4812667364077199, "vf_explained_var": 0.03717016092053166, "kl": 0.00734107956882441, "entropy": 0.556569331095963, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 123795.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 264000, "num_env_steps_trained": 264000, "num_agent_steps_sampled": 1056000, "num_agent_steps_trained": 1056000}, "env_runners": {"episode_reward_max": 3.9999999999999587, "episode_reward_min": -79.81999999999859, "episode_reward_mean": -9.079999999999961, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -150.76000000000073, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 2.0000000000000013, "predator_policy": 76.0}, "policy_reward_mean": {"prey_policy": -13.07499999999997, "predator_policy": 8.535}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-3.100000000000083, 0.8899999999999836, -14.179999999999739, -21.299999999999443, -7.110000000000083, -1.050000000000063, -14.17999999999976, 0.9299999999999827, -0.050000000000032116, 2.989999999999981, -7.110000000000083, -4.080000000000084, -4.080000000000084, -30.300000000000104, -9.150000000000082, 0.949999999999981, -2.0900000000000825, -8.110000000000083, 2.989999999999981, -3.0700000000000838, -4.070000000000084, -13.20999999999993, -14.179999999999739, -1.1600000000000623, -7.110000000000083, -9.24000000000008, -4.220000000000066, 0.969999999999981, -0.040000000000040996, 3.9999999999999587, -29.339999999999627, -5.090000000000083, -4.080000000000082, -2.060000000000084, -4.240000000000053, -28.55999999999958, -22.259999999999415, -7.110000000000083, -17.209999999999418, -10.160000000000082, -12.230000000000079, 1.9700000000000024, -4.080000000000084, 0.9499999999999819, -13.169999999999952, 1.980000000000003, -32.470000000000375, -13.129999999999924, -12.140000000000082, -30.4, 0.969999999999981, -2.060000000000084, -29.31999999999971, -31.32000000000044, 3.9999999999999587, 2.9799999999999813, -22.259999999999433, -16.199999999999406, -1.050000000000063, -2.060000000000084, -28.369999999999518, -2.0800000000000827, 1.980000000000003, -1.0500000000000622, -22.25999999999944, -57.61000000000056, 0.9699999999999819, -7.110000000000083, 2.989999999999981, -2.110000000000083, 1.9500000000000028, 2.809999999999985, -7.110000000000083, -11.150000000000082, 2.849999999999984, -27.309999999999448, -6.090000000000083, 3.9699999999999593, -5.090000000000083, 2.9699999999999815, -9.130000000000082, -13.16999999999993, -16.19999999999943, 2.989999999999981, -1.050000000000063, -1.2300000000000588, -75.78999999999907, -2.060000000000083, -2.060000000000084, -5.090000000000083, -79.81999999999859, -4.080000000000084, 2.899999999999983, -0.050000000000041, -1.050000000000063, -7.110000000000083, -9.130000000000082, -14.179999999999728, -8.120000000000083, -0.10000000000004099], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-16.0899999999997, -0.00999999999999836, 2.0000000000000013, -20.109999999999705, -8.050000000000042, -24.129999999999708, -42.22000000000035, -14.080000000000041, -12.070000000000041, -6.040000000000042, -8.050000000000042, 2.0000000000000013, -28.149999999999718, -4.030000000000042, 2.0000000000000013, -12.070000000000041, -2.0200000000000378, -4.030000000000042, -0.00999999999999836, 2.0000000000000013, -2.020000000000042, -16.0899999999997, 2.0000000000000013, -14.080000000000041, -4.030000000000042, -8.050000000000042, -36.19000000000036, -20.109999999999705, -6.040000000000042, -20.109999999999705, -8.050000000000042, 2.0000000000000013, 2.0000000000000013, -16.0899999999997, -16.0899999999997, -2.020000000000042, 2.0000000000000013, -0.00999999999999836, -8.050000000000042, -2.020000000000042, -10.060000000000041, -0.00999999999999836, -12.070000000000041, -26.139999999999716, -16.089999999999712, -16.0899999999997, -8.050000000000042, -20.109999999999708, -4.030000000000042, -14.080000000000041, -2.020000000000042, -42.220000000000354, -16.0899999999997, -24.12999999999984, -2.020000000000042, -0.00999999999999836, -6.040000000000042, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, -0.00999999999999836, -64.32999999999922, 2.0000000000000013, -16.0899999999997, -14.080000000000041, 2.0000000000000013, -0.00999999999999836, -8.050000000000042, -26.13999999999971, -18.09999999999984, -108.54999999999929, -0.00999999999999836, -34.18000000000008, -14.080000000000041, -20.109999999999705, 2.0000000000000013, -30.159999999999712, -8.050000000000042, -6.040000000000042, -22.119999999999706, -38.20000000000035, -4.030000000000042, -4.030000000000042, 2.0000000000000013, 2.0000000000000013, -14.080000000000041, 2.0000000000000013, -8.050000000000042, -24.129999999999725, -6.040000000000042, -0.00999999999999836, -0.009999999999998581, -12.070000000000041, -78.39999999999931, -12.070000000000041, -10.060000000000041, -12.070000000000041, -12.070000000000041, -24.129999999999708, -52.27000000000029, -2.020000000000042, -0.00999999999999836, -10.060000000000041, 2.0000000000000013, -6.040000000000042, -54.28000000000034, -10.060000000000038, -50.260000000000346, 2.0000000000000013, 2.0000000000000013, -2.0200000000000418, 2.0000000000000013, -34.18000000000035, -14.080000000000041, -16.0899999999997, -20.109999999999705, -6.040000000000042, -0.00999999999999836, -4.030000000000042, -4.030000000000042, -68.34999999999927, -2.020000000000042, 2.0000000000000013, -14.080000000000041, 2.0000000000000013, -2.020000000000037, 2.0000000000000013, -8.050000000000042, -0.00999999999999836, -48.25000000000035, -108.5499999999993, -10.060000000000041, 2.0000000000000013, -4.030000000000042, -20.109999999999705, 2.0000000000000013, 2.0000000000000013, -0.00999999999999836, -14.080000000000041, -4.030000000000042, 2.0000000000000013, -8.050000000000042, 2.0000000000000013, -36.19000000000036, -12.070000000000041, -6.040000000000042, -20.109999999999705, -6.040000000000042, -28.14999999999971, 2.0000000000000013, -36.19000000000036, -22.11999999999974, -8.050000000000042, -6.040000000000042, -4.030000000000042, 2.0000000000000013, -0.00999999999999836, -14.080000000000041, -4.030000000000042, 2.0000000000000013, -16.0899999999997, -6.040000000000042, -28.149999999999714, -2.020000000000042, -8.050000000000042, -28.149999999999714, 2.0000000000000013, -0.00999999999999836, -0.00999999999999836, -6.040000000000042, -8.050000000000042, -34.18000000000031, -150.76000000000073, -4.030000000000042, -10.060000000000041, 2.0000000000000013, -4.030000000000042, -4.030000000000042, -6.040000000000042, -8.050000000000042, -46.24000000000035, -114.57999999999927, -10.060000000000041, -2.020000000000041, 2.0000000000000013, -18.099999999999703, -0.00999999999999836, -6.040000000000042, -8.050000000000042, 2.0000000000000013, -10.060000000000041, -8.050000000000042, -14.080000000000041, -8.050000000000038, -18.099999999999703, -14.080000000000041, -4.030000000000042, -16.08999999999971, -16.0899999999997, -0.00999999999999836], "policy_predator_policy_reward": [4.0, 9.0, 11.0, 8.0, 5.0, 13.0, 20.0, 15.0, 7.0, 4.0, 0.0, 5.0, 8.0, 10.0, 7.0, 4.0, 3.0, 3.0, 0.0, 1.0, 2.0, 9.0, 8.0, 0.0, 3.0, 5.0, 5.0, 21.0, 11.0, 6.0, 4.0, 3.0, 8.0, 4.0, 1.0, 9.0, 0.0, 1.0, 2.0, 5.0, 0.0, 6.0, 7.0, 18.0, 9.0, 9.0, 13.0, 14.0, 3.0, 8.0, 14.0, 21.0, 18.0, 18.0, 2.0, 1.0, 4.0, 0.0, 0.0, 0.0, 28.0, 7.0, 0.0, 9.0, 0.0, 8.0, 1.0, 5.0, 23.0, 17.0, 32.0, 48.0, 10.0, 16.0, 11.0, 0.0, 15.0, 6.0, 6.0, 12.0, 18.0, 12.0, 3.0, 1.0, 8.0, 0.0, 2.0, 5.0, 4.0, 13.0, 1.0, 1.0, 25.0, 33.0, 8.0, 1.0, 5.0, 7.0, 16.0, 30.0, 1.0, 2.0, 0.0, 6.0, 5.0, 26.0, 1.0, 28.0, 0.0, 0.0, 2.0, 1.0, 21.0, 5.0, 9.0, 11.0, 1.0, 4.0, 3.0, 3.0, 15.0, 27.0, 5.0, 5.0, 2.0, 0.0, 0.0, 5.0, 1.0, 25.0, 52.0, 9.0, 0.0, 3.0, 11.0, 0.0, 1.0, 0.0, 8.0, 8.0, 3.0, 5.0, 19.0, 18.0, 4.0, 7.0, 11.0, 4.0, 15.0, 14.0, 1.0, 30.0, 3.0, 5.0, 3.0, 3.0, 1.0, 8.0, 2.0, 3.0, 4.0, 9.0, 12.0, 5.0, 15.0, 5.0, 0.0, 1.0, 4.0, 1.0, 21.0, 20.0, 76.0, 3.0, 6.0, 0.0, 3.0, 3.0, 4.0, 5.0, 64.0, 17.0, 8.0, 0.0, 9.0, 10.0, 2.0, 4.0, 5.0, 0.0, 6.0, 5.0, 0.0, 13.0, 10.0, 8.0, 12.0, 0.0, 9.0, 7.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 8.031867783195546, "mean_inference_ms": 23.17367187919656, "mean_action_processing_ms": 0.25760627968635263, "mean_env_wait_ms": 3.739340321653935, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0047380924224853516, "StateBufferConnector_ms": 0.0038319826126098633, "ViewRequirementAgentConnector_ms": 0.11420893669128418}, "num_episodes": 18, "episode_return_max": 3.9999999999999587, "episode_return_min": -79.81999999999859, "episode_return_mean": -9.079999999999961, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1056000, "num_agent_steps_trained": 1056000, "num_env_steps_sampled": 264000, "num_env_steps_trained": 264000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 263.57892780137144, "num_env_steps_trained_throughput_per_sec": 263.57892780137144, "timesteps_total": 264000, "num_env_steps_sampled_lifetime": 264000, "num_agent_steps_sampled_lifetime": 1056000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1056000, "timers": {"training_iteration_time_ms": 200254.42, "restore_workers_time_ms": 0.013, "training_step_time_ms": 200254.377, "sample_time_ms": 1746.726, "learn_time_ms": 198488.387, "learn_throughput": 20.152, "synch_weights_time_ms": 16.944}, "counters": {"num_env_steps_sampled": 264000, "num_env_steps_trained": 264000, "num_agent_steps_sampled": 1056000, "num_agent_steps_trained": 1056000}, "done": false, "training_iteration": 66, "trial_id": "8e499_00000", "date": "2024-08-15_03-10-26", "timestamp": 1723671626, "time_this_iter_s": 15.243363857269287, "time_total_s": 3965.8305258750916, "pid": 33199, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b43f3790>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3965.8305258750916, "iterations_since_restore": 66, "perf": {"cpu_util_percent": 71.49545454545456, "ram_util_percent": 81.1590909090909}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9279334022018014, "cur_kl_coeff": 0.028125000000000008, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.3873418194118631, "policy_loss": -0.0052317392669874365, "vf_loss": 0.3923763068658965, "vf_explained_var": 0.23115148493852564, "kl": 0.00701341866767421, "entropy": 0.6361699745768592, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 125685.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9294913854706224, "cur_kl_coeff": 0.056250000000000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.5690343070937882, "policy_loss": -0.013214964372790837, "vf_loss": 0.5808129091724931, "vf_explained_var": 0.013931877556301299, "kl": 0.025535291376656853, "entropy": 0.570808616958598, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 125685.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 268000, "num_env_steps_trained": 268000, "num_agent_steps_sampled": 1072000, "num_agent_steps_trained": 1072000}, "env_runners": {"episode_reward_max": 3.9999999999999587, "episode_reward_min": -181.31000000000134, "episode_reward_mean": -11.569699999999962, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -150.76000000000073, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 2.0000000000000013, "predator_policy": 76.0}, "policy_reward_mean": {"prey_policy": -15.054849999999979, "predator_policy": 9.27}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-14.179999999999739, -1.1600000000000623, -7.110000000000083, -9.24000000000008, -4.220000000000066, 0.969999999999981, -0.040000000000040996, 3.9999999999999587, -29.339999999999627, -5.090000000000083, -4.080000000000082, -2.060000000000084, -4.240000000000053, -28.55999999999958, -22.259999999999415, -7.110000000000083, -17.209999999999418, -10.160000000000082, -12.230000000000079, 1.9700000000000024, -4.080000000000084, 0.9499999999999819, -13.169999999999952, 1.980000000000003, -32.470000000000375, -13.129999999999924, -12.140000000000082, -30.4, 0.969999999999981, -2.060000000000084, -29.31999999999971, -31.32000000000044, 3.9999999999999587, 2.9799999999999813, -22.259999999999433, -16.199999999999406, -1.050000000000063, -2.060000000000084, -28.369999999999518, -2.0800000000000827, 1.980000000000003, -1.0500000000000622, -22.25999999999944, -57.61000000000056, 0.9699999999999819, -7.110000000000083, 2.989999999999981, -2.110000000000083, 1.9500000000000028, 2.809999999999985, -7.110000000000083, -11.150000000000082, 2.849999999999984, -27.309999999999448, -6.090000000000083, 3.9699999999999593, -5.090000000000083, 2.9699999999999815, -9.130000000000082, -13.16999999999993, -16.19999999999943, 2.989999999999981, -1.050000000000063, -1.2300000000000588, -75.78999999999907, -2.060000000000083, -2.060000000000084, -5.090000000000083, -79.81999999999859, -4.080000000000084, 2.899999999999983, -0.050000000000041, -1.050000000000063, -7.110000000000083, -9.130000000000082, -14.179999999999728, -8.120000000000083, -0.10000000000004099, -120.03999999999864, -6.170000000000082, 0.9699999999999819, -24.279999999999422, 1.920000000000003, -6.100000000000083, -6.140000000000082, 2.9699999999999815, 3.8899999999999615, 3.9999999999999587, -181.31000000000134, -1.0600000000000631, -37.3700000000006, -5.090000000000082, -9.150000000000082, -14.169999999999732, 2.9499999999999815, 2.949999999999982, 1.9100000000000028, 0.969999999999981, 1.960000000000003, -0.07000000000003034], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-16.089999999999712, -16.0899999999997, -8.050000000000042, -20.109999999999708, -4.030000000000042, -14.080000000000041, -2.020000000000042, -42.220000000000354, -16.0899999999997, -24.12999999999984, -2.020000000000042, -0.00999999999999836, -6.040000000000042, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, -0.00999999999999836, -64.32999999999922, 2.0000000000000013, -16.0899999999997, -14.080000000000041, 2.0000000000000013, -0.00999999999999836, -8.050000000000042, -26.13999999999971, -18.09999999999984, -108.54999999999929, -0.00999999999999836, -34.18000000000008, -14.080000000000041, -20.109999999999705, 2.0000000000000013, -30.159999999999712, -8.050000000000042, -6.040000000000042, -22.119999999999706, -38.20000000000035, -4.030000000000042, -4.030000000000042, 2.0000000000000013, 2.0000000000000013, -14.080000000000041, 2.0000000000000013, -8.050000000000042, -24.129999999999725, -6.040000000000042, -0.00999999999999836, -0.009999999999998581, -12.070000000000041, -78.39999999999931, -12.070000000000041, -10.060000000000041, -12.070000000000041, -12.070000000000041, -24.129999999999708, -52.27000000000029, -2.020000000000042, -0.00999999999999836, -10.060000000000041, 2.0000000000000013, -6.040000000000042, -54.28000000000034, -10.060000000000038, -50.260000000000346, 2.0000000000000013, 2.0000000000000013, -2.0200000000000418, 2.0000000000000013, -34.18000000000035, -14.080000000000041, -16.0899999999997, -20.109999999999705, -6.040000000000042, -0.00999999999999836, -4.030000000000042, -4.030000000000042, -68.34999999999927, -2.020000000000042, 2.0000000000000013, -14.080000000000041, 2.0000000000000013, -2.020000000000037, 2.0000000000000013, -8.050000000000042, -0.00999999999999836, -48.25000000000035, -108.5499999999993, -10.060000000000041, 2.0000000000000013, -4.030000000000042, -20.109999999999705, 2.0000000000000013, 2.0000000000000013, -0.00999999999999836, -14.080000000000041, -4.030000000000042, 2.0000000000000013, -8.050000000000042, 2.0000000000000013, -36.19000000000036, -12.070000000000041, -6.040000000000042, -20.109999999999705, -6.040000000000042, -28.14999999999971, 2.0000000000000013, -36.19000000000036, -22.11999999999974, -8.050000000000042, -6.040000000000042, -4.030000000000042, 2.0000000000000013, -0.00999999999999836, -14.080000000000041, -4.030000000000042, 2.0000000000000013, -16.0899999999997, -6.040000000000042, -28.149999999999714, -2.020000000000042, -8.050000000000042, -28.149999999999714, 2.0000000000000013, -0.00999999999999836, -0.00999999999999836, -6.040000000000042, -8.050000000000042, -34.18000000000031, -150.76000000000073, -4.030000000000042, -10.060000000000041, 2.0000000000000013, -4.030000000000042, -4.030000000000042, -6.040000000000042, -8.050000000000042, -46.24000000000035, -114.57999999999927, -10.060000000000041, -2.020000000000041, 2.0000000000000013, -18.099999999999703, -0.00999999999999836, -6.040000000000042, -8.050000000000042, 2.0000000000000013, -10.060000000000041, -8.050000000000042, -14.080000000000041, -8.050000000000038, -18.099999999999703, -14.080000000000041, -4.030000000000042, -16.08999999999971, -16.0899999999997, -0.00999999999999836, -128.65000000000123, -76.38999999999936, -6.040000000000042, -24.129999999999708, -4.030000000000042, 2.0000000000000013, -12.070000000000041, -40.210000000000356, 2.0000000000000013, -14.080000000000041, -10.060000000000041, -6.040000000000042, -0.00999999999999836, -24.129999999999708, -4.030000000000042, 2.0000000000000013, 2.0000000000000013, -20.109999999999705, 2.0000000000000013, 2.0000000000000013, -142.72000000000068, -116.58999999999959, -10.060000000000041, 2.0000000000000013, -58.30000000000029, -12.070000000000032, -6.04000000000004, -8.050000000000042, -10.060000000000041, -16.0899999999997, -16.0899999999997, -14.080000000000041, 2.0000000000000013, -8.050000000000042, 2.0000000000000013, -8.050000000000042, -16.0899999999997, 2.0000000000000013, -4.030000000000042, 2.0000000000000013, -6.040000000000042, 2.0000000000000013, -2.020000000000035, -8.050000000000042], "policy_predator_policy_reward": [9.0, 9.0, 13.0, 14.0, 3.0, 8.0, 14.0, 21.0, 18.0, 18.0, 2.0, 1.0, 4.0, 0.0, 0.0, 0.0, 28.0, 7.0, 0.0, 9.0, 0.0, 8.0, 1.0, 5.0, 23.0, 17.0, 32.0, 48.0, 10.0, 16.0, 11.0, 0.0, 15.0, 6.0, 6.0, 12.0, 18.0, 12.0, 3.0, 1.0, 8.0, 0.0, 2.0, 5.0, 4.0, 13.0, 1.0, 1.0, 25.0, 33.0, 8.0, 1.0, 5.0, 7.0, 16.0, 30.0, 1.0, 2.0, 0.0, 6.0, 5.0, 26.0, 1.0, 28.0, 0.0, 0.0, 2.0, 1.0, 21.0, 5.0, 9.0, 11.0, 1.0, 4.0, 3.0, 3.0, 15.0, 27.0, 5.0, 5.0, 2.0, 0.0, 0.0, 5.0, 1.0, 25.0, 52.0, 9.0, 0.0, 3.0, 11.0, 0.0, 1.0, 0.0, 8.0, 8.0, 3.0, 5.0, 19.0, 18.0, 4.0, 7.0, 11.0, 4.0, 15.0, 14.0, 1.0, 30.0, 3.0, 5.0, 3.0, 3.0, 1.0, 8.0, 2.0, 3.0, 4.0, 9.0, 12.0, 5.0, 15.0, 5.0, 0.0, 1.0, 4.0, 1.0, 21.0, 20.0, 76.0, 3.0, 6.0, 0.0, 3.0, 3.0, 4.0, 5.0, 64.0, 17.0, 8.0, 0.0, 9.0, 10.0, 2.0, 4.0, 5.0, 0.0, 6.0, 5.0, 0.0, 13.0, 10.0, 8.0, 12.0, 0.0, 9.0, 7.0, 65.0, 20.0, 11.0, 13.0, 3.0, 0.0, 7.0, 21.0, 8.0, 6.0, 6.0, 4.0, 5.0, 13.0, 2.0, 3.0, 11.0, 11.0, 0.0, 0.0, 72.0, 6.0, 6.0, 1.0, 23.0, 10.0, 9.0, 0.0, 8.0, 9.0, 8.0, 8.0, 5.0, 4.0, 4.0, 5.0, 9.0, 7.0, 3.0, 0.0, 4.0, 2.0, 4.0, 6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 6.926696996833025, "mean_inference_ms": 23.496898868262242, "mean_action_processing_ms": 0.25798689327456636, "mean_env_wait_ms": 3.9975736356219342, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004782438278198242, "StateBufferConnector_ms": 0.004064321517944336, "ViewRequirementAgentConnector_ms": 0.1216045618057251}, "num_episodes": 22, "episode_return_max": 3.9999999999999587, "episode_return_min": -181.31000000000134, "episode_return_mean": -11.569699999999962, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1072000, "num_agent_steps_trained": 1072000, "num_env_steps_sampled": 268000, "num_env_steps_trained": 268000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 336.22902350805225, "num_env_steps_trained_throughput_per_sec": 336.22902350805225, "timesteps_total": 268000, "num_env_steps_sampled_lifetime": 268000, "num_agent_steps_sampled_lifetime": 1072000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1072000, "timers": {"training_iteration_time_ms": 200194.749, "restore_workers_time_ms": 0.015, "training_step_time_ms": 200194.704, "sample_time_ms": 1712.965, "learn_time_ms": 198461.641, "learn_throughput": 20.155, "synch_weights_time_ms": 17.562}, "counters": {"num_env_steps_sampled": 268000, "num_env_steps_trained": 268000, "num_agent_steps_sampled": 1072000, "num_agent_steps_trained": 1072000}, "done": false, "training_iteration": 67, "trial_id": "8e499_00000", "date": "2024-08-15_03-10-38", "timestamp": 1723671638, "time_this_iter_s": 11.952672004699707, "time_total_s": 3977.7831978797913, "pid": 33199, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x1580efaf0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3977.7831978797913, "iterations_since_restore": 67, "perf": {"cpu_util_percent": 55.64117647058824, "ram_util_percent": 83.14117647058822}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5553039376382474, "cur_kl_coeff": 0.028125000000000008, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.421440816051746, "policy_loss": -0.004522840647524587, "vf_loss": 5.4257496028980885, "vf_explained_var": 0.02092674459729876, "kl": 0.007610735715053302, "entropy": 0.6299167075800517, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 127575.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5591689138658462, "cur_kl_coeff": 0.084375, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.119488075422862, "policy_loss": -0.012390655245898025, "vf_loss": 4.130419847952626, "vf_explained_var": 0.09392827727176525, "kl": 0.01729042529239224, "entropy": 0.8317969352479965, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 127575.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 272000, "num_env_steps_trained": 272000, "num_agent_steps_sampled": 1088000, "num_agent_steps_trained": 1088000}, "env_runners": {"episode_reward_max": 3.9999999999999587, "episode_reward_min": -181.31000000000134, "episode_reward_mean": -15.213099999999962, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -281.4099999999999, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 2.0000000000000013, "predator_policy": 146.0}, "policy_reward_mean": {"prey_policy": -21.426549999999988, "predator_policy": 13.82}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-12.230000000000079, 1.9700000000000024, -4.080000000000084, 0.9499999999999819, -13.169999999999952, 1.980000000000003, -32.470000000000375, -13.129999999999924, -12.140000000000082, -30.4, 0.969999999999981, -2.060000000000084, -29.31999999999971, -31.32000000000044, 3.9999999999999587, 2.9799999999999813, -22.259999999999433, -16.199999999999406, -1.050000000000063, -2.060000000000084, -28.369999999999518, -2.0800000000000827, 1.980000000000003, -1.0500000000000622, -22.25999999999944, -57.61000000000056, 0.9699999999999819, -7.110000000000083, 2.989999999999981, -2.110000000000083, 1.9500000000000028, 2.809999999999985, -7.110000000000083, -11.150000000000082, 2.849999999999984, -27.309999999999448, -6.090000000000083, 3.9699999999999593, -5.090000000000083, 2.9699999999999815, -9.130000000000082, -13.16999999999993, -16.19999999999943, 2.989999999999981, -1.050000000000063, -1.2300000000000588, -75.78999999999907, -2.060000000000083, -2.060000000000084, -5.090000000000083, -79.81999999999859, -4.080000000000084, 2.899999999999983, -0.050000000000041, -1.050000000000063, -7.110000000000083, -9.130000000000082, -14.179999999999728, -8.120000000000083, -0.10000000000004099, -120.03999999999864, -6.170000000000082, 0.9699999999999819, -24.279999999999422, 1.920000000000003, -6.100000000000083, -6.140000000000082, 2.9699999999999815, 3.8899999999999615, 3.9999999999999587, -181.31000000000134, -1.0600000000000631, -37.3700000000006, -5.090000000000082, -9.150000000000082, -14.169999999999732, 2.9499999999999815, 2.949999999999982, 1.9100000000000028, 0.969999999999981, 1.960000000000003, -0.07000000000003034, -7.170000000000002, -77.26999999999974, -33.409999999999634, -25.709999999999827, -3.070000000000083, 2.989999999999981, -67.78, -58.09999999999987, -9.22000000000008, -65.03999999999948, -3.0700000000000838, -9.26000000000008, -10.140000000000082, -34.38000000000005, -0.08000000000004011, -5.16000000000008, -8.130000000000082, -111.42999999999942], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-38.20000000000035, -4.030000000000042, -4.030000000000042, 2.0000000000000013, 2.0000000000000013, -14.080000000000041, 2.0000000000000013, -8.050000000000042, -24.129999999999725, -6.040000000000042, -0.00999999999999836, -0.009999999999998581, -12.070000000000041, -78.39999999999931, -12.070000000000041, -10.060000000000041, -12.070000000000041, -12.070000000000041, -24.129999999999708, -52.27000000000029, -2.020000000000042, -0.00999999999999836, -10.060000000000041, 2.0000000000000013, -6.040000000000042, -54.28000000000034, -10.060000000000038, -50.260000000000346, 2.0000000000000013, 2.0000000000000013, -2.0200000000000418, 2.0000000000000013, -34.18000000000035, -14.080000000000041, -16.0899999999997, -20.109999999999705, -6.040000000000042, -0.00999999999999836, -4.030000000000042, -4.030000000000042, -68.34999999999927, -2.020000000000042, 2.0000000000000013, -14.080000000000041, 2.0000000000000013, -2.020000000000037, 2.0000000000000013, -8.050000000000042, -0.00999999999999836, -48.25000000000035, -108.5499999999993, -10.060000000000041, 2.0000000000000013, -4.030000000000042, -20.109999999999705, 2.0000000000000013, 2.0000000000000013, -0.00999999999999836, -14.080000000000041, -4.030000000000042, 2.0000000000000013, -8.050000000000042, 2.0000000000000013, -36.19000000000036, -12.070000000000041, -6.040000000000042, -20.109999999999705, -6.040000000000042, -28.14999999999971, 2.0000000000000013, -36.19000000000036, -22.11999999999974, -8.050000000000042, -6.040000000000042, -4.030000000000042, 2.0000000000000013, -0.00999999999999836, -14.080000000000041, -4.030000000000042, 2.0000000000000013, -16.0899999999997, -6.040000000000042, -28.149999999999714, -2.020000000000042, -8.050000000000042, -28.149999999999714, 2.0000000000000013, -0.00999999999999836, -0.00999999999999836, -6.040000000000042, -8.050000000000042, -34.18000000000031, -150.76000000000073, -4.030000000000042, -10.060000000000041, 2.0000000000000013, -4.030000000000042, -4.030000000000042, -6.040000000000042, -8.050000000000042, -46.24000000000035, -114.57999999999927, -10.060000000000041, -2.020000000000041, 2.0000000000000013, -18.099999999999703, -0.00999999999999836, -6.040000000000042, -8.050000000000042, 2.0000000000000013, -10.060000000000041, -8.050000000000042, -14.080000000000041, -8.050000000000038, -18.099999999999703, -14.080000000000041, -4.030000000000042, -16.08999999999971, -16.0899999999997, -0.00999999999999836, -128.65000000000123, -76.38999999999936, -6.040000000000042, -24.129999999999708, -4.030000000000042, 2.0000000000000013, -12.070000000000041, -40.210000000000356, 2.0000000000000013, -14.080000000000041, -10.060000000000041, -6.040000000000042, -0.00999999999999836, -24.129999999999708, -4.030000000000042, 2.0000000000000013, 2.0000000000000013, -20.109999999999705, 2.0000000000000013, 2.0000000000000013, -142.72000000000068, -116.58999999999959, -10.060000000000041, 2.0000000000000013, -58.30000000000029, -12.070000000000032, -6.04000000000004, -8.050000000000042, -10.060000000000041, -16.0899999999997, -16.0899999999997, -14.080000000000041, 2.0000000000000013, -8.050000000000042, 2.0000000000000013, -8.050000000000042, -16.0899999999997, 2.0000000000000013, -4.030000000000042, 2.0000000000000013, -6.040000000000042, 2.0000000000000013, -2.020000000000035, -8.050000000000042, -32.17000000000004, 2.0000000000000013, -112.56999999999931, -138.7000000000001, -6.040000000000042, -72.36999999999999, -140.71000000000038, 2.0000000000000013, 2.0000000000000013, -12.070000000000041, -0.00999999999999836, 2.0000000000000013, -72.3699999999992, -281.4099999999999, -60.31000000000024, -156.78999999999982, -22.119999999999706, -18.099999999999724, -30.159999999999794, -174.88000000000022, -2.020000000000042, -8.050000000000042, -40.210000000000356, -8.050000000000042, -2.020000000000042, -22.119999999999706, -74.37999999999971, 2.0000000000000013, -14.080000000000041, 2.0000000000000013, 2.0000000000000013, -30.159999999999712, -18.099999999999707, -4.030000000000042, -128.6500000000007, -154.7799999999999], "policy_predator_policy_reward": [18.0, 12.0, 3.0, 1.0, 8.0, 0.0, 2.0, 5.0, 4.0, 13.0, 1.0, 1.0, 25.0, 33.0, 8.0, 1.0, 5.0, 7.0, 16.0, 30.0, 1.0, 2.0, 0.0, 6.0, 5.0, 26.0, 1.0, 28.0, 0.0, 0.0, 2.0, 1.0, 21.0, 5.0, 9.0, 11.0, 1.0, 4.0, 3.0, 3.0, 15.0, 27.0, 5.0, 5.0, 2.0, 0.0, 0.0, 5.0, 1.0, 25.0, 52.0, 9.0, 0.0, 3.0, 11.0, 0.0, 1.0, 0.0, 8.0, 8.0, 3.0, 5.0, 19.0, 18.0, 4.0, 7.0, 11.0, 4.0, 15.0, 14.0, 1.0, 30.0, 3.0, 5.0, 3.0, 3.0, 1.0, 8.0, 2.0, 3.0, 4.0, 9.0, 12.0, 5.0, 15.0, 5.0, 0.0, 1.0, 4.0, 1.0, 21.0, 20.0, 76.0, 3.0, 6.0, 0.0, 3.0, 3.0, 4.0, 5.0, 64.0, 17.0, 8.0, 0.0, 9.0, 10.0, 2.0, 4.0, 5.0, 0.0, 6.0, 5.0, 0.0, 13.0, 10.0, 8.0, 12.0, 0.0, 9.0, 7.0, 65.0, 20.0, 11.0, 13.0, 3.0, 0.0, 7.0, 21.0, 8.0, 6.0, 6.0, 4.0, 5.0, 13.0, 2.0, 3.0, 11.0, 11.0, 0.0, 0.0, 72.0, 6.0, 6.0, 1.0, 23.0, 10.0, 9.0, 0.0, 8.0, 9.0, 8.0, 8.0, 5.0, 4.0, 4.0, 5.0, 9.0, 7.0, 3.0, 0.0, 4.0, 2.0, 4.0, 6.0, 12.0, 11.0, 106.0, 68.0, 22.0, 23.0, 58.0, 55.0, 0.0, 7.0, 1.0, 0.0, 146.0, 140.0, 75.0, 84.0, 18.0, 13.0, 61.0, 79.0, 5.0, 2.0, 18.0, 21.0, 2.0, 12.0, 38.0, 0.0, 4.0, 8.0, 8.0, 15.0, 5.0, 9.0, 96.0, 76.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 7.8118159292785005, "mean_inference_ms": 22.564744114383387, "mean_action_processing_ms": 0.25938203060826354, "mean_env_wait_ms": 3.624392580415349, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004731893539428711, "StateBufferConnector_ms": 0.0046923160552978516, "ViewRequirementAgentConnector_ms": 0.12410247325897217}, "num_episodes": 18, "episode_return_max": 3.9999999999999587, "episode_return_min": -181.31000000000134, "episode_return_mean": -15.213099999999962, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1088000, "num_agent_steps_trained": 1088000, "num_env_steps_sampled": 272000, "num_env_steps_trained": 272000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 358.6811478743568, "num_env_steps_trained_throughput_per_sec": 358.6811478743568, "timesteps_total": 272000, "num_env_steps_sampled_lifetime": 272000, "num_agent_steps_sampled_lifetime": 1088000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1088000, "timers": {"training_iteration_time_ms": 200130.921, "restore_workers_time_ms": 0.015, "training_step_time_ms": 200130.872, "sample_time_ms": 1704.308, "learn_time_ms": 198406.529, "learn_throughput": 20.161, "synch_weights_time_ms": 17.493}, "counters": {"num_env_steps_sampled": 272000, "num_env_steps_trained": 272000, "num_agent_steps_sampled": 1088000, "num_agent_steps_trained": 1088000}, "done": false, "training_iteration": 68, "trial_id": "8e499_00000", "date": "2024-08-15_03-10-49", "timestamp": 1723671649, "time_this_iter_s": 11.185853242874146, "time_total_s": 3988.9690511226654, "pid": 33199, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x1580ddf70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3988.9690511226654, "iterations_since_restore": 68, "perf": {"cpu_util_percent": 41.4875, "ram_util_percent": 82.0875}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4813332970180209, "cur_kl_coeff": 0.028125000000000008, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.2609743349135867, "policy_loss": -0.004120692940276096, "vf_loss": 2.264839148206055, "vf_explained_var": 0.02961262656898095, "kl": 0.00909818426095324, "entropy": 0.6702943766243243, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 129465.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2860311713325914, "cur_kl_coeff": 0.084375, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.7435576617717743, "policy_loss": -0.01113365602004465, "vf_loss": 1.7539400931703981, "vf_explained_var": 0.03838391947367835, "kl": 0.008903375820723524, "entropy": 0.7147370497385661, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 129465.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 276000, "num_env_steps_trained": 276000, "num_agent_steps_sampled": 1104000, "num_agent_steps_trained": 1104000}, "env_runners": {"episode_reward_max": 3.9999999999999587, "episode_reward_min": -590.98, "episode_reward_mean": -23.649399999999943, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 2.0000000000000013, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -31.104699999999983, "predator_policy": 19.28}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-1.0500000000000622, -22.25999999999944, -57.61000000000056, 0.9699999999999819, -7.110000000000083, 2.989999999999981, -2.110000000000083, 1.9500000000000028, 2.809999999999985, -7.110000000000083, -11.150000000000082, 2.849999999999984, -27.309999999999448, -6.090000000000083, 3.9699999999999593, -5.090000000000083, 2.9699999999999815, -9.130000000000082, -13.16999999999993, -16.19999999999943, 2.989999999999981, -1.050000000000063, -1.2300000000000588, -75.78999999999907, -2.060000000000083, -2.060000000000084, -5.090000000000083, -79.81999999999859, -4.080000000000084, 2.899999999999983, -0.050000000000041, -1.050000000000063, -7.110000000000083, -9.130000000000082, -14.179999999999728, -8.120000000000083, -0.10000000000004099, -120.03999999999864, -6.170000000000082, 0.9699999999999819, -24.279999999999422, 1.920000000000003, -6.100000000000083, -6.140000000000082, 2.9699999999999815, 3.8899999999999615, 3.9999999999999587, -181.31000000000134, -1.0600000000000631, -37.3700000000006, -5.090000000000082, -9.150000000000082, -14.169999999999732, 2.9499999999999815, 2.949999999999982, 1.9100000000000028, 0.969999999999981, 1.960000000000003, -0.07000000000003034, -7.170000000000002, -77.26999999999974, -33.409999999999634, -25.709999999999827, -3.070000000000083, 2.989999999999981, -67.78, -58.09999999999987, -9.22000000000008, -65.03999999999948, -3.0700000000000838, -9.26000000000008, -10.140000000000082, -34.38000000000005, -0.08000000000004011, -5.16000000000008, -8.130000000000082, -111.42999999999942, -29.48999999999961, -5.090000000000083, -18.529999999999458, -590.98, -48.050000000000516, -6.580000000000071, -15.149999999999554, -4.080000000000084, -84.35999999999969, -4.080000000000084, -6.100000000000083, 2.989999999999981, -6.180000000000081, -23.509999999999547, -6.100000000000078, -34.41999999999988, -15.17999999999955, -32.619999999999905, -18.239999999999412, -28.319999999999446, -23.48000000000002, -7.110000000000083, -76.47999999999996], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [2.0000000000000013, -8.050000000000042, -0.00999999999999836, -48.25000000000035, -108.5499999999993, -10.060000000000041, 2.0000000000000013, -4.030000000000042, -20.109999999999705, 2.0000000000000013, 2.0000000000000013, -0.00999999999999836, -14.080000000000041, -4.030000000000042, 2.0000000000000013, -8.050000000000042, 2.0000000000000013, -36.19000000000036, -12.070000000000041, -6.040000000000042, -20.109999999999705, -6.040000000000042, -28.14999999999971, 2.0000000000000013, -36.19000000000036, -22.11999999999974, -8.050000000000042, -6.040000000000042, -4.030000000000042, 2.0000000000000013, -0.00999999999999836, -14.080000000000041, -4.030000000000042, 2.0000000000000013, -16.0899999999997, -6.040000000000042, -28.149999999999714, -2.020000000000042, -8.050000000000042, -28.149999999999714, 2.0000000000000013, -0.00999999999999836, -0.00999999999999836, -6.040000000000042, -8.050000000000042, -34.18000000000031, -150.76000000000073, -4.030000000000042, -10.060000000000041, 2.0000000000000013, -4.030000000000042, -4.030000000000042, -6.040000000000042, -8.050000000000042, -46.24000000000035, -114.57999999999927, -10.060000000000041, -2.020000000000041, 2.0000000000000013, -18.099999999999703, -0.00999999999999836, -6.040000000000042, -8.050000000000042, 2.0000000000000013, -10.060000000000041, -8.050000000000042, -14.080000000000041, -8.050000000000038, -18.099999999999703, -14.080000000000041, -4.030000000000042, -16.08999999999971, -16.0899999999997, -0.00999999999999836, -128.65000000000123, -76.38999999999936, -6.040000000000042, -24.129999999999708, -4.030000000000042, 2.0000000000000013, -12.070000000000041, -40.210000000000356, 2.0000000000000013, -14.080000000000041, -10.060000000000041, -6.040000000000042, -0.00999999999999836, -24.129999999999708, -4.030000000000042, 2.0000000000000013, 2.0000000000000013, -20.109999999999705, 2.0000000000000013, 2.0000000000000013, -142.72000000000068, -116.58999999999959, -10.060000000000041, 2.0000000000000013, -58.30000000000029, -12.070000000000032, -6.04000000000004, -8.050000000000042, -10.060000000000041, -16.0899999999997, -16.0899999999997, -14.080000000000041, 2.0000000000000013, -8.050000000000042, 2.0000000000000013, -8.050000000000042, -16.0899999999997, 2.0000000000000013, -4.030000000000042, 2.0000000000000013, -6.040000000000042, 2.0000000000000013, -2.020000000000035, -8.050000000000042, -32.17000000000004, 2.0000000000000013, -112.56999999999931, -138.7000000000001, -6.040000000000042, -72.36999999999999, -140.71000000000038, 2.0000000000000013, 2.0000000000000013, -12.070000000000041, -0.00999999999999836, 2.0000000000000013, -72.3699999999992, -281.4099999999999, -60.31000000000024, -156.78999999999982, -22.119999999999706, -18.099999999999724, -30.159999999999794, -174.88000000000022, -2.020000000000042, -8.050000000000042, -40.210000000000356, -8.050000000000042, -2.020000000000042, -22.119999999999706, -74.37999999999971, 2.0000000000000013, -14.080000000000041, 2.0000000000000013, 2.0000000000000013, -30.159999999999712, -18.099999999999707, -4.030000000000042, -128.6500000000007, -154.7799999999999, -54.28000000000034, -40.210000000000164, -12.070000000000041, -2.020000000000042, -18.099999999999703, -84.4299999999992, -400.0, -395.98, -136.6900000000012, -70.35999999999972, -104.52999999999945, -8.050000000000042, -14.08000000000004, -12.070000000000041, -8.050000000000042, -4.030000000000042, -136.68999999999988, -132.67000000000007, 2.0000000000000013, -14.080000000000041, -6.040000000000042, -10.060000000000041, 2.0000000000000013, -0.00999999999999836, -6.040000000000042, -26.13999999999971, -100.50999999999931, 2.0000000000000013, -0.00999999999999836, -16.090000000000014, -80.40999999999993, -0.00999999999999836, -18.099999999999703, -14.080000000000041, -110.55999999999996, -10.060000000000041, -26.13999999999971, -18.099999999999703, -4.030000000000042, -56.29000000000034, -72.37, -20.109999999999705, -8.050000000000042, -10.060000000000041, -16.0899999999997, -277.3900000000001], "policy_predator_policy_reward": [0.0, 5.0, 1.0, 25.0, 52.0, 9.0, 0.0, 3.0, 11.0, 0.0, 1.0, 0.0, 8.0, 8.0, 3.0, 5.0, 19.0, 18.0, 4.0, 7.0, 11.0, 4.0, 15.0, 14.0, 1.0, 30.0, 3.0, 5.0, 3.0, 3.0, 1.0, 8.0, 2.0, 3.0, 4.0, 9.0, 12.0, 5.0, 15.0, 5.0, 0.0, 1.0, 4.0, 1.0, 21.0, 20.0, 76.0, 3.0, 6.0, 0.0, 3.0, 3.0, 4.0, 5.0, 64.0, 17.0, 8.0, 0.0, 9.0, 10.0, 2.0, 4.0, 5.0, 0.0, 6.0, 5.0, 0.0, 13.0, 10.0, 8.0, 12.0, 0.0, 9.0, 7.0, 65.0, 20.0, 11.0, 13.0, 3.0, 0.0, 7.0, 21.0, 8.0, 6.0, 6.0, 4.0, 5.0, 13.0, 2.0, 3.0, 11.0, 11.0, 0.0, 0.0, 72.0, 6.0, 6.0, 1.0, 23.0, 10.0, 9.0, 0.0, 8.0, 9.0, 8.0, 8.0, 5.0, 4.0, 4.0, 5.0, 9.0, 7.0, 3.0, 0.0, 4.0, 2.0, 4.0, 6.0, 12.0, 11.0, 106.0, 68.0, 22.0, 23.0, 58.0, 55.0, 0.0, 7.0, 1.0, 0.0, 146.0, 140.0, 75.0, 84.0, 18.0, 13.0, 61.0, 79.0, 5.0, 2.0, 18.0, 21.0, 2.0, 12.0, 38.0, 0.0, 4.0, 8.0, 8.0, 15.0, 5.0, 9.0, 96.0, 76.0, 32.0, 33.0, 2.0, 7.0, 43.0, 41.0, 200.0, 5.0, 82.0, 77.0, 52.0, 54.0, 0.0, 11.0, 4.0, 4.0, 88.0, 97.0, 0.0, 8.0, 6.0, 4.0, 1.0, 0.0, 14.0, 12.0, 29.0, 46.0, 8.0, 2.0, 28.0, 18.0, 7.0, 10.0, 43.0, 45.0, 14.0, 12.0, 3.0, 29.0, 30.0, 39.0, 5.0, 6.0, 104.0, 113.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 7.69317404766427, "mean_inference_ms": 22.201019383622416, "mean_action_processing_ms": 0.2603738836110559, "mean_env_wait_ms": 3.5789394276098907, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005630373954772949, "StateBufferConnector_ms": 0.004859447479248047, "ViewRequirementAgentConnector_ms": 0.12775194644927979}, "num_episodes": 23, "episode_return_max": 3.9999999999999587, "episode_return_min": -590.98, "episode_return_mean": -23.649399999999943, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1104000, "num_agent_steps_trained": 1104000, "num_env_steps_sampled": 276000, "num_env_steps_trained": 276000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 4.2173240863979915, "num_env_steps_trained_throughput_per_sec": 4.2173240863979915, "timesteps_total": 276000, "num_env_steps_sampled_lifetime": 276000, "num_agent_steps_sampled_lifetime": 1104000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1104000, "timers": {"training_iteration_time_ms": 200143.149, "restore_workers_time_ms": 0.015, "training_step_time_ms": 200143.1, "sample_time_ms": 1687.715, "learn_time_ms": 198435.027, "learn_throughput": 20.158, "synch_weights_time_ms": 17.422}, "counters": {"num_env_steps_sampled": 276000, "num_env_steps_trained": 276000, "num_agent_steps_sampled": 1104000, "num_agent_steps_trained": 1104000}, "done": false, "training_iteration": 69, "trial_id": "8e499_00000", "date": "2024-08-15_03-26-38", "timestamp": 1723672598, "time_this_iter_s": 948.5374600887299, "time_total_s": 4937.506511211395, "pid": 33199, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x1580dd9d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 4937.506511211395, "iterations_since_restore": 69, "perf": {"cpu_util_percent": 64.35263157894737, "ram_util_percent": 78.78421052631579}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1826848420989577, "cur_kl_coeff": 0.028125000000000008, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.7093491952255289, "policy_loss": -0.003097310606710534, "vf_loss": 1.7121628921498697, "vf_explained_var": 0.10631507512122866, "kl": 0.010084075351492807, "entropy": 0.6037841475672192, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 131355.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0144982629509829, "cur_kl_coeff": 0.084375, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.5442461155709766, "policy_loss": -0.00672780389875351, "vf_loss": 2.5502950324583304, "vf_explained_var": 0.004906806428596457, "kl": 0.008046000574160193, "entropy": 0.7025066311712618, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 131355.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 280000, "num_env_steps_trained": 280000, "num_agent_steps_sampled": 1120000, "num_agent_steps_trained": 1120000}, "env_runners": {"episode_reward_max": 3.9999999999999587, "episode_reward_min": -590.98, "episode_reward_mean": -31.95299999999994, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 2.0000000000000013, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -37.49649999999999, "predator_policy": 21.52}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-13.16999999999993, -16.19999999999943, 2.989999999999981, -1.050000000000063, -1.2300000000000588, -75.78999999999907, -2.060000000000083, -2.060000000000084, -5.090000000000083, -79.81999999999859, -4.080000000000084, 2.899999999999983, -0.050000000000041, -1.050000000000063, -7.110000000000083, -9.130000000000082, -14.179999999999728, -8.120000000000083, -0.10000000000004099, -120.03999999999864, -6.170000000000082, 0.9699999999999819, -24.279999999999422, 1.920000000000003, -6.100000000000083, -6.140000000000082, 2.9699999999999815, 3.8899999999999615, 3.9999999999999587, -181.31000000000134, -1.0600000000000631, -37.3700000000006, -5.090000000000082, -9.150000000000082, -14.169999999999732, 2.9499999999999815, 2.949999999999982, 1.9100000000000028, 0.969999999999981, 1.960000000000003, -0.07000000000003034, -7.170000000000002, -77.26999999999974, -33.409999999999634, -25.709999999999827, -3.070000000000083, 2.989999999999981, -67.78, -58.09999999999987, -9.22000000000008, -65.03999999999948, -3.0700000000000838, -9.26000000000008, -10.140000000000082, -34.38000000000005, -0.08000000000004011, -5.16000000000008, -8.130000000000082, -111.42999999999942, -29.48999999999961, -5.090000000000083, -18.529999999999458, -590.98, -48.050000000000516, -6.580000000000071, -15.149999999999554, -4.080000000000084, -84.35999999999969, -4.080000000000084, -6.100000000000083, 2.989999999999981, -6.180000000000081, -23.509999999999547, -6.100000000000078, -34.41999999999988, -15.17999999999955, -32.619999999999905, -18.239999999999412, -28.319999999999446, -23.48000000000002, -7.110000000000083, -76.47999999999996, -5.090000000000013, -11.160000000000082, 1.9800000000000026, 0.9699999999999819, -4.090000000000082, -18.219999999999427, -8.180000000000081, -260.36000000000024, -5.090000000000083, -489.53000000000037, -48.52000000000034, -7.110000000000083, 3.9499999999999598, -10.130000000000082, -4.0900000000000825, 0.9299999999999818, -100.04999999999905, -4.080000000000082], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-28.149999999999714, -2.020000000000042, -8.050000000000042, -28.149999999999714, 2.0000000000000013, -0.00999999999999836, -0.00999999999999836, -6.040000000000042, -8.050000000000042, -34.18000000000031, -150.76000000000073, -4.030000000000042, -10.060000000000041, 2.0000000000000013, -4.030000000000042, -4.030000000000042, -6.040000000000042, -8.050000000000042, -46.24000000000035, -114.57999999999927, -10.060000000000041, -2.020000000000041, 2.0000000000000013, -18.099999999999703, -0.00999999999999836, -6.040000000000042, -8.050000000000042, 2.0000000000000013, -10.060000000000041, -8.050000000000042, -14.080000000000041, -8.050000000000038, -18.099999999999703, -14.080000000000041, -4.030000000000042, -16.08999999999971, -16.0899999999997, -0.00999999999999836, -128.65000000000123, -76.38999999999936, -6.040000000000042, -24.129999999999708, -4.030000000000042, 2.0000000000000013, -12.070000000000041, -40.210000000000356, 2.0000000000000013, -14.080000000000041, -10.060000000000041, -6.040000000000042, -0.00999999999999836, -24.129999999999708, -4.030000000000042, 2.0000000000000013, 2.0000000000000013, -20.109999999999705, 2.0000000000000013, 2.0000000000000013, -142.72000000000068, -116.58999999999959, -10.060000000000041, 2.0000000000000013, -58.30000000000029, -12.070000000000032, -6.04000000000004, -8.050000000000042, -10.060000000000041, -16.0899999999997, -16.0899999999997, -14.080000000000041, 2.0000000000000013, -8.050000000000042, 2.0000000000000013, -8.050000000000042, -16.0899999999997, 2.0000000000000013, -4.030000000000042, 2.0000000000000013, -6.040000000000042, 2.0000000000000013, -2.020000000000035, -8.050000000000042, -32.17000000000004, 2.0000000000000013, -112.56999999999931, -138.7000000000001, -6.040000000000042, -72.36999999999999, -140.71000000000038, 2.0000000000000013, 2.0000000000000013, -12.070000000000041, -0.00999999999999836, 2.0000000000000013, -72.3699999999992, -281.4099999999999, -60.31000000000024, -156.78999999999982, -22.119999999999706, -18.099999999999724, -30.159999999999794, -174.88000000000022, -2.020000000000042, -8.050000000000042, -40.210000000000356, -8.050000000000042, -2.020000000000042, -22.119999999999706, -74.37999999999971, 2.0000000000000013, -14.080000000000041, 2.0000000000000013, 2.0000000000000013, -30.159999999999712, -18.099999999999707, -4.030000000000042, -128.6500000000007, -154.7799999999999, -54.28000000000034, -40.210000000000164, -12.070000000000041, -2.020000000000042, -18.099999999999703, -84.4299999999992, -400.0, -395.98, -136.6900000000012, -70.35999999999972, -104.52999999999945, -8.050000000000042, -14.08000000000004, -12.070000000000041, -8.050000000000042, -4.030000000000042, -136.68999999999988, -132.67000000000007, 2.0000000000000013, -14.080000000000041, -6.040000000000042, -10.060000000000041, 2.0000000000000013, -0.00999999999999836, -6.040000000000042, -26.13999999999971, -100.50999999999931, 2.0000000000000013, -0.00999999999999836, -16.090000000000014, -80.40999999999993, -0.00999999999999836, -18.099999999999703, -14.080000000000041, -110.55999999999996, -10.060000000000041, -26.13999999999971, -18.099999999999703, -4.030000000000042, -56.29000000000034, -72.37, -20.109999999999705, -8.050000000000042, -10.060000000000041, -16.0899999999997, -277.3900000000001, 2.0000000000000013, -16.08999999999998, -18.099999999999927, -10.060000000000041, -2.020000000000042, 2.0000000000000013, 2.0000000000000013, -4.030000000000042, 2.0000000000000013, -16.0899999999997, -36.19000000000036, -4.030000000000042, -22.119999999999706, -10.060000000000041, -140.71, -329.65000000000015, -0.00999999999999836, -14.080000000000041, -391.96000000000004, -313.5700000000004, -98.49999999999964, -2.020000000000042, -8.050000000000042, -10.060000000000041, 2.0000000000000013, -8.050000000000042, -10.060000000000041, -12.070000000000041, 2.0000000000000013, -16.089999999999883, -12.070000000000041, 2.0000000000000013, -34.180000000000305, -172.87000000000063, -14.08000000000004, 2.0000000000000013], "policy_predator_policy_reward": [12.0, 5.0, 15.0, 5.0, 0.0, 1.0, 4.0, 1.0, 21.0, 20.0, 76.0, 3.0, 6.0, 0.0, 3.0, 3.0, 4.0, 5.0, 64.0, 17.0, 8.0, 0.0, 9.0, 10.0, 2.0, 4.0, 5.0, 0.0, 6.0, 5.0, 0.0, 13.0, 10.0, 8.0, 12.0, 0.0, 9.0, 7.0, 65.0, 20.0, 11.0, 13.0, 3.0, 0.0, 7.0, 21.0, 8.0, 6.0, 6.0, 4.0, 5.0, 13.0, 2.0, 3.0, 11.0, 11.0, 0.0, 0.0, 72.0, 6.0, 6.0, 1.0, 23.0, 10.0, 9.0, 0.0, 8.0, 9.0, 8.0, 8.0, 5.0, 4.0, 4.0, 5.0, 9.0, 7.0, 3.0, 0.0, 4.0, 2.0, 4.0, 6.0, 12.0, 11.0, 106.0, 68.0, 22.0, 23.0, 58.0, 55.0, 0.0, 7.0, 1.0, 0.0, 146.0, 140.0, 75.0, 84.0, 18.0, 13.0, 61.0, 79.0, 5.0, 2.0, 18.0, 21.0, 2.0, 12.0, 38.0, 0.0, 4.0, 8.0, 8.0, 15.0, 5.0, 9.0, 96.0, 76.0, 32.0, 33.0, 2.0, 7.0, 43.0, 41.0, 200.0, 5.0, 82.0, 77.0, 52.0, 54.0, 0.0, 11.0, 4.0, 4.0, 88.0, 97.0, 0.0, 8.0, 6.0, 4.0, 1.0, 0.0, 14.0, 12.0, 29.0, 46.0, 8.0, 2.0, 28.0, 18.0, 7.0, 10.0, 43.0, 45.0, 14.0, 12.0, 3.0, 29.0, 30.0, 39.0, 5.0, 6.0, 104.0, 113.0, 9.0, 0.0, 11.0, 6.0, 0.0, 2.0, 0.0, 3.0, 1.0, 9.0, 19.0, 3.0, 12.0, 12.0, 36.0, 174.0, 8.0, 1.0, 199.0, 17.0, 40.0, 12.0, 6.0, 5.0, 5.0, 5.0, 7.0, 5.0, 1.0, 9.0, 7.0, 4.0, 91.0, 16.0, 8.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 7.601239851104119, "mean_inference_ms": 21.940017673029814, "mean_action_processing_ms": 0.2615514674111856, "mean_env_wait_ms": 3.53504805795558, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0064868927001953125, "StateBufferConnector_ms": 0.004938006401062012, "ViewRequirementAgentConnector_ms": 0.1511385440826416}, "num_episodes": 18, "episode_return_max": 3.9999999999999587, "episode_return_min": -590.98, "episode_return_mean": -31.95299999999994, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1120000, "num_agent_steps_trained": 1120000, "num_env_steps_sampled": 280000, "num_env_steps_trained": 280000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 325.71666012957326, "num_env_steps_trained_throughput_per_sec": 325.71666012957326, "timesteps_total": 280000, "num_env_steps_sampled_lifetime": 280000, "num_agent_steps_sampled_lifetime": 1120000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1120000, "timers": {"training_iteration_time_ms": 200106.84, "restore_workers_time_ms": 0.015, "training_step_time_ms": 200106.792, "sample_time_ms": 1685.142, "learn_time_ms": 198401.359, "learn_throughput": 20.161, "synch_weights_time_ms": 17.24}, "counters": {"num_env_steps_sampled": 280000, "num_env_steps_trained": 280000, "num_agent_steps_sampled": 1120000, "num_agent_steps_trained": 1120000}, "done": false, "training_iteration": 70, "trial_id": "8e499_00000", "date": "2024-08-15_03-26-51", "timestamp": 1723672611, "time_this_iter_s": 12.328188180923462, "time_total_s": 4949.834699392319, "pid": 33199, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x1580efaf0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 4949.834699392319, "iterations_since_restore": 70, "perf": {"cpu_util_percent": 56.822222222222216, "ram_util_percent": 81.57777777777778}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.226644195482214, "cur_kl_coeff": 0.028125000000000008, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.071096744865336, "policy_loss": -0.004480815330944049, "vf_loss": 4.0753393454526465, "vf_explained_var": 0.06104374436474351, "kl": 0.00846959930350868, "entropy": 0.6182339049836315, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 133245.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2285294120431578, "cur_kl_coeff": 0.084375, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.9118339199237724, "policy_loss": -0.005295416420675499, "vf_loss": 3.9164737340634463, "vf_explained_var": 0.014958447659457171, "kl": 0.007770149536446013, "entropy": 0.7506310146952432, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 133245.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 284000, "num_env_steps_trained": 284000, "num_agent_steps_sampled": 1136000, "num_agent_steps_trained": 1136000}, "env_runners": {"episode_reward_max": 3.9999999999999587, "episode_reward_min": -590.98, "episode_reward_mean": -40.143699999999946, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 2.0000000000000013, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -44.60184999999998, "predator_policy": 24.53}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.10000000000004099, -120.03999999999864, -6.170000000000082, 0.9699999999999819, -24.279999999999422, 1.920000000000003, -6.100000000000083, -6.140000000000082, 2.9699999999999815, 3.8899999999999615, 3.9999999999999587, -181.31000000000134, -1.0600000000000631, -37.3700000000006, -5.090000000000082, -9.150000000000082, -14.169999999999732, 2.9499999999999815, 2.949999999999982, 1.9100000000000028, 0.969999999999981, 1.960000000000003, -0.07000000000003034, -7.170000000000002, -77.26999999999974, -33.409999999999634, -25.709999999999827, -3.070000000000083, 2.989999999999981, -67.78, -58.09999999999987, -9.22000000000008, -65.03999999999948, -3.0700000000000838, -9.26000000000008, -10.140000000000082, -34.38000000000005, -0.08000000000004011, -5.16000000000008, -8.130000000000082, -111.42999999999942, -29.48999999999961, -5.090000000000083, -18.529999999999458, -590.98, -48.050000000000516, -6.580000000000071, -15.149999999999554, -4.080000000000084, -84.35999999999969, -4.080000000000084, -6.100000000000083, 2.989999999999981, -6.180000000000081, -23.509999999999547, -6.100000000000078, -34.41999999999988, -15.17999999999955, -32.619999999999905, -18.239999999999412, -28.319999999999446, -23.48000000000002, -7.110000000000083, -76.47999999999996, -5.090000000000013, -11.160000000000082, 1.9800000000000026, 0.9699999999999819, -4.090000000000082, -18.219999999999427, -8.180000000000081, -260.36000000000024, -5.090000000000083, -489.53000000000037, -48.52000000000034, -7.110000000000083, 3.9499999999999598, -10.130000000000082, -4.0900000000000825, 0.9299999999999818, -100.04999999999905, -4.080000000000082, -42.49000000000034, -10.330000000000055, -59.63000000000062, -86.89999999999945, -17.209999999999532, -42.69000000000065, -4.120000000000023, -15.280000000000026, -9.130000000000017, -37.41000000000043, -66.5299999999984, -22.369999999999433, 3.889999999999961, 3.9499999999999598, -79.6399999999984, -71.75000000000001, -448.22000000000014, -47.51000000000031], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-16.0899999999997, -0.00999999999999836, -128.65000000000123, -76.38999999999936, -6.040000000000042, -24.129999999999708, -4.030000000000042, 2.0000000000000013, -12.070000000000041, -40.210000000000356, 2.0000000000000013, -14.080000000000041, -10.060000000000041, -6.040000000000042, -0.00999999999999836, -24.129999999999708, -4.030000000000042, 2.0000000000000013, 2.0000000000000013, -20.109999999999705, 2.0000000000000013, 2.0000000000000013, -142.72000000000068, -116.58999999999959, -10.060000000000041, 2.0000000000000013, -58.30000000000029, -12.070000000000032, -6.04000000000004, -8.050000000000042, -10.060000000000041, -16.0899999999997, -16.0899999999997, -14.080000000000041, 2.0000000000000013, -8.050000000000042, 2.0000000000000013, -8.050000000000042, -16.0899999999997, 2.0000000000000013, -4.030000000000042, 2.0000000000000013, -6.040000000000042, 2.0000000000000013, -2.020000000000035, -8.050000000000042, -32.17000000000004, 2.0000000000000013, -112.56999999999931, -138.7000000000001, -6.040000000000042, -72.36999999999999, -140.71000000000038, 2.0000000000000013, 2.0000000000000013, -12.070000000000041, -0.00999999999999836, 2.0000000000000013, -72.3699999999992, -281.4099999999999, -60.31000000000024, -156.78999999999982, -22.119999999999706, -18.099999999999724, -30.159999999999794, -174.88000000000022, -2.020000000000042, -8.050000000000042, -40.210000000000356, -8.050000000000042, -2.020000000000042, -22.119999999999706, -74.37999999999971, 2.0000000000000013, -14.080000000000041, 2.0000000000000013, 2.0000000000000013, -30.159999999999712, -18.099999999999707, -4.030000000000042, -128.6500000000007, -154.7799999999999, -54.28000000000034, -40.210000000000164, -12.070000000000041, -2.020000000000042, -18.099999999999703, -84.4299999999992, -400.0, -395.98, -136.6900000000012, -70.35999999999972, -104.52999999999945, -8.050000000000042, -14.08000000000004, -12.070000000000041, -8.050000000000042, -4.030000000000042, -136.68999999999988, -132.67000000000007, 2.0000000000000013, -14.080000000000041, -6.040000000000042, -10.060000000000041, 2.0000000000000013, -0.00999999999999836, -6.040000000000042, -26.13999999999971, -100.50999999999931, 2.0000000000000013, -0.00999999999999836, -16.090000000000014, -80.40999999999993, -0.00999999999999836, -18.099999999999703, -14.080000000000041, -110.55999999999996, -10.060000000000041, -26.13999999999971, -18.099999999999703, -4.030000000000042, -56.29000000000034, -72.37, -20.109999999999705, -8.050000000000042, -10.060000000000041, -16.0899999999997, -277.3900000000001, 2.0000000000000013, -16.08999999999998, -18.099999999999927, -10.060000000000041, -2.020000000000042, 2.0000000000000013, 2.0000000000000013, -4.030000000000042, 2.0000000000000013, -16.0899999999997, -36.19000000000036, -4.030000000000042, -22.119999999999706, -10.060000000000041, -140.71, -329.65000000000015, -0.00999999999999836, -14.080000000000041, -391.96000000000004, -313.5700000000004, -98.49999999999964, -2.020000000000042, -8.050000000000042, -10.060000000000041, 2.0000000000000013, -8.050000000000042, -10.060000000000041, -12.070000000000041, 2.0000000000000013, -16.089999999999883, -12.070000000000041, 2.0000000000000013, -34.180000000000305, -172.87000000000063, -14.08000000000004, 2.0000000000000013, -74.37999999999958, -20.10999999999981, -40.21000000000025, -22.120000000000015, -108.5499999999993, -14.080000000000041, -12.070000000000041, -164.82999999999998, -26.139999999999763, -12.070000000000041, -98.49999999999928, -36.19000000000036, -8.05, -12.070000000000041, -4.030000000000042, -48.24999999999998, -4.0299999999999985, -18.099999999999994, -76.3899999999994, -2.020000000000042, -58.30000000000031, -44.23000000000032, -22.119999999999706, -48.25000000000035, 2.0000000000000013, -20.109999999999705, 2.0000000000000013, -8.050000000000042, -44.230000000000295, -80.40999999999919, -120.60999999999979, -26.139999999999933, -349.7500000000001, -293.4699999999999, -52.27000000000017, -46.23999999999991], "policy_predator_policy_reward": [9.0, 7.0, 65.0, 20.0, 11.0, 13.0, 3.0, 0.0, 7.0, 21.0, 8.0, 6.0, 6.0, 4.0, 5.0, 13.0, 2.0, 3.0, 11.0, 11.0, 0.0, 0.0, 72.0, 6.0, 6.0, 1.0, 23.0, 10.0, 9.0, 0.0, 8.0, 9.0, 8.0, 8.0, 5.0, 4.0, 4.0, 5.0, 9.0, 7.0, 3.0, 0.0, 4.0, 2.0, 4.0, 6.0, 12.0, 11.0, 106.0, 68.0, 22.0, 23.0, 58.0, 55.0, 0.0, 7.0, 1.0, 0.0, 146.0, 140.0, 75.0, 84.0, 18.0, 13.0, 61.0, 79.0, 5.0, 2.0, 18.0, 21.0, 2.0, 12.0, 38.0, 0.0, 4.0, 8.0, 8.0, 15.0, 5.0, 9.0, 96.0, 76.0, 32.0, 33.0, 2.0, 7.0, 43.0, 41.0, 200.0, 5.0, 82.0, 77.0, 52.0, 54.0, 0.0, 11.0, 4.0, 4.0, 88.0, 97.0, 0.0, 8.0, 6.0, 4.0, 1.0, 0.0, 14.0, 12.0, 29.0, 46.0, 8.0, 2.0, 28.0, 18.0, 7.0, 10.0, 43.0, 45.0, 14.0, 12.0, 3.0, 29.0, 30.0, 39.0, 5.0, 6.0, 104.0, 113.0, 9.0, 0.0, 11.0, 6.0, 0.0, 2.0, 0.0, 3.0, 1.0, 9.0, 19.0, 3.0, 12.0, 12.0, 36.0, 174.0, 8.0, 1.0, 199.0, 17.0, 40.0, 12.0, 6.0, 5.0, 5.0, 5.0, 7.0, 5.0, 1.0, 9.0, 7.0, 4.0, 91.0, 16.0, 8.0, 0.0, 3.0, 49.0, 28.0, 24.0, 55.0, 8.0, 83.0, 7.0, 21.0, 0.0, 46.0, 46.0, 5.0, 11.0, 18.0, 19.0, 0.0, 13.0, 3.0, 38.0, 8.0, 28.0, 23.0, 25.0, 11.0, 11.0, 5.0, 5.0, 44.0, 1.0, 4.0, 71.0, 195.0, 0.0, 11.0, 40.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 7.510307990924979, "mean_inference_ms": 21.681145822030757, "mean_action_processing_ms": 0.26193107186090203, "mean_env_wait_ms": 3.4917596762556515, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006518244743347168, "StateBufferConnector_ms": 0.004502773284912109, "ViewRequirementAgentConnector_ms": 0.13691306114196777}, "num_episodes": 18, "episode_return_max": 3.9999999999999587, "episode_return_min": -590.98, "episode_return_mean": -40.143699999999946, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1136000, "num_agent_steps_trained": 1136000, "num_env_steps_sampled": 284000, "num_env_steps_trained": 284000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 375.3023245336581, "num_env_steps_trained_throughput_per_sec": 375.3023245336581, "timesteps_total": 284000, "num_env_steps_sampled_lifetime": 284000, "num_agent_steps_sampled_lifetime": 1136000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1136000, "timers": {"training_iteration_time_ms": 200043.49, "restore_workers_time_ms": 0.016, "training_step_time_ms": 200043.44, "sample_time_ms": 1678.515, "learn_time_ms": 198344.505, "learn_throughput": 20.167, "synch_weights_time_ms": 17.337}, "counters": {"num_env_steps_sampled": 284000, "num_env_steps_trained": 284000, "num_agent_steps_sampled": 1136000, "num_agent_steps_trained": 1136000}, "done": false, "training_iteration": 71, "trial_id": "8e499_00000", "date": "2024-08-15_03-27-01", "timestamp": 1723672621, "time_this_iter_s": 10.698306798934937, "time_total_s": 4960.533006191254, "pid": 33199, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b43f25e0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 4960.533006191254, "iterations_since_restore": 71, "perf": {"cpu_util_percent": 43.34, "ram_util_percent": 82.47333333333334}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.0907019039625845, "cur_kl_coeff": 0.028125000000000008, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.427293611834289, "policy_loss": -0.004180527434723757, "vf_loss": 4.431308323365671, "vf_explained_var": 0.029034049422652634, "kl": 0.005895656827412394, "entropy": 0.5526225608808023, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 135135.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6258016852790085, "cur_kl_coeff": 0.084375, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.080973454757973, "policy_loss": -0.00536048120299167, "vf_loss": 5.085662806854046, "vf_explained_var": 0.018824502021547347, "kl": 0.007954008695673784, "entropy": 0.7548792350859869, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 135135.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 288000, "num_env_steps_trained": 288000, "num_agent_steps_sampled": 1152000, "num_agent_steps_trained": 1152000}, "env_runners": {"episode_reward_max": 3.9499999999999598, "episode_reward_min": -590.98, "episode_reward_mean": -49.35489999999994, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 2.0000000000000013, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -53.76744999999997, "predator_policy": 29.09}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.07000000000003034, -7.170000000000002, -77.26999999999974, -33.409999999999634, -25.709999999999827, -3.070000000000083, 2.989999999999981, -67.78, -58.09999999999987, -9.22000000000008, -65.03999999999948, -3.0700000000000838, -9.26000000000008, -10.140000000000082, -34.38000000000005, -0.08000000000004011, -5.16000000000008, -8.130000000000082, -111.42999999999942, -29.48999999999961, -5.090000000000083, -18.529999999999458, -590.98, -48.050000000000516, -6.580000000000071, -15.149999999999554, -4.080000000000084, -84.35999999999969, -4.080000000000084, -6.100000000000083, 2.989999999999981, -6.180000000000081, -23.509999999999547, -6.100000000000078, -34.41999999999988, -15.17999999999955, -32.619999999999905, -18.239999999999412, -28.319999999999446, -23.48000000000002, -7.110000000000083, -76.47999999999996, -5.090000000000013, -11.160000000000082, 1.9800000000000026, 0.9699999999999819, -4.090000000000082, -18.219999999999427, -8.180000000000081, -260.36000000000024, -5.090000000000083, -489.53000000000037, -48.52000000000034, -7.110000000000083, 3.9499999999999598, -10.130000000000082, -4.0900000000000825, 0.9299999999999818, -100.04999999999905, -4.080000000000082, -42.49000000000034, -10.330000000000055, -59.63000000000062, -86.89999999999945, -17.209999999999532, -42.69000000000065, -4.120000000000023, -15.280000000000026, -9.130000000000017, -37.41000000000043, -66.5299999999984, -22.369999999999433, 3.889999999999961, 3.9499999999999598, -79.6399999999984, -71.75000000000001, -448.22000000000014, -47.51000000000031, -36.36000000000066, -168.69000000000005, -160.12000000000003, -32.35999999999998, -20.46999999999945, -74.75000000000043, -62.68000000000005, -279.38000000000045, -14.279999999999974, -77.83999999999843, -6.100000000000083, -62.49000000000024, -40.540000000000184, -14.179999999999731, 1.8599999999999624, -18.219999999999736, -55.589999999999876, -13.570000000000054, -11.150000000000082, -25.21999999999992, -88.98999999999944, -46.4899999999997], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-2.020000000000035, -8.050000000000042, -32.17000000000004, 2.0000000000000013, -112.56999999999931, -138.7000000000001, -6.040000000000042, -72.36999999999999, -140.71000000000038, 2.0000000000000013, 2.0000000000000013, -12.070000000000041, -0.00999999999999836, 2.0000000000000013, -72.3699999999992, -281.4099999999999, -60.31000000000024, -156.78999999999982, -22.119999999999706, -18.099999999999724, -30.159999999999794, -174.88000000000022, -2.020000000000042, -8.050000000000042, -40.210000000000356, -8.050000000000042, -2.020000000000042, -22.119999999999706, -74.37999999999971, 2.0000000000000013, -14.080000000000041, 2.0000000000000013, 2.0000000000000013, -30.159999999999712, -18.099999999999707, -4.030000000000042, -128.6500000000007, -154.7799999999999, -54.28000000000034, -40.210000000000164, -12.070000000000041, -2.020000000000042, -18.099999999999703, -84.4299999999992, -400.0, -395.98, -136.6900000000012, -70.35999999999972, -104.52999999999945, -8.050000000000042, -14.08000000000004, -12.070000000000041, -8.050000000000042, -4.030000000000042, -136.68999999999988, -132.67000000000007, 2.0000000000000013, -14.080000000000041, -6.040000000000042, -10.060000000000041, 2.0000000000000013, -0.00999999999999836, -6.040000000000042, -26.13999999999971, -100.50999999999931, 2.0000000000000013, -0.00999999999999836, -16.090000000000014, -80.40999999999993, -0.00999999999999836, -18.099999999999703, -14.080000000000041, -110.55999999999996, -10.060000000000041, -26.13999999999971, -18.099999999999703, -4.030000000000042, -56.29000000000034, -72.37, -20.109999999999705, -8.050000000000042, -10.060000000000041, -16.0899999999997, -277.3900000000001, 2.0000000000000013, -16.08999999999998, -18.099999999999927, -10.060000000000041, -2.020000000000042, 2.0000000000000013, 2.0000000000000013, -4.030000000000042, 2.0000000000000013, -16.0899999999997, -36.19000000000036, -4.030000000000042, -22.119999999999706, -10.060000000000041, -140.71, -329.65000000000015, -0.00999999999999836, -14.080000000000041, -391.96000000000004, -313.5700000000004, -98.49999999999964, -2.020000000000042, -8.050000000000042, -10.060000000000041, 2.0000000000000013, -8.050000000000042, -10.060000000000041, -12.070000000000041, 2.0000000000000013, -16.089999999999883, -12.070000000000041, 2.0000000000000013, -34.180000000000305, -172.87000000000063, -14.08000000000004, 2.0000000000000013, -74.37999999999958, -20.10999999999981, -40.21000000000025, -22.120000000000015, -108.5499999999993, -14.080000000000041, -12.070000000000041, -164.82999999999998, -26.139999999999763, -12.070000000000041, -98.49999999999928, -36.19000000000036, -8.05, -12.070000000000041, -4.030000000000042, -48.24999999999998, -4.0299999999999985, -18.099999999999994, -76.3899999999994, -2.020000000000042, -58.30000000000031, -44.23000000000032, -22.119999999999706, -48.25000000000035, 2.0000000000000013, -20.109999999999705, 2.0000000000000013, -8.050000000000042, -44.230000000000295, -80.40999999999919, -120.60999999999979, -26.139999999999933, -349.7500000000001, -293.4699999999999, -52.27000000000017, -46.23999999999991, -62.320000000000334, -6.040000000000042, -156.79000000000005, -178.89999999999984, -110.56000000000003, -110.56000000000003, -24.129999999999868, -44.23000000000035, -46.24000000000035, -44.22999999999972, -106.53999999999942, -40.210000000000036, -52.2700000000001, -80.41000000000003, -201.0099999999998, -273.37, -18.099999999999703, -34.180000000000234, -66.3399999999992, -98.49999999999925, -14.080000000000041, -2.020000000000042, -60.30999999999989, -34.180000000000085, -22.11999999999972, -82.41999999999958, -12.070000000000041, -20.109999999999705, -16.09000000000004, -8.050000000000042, 2.0000000000000013, -42.22000000000006, 2.0000000000000013, -116.59, -96.4899999999997, -14.080000000000041, -8.050000000000042, -18.099999999999827, -18.09999999999996, -22.119999999999994, -188.95000000000033, -6.040000000000042, -60.310000000000315, -34.180000000000085], "policy_predator_policy_reward": [4.0, 6.0, 12.0, 11.0, 106.0, 68.0, 22.0, 23.0, 58.0, 55.0, 0.0, 7.0, 1.0, 0.0, 146.0, 140.0, 75.0, 84.0, 18.0, 13.0, 61.0, 79.0, 5.0, 2.0, 18.0, 21.0, 2.0, 12.0, 38.0, 0.0, 4.0, 8.0, 8.0, 15.0, 5.0, 9.0, 96.0, 76.0, 32.0, 33.0, 2.0, 7.0, 43.0, 41.0, 200.0, 5.0, 82.0, 77.0, 52.0, 54.0, 0.0, 11.0, 4.0, 4.0, 88.0, 97.0, 0.0, 8.0, 6.0, 4.0, 1.0, 0.0, 14.0, 12.0, 29.0, 46.0, 8.0, 2.0, 28.0, 18.0, 7.0, 10.0, 43.0, 45.0, 14.0, 12.0, 3.0, 29.0, 30.0, 39.0, 5.0, 6.0, 104.0, 113.0, 9.0, 0.0, 11.0, 6.0, 0.0, 2.0, 0.0, 3.0, 1.0, 9.0, 19.0, 3.0, 12.0, 12.0, 36.0, 174.0, 8.0, 1.0, 199.0, 17.0, 40.0, 12.0, 6.0, 5.0, 5.0, 5.0, 7.0, 5.0, 1.0, 9.0, 7.0, 4.0, 91.0, 16.0, 8.0, 0.0, 3.0, 49.0, 28.0, 24.0, 55.0, 8.0, 83.0, 7.0, 21.0, 0.0, 46.0, 46.0, 5.0, 11.0, 18.0, 19.0, 0.0, 13.0, 3.0, 38.0, 8.0, 28.0, 23.0, 25.0, 11.0, 11.0, 5.0, 5.0, 44.0, 1.0, 4.0, 71.0, 195.0, 0.0, 11.0, 40.0, 32.0, 0.0, 90.0, 77.0, 6.0, 55.0, 10.0, 26.0, 34.0, 36.0, 49.0, 23.0, 55.0, 15.0, 120.0, 75.0, 18.0, 20.0, 47.0, 40.0, 8.0, 2.0, 8.0, 24.0, 35.0, 29.0, 11.0, 7.0, 14.0, 12.0, 9.0, 13.0, 45.0, 14.0, 54.0, 43.0, 5.0, 10.0, 3.0, 12.0, 84.0, 22.0, 24.0, 24.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 7.39982501316998, "mean_inference_ms": 21.384879842486413, "mean_action_processing_ms": 0.26209965444072264, "mean_env_wait_ms": 3.428264873379967, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007198691368103027, "StateBufferConnector_ms": 0.004316091537475586, "ViewRequirementAgentConnector_ms": 0.1318659782409668}, "num_episodes": 22, "episode_return_max": 3.9499999999999598, "episode_return_min": -590.98, "episode_return_mean": -49.35489999999994, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1152000, "num_agent_steps_trained": 1152000, "num_env_steps_sampled": 288000, "num_env_steps_trained": 288000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 401.53603686281684, "num_env_steps_trained_throughput_per_sec": 401.53603686281684, "timesteps_total": 288000, "num_env_steps_sampled_lifetime": 288000, "num_agent_steps_sampled_lifetime": 1152000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1152000, "timers": {"training_iteration_time_ms": 199964.243, "restore_workers_time_ms": 0.016, "training_step_time_ms": 199964.194, "sample_time_ms": 1672.064, "learn_time_ms": 198272.359, "learn_throughput": 20.174, "synch_weights_time_ms": 16.809}, "counters": {"num_env_steps_sampled": 288000, "num_env_steps_trained": 288000, "num_agent_steps_sampled": 1152000, "num_agent_steps_trained": 1152000}, "done": false, "training_iteration": 72, "trial_id": "8e499_00000", "date": "2024-08-15_03-27-11", "timestamp": 1723672631, "time_this_iter_s": 9.968501091003418, "time_total_s": 4970.501507282257, "pid": 33199, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x1580f8160>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 4970.501507282257, "iterations_since_restore": 72, "perf": {"cpu_util_percent": 35.98571428571429, "ram_util_percent": 80.07142857142857}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8319465189383775, "cur_kl_coeff": 0.028125000000000008, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.251457778991215, "policy_loss": -0.002975305318142529, "vf_loss": 6.254269039315521, "vf_explained_var": 0.007505422168307834, "kl": 0.0058326865075677805, "entropy": 0.5182533786725746, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 137025.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6327167691850157, "cur_kl_coeff": 0.084375, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.146630772081002, "policy_loss": -0.004810988741049731, "vf_loss": 6.150965098729209, "vf_explained_var": 0.03324391349913582, "kl": 0.005649315164826985, "entropy": 0.7238732835603139, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 137025.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 292000, "num_env_steps_trained": 292000, "num_agent_steps_sampled": 1168000, "num_agent_steps_trained": 1168000}, "env_runners": {"episode_reward_max": 3.9499999999999598, "episode_reward_min": -489.53000000000037, "episode_reward_mean": -60.83209999999992, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -391.96000000000004, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 2.0000000000000013, "predator_policy": 199.0}, "policy_reward_mean": {"prey_policy": -63.65604999999999, "predator_policy": 33.24}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-48.050000000000516, -6.580000000000071, -15.149999999999554, -4.080000000000084, -84.35999999999969, -4.080000000000084, -6.100000000000083, 2.989999999999981, -6.180000000000081, -23.509999999999547, -6.100000000000078, -34.41999999999988, -15.17999999999955, -32.619999999999905, -18.239999999999412, -28.319999999999446, -23.48000000000002, -7.110000000000083, -76.47999999999996, -5.090000000000013, -11.160000000000082, 1.9800000000000026, 0.9699999999999819, -4.090000000000082, -18.219999999999427, -8.180000000000081, -260.36000000000024, -5.090000000000083, -489.53000000000037, -48.52000000000034, -7.110000000000083, 3.9499999999999598, -10.130000000000082, -4.0900000000000825, 0.9299999999999818, -100.04999999999905, -4.080000000000082, -42.49000000000034, -10.330000000000055, -59.63000000000062, -86.89999999999945, -17.209999999999532, -42.69000000000065, -4.120000000000023, -15.280000000000026, -9.130000000000017, -37.41000000000043, -66.5299999999984, -22.369999999999433, 3.889999999999961, 3.9499999999999598, -79.6399999999984, -71.75000000000001, -448.22000000000014, -47.51000000000031, -36.36000000000066, -168.69000000000005, -160.12000000000003, -32.35999999999998, -20.46999999999945, -74.75000000000043, -62.68000000000005, -279.38000000000045, -14.279999999999974, -77.83999999999843, -6.100000000000083, -62.49000000000024, -40.540000000000184, -14.179999999999731, 1.8599999999999624, -18.219999999999736, -55.589999999999876, -13.570000000000054, -11.150000000000082, -25.21999999999992, -88.98999999999944, -46.4899999999997, -124.27999999999972, -182.26999999999958, -29.66000000000013, -261.15000000000055, -106.93000000000005, -167.40999999999963, -7.119999999999997, -218.8900000000002, -84.90000000000002, -24.289999999999424, -103.48999999999965, -118.97, -48.860000000000625, -52.10000000000005, -20.23999999999943, -23.279999999999447, -38.820000000000356, 3.889999999999961, -389.09000000000003, -128.27999999999963, 1.8900000000000028, -153.5699999999997, -39.489999999999895], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-136.6900000000012, -70.35999999999972, -104.52999999999945, -8.050000000000042, -14.08000000000004, -12.070000000000041, -8.050000000000042, -4.030000000000042, -136.68999999999988, -132.67000000000007, 2.0000000000000013, -14.080000000000041, -6.040000000000042, -10.060000000000041, 2.0000000000000013, -0.00999999999999836, -6.040000000000042, -26.13999999999971, -100.50999999999931, 2.0000000000000013, -0.00999999999999836, -16.090000000000014, -80.40999999999993, -0.00999999999999836, -18.099999999999703, -14.080000000000041, -110.55999999999996, -10.060000000000041, -26.13999999999971, -18.099999999999703, -4.030000000000042, -56.29000000000034, -72.37, -20.109999999999705, -8.050000000000042, -10.060000000000041, -16.0899999999997, -277.3900000000001, 2.0000000000000013, -16.08999999999998, -18.099999999999927, -10.060000000000041, -2.020000000000042, 2.0000000000000013, 2.0000000000000013, -4.030000000000042, 2.0000000000000013, -16.0899999999997, -36.19000000000036, -4.030000000000042, -22.119999999999706, -10.060000000000041, -140.71, -329.65000000000015, -0.00999999999999836, -14.080000000000041, -391.96000000000004, -313.5700000000004, -98.49999999999964, -2.020000000000042, -8.050000000000042, -10.060000000000041, 2.0000000000000013, -8.050000000000042, -10.060000000000041, -12.070000000000041, 2.0000000000000013, -16.089999999999883, -12.070000000000041, 2.0000000000000013, -34.180000000000305, -172.87000000000063, -14.08000000000004, 2.0000000000000013, -74.37999999999958, -20.10999999999981, -40.21000000000025, -22.120000000000015, -108.5499999999993, -14.080000000000041, -12.070000000000041, -164.82999999999998, -26.139999999999763, -12.070000000000041, -98.49999999999928, -36.19000000000036, -8.05, -12.070000000000041, -4.030000000000042, -48.24999999999998, -4.0299999999999985, -18.099999999999994, -76.3899999999994, -2.020000000000042, -58.30000000000031, -44.23000000000032, -22.119999999999706, -48.25000000000035, 2.0000000000000013, -20.109999999999705, 2.0000000000000013, -8.050000000000042, -44.230000000000295, -80.40999999999919, -120.60999999999979, -26.139999999999933, -349.7500000000001, -293.4699999999999, -52.27000000000017, -46.23999999999991, -62.320000000000334, -6.040000000000042, -156.79000000000005, -178.89999999999984, -110.56000000000003, -110.56000000000003, -24.129999999999868, -44.23000000000035, -46.24000000000035, -44.22999999999972, -106.53999999999942, -40.210000000000036, -52.2700000000001, -80.41000000000003, -201.0099999999998, -273.37, -18.099999999999703, -34.180000000000234, -66.3399999999992, -98.49999999999925, -14.080000000000041, -2.020000000000042, -60.30999999999989, -34.180000000000085, -22.11999999999972, -82.41999999999958, -12.070000000000041, -20.109999999999705, -16.09000000000004, -8.050000000000042, 2.0000000000000013, -42.22000000000006, 2.0000000000000013, -116.59, -96.4899999999997, -14.080000000000041, -8.050000000000042, -18.099999999999827, -18.09999999999996, -22.119999999999994, -188.95000000000033, -6.040000000000042, -60.310000000000315, -34.180000000000085, -263.28, 2.0000000000000013, -132.6699999999998, -118.60000000000002, -301.50999999999993, -28.14999999999978, -146.74000000000038, -281.4099999999997, -114.58000000000015, -68.3500000000001, -122.61999999999978, -156.79000000000022, -14.080000000000041, -6.039999999999998, -289.4500000000001, -86.43999999999978, -12.070000000000041, -164.82999999999996, -38.20000000000036, -16.089999999999705, -20.109999999999705, -275.38, -80.41, -110.55999999999977, -36.19000000000036, -132.67000000000078, -78.39999999999976, -138.70000000000022, -6.040000000000042, -38.20000000000036, -54.28000000000034, 2.0000000000000013, -170.82000000000082, 2.0000000000000013, -20.109999999999705, 2.0000000000000013, -319.59999999999997, -297.49, -146.74000000000007, -106.54000000000023, -20.109999999999705, 2.0000000000000013, -303.4799999999998, -16.09000000000004, -96.48999999999933, 2.0000000000000013], "policy_predator_policy_reward": [82.0, 77.0, 52.0, 54.0, 0.0, 11.0, 4.0, 4.0, 88.0, 97.0, 0.0, 8.0, 6.0, 4.0, 1.0, 0.0, 14.0, 12.0, 29.0, 46.0, 8.0, 2.0, 28.0, 18.0, 7.0, 10.0, 43.0, 45.0, 14.0, 12.0, 3.0, 29.0, 30.0, 39.0, 5.0, 6.0, 104.0, 113.0, 9.0, 0.0, 11.0, 6.0, 0.0, 2.0, 0.0, 3.0, 1.0, 9.0, 19.0, 3.0, 12.0, 12.0, 36.0, 174.0, 8.0, 1.0, 199.0, 17.0, 40.0, 12.0, 6.0, 5.0, 5.0, 5.0, 7.0, 5.0, 1.0, 9.0, 7.0, 4.0, 91.0, 16.0, 8.0, 0.0, 3.0, 49.0, 28.0, 24.0, 55.0, 8.0, 83.0, 7.0, 21.0, 0.0, 46.0, 46.0, 5.0, 11.0, 18.0, 19.0, 0.0, 13.0, 3.0, 38.0, 8.0, 28.0, 23.0, 25.0, 11.0, 11.0, 5.0, 5.0, 44.0, 1.0, 4.0, 71.0, 195.0, 0.0, 11.0, 40.0, 32.0, 0.0, 90.0, 77.0, 6.0, 55.0, 10.0, 26.0, 34.0, 36.0, 49.0, 23.0, 55.0, 15.0, 120.0, 75.0, 18.0, 20.0, 47.0, 40.0, 8.0, 2.0, 8.0, 24.0, 35.0, 29.0, 11.0, 7.0, 14.0, 12.0, 9.0, 13.0, 45.0, 14.0, 54.0, 43.0, 5.0, 10.0, 3.0, 12.0, 84.0, 22.0, 24.0, 24.0, 137.0, 0.0, 1.0, 68.0, 142.0, 158.0, 108.0, 59.0, 45.0, 31.0, 83.0, 29.0, 7.0, 6.0, 126.0, 31.0, 90.0, 2.0, 20.0, 10.0, 145.0, 47.0, 16.0, 56.0, 64.0, 56.0, 84.0, 81.0, 20.0, 4.0, 1.0, 28.0, 62.0, 68.0, 11.0, 11.0, 76.0, 152.0, 89.0, 36.0, 11.0, 9.0, 104.0, 62.0, 23.0, 32.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 6.6971294740182, "mean_inference_ms": 21.670851189665996, "mean_action_processing_ms": 0.2624561156089634, "mean_env_wait_ms": 3.3873660502708356, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007097482681274414, "StateBufferConnector_ms": 0.0036864280700683594, "ViewRequirementAgentConnector_ms": 0.12763190269470215}, "num_episodes": 23, "episode_return_max": 3.9499999999999598, "episode_return_min": -489.53000000000037, "episode_return_mean": -60.83209999999992, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1168000, "num_agent_steps_trained": 1168000, "num_env_steps_sampled": 292000, "num_env_steps_trained": 292000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 399.08267115768643, "num_env_steps_trained_throughput_per_sec": 399.08267115768643, "timesteps_total": 292000, "num_env_steps_sampled_lifetime": 292000, "num_agent_steps_sampled_lifetime": 1168000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1168000, "timers": {"training_iteration_time_ms": 199899.389, "restore_workers_time_ms": 0.016, "training_step_time_ms": 199899.34, "sample_time_ms": 1657.127, "learn_time_ms": 198222.954, "learn_throughput": 20.179, "synch_weights_time_ms": 16.543}, "counters": {"num_env_steps_sampled": 292000, "num_env_steps_trained": 292000, "num_agent_steps_sampled": 1168000, "num_agent_steps_trained": 1168000}, "done": false, "training_iteration": 73, "trial_id": "8e499_00000", "date": "2024-08-15_03-27-21", "timestamp": 1723672641, "time_this_iter_s": 10.028806209564209, "time_total_s": 4980.530313491821, "pid": 33199, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x158145d30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 4980.530313491821, "iterations_since_restore": 73, "perf": {"cpu_util_percent": 35.15714285714286, "ram_util_percent": 79.59285714285714}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5871984382943503, "cur_kl_coeff": 0.028125000000000008, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.83988688862513, "policy_loss": -0.0037313224884518792, "vf_loss": 6.843444808828767, "vf_explained_var": 0.011862908343158701, "kl": 0.006165649677721618, "entropy": 0.46046343292824177, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 138915.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.432037705656082, "cur_kl_coeff": 0.084375, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.8884603412063035, "policy_loss": -0.005698718071826512, "vf_loss": 5.893400110264935, "vf_explained_var": 0.05474961037358279, "kl": 0.008994729848580336, "entropy": 0.9010373373195608, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 138915.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 296000, "num_env_steps_trained": 296000, "num_agent_steps_sampled": 1184000, "num_agent_steps_trained": 1184000}, "env_runners": {"episode_reward_max": 3.9499999999999598, "episode_reward_min": -489.53000000000037, "episode_reward_mean": -73.55069999999994, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -391.96000000000004, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 2.0000000000000013, "predator_policy": 199.0}, "policy_reward_mean": {"prey_policy": -76.62035, "predator_policy": 39.845}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-76.47999999999996, -5.090000000000013, -11.160000000000082, 1.9800000000000026, 0.9699999999999819, -4.090000000000082, -18.219999999999427, -8.180000000000081, -260.36000000000024, -5.090000000000083, -489.53000000000037, -48.52000000000034, -7.110000000000083, 3.9499999999999598, -10.130000000000082, -4.0900000000000825, 0.9299999999999818, -100.04999999999905, -4.080000000000082, -42.49000000000034, -10.330000000000055, -59.63000000000062, -86.89999999999945, -17.209999999999532, -42.69000000000065, -4.120000000000023, -15.280000000000026, -9.130000000000017, -37.41000000000043, -66.5299999999984, -22.369999999999433, 3.889999999999961, 3.9499999999999598, -79.6399999999984, -71.75000000000001, -448.22000000000014, -47.51000000000031, -36.36000000000066, -168.69000000000005, -160.12000000000003, -32.35999999999998, -20.46999999999945, -74.75000000000043, -62.68000000000005, -279.38000000000045, -14.279999999999974, -77.83999999999843, -6.100000000000083, -62.49000000000024, -40.540000000000184, -14.179999999999731, 1.8599999999999624, -18.219999999999736, -55.589999999999876, -13.570000000000054, -11.150000000000082, -25.21999999999992, -88.98999999999944, -46.4899999999997, -124.27999999999972, -182.26999999999958, -29.66000000000013, -261.15000000000055, -106.93000000000005, -167.40999999999963, -7.119999999999997, -218.8900000000002, -84.90000000000002, -24.289999999999424, -103.48999999999965, -118.97, -48.860000000000625, -52.10000000000005, -20.23999999999943, -23.279999999999447, -38.820000000000356, 3.889999999999961, -389.09000000000003, -128.27999999999963, 1.8900000000000028, -153.5699999999997, -39.489999999999895, -185.5, -27.319999999999922, -54.63000000000059, -127.2999999999989, -69.73999999999988, -160.97000000000003, -12.160000000000082, -171.96000000000004, -73.61000000000017, -9.450000000000042, -89.01999999999863, -51.51000000000043, -127.79000000000008, -81.21999999999994, -81.30999999999962, -53.8200000000002, -120.91999999999912, -134.20000000000041], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-16.0899999999997, -277.3900000000001, 2.0000000000000013, -16.08999999999998, -18.099999999999927, -10.060000000000041, -2.020000000000042, 2.0000000000000013, 2.0000000000000013, -4.030000000000042, 2.0000000000000013, -16.0899999999997, -36.19000000000036, -4.030000000000042, -22.119999999999706, -10.060000000000041, -140.71, -329.65000000000015, -0.00999999999999836, -14.080000000000041, -391.96000000000004, -313.5700000000004, -98.49999999999964, -2.020000000000042, -8.050000000000042, -10.060000000000041, 2.0000000000000013, -8.050000000000042, -10.060000000000041, -12.070000000000041, 2.0000000000000013, -16.089999999999883, -12.070000000000041, 2.0000000000000013, -34.180000000000305, -172.87000000000063, -14.08000000000004, 2.0000000000000013, -74.37999999999958, -20.10999999999981, -40.21000000000025, -22.120000000000015, -108.5499999999993, -14.080000000000041, -12.070000000000041, -164.82999999999998, -26.139999999999763, -12.070000000000041, -98.49999999999928, -36.19000000000036, -8.05, -12.070000000000041, -4.030000000000042, -48.24999999999998, -4.0299999999999985, -18.099999999999994, -76.3899999999994, -2.020000000000042, -58.30000000000031, -44.23000000000032, -22.119999999999706, -48.25000000000035, 2.0000000000000013, -20.109999999999705, 2.0000000000000013, -8.050000000000042, -44.230000000000295, -80.40999999999919, -120.60999999999979, -26.139999999999933, -349.7500000000001, -293.4699999999999, -52.27000000000017, -46.23999999999991, -62.320000000000334, -6.040000000000042, -156.79000000000005, -178.89999999999984, -110.56000000000003, -110.56000000000003, -24.129999999999868, -44.23000000000035, -46.24000000000035, -44.22999999999972, -106.53999999999942, -40.210000000000036, -52.2700000000001, -80.41000000000003, -201.0099999999998, -273.37, -18.099999999999703, -34.180000000000234, -66.3399999999992, -98.49999999999925, -14.080000000000041, -2.020000000000042, -60.30999999999989, -34.180000000000085, -22.11999999999972, -82.41999999999958, -12.070000000000041, -20.109999999999705, -16.09000000000004, -8.050000000000042, 2.0000000000000013, -42.22000000000006, 2.0000000000000013, -116.59, -96.4899999999997, -14.080000000000041, -8.050000000000042, -18.099999999999827, -18.09999999999996, -22.119999999999994, -188.95000000000033, -6.040000000000042, -60.310000000000315, -34.180000000000085, -263.28, 2.0000000000000013, -132.6699999999998, -118.60000000000002, -301.50999999999993, -28.14999999999978, -146.74000000000038, -281.4099999999997, -114.58000000000015, -68.3500000000001, -122.61999999999978, -156.79000000000022, -14.080000000000041, -6.039999999999998, -289.4500000000001, -86.43999999999978, -12.070000000000041, -164.82999999999996, -38.20000000000036, -16.089999999999705, -20.109999999999705, -275.38, -80.41, -110.55999999999977, -36.19000000000036, -132.67000000000078, -78.39999999999976, -138.70000000000022, -6.040000000000042, -38.20000000000036, -54.28000000000034, 2.0000000000000013, -170.82000000000082, 2.0000000000000013, -20.109999999999705, 2.0000000000000013, -319.59999999999997, -297.49, -146.74000000000007, -106.54000000000023, -20.109999999999705, 2.0000000000000013, -303.4799999999998, -16.09000000000004, -96.48999999999933, 2.0000000000000013, -126.60000000000001, -178.90000000000003, -62.31999999999995, 2.0000000000000013, -4.030000000000042, -118.5999999999993, -203.0200000000009, -54.27999999999993, -94.47999999999993, -50.26000000000012, -76.38999999999993, -315.58000000000015, -8.050000000000042, -20.109999999999744, -231.16000000000017, -158.80000000000018, -271.36, -48.250000000000234, 2.0000000000000013, -88.44999999999963, -48.25000000000034, -152.770000000001, -58.30000000000021, -40.210000000000186, -60.31000000000016, -295.4799999999999, -34.18000000000036, -207.04000000000013, -92.46999999999964, -166.8400000000001, -4.030000000000042, -156.79000000000036, -100.50999999999941, -80.40999999999937, -64.32999999999973, -172.8700000000002], "policy_predator_policy_reward": [104.0, 113.0, 9.0, 0.0, 11.0, 6.0, 0.0, 2.0, 0.0, 3.0, 1.0, 9.0, 19.0, 3.0, 12.0, 12.0, 36.0, 174.0, 8.0, 1.0, 199.0, 17.0, 40.0, 12.0, 6.0, 5.0, 5.0, 5.0, 7.0, 5.0, 1.0, 9.0, 7.0, 4.0, 91.0, 16.0, 8.0, 0.0, 3.0, 49.0, 28.0, 24.0, 55.0, 8.0, 83.0, 7.0, 21.0, 0.0, 46.0, 46.0, 5.0, 11.0, 18.0, 19.0, 0.0, 13.0, 3.0, 38.0, 8.0, 28.0, 23.0, 25.0, 11.0, 11.0, 5.0, 5.0, 44.0, 1.0, 4.0, 71.0, 195.0, 0.0, 11.0, 40.0, 32.0, 0.0, 90.0, 77.0, 6.0, 55.0, 10.0, 26.0, 34.0, 36.0, 49.0, 23.0, 55.0, 15.0, 120.0, 75.0, 18.0, 20.0, 47.0, 40.0, 8.0, 2.0, 8.0, 24.0, 35.0, 29.0, 11.0, 7.0, 14.0, 12.0, 9.0, 13.0, 45.0, 14.0, 54.0, 43.0, 5.0, 10.0, 3.0, 12.0, 84.0, 22.0, 24.0, 24.0, 137.0, 0.0, 1.0, 68.0, 142.0, 158.0, 108.0, 59.0, 45.0, 31.0, 83.0, 29.0, 7.0, 6.0, 126.0, 31.0, 90.0, 2.0, 20.0, 10.0, 145.0, 47.0, 16.0, 56.0, 64.0, 56.0, 84.0, 81.0, 20.0, 4.0, 1.0, 28.0, 62.0, 68.0, 11.0, 11.0, 76.0, 152.0, 89.0, 36.0, 11.0, 9.0, 104.0, 62.0, 23.0, 32.0, 115.0, 5.0, 32.0, 1.0, 25.0, 43.0, 28.0, 102.0, 21.0, 54.0, 96.0, 135.0, 3.0, 13.0, 117.0, 101.0, 131.0, 115.0, 40.0, 37.0, 37.0, 75.0, 26.0, 21.0, 116.0, 112.0, 72.0, 88.0, 98.0, 80.0, 69.0, 38.0, 33.0, 27.0, 48.0, 55.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 7.211790053073225, "mean_inference_ms": 20.830457013320874, "mean_action_processing_ms": 0.262022445577532, "mean_env_wait_ms": 3.346998875553668, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0062713623046875, "StateBufferConnector_ms": 0.003475785255432129, "ViewRequirementAgentConnector_ms": 0.12268435955047607}, "num_episodes": 18, "episode_return_max": 3.9499999999999598, "episode_return_min": -489.53000000000037, "episode_return_mean": -73.55069999999994, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1184000, "num_agent_steps_trained": 1184000, "num_env_steps_sampled": 296000, "num_env_steps_trained": 296000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 4.182619508382878, "num_env_steps_trained_throughput_per_sec": 4.182619508382878, "timesteps_total": 296000, "num_env_steps_sampled_lifetime": 296000, "num_agent_steps_sampled_lifetime": 1184000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1184000, "timers": {"training_iteration_time_ms": 294503.114, "restore_workers_time_ms": 0.016, "training_step_time_ms": 294503.064, "sample_time_ms": 1641.776, "learn_time_ms": 292841.373, "learn_throughput": 13.659, "synch_weights_time_ms": 16.847}, "counters": {"num_env_steps_sampled": 296000, "num_env_steps_trained": 296000, "num_agent_steps_sampled": 1184000, "num_agent_steps_trained": 1184000}, "done": false, "training_iteration": 74, "trial_id": "8e499_00000", "date": "2024-08-15_03-43-18", "timestamp": 1723673598, "time_this_iter_s": 956.3788769245148, "time_total_s": 5936.909190416336, "pid": 33199, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x158199c10>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 5936.909190416336, "iterations_since_restore": 74, "perf": {"cpu_util_percent": 45.861111111111114, "ram_util_percent": 79.6277777777778}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8360137778615195, "cur_kl_coeff": 0.028125000000000008, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.422350542759769, "policy_loss": -0.0018947617360267532, "vf_loss": 4.424162922712861, "vf_explained_var": 0.004464526435054799, "kl": 0.0029291796409580805, "entropy": 0.3473402240446636, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 140805.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4156600639618262, "cur_kl_coeff": 0.084375, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.7813563039063145, "policy_loss": -0.006931838853205874, "vf_loss": 3.7873687209275664, "vf_explained_var": 0.07574479387550757, "kl": 0.010896783376781044, "entropy": 0.879667416104564, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 140805.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 300000, "num_env_steps_trained": 300000, "num_agent_steps_sampled": 1200000, "num_agent_steps_trained": 1200000}, "env_runners": {"episode_reward_max": 3.9499999999999598, "episode_reward_min": -448.22000000000014, "episode_reward_mean": -73.23589999999992, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -349.7500000000001, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 2.0000000000000013, "predator_policy": 195.0}, "policy_reward_mean": {"prey_policy": -82.16794999999998, "predator_policy": 45.55}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.080000000000082, -42.49000000000034, -10.330000000000055, -59.63000000000062, -86.89999999999945, -17.209999999999532, -42.69000000000065, -4.120000000000023, -15.280000000000026, -9.130000000000017, -37.41000000000043, -66.5299999999984, -22.369999999999433, 3.889999999999961, 3.9499999999999598, -79.6399999999984, -71.75000000000001, -448.22000000000014, -47.51000000000031, -36.36000000000066, -168.69000000000005, -160.12000000000003, -32.35999999999998, -20.46999999999945, -74.75000000000043, -62.68000000000005, -279.38000000000045, -14.279999999999974, -77.83999999999843, -6.100000000000083, -62.49000000000024, -40.540000000000184, -14.179999999999731, 1.8599999999999624, -18.219999999999736, -55.589999999999876, -13.570000000000054, -11.150000000000082, -25.21999999999992, -88.98999999999944, -46.4899999999997, -124.27999999999972, -182.26999999999958, -29.66000000000013, -261.15000000000055, -106.93000000000005, -167.40999999999963, -7.119999999999997, -218.8900000000002, -84.90000000000002, -24.289999999999424, -103.48999999999965, -118.97, -48.860000000000625, -52.10000000000005, -20.23999999999943, -23.279999999999447, -38.820000000000356, 3.889999999999961, -389.09000000000003, -128.27999999999963, 1.8900000000000028, -153.5699999999997, -39.489999999999895, -185.5, -27.319999999999922, -54.63000000000059, -127.2999999999989, -69.73999999999988, -160.97000000000003, -12.160000000000082, -171.96000000000004, -73.61000000000017, -9.450000000000042, -89.01999999999863, -51.51000000000043, -127.79000000000008, -81.21999999999994, -81.30999999999962, -53.8200000000002, -120.91999999999912, -134.20000000000041, -4.4500000000000535, -1.0600000000000631, -61.510000000000176, -2.190000000000069, -126.12999999999877, -37.98999999999997, -140.43000000000018, -37.65000000000031, -44.470000000000475, -160.34000000000108, -27.30999999999977, -27.289999999999473, -121.54999999999961, -18.64999999999951, 2.949999999999982, -115.359999999999, -76.4400000000001, -8.920000000000066], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-14.08000000000004, 2.0000000000000013, -74.37999999999958, -20.10999999999981, -40.21000000000025, -22.120000000000015, -108.5499999999993, -14.080000000000041, -12.070000000000041, -164.82999999999998, -26.139999999999763, -12.070000000000041, -98.49999999999928, -36.19000000000036, -8.05, -12.070000000000041, -4.030000000000042, -48.24999999999998, -4.0299999999999985, -18.099999999999994, -76.3899999999994, -2.020000000000042, -58.30000000000031, -44.23000000000032, -22.119999999999706, -48.25000000000035, 2.0000000000000013, -20.109999999999705, 2.0000000000000013, -8.050000000000042, -44.230000000000295, -80.40999999999919, -120.60999999999979, -26.139999999999933, -349.7500000000001, -293.4699999999999, -52.27000000000017, -46.23999999999991, -62.320000000000334, -6.040000000000042, -156.79000000000005, -178.89999999999984, -110.56000000000003, -110.56000000000003, -24.129999999999868, -44.23000000000035, -46.24000000000035, -44.22999999999972, -106.53999999999942, -40.210000000000036, -52.2700000000001, -80.41000000000003, -201.0099999999998, -273.37, -18.099999999999703, -34.180000000000234, -66.3399999999992, -98.49999999999925, -14.080000000000041, -2.020000000000042, -60.30999999999989, -34.180000000000085, -22.11999999999972, -82.41999999999958, -12.070000000000041, -20.109999999999705, -16.09000000000004, -8.050000000000042, 2.0000000000000013, -42.22000000000006, 2.0000000000000013, -116.59, -96.4899999999997, -14.080000000000041, -8.050000000000042, -18.099999999999827, -18.09999999999996, -22.119999999999994, -188.95000000000033, -6.040000000000042, -60.310000000000315, -34.180000000000085, -263.28, 2.0000000000000013, -132.6699999999998, -118.60000000000002, -301.50999999999993, -28.14999999999978, -146.74000000000038, -281.4099999999997, -114.58000000000015, -68.3500000000001, -122.61999999999978, -156.79000000000022, -14.080000000000041, -6.039999999999998, -289.4500000000001, -86.43999999999978, -12.070000000000041, -164.82999999999996, -38.20000000000036, -16.089999999999705, -20.109999999999705, -275.38, -80.41, -110.55999999999977, -36.19000000000036, -132.67000000000078, -78.39999999999976, -138.70000000000022, -6.040000000000042, -38.20000000000036, -54.28000000000034, 2.0000000000000013, -170.82000000000082, 2.0000000000000013, -20.109999999999705, 2.0000000000000013, -319.59999999999997, -297.49, -146.74000000000007, -106.54000000000023, -20.109999999999705, 2.0000000000000013, -303.4799999999998, -16.09000000000004, -96.48999999999933, 2.0000000000000013, -126.60000000000001, -178.90000000000003, -62.31999999999995, 2.0000000000000013, -4.030000000000042, -118.5999999999993, -203.0200000000009, -54.27999999999993, -94.47999999999993, -50.26000000000012, -76.38999999999993, -315.58000000000015, -8.050000000000042, -20.109999999999744, -231.16000000000017, -158.80000000000018, -271.36, -48.250000000000234, 2.0000000000000013, -88.44999999999963, -48.25000000000034, -152.770000000001, -58.30000000000021, -40.210000000000186, -60.31000000000016, -295.4799999999999, -34.18000000000036, -207.04000000000013, -92.46999999999964, -166.8400000000001, -4.030000000000042, -156.79000000000036, -100.50999999999941, -80.40999999999937, -64.32999999999973, -172.8700000000002, -38.20000000000032, -249.25, -10.060000000000041, 2.0000000000000013, 2.0000000000000013, -301.51000000000033, -24.129999999999754, -10.060000000000041, -94.47999999999935, -128.65000000000072, 2.0000000000000013, -196.99, -30.159999999999716, -253.2700000000005, 2.0000000000000013, -128.64999999999952, -54.2800000000002, -36.19000000000022, -166.84000000000052, -98.4999999999995, -6.040000000000042, -52.27000000000001, -30.159999999999748, -24.129999999999725, -96.4899999999997, -211.06000000000006, -118.59999999999928, -8.050000000000042, -8.050000000000042, 2.0000000000000013, -219.10000000000065, -50.260000000000346, -245.23000000000002, -40.21000000000016, -166.84000000000012, -14.080000000000041], "policy_predator_policy_reward": [8.0, 0.0, 3.0, 49.0, 28.0, 24.0, 55.0, 8.0, 83.0, 7.0, 21.0, 0.0, 46.0, 46.0, 5.0, 11.0, 18.0, 19.0, 0.0, 13.0, 3.0, 38.0, 8.0, 28.0, 23.0, 25.0, 11.0, 11.0, 5.0, 5.0, 44.0, 1.0, 4.0, 71.0, 195.0, 0.0, 11.0, 40.0, 32.0, 0.0, 90.0, 77.0, 6.0, 55.0, 10.0, 26.0, 34.0, 36.0, 49.0, 23.0, 55.0, 15.0, 120.0, 75.0, 18.0, 20.0, 47.0, 40.0, 8.0, 2.0, 8.0, 24.0, 35.0, 29.0, 11.0, 7.0, 14.0, 12.0, 9.0, 13.0, 45.0, 14.0, 54.0, 43.0, 5.0, 10.0, 3.0, 12.0, 84.0, 22.0, 24.0, 24.0, 137.0, 0.0, 1.0, 68.0, 142.0, 158.0, 108.0, 59.0, 45.0, 31.0, 83.0, 29.0, 7.0, 6.0, 126.0, 31.0, 90.0, 2.0, 20.0, 10.0, 145.0, 47.0, 16.0, 56.0, 64.0, 56.0, 84.0, 81.0, 20.0, 4.0, 1.0, 28.0, 62.0, 68.0, 11.0, 11.0, 76.0, 152.0, 89.0, 36.0, 11.0, 9.0, 104.0, 62.0, 23.0, 32.0, 115.0, 5.0, 32.0, 1.0, 25.0, 43.0, 28.0, 102.0, 21.0, 54.0, 96.0, 135.0, 3.0, 13.0, 117.0, 101.0, 131.0, 115.0, 40.0, 37.0, 37.0, 75.0, 26.0, 21.0, 116.0, 112.0, 72.0, 88.0, 98.0, 80.0, 69.0, 38.0, 33.0, 27.0, 48.0, 55.0, 140.0, 143.0, 6.0, 1.0, 151.0, 87.0, 18.0, 14.0, 31.0, 66.0, 62.0, 95.0, 127.0, 16.0, 55.0, 34.0, 16.0, 30.0, 83.0, 22.0, 13.0, 18.0, 2.0, 25.0, 92.0, 94.0, 48.0, 60.0, 4.0, 5.0, 118.0, 36.0, 101.0, 108.0, 90.0, 82.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 7.131219937857258, "mean_inference_ms": 20.600629157721436, "mean_action_processing_ms": 0.2626196691187592, "mean_env_wait_ms": 3.308414247139375, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0069457292556762695, "StateBufferConnector_ms": 0.0076912641525268555, "ViewRequirementAgentConnector_ms": 0.16305947303771973}, "num_episodes": 18, "episode_return_max": 3.9499999999999598, "episode_return_min": -448.22000000000014, "episode_return_mean": -73.23589999999992, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1200000, "num_agent_steps_trained": 1200000, "num_env_steps_sampled": 300000, "num_env_steps_trained": 300000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 286.84158974087, "num_env_steps_trained_throughput_per_sec": 286.84158974087, "timesteps_total": 300000, "num_env_steps_sampled_lifetime": 300000, "num_agent_steps_sampled_lifetime": 1200000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1200000, "timers": {"training_iteration_time_ms": 199990.004, "restore_workers_time_ms": 0.016, "training_step_time_ms": 199989.953, "sample_time_ms": 1888.686, "learn_time_ms": 198082.014, "learn_throughput": 20.194, "synch_weights_time_ms": 16.028}, "counters": {"num_env_steps_sampled": 300000, "num_env_steps_trained": 300000, "num_agent_steps_sampled": 1200000, "num_agent_steps_trained": 1200000}, "done": false, "training_iteration": 75, "trial_id": "8e499_00000", "date": "2024-08-15_03-43-32", "timestamp": 1723673612, "time_this_iter_s": 14.0085928440094, "time_total_s": 5950.9177832603455, "pid": 33199, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x158199a60>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 5950.9177832603455, "iterations_since_restore": 75, "perf": {"cpu_util_percent": 69.83684210526317, "ram_util_percent": 82.49473684210528}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.331820059264148, "cur_kl_coeff": 0.014062500000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.048630869073212, "policy_loss": -0.002238475528383066, "vf_loss": 4.0507889584889485, "vf_explained_var": 0.11669418490122235, "kl": 0.005716218462085062, "entropy": 0.3948510786055257, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 142695.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5474269769494495, "cur_kl_coeff": 0.084375, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.184953895573893, "policy_loss": -0.011922508928427108, "vf_loss": 4.195343305068041, "vf_explained_var": 0.05117243244534447, "kl": 0.018170156530935497, "entropy": 0.9355460561772503, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 142695.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 304000, "num_env_steps_trained": 304000, "num_agent_steps_sampled": 1216000, "num_agent_steps_trained": 1216000}, "env_runners": {"episode_reward_max": 3.889999999999961, "episode_reward_min": -389.09000000000003, "episode_reward_mean": -69.00759999999987, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -319.59999999999997, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 2.0000000000000013, "predator_policy": 158.0}, "policy_reward_mean": {"prey_policy": -80.32879999999999, "predator_policy": 45.825}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-32.35999999999998, -20.46999999999945, -74.75000000000043, -62.68000000000005, -279.38000000000045, -14.279999999999974, -77.83999999999843, -6.100000000000083, -62.49000000000024, -40.540000000000184, -14.179999999999731, 1.8599999999999624, -18.219999999999736, -55.589999999999876, -13.570000000000054, -11.150000000000082, -25.21999999999992, -88.98999999999944, -46.4899999999997, -124.27999999999972, -182.26999999999958, -29.66000000000013, -261.15000000000055, -106.93000000000005, -167.40999999999963, -7.119999999999997, -218.8900000000002, -84.90000000000002, -24.289999999999424, -103.48999999999965, -118.97, -48.860000000000625, -52.10000000000005, -20.23999999999943, -23.279999999999447, -38.820000000000356, 3.889999999999961, -389.09000000000003, -128.27999999999963, 1.8900000000000028, -153.5699999999997, -39.489999999999895, -185.5, -27.319999999999922, -54.63000000000059, -127.2999999999989, -69.73999999999988, -160.97000000000003, -12.160000000000082, -171.96000000000004, -73.61000000000017, -9.450000000000042, -89.01999999999863, -51.51000000000043, -127.79000000000008, -81.21999999999994, -81.30999999999962, -53.8200000000002, -120.91999999999912, -134.20000000000041, -4.4500000000000535, -1.0600000000000631, -61.510000000000176, -2.190000000000069, -126.12999999999877, -37.98999999999997, -140.43000000000018, -37.65000000000031, -44.470000000000475, -160.34000000000108, -27.30999999999977, -27.289999999999473, -121.54999999999961, -18.64999999999951, 2.949999999999982, -115.359999999999, -76.4400000000001, -8.920000000000066, -74.75999999999978, -64.6699999999995, -27.309999999999736, -10.190000000000081, -31.419999999999952, -1.1000000000000356, -1.0700000000000587, -65.6899999999986, -87.85999999999895, 2.9599999999999818, -90.9299999999993, -50.530000000000335, -13.219999999999922, 0.8999999999999827, -93.05999999999914, -44.87000000000047, -89.86999999999931, -60.64000000000038, -61.640000000000434, 3.849999999999962, -61.68000000000039, -76.98999999999906], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-24.129999999999868, -44.23000000000035, -46.24000000000035, -44.22999999999972, -106.53999999999942, -40.210000000000036, -52.2700000000001, -80.41000000000003, -201.0099999999998, -273.37, -18.099999999999703, -34.180000000000234, -66.3399999999992, -98.49999999999925, -14.080000000000041, -2.020000000000042, -60.30999999999989, -34.180000000000085, -22.11999999999972, -82.41999999999958, -12.070000000000041, -20.109999999999705, -16.09000000000004, -8.050000000000042, 2.0000000000000013, -42.22000000000006, 2.0000000000000013, -116.59, -96.4899999999997, -14.080000000000041, -8.050000000000042, -18.099999999999827, -18.09999999999996, -22.119999999999994, -188.95000000000033, -6.040000000000042, -60.310000000000315, -34.180000000000085, -263.28, 2.0000000000000013, -132.6699999999998, -118.60000000000002, -301.50999999999993, -28.14999999999978, -146.74000000000038, -281.4099999999997, -114.58000000000015, -68.3500000000001, -122.61999999999978, -156.79000000000022, -14.080000000000041, -6.039999999999998, -289.4500000000001, -86.43999999999978, -12.070000000000041, -164.82999999999996, -38.20000000000036, -16.089999999999705, -20.109999999999705, -275.38, -80.41, -110.55999999999977, -36.19000000000036, -132.67000000000078, -78.39999999999976, -138.70000000000022, -6.040000000000042, -38.20000000000036, -54.28000000000034, 2.0000000000000013, -170.82000000000082, 2.0000000000000013, -20.109999999999705, 2.0000000000000013, -319.59999999999997, -297.49, -146.74000000000007, -106.54000000000023, -20.109999999999705, 2.0000000000000013, -303.4799999999998, -16.09000000000004, -96.48999999999933, 2.0000000000000013, -126.60000000000001, -178.90000000000003, -62.31999999999995, 2.0000000000000013, -4.030000000000042, -118.5999999999993, -203.0200000000009, -54.27999999999993, -94.47999999999993, -50.26000000000012, -76.38999999999993, -315.58000000000015, -8.050000000000042, -20.109999999999744, -231.16000000000017, -158.80000000000018, -271.36, -48.250000000000234, 2.0000000000000013, -88.44999999999963, -48.25000000000034, -152.770000000001, -58.30000000000021, -40.210000000000186, -60.31000000000016, -295.4799999999999, -34.18000000000036, -207.04000000000013, -92.46999999999964, -166.8400000000001, -4.030000000000042, -156.79000000000036, -100.50999999999941, -80.40999999999937, -64.32999999999973, -172.8700000000002, -38.20000000000032, -249.25, -10.060000000000041, 2.0000000000000013, 2.0000000000000013, -301.51000000000033, -24.129999999999754, -10.060000000000041, -94.47999999999935, -128.65000000000072, 2.0000000000000013, -196.99, -30.159999999999716, -253.2700000000005, 2.0000000000000013, -128.64999999999952, -54.2800000000002, -36.19000000000022, -166.84000000000052, -98.4999999999995, -6.040000000000042, -52.27000000000001, -30.159999999999748, -24.129999999999725, -96.4899999999997, -211.06000000000006, -118.59999999999928, -8.050000000000042, -8.050000000000042, 2.0000000000000013, -219.10000000000065, -50.260000000000346, -245.23000000000002, -40.21000000000016, -166.84000000000012, -14.080000000000041, -58.30000000000028, -90.45999999999985, -112.56999999999933, -18.09999999999991, -10.060000000000041, -48.25000000000007, -0.009999999999998581, -34.18000000000013, -16.0899999999997, -64.32999999999973, 2.0000000000000013, -18.0999999999998, -12.070000000000041, 2.0000000000000013, -54.28000000000034, -80.40999999999919, -44.23000000000011, -124.62999999999943, -6.040000000000042, 2.0000000000000013, -132.6700000000006, -50.260000000000275, -64.32999999999983, -38.20000000000028, -32.170000000000364, -8.050000000000042, 2.0000000000000013, -18.099999999999703, -98.4999999999997, -110.55999999999955, -108.54999999999944, -62.32000000000031, -106.53999999999965, -64.32999999999964, -86.43999999999946, -38.200000000000244, -44.23000000000029, -80.4099999999997, -16.089999999999797, -10.060000000000041, -0.00999999999999836, -132.67000000000075, -170.86000000000064, -24.129999999999708], "policy_predator_policy_reward": [10.0, 26.0, 34.0, 36.0, 49.0, 23.0, 55.0, 15.0, 120.0, 75.0, 18.0, 20.0, 47.0, 40.0, 8.0, 2.0, 8.0, 24.0, 35.0, 29.0, 11.0, 7.0, 14.0, 12.0, 9.0, 13.0, 45.0, 14.0, 54.0, 43.0, 5.0, 10.0, 3.0, 12.0, 84.0, 22.0, 24.0, 24.0, 137.0, 0.0, 1.0, 68.0, 142.0, 158.0, 108.0, 59.0, 45.0, 31.0, 83.0, 29.0, 7.0, 6.0, 126.0, 31.0, 90.0, 2.0, 20.0, 10.0, 145.0, 47.0, 16.0, 56.0, 64.0, 56.0, 84.0, 81.0, 20.0, 4.0, 1.0, 28.0, 62.0, 68.0, 11.0, 11.0, 76.0, 152.0, 89.0, 36.0, 11.0, 9.0, 104.0, 62.0, 23.0, 32.0, 115.0, 5.0, 32.0, 1.0, 25.0, 43.0, 28.0, 102.0, 21.0, 54.0, 96.0, 135.0, 3.0, 13.0, 117.0, 101.0, 131.0, 115.0, 40.0, 37.0, 37.0, 75.0, 26.0, 21.0, 116.0, 112.0, 72.0, 88.0, 98.0, 80.0, 69.0, 38.0, 33.0, 27.0, 48.0, 55.0, 140.0, 143.0, 6.0, 1.0, 151.0, 87.0, 18.0, 14.0, 31.0, 66.0, 62.0, 95.0, 127.0, 16.0, 55.0, 34.0, 16.0, 30.0, 83.0, 22.0, 13.0, 18.0, 2.0, 25.0, 92.0, 94.0, 48.0, 60.0, 4.0, 5.0, 118.0, 36.0, 101.0, 108.0, 90.0, 82.0, 46.0, 28.0, 52.0, 14.0, 13.0, 18.0, 13.0, 11.0, 23.0, 26.0, 9.0, 6.0, 6.0, 3.0, 49.0, 20.0, 59.0, 22.0, 3.0, 4.0, 1.0, 91.0, 39.0, 13.0, 10.0, 17.0, 10.0, 7.0, 65.0, 51.0, 49.0, 77.0, 20.0, 61.0, 43.0, 21.0, 47.0, 16.0, 15.0, 15.0, 49.0, 22.0, 35.0, 83.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 6.178245291078558, "mean_inference_ms": 20.919542682215965, "mean_action_processing_ms": 0.2631141209064179, "mean_env_wait_ms": 3.5414553929865322, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006181478500366211, "StateBufferConnector_ms": 0.0077512264251708984, "ViewRequirementAgentConnector_ms": 0.1599133014678955}, "num_episodes": 22, "episode_return_max": 3.889999999999961, "episode_return_min": -389.09000000000003, "episode_return_mean": -69.00759999999987, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1216000, "num_agent_steps_trained": 1216000, "num_env_steps_sampled": 304000, "num_env_steps_trained": 304000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 339.1863949695365, "num_env_steps_trained_throughput_per_sec": 339.1863949695365, "timesteps_total": 304000, "num_env_steps_sampled_lifetime": 304000, "num_agent_steps_sampled_lifetime": 1216000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1216000, "timers": {"training_iteration_time_ms": 199651.724, "restore_workers_time_ms": 0.016, "training_step_time_ms": 199651.674, "sample_time_ms": 1771.292, "learn_time_ms": 197861.256, "learn_throughput": 20.216, "synch_weights_time_ms": 15.901}, "counters": {"num_env_steps_sampled": 304000, "num_env_steps_trained": 304000, "num_agent_steps_sampled": 1216000, "num_agent_steps_trained": 1216000}, "done": false, "training_iteration": 76, "trial_id": "8e499_00000", "date": "2024-08-15_03-43-44", "timestamp": 1723673624, "time_this_iter_s": 11.830142259597778, "time_total_s": 5962.747925519943, "pid": 33199, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x1580f8430>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 5962.747925519943, "iterations_since_restore": 76, "perf": {"cpu_util_percent": 54.10588235294117, "ram_util_percent": 83.75882352941176}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.417044589128444, "cur_kl_coeff": 0.014062500000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.753815418639511, "policy_loss": -0.0026987909477342057, "vf_loss": 2.7564585359008222, "vf_explained_var": 0.2559102361479764, "kl": 0.003958551353001481, "entropy": 0.35867069738882557, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 144585.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2214598749365126, "cur_kl_coeff": 0.084375, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.6728956052865933, "policy_loss": -0.007097382901640481, "vf_loss": 2.67953504027513, "vf_explained_var": 0.03619712420872279, "kl": 0.005427548880673993, "entropy": 0.8414498017578529, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 144585.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 308000, "num_env_steps_trained": 308000, "num_agent_steps_sampled": 1232000, "num_agent_steps_trained": 1232000}, "env_runners": {"episode_reward_max": 3.8999999999999613, "episode_reward_min": -389.09000000000003, "episode_reward_mean": -64.6111999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -319.59999999999997, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 2.0000000000000013, "predator_policy": 158.0}, "policy_reward_mean": {"prey_policy": -76.67059999999998, "predator_policy": 44.365}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-46.4899999999997, -124.27999999999972, -182.26999999999958, -29.66000000000013, -261.15000000000055, -106.93000000000005, -167.40999999999963, -7.119999999999997, -218.8900000000002, -84.90000000000002, -24.289999999999424, -103.48999999999965, -118.97, -48.860000000000625, -52.10000000000005, -20.23999999999943, -23.279999999999447, -38.820000000000356, 3.889999999999961, -389.09000000000003, -128.27999999999963, 1.8900000000000028, -153.5699999999997, -39.489999999999895, -185.5, -27.319999999999922, -54.63000000000059, -127.2999999999989, -69.73999999999988, -160.97000000000003, -12.160000000000082, -171.96000000000004, -73.61000000000017, -9.450000000000042, -89.01999999999863, -51.51000000000043, -127.79000000000008, -81.21999999999994, -81.30999999999962, -53.8200000000002, -120.91999999999912, -134.20000000000041, -4.4500000000000535, -1.0600000000000631, -61.510000000000176, -2.190000000000069, -126.12999999999877, -37.98999999999997, -140.43000000000018, -37.65000000000031, -44.470000000000475, -160.34000000000108, -27.30999999999977, -27.289999999999473, -121.54999999999961, -18.64999999999951, 2.949999999999982, -115.359999999999, -76.4400000000001, -8.920000000000066, -74.75999999999978, -64.6699999999995, -27.309999999999736, -10.190000000000081, -31.419999999999952, -1.1000000000000356, -1.0700000000000587, -65.6899999999986, -87.85999999999895, 2.9599999999999818, -90.9299999999993, -50.530000000000335, -13.219999999999922, 0.8999999999999827, -93.05999999999914, -44.87000000000047, -89.86999999999931, -60.64000000000038, -61.640000000000434, 3.849999999999962, -61.68000000000039, -76.98999999999906, 0.8999999999999836, -18.249999999999943, -3.160000000000082, -11.170000000000082, -25.289999999999907, -50.54000000000045, -31.570000000000196, -6.1000000000000565, -93.79999999999954, -42.58000000000062, -26.45999999999971, 3.8999999999999613, -54.580000000000545, -10.23000000000008, -15.459999999999825, -34.38000000000035, -22.319999999999943, -15.219999999999795], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-60.310000000000315, -34.180000000000085, -263.28, 2.0000000000000013, -132.6699999999998, -118.60000000000002, -301.50999999999993, -28.14999999999978, -146.74000000000038, -281.4099999999997, -114.58000000000015, -68.3500000000001, -122.61999999999978, -156.79000000000022, -14.080000000000041, -6.039999999999998, -289.4500000000001, -86.43999999999978, -12.070000000000041, -164.82999999999996, -38.20000000000036, -16.089999999999705, -20.109999999999705, -275.38, -80.41, -110.55999999999977, -36.19000000000036, -132.67000000000078, -78.39999999999976, -138.70000000000022, -6.040000000000042, -38.20000000000036, -54.28000000000034, 2.0000000000000013, -170.82000000000082, 2.0000000000000013, -20.109999999999705, 2.0000000000000013, -319.59999999999997, -297.49, -146.74000000000007, -106.54000000000023, -20.109999999999705, 2.0000000000000013, -303.4799999999998, -16.09000000000004, -96.48999999999933, 2.0000000000000013, -126.60000000000001, -178.90000000000003, -62.31999999999995, 2.0000000000000013, -4.030000000000042, -118.5999999999993, -203.0200000000009, -54.27999999999993, -94.47999999999993, -50.26000000000012, -76.38999999999993, -315.58000000000015, -8.050000000000042, -20.109999999999744, -231.16000000000017, -158.80000000000018, -271.36, -48.250000000000234, 2.0000000000000013, -88.44999999999963, -48.25000000000034, -152.770000000001, -58.30000000000021, -40.210000000000186, -60.31000000000016, -295.4799999999999, -34.18000000000036, -207.04000000000013, -92.46999999999964, -166.8400000000001, -4.030000000000042, -156.79000000000036, -100.50999999999941, -80.40999999999937, -64.32999999999973, -172.8700000000002, -38.20000000000032, -249.25, -10.060000000000041, 2.0000000000000013, 2.0000000000000013, -301.51000000000033, -24.129999999999754, -10.060000000000041, -94.47999999999935, -128.65000000000072, 2.0000000000000013, -196.99, -30.159999999999716, -253.2700000000005, 2.0000000000000013, -128.64999999999952, -54.2800000000002, -36.19000000000022, -166.84000000000052, -98.4999999999995, -6.040000000000042, -52.27000000000001, -30.159999999999748, -24.129999999999725, -96.4899999999997, -211.06000000000006, -118.59999999999928, -8.050000000000042, -8.050000000000042, 2.0000000000000013, -219.10000000000065, -50.260000000000346, -245.23000000000002, -40.21000000000016, -166.84000000000012, -14.080000000000041, -58.30000000000028, -90.45999999999985, -112.56999999999933, -18.09999999999991, -10.060000000000041, -48.25000000000007, -0.009999999999998581, -34.18000000000013, -16.0899999999997, -64.32999999999973, 2.0000000000000013, -18.0999999999998, -12.070000000000041, 2.0000000000000013, -54.28000000000034, -80.40999999999919, -44.23000000000011, -124.62999999999943, -6.040000000000042, 2.0000000000000013, -132.6700000000006, -50.260000000000275, -64.32999999999983, -38.20000000000028, -32.170000000000364, -8.050000000000042, 2.0000000000000013, -18.099999999999703, -98.4999999999997, -110.55999999999955, -108.54999999999944, -62.32000000000031, -106.53999999999965, -64.32999999999964, -86.43999999999946, -38.200000000000244, -44.23000000000029, -80.4099999999997, -16.089999999999797, -10.060000000000041, -0.00999999999999836, -132.67000000000075, -170.86000000000064, -24.129999999999708, 2.0000000000000013, -18.099999999999707, -8.050000000000042, -38.19999999999999, -30.159999999999787, 2.0000000000000013, 2.0000000000000013, -32.17000000000031, -10.060000000000041, -44.230000000000096, -14.080000000000027, -90.4599999999994, -88.44999999999925, -22.119999999999816, -18.099999999999795, 2.0000000000000013, -92.46999999999984, -64.3299999999998, -84.4299999999992, -28.14999999999976, -32.170000000000236, -56.2900000000002, -2.020000000000042, -14.08000000000004, -38.200000000000266, -74.37999999999943, -36.1900000000003, -6.040000000000042, -70.35999999999962, -18.099999999999778, -38.200000000000266, -34.18000000000018, -14.080000000000041, -46.23999999999993, -12.070000000000025, -28.149999999999828], "policy_predator_policy_reward": [24.0, 24.0, 137.0, 0.0, 1.0, 68.0, 142.0, 158.0, 108.0, 59.0, 45.0, 31.0, 83.0, 29.0, 7.0, 6.0, 126.0, 31.0, 90.0, 2.0, 20.0, 10.0, 145.0, 47.0, 16.0, 56.0, 64.0, 56.0, 84.0, 81.0, 20.0, 4.0, 1.0, 28.0, 62.0, 68.0, 11.0, 11.0, 76.0, 152.0, 89.0, 36.0, 11.0, 9.0, 104.0, 62.0, 23.0, 32.0, 115.0, 5.0, 32.0, 1.0, 25.0, 43.0, 28.0, 102.0, 21.0, 54.0, 96.0, 135.0, 3.0, 13.0, 117.0, 101.0, 131.0, 115.0, 40.0, 37.0, 37.0, 75.0, 26.0, 21.0, 116.0, 112.0, 72.0, 88.0, 98.0, 80.0, 69.0, 38.0, 33.0, 27.0, 48.0, 55.0, 140.0, 143.0, 6.0, 1.0, 151.0, 87.0, 18.0, 14.0, 31.0, 66.0, 62.0, 95.0, 127.0, 16.0, 55.0, 34.0, 16.0, 30.0, 83.0, 22.0, 13.0, 18.0, 2.0, 25.0, 92.0, 94.0, 48.0, 60.0, 4.0, 5.0, 118.0, 36.0, 101.0, 108.0, 90.0, 82.0, 46.0, 28.0, 52.0, 14.0, 13.0, 18.0, 13.0, 11.0, 23.0, 26.0, 9.0, 6.0, 6.0, 3.0, 49.0, 20.0, 59.0, 22.0, 3.0, 4.0, 1.0, 91.0, 39.0, 13.0, 10.0, 17.0, 10.0, 7.0, 65.0, 51.0, 49.0, 77.0, 20.0, 61.0, 43.0, 21.0, 47.0, 16.0, 15.0, 15.0, 49.0, 22.0, 35.0, 83.0, 10.0, 7.0, 10.0, 18.0, 16.0, 9.0, 2.0, 17.0, 1.0, 28.0, 30.0, 24.0, 43.0, 36.0, 1.0, 9.0, 16.0, 47.0, 47.0, 23.0, 33.0, 29.0, 10.0, 10.0, 28.0, 30.0, 18.0, 14.0, 45.0, 28.0, 22.0, 16.0, 25.0, 13.0, 15.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 6.9639861400851295, "mean_inference_ms": 20.136099809343033, "mean_action_processing_ms": 0.26460237442984896, "mean_env_wait_ms": 3.2199635337908132, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006174921989440918, "StateBufferConnector_ms": 0.011084318161010742, "ViewRequirementAgentConnector_ms": 0.1780639886856079}, "num_episodes": 18, "episode_return_max": 3.8999999999999613, "episode_return_min": -389.09000000000003, "episode_return_mean": -64.6111999999999, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1232000, "num_agent_steps_trained": 1232000, "num_env_steps_sampled": 308000, "num_env_steps_trained": 308000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 347.00516494725827, "num_env_steps_trained_throughput_per_sec": 347.00516494725827, "timesteps_total": 308000, "num_env_steps_sampled_lifetime": 308000, "num_agent_steps_sampled_lifetime": 1232000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1232000, "timers": {"training_iteration_time_ms": 199614.779, "restore_workers_time_ms": 0.014, "training_step_time_ms": 199614.732, "sample_time_ms": 1786.204, "learn_time_ms": 197810.224, "learn_throughput": 20.221, "synch_weights_time_ms": 15.302}, "counters": {"num_env_steps_sampled": 308000, "num_env_steps_trained": 308000, "num_agent_steps_sampled": 1232000, "num_agent_steps_trained": 1232000}, "done": false, "training_iteration": 77, "trial_id": "8e499_00000", "date": "2024-08-15_03-43-55", "timestamp": 1723673635, "time_this_iter_s": 11.572678089141846, "time_total_s": 5974.320603609085, "pid": 33199, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x158199c10>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 5974.320603609085, "iterations_since_restore": 77, "perf": {"cpu_util_percent": 39.04117647058824, "ram_util_percent": 83.41176470588235}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.0583193844272976, "cur_kl_coeff": 0.007031250000000002, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.063351370922472, "policy_loss": -0.00390713109964968, "vf_loss": 4.067221197627839, "vf_explained_var": 0.14741386102620888, "kl": 0.005306795781579444, "entropy": 0.40629763253151424, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 146475.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5959984613158715, "cur_kl_coeff": 0.084375, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.0195989768971843, "policy_loss": -0.0107025868223645, "vf_loss": 3.029400411610881, "vf_explained_var": 0.05917788188924234, "kl": 0.010680320348922225, "entropy": 0.793725410813377, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 146475.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 312000, "num_env_steps_trained": 312000, "num_agent_steps_sampled": 1248000, "num_agent_steps_trained": 1248000}, "env_runners": {"episode_reward_max": 3.8999999999999613, "episode_reward_min": -185.5, "episode_reward_mean": -48.51549999999991, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -315.58000000000015, "predator_policy": 1.0}, "policy_reward_max": {"prey_policy": 2.0000000000000013, "predator_policy": 151.0}, "policy_reward_mean": {"prey_policy": -61.90774999999999, "predator_policy": 37.65}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-39.489999999999895, -185.5, -27.319999999999922, -54.63000000000059, -127.2999999999989, -69.73999999999988, -160.97000000000003, -12.160000000000082, -171.96000000000004, -73.61000000000017, -9.450000000000042, -89.01999999999863, -51.51000000000043, -127.79000000000008, -81.21999999999994, -81.30999999999962, -53.8200000000002, -120.91999999999912, -134.20000000000041, -4.4500000000000535, -1.0600000000000631, -61.510000000000176, -2.190000000000069, -126.12999999999877, -37.98999999999997, -140.43000000000018, -37.65000000000031, -44.470000000000475, -160.34000000000108, -27.30999999999977, -27.289999999999473, -121.54999999999961, -18.64999999999951, 2.949999999999982, -115.359999999999, -76.4400000000001, -8.920000000000066, -74.75999999999978, -64.6699999999995, -27.309999999999736, -10.190000000000081, -31.419999999999952, -1.1000000000000356, -1.0700000000000587, -65.6899999999986, -87.85999999999895, 2.9599999999999818, -90.9299999999993, -50.530000000000335, -13.219999999999922, 0.8999999999999827, -93.05999999999914, -44.87000000000047, -89.86999999999931, -60.64000000000038, -61.640000000000434, 3.849999999999962, -61.68000000000039, -76.98999999999906, 0.8999999999999836, -18.249999999999943, -3.160000000000082, -11.170000000000082, -25.289999999999907, -50.54000000000045, -31.570000000000196, -6.1000000000000565, -93.79999999999954, -42.58000000000062, -26.45999999999971, 3.8999999999999613, -54.580000000000545, -10.23000000000008, -15.459999999999825, -34.38000000000035, -22.319999999999943, -15.219999999999795, -14.33000000000009, -33.36999999999978, -39.36000000000037, -31.810000000000276, -74.81999999999965, -17.259999999999668, 1.9200000000000028, -13.380000000000098, -33.370000000000495, -2.180000000000078, -19.229999999999624, -14.179999999999906, -3.2200000000000566, -52.560000000000315, -0.22000000000003572, -10.440000000000063, -30.299999999999883, -145.41000000000105, -20.379999999999594, -17.259999999999586, -86.9199999999993, -34.399999999999885, -22.259999999999735], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-96.48999999999933, 2.0000000000000013, -126.60000000000001, -178.90000000000003, -62.31999999999995, 2.0000000000000013, -4.030000000000042, -118.5999999999993, -203.0200000000009, -54.27999999999993, -94.47999999999993, -50.26000000000012, -76.38999999999993, -315.58000000000015, -8.050000000000042, -20.109999999999744, -231.16000000000017, -158.80000000000018, -271.36, -48.250000000000234, 2.0000000000000013, -88.44999999999963, -48.25000000000034, -152.770000000001, -58.30000000000021, -40.210000000000186, -60.31000000000016, -295.4799999999999, -34.18000000000036, -207.04000000000013, -92.46999999999964, -166.8400000000001, -4.030000000000042, -156.79000000000036, -100.50999999999941, -80.40999999999937, -64.32999999999973, -172.8700000000002, -38.20000000000032, -249.25, -10.060000000000041, 2.0000000000000013, 2.0000000000000013, -301.51000000000033, -24.129999999999754, -10.060000000000041, -94.47999999999935, -128.65000000000072, 2.0000000000000013, -196.99, -30.159999999999716, -253.2700000000005, 2.0000000000000013, -128.64999999999952, -54.2800000000002, -36.19000000000022, -166.84000000000052, -98.4999999999995, -6.040000000000042, -52.27000000000001, -30.159999999999748, -24.129999999999725, -96.4899999999997, -211.06000000000006, -118.59999999999928, -8.050000000000042, -8.050000000000042, 2.0000000000000013, -219.10000000000065, -50.260000000000346, -245.23000000000002, -40.21000000000016, -166.84000000000012, -14.080000000000041, -58.30000000000028, -90.45999999999985, -112.56999999999933, -18.09999999999991, -10.060000000000041, -48.25000000000007, -0.009999999999998581, -34.18000000000013, -16.0899999999997, -64.32999999999973, 2.0000000000000013, -18.0999999999998, -12.070000000000041, 2.0000000000000013, -54.28000000000034, -80.40999999999919, -44.23000000000011, -124.62999999999943, -6.040000000000042, 2.0000000000000013, -132.6700000000006, -50.260000000000275, -64.32999999999983, -38.20000000000028, -32.170000000000364, -8.050000000000042, 2.0000000000000013, -18.099999999999703, -98.4999999999997, -110.55999999999955, -108.54999999999944, -62.32000000000031, -106.53999999999965, -64.32999999999964, -86.43999999999946, -38.200000000000244, -44.23000000000029, -80.4099999999997, -16.089999999999797, -10.060000000000041, -0.00999999999999836, -132.67000000000075, -170.86000000000064, -24.129999999999708, 2.0000000000000013, -18.099999999999707, -8.050000000000042, -38.19999999999999, -30.159999999999787, 2.0000000000000013, 2.0000000000000013, -32.17000000000031, -10.060000000000041, -44.230000000000096, -14.080000000000027, -90.4599999999994, -88.44999999999925, -22.119999999999816, -18.099999999999795, 2.0000000000000013, -92.46999999999984, -64.3299999999998, -84.4299999999992, -28.14999999999976, -32.170000000000236, -56.2900000000002, -2.020000000000042, -14.08000000000004, -38.200000000000266, -74.37999999999943, -36.1900000000003, -6.040000000000042, -70.35999999999962, -18.099999999999778, -38.200000000000266, -34.18000000000018, -14.080000000000041, -46.23999999999993, -12.070000000000025, -28.149999999999828, -10.060000000000041, -52.26999999999993, -62.32000000000023, -8.050000000000042, -54.28000000000021, -14.080000000000041, -136.69000000000062, -22.119999999999752, -96.48999999999978, -64.32999999999946, -42.22000000000022, -6.040000000000042, -0.009999999999998581, -12.070000000000041, -44.23000000000035, -28.149999999999793, -16.089999999999705, -54.28000000000026, 2.0000000000000013, -34.18000000000036, 2.0000000000000013, -44.230000000000274, 2.0000000000000013, -34.18000000000028, 2.0000000000000013, -42.219999999999935, -58.30000000000034, -50.26000000000023, -18.099999999999728, -22.119999999999706, -40.209999999999944, -44.230000000000274, -28.149999999999824, -28.149999999999814, -78.3999999999996, -201.0100000000005, -36.19000000000025, -36.19000000000029, -48.250000000000256, -0.00999999999999836, -162.82000000000045, -18.099999999999703, -36.19000000000007, -40.210000000000356, -50.260000000000176, 2.0000000000000013], "policy_predator_policy_reward": [23.0, 32.0, 115.0, 5.0, 32.0, 1.0, 25.0, 43.0, 28.0, 102.0, 21.0, 54.0, 96.0, 135.0, 3.0, 13.0, 117.0, 101.0, 131.0, 115.0, 40.0, 37.0, 37.0, 75.0, 26.0, 21.0, 116.0, 112.0, 72.0, 88.0, 98.0, 80.0, 69.0, 38.0, 33.0, 27.0, 48.0, 55.0, 140.0, 143.0, 6.0, 1.0, 151.0, 87.0, 18.0, 14.0, 31.0, 66.0, 62.0, 95.0, 127.0, 16.0, 55.0, 34.0, 16.0, 30.0, 83.0, 22.0, 13.0, 18.0, 2.0, 25.0, 92.0, 94.0, 48.0, 60.0, 4.0, 5.0, 118.0, 36.0, 101.0, 108.0, 90.0, 82.0, 46.0, 28.0, 52.0, 14.0, 13.0, 18.0, 13.0, 11.0, 23.0, 26.0, 9.0, 6.0, 6.0, 3.0, 49.0, 20.0, 59.0, 22.0, 3.0, 4.0, 1.0, 91.0, 39.0, 13.0, 10.0, 17.0, 10.0, 7.0, 65.0, 51.0, 49.0, 77.0, 20.0, 61.0, 43.0, 21.0, 47.0, 16.0, 15.0, 15.0, 49.0, 22.0, 35.0, 83.0, 10.0, 7.0, 10.0, 18.0, 16.0, 9.0, 2.0, 17.0, 1.0, 28.0, 30.0, 24.0, 43.0, 36.0, 1.0, 9.0, 16.0, 47.0, 47.0, 23.0, 33.0, 29.0, 10.0, 10.0, 28.0, 30.0, 18.0, 14.0, 45.0, 28.0, 22.0, 16.0, 25.0, 13.0, 15.0, 10.0, 21.0, 27.0, 12.0, 25.0, 23.0, 6.0, 49.0, 78.0, 55.0, 31.0, 14.0, 17.0, 7.0, 7.0, 34.0, 25.0, 31.0, 6.0, 12.0, 18.0, 6.0, 17.0, 10.0, 8.0, 19.0, 18.0, 30.0, 26.0, 19.0, 21.0, 36.0, 38.0, 15.0, 11.0, 95.0, 39.0, 23.0, 29.0, 20.0, 11.0, 35.0, 59.0, 33.0, 9.0, 9.0, 17.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 6.874269984974019, "mean_inference_ms": 19.85845671032401, "mean_action_processing_ms": 0.2659715870864824, "mean_env_wait_ms": 3.1850332068827676, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006156206130981445, "StateBufferConnector_ms": 0.011135578155517578, "ViewRequirementAgentConnector_ms": 0.18088829517364502}, "num_episodes": 23, "episode_return_max": 3.8999999999999613, "episode_return_min": -185.5, "episode_return_mean": -48.51549999999991, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1248000, "num_agent_steps_trained": 1248000, "num_env_steps_sampled": 312000, "num_env_steps_trained": 312000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 4.205936633384316, "num_env_steps_trained_throughput_per_sec": 4.205936633384316, "timesteps_total": 312000, "num_env_steps_sampled_lifetime": 312000, "num_agent_steps_sampled_lifetime": 1248000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1248000, "timers": {"training_iteration_time_ms": 293603.25, "restore_workers_time_ms": 0.014, "training_step_time_ms": 293603.207, "sample_time_ms": 1765.556, "learn_time_ms": 291818.214, "learn_throughput": 13.707, "synch_weights_time_ms": 16.285}, "counters": {"num_env_steps_sampled": 312000, "num_env_steps_trained": 312000, "num_agent_steps_sampled": 1248000, "num_agent_steps_trained": 1248000}, "done": false, "training_iteration": 78, "trial_id": "8e499_00000", "date": "2024-08-15_03-59-46", "timestamp": 1723674586, "time_this_iter_s": 951.1036748886108, "time_total_s": 6925.424278497696, "pid": 33199, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x1580f8c10>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 6925.424278497696, "iterations_since_restore": 78, "perf": {"cpu_util_percent": 63.11666666666666, "ram_util_percent": 80.95}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.91700206758484, "cur_kl_coeff": 0.007031250000000002, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.8322737170274928, "policy_loss": -0.005154047303872488, "vf_loss": 3.8373899319815257, "vf_explained_var": 0.23177648101534162, "kl": 0.0053810221764870126, "entropy": 0.4646200659413817, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 148365.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3798408071200052, "cur_kl_coeff": 0.084375, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.553922729454343, "policy_loss": -0.006307686779096171, "vf_loss": 2.5596290284994416, "vf_explained_var": 0.06874291439535757, "kl": 0.007127580463532576, "entropy": 0.5963174053916225, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 148365.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 316000, "num_env_steps_trained": 316000, "num_agent_steps_sampled": 1264000, "num_agent_steps_trained": 1264000}, "env_runners": {"episode_reward_max": 3.8999999999999613, "episode_reward_min": -160.34000000000108, "episode_reward_mean": -38.12449999999996, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -301.51000000000033, "predator_policy": 1.0}, "policy_reward_max": {"prey_policy": 2.0000000000000013, "predator_policy": 151.0}, "policy_reward_mean": {"prey_policy": -49.70724999999999, "predator_policy": 30.645}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-134.20000000000041, -4.4500000000000535, -1.0600000000000631, -61.510000000000176, -2.190000000000069, -126.12999999999877, -37.98999999999997, -140.43000000000018, -37.65000000000031, -44.470000000000475, -160.34000000000108, -27.30999999999977, -27.289999999999473, -121.54999999999961, -18.64999999999951, 2.949999999999982, -115.359999999999, -76.4400000000001, -8.920000000000066, -74.75999999999978, -64.6699999999995, -27.309999999999736, -10.190000000000081, -31.419999999999952, -1.1000000000000356, -1.0700000000000587, -65.6899999999986, -87.85999999999895, 2.9599999999999818, -90.9299999999993, -50.530000000000335, -13.219999999999922, 0.8999999999999827, -93.05999999999914, -44.87000000000047, -89.86999999999931, -60.64000000000038, -61.640000000000434, 3.849999999999962, -61.68000000000039, -76.98999999999906, 0.8999999999999836, -18.249999999999943, -3.160000000000082, -11.170000000000082, -25.289999999999907, -50.54000000000045, -31.570000000000196, -6.1000000000000565, -93.79999999999954, -42.58000000000062, -26.45999999999971, 3.8999999999999613, -54.580000000000545, -10.23000000000008, -15.459999999999825, -34.38000000000035, -22.319999999999943, -15.219999999999795, -14.33000000000009, -33.36999999999978, -39.36000000000037, -31.810000000000276, -74.81999999999965, -17.259999999999668, 1.9200000000000028, -13.380000000000098, -33.370000000000495, -2.180000000000078, -19.229999999999624, -14.179999999999906, -3.2200000000000566, -52.560000000000315, -0.22000000000003572, -10.440000000000063, -30.299999999999883, -145.41000000000105, -20.379999999999594, -17.259999999999586, -86.9199999999993, -34.399999999999885, -22.259999999999735, -15.24000000000008, -51.5500000000003, -27.21999999999941, -3.2000000000000703, -34.57000000000011, -20.23999999999943, -39.39000000000038, -9.210000000000079, -46.750000000000284, -51.55000000000065, -9.250000000000076, -3.0900000000000736, -25.28999999999967, -34.380000000000464, -25.499999999999805, -63.66999999999942, -40.44999999999996, 1.9300000000000028], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-64.32999999999973, -172.8700000000002, -38.20000000000032, -249.25, -10.060000000000041, 2.0000000000000013, 2.0000000000000013, -301.51000000000033, -24.129999999999754, -10.060000000000041, -94.47999999999935, -128.65000000000072, 2.0000000000000013, -196.99, -30.159999999999716, -253.2700000000005, 2.0000000000000013, -128.64999999999952, -54.2800000000002, -36.19000000000022, -166.84000000000052, -98.4999999999995, -6.040000000000042, -52.27000000000001, -30.159999999999748, -24.129999999999725, -96.4899999999997, -211.06000000000006, -118.59999999999928, -8.050000000000042, -8.050000000000042, 2.0000000000000013, -219.10000000000065, -50.260000000000346, -245.23000000000002, -40.21000000000016, -166.84000000000012, -14.080000000000041, -58.30000000000028, -90.45999999999985, -112.56999999999933, -18.09999999999991, -10.060000000000041, -48.25000000000007, -0.009999999999998581, -34.18000000000013, -16.0899999999997, -64.32999999999973, 2.0000000000000013, -18.0999999999998, -12.070000000000041, 2.0000000000000013, -54.28000000000034, -80.40999999999919, -44.23000000000011, -124.62999999999943, -6.040000000000042, 2.0000000000000013, -132.6700000000006, -50.260000000000275, -64.32999999999983, -38.20000000000028, -32.170000000000364, -8.050000000000042, 2.0000000000000013, -18.099999999999703, -98.4999999999997, -110.55999999999955, -108.54999999999944, -62.32000000000031, -106.53999999999965, -64.32999999999964, -86.43999999999946, -38.200000000000244, -44.23000000000029, -80.4099999999997, -16.089999999999797, -10.060000000000041, -0.00999999999999836, -132.67000000000075, -170.86000000000064, -24.129999999999708, 2.0000000000000013, -18.099999999999707, -8.050000000000042, -38.19999999999999, -30.159999999999787, 2.0000000000000013, 2.0000000000000013, -32.17000000000031, -10.060000000000041, -44.230000000000096, -14.080000000000027, -90.4599999999994, -88.44999999999925, -22.119999999999816, -18.099999999999795, 2.0000000000000013, -92.46999999999984, -64.3299999999998, -84.4299999999992, -28.14999999999976, -32.170000000000236, -56.2900000000002, -2.020000000000042, -14.08000000000004, -38.200000000000266, -74.37999999999943, -36.1900000000003, -6.040000000000042, -70.35999999999962, -18.099999999999778, -38.200000000000266, -34.18000000000018, -14.080000000000041, -46.23999999999993, -12.070000000000025, -28.149999999999828, -10.060000000000041, -52.26999999999993, -62.32000000000023, -8.050000000000042, -54.28000000000021, -14.080000000000041, -136.69000000000062, -22.119999999999752, -96.48999999999978, -64.32999999999946, -42.22000000000022, -6.040000000000042, -0.009999999999998581, -12.070000000000041, -44.23000000000035, -28.149999999999793, -16.089999999999705, -54.28000000000026, 2.0000000000000013, -34.18000000000036, 2.0000000000000013, -44.230000000000274, 2.0000000000000013, -34.18000000000028, 2.0000000000000013, -42.219999999999935, -58.30000000000034, -50.26000000000023, -18.099999999999728, -22.119999999999706, -40.209999999999944, -44.230000000000274, -28.149999999999824, -28.149999999999814, -78.3999999999996, -201.0100000000005, -36.19000000000025, -36.19000000000029, -48.250000000000256, -0.00999999999999836, -162.82000000000045, -18.099999999999703, -36.19000000000007, -40.210000000000356, -50.260000000000176, 2.0000000000000013, -26.13999999999994, -18.099999999999703, -8.050000000000038, -98.4999999999997, -20.109999999999705, -20.109999999999705, -8.050000000000034, -28.14999999999971, -18.099999999999703, -92.46999999999956, -12.070000000000041, -32.17000000000021, -28.1499999999998, -46.240000000000336, -24.129999999999754, -14.080000000000041, -8.050000000000042, -138.7000000000007, -42.22000000000029, -64.32999999999927, -48.25000000000031, 2.0000000000000013, -16.089999999999737, 2.0000000000000013, -30.15999999999986, -24.129999999999708, -28.149999999999764, -44.23000000000024, -72.36999999999951, -24.12999999999987, -70.3599999999996, -60.31000000000033, -42.22000000000014, -44.22999999999999, -12.070000000000041, 2.0000000000000013], "policy_predator_policy_reward": [48.0, 55.0, 140.0, 143.0, 6.0, 1.0, 151.0, 87.0, 18.0, 14.0, 31.0, 66.0, 62.0, 95.0, 127.0, 16.0, 55.0, 34.0, 16.0, 30.0, 83.0, 22.0, 13.0, 18.0, 2.0, 25.0, 92.0, 94.0, 48.0, 60.0, 4.0, 5.0, 118.0, 36.0, 101.0, 108.0, 90.0, 82.0, 46.0, 28.0, 52.0, 14.0, 13.0, 18.0, 13.0, 11.0, 23.0, 26.0, 9.0, 6.0, 6.0, 3.0, 49.0, 20.0, 59.0, 22.0, 3.0, 4.0, 1.0, 91.0, 39.0, 13.0, 10.0, 17.0, 10.0, 7.0, 65.0, 51.0, 49.0, 77.0, 20.0, 61.0, 43.0, 21.0, 47.0, 16.0, 15.0, 15.0, 49.0, 22.0, 35.0, 83.0, 10.0, 7.0, 10.0, 18.0, 16.0, 9.0, 2.0, 17.0, 1.0, 28.0, 30.0, 24.0, 43.0, 36.0, 1.0, 9.0, 16.0, 47.0, 47.0, 23.0, 33.0, 29.0, 10.0, 10.0, 28.0, 30.0, 18.0, 14.0, 45.0, 28.0, 22.0, 16.0, 25.0, 13.0, 15.0, 10.0, 21.0, 27.0, 12.0, 25.0, 23.0, 6.0, 49.0, 78.0, 55.0, 31.0, 14.0, 17.0, 7.0, 7.0, 34.0, 25.0, 31.0, 6.0, 12.0, 18.0, 6.0, 17.0, 10.0, 8.0, 19.0, 18.0, 30.0, 26.0, 19.0, 21.0, 36.0, 38.0, 15.0, 11.0, 95.0, 39.0, 23.0, 29.0, 20.0, 11.0, 35.0, 59.0, 33.0, 9.0, 9.0, 17.0, 10.0, 19.0, 2.0, 53.0, 2.0, 11.0, 14.0, 19.0, 40.0, 36.0, 14.0, 10.0, 17.0, 18.0, 19.0, 10.0, 59.0, 41.0, 13.0, 42.0, 18.0, 19.0, 5.0, 6.0, 6.0, 23.0, 37.0, 1.0, 36.0, 35.0, 42.0, 25.0, 34.0, 12.0, 7.0, 5.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 6.804748640949192, "mean_inference_ms": 19.660049430483664, "mean_action_processing_ms": 0.2676041523329255, "mean_env_wait_ms": 3.151150510944037, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0063495635986328125, "StateBufferConnector_ms": 0.011263370513916016, "ViewRequirementAgentConnector_ms": 0.19130122661590576}, "num_episodes": 18, "episode_return_max": 3.8999999999999613, "episode_return_min": -160.34000000000108, "episode_return_mean": -38.12449999999996, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1264000, "num_agent_steps_trained": 1264000, "num_env_steps_sampled": 316000, "num_env_steps_trained": 316000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 279.6125633405466, "num_env_steps_trained_throughput_per_sec": 279.6125633405466, "timesteps_total": 316000, "num_env_steps_sampled_lifetime": 316000, "num_agent_steps_sampled_lifetime": 1264000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1264000, "timers": {"training_iteration_time_ms": 200186.928, "restore_workers_time_ms": 0.014, "training_step_time_ms": 200186.885, "sample_time_ms": 1874.492, "learn_time_ms": 198292.013, "learn_throughput": 20.172, "synch_weights_time_ms": 17.285}, "counters": {"num_env_steps_sampled": 316000, "num_env_steps_trained": 316000, "num_agent_steps_sampled": 1264000, "num_agent_steps_trained": 1264000}, "done": false, "training_iteration": 79, "trial_id": "8e499_00000", "date": "2024-08-15_04-00-01", "timestamp": 1723674601, "time_this_iter_s": 14.334809064865112, "time_total_s": 6939.759087562561, "pid": 33199, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x1580dd9d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 6939.759087562561, "iterations_since_restore": 79, "perf": {"cpu_util_percent": 63.500000000000014, "ram_util_percent": 80.57}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.1846883112475988, "cur_kl_coeff": 0.007031250000000002, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.5208871293950965, "policy_loss": -0.004004082707294002, "vf_loss": 3.5248243928586365, "vf_explained_var": 0.08953875833087498, "kl": 0.009504117313595463, "entropy": 0.48712220351216656, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 150255.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5393865657546533, "cur_kl_coeff": 0.084375, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.3864445276361295, "policy_loss": -0.010486216936137271, "vf_loss": 2.3964352636740953, "vf_explained_var": 0.057123962123558004, "kl": 0.005872267234625782, "entropy": 0.5266402586900368, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 150255.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 320000, "num_env_steps_trained": 320000, "num_agent_steps_sampled": 1280000, "num_agent_steps_trained": 1280000}, "env_runners": {"episode_reward_max": 3.8999999999999613, "episode_reward_min": -145.41000000000105, "episode_reward_mean": -31.69199999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -201.0100000000005, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 2.0000000000000013, "predator_policy": 95.0}, "policy_reward_mean": {"prey_policy": -39.44599999999997, "predator_policy": 23.6}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-10.190000000000081, -31.419999999999952, -1.1000000000000356, -1.0700000000000587, -65.6899999999986, -87.85999999999895, 2.9599999999999818, -90.9299999999993, -50.530000000000335, -13.219999999999922, 0.8999999999999827, -93.05999999999914, -44.87000000000047, -89.86999999999931, -60.64000000000038, -61.640000000000434, 3.849999999999962, -61.68000000000039, -76.98999999999906, 0.8999999999999836, -18.249999999999943, -3.160000000000082, -11.170000000000082, -25.289999999999907, -50.54000000000045, -31.570000000000196, -6.1000000000000565, -93.79999999999954, -42.58000000000062, -26.45999999999971, 3.8999999999999613, -54.580000000000545, -10.23000000000008, -15.459999999999825, -34.38000000000035, -22.319999999999943, -15.219999999999795, -14.33000000000009, -33.36999999999978, -39.36000000000037, -31.810000000000276, -74.81999999999965, -17.259999999999668, 1.9200000000000028, -13.380000000000098, -33.370000000000495, -2.180000000000078, -19.229999999999624, -14.179999999999906, -3.2200000000000566, -52.560000000000315, -0.22000000000003572, -10.440000000000063, -30.299999999999883, -145.41000000000105, -20.379999999999594, -17.259999999999586, -86.9199999999993, -34.399999999999885, -22.259999999999735, -15.24000000000008, -51.5500000000003, -27.21999999999941, -3.2000000000000703, -34.57000000000011, -20.23999999999943, -39.39000000000038, -9.210000000000079, -46.750000000000284, -51.55000000000065, -9.250000000000076, -3.0900000000000736, -25.28999999999967, -34.380000000000464, -25.499999999999805, -63.66999999999942, -40.44999999999996, 1.9300000000000028, -6.120000000000081, -36.44000000000023, -48.520000000000444, -47.43000000000034, -12.310000000000084, -29.41999999999947, -39.430000000000426, -2.0900000000000833, -28.29999999999943, -7.220000000000081, -42.52000000000005, -60.67000000000066, -84.85999999999977, 2.9299999999999824, -50.56000000000026, -12.160000000000078, -24.379999999999516, -19.389999999999514, -55.58000000000063, 0.969999999999981, -54.63999999999973, -8.340000000000078], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-0.009999999999998581, -34.18000000000013, -16.0899999999997, -64.32999999999973, 2.0000000000000013, -18.0999999999998, -12.070000000000041, 2.0000000000000013, -54.28000000000034, -80.40999999999919, -44.23000000000011, -124.62999999999943, -6.040000000000042, 2.0000000000000013, -132.6700000000006, -50.260000000000275, -64.32999999999983, -38.20000000000028, -32.170000000000364, -8.050000000000042, 2.0000000000000013, -18.099999999999703, -98.4999999999997, -110.55999999999955, -108.54999999999944, -62.32000000000031, -106.53999999999965, -64.32999999999964, -86.43999999999946, -38.200000000000244, -44.23000000000029, -80.4099999999997, -16.089999999999797, -10.060000000000041, -0.00999999999999836, -132.67000000000075, -170.86000000000064, -24.129999999999708, 2.0000000000000013, -18.099999999999707, -8.050000000000042, -38.19999999999999, -30.159999999999787, 2.0000000000000013, 2.0000000000000013, -32.17000000000031, -10.060000000000041, -44.230000000000096, -14.080000000000027, -90.4599999999994, -88.44999999999925, -22.119999999999816, -18.099999999999795, 2.0000000000000013, -92.46999999999984, -64.3299999999998, -84.4299999999992, -28.14999999999976, -32.170000000000236, -56.2900000000002, -2.020000000000042, -14.08000000000004, -38.200000000000266, -74.37999999999943, -36.1900000000003, -6.040000000000042, -70.35999999999962, -18.099999999999778, -38.200000000000266, -34.18000000000018, -14.080000000000041, -46.23999999999993, -12.070000000000025, -28.149999999999828, -10.060000000000041, -52.26999999999993, -62.32000000000023, -8.050000000000042, -54.28000000000021, -14.080000000000041, -136.69000000000062, -22.119999999999752, -96.48999999999978, -64.32999999999946, -42.22000000000022, -6.040000000000042, -0.009999999999998581, -12.070000000000041, -44.23000000000035, -28.149999999999793, -16.089999999999705, -54.28000000000026, 2.0000000000000013, -34.18000000000036, 2.0000000000000013, -44.230000000000274, 2.0000000000000013, -34.18000000000028, 2.0000000000000013, -42.219999999999935, -58.30000000000034, -50.26000000000023, -18.099999999999728, -22.119999999999706, -40.209999999999944, -44.230000000000274, -28.149999999999824, -28.149999999999814, -78.3999999999996, -201.0100000000005, -36.19000000000025, -36.19000000000029, -48.250000000000256, -0.00999999999999836, -162.82000000000045, -18.099999999999703, -36.19000000000007, -40.210000000000356, -50.260000000000176, 2.0000000000000013, -26.13999999999994, -18.099999999999703, -8.050000000000038, -98.4999999999997, -20.109999999999705, -20.109999999999705, -8.050000000000034, -28.14999999999971, -18.099999999999703, -92.46999999999956, -12.070000000000041, -32.17000000000021, -28.1499999999998, -46.240000000000336, -24.129999999999754, -14.080000000000041, -8.050000000000042, -138.7000000000007, -42.22000000000029, -64.32999999999927, -48.25000000000031, 2.0000000000000013, -16.089999999999737, 2.0000000000000013, -30.15999999999986, -24.129999999999708, -28.149999999999764, -44.23000000000024, -72.36999999999951, -24.12999999999987, -70.3599999999996, -60.31000000000033, -42.22000000000014, -44.22999999999999, -12.070000000000041, 2.0000000000000013, -6.040000000000039, -14.080000000000041, -86.4399999999997, 2.0000000000000013, -24.129999999999708, -76.38999999999933, -42.21999999999997, -40.2099999999998, -50.26000000000032, -8.05000000000004, -42.22000000000001, -38.20000000000036, -82.41999999999939, -0.00999999999999836, -2.020000000000042, -12.070000000000041, -42.220000000000354, -14.080000000000041, -8.050000000000042, -32.170000000000364, -86.43999999999978, -14.080000000000041, -70.35999999999916, -60.310000000000336, -60.310000000000095, -108.54999999999991, 2.0000000000000013, -12.070000000000041, -6.040000000000042, -102.51999999999965, -24.12999999999978, -4.030000000000042, -16.0899999999997, -56.290000000000305, 2.0000000000000013, -76.38999999999918, -72.36999999999922, -40.2100000000003, -4.030000000000042, 2.0000000000000013, -78.36, -54.280000000000314, -14.080000000000041, -50.26000000000029], "policy_predator_policy_reward": [13.0, 11.0, 23.0, 26.0, 9.0, 6.0, 6.0, 3.0, 49.0, 20.0, 59.0, 22.0, 3.0, 4.0, 1.0, 91.0, 39.0, 13.0, 10.0, 17.0, 10.0, 7.0, 65.0, 51.0, 49.0, 77.0, 20.0, 61.0, 43.0, 21.0, 47.0, 16.0, 15.0, 15.0, 49.0, 22.0, 35.0, 83.0, 10.0, 7.0, 10.0, 18.0, 16.0, 9.0, 2.0, 17.0, 1.0, 28.0, 30.0, 24.0, 43.0, 36.0, 1.0, 9.0, 16.0, 47.0, 47.0, 23.0, 33.0, 29.0, 10.0, 10.0, 28.0, 30.0, 18.0, 14.0, 45.0, 28.0, 22.0, 16.0, 25.0, 13.0, 15.0, 10.0, 21.0, 27.0, 12.0, 25.0, 23.0, 6.0, 49.0, 78.0, 55.0, 31.0, 14.0, 17.0, 7.0, 7.0, 34.0, 25.0, 31.0, 6.0, 12.0, 18.0, 6.0, 17.0, 10.0, 8.0, 19.0, 18.0, 30.0, 26.0, 19.0, 21.0, 36.0, 38.0, 15.0, 11.0, 95.0, 39.0, 23.0, 29.0, 20.0, 11.0, 35.0, 59.0, 33.0, 9.0, 9.0, 17.0, 10.0, 19.0, 2.0, 53.0, 2.0, 11.0, 14.0, 19.0, 40.0, 36.0, 14.0, 10.0, 17.0, 18.0, 19.0, 10.0, 59.0, 41.0, 13.0, 42.0, 18.0, 19.0, 5.0, 6.0, 6.0, 23.0, 37.0, 1.0, 36.0, 35.0, 42.0, 25.0, 34.0, 12.0, 7.0, 5.0, 10.0, 4.0, 40.0, 8.0, 4.0, 48.0, 25.0, 10.0, 26.0, 20.0, 23.0, 28.0, 7.0, 36.0, 6.0, 6.0, 6.0, 22.0, 16.0, 17.0, 23.0, 35.0, 31.0, 39.0, 54.0, 30.0, 6.0, 7.0, 45.0, 13.0, 0.0, 16.0, 32.0, 16.0, 23.0, 32.0, 19.0, 38.0, 0.0, 3.0, 13.0, 65.0, 26.0, 30.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 5.906577737319804, "mean_inference_ms": 19.974353848423547, "mean_action_processing_ms": 0.26807438098078085, "mean_env_wait_ms": 3.3745257771974684, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00482785701751709, "StateBufferConnector_ms": 0.007012844085693359, "ViewRequirementAgentConnector_ms": 0.13138794898986816}, "num_episodes": 22, "episode_return_max": 3.8999999999999613, "episode_return_min": -145.41000000000105, "episode_return_mean": -31.69199999999999, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1280000, "num_agent_steps_trained": 1280000, "num_env_steps_sampled": 320000, "num_env_steps_trained": 320000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 366.91070933772124, "num_env_steps_trained_throughput_per_sec": 366.91070933772124, "timesteps_total": 320000, "num_env_steps_sampled_lifetime": 320000, "num_agent_steps_sampled_lifetime": 1280000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1280000, "timers": {"training_iteration_time_ms": 200049.051, "restore_workers_time_ms": 0.014, "training_step_time_ms": 200049.007, "sample_time_ms": 1815.52, "learn_time_ms": 198211.859, "learn_throughput": 20.18, "synch_weights_time_ms": 18.54}, "counters": {"num_env_steps_sampled": 320000, "num_env_steps_trained": 320000, "num_agent_steps_sampled": 1280000, "num_agent_steps_trained": 1280000}, "done": false, "training_iteration": 80, "trial_id": "8e499_00000", "date": "2024-08-15_04-00-12", "timestamp": 1723674612, "time_this_iter_s": 10.956984996795654, "time_total_s": 6950.716072559357, "pid": 33199, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b43f0160>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 6950.716072559357, "iterations_since_restore": 80, "perf": {"cpu_util_percent": 34.6625, "ram_util_percent": 82.98125}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.329324619038395, "cur_kl_coeff": 0.007031250000000002, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.980422402437402, "policy_loss": -0.004075213535269968, "vf_loss": 2.9844533886859024, "vf_explained_var": 0.04037467266516711, "kl": 0.006291033457494561, "entropy": 0.5183985560501694, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 152145.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3941347801811481, "cur_kl_coeff": 0.084375, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.0983922807627886, "policy_loss": -0.0065177723583050825, "vf_loss": 2.104401779174805, "vf_explained_var": 0.10703582612295, "kl": 0.006023932214795579, "entropy": 0.48530666886498686, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 152145.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 324000, "num_env_steps_trained": 324000, "num_agent_steps_sampled": 1296000, "num_agent_steps_trained": 1296000}, "env_runners": {"episode_reward_max": 3.8999999999999613, "episode_reward_min": -145.41000000000105, "episode_reward_mean": -28.764199999999988, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -221.07000000000068, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 2.0000000000000013, "predator_policy": 95.0}, "policy_reward_mean": {"prey_policy": -37.69709999999997, "predator_policy": 23.315}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-76.98999999999906, 0.8999999999999836, -18.249999999999943, -3.160000000000082, -11.170000000000082, -25.289999999999907, -50.54000000000045, -31.570000000000196, -6.1000000000000565, -93.79999999999954, -42.58000000000062, -26.45999999999971, 3.8999999999999613, -54.580000000000545, -10.23000000000008, -15.459999999999825, -34.38000000000035, -22.319999999999943, -15.219999999999795, -14.33000000000009, -33.36999999999978, -39.36000000000037, -31.810000000000276, -74.81999999999965, -17.259999999999668, 1.9200000000000028, -13.380000000000098, -33.370000000000495, -2.180000000000078, -19.229999999999624, -14.179999999999906, -3.2200000000000566, -52.560000000000315, -0.22000000000003572, -10.440000000000063, -30.299999999999883, -145.41000000000105, -20.379999999999594, -17.259999999999586, -86.9199999999993, -34.399999999999885, -22.259999999999735, -15.24000000000008, -51.5500000000003, -27.21999999999941, -3.2000000000000703, -34.57000000000011, -20.23999999999943, -39.39000000000038, -9.210000000000079, -46.750000000000284, -51.55000000000065, -9.250000000000076, -3.0900000000000736, -25.28999999999967, -34.380000000000464, -25.499999999999805, -63.66999999999942, -40.44999999999996, 1.9300000000000028, -6.120000000000081, -36.44000000000023, -48.520000000000444, -47.43000000000034, -12.310000000000084, -29.41999999999947, -39.430000000000426, -2.0900000000000833, -28.29999999999943, -7.220000000000081, -42.52000000000005, -60.67000000000066, -84.85999999999977, 2.9299999999999824, -50.56000000000026, -12.160000000000078, -24.379999999999516, -19.389999999999514, -55.58000000000063, 0.969999999999981, -54.63999999999973, -8.340000000000078, -9.130000000000082, -27.35999999999954, 0.6099999999999958, -33.370000000000545, -63.799999999999294, -26.299999999999454, -18.509999999999643, -0.12000000000004098, -51.570000000000455, -39.4300000000002, -24.359999999999534, -3.3400000000000603, -37.41999999999997, -17.349999999999554, -26.299999999999432, -20.26999999999961, -62.11000000000038, -3.150000000000081], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-170.86000000000064, -24.129999999999708, 2.0000000000000013, -18.099999999999707, -8.050000000000042, -38.19999999999999, -30.159999999999787, 2.0000000000000013, 2.0000000000000013, -32.17000000000031, -10.060000000000041, -44.230000000000096, -14.080000000000027, -90.4599999999994, -88.44999999999925, -22.119999999999816, -18.099999999999795, 2.0000000000000013, -92.46999999999984, -64.3299999999998, -84.4299999999992, -28.14999999999976, -32.170000000000236, -56.2900000000002, -2.020000000000042, -14.08000000000004, -38.200000000000266, -74.37999999999943, -36.1900000000003, -6.040000000000042, -70.35999999999962, -18.099999999999778, -38.200000000000266, -34.18000000000018, -14.080000000000041, -46.23999999999993, -12.070000000000025, -28.149999999999828, -10.060000000000041, -52.26999999999993, -62.32000000000023, -8.050000000000042, -54.28000000000021, -14.080000000000041, -136.69000000000062, -22.119999999999752, -96.48999999999978, -64.32999999999946, -42.22000000000022, -6.040000000000042, -0.009999999999998581, -12.070000000000041, -44.23000000000035, -28.149999999999793, -16.089999999999705, -54.28000000000026, 2.0000000000000013, -34.18000000000036, 2.0000000000000013, -44.230000000000274, 2.0000000000000013, -34.18000000000028, 2.0000000000000013, -42.219999999999935, -58.30000000000034, -50.26000000000023, -18.099999999999728, -22.119999999999706, -40.209999999999944, -44.230000000000274, -28.149999999999824, -28.149999999999814, -78.3999999999996, -201.0100000000005, -36.19000000000025, -36.19000000000029, -48.250000000000256, -0.00999999999999836, -162.82000000000045, -18.099999999999703, -36.19000000000007, -40.210000000000356, -50.260000000000176, 2.0000000000000013, -26.13999999999994, -18.099999999999703, -8.050000000000038, -98.4999999999997, -20.109999999999705, -20.109999999999705, -8.050000000000034, -28.14999999999971, -18.099999999999703, -92.46999999999956, -12.070000000000041, -32.17000000000021, -28.1499999999998, -46.240000000000336, -24.129999999999754, -14.080000000000041, -8.050000000000042, -138.7000000000007, -42.22000000000029, -64.32999999999927, -48.25000000000031, 2.0000000000000013, -16.089999999999737, 2.0000000000000013, -30.15999999999986, -24.129999999999708, -28.149999999999764, -44.23000000000024, -72.36999999999951, -24.12999999999987, -70.3599999999996, -60.31000000000033, -42.22000000000014, -44.22999999999999, -12.070000000000041, 2.0000000000000013, -6.040000000000039, -14.080000000000041, -86.4399999999997, 2.0000000000000013, -24.129999999999708, -76.38999999999933, -42.21999999999997, -40.2099999999998, -50.26000000000032, -8.05000000000004, -42.22000000000001, -38.20000000000036, -82.41999999999939, -0.00999999999999836, -2.020000000000042, -12.070000000000041, -42.220000000000354, -14.080000000000041, -8.050000000000042, -32.170000000000364, -86.43999999999978, -14.080000000000041, -70.35999999999916, -60.310000000000336, -60.310000000000095, -108.54999999999991, 2.0000000000000013, -12.070000000000041, -6.040000000000042, -102.51999999999965, -24.12999999999978, -4.030000000000042, -16.0899999999997, -56.290000000000305, 2.0000000000000013, -76.38999999999918, -72.36999999999922, -40.2100000000003, -4.030000000000042, 2.0000000000000013, -78.36, -54.280000000000314, -14.080000000000041, -50.26000000000029, -6.040000000000033, -16.0899999999997, -10.060000000000041, -58.30000000000029, 2.0000000000000013, -76.38999999999933, -50.260000000000346, -20.10999999999974, -62.32000000000031, -94.47999999999942, -46.24000000000034, -10.060000000000041, -2.020000000000042, -96.48999999999944, -22.119999999999706, 2.0000000000000013, -62.320000000000235, -48.25000000000015, -28.149999999999718, -54.280000000000086, -56.290000000000276, -12.070000000000041, -66.33999999999938, 2.0000000000000013, 2.0000000000000013, -82.41999999999972, 2.0000000000000013, -68.34999999999924, -8.050000000000042, -48.25000000000027, -6.040000000000041, -44.23000000000026, -221.07000000000068, -6.040000000000042, -4.030000000000037, -22.119999999999706], "policy_predator_policy_reward": [35.0, 83.0, 10.0, 7.0, 10.0, 18.0, 16.0, 9.0, 2.0, 17.0, 1.0, 28.0, 30.0, 24.0, 43.0, 36.0, 1.0, 9.0, 16.0, 47.0, 47.0, 23.0, 33.0, 29.0, 10.0, 10.0, 28.0, 30.0, 18.0, 14.0, 45.0, 28.0, 22.0, 16.0, 25.0, 13.0, 15.0, 10.0, 21.0, 27.0, 12.0, 25.0, 23.0, 6.0, 49.0, 78.0, 55.0, 31.0, 14.0, 17.0, 7.0, 7.0, 34.0, 25.0, 31.0, 6.0, 12.0, 18.0, 6.0, 17.0, 10.0, 8.0, 19.0, 18.0, 30.0, 26.0, 19.0, 21.0, 36.0, 38.0, 15.0, 11.0, 95.0, 39.0, 23.0, 29.0, 20.0, 11.0, 35.0, 59.0, 33.0, 9.0, 9.0, 17.0, 10.0, 19.0, 2.0, 53.0, 2.0, 11.0, 14.0, 19.0, 40.0, 36.0, 14.0, 10.0, 17.0, 18.0, 19.0, 10.0, 59.0, 41.0, 13.0, 42.0, 18.0, 19.0, 5.0, 6.0, 6.0, 23.0, 37.0, 1.0, 36.0, 35.0, 42.0, 25.0, 34.0, 12.0, 7.0, 5.0, 10.0, 4.0, 40.0, 8.0, 4.0, 48.0, 25.0, 10.0, 26.0, 20.0, 23.0, 28.0, 7.0, 36.0, 6.0, 6.0, 6.0, 22.0, 16.0, 17.0, 23.0, 35.0, 31.0, 39.0, 54.0, 30.0, 6.0, 7.0, 45.0, 13.0, 0.0, 16.0, 32.0, 16.0, 23.0, 32.0, 19.0, 38.0, 0.0, 3.0, 13.0, 65.0, 26.0, 30.0, 13.0, 0.0, 21.0, 20.0, 36.0, 39.0, 1.0, 36.0, 47.0, 46.0, 28.0, 2.0, 35.0, 45.0, 11.0, 9.0, 8.0, 51.0, 33.0, 10.0, 13.0, 31.0, 27.0, 34.0, 28.0, 15.0, 17.0, 32.0, 5.0, 25.0, 9.0, 21.0, 88.0, 77.0, 12.0, 11.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 6.652817921731232, "mean_inference_ms": 19.238440582524753, "mean_action_processing_ms": 0.2691040086926974, "mean_env_wait_ms": 3.0713897009042364, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004622101783752441, "StateBufferConnector_ms": 0.0071250200271606445, "ViewRequirementAgentConnector_ms": 0.1258094310760498}, "num_episodes": 18, "episode_return_max": 3.8999999999999613, "episode_return_min": -145.41000000000105, "episode_return_mean": -28.764199999999988, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1296000, "num_agent_steps_trained": 1296000, "num_env_steps_sampled": 324000, "num_env_steps_trained": 324000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 378.11776360725247, "num_env_steps_trained_throughput_per_sec": 378.11776360725247, "timesteps_total": 324000, "num_env_steps_sampled_lifetime": 324000, "num_agent_steps_sampled_lifetime": 1296000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1296000, "timers": {"training_iteration_time_ms": 200041.114, "restore_workers_time_ms": 0.013, "training_step_time_ms": 200041.073, "sample_time_ms": 1810.018, "learn_time_ms": 198209.705, "learn_throughput": 20.181, "synch_weights_time_ms": 18.379}, "counters": {"num_env_steps_sampled": 324000, "num_env_steps_trained": 324000, "num_agent_steps_sampled": 1296000, "num_agent_steps_trained": 1296000}, "done": false, "training_iteration": 81, "trial_id": "8e499_00000", "date": "2024-08-15_04-00-22", "timestamp": 1723674622, "time_this_iter_s": 10.584366083145142, "time_total_s": 6961.300438642502, "pid": 33199, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x1580efa60>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 6961.300438642502, "iterations_since_restore": 81, "perf": {"cpu_util_percent": 33.300000000000004, "ram_util_percent": 80.70666666666666}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9079310644871343, "cur_kl_coeff": 0.007031250000000002, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.8030041026690649, "policy_loss": -0.003061771740713132, "vf_loss": 1.806022814688859, "vf_explained_var": 0.0174436592866504, "kl": 0.006123826782840111, "entropy": 0.5425591454304085, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 154035.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4133341538843023, "cur_kl_coeff": 0.084375, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.4454903290227608, "policy_loss": -0.019627333494893734, "vf_loss": 1.4638825326369553, "vf_explained_var": 0.20471379741159065, "kl": 0.014638590960229613, "entropy": 0.42601254051009185, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 154035.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 328000, "num_env_steps_trained": 328000, "num_agent_steps_sampled": 1312000, "num_agent_steps_trained": 1312000}, "env_runners": {"episode_reward_max": 2.989999999999981, "episode_reward_min": -145.41000000000105, "episode_reward_mean": -27.834599999999963, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -221.07000000000068, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 2.0000000000000013, "predator_policy": 95.0}, "policy_reward_mean": {"prey_policy": -36.732299999999974, "predator_policy": 22.815}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-74.81999999999965, -17.259999999999668, 1.9200000000000028, -13.380000000000098, -33.370000000000495, -2.180000000000078, -19.229999999999624, -14.179999999999906, -3.2200000000000566, -52.560000000000315, -0.22000000000003572, -10.440000000000063, -30.299999999999883, -145.41000000000105, -20.379999999999594, -17.259999999999586, -86.9199999999993, -34.399999999999885, -22.259999999999735, -15.24000000000008, -51.5500000000003, -27.21999999999941, -3.2000000000000703, -34.57000000000011, -20.23999999999943, -39.39000000000038, -9.210000000000079, -46.750000000000284, -51.55000000000065, -9.250000000000076, -3.0900000000000736, -25.28999999999967, -34.380000000000464, -25.499999999999805, -63.66999999999942, -40.44999999999996, 1.9300000000000028, -6.120000000000081, -36.44000000000023, -48.520000000000444, -47.43000000000034, -12.310000000000084, -29.41999999999947, -39.430000000000426, -2.0900000000000833, -28.29999999999943, -7.220000000000081, -42.52000000000005, -60.67000000000066, -84.85999999999977, 2.9299999999999824, -50.56000000000026, -12.160000000000078, -24.379999999999516, -19.389999999999514, -55.58000000000063, 0.969999999999981, -54.63999999999973, -8.340000000000078, -9.130000000000082, -27.35999999999954, 0.6099999999999958, -33.370000000000545, -63.799999999999294, -26.299999999999454, -18.509999999999643, -0.12000000000004098, -51.570000000000455, -39.4300000000002, -24.359999999999534, -3.3400000000000603, -37.41999999999997, -17.349999999999554, -26.299999999999432, -20.26999999999961, -62.11000000000038, -3.150000000000081, -39.570000000000434, -19.529999999999593, -47.53000000000032, -14.269999999999808, -60.64000000000061, -43.58000000000055, -1.33000000000005, -29.269999999999737, -30.749999999999854, -37.41000000000068, -25.349999999999447, 0.8500000000000002, -7.110000000000083, -54.680000000000526, -16.419999999999657, -19.199999999999406, 2.989999999999981, -21.24999999999946, -18.21999999999942, -29.289999999999647, 1.9300000000000033, -21.249999999999662, -28.329999999999444], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-96.48999999999978, -64.32999999999946, -42.22000000000022, -6.040000000000042, -0.009999999999998581, -12.070000000000041, -44.23000000000035, -28.149999999999793, -16.089999999999705, -54.28000000000026, 2.0000000000000013, -34.18000000000036, 2.0000000000000013, -44.230000000000274, 2.0000000000000013, -34.18000000000028, 2.0000000000000013, -42.219999999999935, -58.30000000000034, -50.26000000000023, -18.099999999999728, -22.119999999999706, -40.209999999999944, -44.230000000000274, -28.149999999999824, -28.149999999999814, -78.3999999999996, -201.0100000000005, -36.19000000000025, -36.19000000000029, -48.250000000000256, -0.00999999999999836, -162.82000000000045, -18.099999999999703, -36.19000000000007, -40.210000000000356, -50.260000000000176, 2.0000000000000013, -26.13999999999994, -18.099999999999703, -8.050000000000038, -98.4999999999997, -20.109999999999705, -20.109999999999705, -8.050000000000034, -28.14999999999971, -18.099999999999703, -92.46999999999956, -12.070000000000041, -32.17000000000021, -28.1499999999998, -46.240000000000336, -24.129999999999754, -14.080000000000041, -8.050000000000042, -138.7000000000007, -42.22000000000029, -64.32999999999927, -48.25000000000031, 2.0000000000000013, -16.089999999999737, 2.0000000000000013, -30.15999999999986, -24.129999999999708, -28.149999999999764, -44.23000000000024, -72.36999999999951, -24.12999999999987, -70.3599999999996, -60.31000000000033, -42.22000000000014, -44.22999999999999, -12.070000000000041, 2.0000000000000013, -6.040000000000039, -14.080000000000041, -86.4399999999997, 2.0000000000000013, -24.129999999999708, -76.38999999999933, -42.21999999999997, -40.2099999999998, -50.26000000000032, -8.05000000000004, -42.22000000000001, -38.20000000000036, -82.41999999999939, -0.00999999999999836, -2.020000000000042, -12.070000000000041, -42.220000000000354, -14.080000000000041, -8.050000000000042, -32.170000000000364, -86.43999999999978, -14.080000000000041, -70.35999999999916, -60.310000000000336, -60.310000000000095, -108.54999999999991, 2.0000000000000013, -12.070000000000041, -6.040000000000042, -102.51999999999965, -24.12999999999978, -4.030000000000042, -16.0899999999997, -56.290000000000305, 2.0000000000000013, -76.38999999999918, -72.36999999999922, -40.2100000000003, -4.030000000000042, 2.0000000000000013, -78.36, -54.280000000000314, -14.080000000000041, -50.26000000000029, -6.040000000000033, -16.0899999999997, -10.060000000000041, -58.30000000000029, 2.0000000000000013, -76.38999999999933, -50.260000000000346, -20.10999999999974, -62.32000000000031, -94.47999999999942, -46.24000000000034, -10.060000000000041, -2.020000000000042, -96.48999999999944, -22.119999999999706, 2.0000000000000013, -62.320000000000235, -48.25000000000015, -28.149999999999718, -54.280000000000086, -56.290000000000276, -12.070000000000041, -66.33999999999938, 2.0000000000000013, 2.0000000000000013, -82.41999999999972, 2.0000000000000013, -68.34999999999924, -8.050000000000042, -48.25000000000027, -6.040000000000041, -44.23000000000026, -221.07000000000068, -6.040000000000042, -4.030000000000037, -22.119999999999706, -20.109999999999744, -90.45999999999933, -18.09999999999983, -84.42999999999932, -100.50999999999951, -2.020000000000042, -52.27000000000029, 2.0000000000000013, -60.3100000000002, -64.32999999999915, -62.32000000000024, -50.26000000000031, -40.210000000000356, -22.119999999999767, -28.14999999999971, -22.119999999999717, -52.2700000000003, -94.47999999999941, -58.30000000000033, -20.109999999999708, -36.19000000000036, -30.15999999999975, -2.0200000000000413, -24.12999999999979, -12.070000000000041, -6.040000000000042, -50.260000000000275, -82.41999999999942, -44.23000000000022, -36.190000000000325, -24.12999999999971, -12.070000000000041, -0.00999999999999836, 2.0000000000000013, 2.0000000000000013, -48.25000000000034, -32.17000000000036, -8.050000000000042, -14.080000000000041, -40.21000000000026, 2.0000000000000013, -12.070000000000041, -30.159999999999837, -16.089999999999776, -42.22000000000035, -20.109999999999708], "policy_predator_policy_reward": [55.0, 31.0, 14.0, 17.0, 7.0, 7.0, 34.0, 25.0, 31.0, 6.0, 12.0, 18.0, 6.0, 17.0, 10.0, 8.0, 19.0, 18.0, 30.0, 26.0, 19.0, 21.0, 36.0, 38.0, 15.0, 11.0, 95.0, 39.0, 23.0, 29.0, 20.0, 11.0, 35.0, 59.0, 33.0, 9.0, 9.0, 17.0, 10.0, 19.0, 2.0, 53.0, 2.0, 11.0, 14.0, 19.0, 40.0, 36.0, 14.0, 10.0, 17.0, 18.0, 19.0, 10.0, 59.0, 41.0, 13.0, 42.0, 18.0, 19.0, 5.0, 6.0, 6.0, 23.0, 37.0, 1.0, 36.0, 35.0, 42.0, 25.0, 34.0, 12.0, 7.0, 5.0, 10.0, 4.0, 40.0, 8.0, 4.0, 48.0, 25.0, 10.0, 26.0, 20.0, 23.0, 28.0, 7.0, 36.0, 6.0, 6.0, 6.0, 22.0, 16.0, 17.0, 23.0, 35.0, 31.0, 39.0, 54.0, 30.0, 6.0, 7.0, 45.0, 13.0, 0.0, 16.0, 32.0, 16.0, 23.0, 32.0, 19.0, 38.0, 0.0, 3.0, 13.0, 65.0, 26.0, 30.0, 13.0, 0.0, 21.0, 20.0, 36.0, 39.0, 1.0, 36.0, 47.0, 46.0, 28.0, 2.0, 35.0, 45.0, 11.0, 9.0, 8.0, 51.0, 33.0, 10.0, 13.0, 31.0, 27.0, 34.0, 28.0, 15.0, 17.0, 32.0, 5.0, 25.0, 9.0, 21.0, 88.0, 77.0, 12.0, 11.0, 38.0, 33.0, 39.0, 44.0, 42.0, 13.0, 17.0, 19.0, 10.0, 54.0, 20.0, 49.0, 30.0, 31.0, 19.0, 2.0, 59.0, 57.0, 11.0, 30.0, 11.0, 30.0, 12.0, 15.0, 7.0, 4.0, 36.0, 42.0, 25.0, 39.0, 9.0, 8.0, 0.0, 1.0, 25.0, 0.0, 6.0, 16.0, 22.0, 3.0, 5.0, 7.0, 5.0, 20.0, 14.0, 20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 6.042122514965037, "mean_inference_ms": 19.52416390375019, "mean_action_processing_ms": 0.2698028665272334, "mean_env_wait_ms": 3.039311579236602, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003919363021850586, "StateBufferConnector_ms": 0.0036449432373046875, "ViewRequirementAgentConnector_ms": 0.10463333129882812}, "num_episodes": 23, "episode_return_max": 2.989999999999981, "episode_return_min": -145.41000000000105, "episode_return_mean": -27.834599999999963, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1312000, "num_agent_steps_trained": 1312000, "num_env_steps_sampled": 328000, "num_env_steps_trained": 328000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 404.0334722382704, "num_env_steps_trained_throughput_per_sec": 404.0334722382704, "timesteps_total": 328000, "num_env_steps_sampled_lifetime": 328000, "num_agent_steps_sampled_lifetime": 1312000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1312000, "timers": {"training_iteration_time_ms": 200034.957, "restore_workers_time_ms": 0.013, "training_step_time_ms": 200034.915, "sample_time_ms": 1808.511, "learn_time_ms": 198205.027, "learn_throughput": 20.181, "synch_weights_time_ms": 18.334}, "counters": {"num_env_steps_sampled": 328000, "num_env_steps_trained": 328000, "num_agent_steps_sampled": 1312000, "num_agent_steps_trained": 1312000}, "done": false, "training_iteration": 82, "trial_id": "8e499_00000", "date": "2024-08-15_04-00-32", "timestamp": 1723674632, "time_this_iter_s": 9.905837059020996, "time_total_s": 6971.206275701523, "pid": 33199, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x15800f790>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 6971.206275701523, "iterations_since_restore": 82, "perf": {"cpu_util_percent": 35.13571428571429, "ram_util_percent": 79.59285714285714}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.656816153898441, "cur_kl_coeff": 0.007031250000000002, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.115104247274853, "policy_loss": -0.006172631942499528, "vf_loss": 3.1212278441777306, "vf_explained_var": 0.029048682867534578, "kl": 0.006974377638605455, "entropy": 0.5548258772602788, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 155925.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.570607559516947, "cur_kl_coeff": 0.084375, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.3653926443801354, "policy_loss": -0.009259518128745849, "vf_loss": 2.3742382565818767, "vf_explained_var": 0.11408853600264857, "kl": 0.004905475215708126, "entropy": 0.5484480489025672, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 155925.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 332000, "num_env_steps_trained": 332000, "num_agent_steps_sampled": 1328000, "num_agent_steps_trained": 1328000}, "env_runners": {"episode_reward_max": 2.989999999999981, "episode_reward_min": -84.85999999999977, "episode_reward_mean": -25.80439999999996, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -239.04000000000087, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 2.0000000000000013, "predator_policy": 113.0}, "policy_reward_mean": {"prey_policy": -35.907199999999946, "predator_policy": 23.005}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-22.259999999999735, -15.24000000000008, -51.5500000000003, -27.21999999999941, -3.2000000000000703, -34.57000000000011, -20.23999999999943, -39.39000000000038, -9.210000000000079, -46.750000000000284, -51.55000000000065, -9.250000000000076, -3.0900000000000736, -25.28999999999967, -34.380000000000464, -25.499999999999805, -63.66999999999942, -40.44999999999996, 1.9300000000000028, -6.120000000000081, -36.44000000000023, -48.520000000000444, -47.43000000000034, -12.310000000000084, -29.41999999999947, -39.430000000000426, -2.0900000000000833, -28.29999999999943, -7.220000000000081, -42.52000000000005, -60.67000000000066, -84.85999999999977, 2.9299999999999824, -50.56000000000026, -12.160000000000078, -24.379999999999516, -19.389999999999514, -55.58000000000063, 0.969999999999981, -54.63999999999973, -8.340000000000078, -9.130000000000082, -27.35999999999954, 0.6099999999999958, -33.370000000000545, -63.799999999999294, -26.299999999999454, -18.509999999999643, -0.12000000000004098, -51.570000000000455, -39.4300000000002, -24.359999999999534, -3.3400000000000603, -37.41999999999997, -17.349999999999554, -26.299999999999432, -20.26999999999961, -62.11000000000038, -3.150000000000081, -39.570000000000434, -19.529999999999593, -47.53000000000032, -14.269999999999808, -60.64000000000061, -43.58000000000055, -1.33000000000005, -29.269999999999737, -30.749999999999854, -37.41000000000068, -25.349999999999447, 0.8500000000000002, -7.110000000000083, -54.680000000000526, -16.419999999999657, -19.199999999999406, 2.989999999999981, -21.24999999999946, -18.21999999999942, -29.289999999999647, 1.9300000000000033, -21.249999999999662, -28.329999999999444, 0.969999999999981, -25.70999999999995, -2.0700000000000696, -36.52000000000041, -38.42000000000052, -17.179999999999417, -6.110000000000081, -38.43000000000014, -20.349999999999554, -16.24999999999945, -37.55000000000002, -12.160000000000082, -58.62000000000039, -19.339999999999492, -19.599999999999696, -23.039999999999637, 1.9100000000000028, -2.120000000000081], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-50.260000000000176, 2.0000000000000013, -26.13999999999994, -18.099999999999703, -8.050000000000038, -98.4999999999997, -20.109999999999705, -20.109999999999705, -8.050000000000034, -28.14999999999971, -18.099999999999703, -92.46999999999956, -12.070000000000041, -32.17000000000021, -28.1499999999998, -46.240000000000336, -24.129999999999754, -14.080000000000041, -8.050000000000042, -138.7000000000007, -42.22000000000029, -64.32999999999927, -48.25000000000031, 2.0000000000000013, -16.089999999999737, 2.0000000000000013, -30.15999999999986, -24.129999999999708, -28.149999999999764, -44.23000000000024, -72.36999999999951, -24.12999999999987, -70.3599999999996, -60.31000000000033, -42.22000000000014, -44.22999999999999, -12.070000000000041, 2.0000000000000013, -6.040000000000039, -14.080000000000041, -86.4399999999997, 2.0000000000000013, -24.129999999999708, -76.38999999999933, -42.21999999999997, -40.2099999999998, -50.26000000000032, -8.05000000000004, -42.22000000000001, -38.20000000000036, -82.41999999999939, -0.00999999999999836, -2.020000000000042, -12.070000000000041, -42.220000000000354, -14.080000000000041, -8.050000000000042, -32.170000000000364, -86.43999999999978, -14.080000000000041, -70.35999999999916, -60.310000000000336, -60.310000000000095, -108.54999999999991, 2.0000000000000013, -12.070000000000041, -6.040000000000042, -102.51999999999965, -24.12999999999978, -4.030000000000042, -16.0899999999997, -56.290000000000305, 2.0000000000000013, -76.38999999999918, -72.36999999999922, -40.2100000000003, -4.030000000000042, 2.0000000000000013, -78.36, -54.280000000000314, -14.080000000000041, -50.26000000000029, -6.040000000000033, -16.0899999999997, -10.060000000000041, -58.30000000000029, 2.0000000000000013, -76.38999999999933, -50.260000000000346, -20.10999999999974, -62.32000000000031, -94.47999999999942, -46.24000000000034, -10.060000000000041, -2.020000000000042, -96.48999999999944, -22.119999999999706, 2.0000000000000013, -62.320000000000235, -48.25000000000015, -28.149999999999718, -54.280000000000086, -56.290000000000276, -12.070000000000041, -66.33999999999938, 2.0000000000000013, 2.0000000000000013, -82.41999999999972, 2.0000000000000013, -68.34999999999924, -8.050000000000042, -48.25000000000027, -6.040000000000041, -44.23000000000026, -221.07000000000068, -6.040000000000042, -4.030000000000037, -22.119999999999706, -20.109999999999744, -90.45999999999933, -18.09999999999983, -84.42999999999932, -100.50999999999951, -2.020000000000042, -52.27000000000029, 2.0000000000000013, -60.3100000000002, -64.32999999999915, -62.32000000000024, -50.26000000000031, -40.210000000000356, -22.119999999999767, -28.14999999999971, -22.119999999999717, -52.2700000000003, -94.47999999999941, -58.30000000000033, -20.109999999999708, -36.19000000000036, -30.15999999999975, -2.0200000000000413, -24.12999999999979, -12.070000000000041, -6.040000000000042, -50.260000000000275, -82.41999999999942, -44.23000000000022, -36.190000000000325, -24.12999999999971, -12.070000000000041, -0.00999999999999836, 2.0000000000000013, 2.0000000000000013, -48.25000000000034, -32.17000000000036, -8.050000000000042, -14.080000000000041, -40.21000000000026, 2.0000000000000013, -12.070000000000041, -30.159999999999837, -16.089999999999776, -42.22000000000035, -20.109999999999708, -4.030000000000042, 2.0000000000000013, -140.7100000000002, 2.0000000000000013, -12.070000000000041, 2.0000000000000013, -28.14999999999971, -72.36999999999948, -40.21000000000035, -40.21000000000029, -6.040000000000042, -26.13999999999971, 2.0000000000000013, -20.109999999999705, -12.070000000000034, -78.3599999999999, -14.080000000000041, -52.27000000000027, -48.25000000000035, 2.0000000000000013, -10.060000000000041, -96.48999999999975, -14.080000000000041, -14.08000000000004, -98.49999999999942, -22.119999999999706, 2.0000000000000013, -66.33999999999928, 2.0000000000000013, -118.59999999999961, -239.04000000000087, 2.0000000000000013, -16.0899999999997, 2.0000000000000013, 2.0000000000000013, -22.119999999999706], "policy_predator_policy_reward": [9.0, 17.0, 10.0, 19.0, 2.0, 53.0, 2.0, 11.0, 14.0, 19.0, 40.0, 36.0, 14.0, 10.0, 17.0, 18.0, 19.0, 10.0, 59.0, 41.0, 13.0, 42.0, 18.0, 19.0, 5.0, 6.0, 6.0, 23.0, 37.0, 1.0, 36.0, 35.0, 42.0, 25.0, 34.0, 12.0, 7.0, 5.0, 10.0, 4.0, 40.0, 8.0, 4.0, 48.0, 25.0, 10.0, 26.0, 20.0, 23.0, 28.0, 7.0, 36.0, 6.0, 6.0, 6.0, 22.0, 16.0, 17.0, 23.0, 35.0, 31.0, 39.0, 54.0, 30.0, 6.0, 7.0, 45.0, 13.0, 0.0, 16.0, 32.0, 16.0, 23.0, 32.0, 19.0, 38.0, 0.0, 3.0, 13.0, 65.0, 26.0, 30.0, 13.0, 0.0, 21.0, 20.0, 36.0, 39.0, 1.0, 36.0, 47.0, 46.0, 28.0, 2.0, 35.0, 45.0, 11.0, 9.0, 8.0, 51.0, 33.0, 10.0, 13.0, 31.0, 27.0, 34.0, 28.0, 15.0, 17.0, 32.0, 5.0, 25.0, 9.0, 21.0, 88.0, 77.0, 12.0, 11.0, 38.0, 33.0, 39.0, 44.0, 42.0, 13.0, 17.0, 19.0, 10.0, 54.0, 20.0, 49.0, 30.0, 31.0, 19.0, 2.0, 59.0, 57.0, 11.0, 30.0, 11.0, 30.0, 12.0, 15.0, 7.0, 4.0, 36.0, 42.0, 25.0, 39.0, 9.0, 8.0, 0.0, 1.0, 25.0, 0.0, 6.0, 16.0, 22.0, 3.0, 5.0, 7.0, 5.0, 20.0, 14.0, 20.0, 3.0, 0.0, 47.0, 66.0, 3.0, 5.0, 42.0, 22.0, 2.0, 40.0, 14.0, 1.0, 11.0, 1.0, 51.0, 1.0, 21.0, 25.0, 8.0, 22.0, 34.0, 35.0, 16.0, 0.0, 18.0, 44.0, 17.0, 28.0, 41.0, 56.0, 113.0, 101.0, 9.0, 7.0, 12.0, 6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 6.505226377269371, "mean_inference_ms": 18.80476630998674, "mean_action_processing_ms": 0.2696897529262934, "mean_env_wait_ms": 3.0076550916343363, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0037348270416259766, "StateBufferConnector_ms": 0.0034683942794799805, "ViewRequirementAgentConnector_ms": 0.09937310218811035}, "num_episodes": 18, "episode_return_max": 2.989999999999981, "episode_return_min": -84.85999999999977, "episode_return_mean": -25.80439999999996, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1328000, "num_agent_steps_trained": 1328000, "num_env_steps_sampled": 332000, "num_env_steps_trained": 332000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 402.545990833193, "num_env_steps_trained_throughput_per_sec": 402.545990833193, "timesteps_total": 332000, "num_env_steps_sampled_lifetime": 332000, "num_agent_steps_sampled_lifetime": 1328000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1328000, "timers": {"training_iteration_time_ms": 200026.333, "restore_workers_time_ms": 0.013, "training_step_time_ms": 200026.292, "sample_time_ms": 1809.22, "learn_time_ms": 198195.904, "learn_throughput": 20.182, "synch_weights_time_ms": 18.09}, "counters": {"num_env_steps_sampled": 332000, "num_env_steps_trained": 332000, "num_agent_steps_sampled": 1328000, "num_agent_steps_trained": 1328000}, "done": false, "training_iteration": 83, "trial_id": "8e499_00000", "date": "2024-08-15_04-00-42", "timestamp": 1723674642, "time_this_iter_s": 9.944912910461426, "time_total_s": 6981.151188611984, "pid": 33199, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x15819ca60>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 6981.151188611984, "iterations_since_restore": 83, "perf": {"cpu_util_percent": 34.62142857142857, "ram_util_percent": 79.3}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6202739806717665, "cur_kl_coeff": 0.007031250000000002, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.638181157465334, "policy_loss": -0.0044358136058445016, "vf_loss": 4.642561702627353, "vf_explained_var": 0.01168220938828887, "kl": 0.00786163097785729, "entropy": 0.5505734309317574, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 157815.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3993181415335842, "cur_kl_coeff": 0.0421875, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.5476431099826065, "policy_loss": -0.009440693243470773, "vf_loss": 3.5567003541522557, "vf_explained_var": 0.09187518522222206, "kl": 0.009089089796264525, "entropy": 0.6978519778718393, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 157815.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 336000, "num_env_steps_trained": 336000, "num_agent_steps_sampled": 1344000, "num_agent_steps_trained": 1344000}, "env_runners": {"episode_reward_max": 3.8799999999999617, "episode_reward_min": -150.53000000000014, "episode_reward_mean": -26.85609999999995, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -303.52, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 2.0000000000000013, "predator_policy": 152.0}, "policy_reward_mean": {"prey_policy": -39.13304999999997, "predator_policy": 25.705}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.9300000000000028, -6.120000000000081, -36.44000000000023, -48.520000000000444, -47.43000000000034, -12.310000000000084, -29.41999999999947, -39.430000000000426, -2.0900000000000833, -28.29999999999943, -7.220000000000081, -42.52000000000005, -60.67000000000066, -84.85999999999977, 2.9299999999999824, -50.56000000000026, -12.160000000000078, -24.379999999999516, -19.389999999999514, -55.58000000000063, 0.969999999999981, -54.63999999999973, -8.340000000000078, -9.130000000000082, -27.35999999999954, 0.6099999999999958, -33.370000000000545, -63.799999999999294, -26.299999999999454, -18.509999999999643, -0.12000000000004098, -51.570000000000455, -39.4300000000002, -24.359999999999534, -3.3400000000000603, -37.41999999999997, -17.349999999999554, -26.299999999999432, -20.26999999999961, -62.11000000000038, -3.150000000000081, -39.570000000000434, -19.529999999999593, -47.53000000000032, -14.269999999999808, -60.64000000000061, -43.58000000000055, -1.33000000000005, -29.269999999999737, -30.749999999999854, -37.41000000000068, -25.349999999999447, 0.8500000000000002, -7.110000000000083, -54.680000000000526, -16.419999999999657, -19.199999999999406, 2.989999999999981, -21.24999999999946, -18.21999999999942, -29.289999999999647, 1.9300000000000033, -21.249999999999662, -28.329999999999444, 0.969999999999981, -25.70999999999995, -2.0700000000000696, -36.52000000000041, -38.42000000000052, -17.179999999999417, -6.110000000000081, -38.43000000000014, -20.349999999999554, -16.24999999999945, -37.55000000000002, -12.160000000000082, -58.62000000000039, -19.339999999999492, -19.599999999999696, -23.039999999999637, 1.9100000000000028, -2.120000000000081, -35.39000000000042, -46.520000000000046, 0.9599999999999836, -23.28999999999942, -21.559999999999867, -49.980000000000054, -18.2199999999995, -41.01, -42.74000000000003, -47.50999999999984, -0.16000000000003922, 3.8799999999999617, -150.53000000000014, -11.600000000000046, -18.219999999999434, -44.58000000000034, -69.06999999999978, -12.440000000000039], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-12.070000000000041, 2.0000000000000013, -6.040000000000039, -14.080000000000041, -86.4399999999997, 2.0000000000000013, -24.129999999999708, -76.38999999999933, -42.21999999999997, -40.2099999999998, -50.26000000000032, -8.05000000000004, -42.22000000000001, -38.20000000000036, -82.41999999999939, -0.00999999999999836, -2.020000000000042, -12.070000000000041, -42.220000000000354, -14.080000000000041, -8.050000000000042, -32.170000000000364, -86.43999999999978, -14.080000000000041, -70.35999999999916, -60.310000000000336, -60.310000000000095, -108.54999999999991, 2.0000000000000013, -12.070000000000041, -6.040000000000042, -102.51999999999965, -24.12999999999978, -4.030000000000042, -16.0899999999997, -56.290000000000305, 2.0000000000000013, -76.38999999999918, -72.36999999999922, -40.2100000000003, -4.030000000000042, 2.0000000000000013, -78.36, -54.280000000000314, -14.080000000000041, -50.26000000000029, -6.040000000000033, -16.0899999999997, -10.060000000000041, -58.30000000000029, 2.0000000000000013, -76.38999999999933, -50.260000000000346, -20.10999999999974, -62.32000000000031, -94.47999999999942, -46.24000000000034, -10.060000000000041, -2.020000000000042, -96.48999999999944, -22.119999999999706, 2.0000000000000013, -62.320000000000235, -48.25000000000015, -28.149999999999718, -54.280000000000086, -56.290000000000276, -12.070000000000041, -66.33999999999938, 2.0000000000000013, 2.0000000000000013, -82.41999999999972, 2.0000000000000013, -68.34999999999924, -8.050000000000042, -48.25000000000027, -6.040000000000041, -44.23000000000026, -221.07000000000068, -6.040000000000042, -4.030000000000037, -22.119999999999706, -20.109999999999744, -90.45999999999933, -18.09999999999983, -84.42999999999932, -100.50999999999951, -2.020000000000042, -52.27000000000029, 2.0000000000000013, -60.3100000000002, -64.32999999999915, -62.32000000000024, -50.26000000000031, -40.210000000000356, -22.119999999999767, -28.14999999999971, -22.119999999999717, -52.2700000000003, -94.47999999999941, -58.30000000000033, -20.109999999999708, -36.19000000000036, -30.15999999999975, -2.0200000000000413, -24.12999999999979, -12.070000000000041, -6.040000000000042, -50.260000000000275, -82.41999999999942, -44.23000000000022, -36.190000000000325, -24.12999999999971, -12.070000000000041, -0.00999999999999836, 2.0000000000000013, 2.0000000000000013, -48.25000000000034, -32.17000000000036, -8.050000000000042, -14.080000000000041, -40.21000000000026, 2.0000000000000013, -12.070000000000041, -30.159999999999837, -16.089999999999776, -42.22000000000035, -20.109999999999708, -4.030000000000042, 2.0000000000000013, -140.7100000000002, 2.0000000000000013, -12.070000000000041, 2.0000000000000013, -28.14999999999971, -72.36999999999948, -40.21000000000035, -40.21000000000029, -6.040000000000042, -26.13999999999971, 2.0000000000000013, -20.109999999999705, -12.070000000000034, -78.3599999999999, -14.080000000000041, -52.27000000000027, -48.25000000000035, 2.0000000000000013, -10.060000000000041, -96.48999999999975, -14.080000000000041, -14.08000000000004, -98.49999999999942, -22.119999999999706, 2.0000000000000013, -66.33999999999928, 2.0000000000000013, -118.59999999999961, -239.04000000000087, 2.0000000000000013, -16.0899999999997, 2.0000000000000013, 2.0000000000000013, -22.119999999999706, -16.0899999999997, -58.3000000000002, -34.180000000000234, -66.34000000000005, -4.03000000000004, -0.00999999999999836, -40.21000000000027, -14.080000000000041, -94.47999999999956, -14.080000000000032, -146.74000000000018, -46.24000000000035, -18.099999999999756, -22.11999999999974, -196.99, -2.020000000000042, -148.7099999999994, -4.030000000000042, -52.27000000000003, -46.24000000000018, 2.0000000000000013, -30.159999999999712, 2.0000000000000013, -22.119999999999706, -0.00999999999999836, -303.52, 2.0000000000000013, -118.59999999999964, -42.220000000000354, 2.0000000000000013, -58.30000000000034, -54.28000000000016, -40.21000000000028, -170.86000000000018, -80.40999999999973, -4.030000000000033], "policy_predator_policy_reward": [7.0, 5.0, 10.0, 4.0, 40.0, 8.0, 4.0, 48.0, 25.0, 10.0, 26.0, 20.0, 23.0, 28.0, 7.0, 36.0, 6.0, 6.0, 6.0, 22.0, 16.0, 17.0, 23.0, 35.0, 31.0, 39.0, 54.0, 30.0, 6.0, 7.0, 45.0, 13.0, 0.0, 16.0, 32.0, 16.0, 23.0, 32.0, 19.0, 38.0, 0.0, 3.0, 13.0, 65.0, 26.0, 30.0, 13.0, 0.0, 21.0, 20.0, 36.0, 39.0, 1.0, 36.0, 47.0, 46.0, 28.0, 2.0, 35.0, 45.0, 11.0, 9.0, 8.0, 51.0, 33.0, 10.0, 13.0, 31.0, 27.0, 34.0, 28.0, 15.0, 17.0, 32.0, 5.0, 25.0, 9.0, 21.0, 88.0, 77.0, 12.0, 11.0, 38.0, 33.0, 39.0, 44.0, 42.0, 13.0, 17.0, 19.0, 10.0, 54.0, 20.0, 49.0, 30.0, 31.0, 19.0, 2.0, 59.0, 57.0, 11.0, 30.0, 11.0, 30.0, 12.0, 15.0, 7.0, 4.0, 36.0, 42.0, 25.0, 39.0, 9.0, 8.0, 0.0, 1.0, 25.0, 0.0, 6.0, 16.0, 22.0, 3.0, 5.0, 7.0, 5.0, 20.0, 14.0, 20.0, 3.0, 0.0, 47.0, 66.0, 3.0, 5.0, 42.0, 22.0, 2.0, 40.0, 14.0, 1.0, 11.0, 1.0, 51.0, 1.0, 21.0, 25.0, 8.0, 22.0, 34.0, 35.0, 16.0, 0.0, 18.0, 44.0, 17.0, 28.0, 41.0, 56.0, 113.0, 101.0, 9.0, 7.0, 12.0, 6.0, 1.0, 38.0, 47.0, 7.0, 1.0, 4.0, 12.0, 19.0, 51.0, 36.0, 67.0, 76.0, 18.0, 4.0, 71.0, 87.0, 67.0, 43.0, 5.0, 46.0, 12.0, 16.0, 12.0, 12.0, 152.0, 1.0, 54.0, 51.0, 22.0, 0.0, 33.0, 35.0, 67.0, 75.0, 33.0, 39.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 6.439428437774224, "mean_inference_ms": 18.617276722852157, "mean_action_processing_ms": 0.26950101114308095, "mean_env_wait_ms": 2.976701215300343, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0036667585372924805, "StateBufferConnector_ms": 0.0034891366958618164, "ViewRequirementAgentConnector_ms": 0.09715676307678223}, "num_episodes": 18, "episode_return_max": 3.8799999999999617, "episode_return_min": -150.53000000000014, "episode_return_mean": -26.85609999999995, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1344000, "num_agent_steps_trained": 1344000, "num_env_steps_sampled": 336000, "num_env_steps_trained": 336000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 5.368670675164042, "num_env_steps_trained_throughput_per_sec": 5.368670675164042, "timesteps_total": 336000, "num_env_steps_sampled_lifetime": 336000, "num_agent_steps_sampled_lifetime": 1344000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1344000, "timers": {"training_iteration_time_ms": 178898.824, "restore_workers_time_ms": 0.013, "training_step_time_ms": 178898.784, "sample_time_ms": 1837.422, "learn_time_ms": 177040.382, "learn_throughput": 22.594, "synch_weights_time_ms": 17.936}, "counters": {"num_env_steps_sampled": 336000, "num_env_steps_trained": 336000, "num_agent_steps_sampled": 1344000, "num_agent_steps_trained": 1344000}, "done": false, "training_iteration": 84, "trial_id": "8e499_00000", "date": "2024-08-15_04-13-07", "timestamp": 1723675387, "time_this_iter_s": 745.1060538291931, "time_total_s": 7726.257242441177, "pid": 33199, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x15818de50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 7726.257242441177, "iterations_since_restore": 84, "perf": {"cpu_util_percent": 44.559999999999995, "ram_util_percent": 79.14666666666666}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.24052557469045, "cur_kl_coeff": 0.007031250000000002, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.658781143849489, "policy_loss": -0.002056257353563394, "vf_loss": 4.660800526255653, "vf_explained_var": 0.008646165283899459, "kl": 0.005244716084133821, "entropy": 0.5727669285561042, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 159705.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.0392034798702867, "cur_kl_coeff": 0.0421875, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.027631624918135, "policy_loss": -0.006565647202275359, "vf_loss": 4.033640050257325, "vf_explained_var": 0.1653925604605801, "kl": 0.013208175806727358, "entropy": 0.7463635667922005, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 159705.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 340000, "num_env_steps_trained": 340000, "num_agent_steps_sampled": 1360000, "num_agent_steps_trained": 1360000}, "env_runners": {"episode_reward_max": 3.8799999999999617, "episode_reward_min": -150.53000000000014, "episode_reward_mean": -27.132199999999916, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -303.52, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 2.0000000000000013, "predator_policy": 152.0}, "policy_reward_mean": {"prey_policy": -42.761099999999985, "predator_policy": 29.195}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-8.340000000000078, -9.130000000000082, -27.35999999999954, 0.6099999999999958, -33.370000000000545, -63.799999999999294, -26.299999999999454, -18.509999999999643, -0.12000000000004098, -51.570000000000455, -39.4300000000002, -24.359999999999534, -3.3400000000000603, -37.41999999999997, -17.349999999999554, -26.299999999999432, -20.26999999999961, -62.11000000000038, -3.150000000000081, -39.570000000000434, -19.529999999999593, -47.53000000000032, -14.269999999999808, -60.64000000000061, -43.58000000000055, -1.33000000000005, -29.269999999999737, -30.749999999999854, -37.41000000000068, -25.349999999999447, 0.8500000000000002, -7.110000000000083, -54.680000000000526, -16.419999999999657, -19.199999999999406, 2.989999999999981, -21.24999999999946, -18.21999999999942, -29.289999999999647, 1.9300000000000033, -21.249999999999662, -28.329999999999444, 0.969999999999981, -25.70999999999995, -2.0700000000000696, -36.52000000000041, -38.42000000000052, -17.179999999999417, -6.110000000000081, -38.43000000000014, -20.349999999999554, -16.24999999999945, -37.55000000000002, -12.160000000000082, -58.62000000000039, -19.339999999999492, -19.599999999999696, -23.039999999999637, 1.9100000000000028, -2.120000000000081, -35.39000000000042, -46.520000000000046, 0.9599999999999836, -23.28999999999942, -21.559999999999867, -49.980000000000054, -18.2199999999995, -41.01, -42.74000000000003, -47.50999999999984, -0.16000000000003922, 3.8799999999999617, -150.53000000000014, -11.600000000000046, -18.219999999999434, -44.58000000000034, -69.06999999999978, -12.440000000000039, -2.1300000000000825, -20.310000000000066, -19.229999999999457, -116.41999999999933, -2.3100000000000307, -22.389999999999656, -5.030000000000019, -76.79999999999927, -3.5600000000000733, -91.75999999999847, -36.64000000000012, -1.4300000000000386, 0.749999999999987, -14.250000000000028, -39.43000000000071, -65.65999999999944, -8.550000000000066, -2.20000000000001, -41.71000000000059, -36.52999999999971, -35.76999999999988, -42.4600000000007], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-14.080000000000041, -50.26000000000029, -6.040000000000033, -16.0899999999997, -10.060000000000041, -58.30000000000029, 2.0000000000000013, -76.38999999999933, -50.260000000000346, -20.10999999999974, -62.32000000000031, -94.47999999999942, -46.24000000000034, -10.060000000000041, -2.020000000000042, -96.48999999999944, -22.119999999999706, 2.0000000000000013, -62.320000000000235, -48.25000000000015, -28.149999999999718, -54.280000000000086, -56.290000000000276, -12.070000000000041, -66.33999999999938, 2.0000000000000013, 2.0000000000000013, -82.41999999999972, 2.0000000000000013, -68.34999999999924, -8.050000000000042, -48.25000000000027, -6.040000000000041, -44.23000000000026, -221.07000000000068, -6.040000000000042, -4.030000000000037, -22.119999999999706, -20.109999999999744, -90.45999999999933, -18.09999999999983, -84.42999999999932, -100.50999999999951, -2.020000000000042, -52.27000000000029, 2.0000000000000013, -60.3100000000002, -64.32999999999915, -62.32000000000024, -50.26000000000031, -40.210000000000356, -22.119999999999767, -28.14999999999971, -22.119999999999717, -52.2700000000003, -94.47999999999941, -58.30000000000033, -20.109999999999708, -36.19000000000036, -30.15999999999975, -2.0200000000000413, -24.12999999999979, -12.070000000000041, -6.040000000000042, -50.260000000000275, -82.41999999999942, -44.23000000000022, -36.190000000000325, -24.12999999999971, -12.070000000000041, -0.00999999999999836, 2.0000000000000013, 2.0000000000000013, -48.25000000000034, -32.17000000000036, -8.050000000000042, -14.080000000000041, -40.21000000000026, 2.0000000000000013, -12.070000000000041, -30.159999999999837, -16.089999999999776, -42.22000000000035, -20.109999999999708, -4.030000000000042, 2.0000000000000013, -140.7100000000002, 2.0000000000000013, -12.070000000000041, 2.0000000000000013, -28.14999999999971, -72.36999999999948, -40.21000000000035, -40.21000000000029, -6.040000000000042, -26.13999999999971, 2.0000000000000013, -20.109999999999705, -12.070000000000034, -78.3599999999999, -14.080000000000041, -52.27000000000027, -48.25000000000035, 2.0000000000000013, -10.060000000000041, -96.48999999999975, -14.080000000000041, -14.08000000000004, -98.49999999999942, -22.119999999999706, 2.0000000000000013, -66.33999999999928, 2.0000000000000013, -118.59999999999961, -239.04000000000087, 2.0000000000000013, -16.0899999999997, 2.0000000000000013, 2.0000000000000013, -22.119999999999706, -16.0899999999997, -58.3000000000002, -34.180000000000234, -66.34000000000005, -4.03000000000004, -0.00999999999999836, -40.21000000000027, -14.080000000000041, -94.47999999999956, -14.080000000000032, -146.74000000000018, -46.24000000000035, -18.099999999999756, -22.11999999999974, -196.99, -2.020000000000042, -148.7099999999994, -4.030000000000042, -52.27000000000003, -46.24000000000018, 2.0000000000000013, -30.159999999999712, 2.0000000000000013, -22.119999999999706, -0.00999999999999836, -303.52, 2.0000000000000013, -118.59999999999964, -42.220000000000354, 2.0000000000000013, -58.30000000000034, -54.28000000000016, -40.21000000000028, -170.86000000000018, -80.40999999999973, -4.030000000000033, -22.119999999999706, -0.00999999999999836, -48.25000000000007, -10.06, -10.060000000000032, -32.17000000000033, -138.70000000000033, -142.72000000000088, -18.099999999999856, -40.210000000000136, -42.22000000000017, -32.170000000000165, -205.03000000000003, 2.0000000000000013, -84.4299999999994, -72.3700000000003, -52.23000000000013, -64.32999999999964, -90.45999999999927, -58.30000000000033, -92.46999999999966, -32.170000000000364, 2.0000000000000013, -84.42999999999981, 2.0000000000000013, -48.250000000000334, -44.23000000000022, -2.020000000000042, -40.210000000000356, -42.220000000000354, -52.27000000000009, -76.38999999999953, -60.31000000000012, -46.240000000000315, 2.0000000000000013, -38.199999999999804, -84.42999999999942, -54.28000000000034, -8.050000000000042, -94.48000000000009, -58.30000000000004, -92.46999999999993, -30.159999999999712, -58.30000000000034], "policy_predator_policy_reward": [26.0, 30.0, 13.0, 0.0, 21.0, 20.0, 36.0, 39.0, 1.0, 36.0, 47.0, 46.0, 28.0, 2.0, 35.0, 45.0, 11.0, 9.0, 8.0, 51.0, 33.0, 10.0, 13.0, 31.0, 27.0, 34.0, 28.0, 15.0, 17.0, 32.0, 5.0, 25.0, 9.0, 21.0, 88.0, 77.0, 12.0, 11.0, 38.0, 33.0, 39.0, 44.0, 42.0, 13.0, 17.0, 19.0, 10.0, 54.0, 20.0, 49.0, 30.0, 31.0, 19.0, 2.0, 59.0, 57.0, 11.0, 30.0, 11.0, 30.0, 12.0, 15.0, 7.0, 4.0, 36.0, 42.0, 25.0, 39.0, 9.0, 8.0, 0.0, 1.0, 25.0, 0.0, 6.0, 16.0, 22.0, 3.0, 5.0, 7.0, 5.0, 20.0, 14.0, 20.0, 3.0, 0.0, 47.0, 66.0, 3.0, 5.0, 42.0, 22.0, 2.0, 40.0, 14.0, 1.0, 11.0, 1.0, 51.0, 1.0, 21.0, 25.0, 8.0, 22.0, 34.0, 35.0, 16.0, 0.0, 18.0, 44.0, 17.0, 28.0, 41.0, 56.0, 113.0, 101.0, 9.0, 7.0, 12.0, 6.0, 1.0, 38.0, 47.0, 7.0, 1.0, 4.0, 12.0, 19.0, 51.0, 36.0, 67.0, 76.0, 18.0, 4.0, 71.0, 87.0, 67.0, 43.0, 5.0, 46.0, 12.0, 16.0, 12.0, 12.0, 152.0, 1.0, 54.0, 51.0, 22.0, 0.0, 33.0, 35.0, 67.0, 75.0, 33.0, 39.0, 9.0, 11.0, 17.0, 21.0, 22.0, 1.0, 66.0, 99.0, 26.0, 30.0, 21.0, 31.0, 99.0, 99.0, 43.0, 37.0, 61.0, 52.0, 57.0, 0.0, 30.0, 58.0, 40.0, 41.0, 25.0, 22.0, 23.0, 9.0, 17.0, 26.0, 16.0, 47.0, 49.0, 49.0, 18.0, 16.0, 58.0, 39.0, 38.0, 28.0, 63.0, 52.0, 16.0, 30.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 6.35950251372625, "mean_inference_ms": 18.402239281873484, "mean_action_processing_ms": 0.2690971051302992, "mean_env_wait_ms": 2.931181824002579, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003652811050415039, "StateBufferConnector_ms": 0.003456711769104004, "ViewRequirementAgentConnector_ms": 0.09560286998748779}, "num_episodes": 22, "episode_return_max": 3.8799999999999617, "episode_return_min": -150.53000000000014, "episode_return_mean": -27.132199999999916, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1360000, "num_agent_steps_trained": 1360000, "num_env_steps_sampled": 340000, "num_env_steps_trained": 340000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 382.118931864587, "num_env_steps_trained_throughput_per_sec": 382.118931864587, "timesteps_total": 340000, "num_env_steps_sampled_lifetime": 340000, "num_agent_steps_sampled_lifetime": 1360000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1360000, "timers": {"training_iteration_time_ms": 178551.121, "restore_workers_time_ms": 0.013, "training_step_time_ms": 178551.081, "sample_time_ms": 1593.8, "learn_time_ms": 176936.84, "learn_throughput": 22.607, "synch_weights_time_ms": 17.707}, "counters": {"num_env_steps_sampled": 340000, "num_env_steps_trained": 340000, "num_agent_steps_sampled": 1360000, "num_agent_steps_trained": 1360000}, "done": false, "training_iteration": 85, "trial_id": "8e499_00000", "date": "2024-08-15_04-13-18", "timestamp": 1723675398, "time_this_iter_s": 10.47576117515564, "time_total_s": 7736.733003616333, "pid": 33199, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x15818dee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 7736.733003616333, "iterations_since_restore": 85, "perf": {"cpu_util_percent": 45.126666666666665, "ram_util_percent": 79.49333333333334}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.164226126166248, "cur_kl_coeff": 0.007031250000000002, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.7774442188954227, "policy_loss": -0.0034965363488823334, "vf_loss": 2.7808953807467507, "vf_explained_var": 0.020632261826247764, "kl": 0.0064534799734757, "entropy": 0.5668590947906808, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 161595.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.148757105813455, "cur_kl_coeff": 0.0421875, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.4984481132850447, "policy_loss": -0.013459788060318383, "vf_loss": 3.5111942744128917, "vf_explained_var": 0.041929514445955794, "kl": 0.016915495285541073, "entropy": 0.9534513261583116, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 161595.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 344000, "num_env_steps_trained": 344000, "num_agent_steps_sampled": 1376000, "num_agent_steps_trained": 1376000}, "env_runners": {"episode_reward_max": 3.8799999999999617, "episode_reward_min": -150.53000000000014, "episode_reward_mean": -27.963799999999942, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -303.52, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 2.0000000000000013, "predator_policy": 152.0}, "policy_reward_mean": {"prey_policy": -42.88189999999999, "predator_policy": 28.9}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-3.150000000000081, -39.570000000000434, -19.529999999999593, -47.53000000000032, -14.269999999999808, -60.64000000000061, -43.58000000000055, -1.33000000000005, -29.269999999999737, -30.749999999999854, -37.41000000000068, -25.349999999999447, 0.8500000000000002, -7.110000000000083, -54.680000000000526, -16.419999999999657, -19.199999999999406, 2.989999999999981, -21.24999999999946, -18.21999999999942, -29.289999999999647, 1.9300000000000033, -21.249999999999662, -28.329999999999444, 0.969999999999981, -25.70999999999995, -2.0700000000000696, -36.52000000000041, -38.42000000000052, -17.179999999999417, -6.110000000000081, -38.43000000000014, -20.349999999999554, -16.24999999999945, -37.55000000000002, -12.160000000000082, -58.62000000000039, -19.339999999999492, -19.599999999999696, -23.039999999999637, 1.9100000000000028, -2.120000000000081, -35.39000000000042, -46.520000000000046, 0.9599999999999836, -23.28999999999942, -21.559999999999867, -49.980000000000054, -18.2199999999995, -41.01, -42.74000000000003, -47.50999999999984, -0.16000000000003922, 3.8799999999999617, -150.53000000000014, -11.600000000000046, -18.219999999999434, -44.58000000000034, -69.06999999999978, -12.440000000000039, -2.1300000000000825, -20.310000000000066, -19.229999999999457, -116.41999999999933, -2.3100000000000307, -22.389999999999656, -5.030000000000019, -76.79999999999927, -3.5600000000000733, -91.75999999999847, -36.64000000000012, -1.4300000000000386, 0.749999999999987, -14.250000000000028, -39.43000000000071, -65.65999999999944, -8.550000000000066, -2.20000000000001, -41.71000000000059, -36.52999999999971, -35.76999999999988, -42.4600000000007, -2.1800000000000788, -31.290000000000465, -15.450000000000006, -5.17000000000008, -53.57000000000068, -30.379999999999484, -22.259999999999707, -15.24999999999961, -10.500000000000075, -127.29999999999893, -19.219999999999445, -51.420000000000705, -6.340000000000064, -30.529999999999795, -21.249999999999424, -57.61000000000041, -39.74000000000058, -12.17000000000008], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-4.030000000000037, -22.119999999999706, -20.109999999999744, -90.45999999999933, -18.09999999999983, -84.42999999999932, -100.50999999999951, -2.020000000000042, -52.27000000000029, 2.0000000000000013, -60.3100000000002, -64.32999999999915, -62.32000000000024, -50.26000000000031, -40.210000000000356, -22.119999999999767, -28.14999999999971, -22.119999999999717, -52.2700000000003, -94.47999999999941, -58.30000000000033, -20.109999999999708, -36.19000000000036, -30.15999999999975, -2.0200000000000413, -24.12999999999979, -12.070000000000041, -6.040000000000042, -50.260000000000275, -82.41999999999942, -44.23000000000022, -36.190000000000325, -24.12999999999971, -12.070000000000041, -0.00999999999999836, 2.0000000000000013, 2.0000000000000013, -48.25000000000034, -32.17000000000036, -8.050000000000042, -14.080000000000041, -40.21000000000026, 2.0000000000000013, -12.070000000000041, -30.159999999999837, -16.089999999999776, -42.22000000000035, -20.109999999999708, -4.030000000000042, 2.0000000000000013, -140.7100000000002, 2.0000000000000013, -12.070000000000041, 2.0000000000000013, -28.14999999999971, -72.36999999999948, -40.21000000000035, -40.21000000000029, -6.040000000000042, -26.13999999999971, 2.0000000000000013, -20.109999999999705, -12.070000000000034, -78.3599999999999, -14.080000000000041, -52.27000000000027, -48.25000000000035, 2.0000000000000013, -10.060000000000041, -96.48999999999975, -14.080000000000041, -14.08000000000004, -98.49999999999942, -22.119999999999706, 2.0000000000000013, -66.33999999999928, 2.0000000000000013, -118.59999999999961, -239.04000000000087, 2.0000000000000013, -16.0899999999997, 2.0000000000000013, 2.0000000000000013, -22.119999999999706, -16.0899999999997, -58.3000000000002, -34.180000000000234, -66.34000000000005, -4.03000000000004, -0.00999999999999836, -40.21000000000027, -14.080000000000041, -94.47999999999956, -14.080000000000032, -146.74000000000018, -46.24000000000035, -18.099999999999756, -22.11999999999974, -196.99, -2.020000000000042, -148.7099999999994, -4.030000000000042, -52.27000000000003, -46.24000000000018, 2.0000000000000013, -30.159999999999712, 2.0000000000000013, -22.119999999999706, -0.00999999999999836, -303.52, 2.0000000000000013, -118.59999999999964, -42.220000000000354, 2.0000000000000013, -58.30000000000034, -54.28000000000016, -40.21000000000028, -170.86000000000018, -80.40999999999973, -4.030000000000033, -22.119999999999706, -0.00999999999999836, -48.25000000000007, -10.06, -10.060000000000032, -32.17000000000033, -138.70000000000033, -142.72000000000088, -18.099999999999856, -40.210000000000136, -42.22000000000017, -32.170000000000165, -205.03000000000003, 2.0000000000000013, -84.4299999999994, -72.3700000000003, -52.23000000000013, -64.32999999999964, -90.45999999999927, -58.30000000000033, -92.46999999999966, -32.170000000000364, 2.0000000000000013, -84.42999999999981, 2.0000000000000013, -48.250000000000334, -44.23000000000022, -2.020000000000042, -40.210000000000356, -42.220000000000354, -52.27000000000009, -76.38999999999953, -60.31000000000012, -46.240000000000315, 2.0000000000000013, -38.199999999999804, -84.42999999999942, -54.28000000000034, -8.050000000000042, -94.48000000000009, -58.30000000000004, -92.46999999999993, -30.159999999999712, -58.30000000000034, -4.030000000000039, -28.14999999999971, -30.159999999999712, -24.12999999999972, -74.3799999999999, -12.070000000000041, 2.0000000000000013, -32.170000000000364, -68.34999999999916, -42.220000000000354, -18.099999999999884, -54.28000000000034, -22.119999999999717, -26.139999999999855, -48.250000000000334, 2.0000000000000013, -90.45999999999962, -6.040000000000042, -20.109999999999705, -237.19000000000074, -0.009999999999998581, -40.21000000000035, -32.17000000000033, -48.25000000000035, -52.27000000000003, -12.070000000000041, -12.070000000000041, -90.45999999999972, -28.14999999999971, -18.09999999999978, -74.37999999999936, -44.230000000000146, -134.6800000000011, -10.060000000000041, 2.0000000000000013, -32.170000000000336], "policy_predator_policy_reward": [12.0, 11.0, 38.0, 33.0, 39.0, 44.0, 42.0, 13.0, 17.0, 19.0, 10.0, 54.0, 20.0, 49.0, 30.0, 31.0, 19.0, 2.0, 59.0, 57.0, 11.0, 30.0, 11.0, 30.0, 12.0, 15.0, 7.0, 4.0, 36.0, 42.0, 25.0, 39.0, 9.0, 8.0, 0.0, 1.0, 25.0, 0.0, 6.0, 16.0, 22.0, 3.0, 5.0, 7.0, 5.0, 20.0, 14.0, 20.0, 3.0, 0.0, 47.0, 66.0, 3.0, 5.0, 42.0, 22.0, 2.0, 40.0, 14.0, 1.0, 11.0, 1.0, 51.0, 1.0, 21.0, 25.0, 8.0, 22.0, 34.0, 35.0, 16.0, 0.0, 18.0, 44.0, 17.0, 28.0, 41.0, 56.0, 113.0, 101.0, 9.0, 7.0, 12.0, 6.0, 1.0, 38.0, 47.0, 7.0, 1.0, 4.0, 12.0, 19.0, 51.0, 36.0, 67.0, 76.0, 18.0, 4.0, 71.0, 87.0, 67.0, 43.0, 5.0, 46.0, 12.0, 16.0, 12.0, 12.0, 152.0, 1.0, 54.0, 51.0, 22.0, 0.0, 33.0, 35.0, 67.0, 75.0, 33.0, 39.0, 9.0, 11.0, 17.0, 21.0, 22.0, 1.0, 66.0, 99.0, 26.0, 30.0, 21.0, 31.0, 99.0, 99.0, 43.0, 37.0, 61.0, 52.0, 57.0, 0.0, 30.0, 58.0, 40.0, 41.0, 25.0, 22.0, 23.0, 9.0, 17.0, 26.0, 16.0, 47.0, 49.0, 49.0, 18.0, 16.0, 58.0, 39.0, 38.0, 28.0, 63.0, 52.0, 16.0, 30.0, 14.0, 16.0, 20.0, 3.0, 35.0, 36.0, 11.0, 14.0, 22.0, 35.0, 5.0, 37.0, 12.0, 14.0, 14.0, 17.0, 45.0, 41.0, 11.0, 119.0, 9.0, 12.0, 0.0, 29.0, 27.0, 31.0, 35.0, 37.0, 20.0, 5.0, 44.0, 17.0, 57.0, 48.0, 7.0, 11.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 6.296201833664758, "mean_inference_ms": 18.221889755822545, "mean_action_processing_ms": 0.2687000849882963, "mean_env_wait_ms": 2.901401379613809, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0036493539810180664, "StateBufferConnector_ms": 0.00312197208404541, "ViewRequirementAgentConnector_ms": 0.0961376428604126}, "num_episodes": 18, "episode_return_max": 3.8799999999999617, "episode_return_min": -150.53000000000014, "episode_return_mean": -27.963799999999942, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1376000, "num_agent_steps_trained": 1376000, "num_env_steps_sampled": 344000, "num_env_steps_trained": 344000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 404.2108704123428, "num_env_steps_trained_throughput_per_sec": 404.2108704123428, "timesteps_total": 344000, "num_env_steps_sampled_lifetime": 344000, "num_agent_steps_sampled_lifetime": 1376000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1376000, "timers": {"training_iteration_time_ms": 178361.411, "restore_workers_time_ms": 0.013, "training_step_time_ms": 178361.371, "sample_time_ms": 1530.832, "learn_time_ms": 176810.594, "learn_throughput": 22.623, "synch_weights_time_ms": 17.356}, "counters": {"num_env_steps_sampled": 344000, "num_env_steps_trained": 344000, "num_agent_steps_sampled": 1376000, "num_agent_steps_trained": 1376000}, "done": false, "training_iteration": 86, "trial_id": "8e499_00000", "date": "2024-08-15_04-13-28", "timestamp": 1723675408, "time_this_iter_s": 9.89970874786377, "time_total_s": 7746.632712364197, "pid": 33199, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x15819caf0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 7746.632712364197, "iterations_since_restore": 86, "perf": {"cpu_util_percent": 41.857142857142854, "ram_util_percent": 80.27857142857142}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4241619747467142, "cur_kl_coeff": 0.007031250000000002, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.7474415247402495, "policy_loss": -0.0036280187148669805, "vf_loss": 1.7510242228154782, "vf_explained_var": 0.019025539689593845, "kl": 0.0064449862554437215, "entropy": 0.5446275809769908, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 163485.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.285691979732463, "cur_kl_coeff": 0.0421875, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.5104348850155633, "policy_loss": -0.008609962778870588, "vf_loss": 1.5185386002063752, "vf_explained_var": 0.04032600443199198, "kl": 0.011999907182492293, "entropy": 1.04793907303028, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 163485.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 348000, "num_env_steps_trained": 348000, "num_agent_steps_sampled": 1392000, "num_agent_steps_trained": 1392000}, "env_runners": {"episode_reward_max": 3.9999999999999587, "episode_reward_min": -150.53000000000014, "episode_reward_mean": -26.58189999999994, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -303.52, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 2.0000000000000013, "predator_policy": 152.0}, "policy_reward_mean": {"prey_policy": -42.690950000000015, "predator_policy": 29.4}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-28.329999999999444, 0.969999999999981, -25.70999999999995, -2.0700000000000696, -36.52000000000041, -38.42000000000052, -17.179999999999417, -6.110000000000081, -38.43000000000014, -20.349999999999554, -16.24999999999945, -37.55000000000002, -12.160000000000082, -58.62000000000039, -19.339999999999492, -19.599999999999696, -23.039999999999637, 1.9100000000000028, -2.120000000000081, -35.39000000000042, -46.520000000000046, 0.9599999999999836, -23.28999999999942, -21.559999999999867, -49.980000000000054, -18.2199999999995, -41.01, -42.74000000000003, -47.50999999999984, -0.16000000000003922, 3.8799999999999617, -150.53000000000014, -11.600000000000046, -18.219999999999434, -44.58000000000034, -69.06999999999978, -12.440000000000039, -2.1300000000000825, -20.310000000000066, -19.229999999999457, -116.41999999999933, -2.3100000000000307, -22.389999999999656, -5.030000000000019, -76.79999999999927, -3.5600000000000733, -91.75999999999847, -36.64000000000012, -1.4300000000000386, 0.749999999999987, -14.250000000000028, -39.43000000000071, -65.65999999999944, -8.550000000000066, -2.20000000000001, -41.71000000000059, -36.52999999999971, -35.76999999999988, -42.4600000000007, -2.1800000000000788, -31.290000000000465, -15.450000000000006, -5.17000000000008, -53.57000000000068, -30.379999999999484, -22.259999999999707, -15.24999999999961, -10.500000000000075, -127.29999999999893, -19.219999999999445, -51.420000000000705, -6.340000000000064, -30.529999999999795, -21.249999999999424, -57.61000000000041, -39.74000000000058, -12.17000000000008, -4.260000000000077, -0.04000000000004011, -13.26999999999995, -20.239999999999423, -56.01000000000037, -28.33999999999943, 2.949999999999982, -1.5100000000000617, -29.329999999999668, -7.110000000000083, -31.35000000000041, -58.62000000000055, -1.2000000000000455, 3.9999999999999587, -20.469999999999715, 0.9699999999999828, -1.5400000000000538, -64.67999999999935, -29.389999999999596, -5.110000000000083, -3.0700000000000838, -6.100000000000078, -22.119999999999816], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-42.22000000000035, -20.109999999999708, -4.030000000000042, 2.0000000000000013, -140.7100000000002, 2.0000000000000013, -12.070000000000041, 2.0000000000000013, -28.14999999999971, -72.36999999999948, -40.21000000000035, -40.21000000000029, -6.040000000000042, -26.13999999999971, 2.0000000000000013, -20.109999999999705, -12.070000000000034, -78.3599999999999, -14.080000000000041, -52.27000000000027, -48.25000000000035, 2.0000000000000013, -10.060000000000041, -96.48999999999975, -14.080000000000041, -14.08000000000004, -98.49999999999942, -22.119999999999706, 2.0000000000000013, -66.33999999999928, 2.0000000000000013, -118.59999999999961, -239.04000000000087, 2.0000000000000013, -16.0899999999997, 2.0000000000000013, 2.0000000000000013, -22.119999999999706, -16.0899999999997, -58.3000000000002, -34.180000000000234, -66.34000000000005, -4.03000000000004, -0.00999999999999836, -40.21000000000027, -14.080000000000041, -94.47999999999956, -14.080000000000032, -146.74000000000018, -46.24000000000035, -18.099999999999756, -22.11999999999974, -196.99, -2.020000000000042, -148.7099999999994, -4.030000000000042, -52.27000000000003, -46.24000000000018, 2.0000000000000013, -30.159999999999712, 2.0000000000000013, -22.119999999999706, -0.00999999999999836, -303.52, 2.0000000000000013, -118.59999999999964, -42.220000000000354, 2.0000000000000013, -58.30000000000034, -54.28000000000016, -40.21000000000028, -170.86000000000018, -80.40999999999973, -4.030000000000033, -22.119999999999706, -0.00999999999999836, -48.25000000000007, -10.06, -10.060000000000032, -32.17000000000033, -138.70000000000033, -142.72000000000088, -18.099999999999856, -40.210000000000136, -42.22000000000017, -32.170000000000165, -205.03000000000003, 2.0000000000000013, -84.4299999999994, -72.3700000000003, -52.23000000000013, -64.32999999999964, -90.45999999999927, -58.30000000000033, -92.46999999999966, -32.170000000000364, 2.0000000000000013, -84.42999999999981, 2.0000000000000013, -48.250000000000334, -44.23000000000022, -2.020000000000042, -40.210000000000356, -42.220000000000354, -52.27000000000009, -76.38999999999953, -60.31000000000012, -46.240000000000315, 2.0000000000000013, -38.199999999999804, -84.42999999999942, -54.28000000000034, -8.050000000000042, -94.48000000000009, -58.30000000000004, -92.46999999999993, -30.159999999999712, -58.30000000000034, -4.030000000000039, -28.14999999999971, -30.159999999999712, -24.12999999999972, -74.3799999999999, -12.070000000000041, 2.0000000000000013, -32.170000000000364, -68.34999999999916, -42.220000000000354, -18.099999999999884, -54.28000000000034, -22.119999999999717, -26.139999999999855, -48.250000000000334, 2.0000000000000013, -90.45999999999962, -6.040000000000042, -20.109999999999705, -237.19000000000074, -0.009999999999998581, -40.21000000000035, -32.17000000000033, -48.25000000000035, -52.27000000000003, -12.070000000000041, -12.070000000000041, -90.45999999999972, -28.14999999999971, -18.09999999999978, -74.37999999999936, -44.230000000000146, -134.6800000000011, -10.060000000000041, 2.0000000000000013, -32.170000000000336, 2.0000000000000013, -50.260000000000026, 2.0000000000000013, -6.040000000000042, -12.070000000000041, -38.200000000000344, -8.050000000000042, -36.19000000000036, -64.32999999999954, -134.68000000000092, -28.14999999999971, -36.19000000000036, -8.050000000000042, 2.0000000000000013, -100.50999999999927, 2.0000000000000013, -62.320000000000334, -0.00999999999999836, -20.109999999999705, 2.0000000000000013, -26.13999999999974, -40.210000000000356, 2.0000000000000013, -122.61999999999934, 2.0000000000000013, -38.20000000000029, 2.0000000000000013, 2.0000000000000013, -62.320000000000334, -28.149999999999842, 2.0000000000000013, -4.030000000000041, 2.0000000000000013, -106.5399999999993, -132.67000000000053, -0.009999999999998581, -72.3699999999993, -2.0200000000000267, 2.0000000000000013, -20.109999999999708, -10.060000000000041, -0.00999999999999836, -18.099999999999728, 2.0000000000000013, -6.040000000000042, -215.08000000000084], "policy_predator_policy_reward": [14.0, 20.0, 3.0, 0.0, 47.0, 66.0, 3.0, 5.0, 42.0, 22.0, 2.0, 40.0, 14.0, 1.0, 11.0, 1.0, 51.0, 1.0, 21.0, 25.0, 8.0, 22.0, 34.0, 35.0, 16.0, 0.0, 18.0, 44.0, 17.0, 28.0, 41.0, 56.0, 113.0, 101.0, 9.0, 7.0, 12.0, 6.0, 1.0, 38.0, 47.0, 7.0, 1.0, 4.0, 12.0, 19.0, 51.0, 36.0, 67.0, 76.0, 18.0, 4.0, 71.0, 87.0, 67.0, 43.0, 5.0, 46.0, 12.0, 16.0, 12.0, 12.0, 152.0, 1.0, 54.0, 51.0, 22.0, 0.0, 33.0, 35.0, 67.0, 75.0, 33.0, 39.0, 9.0, 11.0, 17.0, 21.0, 22.0, 1.0, 66.0, 99.0, 26.0, 30.0, 21.0, 31.0, 99.0, 99.0, 43.0, 37.0, 61.0, 52.0, 57.0, 0.0, 30.0, 58.0, 40.0, 41.0, 25.0, 22.0, 23.0, 9.0, 17.0, 26.0, 16.0, 47.0, 49.0, 49.0, 18.0, 16.0, 58.0, 39.0, 38.0, 28.0, 63.0, 52.0, 16.0, 30.0, 14.0, 16.0, 20.0, 3.0, 35.0, 36.0, 11.0, 14.0, 22.0, 35.0, 5.0, 37.0, 12.0, 14.0, 14.0, 17.0, 45.0, 41.0, 11.0, 119.0, 9.0, 12.0, 0.0, 29.0, 27.0, 31.0, 35.0, 37.0, 20.0, 5.0, 44.0, 17.0, 57.0, 48.0, 7.0, 11.0, 23.0, 21.0, 0.0, 4.0, 21.0, 16.0, 13.0, 11.0, 72.0, 71.0, 18.0, 18.0, 5.0, 4.0, 48.0, 49.0, 1.0, 32.0, 0.0, 11.0, 30.0, 5.0, 18.0, 44.0, 17.0, 18.0, 0.0, 0.0, 46.0, 24.0, 0.0, 3.0, 51.0, 52.0, 68.0, 0.0, 36.0, 9.0, 7.0, 6.0, 7.0, 0.0, 10.0, 0.0, 101.0, 98.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 6.219701256667978, "mean_inference_ms": 17.987299444529075, "mean_action_processing_ms": 0.2681916796386185, "mean_env_wait_ms": 2.872223821183273, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003653883934020996, "StateBufferConnector_ms": 0.0030922889709472656, "ViewRequirementAgentConnector_ms": 0.09947562217712402}, "num_episodes": 23, "episode_return_max": 3.9999999999999587, "episode_return_min": -150.53000000000014, "episode_return_mean": -26.58189999999994, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1392000, "num_agent_steps_trained": 1392000, "num_env_steps_sampled": 348000, "num_env_steps_trained": 348000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 388.86734208386775, "num_env_steps_trained_throughput_per_sec": 388.86734208386775, "timesteps_total": 348000, "num_env_steps_sampled_lifetime": 348000, "num_agent_steps_sampled_lifetime": 1392000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1392000, "timers": {"training_iteration_time_ms": 178237.319, "restore_workers_time_ms": 0.013, "training_step_time_ms": 178237.279, "sample_time_ms": 1450.535, "learn_time_ms": 176766.772, "learn_throughput": 22.629, "synch_weights_time_ms": 17.224}, "counters": {"num_env_steps_sampled": 348000, "num_env_steps_trained": 348000, "num_agent_steps_sampled": 1392000, "num_agent_steps_trained": 1392000}, "done": false, "training_iteration": 87, "trial_id": "8e499_00000", "date": "2024-08-15_04-13-38", "timestamp": 1723675418, "time_this_iter_s": 10.33490800857544, "time_total_s": 7756.967620372772, "pid": 33199, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x1580efb80>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 7756.967620372772, "iterations_since_restore": 87, "perf": {"cpu_util_percent": 40.57333333333334, "ram_util_percent": 80.96666666666665}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4203839562399678, "cur_kl_coeff": 0.007031250000000002, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.1210419808746015, "policy_loss": -0.0053633146505388946, "vf_loss": 1.1263434673112536, "vf_explained_var": 0.02998479371348386, "kl": 0.008793278866329591, "entropy": 0.5521210970386626, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 165375.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.596533601624625, "cur_kl_coeff": 0.0421875, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.0310253312624005, "policy_loss": -0.012575260481289612, "vf_loss": 1.0427596197241829, "vf_explained_var": 0.009014798377556775, "kl": 0.019934140376464442, "entropy": 1.060310939758543, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 165375.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 352000, "num_env_steps_trained": 352000, "num_agent_steps_sampled": 1408000, "num_agent_steps_trained": 1408000}, "env_runners": {"episode_reward_max": 3.9999999999999587, "episode_reward_min": -234.69000000000182, "episode_reward_mean": -26.365399999999962, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -303.52, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 2.0000000000000013, "predator_policy": 152.0}, "policy_reward_mean": {"prey_policy": -40.83270000000003, "predator_policy": 27.65}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-2.120000000000081, -35.39000000000042, -46.520000000000046, 0.9599999999999836, -23.28999999999942, -21.559999999999867, -49.980000000000054, -18.2199999999995, -41.01, -42.74000000000003, -47.50999999999984, -0.16000000000003922, 3.8799999999999617, -150.53000000000014, -11.600000000000046, -18.219999999999434, -44.58000000000034, -69.06999999999978, -12.440000000000039, -2.1300000000000825, -20.310000000000066, -19.229999999999457, -116.41999999999933, -2.3100000000000307, -22.389999999999656, -5.030000000000019, -76.79999999999927, -3.5600000000000733, -91.75999999999847, -36.64000000000012, -1.4300000000000386, 0.749999999999987, -14.250000000000028, -39.43000000000071, -65.65999999999944, -8.550000000000066, -2.20000000000001, -41.71000000000059, -36.52999999999971, -35.76999999999988, -42.4600000000007, -2.1800000000000788, -31.290000000000465, -15.450000000000006, -5.17000000000008, -53.57000000000068, -30.379999999999484, -22.259999999999707, -15.24999999999961, -10.500000000000075, -127.29999999999893, -19.219999999999445, -51.420000000000705, -6.340000000000064, -30.529999999999795, -21.249999999999424, -57.61000000000041, -39.74000000000058, -12.17000000000008, -4.260000000000077, -0.04000000000004011, -13.26999999999995, -20.239999999999423, -56.01000000000037, -28.33999999999943, 2.949999999999982, -1.5100000000000617, -29.329999999999668, -7.110000000000083, -31.35000000000041, -58.62000000000055, -1.2000000000000455, 3.9999999999999587, -20.469999999999715, 0.9699999999999828, -1.5400000000000538, -64.67999999999935, -29.389999999999596, -5.110000000000083, -3.0700000000000838, -6.100000000000078, -22.119999999999816, -25.67999999999969, -3.0700000000000838, 1.9400000000000026, -0.050000000000041, -14.149999999999736, -234.69000000000182, -3.0900000000000833, -3.1200000000000827, -1.1700000000000597, -14.209999999999763, 2.9799999999999813, 1.960000000000003, -17.30999999999947, -54.750000000000355, 0.6099999999999869, -10.25000000000008, -5.100000000000083, 3.9999999999999587], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [2.0000000000000013, -22.119999999999706, -16.0899999999997, -58.3000000000002, -34.180000000000234, -66.34000000000005, -4.03000000000004, -0.00999999999999836, -40.21000000000027, -14.080000000000041, -94.47999999999956, -14.080000000000032, -146.74000000000018, -46.24000000000035, -18.099999999999756, -22.11999999999974, -196.99, -2.020000000000042, -148.7099999999994, -4.030000000000042, -52.27000000000003, -46.24000000000018, 2.0000000000000013, -30.159999999999712, 2.0000000000000013, -22.119999999999706, -0.00999999999999836, -303.52, 2.0000000000000013, -118.59999999999964, -42.220000000000354, 2.0000000000000013, -58.30000000000034, -54.28000000000016, -40.21000000000028, -170.86000000000018, -80.40999999999973, -4.030000000000033, -22.119999999999706, -0.00999999999999836, -48.25000000000007, -10.06, -10.060000000000032, -32.17000000000033, -138.70000000000033, -142.72000000000088, -18.099999999999856, -40.210000000000136, -42.22000000000017, -32.170000000000165, -205.03000000000003, 2.0000000000000013, -84.4299999999994, -72.3700000000003, -52.23000000000013, -64.32999999999964, -90.45999999999927, -58.30000000000033, -92.46999999999966, -32.170000000000364, 2.0000000000000013, -84.42999999999981, 2.0000000000000013, -48.250000000000334, -44.23000000000022, -2.020000000000042, -40.210000000000356, -42.220000000000354, -52.27000000000009, -76.38999999999953, -60.31000000000012, -46.240000000000315, 2.0000000000000013, -38.199999999999804, -84.42999999999942, -54.28000000000034, -8.050000000000042, -94.48000000000009, -58.30000000000004, -92.46999999999993, -30.159999999999712, -58.30000000000034, -4.030000000000039, -28.14999999999971, -30.159999999999712, -24.12999999999972, -74.3799999999999, -12.070000000000041, 2.0000000000000013, -32.170000000000364, -68.34999999999916, -42.220000000000354, -18.099999999999884, -54.28000000000034, -22.119999999999717, -26.139999999999855, -48.250000000000334, 2.0000000000000013, -90.45999999999962, -6.040000000000042, -20.109999999999705, -237.19000000000074, -0.009999999999998581, -40.21000000000035, -32.17000000000033, -48.25000000000035, -52.27000000000003, -12.070000000000041, -12.070000000000041, -90.45999999999972, -28.14999999999971, -18.09999999999978, -74.37999999999936, -44.230000000000146, -134.6800000000011, -10.060000000000041, 2.0000000000000013, -32.170000000000336, 2.0000000000000013, -50.260000000000026, 2.0000000000000013, -6.040000000000042, -12.070000000000041, -38.200000000000344, -8.050000000000042, -36.19000000000036, -64.32999999999954, -134.68000000000092, -28.14999999999971, -36.19000000000036, -8.050000000000042, 2.0000000000000013, -100.50999999999927, 2.0000000000000013, -62.320000000000334, -0.00999999999999836, -20.109999999999705, 2.0000000000000013, -26.13999999999974, -40.210000000000356, 2.0000000000000013, -122.61999999999934, 2.0000000000000013, -38.20000000000029, 2.0000000000000013, 2.0000000000000013, -62.320000000000334, -28.149999999999842, 2.0000000000000013, -4.030000000000041, 2.0000000000000013, -106.5399999999993, -132.67000000000053, -0.009999999999998581, -72.3699999999993, -2.0200000000000267, 2.0000000000000013, -20.109999999999708, -10.060000000000041, -0.00999999999999836, -18.099999999999728, 2.0000000000000013, -6.040000000000042, -215.08000000000084, 2.0000000000000013, -134.68000000000052, -8.050000000000042, -2.020000000000042, -10.060000000000041, 2.0000000000000013, -8.050000000000042, 2.0000000000000013, -10.060000000000041, -16.0899999999997, -146.74000000000095, -188.9500000000009, -2.020000000000042, -12.070000000000041, -22.119999999999706, 2.0000000000000013, -8.050000000000042, -22.11999999999972, 2.0000000000000013, -40.210000000000356, -2.020000000000042, 2.0000000000000013, -6.040000000000042, 2.0000000000000013, -60.31000000000033, 2.0000000000000013, -148.7500000000005, 2.0000000000000013, -32.17000000000036, -42.220000000000304, -48.25000000000035, 2.0000000000000013, -18.099999999999707, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013], "policy_predator_policy_reward": [12.0, 6.0, 1.0, 38.0, 47.0, 7.0, 1.0, 4.0, 12.0, 19.0, 51.0, 36.0, 67.0, 76.0, 18.0, 4.0, 71.0, 87.0, 67.0, 43.0, 5.0, 46.0, 12.0, 16.0, 12.0, 12.0, 152.0, 1.0, 54.0, 51.0, 22.0, 0.0, 33.0, 35.0, 67.0, 75.0, 33.0, 39.0, 9.0, 11.0, 17.0, 21.0, 22.0, 1.0, 66.0, 99.0, 26.0, 30.0, 21.0, 31.0, 99.0, 99.0, 43.0, 37.0, 61.0, 52.0, 57.0, 0.0, 30.0, 58.0, 40.0, 41.0, 25.0, 22.0, 23.0, 9.0, 17.0, 26.0, 16.0, 47.0, 49.0, 49.0, 18.0, 16.0, 58.0, 39.0, 38.0, 28.0, 63.0, 52.0, 16.0, 30.0, 14.0, 16.0, 20.0, 3.0, 35.0, 36.0, 11.0, 14.0, 22.0, 35.0, 5.0, 37.0, 12.0, 14.0, 14.0, 17.0, 45.0, 41.0, 11.0, 119.0, 9.0, 12.0, 0.0, 29.0, 27.0, 31.0, 35.0, 37.0, 20.0, 5.0, 44.0, 17.0, 57.0, 48.0, 7.0, 11.0, 23.0, 21.0, 0.0, 4.0, 21.0, 16.0, 13.0, 11.0, 72.0, 71.0, 18.0, 18.0, 5.0, 4.0, 48.0, 49.0, 1.0, 32.0, 0.0, 11.0, 30.0, 5.0, 18.0, 44.0, 17.0, 18.0, 0.0, 0.0, 46.0, 24.0, 0.0, 3.0, 51.0, 52.0, 68.0, 0.0, 36.0, 9.0, 7.0, 6.0, 7.0, 0.0, 10.0, 0.0, 101.0, 98.0, 50.0, 57.0, 5.0, 2.0, 6.0, 4.0, 5.0, 1.0, 3.0, 9.0, 6.0, 95.0, 6.0, 5.0, 12.0, 5.0, 14.0, 15.0, 21.0, 3.0, 2.0, 1.0, 4.0, 2.0, 31.0, 10.0, 32.0, 60.0, 38.0, 37.0, 24.0, 12.0, 4.0, 7.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 6.159822246991806, "mean_inference_ms": 17.81629851573479, "mean_action_processing_ms": 0.267906976894476, "mean_env_wait_ms": 2.8439503586740575, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00388181209564209, "StateBufferConnector_ms": 0.0031987428665161133, "ViewRequirementAgentConnector_ms": 0.10852885246276855}, "num_episodes": 18, "episode_return_max": 3.9999999999999587, "episode_return_min": -234.69000000000182, "episode_return_mean": -26.365399999999962, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1408000, "num_agent_steps_trained": 1408000, "num_env_steps_sampled": 352000, "num_env_steps_trained": 352000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 383.32866012124515, "num_env_steps_trained_throughput_per_sec": 383.32866012124515, "timesteps_total": 352000, "num_env_steps_sampled_lifetime": 352000, "num_agent_steps_sampled_lifetime": 1408000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1408000, "timers": {"training_iteration_time_ms": 84177.142, "restore_workers_time_ms": 0.013, "training_step_time_ms": 84177.102, "sample_time_ms": 1477.221, "learn_time_ms": 82681.207, "learn_throughput": 48.379, "synch_weights_time_ms": 16.109}, "counters": {"num_env_steps_sampled": 352000, "num_env_steps_trained": 352000, "num_agent_steps_sampled": 1408000, "num_agent_steps_trained": 1408000}, "done": false, "training_iteration": 88, "trial_id": "8e499_00000", "date": "2024-08-15_04-13-49", "timestamp": 1723675429, "time_this_iter_s": 10.490848064422607, "time_total_s": 7767.458468437195, "pid": 33199, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x1580f80d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 7767.458468437195, "iterations_since_restore": 88, "perf": {"cpu_util_percent": 42.56666666666668, "ram_util_percent": 81.68}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4394419324461114, "cur_kl_coeff": 0.007031250000000002, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.0746229596869656, "policy_loss": -0.004709738498878857, "vf_loss": 3.0792814299543068, "vf_explained_var": 0.08491183011620133, "kl": 0.007291143779757361, "entropy": 0.5183636897455448, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 167265.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2574968171498133, "cur_kl_coeff": 0.0421875, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.694659954151779, "policy_loss": -0.006427954103571003, "vf_loss": 3.700738889452011, "vf_explained_var": 0.015275226225928655, "kl": 0.008273245959812643, "entropy": 1.071115834025479, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 167265.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 356000, "num_env_steps_trained": 356000, "num_agent_steps_sampled": 1424000, "num_agent_steps_trained": 1424000}, "env_runners": {"episode_reward_max": 3.9999999999999587, "episode_reward_min": -346.06000000000023, "episode_reward_mean": -32.79509999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -335.68000000000023, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 2.0000000000000013, "predator_policy": 182.0}, "policy_reward_mean": {"prey_policy": -43.81755000000001, "predator_policy": 27.42}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-116.41999999999933, -2.3100000000000307, -22.389999999999656, -5.030000000000019, -76.79999999999927, -3.5600000000000733, -91.75999999999847, -36.64000000000012, -1.4300000000000386, 0.749999999999987, -14.250000000000028, -39.43000000000071, -65.65999999999944, -8.550000000000066, -2.20000000000001, -41.71000000000059, -36.52999999999971, -35.76999999999988, -42.4600000000007, -2.1800000000000788, -31.290000000000465, -15.450000000000006, -5.17000000000008, -53.57000000000068, -30.379999999999484, -22.259999999999707, -15.24999999999961, -10.500000000000075, -127.29999999999893, -19.219999999999445, -51.420000000000705, -6.340000000000064, -30.529999999999795, -21.249999999999424, -57.61000000000041, -39.74000000000058, -12.17000000000008, -4.260000000000077, -0.04000000000004011, -13.26999999999995, -20.239999999999423, -56.01000000000037, -28.33999999999943, 2.949999999999982, -1.5100000000000617, -29.329999999999668, -7.110000000000083, -31.35000000000041, -58.62000000000055, -1.2000000000000455, 3.9999999999999587, -20.469999999999715, 0.9699999999999828, -1.5400000000000538, -64.67999999999935, -29.389999999999596, -5.110000000000083, -3.0700000000000838, -6.100000000000078, -22.119999999999816, -25.67999999999969, -3.0700000000000838, 1.9400000000000026, -0.050000000000041, -14.149999999999736, -234.69000000000182, -3.0900000000000833, -3.1200000000000827, -1.1700000000000597, -14.209999999999763, 2.9799999999999813, 1.960000000000003, -17.30999999999947, -54.750000000000355, 0.6099999999999869, -10.25000000000008, -5.100000000000083, 3.9999999999999587, -15.459999999999644, -29.619999999999525, -60.47000000000037, -22.259999999999977, -35.670000000000364, -29.329999999999732, -0.040000000000040996, -52.5800000000006, -38.42000000000058, -11.15000000000008, -127.32999999999922, -165.24000000000106, -29.439999999999692, 3.9699999999999593, -33.37000000000005, -51.44999999999986, -29.329999999999703, -1.270000000000058, -7.360000000000076, -346.06000000000023, -48.38999999999987, -184.46999999999974], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-138.70000000000033, -142.72000000000088, -18.099999999999856, -40.210000000000136, -42.22000000000017, -32.170000000000165, -205.03000000000003, 2.0000000000000013, -84.4299999999994, -72.3700000000003, -52.23000000000013, -64.32999999999964, -90.45999999999927, -58.30000000000033, -92.46999999999966, -32.170000000000364, 2.0000000000000013, -84.42999999999981, 2.0000000000000013, -48.250000000000334, -44.23000000000022, -2.020000000000042, -40.210000000000356, -42.220000000000354, -52.27000000000009, -76.38999999999953, -60.31000000000012, -46.240000000000315, 2.0000000000000013, -38.199999999999804, -84.42999999999942, -54.28000000000034, -8.050000000000042, -94.48000000000009, -58.30000000000004, -92.46999999999993, -30.159999999999712, -58.30000000000034, -4.030000000000039, -28.14999999999971, -30.159999999999712, -24.12999999999972, -74.3799999999999, -12.070000000000041, 2.0000000000000013, -32.170000000000364, -68.34999999999916, -42.220000000000354, -18.099999999999884, -54.28000000000034, -22.119999999999717, -26.139999999999855, -48.250000000000334, 2.0000000000000013, -90.45999999999962, -6.040000000000042, -20.109999999999705, -237.19000000000074, -0.009999999999998581, -40.21000000000035, -32.17000000000033, -48.25000000000035, -52.27000000000003, -12.070000000000041, -12.070000000000041, -90.45999999999972, -28.14999999999971, -18.09999999999978, -74.37999999999936, -44.230000000000146, -134.6800000000011, -10.060000000000041, 2.0000000000000013, -32.170000000000336, 2.0000000000000013, -50.260000000000026, 2.0000000000000013, -6.040000000000042, -12.070000000000041, -38.200000000000344, -8.050000000000042, -36.19000000000036, -64.32999999999954, -134.68000000000092, -28.14999999999971, -36.19000000000036, -8.050000000000042, 2.0000000000000013, -100.50999999999927, 2.0000000000000013, -62.320000000000334, -0.00999999999999836, -20.109999999999705, 2.0000000000000013, -26.13999999999974, -40.210000000000356, 2.0000000000000013, -122.61999999999934, 2.0000000000000013, -38.20000000000029, 2.0000000000000013, 2.0000000000000013, -62.320000000000334, -28.149999999999842, 2.0000000000000013, -4.030000000000041, 2.0000000000000013, -106.5399999999993, -132.67000000000053, -0.009999999999998581, -72.3699999999993, -2.0200000000000267, 2.0000000000000013, -20.109999999999708, -10.060000000000041, -0.00999999999999836, -18.099999999999728, 2.0000000000000013, -6.040000000000042, -215.08000000000084, 2.0000000000000013, -134.68000000000052, -8.050000000000042, -2.020000000000042, -10.060000000000041, 2.0000000000000013, -8.050000000000042, 2.0000000000000013, -10.060000000000041, -16.0899999999997, -146.74000000000095, -188.9500000000009, -2.020000000000042, -12.070000000000041, -22.119999999999706, 2.0000000000000013, -8.050000000000042, -22.11999999999972, 2.0000000000000013, -40.210000000000356, -2.020000000000042, 2.0000000000000013, -6.040000000000042, 2.0000000000000013, -60.31000000000033, 2.0000000000000013, -148.7500000000005, 2.0000000000000013, -32.17000000000036, -42.220000000000304, -48.25000000000035, 2.0000000000000013, -18.099999999999707, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, -90.45999999999928, 2.0000000000000013, -14.080000000000041, -106.53999999999932, -38.20000000000018, -52.2700000000002, -16.089999999999996, -32.17000000000032, -132.66999999999953, 2.0000000000000013, -18.099999999999703, -44.23000000000035, -6.040000000000042, 2.0000000000000013, -92.46999999999929, -20.109999999999705, -80.40999999999926, -0.00999999999999836, -6.040000000000042, -20.110000000000035, -28.14999999999971, -243.18000000000046, -156.79000000000053, -88.4499999999997, -68.34999999999918, -16.0899999999997, -4.030000000000042, 2.0000000000000013, -52.270000000000124, -18.099999999999703, -24.129999999999946, -62.32000000000033, -6.040000000000042, -56.29000000000034, -52.270000000000344, 2.0000000000000013, 2.0000000000000013, -70.35999999999935, -335.68000000000023, -275.38000000000017, -30.16000000000001, -44.22999999999973, -128.65000000000003, -162.82000000000025], "policy_predator_policy_reward": [66.0, 99.0, 26.0, 30.0, 21.0, 31.0, 99.0, 99.0, 43.0, 37.0, 61.0, 52.0, 57.0, 0.0, 30.0, 58.0, 40.0, 41.0, 25.0, 22.0, 23.0, 9.0, 17.0, 26.0, 16.0, 47.0, 49.0, 49.0, 18.0, 16.0, 58.0, 39.0, 38.0, 28.0, 63.0, 52.0, 16.0, 30.0, 14.0, 16.0, 20.0, 3.0, 35.0, 36.0, 11.0, 14.0, 22.0, 35.0, 5.0, 37.0, 12.0, 14.0, 14.0, 17.0, 45.0, 41.0, 11.0, 119.0, 9.0, 12.0, 0.0, 29.0, 27.0, 31.0, 35.0, 37.0, 20.0, 5.0, 44.0, 17.0, 57.0, 48.0, 7.0, 11.0, 23.0, 21.0, 0.0, 4.0, 21.0, 16.0, 13.0, 11.0, 72.0, 71.0, 18.0, 18.0, 5.0, 4.0, 48.0, 49.0, 1.0, 32.0, 0.0, 11.0, 30.0, 5.0, 18.0, 44.0, 17.0, 18.0, 0.0, 0.0, 46.0, 24.0, 0.0, 3.0, 51.0, 52.0, 68.0, 0.0, 36.0, 9.0, 7.0, 6.0, 7.0, 0.0, 10.0, 0.0, 101.0, 98.0, 50.0, 57.0, 5.0, 2.0, 6.0, 4.0, 5.0, 1.0, 3.0, 9.0, 6.0, 95.0, 6.0, 5.0, 12.0, 5.0, 14.0, 15.0, 21.0, 3.0, 2.0, 1.0, 4.0, 2.0, 31.0, 10.0, 32.0, 60.0, 38.0, 37.0, 24.0, 12.0, 4.0, 7.0, 0.0, 0.0, 42.0, 31.0, 48.0, 43.0, 4.0, 26.0, 23.0, 3.0, 53.0, 42.0, 23.0, 10.0, 4.0, 0.0, 35.0, 25.0, 2.0, 40.0, 9.0, 6.0, 15.0, 129.0, 75.0, 5.0, 34.0, 21.0, 3.0, 3.0, 27.0, 10.0, 23.0, 12.0, 29.0, 4.0, 25.0, 24.0, 31.0, 30.0, 182.0, 83.0, 12.0, 14.0, 26.0, 81.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 5.361845661974257, "mean_inference_ms": 18.10971925677188, "mean_action_processing_ms": 0.26706583402187956, "mean_env_wait_ms": 3.047083620874128, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003991603851318359, "StateBufferConnector_ms": 0.003039121627807617, "ViewRequirementAgentConnector_ms": 0.10036754608154297}, "num_episodes": 22, "episode_return_max": 3.9999999999999587, "episode_return_min": -346.06000000000023, "episode_return_mean": -32.79509999999999, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1424000, "num_agent_steps_trained": 1424000, "num_env_steps_sampled": 356000, "num_env_steps_trained": 356000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 382.1590228481093, "num_env_steps_trained_throughput_per_sec": 382.1590228481093, "timesteps_total": 356000, "num_env_steps_sampled_lifetime": 356000, "num_agent_steps_sampled_lifetime": 1424000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1424000, "timers": {"training_iteration_time_ms": 83793.276, "restore_workers_time_ms": 0.013, "training_step_time_ms": 83793.236, "sample_time_ms": 1376.28, "learn_time_ms": 82400.416, "learn_throughput": 48.543, "synch_weights_time_ms": 14.336}, "counters": {"num_env_steps_sampled": 356000, "num_env_steps_trained": 356000, "num_agent_steps_sampled": 1424000, "num_agent_steps_trained": 1424000}, "done": false, "training_iteration": 89, "trial_id": "8e499_00000", "date": "2024-08-15_04-13-59", "timestamp": 1723675439, "time_this_iter_s": 10.508705139160156, "time_total_s": 7777.967173576355, "pid": 33199, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x1580dd310>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 7777.967173576355, "iterations_since_restore": 89, "perf": {"cpu_util_percent": 41.00666666666667, "ram_util_percent": 81.63333333333335}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.175051625033535, "cur_kl_coeff": 0.007031250000000002, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.232084669511785, "policy_loss": -0.004113815066517976, "vf_loss": 4.236148608803118, "vf_explained_var": 0.07760091433449397, "kl": 0.007093367335546026, "entropy": 0.46063203310209605, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 169155.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6391093444256555, "cur_kl_coeff": 0.0421875, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.376862814565184, "policy_loss": -0.010180992831195158, "vf_loss": 4.386514136778614, "vf_explained_var": 0.02531973170855689, "kl": 0.01255510834732248, "entropy": 0.9957600347579472, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 169155.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 360000, "num_env_steps_trained": 360000, "num_agent_steps_sampled": 1440000, "num_agent_steps_trained": 1440000}, "env_runners": {"episode_reward_max": 3.9999999999999587, "episode_reward_min": -346.06000000000023, "episode_reward_mean": -36.122799999999955, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -335.68000000000023, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 2.0000000000000013, "predator_policy": 182.0}, "policy_reward_mean": {"prey_policy": -43.58640000000001, "predator_policy": 25.525}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-42.4600000000007, -2.1800000000000788, -31.290000000000465, -15.450000000000006, -5.17000000000008, -53.57000000000068, -30.379999999999484, -22.259999999999707, -15.24999999999961, -10.500000000000075, -127.29999999999893, -19.219999999999445, -51.420000000000705, -6.340000000000064, -30.529999999999795, -21.249999999999424, -57.61000000000041, -39.74000000000058, -12.17000000000008, -4.260000000000077, -0.04000000000004011, -13.26999999999995, -20.239999999999423, -56.01000000000037, -28.33999999999943, 2.949999999999982, -1.5100000000000617, -29.329999999999668, -7.110000000000083, -31.35000000000041, -58.62000000000055, -1.2000000000000455, 3.9999999999999587, -20.469999999999715, 0.9699999999999828, -1.5400000000000538, -64.67999999999935, -29.389999999999596, -5.110000000000083, -3.0700000000000838, -6.100000000000078, -22.119999999999816, -25.67999999999969, -3.0700000000000838, 1.9400000000000026, -0.050000000000041, -14.149999999999736, -234.69000000000182, -3.0900000000000833, -3.1200000000000827, -1.1700000000000597, -14.209999999999763, 2.9799999999999813, 1.960000000000003, -17.30999999999947, -54.750000000000355, 0.6099999999999869, -10.25000000000008, -5.100000000000083, 3.9999999999999587, -15.459999999999644, -29.619999999999525, -60.47000000000037, -22.259999999999977, -35.670000000000364, -29.329999999999732, -0.040000000000040996, -52.5800000000006, -38.42000000000058, -11.15000000000008, -127.32999999999922, -165.24000000000106, -29.439999999999692, 3.9699999999999593, -33.37000000000005, -51.44999999999986, -29.329999999999703, -1.270000000000058, -7.360000000000076, -346.06000000000023, -48.38999999999987, -184.46999999999974, -22.249999999999414, -104.07999999999907, 2.9799999999999813, -129.36999999999966, -115.78999999999988, -16.249999999999954, -21.219999999999892, -29.32999999999968, -14.179999999999753, -107.28999999999878, -31.380000000000003, 0.9399999999999827, -9.130000000000082, -61.69000000000041, -50.550000000000125, -27.309999999999715, -84.70999999999917, -111.8499999999985], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-30.159999999999712, -58.30000000000034, -4.030000000000039, -28.14999999999971, -30.159999999999712, -24.12999999999972, -74.3799999999999, -12.070000000000041, 2.0000000000000013, -32.170000000000364, -68.34999999999916, -42.220000000000354, -18.099999999999884, -54.28000000000034, -22.119999999999717, -26.139999999999855, -48.250000000000334, 2.0000000000000013, -90.45999999999962, -6.040000000000042, -20.109999999999705, -237.19000000000074, -0.009999999999998581, -40.21000000000035, -32.17000000000033, -48.25000000000035, -52.27000000000003, -12.070000000000041, -12.070000000000041, -90.45999999999972, -28.14999999999971, -18.09999999999978, -74.37999999999936, -44.230000000000146, -134.6800000000011, -10.060000000000041, 2.0000000000000013, -32.170000000000336, 2.0000000000000013, -50.260000000000026, 2.0000000000000013, -6.040000000000042, -12.070000000000041, -38.200000000000344, -8.050000000000042, -36.19000000000036, -64.32999999999954, -134.68000000000092, -28.14999999999971, -36.19000000000036, -8.050000000000042, 2.0000000000000013, -100.50999999999927, 2.0000000000000013, -62.320000000000334, -0.00999999999999836, -20.109999999999705, 2.0000000000000013, -26.13999999999974, -40.210000000000356, 2.0000000000000013, -122.61999999999934, 2.0000000000000013, -38.20000000000029, 2.0000000000000013, 2.0000000000000013, -62.320000000000334, -28.149999999999842, 2.0000000000000013, -4.030000000000041, 2.0000000000000013, -106.5399999999993, -132.67000000000053, -0.009999999999998581, -72.3699999999993, -2.0200000000000267, 2.0000000000000013, -20.109999999999708, -10.060000000000041, -0.00999999999999836, -18.099999999999728, 2.0000000000000013, -6.040000000000042, -215.08000000000084, 2.0000000000000013, -134.68000000000052, -8.050000000000042, -2.020000000000042, -10.060000000000041, 2.0000000000000013, -8.050000000000042, 2.0000000000000013, -10.060000000000041, -16.0899999999997, -146.74000000000095, -188.9500000000009, -2.020000000000042, -12.070000000000041, -22.119999999999706, 2.0000000000000013, -8.050000000000042, -22.11999999999972, 2.0000000000000013, -40.210000000000356, -2.020000000000042, 2.0000000000000013, -6.040000000000042, 2.0000000000000013, -60.31000000000033, 2.0000000000000013, -148.7500000000005, 2.0000000000000013, -32.17000000000036, -42.220000000000304, -48.25000000000035, 2.0000000000000013, -18.099999999999707, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, -90.45999999999928, 2.0000000000000013, -14.080000000000041, -106.53999999999932, -38.20000000000018, -52.2700000000002, -16.089999999999996, -32.17000000000032, -132.66999999999953, 2.0000000000000013, -18.099999999999703, -44.23000000000035, -6.040000000000042, 2.0000000000000013, -92.46999999999929, -20.109999999999705, -80.40999999999926, -0.00999999999999836, -6.040000000000042, -20.110000000000035, -28.14999999999971, -243.18000000000046, -156.79000000000053, -88.4499999999997, -68.34999999999918, -16.0899999999997, -4.030000000000042, 2.0000000000000013, -52.270000000000124, -18.099999999999703, -24.129999999999946, -62.32000000000033, -6.040000000000042, -56.29000000000034, -52.270000000000344, 2.0000000000000013, 2.0000000000000013, -70.35999999999935, -335.68000000000023, -275.38000000000017, -30.16000000000001, -44.22999999999973, -128.65000000000003, -162.82000000000025, -18.099999999999703, -28.149999999999714, -211.0200000000005, -10.060000000000041, -2.020000000000042, 2.0000000000000013, -40.21000000000002, -231.16000000000022, -305.5300000000004, -50.260000000000154, -42.22000000000016, -4.030000000000042, -4.030000000000009, -36.190000000000104, -60.31000000000017, -2.020000000000042, -34.18000000000036, 2.0000000000000013, -86.43999999999937, -168.85000000000105, -56.29000000000006, -16.0899999999997, -10.06000000000004, 2.0000000000000013, -10.060000000000041, -12.070000000000041, -36.19000000000012, -98.49999999999949, -58.30000000000006, -48.25000000000007, 2.0000000000000013, -60.310000000000095, -90.45999999999957, -48.250000000000156, -72.36999999999922, -94.47999999999927], "policy_predator_policy_reward": [16.0, 30.0, 14.0, 16.0, 20.0, 3.0, 35.0, 36.0, 11.0, 14.0, 22.0, 35.0, 5.0, 37.0, 12.0, 14.0, 14.0, 17.0, 45.0, 41.0, 11.0, 119.0, 9.0, 12.0, 0.0, 29.0, 27.0, 31.0, 35.0, 37.0, 20.0, 5.0, 44.0, 17.0, 57.0, 48.0, 7.0, 11.0, 23.0, 21.0, 0.0, 4.0, 21.0, 16.0, 13.0, 11.0, 72.0, 71.0, 18.0, 18.0, 5.0, 4.0, 48.0, 49.0, 1.0, 32.0, 0.0, 11.0, 30.0, 5.0, 18.0, 44.0, 17.0, 18.0, 0.0, 0.0, 46.0, 24.0, 0.0, 3.0, 51.0, 52.0, 68.0, 0.0, 36.0, 9.0, 7.0, 6.0, 7.0, 0.0, 10.0, 0.0, 101.0, 98.0, 50.0, 57.0, 5.0, 2.0, 6.0, 4.0, 5.0, 1.0, 3.0, 9.0, 6.0, 95.0, 6.0, 5.0, 12.0, 5.0, 14.0, 15.0, 21.0, 3.0, 2.0, 1.0, 4.0, 2.0, 31.0, 10.0, 32.0, 60.0, 38.0, 37.0, 24.0, 12.0, 4.0, 7.0, 0.0, 0.0, 42.0, 31.0, 48.0, 43.0, 4.0, 26.0, 23.0, 3.0, 53.0, 42.0, 23.0, 10.0, 4.0, 0.0, 35.0, 25.0, 2.0, 40.0, 9.0, 6.0, 15.0, 129.0, 75.0, 5.0, 34.0, 21.0, 3.0, 3.0, 27.0, 10.0, 23.0, 12.0, 29.0, 4.0, 25.0, 24.0, 31.0, 30.0, 182.0, 83.0, 12.0, 14.0, 26.0, 81.0, 7.0, 17.0, 14.0, 103.0, 2.0, 1.0, 36.0, 106.0, 158.0, 82.0, 12.0, 18.0, 16.0, 3.0, 25.0, 8.0, 0.0, 18.0, 82.0, 66.0, 8.0, 33.0, 4.0, 5.0, 7.0, 6.0, 25.0, 48.0, 31.0, 25.0, 31.0, 0.0, 3.0, 51.0, 54.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 7.407392274161348, "mean_inference_ms": 18.381490487411543, "mean_action_processing_ms": 0.7258811253268876, "mean_env_wait_ms": 2.778424286791043, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004201412200927734, "StateBufferConnector_ms": 0.0038799047470092773, "ViewRequirementAgentConnector_ms": 0.10530292987823486}, "num_episodes": 18, "episode_return_max": 3.9999999999999587, "episode_return_min": -346.06000000000023, "episode_return_mean": -36.122799999999955, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1440000, "num_agent_steps_trained": 1440000, "num_env_steps_sampled": 360000, "num_env_steps_trained": 360000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 4.298079332099952, "num_env_steps_trained_throughput_per_sec": 4.298079332099952, "timesteps_total": 360000, "num_env_steps_sampled_lifetime": 360000, "num_agent_steps_sampled_lifetime": 1440000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1440000, "timers": {"training_iteration_time_ms": 175767.917, "restore_workers_time_ms": 0.013, "training_step_time_ms": 175767.872, "sample_time_ms": 93018.281, "learn_time_ms": 82734.086, "learn_throughput": 48.348, "synch_weights_time_ms": 13.319}, "counters": {"num_env_steps_sampled": 360000, "num_env_steps_trained": 360000, "num_agent_steps_sampled": 1440000, "num_agent_steps_trained": 1440000}, "done": false, "training_iteration": 90, "trial_id": "8e499_00000", "date": "2024-08-15_04-29-30", "timestamp": 1723676370, "time_this_iter_s": 930.7225770950317, "time_total_s": 8708.689750671387, "pid": 33199, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x1580ddd30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 8708.689750671387, "iterations_since_restore": 90, "perf": {"cpu_util_percent": 66.625, "ram_util_percent": 80.85}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.130528626145509, "cur_kl_coeff": 0.007031250000000002, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.201499925340925, "policy_loss": -0.004254260708986924, "vf_loss": 6.205697301329759, "vf_explained_var": 0.03757208374442247, "kl": 0.008093277637663087, "entropy": 0.4294776410652847, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 171045.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4846453731337552, "cur_kl_coeff": 0.0421875, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.740050983428955, "policy_loss": -0.011830622240748236, "vf_loss": 5.751301660234966, "vf_explained_var": 0.03727010961562868, "kl": 0.013746712409579982, "entropy": 1.0319848165625618, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 171045.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 364000, "num_env_steps_trained": 364000, "num_agent_steps_sampled": 1456000, "num_agent_steps_trained": 1456000}, "env_runners": {"episode_reward_max": 3.9999999999999587, "episode_reward_min": -346.06000000000023, "episode_reward_mean": -43.76019999999996, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -335.68000000000023, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 2.0000000000000013, "predator_policy": 182.0}, "policy_reward_mean": {"prey_policy": -53.4551, "predator_policy": 31.575}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-56.01000000000037, -28.33999999999943, 2.949999999999982, -1.5100000000000617, -29.329999999999668, -7.110000000000083, -31.35000000000041, -58.62000000000055, -1.2000000000000455, 3.9999999999999587, -20.469999999999715, 0.9699999999999828, -1.5400000000000538, -64.67999999999935, -29.389999999999596, -5.110000000000083, -3.0700000000000838, -6.100000000000078, -22.119999999999816, -25.67999999999969, -3.0700000000000838, 1.9400000000000026, -0.050000000000041, -14.149999999999736, -234.69000000000182, -3.0900000000000833, -3.1200000000000827, -1.1700000000000597, -14.209999999999763, 2.9799999999999813, 1.960000000000003, -17.30999999999947, -54.750000000000355, 0.6099999999999869, -10.25000000000008, -5.100000000000083, 3.9999999999999587, -15.459999999999644, -29.619999999999525, -60.47000000000037, -22.259999999999977, -35.670000000000364, -29.329999999999732, -0.040000000000040996, -52.5800000000006, -38.42000000000058, -11.15000000000008, -127.32999999999922, -165.24000000000106, -29.439999999999692, 3.9699999999999593, -33.37000000000005, -51.44999999999986, -29.329999999999703, -1.270000000000058, -7.360000000000076, -346.06000000000023, -48.38999999999987, -184.46999999999974, -22.249999999999414, -104.07999999999907, 2.9799999999999813, -129.36999999999966, -115.78999999999988, -16.249999999999954, -21.219999999999892, -29.32999999999968, -14.179999999999753, -107.28999999999878, -31.380000000000003, 0.9399999999999827, -9.130000000000082, -61.69000000000041, -50.550000000000125, -27.309999999999715, -84.70999999999917, -111.8499999999985, -116.57999999999917, -47.59000000000056, -59.63000000000065, -51.01000000000011, -132.37999999999988, -51.550000000000075, -1.2399999999999998, -8.850000000000048, -133.53999999999934, -20.289999999999452, -39.45000000000045, -158.210000000001, -2.1300000000000283, -102.11999999999904, -20.259999999999447, -99.94999999999997, -153.56000000000057, -3.4800000000000244, -20.850000000000026, -43.50000000000018, -12.230000000000032, -111.13999999999979, -6.100000000000083], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-64.32999999999954, -134.68000000000092, -28.14999999999971, -36.19000000000036, -8.050000000000042, 2.0000000000000013, -100.50999999999927, 2.0000000000000013, -62.320000000000334, -0.00999999999999836, -20.109999999999705, 2.0000000000000013, -26.13999999999974, -40.210000000000356, 2.0000000000000013, -122.61999999999934, 2.0000000000000013, -38.20000000000029, 2.0000000000000013, 2.0000000000000013, -62.320000000000334, -28.149999999999842, 2.0000000000000013, -4.030000000000041, 2.0000000000000013, -106.5399999999993, -132.67000000000053, -0.009999999999998581, -72.3699999999993, -2.0200000000000267, 2.0000000000000013, -20.109999999999708, -10.060000000000041, -0.00999999999999836, -18.099999999999728, 2.0000000000000013, -6.040000000000042, -215.08000000000084, 2.0000000000000013, -134.68000000000052, -8.050000000000042, -2.020000000000042, -10.060000000000041, 2.0000000000000013, -8.050000000000042, 2.0000000000000013, -10.060000000000041, -16.0899999999997, -146.74000000000095, -188.9500000000009, -2.020000000000042, -12.070000000000041, -22.119999999999706, 2.0000000000000013, -8.050000000000042, -22.11999999999972, 2.0000000000000013, -40.210000000000356, -2.020000000000042, 2.0000000000000013, -6.040000000000042, 2.0000000000000013, -60.31000000000033, 2.0000000000000013, -148.7500000000005, 2.0000000000000013, -32.17000000000036, -42.220000000000304, -48.25000000000035, 2.0000000000000013, -18.099999999999707, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, -90.45999999999928, 2.0000000000000013, -14.080000000000041, -106.53999999999932, -38.20000000000018, -52.2700000000002, -16.089999999999996, -32.17000000000032, -132.66999999999953, 2.0000000000000013, -18.099999999999703, -44.23000000000035, -6.040000000000042, 2.0000000000000013, -92.46999999999929, -20.109999999999705, -80.40999999999926, -0.00999999999999836, -6.040000000000042, -20.110000000000035, -28.14999999999971, -243.18000000000046, -156.79000000000053, -88.4499999999997, -68.34999999999918, -16.0899999999997, -4.030000000000042, 2.0000000000000013, -52.270000000000124, -18.099999999999703, -24.129999999999946, -62.32000000000033, -6.040000000000042, -56.29000000000034, -52.270000000000344, 2.0000000000000013, 2.0000000000000013, -70.35999999999935, -335.68000000000023, -275.38000000000017, -30.16000000000001, -44.22999999999973, -128.65000000000003, -162.82000000000025, -18.099999999999703, -28.149999999999714, -211.0200000000005, -10.060000000000041, -2.020000000000042, 2.0000000000000013, -40.21000000000002, -231.16000000000022, -305.5300000000004, -50.260000000000154, -42.22000000000016, -4.030000000000042, -4.030000000000009, -36.190000000000104, -60.31000000000017, -2.020000000000042, -34.18000000000036, 2.0000000000000013, -86.43999999999937, -168.85000000000105, -56.29000000000006, -16.0899999999997, -10.06000000000004, 2.0000000000000013, -10.060000000000041, -12.070000000000041, -36.19000000000012, -98.49999999999949, -58.30000000000006, -48.25000000000007, 2.0000000000000013, -60.310000000000095, -90.45999999999957, -48.250000000000156, -72.36999999999922, -94.47999999999927, -219.1000000000004, -94.47999999999924, -10.060000000000041, -104.5299999999993, -88.4100000000003, -42.219999999999736, -130.66000000000065, -68.34999999999997, -136.69000000000003, -136.6900000000002, -0.009999999999998581, -106.54000000000003, 2.0000000000000013, -46.24000000000008, 2.0000000000000013, -168.84999999999985, -156.79000000000093, -148.75000000000003, -14.080000000000027, -40.210000000000356, -68.34999999999934, -18.099999999999792, -142.72000000000054, -96.48999999999972, -16.0899999999997, -6.040000000000013, -78.39999999999968, -142.71999999999986, -50.260000000000346, 2.0000000000000013, -104.52999999999933, -82.42000000000003, -148.75000000000028, -168.81000000000017, -245.23000000000002, -48.25000000000035, -16.089999999999787, -150.75999999999993, -56.29000000000006, -40.20999999999995, -16.089999999999943, -26.13999999999972, -54.28000000000005, -170.86000000000044, -12.070000000000041, -4.030000000000042], "policy_predator_policy_reward": [72.0, 71.0, 18.0, 18.0, 5.0, 4.0, 48.0, 49.0, 1.0, 32.0, 0.0, 11.0, 30.0, 5.0, 18.0, 44.0, 17.0, 18.0, 0.0, 0.0, 46.0, 24.0, 0.0, 3.0, 51.0, 52.0, 68.0, 0.0, 36.0, 9.0, 7.0, 6.0, 7.0, 0.0, 10.0, 0.0, 101.0, 98.0, 50.0, 57.0, 5.0, 2.0, 6.0, 4.0, 5.0, 1.0, 3.0, 9.0, 6.0, 95.0, 6.0, 5.0, 12.0, 5.0, 14.0, 15.0, 21.0, 3.0, 2.0, 1.0, 4.0, 2.0, 31.0, 10.0, 32.0, 60.0, 38.0, 37.0, 24.0, 12.0, 4.0, 7.0, 0.0, 0.0, 42.0, 31.0, 48.0, 43.0, 4.0, 26.0, 23.0, 3.0, 53.0, 42.0, 23.0, 10.0, 4.0, 0.0, 35.0, 25.0, 2.0, 40.0, 9.0, 6.0, 15.0, 129.0, 75.0, 5.0, 34.0, 21.0, 3.0, 3.0, 27.0, 10.0, 23.0, 12.0, 29.0, 4.0, 25.0, 24.0, 31.0, 30.0, 182.0, 83.0, 12.0, 14.0, 26.0, 81.0, 7.0, 17.0, 14.0, 103.0, 2.0, 1.0, 36.0, 106.0, 158.0, 82.0, 12.0, 18.0, 16.0, 3.0, 25.0, 8.0, 0.0, 18.0, 82.0, 66.0, 8.0, 33.0, 4.0, 5.0, 7.0, 6.0, 25.0, 48.0, 31.0, 25.0, 31.0, 0.0, 3.0, 51.0, 54.0, 1.0, 125.0, 72.0, 18.0, 49.0, 31.0, 40.0, 74.0, 74.0, 113.0, 28.0, 55.0, 0.0, 21.0, 22.0, 77.0, 81.0, 77.0, 95.0, 6.0, 28.0, 13.0, 34.0, 7.0, 74.0, 13.0, 7.0, 65.0, 54.0, 12.0, 16.0, 40.0, 47.0, 116.0, 48.0, 142.0, 148.0, 69.0, 77.0, 50.0, 3.0, 11.0, 19.0, 15.0, 99.0, 3.0, 7.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 8.453086617283756, "mean_inference_ms": 20.019088733998004, "mean_action_processing_ms": 1.4066035941329647, "mean_env_wait_ms": 2.7523728243956476, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004710674285888672, "StateBufferConnector_ms": 0.003966569900512695, "ViewRequirementAgentConnector_ms": 0.10973942279815674}, "num_episodes": 23, "episode_return_max": 3.9999999999999587, "episode_return_min": -346.06000000000023, "episode_return_mean": -43.76019999999996, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1456000, "num_agent_steps_trained": 1456000, "num_env_steps_sampled": 364000, "num_env_steps_trained": 364000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 335.1928635786805, "num_env_steps_trained_throughput_per_sec": 335.1928635786805, "timesteps_total": 364000, "num_env_steps_sampled_lifetime": 364000, "num_agent_steps_sampled_lifetime": 1456000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1456000, "timers": {"training_iteration_time_ms": 175903.388, "restore_workers_time_ms": 0.013, "training_step_time_ms": 175903.34, "sample_time_ms": 93063.994, "learn_time_ms": 82822.993, "learn_throughput": 48.296, "synch_weights_time_ms": 13.894}, "counters": {"num_env_steps_sampled": 364000, "num_env_steps_trained": 364000, "num_agent_steps_sampled": 1456000, "num_agent_steps_trained": 1456000}, "done": false, "training_iteration": 91, "trial_id": "8e499_00000", "date": "2024-08-15_04-29-42", "timestamp": 1723676382, "time_this_iter_s": 11.991870880126953, "time_total_s": 8720.681621551514, "pid": 33199, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x1580dde50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 8720.681621551514, "iterations_since_restore": 91, "perf": {"cpu_util_percent": 48.01176470588235, "ram_util_percent": 83.7}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.873523884160178, "cur_kl_coeff": 0.007031250000000002, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.634453910242313, "policy_loss": -0.0026259303556154016, "vf_loss": 4.6370484807503916, "vf_explained_var": 0.018999242624908527, "kl": 0.004458357772590461, "entropy": 0.35886064025144726, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 172935.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2794948555805066, "cur_kl_coeff": 0.0421875, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.343102758397501, "policy_loss": -0.011428161057096625, "vf_loss": 4.353842425598669, "vf_explained_var": 0.042551282127067526, "kl": 0.01631982850706296, "entropy": 0.8571594050636998, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 172935.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 368000, "num_env_steps_trained": 368000, "num_agent_steps_sampled": 1472000, "num_agent_steps_trained": 1472000}, "env_runners": {"episode_reward_max": 3.9999999999999587, "episode_reward_min": -346.06000000000023, "episode_reward_mean": -51.11649999999995, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -335.68000000000023, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 2.0000000000000013, "predator_policy": 182.0}, "policy_reward_mean": {"prey_policy": -60.11825000000001, "predator_policy": 34.56}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-22.119999999999816, -25.67999999999969, -3.0700000000000838, 1.9400000000000026, -0.050000000000041, -14.149999999999736, -234.69000000000182, -3.0900000000000833, -3.1200000000000827, -1.1700000000000597, -14.209999999999763, 2.9799999999999813, 1.960000000000003, -17.30999999999947, -54.750000000000355, 0.6099999999999869, -10.25000000000008, -5.100000000000083, 3.9999999999999587, -15.459999999999644, -29.619999999999525, -60.47000000000037, -22.259999999999977, -35.670000000000364, -29.329999999999732, -0.040000000000040996, -52.5800000000006, -38.42000000000058, -11.15000000000008, -127.32999999999922, -165.24000000000106, -29.439999999999692, 3.9699999999999593, -33.37000000000005, -51.44999999999986, -29.329999999999703, -1.270000000000058, -7.360000000000076, -346.06000000000023, -48.38999999999987, -184.46999999999974, -22.249999999999414, -104.07999999999907, 2.9799999999999813, -129.36999999999966, -115.78999999999988, -16.249999999999954, -21.219999999999892, -29.32999999999968, -14.179999999999753, -107.28999999999878, -31.380000000000003, 0.9399999999999827, -9.130000000000082, -61.69000000000041, -50.550000000000125, -27.309999999999715, -84.70999999999917, -111.8499999999985, -116.57999999999917, -47.59000000000056, -59.63000000000065, -51.01000000000011, -132.37999999999988, -51.550000000000075, -1.2399999999999998, -8.850000000000048, -133.53999999999934, -20.289999999999452, -39.45000000000045, -158.210000000001, -2.1300000000000283, -102.11999999999904, -20.259999999999447, -99.94999999999997, -153.56000000000057, -3.4800000000000244, -20.850000000000026, -43.50000000000018, -12.230000000000032, -111.13999999999979, -6.100000000000083, -98.47000000000001, -3.050000000000084, -16.8299999999999, -10.360000000000076, -52.700000000000315, -14.219999999999766, -111.94000000000011, -48.51000000000048, -121.10999999999979, -3.1900000000000768, -92.89999999999898, -88.91999999999884, -34.38000000000028, -225.07000000000042, -73.68000000000008, -46.62000000000039, -6.320000000000048, -23.269999999999797], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-6.040000000000042, -215.08000000000084, 2.0000000000000013, -134.68000000000052, -8.050000000000042, -2.020000000000042, -10.060000000000041, 2.0000000000000013, -8.050000000000042, 2.0000000000000013, -10.060000000000041, -16.0899999999997, -146.74000000000095, -188.9500000000009, -2.020000000000042, -12.070000000000041, -22.119999999999706, 2.0000000000000013, -8.050000000000042, -22.11999999999972, 2.0000000000000013, -40.210000000000356, -2.020000000000042, 2.0000000000000013, -6.040000000000042, 2.0000000000000013, -60.31000000000033, 2.0000000000000013, -148.7500000000005, 2.0000000000000013, -32.17000000000036, -42.220000000000304, -48.25000000000035, 2.0000000000000013, -18.099999999999707, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, -90.45999999999928, 2.0000000000000013, -14.080000000000041, -106.53999999999932, -38.20000000000018, -52.2700000000002, -16.089999999999996, -32.17000000000032, -132.66999999999953, 2.0000000000000013, -18.099999999999703, -44.23000000000035, -6.040000000000042, 2.0000000000000013, -92.46999999999929, -20.109999999999705, -80.40999999999926, -0.00999999999999836, -6.040000000000042, -20.110000000000035, -28.14999999999971, -243.18000000000046, -156.79000000000053, -88.4499999999997, -68.34999999999918, -16.0899999999997, -4.030000000000042, 2.0000000000000013, -52.270000000000124, -18.099999999999703, -24.129999999999946, -62.32000000000033, -6.040000000000042, -56.29000000000034, -52.270000000000344, 2.0000000000000013, 2.0000000000000013, -70.35999999999935, -335.68000000000023, -275.38000000000017, -30.16000000000001, -44.22999999999973, -128.65000000000003, -162.82000000000025, -18.099999999999703, -28.149999999999714, -211.0200000000005, -10.060000000000041, -2.020000000000042, 2.0000000000000013, -40.21000000000002, -231.16000000000022, -305.5300000000004, -50.260000000000154, -42.22000000000016, -4.030000000000042, -4.030000000000009, -36.190000000000104, -60.31000000000017, -2.020000000000042, -34.18000000000036, 2.0000000000000013, -86.43999999999937, -168.85000000000105, -56.29000000000006, -16.0899999999997, -10.06000000000004, 2.0000000000000013, -10.060000000000041, -12.070000000000041, -36.19000000000012, -98.49999999999949, -58.30000000000006, -48.25000000000007, 2.0000000000000013, -60.310000000000095, -90.45999999999957, -48.250000000000156, -72.36999999999922, -94.47999999999927, -219.1000000000004, -94.47999999999924, -10.060000000000041, -104.5299999999993, -88.4100000000003, -42.219999999999736, -130.66000000000065, -68.34999999999997, -136.69000000000003, -136.6900000000002, -0.009999999999998581, -106.54000000000003, 2.0000000000000013, -46.24000000000008, 2.0000000000000013, -168.84999999999985, -156.79000000000093, -148.75000000000003, -14.080000000000027, -40.210000000000356, -68.34999999999934, -18.099999999999792, -142.72000000000054, -96.48999999999972, -16.0899999999997, -6.040000000000013, -78.39999999999968, -142.71999999999986, -50.260000000000346, 2.0000000000000013, -104.52999999999933, -82.42000000000003, -148.75000000000028, -168.81000000000017, -245.23000000000002, -48.25000000000035, -16.089999999999787, -150.75999999999993, -56.29000000000006, -40.20999999999995, -16.089999999999943, -26.13999999999972, -54.28000000000005, -170.86000000000044, -12.070000000000041, -4.030000000000042, -196.99000000000092, -94.47999999999993, -2.020000000000042, -4.030000000000042, -42.22, -120.60999999999929, -54.28000000000033, -14.080000000000041, 2.0000000000000013, -138.69999999999993, -42.220000000000354, 2.0000000000000013, -88.45000000000005, -96.48999999999967, -20.109999999999705, -78.39999999999948, -58.300000000000054, -160.8100000000004, -10.060000000000041, -24.12999999999973, -54.28000000000017, -122.61999999999952, -62.3200000000003, -118.59999999999937, -24.12999999999979, -48.2500000000003, -182.92000000000053, -229.14999999999986, -38.200000000000045, -94.47999999999963, -122.61999999999944, 2.0000000000000013, -42.220000000000205, -18.099999999999703, -24.12999999999992, -26.139999999999894], "policy_predator_policy_reward": [101.0, 98.0, 50.0, 57.0, 5.0, 2.0, 6.0, 4.0, 5.0, 1.0, 3.0, 9.0, 6.0, 95.0, 6.0, 5.0, 12.0, 5.0, 14.0, 15.0, 21.0, 3.0, 2.0, 1.0, 4.0, 2.0, 31.0, 10.0, 32.0, 60.0, 38.0, 37.0, 24.0, 12.0, 4.0, 7.0, 0.0, 0.0, 42.0, 31.0, 48.0, 43.0, 4.0, 26.0, 23.0, 3.0, 53.0, 42.0, 23.0, 10.0, 4.0, 0.0, 35.0, 25.0, 2.0, 40.0, 9.0, 6.0, 15.0, 129.0, 75.0, 5.0, 34.0, 21.0, 3.0, 3.0, 27.0, 10.0, 23.0, 12.0, 29.0, 4.0, 25.0, 24.0, 31.0, 30.0, 182.0, 83.0, 12.0, 14.0, 26.0, 81.0, 7.0, 17.0, 14.0, 103.0, 2.0, 1.0, 36.0, 106.0, 158.0, 82.0, 12.0, 18.0, 16.0, 3.0, 25.0, 8.0, 0.0, 18.0, 82.0, 66.0, 8.0, 33.0, 4.0, 5.0, 7.0, 6.0, 25.0, 48.0, 31.0, 25.0, 31.0, 0.0, 3.0, 51.0, 54.0, 1.0, 125.0, 72.0, 18.0, 49.0, 31.0, 40.0, 74.0, 74.0, 113.0, 28.0, 55.0, 0.0, 21.0, 22.0, 77.0, 81.0, 77.0, 95.0, 6.0, 28.0, 13.0, 34.0, 7.0, 74.0, 13.0, 7.0, 65.0, 54.0, 12.0, 16.0, 40.0, 47.0, 116.0, 48.0, 142.0, 148.0, 69.0, 77.0, 50.0, 3.0, 11.0, 19.0, 15.0, 99.0, 3.0, 7.0, 97.0, 96.0, 0.0, 3.0, 73.0, 73.0, 28.0, 30.0, 61.0, 23.0, 12.0, 14.0, 55.0, 18.0, 20.0, 30.0, 78.0, 20.0, 17.0, 14.0, 60.0, 24.0, 37.0, 55.0, 20.0, 18.0, 95.0, 92.0, 41.0, 18.0, 46.0, 28.0, 28.0, 26.0, 7.0, 20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 10.217916790713183, "mean_inference_ms": 20.287128532633147, "mean_action_processing_ms": 1.8549566925272611, "mean_env_wait_ms": 2.7267038085505932, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005152463912963867, "StateBufferConnector_ms": 0.004024982452392578, "ViewRequirementAgentConnector_ms": 0.1057976484298706}, "num_episodes": 18, "episode_return_max": 3.9999999999999587, "episode_return_min": -346.06000000000023, "episode_return_mean": -51.11649999999995, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1472000, "num_agent_steps_trained": 1472000, "num_env_steps_sampled": 368000, "num_env_steps_trained": 368000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 396.8690587648895, "num_env_steps_trained_throughput_per_sec": 396.8690587648895, "timesteps_total": 368000, "num_env_steps_sampled_lifetime": 368000, "num_agent_steps_sampled_lifetime": 1472000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1472000, "timers": {"training_iteration_time_ms": 175921.261, "restore_workers_time_ms": 0.013, "training_step_time_ms": 175921.212, "sample_time_ms": 93065.869, "learn_time_ms": 82838.976, "learn_throughput": 48.286, "synch_weights_time_ms": 13.965}, "counters": {"num_env_steps_sampled": 368000, "num_env_steps_trained": 368000, "num_agent_steps_sampled": 1472000, "num_agent_steps_trained": 1472000}, "done": false, "training_iteration": 92, "trial_id": "8e499_00000", "date": "2024-08-15_04-29-52", "timestamp": 1723676392, "time_this_iter_s": 10.13271188735962, "time_total_s": 8730.814333438873, "pid": 33199, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x1580efd30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 8730.814333438873, "iterations_since_restore": 92, "perf": {"cpu_util_percent": 32.82666666666667, "ram_util_percent": 83.07333333333334}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.821546823637826, "cur_kl_coeff": 0.003515625000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.107114905655068, "policy_loss": -0.00314454522264737, "vf_loss": 4.110243374582321, "vf_explained_var": 0.027775389019143646, "kl": 0.004574725899298618, "entropy": 0.32804154610980757, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 174825.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4662943423425079, "cur_kl_coeff": 0.0421875, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.1437325835227967, "policy_loss": -0.009523600147588662, "vf_loss": 3.1527807632451337, "vf_explained_var": 0.05535968756549573, "kl": 0.011269241416236624, "entropy": 0.7930899274096918, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 174825.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 372000, "num_env_steps_trained": 372000, "num_agent_steps_sampled": 1488000, "num_agent_steps_trained": 1488000}, "env_runners": {"episode_reward_max": 3.9999999999999587, "episode_reward_min": -346.06000000000023, "episode_reward_mean": -53.674099999999946, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -335.68000000000023, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 2.0000000000000013, "predator_policy": 182.0}, "policy_reward_mean": {"prey_policy": -63.89704999999999, "predator_policy": 37.06}, "custom_metrics": {}, "hist_stats": {"episode_reward": [3.9999999999999587, -15.459999999999644, -29.619999999999525, -60.47000000000037, -22.259999999999977, -35.670000000000364, -29.329999999999732, -0.040000000000040996, -52.5800000000006, -38.42000000000058, -11.15000000000008, -127.32999999999922, -165.24000000000106, -29.439999999999692, 3.9699999999999593, -33.37000000000005, -51.44999999999986, -29.329999999999703, -1.270000000000058, -7.360000000000076, -346.06000000000023, -48.38999999999987, -184.46999999999974, -22.249999999999414, -104.07999999999907, 2.9799999999999813, -129.36999999999966, -115.78999999999988, -16.249999999999954, -21.219999999999892, -29.32999999999968, -14.179999999999753, -107.28999999999878, -31.380000000000003, 0.9399999999999827, -9.130000000000082, -61.69000000000041, -50.550000000000125, -27.309999999999715, -84.70999999999917, -111.8499999999985, -116.57999999999917, -47.59000000000056, -59.63000000000065, -51.01000000000011, -132.37999999999988, -51.550000000000075, -1.2399999999999998, -8.850000000000048, -133.53999999999934, -20.289999999999452, -39.45000000000045, -158.210000000001, -2.1300000000000283, -102.11999999999904, -20.259999999999447, -99.94999999999997, -153.56000000000057, -3.4800000000000244, -20.850000000000026, -43.50000000000018, -12.230000000000032, -111.13999999999979, -6.100000000000083, -98.47000000000001, -3.050000000000084, -16.8299999999999, -10.360000000000076, -52.700000000000315, -14.219999999999766, -111.94000000000011, -48.51000000000048, -121.10999999999979, -3.1900000000000768, -92.89999999999898, -88.91999999999884, -34.38000000000028, -225.07000000000042, -73.68000000000008, -46.62000000000039, -6.320000000000048, -23.269999999999797, -13.169999999999924, -0.09000000000002856, -54.58000000000011, -17.20999999999962, -98.59999999999916, -21.24999999999953, -12.160000000000082, -31.219999999999573, -34.86000000000013, -45.46000000000056, -52.82000000000017, -36.46000000000068, -23.359999999999708, -33.37000000000056, -126.3899999999997, -8.290000000000079, -3.2100000000000763, -44.53000000000044], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [2.0000000000000013, 2.0000000000000013, -90.45999999999928, 2.0000000000000013, -14.080000000000041, -106.53999999999932, -38.20000000000018, -52.2700000000002, -16.089999999999996, -32.17000000000032, -132.66999999999953, 2.0000000000000013, -18.099999999999703, -44.23000000000035, -6.040000000000042, 2.0000000000000013, -92.46999999999929, -20.109999999999705, -80.40999999999926, -0.00999999999999836, -6.040000000000042, -20.110000000000035, -28.14999999999971, -243.18000000000046, -156.79000000000053, -88.4499999999997, -68.34999999999918, -16.0899999999997, -4.030000000000042, 2.0000000000000013, -52.270000000000124, -18.099999999999703, -24.129999999999946, -62.32000000000033, -6.040000000000042, -56.29000000000034, -52.270000000000344, 2.0000000000000013, 2.0000000000000013, -70.35999999999935, -335.68000000000023, -275.38000000000017, -30.16000000000001, -44.22999999999973, -128.65000000000003, -162.82000000000025, -18.099999999999703, -28.149999999999714, -211.0200000000005, -10.060000000000041, -2.020000000000042, 2.0000000000000013, -40.21000000000002, -231.16000000000022, -305.5300000000004, -50.260000000000154, -42.22000000000016, -4.030000000000042, -4.030000000000009, -36.190000000000104, -60.31000000000017, -2.020000000000042, -34.18000000000036, 2.0000000000000013, -86.43999999999937, -168.85000000000105, -56.29000000000006, -16.0899999999997, -10.06000000000004, 2.0000000000000013, -10.060000000000041, -12.070000000000041, -36.19000000000012, -98.49999999999949, -58.30000000000006, -48.25000000000007, 2.0000000000000013, -60.310000000000095, -90.45999999999957, -48.250000000000156, -72.36999999999922, -94.47999999999927, -219.1000000000004, -94.47999999999924, -10.060000000000041, -104.5299999999993, -88.4100000000003, -42.219999999999736, -130.66000000000065, -68.34999999999997, -136.69000000000003, -136.6900000000002, -0.009999999999998581, -106.54000000000003, 2.0000000000000013, -46.24000000000008, 2.0000000000000013, -168.84999999999985, -156.79000000000093, -148.75000000000003, -14.080000000000027, -40.210000000000356, -68.34999999999934, -18.099999999999792, -142.72000000000054, -96.48999999999972, -16.0899999999997, -6.040000000000013, -78.39999999999968, -142.71999999999986, -50.260000000000346, 2.0000000000000013, -104.52999999999933, -82.42000000000003, -148.75000000000028, -168.81000000000017, -245.23000000000002, -48.25000000000035, -16.089999999999787, -150.75999999999993, -56.29000000000006, -40.20999999999995, -16.089999999999943, -26.13999999999972, -54.28000000000005, -170.86000000000044, -12.070000000000041, -4.030000000000042, -196.99000000000092, -94.47999999999993, -2.020000000000042, -4.030000000000042, -42.22, -120.60999999999929, -54.28000000000033, -14.080000000000041, 2.0000000000000013, -138.69999999999993, -42.220000000000354, 2.0000000000000013, -88.45000000000005, -96.48999999999967, -20.109999999999705, -78.39999999999948, -58.300000000000054, -160.8100000000004, -10.060000000000041, -24.12999999999973, -54.28000000000017, -122.61999999999952, -62.3200000000003, -118.59999999999937, -24.12999999999979, -48.2500000000003, -182.92000000000053, -229.14999999999986, -38.200000000000045, -94.47999999999963, -122.61999999999944, 2.0000000000000013, -42.220000000000205, -18.099999999999703, -24.12999999999992, -26.139999999999894, -24.12999999999971, -6.040000000000042, -10.060000000000034, -4.030000000000042, -114.57999999999976, 2.0000000000000013, -0.00999999999999836, -38.20000000000023, -255.2800000000003, -62.32000000000025, 2.0000000000000013, -48.2500000000003, -8.050000000000034, -20.109999999999705, -213.07000000000028, -28.14999999999984, -164.83000000000055, -4.030000000000042, -44.23000000000027, -44.2300000000001, -32.16999999999986, -128.64999999999975, -44.23000000000035, -44.23000000000016, -70.35999999999956, 2.0000000000000013, -10.06000000000004, -60.3100000000003, -114.57999999999987, -160.81000000000049, -4.030000000000042, -50.260000000000346, 2.0000000000000013, -40.21000000000019, -8.050000000000042, -94.47999999999946], "policy_predator_policy_reward": [0.0, 0.0, 42.0, 31.0, 48.0, 43.0, 4.0, 26.0, 23.0, 3.0, 53.0, 42.0, 23.0, 10.0, 4.0, 0.0, 35.0, 25.0, 2.0, 40.0, 9.0, 6.0, 15.0, 129.0, 75.0, 5.0, 34.0, 21.0, 3.0, 3.0, 27.0, 10.0, 23.0, 12.0, 29.0, 4.0, 25.0, 24.0, 31.0, 30.0, 182.0, 83.0, 12.0, 14.0, 26.0, 81.0, 7.0, 17.0, 14.0, 103.0, 2.0, 1.0, 36.0, 106.0, 158.0, 82.0, 12.0, 18.0, 16.0, 3.0, 25.0, 8.0, 0.0, 18.0, 82.0, 66.0, 8.0, 33.0, 4.0, 5.0, 7.0, 6.0, 25.0, 48.0, 31.0, 25.0, 31.0, 0.0, 3.0, 51.0, 54.0, 1.0, 125.0, 72.0, 18.0, 49.0, 31.0, 40.0, 74.0, 74.0, 113.0, 28.0, 55.0, 0.0, 21.0, 22.0, 77.0, 81.0, 77.0, 95.0, 6.0, 28.0, 13.0, 34.0, 7.0, 74.0, 13.0, 7.0, 65.0, 54.0, 12.0, 16.0, 40.0, 47.0, 116.0, 48.0, 142.0, 148.0, 69.0, 77.0, 50.0, 3.0, 11.0, 19.0, 15.0, 99.0, 3.0, 7.0, 97.0, 96.0, 0.0, 3.0, 73.0, 73.0, 28.0, 30.0, 61.0, 23.0, 12.0, 14.0, 55.0, 18.0, 20.0, 30.0, 78.0, 20.0, 17.0, 14.0, 60.0, 24.0, 37.0, 55.0, 20.0, 18.0, 95.0, 92.0, 41.0, 18.0, 46.0, 28.0, 28.0, 26.0, 7.0, 20.0, 5.0, 12.0, 5.0, 9.0, 9.0, 49.0, 8.0, 13.0, 99.0, 120.0, 7.0, 18.0, 0.0, 16.0, 100.0, 110.0, 54.0, 80.0, 30.0, 13.0, 78.0, 30.0, 24.0, 28.0, 32.0, 13.0, 6.0, 31.0, 114.0, 35.0, 21.0, 25.0, 16.0, 19.0, 40.0, 18.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 11.494530818556491, "mean_inference_ms": 21.02363310698346, "mean_action_processing_ms": 2.298747629466035, "mean_env_wait_ms": 2.7016099553898645, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005474567413330078, "StateBufferConnector_ms": 0.004019260406494141, "ViewRequirementAgentConnector_ms": 0.09968841075897217}, "num_episodes": 18, "episode_return_max": 3.9999999999999587, "episode_return_min": -346.06000000000023, "episode_return_mean": -53.674099999999946, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1488000, "num_agent_steps_trained": 1488000, "num_env_steps_sampled": 372000, "num_env_steps_trained": 372000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 386.00445073944195, "num_env_steps_trained_throughput_per_sec": 386.00445073944195, "timesteps_total": 372000, "num_env_steps_sampled_lifetime": 372000, "num_agent_steps_sampled_lifetime": 1488000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1488000, "timers": {"training_iteration_time_ms": 175963.843, "restore_workers_time_ms": 0.014, "training_step_time_ms": 175963.793, "sample_time_ms": 93072.97, "learn_time_ms": 82874.065, "learn_throughput": 48.266, "synch_weights_time_ms": 14.318}, "counters": {"num_env_steps_sampled": 372000, "num_env_steps_trained": 372000, "num_agent_steps_sampled": 1488000, "num_agent_steps_trained": 1488000}, "done": false, "training_iteration": 93, "trial_id": "8e499_00000", "date": "2024-08-15_04-30-03", "timestamp": 1723676403, "time_this_iter_s": 10.406142950057983, "time_total_s": 8741.220476388931, "pid": 33199, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x15819cca0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 8741.220476388931, "iterations_since_restore": 93, "perf": {"cpu_util_percent": 39.957142857142856, "ram_util_percent": 82.39285714285714}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7887576269882697, "cur_kl_coeff": 0.0017578125000000005, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.124201415833973, "policy_loss": -0.0035456275909882848, "vf_loss": 2.127733854263548, "vf_explained_var": 0.0724135022314768, "kl": 0.007502037205060081, "entropy": 0.2816089645816536, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 176715.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.257932906538721, "cur_kl_coeff": 0.0421875, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.728328911289967, "policy_loss": -0.010610967633196168, "vf_loss": 1.7386028208429851, "vf_explained_var": 0.06578099399647384, "kl": 0.007989497291398626, "entropy": 0.5283920122044427, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 176715.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 376000, "num_env_steps_trained": 376000, "num_agent_steps_sampled": 1504000, "num_agent_steps_trained": 1504000}, "env_runners": {"episode_reward_max": 3.9099999999999606, "episode_reward_min": -225.07000000000042, "episode_reward_mean": -49.225099999999884, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -305.5300000000004, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 2.0000000000000013, "predator_policy": 158.0}, "policy_reward_mean": {"prey_policy": -60.94254999999998, "predator_policy": 36.33}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-184.46999999999974, -22.249999999999414, -104.07999999999907, 2.9799999999999813, -129.36999999999966, -115.78999999999988, -16.249999999999954, -21.219999999999892, -29.32999999999968, -14.179999999999753, -107.28999999999878, -31.380000000000003, 0.9399999999999827, -9.130000000000082, -61.69000000000041, -50.550000000000125, -27.309999999999715, -84.70999999999917, -111.8499999999985, -116.57999999999917, -47.59000000000056, -59.63000000000065, -51.01000000000011, -132.37999999999988, -51.550000000000075, -1.2399999999999998, -8.850000000000048, -133.53999999999934, -20.289999999999452, -39.45000000000045, -158.210000000001, -2.1300000000000283, -102.11999999999904, -20.259999999999447, -99.94999999999997, -153.56000000000057, -3.4800000000000244, -20.850000000000026, -43.50000000000018, -12.230000000000032, -111.13999999999979, -6.100000000000083, -98.47000000000001, -3.050000000000084, -16.8299999999999, -10.360000000000076, -52.700000000000315, -14.219999999999766, -111.94000000000011, -48.51000000000048, -121.10999999999979, -3.1900000000000768, -92.89999999999898, -88.91999999999884, -34.38000000000028, -225.07000000000042, -73.68000000000008, -46.62000000000039, -6.320000000000048, -23.269999999999797, -13.169999999999924, -0.09000000000002856, -54.58000000000011, -17.20999999999962, -98.59999999999916, -21.24999999999953, -12.160000000000082, -31.219999999999573, -34.86000000000013, -45.46000000000056, -52.82000000000017, -36.46000000000068, -23.359999999999708, -33.37000000000056, -126.3899999999997, -8.290000000000079, -3.2100000000000763, -44.53000000000044, -48.530000000000605, 2.9799999999999813, 3.9099999999999606, -62.69000000000017, -57.610000000000554, -36.43000000000012, -11.22000000000008, -63.66999999999928, -20.28999999999965, -18.799999999999944, -0.04000000000004011, -10.370000000000077, -15.189999999999767, -0.24000000000004018, -23.37999999999945, -63.669999999998765, -82.01999999999848, -0.050000000000041, -13.190000000000051, -22.329999999999504, -75.79999999999927, -62.73999999999965], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-128.65000000000003, -162.82000000000025, -18.099999999999703, -28.149999999999714, -211.0200000000005, -10.060000000000041, -2.020000000000042, 2.0000000000000013, -40.21000000000002, -231.16000000000022, -305.5300000000004, -50.260000000000154, -42.22000000000016, -4.030000000000042, -4.030000000000009, -36.190000000000104, -60.31000000000017, -2.020000000000042, -34.18000000000036, 2.0000000000000013, -86.43999999999937, -168.85000000000105, -56.29000000000006, -16.0899999999997, -10.06000000000004, 2.0000000000000013, -10.060000000000041, -12.070000000000041, -36.19000000000012, -98.49999999999949, -58.30000000000006, -48.25000000000007, 2.0000000000000013, -60.310000000000095, -90.45999999999957, -48.250000000000156, -72.36999999999922, -94.47999999999927, -219.1000000000004, -94.47999999999924, -10.060000000000041, -104.5299999999993, -88.4100000000003, -42.219999999999736, -130.66000000000065, -68.34999999999997, -136.69000000000003, -136.6900000000002, -0.009999999999998581, -106.54000000000003, 2.0000000000000013, -46.24000000000008, 2.0000000000000013, -168.84999999999985, -156.79000000000093, -148.75000000000003, -14.080000000000027, -40.210000000000356, -68.34999999999934, -18.099999999999792, -142.72000000000054, -96.48999999999972, -16.0899999999997, -6.040000000000013, -78.39999999999968, -142.71999999999986, -50.260000000000346, 2.0000000000000013, -104.52999999999933, -82.42000000000003, -148.75000000000028, -168.81000000000017, -245.23000000000002, -48.25000000000035, -16.089999999999787, -150.75999999999993, -56.29000000000006, -40.20999999999995, -16.089999999999943, -26.13999999999972, -54.28000000000005, -170.86000000000044, -12.070000000000041, -4.030000000000042, -196.99000000000092, -94.47999999999993, -2.020000000000042, -4.030000000000042, -42.22, -120.60999999999929, -54.28000000000033, -14.080000000000041, 2.0000000000000013, -138.69999999999993, -42.220000000000354, 2.0000000000000013, -88.45000000000005, -96.48999999999967, -20.109999999999705, -78.39999999999948, -58.300000000000054, -160.8100000000004, -10.060000000000041, -24.12999999999973, -54.28000000000017, -122.61999999999952, -62.3200000000003, -118.59999999999937, -24.12999999999979, -48.2500000000003, -182.92000000000053, -229.14999999999986, -38.200000000000045, -94.47999999999963, -122.61999999999944, 2.0000000000000013, -42.220000000000205, -18.099999999999703, -24.12999999999992, -26.139999999999894, -24.12999999999971, -6.040000000000042, -10.060000000000034, -4.030000000000042, -114.57999999999976, 2.0000000000000013, -0.00999999999999836, -38.20000000000023, -255.2800000000003, -62.32000000000025, 2.0000000000000013, -48.2500000000003, -8.050000000000034, -20.109999999999705, -213.07000000000028, -28.14999999999984, -164.83000000000055, -4.030000000000042, -44.23000000000027, -44.2300000000001, -32.16999999999986, -128.64999999999975, -44.23000000000035, -44.23000000000016, -70.35999999999956, 2.0000000000000013, -10.06000000000004, -60.3100000000003, -114.57999999999987, -160.81000000000049, -4.030000000000042, -50.260000000000346, 2.0000000000000013, -40.21000000000019, -8.050000000000042, -94.47999999999946, -66.3399999999992, -36.19000000000012, -2.020000000000042, 2.0000000000000013, 2.0000000000000013, -16.0899999999997, -136.6900000000009, 2.0000000000000013, -92.46999999999932, -26.13999999999979, -32.170000000000364, -50.26000000000015, -12.070000000000041, -28.149999999999793, -92.46999999999952, -38.20000000000027, -10.060000000000041, -44.23000000000023, -138.70000000000002, -18.099999999999703, 2.0000000000000013, -6.040000000000042, -72.36999999999921, 2.0000000000000013, -28.149999999999814, -6.040000000000041, -44.230000000000345, -0.00999999999999836, -48.2500000000003, -24.12999999999972, -70.35999999999926, -60.310000000000336, -122.6199999999993, -78.39999999999918, -8.050000000000042, 2.0000000000000013, -34.18000000000022, -0.009999999999998581, 2.0000000000000013, -64.32999999999919, -134.68000000000035, -22.119999999999752, -38.20000000000024, -106.53999999999935], "policy_predator_policy_reward": [26.0, 81.0, 7.0, 17.0, 14.0, 103.0, 2.0, 1.0, 36.0, 106.0, 158.0, 82.0, 12.0, 18.0, 16.0, 3.0, 25.0, 8.0, 0.0, 18.0, 82.0, 66.0, 8.0, 33.0, 4.0, 5.0, 7.0, 6.0, 25.0, 48.0, 31.0, 25.0, 31.0, 0.0, 3.0, 51.0, 54.0, 1.0, 125.0, 72.0, 18.0, 49.0, 31.0, 40.0, 74.0, 74.0, 113.0, 28.0, 55.0, 0.0, 21.0, 22.0, 77.0, 81.0, 77.0, 95.0, 6.0, 28.0, 13.0, 34.0, 7.0, 74.0, 13.0, 7.0, 65.0, 54.0, 12.0, 16.0, 40.0, 47.0, 116.0, 48.0, 142.0, 148.0, 69.0, 77.0, 50.0, 3.0, 11.0, 19.0, 15.0, 99.0, 3.0, 7.0, 97.0, 96.0, 0.0, 3.0, 73.0, 73.0, 28.0, 30.0, 61.0, 23.0, 12.0, 14.0, 55.0, 18.0, 20.0, 30.0, 78.0, 20.0, 17.0, 14.0, 60.0, 24.0, 37.0, 55.0, 20.0, 18.0, 95.0, 92.0, 41.0, 18.0, 46.0, 28.0, 28.0, 26.0, 7.0, 20.0, 5.0, 12.0, 5.0, 9.0, 9.0, 49.0, 8.0, 13.0, 99.0, 120.0, 7.0, 18.0, 0.0, 16.0, 100.0, 110.0, 54.0, 80.0, 30.0, 13.0, 78.0, 30.0, 24.0, 28.0, 32.0, 13.0, 6.0, 31.0, 114.0, 35.0, 21.0, 25.0, 16.0, 19.0, 40.0, 18.0, 10.0, 44.0, 1.0, 2.0, 9.0, 9.0, 3.0, 69.0, 19.0, 42.0, 25.0, 21.0, 13.0, 16.0, 56.0, 11.0, 22.0, 12.0, 62.0, 76.0, 0.0, 4.0, 32.0, 28.0, 11.0, 8.0, 22.0, 22.0, 25.0, 24.0, 31.0, 36.0, 55.0, 64.0, 1.0, 5.0, 10.0, 11.0, 7.0, 33.0, 47.0, 34.0, 46.0, 36.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 13.183805212159593, "mean_inference_ms": 21.728867297763443, "mean_action_processing_ms": 2.737756973085217, "mean_env_wait_ms": 2.6646912526626054, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006702303886413574, "StateBufferConnector_ms": 0.004152774810791016, "ViewRequirementAgentConnector_ms": 0.10103631019592285}, "num_episodes": 22, "episode_return_max": 3.9099999999999606, "episode_return_min": -225.07000000000042, "episode_return_mean": -49.225099999999884, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1504000, "num_agent_steps_trained": 1504000, "num_env_steps_sampled": 376000, "num_env_steps_trained": 376000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 4.3306138739619335, "num_env_steps_trained_throughput_per_sec": 4.3306138739619335, "timesteps_total": 376000, "num_env_steps_sampled_lifetime": 376000, "num_agent_steps_sampled_lifetime": 1504000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1504000, "timers": {"training_iteration_time_ms": 193823.161, "restore_workers_time_ms": 0.014, "training_step_time_ms": 193823.112, "sample_time_ms": 93051.63, "learn_time_ms": 100754.026, "learn_throughput": 39.701, "synch_weights_time_ms": 14.991}, "counters": {"num_env_steps_sampled": 376000, "num_env_steps_trained": 376000, "num_agent_steps_sampled": 1504000, "num_agent_steps_trained": 1504000}, "done": false, "training_iteration": 94, "trial_id": "8e499_00000", "date": "2024-08-15_04-45-26", "timestamp": 1723677326, "time_this_iter_s": 923.6970498561859, "time_total_s": 9664.917526245117, "pid": 33199, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x1581d1280>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 9664.917526245117, "iterations_since_restore": 94, "perf": {"cpu_util_percent": 68.73809523809524, "ram_util_percent": 81.53809523809525}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8706362184077974, "cur_kl_coeff": 0.0017578125000000005, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.9842945980016515, "policy_loss": -0.002722096848227675, "vf_loss": 2.98700726423314, "vf_explained_var": 0.04720140556809763, "kl": 0.005367768540537996, "entropy": 0.34563534395404594, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 178605.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1883682902527866, "cur_kl_coeff": 0.0421875, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.156296599983538, "policy_loss": -0.014001024192169545, "vf_loss": 2.1698464259268744, "vf_explained_var": 0.0441743740959773, "kl": 0.010695185738298404, "entropy": 0.6106050520662277, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 178605.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 380000, "num_env_steps_trained": 380000, "num_agent_steps_sampled": 1520000, "num_agent_steps_trained": 1520000}, "env_runners": {"episode_reward_max": 3.9599999999999596, "episode_reward_min": -225.07000000000042, "episode_reward_mean": -43.7075999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -255.2800000000003, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 2.0000000000000013, "predator_policy": 148.0}, "policy_reward_mean": {"prey_policy": -56.12879999999998, "predator_policy": 34.275}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-111.8499999999985, -116.57999999999917, -47.59000000000056, -59.63000000000065, -51.01000000000011, -132.37999999999988, -51.550000000000075, -1.2399999999999998, -8.850000000000048, -133.53999999999934, -20.289999999999452, -39.45000000000045, -158.210000000001, -2.1300000000000283, -102.11999999999904, -20.259999999999447, -99.94999999999997, -153.56000000000057, -3.4800000000000244, -20.850000000000026, -43.50000000000018, -12.230000000000032, -111.13999999999979, -6.100000000000083, -98.47000000000001, -3.050000000000084, -16.8299999999999, -10.360000000000076, -52.700000000000315, -14.219999999999766, -111.94000000000011, -48.51000000000048, -121.10999999999979, -3.1900000000000768, -92.89999999999898, -88.91999999999884, -34.38000000000028, -225.07000000000042, -73.68000000000008, -46.62000000000039, -6.320000000000048, -23.269999999999797, -13.169999999999924, -0.09000000000002856, -54.58000000000011, -17.20999999999962, -98.59999999999916, -21.24999999999953, -12.160000000000082, -31.219999999999573, -34.86000000000013, -45.46000000000056, -52.82000000000017, -36.46000000000068, -23.359999999999708, -33.37000000000056, -126.3899999999997, -8.290000000000079, -3.2100000000000763, -44.53000000000044, -48.530000000000605, 2.9799999999999813, 3.9099999999999606, -62.69000000000017, -57.610000000000554, -36.43000000000012, -11.22000000000008, -63.66999999999928, -20.28999999999965, -18.799999999999944, -0.04000000000004011, -10.370000000000077, -15.189999999999767, -0.24000000000004018, -23.37999999999945, -63.669999999998765, -82.01999999999848, -0.050000000000041, -13.190000000000051, -22.329999999999504, -75.79999999999927, -62.73999999999965, -24.279999999999465, 3.9599999999999596, -21.249999999999417, -16.239999999999444, -76.88999999999955, 2.989999999999981, -56.940000000000275, -2.3600000000000527, -25.259999999999437, -40.440000000000666, -17.209999999999667, -5.100000000000083, -6.100000000000083, -52.760000000000545, 1.920000000000003, -3.1300000000000807, -22.33999999999944, -91.89999999999883], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-72.36999999999922, -94.47999999999927, -219.1000000000004, -94.47999999999924, -10.060000000000041, -104.5299999999993, -88.4100000000003, -42.219999999999736, -130.66000000000065, -68.34999999999997, -136.69000000000003, -136.6900000000002, -0.009999999999998581, -106.54000000000003, 2.0000000000000013, -46.24000000000008, 2.0000000000000013, -168.84999999999985, -156.79000000000093, -148.75000000000003, -14.080000000000027, -40.210000000000356, -68.34999999999934, -18.099999999999792, -142.72000000000054, -96.48999999999972, -16.0899999999997, -6.040000000000013, -78.39999999999968, -142.71999999999986, -50.260000000000346, 2.0000000000000013, -104.52999999999933, -82.42000000000003, -148.75000000000028, -168.81000000000017, -245.23000000000002, -48.25000000000035, -16.089999999999787, -150.75999999999993, -56.29000000000006, -40.20999999999995, -16.089999999999943, -26.13999999999972, -54.28000000000005, -170.86000000000044, -12.070000000000041, -4.030000000000042, -196.99000000000092, -94.47999999999993, -2.020000000000042, -4.030000000000042, -42.22, -120.60999999999929, -54.28000000000033, -14.080000000000041, 2.0000000000000013, -138.69999999999993, -42.220000000000354, 2.0000000000000013, -88.45000000000005, -96.48999999999967, -20.109999999999705, -78.39999999999948, -58.300000000000054, -160.8100000000004, -10.060000000000041, -24.12999999999973, -54.28000000000017, -122.61999999999952, -62.3200000000003, -118.59999999999937, -24.12999999999979, -48.2500000000003, -182.92000000000053, -229.14999999999986, -38.200000000000045, -94.47999999999963, -122.61999999999944, 2.0000000000000013, -42.220000000000205, -18.099999999999703, -24.12999999999992, -26.139999999999894, -24.12999999999971, -6.040000000000042, -10.060000000000034, -4.030000000000042, -114.57999999999976, 2.0000000000000013, -0.00999999999999836, -38.20000000000023, -255.2800000000003, -62.32000000000025, 2.0000000000000013, -48.2500000000003, -8.050000000000034, -20.109999999999705, -213.07000000000028, -28.14999999999984, -164.83000000000055, -4.030000000000042, -44.23000000000027, -44.2300000000001, -32.16999999999986, -128.64999999999975, -44.23000000000035, -44.23000000000016, -70.35999999999956, 2.0000000000000013, -10.06000000000004, -60.3100000000003, -114.57999999999987, -160.81000000000049, -4.030000000000042, -50.260000000000346, 2.0000000000000013, -40.21000000000019, -8.050000000000042, -94.47999999999946, -66.3399999999992, -36.19000000000012, -2.020000000000042, 2.0000000000000013, 2.0000000000000013, -16.0899999999997, -136.6900000000009, 2.0000000000000013, -92.46999999999932, -26.13999999999979, -32.170000000000364, -50.26000000000015, -12.070000000000041, -28.149999999999793, -92.46999999999952, -38.20000000000027, -10.060000000000041, -44.23000000000023, -138.70000000000002, -18.099999999999703, 2.0000000000000013, -6.040000000000042, -72.36999999999921, 2.0000000000000013, -28.149999999999814, -6.040000000000041, -44.230000000000345, -0.00999999999999836, -48.2500000000003, -24.12999999999972, -70.35999999999926, -60.310000000000336, -122.6199999999993, -78.39999999999918, -8.050000000000042, 2.0000000000000013, -34.18000000000022, -0.009999999999998581, 2.0000000000000013, -64.32999999999919, -134.68000000000035, -22.119999999999752, -38.20000000000024, -106.53999999999935, -44.230000000000295, -8.050000000000042, 2.0000000000000013, -6.040000000000042, -26.13999999999971, -20.1099999999998, -46.24000000000035, 2.0000000000000013, -30.159999999999712, -144.72999999999973, 2.0000000000000013, -0.00999999999999836, -168.85000000000068, -16.08999999999982, 2.0000000000000013, -70.3599999999994, -24.129999999999754, -24.129999999999722, -32.17000000000022, -52.27000000000033, -34.18000000000019, -4.030000000000042, -6.040000000000042, -10.060000000000041, -16.089999999999712, -0.00999999999999836, -46.2400000000001, -102.51999999999924, -14.080000000000041, 2.0000000000000013, -10.06000000000003, -12.070000000000041, -30.159999999999712, -34.18000000000029, -92.46999999999964, -84.4299999999994], "policy_predator_policy_reward": [54.0, 1.0, 125.0, 72.0, 18.0, 49.0, 31.0, 40.0, 74.0, 74.0, 113.0, 28.0, 55.0, 0.0, 21.0, 22.0, 77.0, 81.0, 77.0, 95.0, 6.0, 28.0, 13.0, 34.0, 7.0, 74.0, 13.0, 7.0, 65.0, 54.0, 12.0, 16.0, 40.0, 47.0, 116.0, 48.0, 142.0, 148.0, 69.0, 77.0, 50.0, 3.0, 11.0, 19.0, 15.0, 99.0, 3.0, 7.0, 97.0, 96.0, 0.0, 3.0, 73.0, 73.0, 28.0, 30.0, 61.0, 23.0, 12.0, 14.0, 55.0, 18.0, 20.0, 30.0, 78.0, 20.0, 17.0, 14.0, 60.0, 24.0, 37.0, 55.0, 20.0, 18.0, 95.0, 92.0, 41.0, 18.0, 46.0, 28.0, 28.0, 26.0, 7.0, 20.0, 5.0, 12.0, 5.0, 9.0, 9.0, 49.0, 8.0, 13.0, 99.0, 120.0, 7.0, 18.0, 0.0, 16.0, 100.0, 110.0, 54.0, 80.0, 30.0, 13.0, 78.0, 30.0, 24.0, 28.0, 32.0, 13.0, 6.0, 31.0, 114.0, 35.0, 21.0, 25.0, 16.0, 19.0, 40.0, 18.0, 10.0, 44.0, 1.0, 2.0, 9.0, 9.0, 3.0, 69.0, 19.0, 42.0, 25.0, 21.0, 13.0, 16.0, 56.0, 11.0, 22.0, 12.0, 62.0, 76.0, 0.0, 4.0, 32.0, 28.0, 11.0, 8.0, 22.0, 22.0, 25.0, 24.0, 31.0, 36.0, 55.0, 64.0, 1.0, 5.0, 10.0, 11.0, 7.0, 33.0, 47.0, 34.0, 46.0, 36.0, 12.0, 16.0, 4.0, 4.0, 19.0, 6.0, 5.0, 23.0, 18.0, 80.0, 0.0, 1.0, 67.0, 61.0, 36.0, 30.0, 1.0, 22.0, 33.0, 11.0, 11.0, 10.0, 6.0, 5.0, 6.0, 4.0, 41.0, 55.0, 8.0, 6.0, 9.0, 10.0, 25.0, 17.0, 18.0, 67.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 13.29063642551497, "mean_inference_ms": 21.53719243306563, "mean_action_processing_ms": 2.7137331023995914, "mean_env_wait_ms": 2.640792634939863, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.008798837661743164, "StateBufferConnector_ms": 0.003324151039123535, "ViewRequirementAgentConnector_ms": 0.10186457633972168}, "num_episodes": 18, "episode_return_max": 3.9599999999999596, "episode_return_min": -225.07000000000042, "episode_return_mean": -43.7075999999999, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1520000, "num_agent_steps_trained": 1520000, "num_env_steps_sampled": 380000, "num_env_steps_trained": 380000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 307.94354344386505, "num_env_steps_trained_throughput_per_sec": 307.94354344386505, "timesteps_total": 380000, "num_env_steps_sampled_lifetime": 380000, "num_agent_steps_sampled_lifetime": 1520000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1520000, "timers": {"training_iteration_time_ms": 194075.306, "restore_workers_time_ms": 0.014, "training_step_time_ms": 194075.256, "sample_time_ms": 93141.414, "learn_time_ms": 100915.45, "learn_throughput": 39.637, "synch_weights_time_ms": 15.205}, "counters": {"num_env_steps_sampled": 380000, "num_env_steps_trained": 380000, "num_agent_steps_sampled": 1520000, "num_agent_steps_trained": 1520000}, "done": false, "training_iteration": 95, "trial_id": "8e499_00000", "date": "2024-08-15_04-45-39", "timestamp": 1723677339, "time_this_iter_s": 13.044988870620728, "time_total_s": 9677.962515115738, "pid": 33199, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x1581ad0d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 9677.962515115738, "iterations_since_restore": 95, "perf": {"cpu_util_percent": 61.13157894736841, "ram_util_percent": 81.00526315789473}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7048053962213021, "cur_kl_coeff": 0.0017578125000000005, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.9945737429396817, "policy_loss": -0.002219243717217256, "vf_loss": 1.9967857423282804, "vf_explained_var": 0.04202131833979692, "kl": 0.004120807190163128, "entropy": 0.374550320925536, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 180495.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3664516235312456, "cur_kl_coeff": 0.0421875, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.825866591804242, "policy_loss": -0.011836258243651145, "vf_loss": 1.837274755277331, "vf_explained_var": 0.08149761563886411, "kl": 0.010147296619570858, "entropy": 0.7031094567327903, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 180495.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 384000, "num_env_steps_trained": 384000, "num_agent_steps_sampled": 1536000, "num_agent_steps_trained": 1536000}, "env_runners": {"episode_reward_max": 3.9599999999999596, "episode_reward_min": -225.07000000000042, "episode_reward_mean": -34.65259999999993, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -255.2800000000003, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 2.0000000000000013, "predator_policy": 120.0}, "policy_reward_mean": {"prey_policy": -45.49629999999996, "predator_policy": 28.17}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-6.100000000000083, -98.47000000000001, -3.050000000000084, -16.8299999999999, -10.360000000000076, -52.700000000000315, -14.219999999999766, -111.94000000000011, -48.51000000000048, -121.10999999999979, -3.1900000000000768, -92.89999999999898, -88.91999999999884, -34.38000000000028, -225.07000000000042, -73.68000000000008, -46.62000000000039, -6.320000000000048, -23.269999999999797, -13.169999999999924, -0.09000000000002856, -54.58000000000011, -17.20999999999962, -98.59999999999916, -21.24999999999953, -12.160000000000082, -31.219999999999573, -34.86000000000013, -45.46000000000056, -52.82000000000017, -36.46000000000068, -23.359999999999708, -33.37000000000056, -126.3899999999997, -8.290000000000079, -3.2100000000000763, -44.53000000000044, -48.530000000000605, 2.9799999999999813, 3.9099999999999606, -62.69000000000017, -57.610000000000554, -36.43000000000012, -11.22000000000008, -63.66999999999928, -20.28999999999965, -18.799999999999944, -0.04000000000004011, -10.370000000000077, -15.189999999999767, -0.24000000000004018, -23.37999999999945, -63.669999999998765, -82.01999999999848, -0.050000000000041, -13.190000000000051, -22.329999999999504, -75.79999999999927, -62.73999999999965, -24.279999999999465, 3.9599999999999596, -21.249999999999417, -16.239999999999444, -76.88999999999955, 2.989999999999981, -56.940000000000275, -2.3600000000000527, -25.259999999999437, -40.440000000000666, -17.209999999999667, -5.100000000000083, -6.100000000000083, -52.760000000000545, 1.920000000000003, -3.1300000000000807, -22.33999999999944, -91.89999999999883, -4.200000000000081, -12.290000000000077, -3.070000000000082, -2.1500000000000785, -34.410000000000466, -35.8700000000002, -54.79000000000012, -112.96999999999854, -5.310000000000079, -38.4300000000005, -24.41999999999952, -8.130000000000082, -3.0700000000000838, -17.269999999999726, -9.340000000000076, -11.150000000000082, -27.389999999999965, -82.06999999999985, -18.44999999999952, 3.9499999999999598, -37.410000000000494, -58.620000000000594, 0.9699999999999841], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-12.070000000000041, -4.030000000000042, -196.99000000000092, -94.47999999999993, -2.020000000000042, -4.030000000000042, -42.22, -120.60999999999929, -54.28000000000033, -14.080000000000041, 2.0000000000000013, -138.69999999999993, -42.220000000000354, 2.0000000000000013, -88.45000000000005, -96.48999999999967, -20.109999999999705, -78.39999999999948, -58.300000000000054, -160.8100000000004, -10.060000000000041, -24.12999999999973, -54.28000000000017, -122.61999999999952, -62.3200000000003, -118.59999999999937, -24.12999999999979, -48.2500000000003, -182.92000000000053, -229.14999999999986, -38.200000000000045, -94.47999999999963, -122.61999999999944, 2.0000000000000013, -42.220000000000205, -18.099999999999703, -24.12999999999992, -26.139999999999894, -24.12999999999971, -6.040000000000042, -10.060000000000034, -4.030000000000042, -114.57999999999976, 2.0000000000000013, -0.00999999999999836, -38.20000000000023, -255.2800000000003, -62.32000000000025, 2.0000000000000013, -48.2500000000003, -8.050000000000034, -20.109999999999705, -213.07000000000028, -28.14999999999984, -164.83000000000055, -4.030000000000042, -44.23000000000027, -44.2300000000001, -32.16999999999986, -128.64999999999975, -44.23000000000035, -44.23000000000016, -70.35999999999956, 2.0000000000000013, -10.06000000000004, -60.3100000000003, -114.57999999999987, -160.81000000000049, -4.030000000000042, -50.260000000000346, 2.0000000000000013, -40.21000000000019, -8.050000000000042, -94.47999999999946, -66.3399999999992, -36.19000000000012, -2.020000000000042, 2.0000000000000013, 2.0000000000000013, -16.0899999999997, -136.6900000000009, 2.0000000000000013, -92.46999999999932, -26.13999999999979, -32.170000000000364, -50.26000000000015, -12.070000000000041, -28.149999999999793, -92.46999999999952, -38.20000000000027, -10.060000000000041, -44.23000000000023, -138.70000000000002, -18.099999999999703, 2.0000000000000013, -6.040000000000042, -72.36999999999921, 2.0000000000000013, -28.149999999999814, -6.040000000000041, -44.230000000000345, -0.00999999999999836, -48.2500000000003, -24.12999999999972, -70.35999999999926, -60.310000000000336, -122.6199999999993, -78.39999999999918, -8.050000000000042, 2.0000000000000013, -34.18000000000022, -0.009999999999998581, 2.0000000000000013, -64.32999999999919, -134.68000000000035, -22.119999999999752, -38.20000000000024, -106.53999999999935, -44.230000000000295, -8.050000000000042, 2.0000000000000013, -6.040000000000042, -26.13999999999971, -20.1099999999998, -46.24000000000035, 2.0000000000000013, -30.159999999999712, -144.72999999999973, 2.0000000000000013, -0.00999999999999836, -168.85000000000068, -16.08999999999982, 2.0000000000000013, -70.3599999999994, -24.129999999999754, -24.129999999999722, -32.17000000000022, -52.27000000000033, -34.18000000000019, -4.030000000000042, -6.040000000000042, -10.060000000000041, -16.089999999999712, -0.00999999999999836, -46.2400000000001, -102.51999999999924, -14.080000000000041, 2.0000000000000013, -10.06000000000003, -12.070000000000041, -30.159999999999712, -34.18000000000029, -92.46999999999964, -84.4299999999994, -22.119999999999795, -14.080000000000041, -10.060000000000024, -44.23000000000032, -4.030000000000042, -6.040000000000038, -28.149999999999714, 2.0000000000000013, -6.040000000000037, -72.36999999999938, -164.8300000000002, -6.040000000000042, -156.7900000000002, 2.0000000000000013, -58.3000000000003, -132.67000000000104, -8.050000000000042, -50.26000000000034, 2.0000000000000013, -84.42999999999931, -64.32999999999926, -16.089999999999822, -8.050000000000042, -14.080000000000041, -10.060000000000041, -0.009999999999998581, -32.170000000000115, -18.09999999999971, 2.0000000000000013, -66.3399999999993, -28.14999999999971, 2.0000000000000013, -54.28000000000008, -20.109999999999705, -203.02000000000058, -8.050000000000042, -74.37999999999924, -12.070000000000041, -8.050000000000042, 2.0000000000000013, -50.260000000000346, -28.149999999999785, -12.070000000000041, -108.54999999999926, -4.030000000000042, 2.0000000000000013], "policy_predator_policy_reward": [3.0, 7.0, 97.0, 96.0, 0.0, 3.0, 73.0, 73.0, 28.0, 30.0, 61.0, 23.0, 12.0, 14.0, 55.0, 18.0, 20.0, 30.0, 78.0, 20.0, 17.0, 14.0, 60.0, 24.0, 37.0, 55.0, 20.0, 18.0, 95.0, 92.0, 41.0, 18.0, 46.0, 28.0, 28.0, 26.0, 7.0, 20.0, 5.0, 12.0, 5.0, 9.0, 9.0, 49.0, 8.0, 13.0, 99.0, 120.0, 7.0, 18.0, 0.0, 16.0, 100.0, 110.0, 54.0, 80.0, 30.0, 13.0, 78.0, 30.0, 24.0, 28.0, 32.0, 13.0, 6.0, 31.0, 114.0, 35.0, 21.0, 25.0, 16.0, 19.0, 40.0, 18.0, 10.0, 44.0, 1.0, 2.0, 9.0, 9.0, 3.0, 69.0, 19.0, 42.0, 25.0, 21.0, 13.0, 16.0, 56.0, 11.0, 22.0, 12.0, 62.0, 76.0, 0.0, 4.0, 32.0, 28.0, 11.0, 8.0, 22.0, 22.0, 25.0, 24.0, 31.0, 36.0, 55.0, 64.0, 1.0, 5.0, 10.0, 11.0, 7.0, 33.0, 47.0, 34.0, 46.0, 36.0, 12.0, 16.0, 4.0, 4.0, 19.0, 6.0, 5.0, 23.0, 18.0, 80.0, 0.0, 1.0, 67.0, 61.0, 36.0, 30.0, 1.0, 22.0, 33.0, 11.0, 11.0, 10.0, 6.0, 5.0, 6.0, 4.0, 41.0, 55.0, 8.0, 6.0, 9.0, 10.0, 25.0, 17.0, 18.0, 67.0, 16.0, 16.0, 19.0, 23.0, 7.0, 0.0, 9.0, 15.0, 11.0, 33.0, 79.0, 56.0, 38.0, 62.0, 6.0, 72.0, 29.0, 24.0, 24.0, 20.0, 36.0, 20.0, 6.0, 8.0, 6.0, 1.0, 22.0, 11.0, 29.0, 26.0, 6.0, 9.0, 10.0, 37.0, 90.0, 39.0, 30.0, 38.0, 5.0, 5.0, 36.0, 5.0, 2.0, 60.0, 2.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 13.144537172814735, "mean_inference_ms": 21.278546602519285, "mean_action_processing_ms": 2.6782988675370607, "mean_env_wait_ms": 2.6174470902493283, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.009148240089416504, "StateBufferConnector_ms": 0.004123210906982422, "ViewRequirementAgentConnector_ms": 0.11414444446563721}, "num_episodes": 23, "episode_return_max": 3.9599999999999596, "episode_return_min": -225.07000000000042, "episode_return_mean": -34.65259999999993, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1536000, "num_agent_steps_trained": 1536000, "num_env_steps_sampled": 384000, "num_env_steps_trained": 384000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 346.94788639760935, "num_env_steps_trained_throughput_per_sec": 346.94788639760935, "timesteps_total": 384000, "num_env_steps_sampled_lifetime": 384000, "num_agent_steps_sampled_lifetime": 1536000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1536000, "timers": {"training_iteration_time_ms": 194238.635, "restore_workers_time_ms": 0.014, "training_step_time_ms": 194238.584, "sample_time_ms": 93189.562, "learn_time_ms": 101029.436, "learn_throughput": 39.592, "synch_weights_time_ms": 16.043}, "counters": {"num_env_steps_sampled": 384000, "num_env_steps_trained": 384000, "num_agent_steps_sampled": 1536000, "num_agent_steps_trained": 1536000}, "done": false, "training_iteration": 96, "trial_id": "8e499_00000", "date": "2024-08-15_04-45-51", "timestamp": 1723677351, "time_this_iter_s": 11.568244934082031, "time_total_s": 9689.53076004982, "pid": 33199, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x15818dc10>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 9689.53076004982, "iterations_since_restore": 96, "perf": {"cpu_util_percent": 43.4125, "ram_util_percent": 83.1625}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.744197048491271, "cur_kl_coeff": 0.0008789062500000002, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.620097184875024, "policy_loss": -0.004678198042271472, "vf_loss": 1.6247698073349301, "vf_explained_var": 0.06677744338121364, "kl": 0.006346161832758349, "entropy": 0.35951176922788064, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 182385.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2800788315673355, "cur_kl_coeff": 0.0421875, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.1652852705990275, "policy_loss": -0.010304562406979068, "vf_loss": 1.1752365187362388, "vf_explained_var": 0.07511067945490439, "kl": 0.008374816525629982, "entropy": 0.6545593671697788, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 182385.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 388000, "num_env_steps_trained": 388000, "num_agent_steps_sampled": 1552000, "num_agent_steps_trained": 1552000}, "env_runners": {"episode_reward_max": 3.9599999999999596, "episode_reward_min": -126.3899999999997, "episode_reward_mean": -27.0303999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -255.2800000000003, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 2.0000000000000013, "predator_policy": 120.0}, "policy_reward_mean": {"prey_policy": -37.235199999999956, "predator_policy": 23.72}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-23.269999999999797, -13.169999999999924, -0.09000000000002856, -54.58000000000011, -17.20999999999962, -98.59999999999916, -21.24999999999953, -12.160000000000082, -31.219999999999573, -34.86000000000013, -45.46000000000056, -52.82000000000017, -36.46000000000068, -23.359999999999708, -33.37000000000056, -126.3899999999997, -8.290000000000079, -3.2100000000000763, -44.53000000000044, -48.530000000000605, 2.9799999999999813, 3.9099999999999606, -62.69000000000017, -57.610000000000554, -36.43000000000012, -11.22000000000008, -63.66999999999928, -20.28999999999965, -18.799999999999944, -0.04000000000004011, -10.370000000000077, -15.189999999999767, -0.24000000000004018, -23.37999999999945, -63.669999999998765, -82.01999999999848, -0.050000000000041, -13.190000000000051, -22.329999999999504, -75.79999999999927, -62.73999999999965, -24.279999999999465, 3.9599999999999596, -21.249999999999417, -16.239999999999444, -76.88999999999955, 2.989999999999981, -56.940000000000275, -2.3600000000000527, -25.259999999999437, -40.440000000000666, -17.209999999999667, -5.100000000000083, -6.100000000000083, -52.760000000000545, 1.920000000000003, -3.1300000000000807, -22.33999999999944, -91.89999999999883, -4.200000000000081, -12.290000000000077, -3.070000000000082, -2.1500000000000785, -34.410000000000466, -35.8700000000002, -54.79000000000012, -112.96999999999854, -5.310000000000079, -38.4300000000005, -24.41999999999952, -8.130000000000082, -3.0700000000000838, -17.269999999999726, -9.340000000000076, -11.150000000000082, -27.389999999999965, -82.06999999999985, -18.44999999999952, 3.9499999999999598, -37.410000000000494, -58.620000000000594, 0.9699999999999841, -3.070000000000073, -9.130000000000082, -14.159999999999746, -5.300000000000079, -25.289999999999452, 2.989999999999981, 1.8700000000000023, -16.199999999999406, -5.1400000000000805, -14.179999999999788, -65.68999999999889, -0.2000000000000446, -3.1700000000000736, -63.66999999999942, -15.139999999999551, -0.040000000000040996, -40.44000000000062, -16.18999999999944], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-24.12999999999992, -26.139999999999894, -24.12999999999971, -6.040000000000042, -10.060000000000034, -4.030000000000042, -114.57999999999976, 2.0000000000000013, -0.00999999999999836, -38.20000000000023, -255.2800000000003, -62.32000000000025, 2.0000000000000013, -48.2500000000003, -8.050000000000034, -20.109999999999705, -213.07000000000028, -28.14999999999984, -164.83000000000055, -4.030000000000042, -44.23000000000027, -44.2300000000001, -32.16999999999986, -128.64999999999975, -44.23000000000035, -44.23000000000016, -70.35999999999956, 2.0000000000000013, -10.06000000000004, -60.3100000000003, -114.57999999999987, -160.81000000000049, -4.030000000000042, -50.260000000000346, 2.0000000000000013, -40.21000000000019, -8.050000000000042, -94.47999999999946, -66.3399999999992, -36.19000000000012, -2.020000000000042, 2.0000000000000013, 2.0000000000000013, -16.0899999999997, -136.6900000000009, 2.0000000000000013, -92.46999999999932, -26.13999999999979, -32.170000000000364, -50.26000000000015, -12.070000000000041, -28.149999999999793, -92.46999999999952, -38.20000000000027, -10.060000000000041, -44.23000000000023, -138.70000000000002, -18.099999999999703, 2.0000000000000013, -6.040000000000042, -72.36999999999921, 2.0000000000000013, -28.149999999999814, -6.040000000000041, -44.230000000000345, -0.00999999999999836, -48.2500000000003, -24.12999999999972, -70.35999999999926, -60.310000000000336, -122.6199999999993, -78.39999999999918, -8.050000000000042, 2.0000000000000013, -34.18000000000022, -0.009999999999998581, 2.0000000000000013, -64.32999999999919, -134.68000000000035, -22.119999999999752, -38.20000000000024, -106.53999999999935, -44.230000000000295, -8.050000000000042, 2.0000000000000013, -6.040000000000042, -26.13999999999971, -20.1099999999998, -46.24000000000035, 2.0000000000000013, -30.159999999999712, -144.72999999999973, 2.0000000000000013, -0.00999999999999836, -168.85000000000068, -16.08999999999982, 2.0000000000000013, -70.3599999999994, -24.129999999999754, -24.129999999999722, -32.17000000000022, -52.27000000000033, -34.18000000000019, -4.030000000000042, -6.040000000000042, -10.060000000000041, -16.089999999999712, -0.00999999999999836, -46.2400000000001, -102.51999999999924, -14.080000000000041, 2.0000000000000013, -10.06000000000003, -12.070000000000041, -30.159999999999712, -34.18000000000029, -92.46999999999964, -84.4299999999994, -22.119999999999795, -14.080000000000041, -10.060000000000024, -44.23000000000032, -4.030000000000042, -6.040000000000038, -28.149999999999714, 2.0000000000000013, -6.040000000000037, -72.36999999999938, -164.8300000000002, -6.040000000000042, -156.7900000000002, 2.0000000000000013, -58.3000000000003, -132.67000000000104, -8.050000000000042, -50.26000000000034, 2.0000000000000013, -84.42999999999931, -64.32999999999926, -16.089999999999822, -8.050000000000042, -14.080000000000041, -10.060000000000041, -0.009999999999998581, -32.170000000000115, -18.09999999999971, 2.0000000000000013, -66.3399999999993, -28.14999999999971, 2.0000000000000013, -54.28000000000008, -20.109999999999705, -203.02000000000058, -8.050000000000042, -74.37999999999924, -12.070000000000041, -8.050000000000042, 2.0000000000000013, -50.260000000000346, -28.149999999999785, -12.070000000000041, -108.54999999999926, -4.030000000000042, 2.0000000000000013, 2.0000000000000013, -12.070000000000036, -24.129999999999722, 2.0000000000000013, -22.119999999999706, -6.04000000000004, 2.0000000000000013, -58.30000000000034, 2.0000000000000013, -56.29000000000034, 2.0000000000000013, -0.00999999999999836, -24.12999999999971, 2.0000000000000013, -18.099999999999703, -18.099999999999703, 2.0000000000000013, -26.139999999999713, -22.11999999999973, -10.060000000000041, -54.28000000000024, -80.40999999999921, -36.19000000000002, -0.00999999999999836, -24.12999999999974, -6.040000000000042, -2.020000000000042, -128.65000000000074, -12.070000000000041, -12.070000000000041, -2.020000000000042, -2.020000000000042, -86.4399999999992, 2.0000000000000013, -18.09999999999972, -16.089999999999712], "policy_predator_policy_reward": [7.0, 20.0, 5.0, 12.0, 5.0, 9.0, 9.0, 49.0, 8.0, 13.0, 99.0, 120.0, 7.0, 18.0, 0.0, 16.0, 100.0, 110.0, 54.0, 80.0, 30.0, 13.0, 78.0, 30.0, 24.0, 28.0, 32.0, 13.0, 6.0, 31.0, 114.0, 35.0, 21.0, 25.0, 16.0, 19.0, 40.0, 18.0, 10.0, 44.0, 1.0, 2.0, 9.0, 9.0, 3.0, 69.0, 19.0, 42.0, 25.0, 21.0, 13.0, 16.0, 56.0, 11.0, 22.0, 12.0, 62.0, 76.0, 0.0, 4.0, 32.0, 28.0, 11.0, 8.0, 22.0, 22.0, 25.0, 24.0, 31.0, 36.0, 55.0, 64.0, 1.0, 5.0, 10.0, 11.0, 7.0, 33.0, 47.0, 34.0, 46.0, 36.0, 12.0, 16.0, 4.0, 4.0, 19.0, 6.0, 5.0, 23.0, 18.0, 80.0, 0.0, 1.0, 67.0, 61.0, 36.0, 30.0, 1.0, 22.0, 33.0, 11.0, 11.0, 10.0, 6.0, 5.0, 6.0, 4.0, 41.0, 55.0, 8.0, 6.0, 9.0, 10.0, 25.0, 17.0, 18.0, 67.0, 16.0, 16.0, 19.0, 23.0, 7.0, 0.0, 9.0, 15.0, 11.0, 33.0, 79.0, 56.0, 38.0, 62.0, 6.0, 72.0, 29.0, 24.0, 24.0, 20.0, 36.0, 20.0, 6.0, 8.0, 6.0, 1.0, 22.0, 11.0, 29.0, 26.0, 6.0, 9.0, 10.0, 37.0, 90.0, 39.0, 30.0, 38.0, 5.0, 5.0, 36.0, 5.0, 2.0, 60.0, 2.0, 1.0, 6.0, 1.0, 7.0, 6.0, 0.0, 14.0, 21.0, 30.0, 5.0, 24.0, 1.0, 0.0, 12.0, 12.0, 10.0, 10.0, 7.0, 12.0, 12.0, 6.0, 24.0, 45.0, 17.0, 19.0, 13.0, 14.0, 37.0, 30.0, 2.0, 7.0, 2.0, 2.0, 44.0, 0.0, 18.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 13.024511367228271, "mean_inference_ms": 21.09436495488364, "mean_action_processing_ms": 2.655167845545409, "mean_env_wait_ms": 2.594535854167517, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.008823513984680176, "StateBufferConnector_ms": 0.004110455513000488, "ViewRequirementAgentConnector_ms": 0.11437714099884033}, "num_episodes": 18, "episode_return_max": 3.9599999999999596, "episode_return_min": -126.3899999999997, "episode_return_mean": -27.0303999999999, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1552000, "num_agent_steps_trained": 1552000, "num_env_steps_sampled": 388000, "num_env_steps_trained": 388000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 397.7674100840766, "num_env_steps_trained_throughput_per_sec": 397.7674100840766, "timesteps_total": 388000, "num_env_steps_sampled_lifetime": 388000, "num_agent_steps_sampled_lifetime": 1552000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1552000, "timers": {"training_iteration_time_ms": 194215.619, "restore_workers_time_ms": 0.014, "training_step_time_ms": 194215.569, "sample_time_ms": 93189.846, "learn_time_ms": 101006.494, "learn_throughput": 39.601, "synch_weights_time_ms": 15.994}, "counters": {"num_env_steps_sampled": 388000, "num_env_steps_trained": 388000, "num_agent_steps_sampled": 1552000, "num_agent_steps_trained": 1552000}, "done": false, "training_iteration": 97, "trial_id": "8e499_00000", "date": "2024-08-15_04-46-01", "timestamp": 1723677361, "time_this_iter_s": 10.060909032821655, "time_total_s": 9699.591669082642, "pid": 33199, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x15818de50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 9699.591669082642, "iterations_since_restore": 97, "perf": {"cpu_util_percent": 29.742857142857144, "ram_util_percent": 80.05714285714285}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.0869117697710715, "cur_kl_coeff": 0.0008789062500000002, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.3925604243757865, "policy_loss": -0.004746156431015128, "vf_loss": 2.3973016391355526, "vf_explained_var": 0.0690800425236818, "kl": 0.005621375441097809, "entropy": 0.4022507714689093, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 184275.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7197754199069644, "cur_kl_coeff": 0.0421875, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.4567685725827695, "policy_loss": -0.0074151747600081815, "vf_loss": 2.46379417300855, "vf_explained_var": 0.05712566640641954, "kl": 0.009234507406458498, "entropy": 0.68691543170384, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 184275.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 392000, "num_env_steps_trained": 392000, "num_agent_steps_sampled": 1568000, "num_agent_steps_trained": 1568000}, "env_runners": {"episode_reward_max": 3.9599999999999596, "episode_reward_min": -136.4299999999991, "episode_reward_mean": -26.84829999999987, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -203.02000000000058, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 2.0000000000000013, "predator_policy": 95.0}, "policy_reward_mean": {"prey_policy": -35.014149999999944, "predator_policy": 21.59}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-62.69000000000017, -57.610000000000554, -36.43000000000012, -11.22000000000008, -63.66999999999928, -20.28999999999965, -18.799999999999944, -0.04000000000004011, -10.370000000000077, -15.189999999999767, -0.24000000000004018, -23.37999999999945, -63.669999999998765, -82.01999999999848, -0.050000000000041, -13.190000000000051, -22.329999999999504, -75.79999999999927, -62.73999999999965, -24.279999999999465, 3.9599999999999596, -21.249999999999417, -16.239999999999444, -76.88999999999955, 2.989999999999981, -56.940000000000275, -2.3600000000000527, -25.259999999999437, -40.440000000000666, -17.209999999999667, -5.100000000000083, -6.100000000000083, -52.760000000000545, 1.920000000000003, -3.1300000000000807, -22.33999999999944, -91.89999999999883, -4.200000000000081, -12.290000000000077, -3.070000000000082, -2.1500000000000785, -34.410000000000466, -35.8700000000002, -54.79000000000012, -112.96999999999854, -5.310000000000079, -38.4300000000005, -24.41999999999952, -8.130000000000082, -3.0700000000000838, -17.269999999999726, -9.340000000000076, -11.150000000000082, -27.389999999999965, -82.06999999999985, -18.44999999999952, 3.9499999999999598, -37.410000000000494, -58.620000000000594, 0.9699999999999841, -3.070000000000073, -9.130000000000082, -14.159999999999746, -5.300000000000079, -25.289999999999452, 2.989999999999981, 1.8700000000000023, -16.199999999999406, -5.1400000000000805, -14.179999999999788, -65.68999999999889, -0.2000000000000446, -3.1700000000000736, -63.66999999999942, -15.139999999999551, -0.040000000000040996, -40.44000000000062, -16.18999999999944, -4.080000000000084, -114.06999999999877, -111.98999999999923, -19.330000000000044, -6.1300000000000825, -3.0700000000000838, -29.579999999999576, -8.280000000000078, -9.130000000000082, -40.38000000000066, -136.4299999999991, -36.45000000000055, -7.160000000000082, -0.30000000000003935, -21.379999999999484, 1.960000000000003, -63.66999999999942, 2.989999999999981, -59.6500000000006, -25.289999999999438, -13.220000000000077, 0.9099999999999827], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-136.6900000000009, 2.0000000000000013, -92.46999999999932, -26.13999999999979, -32.170000000000364, -50.26000000000015, -12.070000000000041, -28.149999999999793, -92.46999999999952, -38.20000000000027, -10.060000000000041, -44.23000000000023, -138.70000000000002, -18.099999999999703, 2.0000000000000013, -6.040000000000042, -72.36999999999921, 2.0000000000000013, -28.149999999999814, -6.040000000000041, -44.230000000000345, -0.00999999999999836, -48.2500000000003, -24.12999999999972, -70.35999999999926, -60.310000000000336, -122.6199999999993, -78.39999999999918, -8.050000000000042, 2.0000000000000013, -34.18000000000022, -0.009999999999998581, 2.0000000000000013, -64.32999999999919, -134.68000000000035, -22.119999999999752, -38.20000000000024, -106.53999999999935, -44.230000000000295, -8.050000000000042, 2.0000000000000013, -6.040000000000042, -26.13999999999971, -20.1099999999998, -46.24000000000035, 2.0000000000000013, -30.159999999999712, -144.72999999999973, 2.0000000000000013, -0.00999999999999836, -168.85000000000068, -16.08999999999982, 2.0000000000000013, -70.3599999999994, -24.129999999999754, -24.129999999999722, -32.17000000000022, -52.27000000000033, -34.18000000000019, -4.030000000000042, -6.040000000000042, -10.060000000000041, -16.089999999999712, -0.00999999999999836, -46.2400000000001, -102.51999999999924, -14.080000000000041, 2.0000000000000013, -10.06000000000003, -12.070000000000041, -30.159999999999712, -34.18000000000029, -92.46999999999964, -84.4299999999994, -22.119999999999795, -14.080000000000041, -10.060000000000024, -44.23000000000032, -4.030000000000042, -6.040000000000038, -28.149999999999714, 2.0000000000000013, -6.040000000000037, -72.36999999999938, -164.8300000000002, -6.040000000000042, -156.7900000000002, 2.0000000000000013, -58.3000000000003, -132.67000000000104, -8.050000000000042, -50.26000000000034, 2.0000000000000013, -84.42999999999931, -64.32999999999926, -16.089999999999822, -8.050000000000042, -14.080000000000041, -10.060000000000041, -0.009999999999998581, -32.170000000000115, -18.09999999999971, 2.0000000000000013, -66.3399999999993, -28.14999999999971, 2.0000000000000013, -54.28000000000008, -20.109999999999705, -203.02000000000058, -8.050000000000042, -74.37999999999924, -12.070000000000041, -8.050000000000042, 2.0000000000000013, -50.260000000000346, -28.149999999999785, -12.070000000000041, -108.54999999999926, -4.030000000000042, 2.0000000000000013, 2.0000000000000013, -12.070000000000036, -24.129999999999722, 2.0000000000000013, -22.119999999999706, -6.04000000000004, 2.0000000000000013, -58.30000000000034, 2.0000000000000013, -56.29000000000034, 2.0000000000000013, -0.00999999999999836, -24.12999999999971, 2.0000000000000013, -18.099999999999703, -18.099999999999703, 2.0000000000000013, -26.139999999999713, -22.11999999999973, -10.060000000000041, -54.28000000000024, -80.40999999999921, -36.19000000000002, -0.00999999999999836, -24.12999999999974, -6.040000000000042, -2.020000000000042, -128.65000000000074, -12.070000000000041, -12.070000000000041, -2.020000000000042, -2.020000000000042, -86.4399999999992, 2.0000000000000013, -18.09999999999972, -16.089999999999712, -2.0200000000000413, -10.060000000000041, -46.24000000000035, -164.83000000000078, -58.300000000000104, -136.6900000000005, -22.119999999999987, -40.210000000000356, -24.130000000000038, 2.0000000000000013, -12.070000000000041, 2.0000000000000013, -18.099999999999707, -94.47999999999924, -50.260000000000346, -2.0200000000000156, -24.12999999999971, 2.0000000000000013, -24.129999999999725, -48.25000000000032, -118.59999999999943, -164.82999999999953, -82.41999999999926, -4.030000000000042, -16.089999999999826, -12.070000000000041, -58.30000000000034, 2.0000000000000013, 2.0000000000000013, -74.37999999999917, 2.0000000000000013, -6.040000000000042, -132.6700000000007, 2.0000000000000013, -0.00999999999999836, 2.0000000000000013, -28.149999999999746, -98.49999999999929, -22.11999999999976, -32.170000000000364, -32.17000000000013, -8.050000000000042, -16.0899999999997, 2.0000000000000013], "policy_predator_policy_reward": [3.0, 69.0, 19.0, 42.0, 25.0, 21.0, 13.0, 16.0, 56.0, 11.0, 22.0, 12.0, 62.0, 76.0, 0.0, 4.0, 32.0, 28.0, 11.0, 8.0, 22.0, 22.0, 25.0, 24.0, 31.0, 36.0, 55.0, 64.0, 1.0, 5.0, 10.0, 11.0, 7.0, 33.0, 47.0, 34.0, 46.0, 36.0, 12.0, 16.0, 4.0, 4.0, 19.0, 6.0, 5.0, 23.0, 18.0, 80.0, 0.0, 1.0, 67.0, 61.0, 36.0, 30.0, 1.0, 22.0, 33.0, 11.0, 11.0, 10.0, 6.0, 5.0, 6.0, 4.0, 41.0, 55.0, 8.0, 6.0, 9.0, 10.0, 25.0, 17.0, 18.0, 67.0, 16.0, 16.0, 19.0, 23.0, 7.0, 0.0, 9.0, 15.0, 11.0, 33.0, 79.0, 56.0, 38.0, 62.0, 6.0, 72.0, 29.0, 24.0, 24.0, 20.0, 36.0, 20.0, 6.0, 8.0, 6.0, 1.0, 22.0, 11.0, 29.0, 26.0, 6.0, 9.0, 10.0, 37.0, 90.0, 39.0, 30.0, 38.0, 5.0, 5.0, 36.0, 5.0, 2.0, 60.0, 2.0, 1.0, 6.0, 1.0, 7.0, 6.0, 0.0, 14.0, 21.0, 30.0, 5.0, 24.0, 1.0, 0.0, 12.0, 12.0, 10.0, 10.0, 7.0, 12.0, 12.0, 6.0, 24.0, 45.0, 17.0, 19.0, 13.0, 14.0, 37.0, 30.0, 2.0, 7.0, 2.0, 2.0, 44.0, 0.0, 18.0, 0.0, 1.0, 7.0, 95.0, 2.0, 74.0, 9.0, 30.0, 13.0, 10.0, 6.0, 0.0, 7.0, 37.0, 46.0, 20.0, 24.0, 8.0, 5.0, 32.0, 0.0, 71.0, 76.0, 29.0, 21.0, 14.0, 7.0, 27.0, 29.0, 35.0, 16.0, 2.0, 4.0, 62.0, 5.0, 0.0, 1.0, 49.0, 18.0, 4.0, 25.0, 17.0, 10.0, 6.0, 9.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 11.78070342682312, "mean_inference_ms": 21.332859730397423, "mean_action_processing_ms": 2.6321203274869838, "mean_env_wait_ms": 2.7817320507605183, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.008101344108581543, "StateBufferConnector_ms": 0.0039327144622802734, "ViewRequirementAgentConnector_ms": 0.11319613456726074}, "num_episodes": 22, "episode_return_max": 3.9599999999999596, "episode_return_min": -136.4299999999991, "episode_return_mean": -26.84829999999987, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1568000, "num_agent_steps_trained": 1568000, "num_env_steps_sampled": 392000, "num_env_steps_trained": 392000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 382.1553319674594, "num_env_steps_trained_throughput_per_sec": 382.1553319674594, "timesteps_total": 392000, "num_env_steps_sampled_lifetime": 392000, "num_agent_steps_sampled_lifetime": 1568000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1568000, "timers": {"training_iteration_time_ms": 194218.823, "restore_workers_time_ms": 0.014, "training_step_time_ms": 194218.774, "sample_time_ms": 93160.335, "learn_time_ms": 101039.32, "learn_throughput": 39.589, "synch_weights_time_ms": 15.932}, "counters": {"num_env_steps_sampled": 392000, "num_env_steps_trained": 392000, "num_agent_steps_sampled": 1568000, "num_agent_steps_trained": 1568000}, "done": false, "training_iteration": 98, "trial_id": "8e499_00000", "date": "2024-08-15_04-46-12", "timestamp": 1723677372, "time_this_iter_s": 10.472424983978271, "time_total_s": 9710.06409406662, "pid": 33199, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b40eb670>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 9710.06409406662, "iterations_since_restore": 98, "perf": {"cpu_util_percent": 29.72666666666667, "ram_util_percent": 79.08666666666666}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9972332015239374, "cur_kl_coeff": 0.0008789062500000002, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.605865593215145, "policy_loss": -0.0037076518507477233, "vf_loss": 1.6095651640463127, "vf_explained_var": 0.062340996000501844, "kl": 0.009197345116002776, "entropy": 0.3712915977946034, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 186165.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2719397408148598, "cur_kl_coeff": 0.0421875, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.4100131001737384, "policy_loss": -0.011043937304968793, "vf_loss": 1.420674998104257, "vf_explained_var": 0.08005779492791998, "kl": 0.009055784280827347, "entropy": 0.5447988213685454, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 186165.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 396000, "num_env_steps_trained": 396000, "num_agent_steps_sampled": 1584000, "num_agent_steps_trained": 1584000}, "env_runners": {"episode_reward_max": 3.9999999999999587, "episode_reward_min": -136.4299999999991, "episode_reward_mean": -25.6502999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -203.02000000000058, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 2.0000000000000013, "predator_policy": 95.0}, "policy_reward_mean": {"prey_policy": -33.20514999999997, "predator_policy": 20.38}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-62.73999999999965, -24.279999999999465, 3.9599999999999596, -21.249999999999417, -16.239999999999444, -76.88999999999955, 2.989999999999981, -56.940000000000275, -2.3600000000000527, -25.259999999999437, -40.440000000000666, -17.209999999999667, -5.100000000000083, -6.100000000000083, -52.760000000000545, 1.920000000000003, -3.1300000000000807, -22.33999999999944, -91.89999999999883, -4.200000000000081, -12.290000000000077, -3.070000000000082, -2.1500000000000785, -34.410000000000466, -35.8700000000002, -54.79000000000012, -112.96999999999854, -5.310000000000079, -38.4300000000005, -24.41999999999952, -8.130000000000082, -3.0700000000000838, -17.269999999999726, -9.340000000000076, -11.150000000000082, -27.389999999999965, -82.06999999999985, -18.44999999999952, 3.9499999999999598, -37.410000000000494, -58.620000000000594, 0.9699999999999841, -3.070000000000073, -9.130000000000082, -14.159999999999746, -5.300000000000079, -25.289999999999452, 2.989999999999981, 1.8700000000000023, -16.199999999999406, -5.1400000000000805, -14.179999999999788, -65.68999999999889, -0.2000000000000446, -3.1700000000000736, -63.66999999999942, -15.139999999999551, -0.040000000000040996, -40.44000000000062, -16.18999999999944, -4.080000000000084, -114.06999999999877, -111.98999999999923, -19.330000000000044, -6.1300000000000825, -3.0700000000000838, -29.579999999999576, -8.280000000000078, -9.130000000000082, -40.38000000000066, -136.4299999999991, -36.45000000000055, -7.160000000000082, -0.30000000000003935, -21.379999999999484, 1.960000000000003, -63.66999999999942, 2.989999999999981, -59.6500000000006, -25.289999999999438, -13.220000000000077, 0.9099999999999827, -16.19999999999948, 0.969999999999981, -8.16000000000008, -75.68999999999906, -7.110000000000083, 3.9999999999999587, 0.7599999999999852, -54.060000000000464, -36.42000000000021, 2.9599999999999818, -81.84999999999934, -17.239999999999462, -11.210000000000077, 0.969999999999981, -0.050000000000041, -14.179999999999739, -85.1799999999991, -59.50000000000068], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-38.20000000000024, -106.53999999999935, -44.230000000000295, -8.050000000000042, 2.0000000000000013, -6.040000000000042, -26.13999999999971, -20.1099999999998, -46.24000000000035, 2.0000000000000013, -30.159999999999712, -144.72999999999973, 2.0000000000000013, -0.00999999999999836, -168.85000000000068, -16.08999999999982, 2.0000000000000013, -70.3599999999994, -24.129999999999754, -24.129999999999722, -32.17000000000022, -52.27000000000033, -34.18000000000019, -4.030000000000042, -6.040000000000042, -10.060000000000041, -16.089999999999712, -0.00999999999999836, -46.2400000000001, -102.51999999999924, -14.080000000000041, 2.0000000000000013, -10.06000000000003, -12.070000000000041, -30.159999999999712, -34.18000000000029, -92.46999999999964, -84.4299999999994, -22.119999999999795, -14.080000000000041, -10.060000000000024, -44.23000000000032, -4.030000000000042, -6.040000000000038, -28.149999999999714, 2.0000000000000013, -6.040000000000037, -72.36999999999938, -164.8300000000002, -6.040000000000042, -156.7900000000002, 2.0000000000000013, -58.3000000000003, -132.67000000000104, -8.050000000000042, -50.26000000000034, 2.0000000000000013, -84.42999999999931, -64.32999999999926, -16.089999999999822, -8.050000000000042, -14.080000000000041, -10.060000000000041, -0.009999999999998581, -32.170000000000115, -18.09999999999971, 2.0000000000000013, -66.3399999999993, -28.14999999999971, 2.0000000000000013, -54.28000000000008, -20.109999999999705, -203.02000000000058, -8.050000000000042, -74.37999999999924, -12.070000000000041, -8.050000000000042, 2.0000000000000013, -50.260000000000346, -28.149999999999785, -12.070000000000041, -108.54999999999926, -4.030000000000042, 2.0000000000000013, 2.0000000000000013, -12.070000000000036, -24.129999999999722, 2.0000000000000013, -22.119999999999706, -6.04000000000004, 2.0000000000000013, -58.30000000000034, 2.0000000000000013, -56.29000000000034, 2.0000000000000013, -0.00999999999999836, -24.12999999999971, 2.0000000000000013, -18.099999999999703, -18.099999999999703, 2.0000000000000013, -26.139999999999713, -22.11999999999973, -10.060000000000041, -54.28000000000024, -80.40999999999921, -36.19000000000002, -0.00999999999999836, -24.12999999999974, -6.040000000000042, -2.020000000000042, -128.65000000000074, -12.070000000000041, -12.070000000000041, -2.020000000000042, -2.020000000000042, -86.4399999999992, 2.0000000000000013, -18.09999999999972, -16.089999999999712, -2.0200000000000413, -10.060000000000041, -46.24000000000035, -164.83000000000078, -58.300000000000104, -136.6900000000005, -22.119999999999987, -40.210000000000356, -24.130000000000038, 2.0000000000000013, -12.070000000000041, 2.0000000000000013, -18.099999999999707, -94.47999999999924, -50.260000000000346, -2.0200000000000156, -24.12999999999971, 2.0000000000000013, -24.129999999999725, -48.25000000000032, -118.59999999999943, -164.82999999999953, -82.41999999999926, -4.030000000000042, -16.089999999999826, -12.070000000000041, -58.30000000000034, 2.0000000000000013, 2.0000000000000013, -74.37999999999917, 2.0000000000000013, -6.040000000000042, -132.6700000000007, 2.0000000000000013, -0.00999999999999836, 2.0000000000000013, -28.149999999999746, -98.49999999999929, -22.11999999999976, -32.170000000000364, -32.17000000000013, -8.050000000000042, -16.0899999999997, 2.0000000000000013, -28.149999999999743, -8.050000000000042, -4.030000000000042, 2.0000000000000013, -30.15999999999978, 2.0000000000000013, -114.57999999999934, -20.10999999999984, 2.0000000000000013, -20.109999999999708, 2.0000000000000013, 2.0000000000000013, -46.24000000000035, 2.0000000000000013, -154.7800000000005, -54.28000000000033, -82.4199999999997, 2.0000000000000013, 2.0000000000000013, -6.040000000000042, -34.1800000000003, -132.6699999999998, -46.240000000000336, 2.0000000000000013, 2.0000000000000013, -40.210000000000214, -4.030000000000042, 2.0000000000000013, -8.050000000000042, 2.0000000000000013, -10.060000000000041, -22.119999999999706, -90.46, -142.72000000000065, -40.21000000000032, -56.29000000000034], "policy_predator_policy_reward": [46.0, 36.0, 12.0, 16.0, 4.0, 4.0, 19.0, 6.0, 5.0, 23.0, 18.0, 80.0, 0.0, 1.0, 67.0, 61.0, 36.0, 30.0, 1.0, 22.0, 33.0, 11.0, 11.0, 10.0, 6.0, 5.0, 6.0, 4.0, 41.0, 55.0, 8.0, 6.0, 9.0, 10.0, 25.0, 17.0, 18.0, 67.0, 16.0, 16.0, 19.0, 23.0, 7.0, 0.0, 9.0, 15.0, 11.0, 33.0, 79.0, 56.0, 38.0, 62.0, 6.0, 72.0, 29.0, 24.0, 24.0, 20.0, 36.0, 20.0, 6.0, 8.0, 6.0, 1.0, 22.0, 11.0, 29.0, 26.0, 6.0, 9.0, 10.0, 37.0, 90.0, 39.0, 30.0, 38.0, 5.0, 5.0, 36.0, 5.0, 2.0, 60.0, 2.0, 1.0, 6.0, 1.0, 7.0, 6.0, 0.0, 14.0, 21.0, 30.0, 5.0, 24.0, 1.0, 0.0, 12.0, 12.0, 10.0, 10.0, 7.0, 12.0, 12.0, 6.0, 24.0, 45.0, 17.0, 19.0, 13.0, 14.0, 37.0, 30.0, 2.0, 7.0, 2.0, 2.0, 44.0, 0.0, 18.0, 0.0, 1.0, 7.0, 95.0, 2.0, 74.0, 9.0, 30.0, 13.0, 10.0, 6.0, 0.0, 7.0, 37.0, 46.0, 20.0, 24.0, 8.0, 5.0, 32.0, 0.0, 71.0, 76.0, 29.0, 21.0, 14.0, 7.0, 27.0, 29.0, 35.0, 16.0, 2.0, 4.0, 62.0, 5.0, 0.0, 1.0, 49.0, 18.0, 4.0, 25.0, 17.0, 10.0, 6.0, 9.0, 2.0, 18.0, 0.0, 3.0, 12.0, 8.0, 58.0, 1.0, 11.0, 0.0, 0.0, 0.0, 22.0, 23.0, 83.0, 72.0, 27.0, 17.0, 4.0, 3.0, 56.0, 29.0, 3.0, 24.0, 18.0, 9.0, 3.0, 0.0, 4.0, 2.0, 12.0, 6.0, 78.0, 70.0, 34.0, 3.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 12.765180787711742, "mean_inference_ms": 20.719581547251483, "mean_action_processing_ms": 2.610361413269554, "mean_env_wait_ms": 2.5411761259200354, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006828665733337402, "StateBufferConnector_ms": 0.0038901567459106445, "ViewRequirementAgentConnector_ms": 0.11201047897338867}, "num_episodes": 18, "episode_return_max": 3.9999999999999587, "episode_return_min": -136.4299999999991, "episode_return_mean": -25.6502999999999, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1584000, "num_agent_steps_trained": 1584000, "num_env_steps_sampled": 396000, "num_env_steps_trained": 396000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 395.646198042745, "num_env_steps_trained_throughput_per_sec": 395.646198042745, "timesteps_total": 396000, "num_env_steps_sampled_lifetime": 396000, "num_agent_steps_sampled_lifetime": 1584000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1584000, "timers": {"training_iteration_time_ms": 194183.142, "restore_workers_time_ms": 0.014, "training_step_time_ms": 194183.095, "sample_time_ms": 93143.962, "learn_time_ms": 101020.423, "learn_throughput": 39.596, "synch_weights_time_ms": 15.607}, "counters": {"num_env_steps_sampled": 396000, "num_env_steps_trained": 396000, "num_agent_steps_sampled": 1584000, "num_agent_steps_trained": 1584000}, "done": false, "training_iteration": 99, "trial_id": "8e499_00000", "date": "2024-08-15_04-46-22", "timestamp": 1723677382, "time_this_iter_s": 10.114382028579712, "time_total_s": 9720.1784760952, "pid": 33199, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x1580f8940>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 9720.1784760952, "iterations_since_restore": 99, "perf": {"cpu_util_percent": 31.953333333333333, "ram_util_percent": 77.82000000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9318915837340884, "cur_kl_coeff": 0.0008789062500000002, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.3648140734465664, "policy_loss": -0.0028853635529115323, "vf_loss": 1.3676936317057837, "vf_explained_var": 0.1274028392065139, "kl": 0.006602499533516613, "entropy": 0.36788016325897643, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 188055.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6190998362485693, "cur_kl_coeff": 0.0421875, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.484891142274337, "policy_loss": -0.010210889066007757, "vf_loss": 1.4948793757529486, "vf_explained_var": 0.1118707589686863, "kl": 0.005277769409799331, "entropy": 0.4829644519816, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 188055.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 400000, "num_env_steps_trained": 400000, "num_agent_steps_sampled": 1600000, "num_agent_steps_trained": 1600000}, "env_runners": {"episode_reward_max": 3.9999999999999587, "episode_reward_min": -136.4299999999991, "episode_reward_mean": -24.416499999999896, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -203.02000000000058, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 2.0000000000000013, "predator_policy": 95.0}, "policy_reward_mean": {"prey_policy": -30.81324999999997, "predator_policy": 18.605}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-34.410000000000466, -35.8700000000002, -54.79000000000012, -112.96999999999854, -5.310000000000079, -38.4300000000005, -24.41999999999952, -8.130000000000082, -3.0700000000000838, -17.269999999999726, -9.340000000000076, -11.150000000000082, -27.389999999999965, -82.06999999999985, -18.44999999999952, 3.9499999999999598, -37.410000000000494, -58.620000000000594, 0.9699999999999841, -3.070000000000073, -9.130000000000082, -14.159999999999746, -5.300000000000079, -25.289999999999452, 2.989999999999981, 1.8700000000000023, -16.199999999999406, -5.1400000000000805, -14.179999999999788, -65.68999999999889, -0.2000000000000446, -3.1700000000000736, -63.66999999999942, -15.139999999999551, -0.040000000000040996, -40.44000000000062, -16.18999999999944, -4.080000000000084, -114.06999999999877, -111.98999999999923, -19.330000000000044, -6.1300000000000825, -3.0700000000000838, -29.579999999999576, -8.280000000000078, -9.130000000000082, -40.38000000000066, -136.4299999999991, -36.45000000000055, -7.160000000000082, -0.30000000000003935, -21.379999999999484, 1.960000000000003, -63.66999999999942, 2.989999999999981, -59.6500000000006, -25.289999999999438, -13.220000000000077, 0.9099999999999827, -16.19999999999948, 0.969999999999981, -8.16000000000008, -75.68999999999906, -7.110000000000083, 3.9999999999999587, 0.7599999999999852, -54.060000000000464, -36.42000000000021, 2.9599999999999818, -81.84999999999934, -17.239999999999462, -11.210000000000077, 0.969999999999981, -0.050000000000041, -14.179999999999739, -85.1799999999991, -59.50000000000068, -3.070000000000083, -5.180000000000081, -27.49999999999951, -31.43000000000016, -10.14000000000008, -33.370000000000495, -88.91999999999858, -14.179999999999795, -17.289999999999452, 0.969999999999981, 2.989999999999981, -14.169999999999746, -10.200000000000081, -18.219999999999434, 3.9999999999999587, -55.560000000000684, -22.259999999999433, -10.140000000000082, -29.239999999999753, -12.160000000000075, 1.9800000000000026, -11.15000000000008, -10.160000000000082], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-6.040000000000037, -72.36999999999938, -164.8300000000002, -6.040000000000042, -156.7900000000002, 2.0000000000000013, -58.3000000000003, -132.67000000000104, -8.050000000000042, -50.26000000000034, 2.0000000000000013, -84.42999999999931, -64.32999999999926, -16.089999999999822, -8.050000000000042, -14.080000000000041, -10.060000000000041, -0.009999999999998581, -32.170000000000115, -18.09999999999971, 2.0000000000000013, -66.3399999999993, -28.14999999999971, 2.0000000000000013, -54.28000000000008, -20.109999999999705, -203.02000000000058, -8.050000000000042, -74.37999999999924, -12.070000000000041, -8.050000000000042, 2.0000000000000013, -50.260000000000346, -28.149999999999785, -12.070000000000041, -108.54999999999926, -4.030000000000042, 2.0000000000000013, 2.0000000000000013, -12.070000000000036, -24.129999999999722, 2.0000000000000013, -22.119999999999706, -6.04000000000004, 2.0000000000000013, -58.30000000000034, 2.0000000000000013, -56.29000000000034, 2.0000000000000013, -0.00999999999999836, -24.12999999999971, 2.0000000000000013, -18.099999999999703, -18.099999999999703, 2.0000000000000013, -26.139999999999713, -22.11999999999973, -10.060000000000041, -54.28000000000024, -80.40999999999921, -36.19000000000002, -0.00999999999999836, -24.12999999999974, -6.040000000000042, -2.020000000000042, -128.65000000000074, -12.070000000000041, -12.070000000000041, -2.020000000000042, -2.020000000000042, -86.4399999999992, 2.0000000000000013, -18.09999999999972, -16.089999999999712, -2.0200000000000413, -10.060000000000041, -46.24000000000035, -164.83000000000078, -58.300000000000104, -136.6900000000005, -22.119999999999987, -40.210000000000356, -24.130000000000038, 2.0000000000000013, -12.070000000000041, 2.0000000000000013, -18.099999999999707, -94.47999999999924, -50.260000000000346, -2.0200000000000156, -24.12999999999971, 2.0000000000000013, -24.129999999999725, -48.25000000000032, -118.59999999999943, -164.82999999999953, -82.41999999999926, -4.030000000000042, -16.089999999999826, -12.070000000000041, -58.30000000000034, 2.0000000000000013, 2.0000000000000013, -74.37999999999917, 2.0000000000000013, -6.040000000000042, -132.6700000000007, 2.0000000000000013, -0.00999999999999836, 2.0000000000000013, -28.149999999999746, -98.49999999999929, -22.11999999999976, -32.170000000000364, -32.17000000000013, -8.050000000000042, -16.0899999999997, 2.0000000000000013, -28.149999999999743, -8.050000000000042, -4.030000000000042, 2.0000000000000013, -30.15999999999978, 2.0000000000000013, -114.57999999999934, -20.10999999999984, 2.0000000000000013, -20.109999999999708, 2.0000000000000013, 2.0000000000000013, -46.24000000000035, 2.0000000000000013, -154.7800000000005, -54.28000000000033, -82.4199999999997, 2.0000000000000013, 2.0000000000000013, -6.040000000000042, -34.1800000000003, -132.6699999999998, -46.240000000000336, 2.0000000000000013, 2.0000000000000013, -40.210000000000214, -4.030000000000042, 2.0000000000000013, -8.050000000000042, 2.0000000000000013, -10.060000000000041, -22.119999999999706, -90.46, -142.72000000000065, -40.21000000000032, -56.29000000000034, 2.0000000000000013, -12.070000000000041, -34.18000000000036, 2.0000000000000013, -92.46999999999926, -4.03000000000001, -64.32999999999936, -18.099999999999703, -20.109999999999708, -4.030000000000042, -12.070000000000041, -58.30000000000026, -142.72000000000094, -38.20000000000036, -18.099999999999717, -14.080000000000041, -14.080000000000041, -40.210000000000356, -4.030000000000042, 2.0000000000000013, 2.0000000000000013, -0.00999999999999836, -20.10999999999971, -10.060000000000041, -36.190000000000126, -0.00999999999999836, -20.109999999999708, -20.109999999999793, 2.0000000000000013, 2.0000000000000013, -48.25000000000033, -60.310000000000336, -10.060000000000041, -38.20000000000036, -12.070000000000041, -12.070000000000041, -24.12999999999971, -20.109999999999705, -30.159999999999734, 2.0000000000000013, -2.020000000000042, 2.0000000000000013, -10.06000000000004, -16.08999999999972, -4.030000000000042, -24.129999999999708], "policy_predator_policy_reward": [11.0, 33.0, 79.0, 56.0, 38.0, 62.0, 6.0, 72.0, 29.0, 24.0, 24.0, 20.0, 36.0, 20.0, 6.0, 8.0, 6.0, 1.0, 22.0, 11.0, 29.0, 26.0, 6.0, 9.0, 10.0, 37.0, 90.0, 39.0, 30.0, 38.0, 5.0, 5.0, 36.0, 5.0, 2.0, 60.0, 2.0, 1.0, 6.0, 1.0, 7.0, 6.0, 0.0, 14.0, 21.0, 30.0, 5.0, 24.0, 1.0, 0.0, 12.0, 12.0, 10.0, 10.0, 7.0, 12.0, 12.0, 6.0, 24.0, 45.0, 17.0, 19.0, 13.0, 14.0, 37.0, 30.0, 2.0, 7.0, 2.0, 2.0, 44.0, 0.0, 18.0, 0.0, 1.0, 7.0, 95.0, 2.0, 74.0, 9.0, 30.0, 13.0, 10.0, 6.0, 0.0, 7.0, 37.0, 46.0, 20.0, 24.0, 8.0, 5.0, 32.0, 0.0, 71.0, 76.0, 29.0, 21.0, 14.0, 7.0, 27.0, 29.0, 35.0, 16.0, 2.0, 4.0, 62.0, 5.0, 0.0, 1.0, 49.0, 18.0, 4.0, 25.0, 17.0, 10.0, 6.0, 9.0, 2.0, 18.0, 0.0, 3.0, 12.0, 8.0, 58.0, 1.0, 11.0, 0.0, 0.0, 0.0, 22.0, 23.0, 83.0, 72.0, 27.0, 17.0, 4.0, 3.0, 56.0, 29.0, 3.0, 24.0, 18.0, 9.0, 3.0, 0.0, 4.0, 2.0, 12.0, 6.0, 78.0, 70.0, 34.0, 3.0, 4.0, 3.0, 16.0, 11.0, 43.0, 26.0, 27.0, 24.0, 0.0, 14.0, 32.0, 5.0, 20.0, 72.0, 15.0, 3.0, 18.0, 19.0, 3.0, 0.0, 0.0, 1.0, 15.0, 1.0, 18.0, 8.0, 16.0, 6.0, 0.0, 0.0, 33.0, 20.0, 21.0, 5.0, 2.0, 12.0, 15.0, 0.0, 1.0, 15.0, 0.0, 2.0, 6.0, 9.0, 7.0, 11.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 11.77283556190523, "mean_inference_ms": 21.353215089765808, "mean_action_processing_ms": 2.794950585735301, "mean_env_wait_ms": 2.5194000552880444, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003795146942138672, "StateBufferConnector_ms": 0.0038825273513793945, "ViewRequirementAgentConnector_ms": 0.09863996505737305}, "num_episodes": 23, "episode_return_max": 3.9999999999999587, "episode_return_min": -136.4299999999991, "episode_return_mean": -24.416499999999896, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1600000, "num_agent_steps_trained": 1600000, "num_env_steps_sampled": 400000, "num_env_steps_trained": 400000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 391.8313018522566, "num_env_steps_trained_throughput_per_sec": 391.8313018522566, "timesteps_total": 400000, "num_env_steps_sampled_lifetime": 400000, "num_agent_steps_sampled_lifetime": 1600000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1600000, "timers": {"training_iteration_time_ms": 102139.165, "restore_workers_time_ms": 0.014, "training_step_time_ms": 102139.123, "sample_time_ms": 1464.112, "learn_time_ms": 100657.445, "learn_throughput": 39.739, "synch_weights_time_ms": 14.835}, "counters": {"num_env_steps_sampled": 400000, "num_env_steps_trained": 400000, "num_agent_steps_sampled": 1600000, "num_agent_steps_trained": 1600000}, "done": true, "training_iteration": 100, "trial_id": "8e499_00000", "date": "2024-08-15_04-46-32", "timestamp": 1723677392, "time_this_iter_s": 10.213785171508789, "time_total_s": 9730.392261266708, "pid": 33199, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b435cb80>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 9730.392261266708, "iterations_since_restore": 100, "perf": {"cpu_util_percent": 29.335714285714282, "ram_util_percent": 76.99285714285713}}
